,Created At,Updated At,Closed At,Merged At,Details,Id
0,2020-03-23T20:06:41Z,2020-03-23T20:06:41Z,,,"I've purposed implementing an `includer` function passed through options (https://github.com/mde/ejs/issues/500), but now I realized that EJS already supports array of `views` paths (not documented ?), it makes easy to add support for `root` array to handle includes with absolute path from multiple directories :relaxed: 

Although not as flexible as an `includer` function, this should be enough for my case and may require fewer changes to the lib, so I'm suggesting it first.

Anyway, I still available to try https://github.com/mde/ejs/issues/500 if it’s still a good idea, wdyt @mde ?",28671602
1,2019-10-19T23:04:27Z,2019-10-30T05:57:09Z,,,"This runs the tests on **Node 0.10** and **Node 0.12**, which are the oldest **EJS**‑supported **Node** releases, according to `package.json`: https://github.com/mde/ejs/blob/c600a788b7f31b6f0bfd269055bd7b266c97c5ac/package.json#L34-L36",28671602
2,2019-07-29T13:06:38Z,2020-02-03T12:04:53Z,,,"* Fixed typo (`if (e.async)`) that lead to the `Or, if you meant to create an async function, pass async: true as an option.` message always being shown regardless of the `async` option.
* Fixed problem in the `__express` function where a raw Promise was being passed to express.js when `async` was enabled, instead of waiting on the Promise to resolve and passing the result to express.

Edit: If anyone is having this problem and would like to fix it, until this gets merged, use:
```js
ejs.__express = (file, options, callback) => {
	if (options.async) {
		ejs.renderFile(file, options, async (err, promise) => {
			callback(err, await promise);
		});
	}
	else {
		ejs.renderFile(file, options, callback);
	}
}
```",28671602
3,2019-02-24T16:03:20Z,2020-01-15T09:16:51Z,,,"This PR fix #426 and also fix #427. Those are different bugs but they are close so that they are fixed together.

The added regex for parenthesis include can match those patterns : 
```
/^\s*include\(\s*['""](\S+)['""].*\)/

include('../ejs/footer.ejs')
include(   '../ejs/footer.ejs')
include(  '../ejs/footer.ejs'   )
include('../ejs/footer.ejs',    {woot:'bla'})
include(""../ejs/footer.ejs"")
include(   ""../ejs/footer.ejs"")
include(  ""../ejs/footer.ejs""   )
include(""../ejs/footer.ejs"",    {woot:'bla'})
```
",28671602
4,2018-12-18T12:44:51Z,2018-12-18T12:44:51Z,,,"Implementation of the check in [#415](https://github.com/mde/ejs/issues/415).

If views is a string and not an array of strings, it can still use the path. There's a type check for `string` to prevent any trouble if views is `undefined`.",28671602
5,2018-08-24T16:49:21Z,2019-04-19T14:32:50Z,,,"Hi,
I find this project very useful and customisable. It fits my needs against others like mustache, pug, handlebars (and I research for that very recently, yesterday, actually). So, great project.

But, I'm missing some features. I have to say that I'm not using ejs to parse a website or mobile app view.

**Empty delimiters**
I don't want to use %%, ??. Just the open and close marks like:

    fn = ejs.compile('<p>[=name]</p>', {delimiter: '', openDelimiter: '[', closeDelimiter: ']'});
    fn({name: 'geddy'});// <p>geddy</p>

_BTW: I saw [this code](https://runkit.com/embed/lox0oqggvlj1) in `/test/ejs.js`, but it's not working with npm package, neither with runkit_


**Force escape**
All the situations I'm going to use has to return a value. There is no need to put `=` mark.

    fn = ejs.compile('<p>[name]</p>', {delimiter: '', openDelimiter: '[', closeDelimiter: ']', forceEscape:true});
    fn({name: 'geddy'});// <p>geddy</p>

If someone wants to use something like `{{name}}`, it could, now with these changes.

**The PR**
I hope you find this useful.

- I have to change `_REGEX_STRING` in order to find the tokens larger to small;
- Some checks for empty delimiter `d === ''`;
- Big change on `scanLine`. I made a small, but due to the `no-fallthough` rule on switch, I have to pull all the cases below in another switch;
- Added `options.forceEscape` and the checker on `scanLine`;
",28671602
6,2018-07-27T22:01:10Z,2018-07-27T22:01:51Z,,,"Ported from Jade.

TODO: CHANGELOG, tests

[ci skip]",28671602
7,2018-05-22T21:08:52Z,2018-05-22T21:08:52Z,,,,28671602
8,2018-05-09T17:57:55Z,2018-05-09T17:57:55Z,,,I needed to modify the paths of included files on the fly for each single include. To be able to do this I had to expose includeFile(). All tests are passing and no new lines were added. I cannot find a reason in my head not to do this. :),28671602
9,2017-12-19T23:41:14Z,2018-01-03T04:38:16Z,,,"Implementing the idea that I've asked about here #328.

Apologies if I made any mistakes! Feedback would be highly appreciated.
For example, ~~I don't really like that I had to use the 'options' object to pass down the '__output' array~~. Never mind, it's been staring me in the face all along... Still don't like that I had to add a 'required' property to the 'options' object, though.
Also I hope that I've done everything correctly regarding the test (I pretty much just copied an earlier one) and that I haven't forgotten anything...
  ",28671602
10,2017-10-23T23:31:45Z,2017-10-23T23:31:45Z,,,"This will be the next one, *after* #311 

I already create the pull request, in case you want to see the next steps.

It currently re-includes the commits that make #311 . But once #311 is done, I can rebase.

Description of what it does is in #288 ",28671602
11,2017-10-23T20:56:47Z,2018-07-11T18:13:15Z,,,See comments on #295 ,28671602
12,2017-09-08T03:42:42Z,2017-09-08T15:19:36Z,,,Just for browsing,28671602
13,2017-08-16T05:55:25Z,2017-10-23T22:51:25Z,,,"This branch contains my entire work.

It is ready for review.  Please see #288 for an overview what changed.
",28671602
14,2017-07-31T10:12:44Z,2017-07-31T12:35:59Z,,,"**feature:** Add expression/output tag with support of whitespace slurping.

The tag is a combination of `<%=`+`<%_`.

Tag introduced `<%=_` and `<%-_`

Proposal for issue #289.

**TODO:**
If needed update test cases.",28671602
15,2017-03-24T02:29:46Z,2017-03-25T19:17:46Z,,,"The `escape` option was not being propagated through to included files, since the key was not saved in the `Template` copy of the options. Using the same key for the input and saved copy fixes this.",28671602
16,2015-02-24T09:33:53Z,2017-09-05T04:33:53Z,,,"It seems that the only way the file can truly be cached is when it's actually loaded by EJS from F/S. Anything that is compile()'d is never cached. Without explicitly meddling with the cache, it's also not possible to update the cache.

This suggests to store compile()'d templates in the cache if `filename` and `cache` options are set. This allows to update the cache.

Thank you.
",28671602
17,2020-03-24T13:52:49Z,2020-03-26T17:15:46Z,,,"### This PR will...
Type the following files:

* src/js/playlist/source.js
* src/js/plugins/loader.js
* src/js/plugins/model.js
* src/js/plugins/utils.ts

### Why is this Pull Request needed?
TS BBY

### Are there any points in the code the reviewer needs to double check?
My PlaylistItemSource typing for sure

### Are there any Pull Requests open in other repos which need to be merged with this?
Nah

#### Addresses Issue(s):

JW8-11034

### Checklist
- [ ] Jenkins builds and unit tests are passing
- [ ] I have reviewed the automated results
",18307175
18,2020-03-16T22:25:57Z,2020-03-26T14:50:11Z,,,"### This PR will...
Remove custom properties from TextTracks when clearing them of cues, so that our tracks mixin will recognize when new cues are added after reloading a video.

### Why is this Pull Request needed?
This fixes two issues in Safari where captions are rendered natively:
1. Recognize text tracks after an ad break (html5 provider) [JW8-10815](https://jwplayer.atlassian.net/browse/JW8-10815) 
2. Recognize text tracks after reloading (pause/unpause) a live stream (hls.js in Safari) [JW8-11006](https://jwplayer.atlassian.net/browse/JW8-11006)

This also resets metadata tracks so that we properly reuse them as well.

#### Addresses Issue(s):
JW8-10815 JW8-11006

### Checklist
- [ ] Jenkins builds and unit tests are passing
- [ ] I have reviewed the automated results
",18307175
19,2020-03-14T16:45:48Z,2020-03-23T15:36:55Z,,,"### This PR will...
Add types to the default provider

### Why is this Pull Request needed?
TS

### Are there any points in the code the reviewer needs to double check?
Comments mark

### Are there any Pull Requests open in other repos which need to be merged with this?
Nah

#### Addresses Issue(s):

JW8-11027

### Checklist
- [ ] Jenkins builds and unit tests are passing
- [ ] I have reviewed the automated results
",18307175
20,2020-03-06T19:16:38Z,2020-03-24T13:12:28Z,,,"### This PR will...
Typescript the following files

- src/js/view/error-container.js
- src/js/view/controls/next-display-icon.js
- src/js/view/controls/templates/display-container.js
- src/js/view/controls/templates/display-icon.js
- src/js/view/controls/templates/info-overlay.js
- src/js/view/controls/templates/nextup.js
- src/js/api/errors.js

### Why is this Pull Request needed?

### Are there any points in the code the reviewer needs to double check?

### Are there any Pull Requests open in other repos which need to be merged with this?

#### Addresses Issue(s):

JW8-10993

### Checklist
- [ ] Jenkins builds and unit tests are passing
- [ ] I have reviewed the automated results
",18307175
21,2020-03-02T20:30:46Z,2020-03-17T22:16:22Z,,,"### This PR will...
Add simple styling and the following for a Demo Tizen App:
- Removing the Right-Click menu
- Removing the Double-Tap to fullscreen
- Removing the ability to click anywhere in the view to play/pause
- Removing the fullscreen and volume icons in control bar
- Adding a 'back' button to the player
- Add controls for navigating a Tizen App with a remote
- Add support for autostarting videos on tizen

Github Repo for Tizen App: https://github.com/jwplayer/jwplayer-tizen-app

Not addressed:

### Why is this Pull Request needed?

### Are there any points in the code the reviewer needs to double check?

### Are there any Pull Requests open in other repos which need to be merged with this?
https://github.com/jwplayer/jwplayer-commercial/pull/7461
#### Addresses Issue(s):

[JW8-10887](https://jwplayer.atlassian.net/browse/JW8-10887)

### Checklist
- [ ] Jenkins builds and unit tests are passing
- [ ] I have reviewed the automated results
",18307175
22,2019-06-12T20:33:21Z,2019-12-09T16:18:30Z,,,"### This PR will...
Reduce the total size of bin-debug/bin-release by 100kb each by removing redundant imports/duplicated polyfills.

### Why is this Pull Request needed?
Removes redundant imports. On commercial, will allow use of spread operators without breaking karma tests.

### Are there any points in the code the reviewer needs to double check?

### Are there any Pull Requests open in other repos which need to be merged with this?

#### Addresses Issue(s):

JW8-###

",18307175
23,2019-05-07T22:32:28Z,2019-12-09T16:17:05Z,,,"### This PR will...
add a listener for `buffer` on the ad program controller and trigger a 'adBuffer' event when the player state changes to `buffering ` when instream is active.
### Why is this Pull Request needed?
Currently when a preRoll is loaded, the player state goes from `idle` to `buffering` but a buffer event is never triggered. I think a buffer event should fire because a developer should be able to rely on our events to detect state changes.

This bug was noticed while working on performance improvements for the iOS SDK. In the past, we would use the `getState` API to determine the state. This resulted in a large amount of javascript injections which are costly. To reduce the amount of javascript injections, and since WKWebView handles javascript asynchronously, we have decided to rely on the player's events to track the state. Given that a buffer event doesn't fire on ads, our state tracking gets out of sync. 

If firing buffer events during ad playback damages our event orders, we could look into changing the state in the SDK to buffer on other events such as playAttempt or adStart. Our preference though would be to rely on the player's buffer event. 
### Are there any points in the code the reviewer needs to double check?

### Are there any Pull Requests open in other repos which need to be merged with this?
Commercial https://github.com/jwplayer/jwplayer-commercial/pull/6682
#### Addresses Issue(s):
SDK-4152

",18307175
24,2020-03-26T09:15:12Z,2020-03-26T09:41:24Z,,,Signed-off-by: Christopher Meis <christopher.meis@9elements.com>,46462030
25,2020-03-25T15:09:37Z,2020-03-26T04:18:23Z,,,@pmazzini @dhendrix @jonzhang-fb @morganjangwiwynn @JingleHsuWiwynn  ,46462030
26,2020-03-23T21:26:56Z,2020-03-25T20:51:38Z,,,"The existing strace screws up pretty much all multi-process traces by tracking stuff like last syscall time and the previous output string on a global basis rather than per-task basis.

The existing strace only supports one of clone/fork/vfork right now, and it doesn't work that well. Luckily, getting it correct is unnecessary - you can have the kernel do the work for you: we switch to the ptrace opt that automatically traces children.

Also, errno handling is fixed on amd64.

ppc, arm, and arm64 are removed *for now*. They were non-functional (syscall args and rets were not filled in at all.)

Newly supported: signal-stop events, new child events, signal-exit events, exit events in addition to syscall-stop events.

TODO: use little C programs for testing. Or perhaps use GOMAXPROCS to control Go programs' determinism, to have a predictable (= testable) order of syscalls ",46462030
27,2020-03-18T07:25:04Z,2020-03-26T07:15:10Z,,,"Implement OEM ipmi command ""Send the information of processors and DIMMs to BMC""

Signed-off-by: Morgan Jang <Morgan_Jang@wiwynn.com>",46462030
28,2020-03-11T00:57:10Z,2020-03-11T07:39:59Z,,,,46462030
29,2020-03-04T07:06:43Z,2020-03-17T23:37:12Z,,,"Send IPMI SEL with OEM format to record fbnetboot failure.

Add reviewer: @pmazzini @johnnylinwiwynn @morganjangwiwynn ",46462030
30,2020-02-27T22:35:54Z,2020-03-11T07:32:11Z,,,"This prepends a timestamp in front of each line of stdin. Useful for
measuring performance from logs.

Signed-off-by: Ryan O'Leary <ryanoleary@google.com>",46462030
31,2020-02-17T19:04:42Z,2020-03-15T10:57:42Z,,,"This Pull Request brings in a few enhancements, sluinit optimizations and also addresses few bugs.

Enhancements:
1. Send measurement events to kernel via sysfs.
2. Add a reference policy file and documentation(as a .md file) on how to create a policy file for a platform.

Bugs:
1. securelaunch pkg was using disboot package to ""Find Devices""(and mount them). This diskboot
package declares a partition as bootable/mountable if that partition has one of the hard coded config files present on it. see here (https://github.com/srcUp/u-root/blob/upstream-PR/pkg/boot/diskboot/config.go#L114). This restriction is not good for securelaunch use case. Hence securelaunch will be migrating from diskboot to storage package for mounting devices..

2. We were measuring kernel/initrd AFTER dumping event logs to disk. This meant that these measurements were not showing up in the evtlog disk file that is used for attestation. This change set moves these measurements to a step BEFORE dumping event logs to disk..

3. securelaunch was using a vendored smbios package (digitalocean) that uses /dev/mem for memory reads. This wont work with secureboot enabled. So securelaunch will now use in house smbios package. The changes have tried to replicate code in cmds/exp/dmidecode/

Optimizations:
1. Currently sluinit is performing a lot of mount/unmount operations that hog up a lot of time during boot. To reduce these mount/unmount operations, a mount cache is introduced that will track a mounted device until we need to remount it/unmount it...Just before the final step of sluinit, we clear this cache and unmount everything...

2. It would be more efficient if the number of remount operations performed in sluinit are reduced.
That means all read mounts are done first followed by all write mounts....To achieve this a persistData slice is used to store all ""write"" mount operations and we perform these writes just before kexecing to new kernel....To give an idea of scope of ""write"" mounts, currently we use write mounts to dump logs to disk for attestation, so eventlog sub package and cpuid collector are the only two users of ""write"" mounts...",46462030
32,2020-02-14T09:20:39Z,2020-02-14T09:22:37Z,,,"#1370
wip: check point what I have now",46462030
33,2020-01-03T19:02:25Z,2020-03-25T21:00:40Z,,,"Adding library for parsing Boot Loader Specification entries

Based on the spec at https://systemd.io/BOOT_LOADER_SPECIFICATION/

This builds on the work in https://github.com/u-root/u-root/pull/1283 but makes a few modifications, namely using boot.LinuxImage instead of BootConfig, and making this a separate package

Signed-off-by: pallaud <plaud@google.com>",46462030
34,2019-12-29T15:36:40Z,2020-01-22T22:44:27Z,,,"This allows showing a splash screen image from a file, currently tailored for PNG on 640x480 / 24bpp. Work in progress. :)",46462030
35,2019-12-03T09:57:25Z,2020-03-26T13:56:10Z,,,"This is a work in progress parsers replacement.
I started in boot as it doesn't use packages. Basically the functions added at the end of boot.go should go to a new ""diskboot"" or ""localboot"" or whatever package.
Opening the PR now to show the work.",46462030
36,2019-11-18T20:51:19Z,2019-12-29T07:14:20Z,,,"Codecov.io is a service that provides code coverage information.

Signed-off-by: Andrea Barberio <insomniac@slackware.it>",46462030
37,2019-09-10T20:54:51Z,2019-11-12T23:22:59Z,,,"This adds Go module support for busybox, while preserving support for GOPATH and vendoring.

I will split this into its own repository soon, so we can also have the bazel/blaze scripts there, without having to support them for all of u-root.",46462030
38,2019-12-27T13:45:52Z,2020-03-24T01:35:29Z,,,"I've had a hard time getting nerves to build under WSL 2 as it kept showing the following error message when running `mix firmware`:
```
** (Mix) fwup.exe is required by the Nerves tooling.
Please see https://hexdocs.pm/nerves/installation.html for installation
instructions.
```

This PR adds a short section to the installation instructions that should help people with more recent WSL releases to figure out the right setup right away :)",50259821
39,2020-03-26T06:09:50Z,2020-03-26T06:17:23Z,,,"Will crash on calling while no indev returned conditions, such as delayed for an deletion of objects automatically when idle(no interactive inputs).
Perhaps we will think of that it is ""your"" responsibility to check before calling. well, I think it may not be easy for the one who does not familar with the library(they usually trust it I think), and I stucked here and debug for hours.",60667730
40,2020-03-25T15:18:56Z,2020-03-25T19:50:23Z,,,"The rollover functionality allows the spinbox to turn around the range of values. 

- Increasing over maximum values restarts from minimum value.
- Decreasing below minimum value restarts from maximum value.

Added a function to enable/disable the rollover, and one to get the rollover status. Added an extended attribute.",60667730
41,2020-03-14T18:34:50Z,2020-03-25T16:52:53Z,,,"Hi,
I added the support of the Arabic and Persian texts. Also, I created a simple new font for Arabic and Persian texts.

Sample code:

```
static void label_create(lv_obj_t * parent)
{
	LV_FONT_DECLARE(lv_font_ap_18);
	static lv_style_t style;
	char * text_persian_raw = ""Persian:\nبنی‌آدم اعضای یکدیگرند\n که در آفرینش ز یک گوهرند"";
	char * text_arabic_raw = ""Arabic:\nيا حبيبي لا تظن كاس الخمر سكرني\n القوافي نار طاحت عل وزن سكرني"";

	char * text_persian;
	char * text_arabic;

	uint32_t text_persian_length = lv_txt_ap_calc_bytes_cnt(text_persian_raw);
	uint32_t text_arabics_length = lv_txt_ap_calc_bytes_cnt(text_arabic_raw);

	text_persian = (char *)lv_mem_alloc(text_persian_length);
	text_arabic = (char *)lv_mem_alloc(text_arabics_length);

	lv_page_set_style(parent, LV_PAGE_STYLE_BG, &lv_style_transp_fit);
	lv_page_set_style(parent, LV_PAGE_STYLE_SCRL, &lv_style_transp_fit);
	


	lv_page_set_sb_mode(parent, LV_SB_MODE_OFF);


	lv_style_copy(&style, &lv_style_plain);
	style.text.font = &lv_font_ap_18;
	style.text.color = lv_color_make(200,255,10);
	lv_obj_t * label_persian = lv_label_create(parent, NULL);
	lv_obj_t * label_arabic = lv_label_create(parent, NULL);

	lv_label_set_style(label_persian, LV_LABEL_STYLE_MAIN, &style);
	lv_label_set_style(label_arabic, LV_LABEL_STYLE_MAIN, &style);

	lv_txt_ap_proc(text_persian_raw, text_persian);
	lv_obj_set_x(label_persian, 5);
	lv_obj_set_y(label_persian, 10);

	lv_txt_ap_proc(text_arabic_raw, text_arabic);
	lv_obj_set_x(label_arabic, 5);
	lv_obj_set_y(label_arabic, 100);

	lv_label_set_text(label_persian, text_persian);
	lv_label_set_text(label_arabic, text_arabic);

	lv_mem_free(text_persian);
	lv_mem_free(text_arabic);

}
```
Hamid Reza Mehrabian/

![](https://i.ibb.co/5LXLNgL/stm32f4-disc.jpg)

![](https://i.ibb.co/yn8Hgwf/simulation.png)
",60667730
42,2020-03-24T14:10:11Z,2020-03-25T00:26:49Z,,,,83160811
43,2020-03-24T13:23:25Z,2020-03-26T12:56:56Z,,,(bugfix) adding line function to clear out all the global 'free' info…rmation so that we can reset it after a failed traversal,83160811
44,2020-03-15T11:45:56Z,2020-03-26T16:22:23Z,,,reduced my binary size by ~13k,83160811
45,2020-03-13T07:39:08Z,2020-03-26T05:59:22Z,,,"It's very slowly to compare one byte at one time. Here are the
performance I get from 128M spinand with NFTL by sequential writing.

| file size | buffer size  | write speed  |
| 10 MB     | 0   B        | 3206.01 KB/s |
| 10 MB     | 1   B        | 2434.04 KB/s |
| 10 MB     | 2   B        | 2685.78 KB/s |
| 10 MB     | 4   B        | 2857.94 KB/s |
| 10 MB     | 8   B        | 3060.68 KB/s |
| 10 MB     | 16  B        | 3155.30 KB/s |
| 10 MB     | 64  B        | 3193.68 KB/s |
| 10 MB     | 128 B        | 3230.62 KB/s |
| 10 MB     | 256 B        | 3153.03 KB/s |

| 70 MB     | 0   B        | 2258.87 KB/s |
| 70 MB     | 1   B        | 1827.83 KB/s |
| 70 MB     | 2   B        | 1962.29 KB/s |
| 70 MB     | 4   B        | 2074.01 KB/s |
| 70 MB     | 8   B        | 2147.03 KB/s |
| 70 MB     | 64  B        | 2179.92 KB/s |
| 70 MB     | 256 B        | 2179.96 KB/s |

The 0 Byte size means no validation and the 1 Byte size is how
littlefs do before. Based on the above table and to save memory,
comparing 8 bytes at one time is more wonderful.

Signed-off-by: WeiXiong Liao <liaoweixiong@allwinnertech.com>",83160811
46,2020-02-26T10:20:26Z,2020-02-26T15:55:15Z,,,fixes emubd compilation with pure MSVC compiler.,83160811
47,2020-01-28T05:51:37Z,2020-01-28T10:18:32Z,,,Resolve #358,83160811
48,2020-01-27T20:02:30Z,2020-03-20T14:26:38Z,,,"This took a bit longer than I thought it would, some because of the number of bugs that fell out, some because I underestimated how much time it would take to edit all of the tests.

EDIT: I did not realize how long the description of this PR would be, sorry for the wall of text. Also sorry about being out-of-touch for a while.

### Test framework rework

This PR reworks the testing framework to better isolate and fix filesystem bugs. This mainly involves generalizing the tests to let them run under different contexts (power-loss, wear, valgrind), while also adding extra scripts to make test results easier to reproduce and visualize.

- Reworked how test.py works. Now instead of just dispatching `tests/test_*.sh` scripts, it loads tests stored in `tests/test_*.toml` files. This lets us store extra attributes describing tests, such as ""leaky"" or ""reentrant"", which we can use to decide how to run tests later.

  - `./scripts/test.py` - Runs tests normally. Each test case is a single function that should terminate without asserting.
  - `./scripts/test.py --reentrant` - Run tests with a simulated power-loss occuring every _n_ cycles where _n_ = _n_+1 every power-loss. Only test cases marked with `reentrant = true` are ran, since the test itself also needs to be able to handle power-loss.
  - `./scripts/test.py --valgrind` - Run tests under valgrind, checking for memory constraint errors. Tests marked with `leaky = true` are skipped here.

  There are also the addition of ""internal"" tests, where test cases can specify `in = ""lfs.c""` or some other file to be compiled as though it was appended to the file ""lfs.c"". This gives the test access to static functions and other internals. I'm planning to use these for more unit-style tests in the future.

  It's worth noting that tests can no longer span multiple sequential processes, but this feature wasn't that helpful and created problems for reproducibility and porting to devices.

  The real kicker is how test.py integrates with gdb. By adding --gdb, test.py will drop you you into gdb at the exact assert where a test fails. This includes reproducing any power-cycles necessary to get the test into the failing state. This is very helpful for reproducing complex test failures.

  ``` bash
  $ ./scripts/test.py --gdb
  ====== building ======
  built 15 test suites, 116 test cases, 740 permutations
  ====== testing ======
  test_alloc ✓✓✓✓✓✓✓✓✓✓✓✓✓
  test_attrs ✓✓✓✓
  test_badblocks ✓✓✓✓✓✓✓✓✓✓✓✓
  test_dirs ✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓
  ✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓
  test_entries ✓✓✓✓✓✓✓✓
  test_exhaustion ✓✓✓✓✓✓✓✓✓✓✓✓
  test_format ✓✓✓✓✗
  ====== results ======
  tests/test_format.toml:29:failure: test_format#5#1 (BLOCK_CYCLES=32, N=10) failed with -6
  tests/test_format.toml:39:assert: assert failed with 2, expected eq 1
          assert(info.type == LFS_TYPE_REG);

  ======= gdb ======
  GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1
  Copyright (C) 2016 Free Software Foundation, Inc.
  License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
  This is free software: you are free to change and redistribute it.
  There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
  and ""show warranty"" for details.
  This GDB was configured as ""x86_64-linux-gnu"".
  Type ""show configuration"" for configuration details.
  For bug reporting instructions, please see:
  <http://www.gnu.org/software/gdb/bugs/>.
  Find the GDB manual and other documentation resources online at:
  <http://www.gnu.org/software/gdb/documentation/>.
  For help, type ""help"".
  Type ""apropos word"" to search for commands related to ""word""...
  Reading symbols from ./tests/test_format.toml.test...done.
  Starting program: /home/geky/littlefs3/tests/test_format.toml.test 5 1
  tests/test_format.toml:39:assert: assert failed with 2, expected eq 1

  Program received signal SIGABRT, Aborted.
  0x00007ffff7a42428 in __GI_raise (sig=6) at ../sysdeps/unix/sysv/linux/raise.c:54
  54      ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.
  #2  0x0000000000401f17 in test_case5 (BLOCK_CYCLES=32, N=10) at tests/test_format.toml:39
  39              assert(info.type == LFS_TYPE_REG);
  (gdb)
  ```

- Restructured the test block devices. Now there is testbd, filebd, and rambd.

  The way that emubd created a separate file for each block wasn't that useful. It was marginally easier? But didn't match the single-file-block-device that was easy to create when dumping flash from an actual device.

  I've replaced emubd with simpler, and hopefully more useful, block devices:
  - filebd - Simulate a block device on a single file.

    As an added plus this block device can be used to mount disk images extracted from a device's flash. You can even use it to mount /dev/sdb devices into a C program.

  - rambd - Simulate a block device in RAM.

    The main reason for adding this is performance. Now that we don't allow separate-process tests, we can test using a block device stored in RAM. This speeds up the tests by ~7x.

    - test_dirs w/ filebd - 0m7.170s
    - test_dirs w/ rambd  - 0m0.966s

  On top of these is testbd, a wrapper for filebd/rambd with extra hooks for testing. This is where a lot of the test magic happens.

  - Simulated block wear - testbd can be configured to keep track of block wear, and force blocks to start reporting LFS_ERR_CORRUPT when exhausted. The current wear modified during a test to tightly control how the block device will behave under littlefs.

    Block wear can also be used to explicitly force geometry of the underlying block device, and lets us change the size of the block device on the fly while testing.

    We can also read the state of wear on the block device after a test, which may be useful for future benchmarks.

  - Simulated power loss - testbd can be give a number of ""write cycles"" to run for. This creates a counter that is decremented every prog/erase cycle. When the counter hits zero the program is forcefully terminated.

    Note this is much faster that using gdb to kill the program externally.

- Added a handful of debugging scripts for visualizing the state of littlefs.

  - `./scripts/readblock.py disk block_size block` - Prints a hex dump of a given block on disk. It's basically just `dd if=disk bs=block_size count=1 skip=block | xxd -g1 -` but with less typing.

    ``` bash
    $ ./scripts/readblock.py disk 512 0xa
    off       data
    00000000: 71 01 00 00 f0 0f ff f7 6c 69 74 74 6c 65 66 73  q.......littlefs
    00000010: 2f e0 00 10 00 00 02 00 00 02 00 00 00 04 00 00  /...............
    00000020: ff 00 00 00 ff ff ff 7f fe 03 00 00 20 00 04 19  ...............
    00000030: 61 00 00 0c 00 62 20 30 0c 09 a0 01 00 00 64 00  a....b 0......d.
    ...
    ```

  - `./scripts/readmdir.py disk block_size block1 block2` - Prints info about the tags in a metadata pair on disk. It can print the currently active tags as well as the raw log of the metadata pair.

    ``` bash
	$ ./scripts/readmdir.py disk 512 0xa 0xb
    off       tag       type            id  len  data (truncated)
    0000003b: 0020000a  dir              0   10  63 6f 6c 64 63 6f 66 66 coldcoff
    00000049: 20000008  dirstruct        0    8  02 02 00 00 03 02 00 00 ........
    00000008: 00200409  dir              1    9  68 6f 74 63 6f 66 66 65 hotcoffe
    00000015: 20000408  dirstruct        1    8  fe 01 00 00 ff 01 00 00 ........
	```

  - `./scripts/readtree.py disk block_size` - Parses the littlefs tree and prints info about the semantics of what's on disk. This includes the superblock, global-state, and directories/metadata-pairs.

    ``` bash
	$ ./scripts/readtree.py disk 512
    superblock ""littlefs""
      version v2.0
      block_size 512
      block_count 1024
      name_max 255
      file_max 2147483647
      attr_max 1022
    gstate 0x000000000000000000000000
    dir ""/""
    mdir {0x0, 0x1} rev 3
    v id 0 superblock ""littlefs"" inline size 24
    mdir {0x77, 0x78} rev 1
      id 0 dir ""coffee"" dir {0x1fc, 0x1fd}
    dir ""/coffee""
    mdir {0x1fd, 0x1fc} rev 2
      id 0 dir ""coldcoffee"" dir {0x202, 0x203}
      id 1 dir ""hotcoffee"" dir {0x1fe, 0x1ff}
    dir ""/coffee/coldcoffee""
    mdir {0x202, 0x203} rev 1
    dir ""/coffee/warmcoffee""
    mdir {0x200, 0x201} rev 1
	```

- Added explode_asserts.py.

  What is explode_asserts.py? It is an extra C preprocessing-step that makes asserts aggressively readable.

  explode_asserts.py takes in a C file and parses any asserts it finds, transforming them into an equivalent statement that can also report the original arguments to the logic operation in the assert. This is very useful for debugging and removes the need for assert_int_eq, assert_str_lt, etc that are a common sight in C testing frameworks.

  And because explode_asserts.py works with traditional asserts, it can be applied to any existing project to get nicer assert results.

  Here's a test failure showing how explode_asserts.py can extract assert arguments:

  ``` bash
  geky@s:littlefs3$ ./scripts/test.py
  ====== building ======
  built 15 test suites, 116 test cases, 740 permutations
  ====== testing ======
  test_alloc ✓✓✓✓✓✓✓✓✓✓✓✓✓
  test_attrs ✓✓✓✓
  test_badblocks ✓✓✓✓✓✓✓✓✓✓✓✓
  test_dirs ✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✗
  ====== results ======
  tests/test_dirs.toml:48:failure: test_dirs#3#1 (N=3) failed with -6
  tests/test_dirs.toml:72:assert: assert failed with ""removeme000"", expected eq ""removeme0""
          assert(strcmp(info.name, path) == 0);

  tests passed: 64
  tests failed: 1
  ```

### Bug fixes!

What was the point of all these test changes? ~It was to make my life easier~ Finding and fixing bugs! of which there were quite a few:

- Fixed bug in dir splitting when there's a large number of open files 9453ebd15d590778a5207920b2671a4fff91a9e0

  Updates open files were depending on the mutable dir rather than the immutable copy intended to avoid sync issues.

- Fixed issues with neighbor updates during moves f4b6a6b3284d8b721ba3db0bba93ee45fde7ead9

  This was found by @eastmoutain and initial fix proposed in https://github.com/ARMmbed/littlefs/issues/343 though there were a couple lingering issues that needed to fixed.

  This lingering issues turned out to be quite involved. There's a better writeup in f4b6a6b3284d8b721ba3db0bba93ee45fde7ead9's commit message.

  Basically the order and number of create/delete tags was assumed to behave a certain way when passed to lfs_dir_commit and this was wrong.

  The fix was to restructure how lfs_dir_commit tracks create/delete tags and how implicit moves in global state are handled (by making them no-longer implicit).

  I believe this was the source of most of the ""LFS_ASSERT(block != LFS_BLOCK_NULL)"" issues. Will be working through open issues to make sure.

- Fixed parent going out of sync when relocated in lfs_mkdir a5d614fbfbf19b8605e08c28a53bc69ea3179a3e

  This can happen if we're creating a new directory in a multi-pair directory, our predecessor has to be relocated as we thread ourselves into the linked-list.

  Fortunately this can be fixed by adding our temporary mdir to the list of open files/dirs, which are automatically updated on metadata-pair changes. Note we need to take care to unhook our temporary before lfs_mkdir returns.

- Fixed to-be-removed child going out of sync when relocated in lfs_remove and lfs_rename a5d614fbfbf19b8605e08c28a53bc69ea3179a3e

  Surprisingly this can happen if a nested directory is removed and it is its own parent's predecessor (which can happen after moving the directory around, since this does not change the threaded linked-list). If this happens, and our parent is relocated, we could go out of sync, causing us to update are predecessor with the incorrect tail pointer.

- Fixed lfs_rename with same source and destination a5d614fbfbf19b8605e08c28a53bc69ea3179a3e

  An uncommon operation, lfs_rename(""deja/vu"", ""deja/vu""). This was broken and would result in two deletes to the same directory entry. Fixed and added test case specifically for this situation.

- Fixed how we manage gstate deltas when we lose power during nested relocations a5d614fbfbf19b8605e08c28a53bc69ea3179a3e

  Managing gstate deltas when we lose power during relocations was broken. And unfortunately complicated.

  The issue happens when we remove a directory, have to relocate its parent, and lose power.

  When we remove a directory, we need to move the contents of its gstate delta to another directory or we'll corrupt littlefs gstate. (gstate is an xor of all deltas on the filesystem). This used to go to the parent, but this actually isn't correct since the threaded linked-list is used to read the gstate, not the directory tree.

  The fix here is to take special care about where we put the gstate delta. Delta depending on removes needs to go to the predecessor, while orphan-related delta describing the remove itself needs to go to the parent.

- Fixed lfs_deorphan so it can handle more than one orphan/half-orphan during a power-loss a5d614fbfbf19b8605e08c28a53bc69ea3179a3e

  Two bugs here:
  1. lfs_deorphan couldn't handle handle multiple orphans in a single power-loss. We can't have multiple _orphans_, but we can have multiple _half-orphans_ (where only one block address is out-of-date in the metadata pair). This happens when we have nested relocations.

  2. lfs_deorphan needs to relocate the current pair if it is a half-orphan. This is because if both a directory and its immediate successor is relocated, the tail pointer we fetch isn't valid until after we fix the half-orphan.

  Fortunately the fix here is simpler than the bug and we just need to carefully handle how lfs_deorphan scans the threaded linked-list of metadata-pairs.

- Fixed reproducability issue when we can't read a directory revision 517d3414c5e04eedb07be2e58107c1f96b8b8684

  An interesting subtlety of the block-device layer is that the block-device is allowed to return LFS_ERR_CORRUPT on reads to untouched blocks. This can easily happen if a user is using ECC or some sort of CMAC on their blocks. Normally we never run into this, except for the optimization around directory revisions where we use uninitialized data to start our revision count.

  We correctly handle this case by ignoring whats on disk if the read fails, but end up using unitialized RAM instead. This is not an issue for normal use, though it can lead to a small information leak. However it creates a big problem for reproducability, which is very helpful for debugging.

  I ended up running into a case where the RAM values for the revision count was different, causing two identical runs to wear-level at different times, leading to one version running out of space before a bug occured because it expanded the superblock early.

- Fixed incorrect erase assumption if lfs_dir_fetch exceeds block size 517d3414c5e04eedb07be2e58107c1f96b8b8684

  This could be caused if the previous tag was a valid commit and we lost power causing a partially written tag as the start of a new commit.

  Fortunately we already have a separate condition for exceeding the block size, so we can force that case to always treat the mdir as unerased.

- Fixed cleanup issue caused by lfs_fs_relocate failing when trying to outline a file in lfs_file_sync 517d3414c5e04eedb07be2e58107c1f96b8b8684

  Most operations involving metadata-pairs treat the mdir struct as entirely temporary and throw it out if any error occurs. Except for lfs_file_sync since the mdir is also a part of the file struct.

  This is relevant because of a cleanup issue in lfs_dir_compact that usually doesn't have side-effects. The issue is that lfs_fs_relocate can fail. It needs to allocate new blocks to relocate to, and as the disk reaches its end of life, it can fail with ENOSPC quite often.

  If lfs_fs_relocate fails, the containing lfs_dir_compact would return immediately without restoring the previous state of the mdir. If a new commit comes in on the same mdir, the old state left there could corrupt the filesystem.

  It's interesting to note this is forced to happen in lfs_file_sync, since it always tries to outline the file if it gets ENOSPC (ENOSPC can mean both no blocks to allocate and that the mdir is full). I'm not actually sure this bit of code is necessary anymore, we may be able to remove it.

- Fixed missing half-orphans when allocating blocks during lfs_fs_deorphan 517d3414c5e04eedb07be2e58107c1f96b8b8684

  This was a really interesting bug. Normally, we don't have to worry about allocations, since we force consistency before we are allowed to allocate blocks. But what about the deorphan operation itself? Don't we need to allocate blocks if we relocate while deorphaning?

  It turns out the deorphan operation can lead to allocating blocks while there's still orphans and half-orphans on the threaded linked-list. Orphans aren't an issue, but half-orphans may contain references to blocks in the outdated half, which doesn't get scanned during the normal allocation pass.

  Fortunately we already fetch directory entries to check CTZ lists, so we can also check half-orphans here. However this causes lfs_fs_traverse to duplicate all metadata-pairs, not sure what to do about this yet.

- Fixed commit issue if block cannot be written to and contains valid commits  77e3078b9f28ff689e5a623250eae5c85ae8b3aa

  We can miss bad writes if the underlying block device contains a valid commit with the exact same size as in the exact same offset.

  The fix here is to check the CRC on disk with the CRC we have in RAM. This avoids the issue without needed to save our entire commit in RAM.

  It could be an issue if the disk contains a valid commit with exact same size at the exact same offset _and_ the exact same CRC. But this is unlikely enough to never happen.

- Fixed broken wear-leveling when block_cycles = 2n-1 fe957de892edbefd7af54acbe19e9a4e0f0fb1d0

  See https://github.com/ARMmbed/littlefs/issues/369

  Blocks in the metadata-pair are relocated every ""block_cycles"", or, more mathy, when rev % block_cycles == 0 as long as rev += 1 every block write.

  But there's a problem, rev isn't += 1 every block write. There are two blocks in a metadata-pair, so looking at it from each blocks perspective, rev += 2 every block write.

  This leads to a sort of aliasing issue, where, if block_cycles is divisible by 2, one block in the metadata-pair is always relocated, and the other block is _never_ relocated. Causing a complete failure of block-level wear-leveling.

  Fortunately, because of a previous workaround to avoid block_cycles = 1 (since this will cause the relocation algorithm to never terminate), the actual math is rev % (block_cycles+1) == 0. This means the bug only shows its head in the much less likely case where block_cycles is a multiple of 2 plus 1, or, in more mathy terms, block_cycles = 2n+1 for some n.

  To workaround this we can bitwise or our block_cycles with 1 to force it to never be a multiple of 2n.

- Fixed lfs_fs_size doubling metadata-pairs 6530cb3a6129f28dda117fdcb0231291b0eff680

  This was caused by the previous fix for allocations during lfs_fs_deorphan in this branch. To catch half-orphans during block allocations we needed to duplicate all metadata-pairs reported to lfs_fs_traverse. Unfortunately this causes lfs_fs_size to report 2x the number of metadata-pairs, which would undoubtably confuse users.

  The fix here is inelegantly simple, just do a different traversale for allocations and size measurements. It reuses the same code but touches slightly different sets of blocks.

  Unfortunately, this causes the public lfs_fs_traverse and lfs_fs_size functions to split in how they report blocks. This is technically allowed, since lfs_fs_traverse may report blocks multiple times due to CoW behavior, however it's undesirable and I'm sure there will be some confusion.

  But I don't have a better solution, so from this point lfs_fs_traverse will be reporting 2x metadata-blocks and shouldn't be used for finding the number of available blocks on the filesystem.

### Related issues

WIP: I'm currently going through open issues to figure out what is impacted. I'm currently behind on this.

- https://github.com/ARMmbed/littlefs/issues/343
- https://github.com/ARMmbed/mbed-os/issues/11704
- https://github.com/ARMmbed/littlefs/issues/295

### TODO

- [x] Add power-cycling tests
- [x] Add better support for debugging single-file block devices
- [x] RAM block device?
- [x] Add more tests around relocations under power-loss
- [ ] Fix non-DAG wear-leveling
- [x] Investigate https://github.com/ARMmbed/littlefs/issues/369
- [ ] Investigate https://github.com/ARMmbed/littlefs/issues/379
- [x] Fix CI to use new framework
- [x] Add tests for recovering from extra bad states
  - Recover from finding bad block addresses on disk
  - Loop detection?
- [ ] Code coverage? (optional)
- [ ] Add minor bump to this",83160811
49,2020-01-02T21:51:24Z,2020-01-28T10:19:02Z,,,"`lfs_npw2` returns a value v such that `2^v >= a` and `2^(v-1) < a`, but
the previous comment incorrectly describes it as ""less than or equal to
a"".",83160811
50,2019-12-30T11:58:43Z,2020-02-24T05:16:39Z,,,"I had a system that was constantly hitting this assert, after making
this change it recovered immediately.",83160811
51,2019-12-19T12:59:38Z,2020-02-02T10:01:42Z,,,fix size in Layout of the CRC tag,83160811
52,2019-11-30T17:56:05Z,2020-03-25T13:32:44Z,,,"Make littlefs superblock magic configurable.

Can be useful, for example, when:
1. You want to distinguish between 2 or more ""visible"" storage (For example, when using [littlefs-fuse](https://github.com/ARMmbed/littlefs-fuse) multiple times, and you want to distinguish between the multiple files that are created).

2. You want to make your storage completely unreadable (For example, in case of using the littlefs-fuse, encrypting the file that is used to manage your storage is not enough to make the file completely unreadable, as simple `hd` on the file will reveal the ""littlefs"" string..)",83160811
53,2019-11-05T20:43:39Z,2020-01-28T10:19:31Z,,,"The terminating comma does not get removed in non-MSVC compilers.  Use ## to consume the comma in this case, allowing zero-arg prints",83160811
54,2019-11-02T20:41:39Z,2019-12-31T00:07:43Z,,,"Configurable thread-safe littlefs.
Closes https://github.com/ARMmbed/littlefs/issues/156

Not sure if that's the best approach. Other options that I thought of raised some problems, for example:
1. Queuing littlefs callbacks and invoke them one by one from a different thread, but:
a. I don't want to make the user create a thread for littlefs due to a possible limitations in embedded devices.
b.  In order to queue a callback and invoke it later, I need to save the buffers (of `lfs_file_write`, `lfs_setattr` etc), which may be a problem.

2. use rwlock on `lfs`, but that won't really solve the problem.

So eventually I just decided to lock an entire littlefs function execution using a spinlock. To do so, I make sure that `lfs_malloc` and `lfs_free` won't be executed inside littlefs function (except `lfs_format` and `lfs_mount`). Also I assume that the read,prog,sync and erase callbacks that are given to `lfs` struct can be called inside a spinlock context.

This ""feature"" requires pointers to spinlock_lock and spinlock_unlock functions (As we don't want + can't add a ""generic"" spinlock implementation to the project), and exposes a nice `lfs_acquire_lock` and `lfs_release_lock` to wrap littlefs functions.

I test it locally simply by creating two threads, each one reads and writes to the same file thousands of times. By disabling this feature, the program aborted in one of the `lfs_file_opencfg` call from one of the threads (it happens everytime, not just once or twice). Enabling this feature and wrap the open, read write and close calls with the `lfs_acquire_lock` and `lfs_release_lock` solved the problem.
Do you have any suggestion how can I add a generic test for this project?

Btw, the diff between the sizes of my test binary with and without this feature is 152 bytes.

Anyway, If you have a better solution for a thread-safe littlefs I would be glad to hear.",83160811
55,2019-08-09T21:09:47Z,2020-01-28T10:19:28Z,,,"This reverts commit fdd239fe21a3721dc7fb55a9cf816544af7e9647.

Bypassing cache turned out to be a mistake which causes more problems
than it solves. Device driver should deal with alignment if this is
required - trying to do that in a file system is not a viable solution
anyway.

#160",83160811
56,2019-08-07T02:23:25Z,2020-01-27T21:46:35Z,,,"- Removed stdlib includes from lfs.h, these should all go through lfs_util.h to let users override these definitions if stdlib is unavailable on their system.

- Changed the name of the LFS_CONFIG macro to LFS_UTIL to avoid confusion with the lfs_config struct. This also hints that LFS_UTIL is related to lfs_util.h.

  LFS_UTIL allows the user to override lfs_util.h so they can provide their own system-level dependencies such as malloc, tracing, builtins, stdint definitions, string.h, and others.

- Moved error code definitions to lfs_util.h. This lets users override the error codes to replace them with their own error codes and avoid a translation layer in some situations. Note the error codes must still be in the range of a negative int.

Note that this is very likely to cause build issues for anyone currently using LFS_CONFIG.

To fix:
- Change LFS_CONFIG to LFS_UTIL
- Make sure you have a copy of the error code definitions in your customized lfs_util.h

Because of these changes this PR will need to wait for at least a minor release.",83160811
57,2019-05-17T11:55:52Z,2020-02-24T05:20:06Z,,,"-> introduce relocateCounter in dir_compact to catch infinite loop when
   lfs has no free space left anymore
-> call lfs_dir_fetchmatch with ftag=-1 in order to set the invalid bit
   and never let the function match a dir

Fixes:

https://github.com/ARMmbed/littlefs/issues/177
https://github.com/ARMmbed/littlefs/issues/184",83160811
58,2019-01-27T06:50:00Z,2020-02-24T05:22:15Z,,,"lfs_traverse has no protection against infinite loops. Consider what happens if a directory entry has dir.d.tail == cwd... you end up hanging forever. [Relevant section of code:](https://github.com/ARMmbed/littlefs/blob/195075819e05a9ce8568d3d98363f2a6f19ed436/lfs.c#L2294)

```
int lfs_traverse(lfs_t *lfs, int (*cb)(void*, lfs_block_t), void *data) {
    ...
    lfs_dir_t dir;
    lfs_block_t cwd[2]
    ...
    while (true) {
        ...
        lfs_dir_fetch(lfs, &dir, cwd);
        ...
        cwd[0] = dir.d.tail[0];
        cwd[1] = dir.d.tail[1];
        ...
    }
}
```

This is mostly a theoretical issue - this can only really happen if the on-flash data is already in an invalid state. However, as littlefs is supposed to be failsafe...

Two fixes come to mind:

1. Keep a counter. If you ever traverse >= the total number of blocks, you know that you've hit a loop. (This may take a while... but this isn't supposed to happen unless something has gone wrong _anyway_, and it's still better than just hanging forever.)
2. Use something like the tortose-and-hare algorithm. (Advance the hare, do the callback, exit if done, panic if hare == tortose, advance the hare, do the callback, exit if done, panic if hare == tortose, advance the tortose, panic if hare == tortose. Repeat.) Probably overkill.

This change implements #1.",83160811
59,2020-01-11T19:13:55Z,2020-03-10T07:19:52Z,,,Define MG_ENABLE_HTTP_IGNORE_INVALID_REQUESTS to ignore nonprintable responses for Apple HomeKit Accessory Protocol,5414488
60,2019-10-18T09:52:16Z,2019-12-24T04:39:17Z,,,Fix segmentation fault in mg_http_reverse_proxy() #1065,5414488
61,2019-10-08T06:28:47Z,2019-10-08T06:28:47Z,,,,5414488
62,2019-06-20T17:59:28Z,2019-06-20T17:59:28Z,,,[link](https://github.com/cesanta/mongoose/issues/1031),5414488
63,2019-03-23T07:34:10Z,2019-03-23T07:34:10Z,,,,5414488
64,2019-03-22T16:56:24Z,2019-11-09T08:17:39Z,,,IPv6 addresses in `mg_connect()` currently don't work (tested on unix / MacOS) as `mg_socket_if_connect_tcp()` uses the fixed family `AF_INET` in `socket()` and fixed `sin`-length in `connect()`. It should use `sa_family` from `socket_address` and the `sin6` length if applicable.,5414488
65,2019-03-20T06:00:02Z,2019-03-20T06:00:02Z,,,"MG uses fcntl(sock, F_SETFL, flags | O_NONBLOCK) to set nbio mode but fusion says: 
#define O_NONBLOCK      0x2000  /* Non-blocking (not supported in Fusion) */

Actually, #define MSG_NONBLOCKING 0x4000  /* override any blocking state */
is used for non-blocking mode.",5414488
66,2018-09-09T12:54:16Z,2019-01-12T11:03:00Z,,,"I have my [private pet-project]( https://bitbucket.org/tsieprawski/taskman) using Mongoose. I'm using [Meson](http://mesonbuild.com/) as build system and I've created a very basic Meson build file to include Mongoose, so it is [automatically downloaded and built alongside my code](https://mesonbuild.com/Wrap-dependency-system-manual.html). I think it would be cool to include it upstream. It's very basic, it just builds Mongoose as shared library.
",5414488
67,2018-08-29T14:17:44Z,2018-08-29T14:17:44Z,,,Add mg_file_upload_handler_string. Keeps uploaded file in memory in a char* string. Returns this string on MG_EV_HTTP_PART_END.,5414488
68,2018-08-17T04:50:18Z,2018-08-17T04:55:24Z,,,In a realtime game or application. Disable Nagle's algorithm is important.,5414488
69,2018-06-03T13:40:12Z,2018-06-03T13:40:12Z,,,I think add line number  for log will be help for debug.,5414488
70,2018-02-01T19:09:20Z,2020-02-13T10:23:53Z,,,"The LWIP commit checks for the LWIP SO_REUSE build option to decide wether to include the setsockop call. This solves the issue of lost connections blocking server ports due to sockets remaining in TIME_WAIT.

The ESP32 logging commits change the stderr logging channel to the ESP-IDF standard syslog channel on an ESP32 platform, so mongoose log output is consistent & cooperative with other log output and can be controlled by the ESP log level. File logging and the mongoose log control & filters can still be used, only the stderr channel is changed.

The debug log on mg_socket_if_destroy_conn() enables tracing socket close behaviour and timing.

These changes have been done for and tested within our ESP32 project (OVMS V3).

Tell me if you need separate pull requests.

Regards,
Michael",5414488
71,2018-01-30T03:33:04Z,2018-01-30T03:33:04Z,,,"bug: When using HTTP1.1 keep-alive, the response line and headers are still in nc->recv_mbuf after MG_EV_HTTP_REPLY.

fix: mongoose.c mg_http_handler mbuf_remove(io, hm->message.len) -> mbuf_remove(io, nc->recv_mbuf.len)",5414488
72,2018-01-29T19:10:56Z,2018-01-29T19:10:56Z,,,,5414488
73,2018-01-12T14:42:47Z,2018-01-12T14:42:47Z,,,"makes mqtt broker use `connection->priv_2` instead of `connection->user_data`, see #883 ",5414488
74,2017-11-23T16:55:37Z,2017-11-23T16:55:37Z,,,,5414488
75,2017-11-23T16:55:00Z,2017-11-23T16:55:00Z,,,,5414488
76,2017-11-22T16:17:50Z,2017-11-22T16:17:50Z,,,Fix bad comparison.,5414488
77,2017-11-21T10:51:43Z,2017-11-21T10:51:43Z,,,"Two way SSL currently can't reuse tls session when using openssl. This can be verified using s_client tool from openssl as follows:

`$> openssl s_client -connect localhost:8443 -CAfile ca-chain.cert.pem -cert bob@example.com.cert.pem -key bob@example.com.key.pem -reconnect`

given proper CA and client cert files we should see that session can't be reused (it works fine on one-way ssl).

Reference: https://wiki.openssl.org/index.php/Manual:SSL_CTX_set_session_id_context(3)
> If the session id context is not set on an SSL/TLS server and client certificates are used, stored sessions will not be reused but a fatal error will be flagged and the handshake will fail.

I'm not 100% sure about setting such id to a default value, although as a SSL_CTX is created per server, I'm assuming sessions are not shared and therefore same session id should not point to same data on different servers.
",5414488
78,2017-11-18T01:55:15Z,2017-11-18T01:55:15Z,,,Modify the method comments that are inconsistent with the parameters.,5414488
79,2017-11-17T21:14:40Z,2017-11-17T21:14:40Z,,,,5414488
80,2017-09-25T22:07:28Z,2017-09-26T17:14:07Z,,,"Most web framework supporting routing request servers to support a fallback resource to be served when the uri does not match any actual file, so as to 'redirect' all requests to a single file (which in term uses the uri in the treatment to serve the actually requested resource).
This is what this does: an new field `fallback_resource` is added to the `mg_serve_http_opts` structure, and used in the `mg_serve_http` function in case the requested resource is not found.",5414488
81,2016-11-24T10:18:23Z,2017-02-28T10:46:19Z,,,"Add a method to modify connect default time in non-blocking mode. Image in some general use occasions which the server ip given doesn't exist, due to setting non-blocking mode in mongoose default, it'll run just like right and we don't know the client is trying to connect nonexistent server until getting through a default time of connect, after that, select function would find the socketfd return read-write available both, actually connect is failed totally. The time is decided by system where you run, and it's probably between 75 seconds to a few minutes. It's wasting the time for our client at least 75 seconds especially for some occasions strict requirments for time. So the time need to be modified in some way.

Hope this would help community~~ LOL

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/cesanta/mongoose/747)
<!-- Reviewable:end -->
",5414488
82,2016-09-20T02:47:00Z,2016-09-20T02:49:54Z,,,"Here is the origin code in the document.

``` c
#include ""mongoose.h""

static const char *s_http_port = ""8000"";

static void ev_handler(struct mg_connection *c, int ev, void *p) {
  if (ev == MG_EV_HTTP_REQUEST) {
    struct http_message *hm = (struct http_message *) p;

    // We have received an HTTP request. Parsed request is contained in `hm`.
    // Send HTTP reply to the client which shows full original request.
    mg_send_head(c, 200, hm.message.len, ""Content-Type: text/plain"");
    mg_printf(c, ""%.*s"", hm.message.len, hm.message.p);
  }
}

int main(void) {
  struct mg_mgr mgr;
  struct mg_connection *c;

  mg_mgr_init(&mgr, NULL);
  c = mg_bind(&mgr, s_http_port, ev_handler);
  mg_set_protocol_http_websocket(c);

  for (;;) {
    mg_mgr_poll(&mgr, 1000);
  }
  mg_mgr_free(&mgr);

  return 0;
}
```

Let's see these two lines:

``` c
    mg_send_head(c, 200, hm.message.len, ""Content-Type: text/plain"");
    mg_printf(c, ""%.*s"", hm.message.len, hm.message.p);
```

The `hm` is a pointer to `struct http_message`, but you use `hm.message` to obtain the element `message` of `*hm`. I think that `hm->message` should be the correct way to represent.

please review 😄  @cpq @rojer . Thank you so much.

<!-- Reviewable:start -->

---

This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/cesanta/mongoose/700)

<!-- Reviewable:end -->
",5414488
83,2016-08-25T03:21:30Z,2016-08-25T03:21:33Z,,,"Use socketpair directly on unix platform which all have this syscall on recent
versions. Current way of creating socketpair is more portable but may block
for nondeterministic time when calling connect. Also it reduce number of
syscalls have to make

<!-- Reviewable:start -->

---

This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/cesanta/mongoose/689)

<!-- Reviewable:end -->
",5414488
84,2020-02-10T02:39:39Z,2020-02-11T02:41:32Z,,,"Purposes:
- Reduce the CPU usage of ""qt.py"" for Windows.
- Fix the bug of loading shared libraries.",41542522
85,2018-02-22T00:40:56Z,2019-02-08T17:44:01Z,,,,41542522
86,2017-07-24T05:40:37Z,2019-02-08T17:44:01Z,,,"This patchset adds some extended options for binding python objects to the browser.
* Allow python/javascript objects to be callable if the python class has `__call__()` function
* Allow optional bind-time-only copying of properties from python object to javascript one.

For more details see Issue #367 and forum: 
https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/cefpython/HVUePvzRXbc ",41542522
87,2017-07-21T03:44:25Z,2019-02-08T17:44:00Z,,,"Expose DragHandler.OnDragEnter
Expose DialogHandler.onFileDialog",41542522
88,2018-09-26T12:38:18Z,2018-10-09T21:04:01Z,,,"Motivation
------------
On the API, we support returning availbility timeslots in increments instead of sequentially using `timeslot_increments` parameter.

However the view is not ideal as timeslots overlap and becomes very cluttered. This PR fixes that by rendering them sequentially but maintains the same timeslot duration internally.

How to use:
```
// Add to widget config
availability: {
  length: '1 hour',
  timeslot_increments: '30 minutes'
}
```

UI & UX
------------

Currently:
<img width=""747"" alt=""screen shot 2018-09-26 at 14 22 43"" src=""https://user-images.githubusercontent.com/222419/46079549-b83c9280-c197-11e8-977e-bf690a4fa341.png"">

Improved view:
<img width=""755"" alt=""screen shot 2018-09-26 at 14 22 00"" src=""https://user-images.githubusercontent.com/222419/46079562-bffc3700-c197-11e8-86c0-9ad0ceb590ed.png"">

Design choices
------------


Side-effects/other
------------


Tests
------------
Made one test that makes sure that timeslots doesn't overlap.

Known issues/limitations
------------
This currently only works when `availability.timeslot_increments` and `availability.length` is available in the config, which doesn't included projects 😢

Release dependencies
------------
N/A

Who should review it
------------
@vistik ",44744780
89,2018-08-17T13:00:07Z,2018-10-09T21:03:53Z,,,🚧 WIP,44744780
90,2020-03-12T19:10:55Z,2020-03-12T19:10:56Z,,,"Bumps [marked](https://github.com/markedjs/marked) from 0.3.3 to 0.8.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/markedjs/marked/releases"">marked's releases</a>.</em></p>
<blockquote>
<h2>0.8.0</h2>
<h2>Breaking changes</h2>
<ul>
<li>Remove substitutions <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1532"">#1532</a></li>
<li>Separate source into modules <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1563"">#1563</a> <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1572"">#1572</a> <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1573"">#1573</a> <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1575"">#1575</a> <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1576"">#1576</a> <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1581"">#1581</a></li>
</ul>
<h2>Fixes</h2>
<ul>
<li>Fix relative urls in <code>baseUrl</code> option <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1526"">#1526</a></li>
<li>Loose task list <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1535"">#1535</a></li>
<li>Fix image parentheses <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1557"">#1557</a></li>
<li>remove module field &amp; update devDependencies <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1581"">#1581</a></li>
</ul>
<h2>Docs</h2>
<ul>
<li>Update examples with es6+ <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1521"">#1521</a></li>
<li>Fix link to USING_PRO.md page <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1552"">#1552</a></li>
<li>Fix typo in USING_ADVANCED.md <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1558"">#1558</a></li>
<li>Node worker threads are stable <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1555"">#1555</a></li>
</ul>
<h2>Dev Dependencies</h2>
<ul>
<li>Update deps <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1516"">#1516</a></li>
<li>Update eslint <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1542"">#1542</a></li>
<li>Update htmldiffer async matcher <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1543"">#1543</a></li>
</ul>
<h2>0.7.0</h2>
<h2>Security</h2>
<ul>
<li>Sanitize <code>paragraph</code> and <code>text</code> tokens <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1504"">#1504</a></li>
<li>Fix ReDOS for links with backticks (issue <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1493"">#1493</a>) <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1515"">#1515</a></li>
</ul>
<h2>Breaking Changes</h2>
<ul>
<li>Deprecate <code>sanitize</code> and <code>sanitizer</code> options <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1504"">#1504</a></li>
<li>Move <code>fences</code> to CommonMark <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1511"">#1511</a></li>
<li>Move <code>tables</code> to GFM <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1511"">#1511</a></li>
<li>Remove <code>tables</code> option <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1511"">#1511</a></li>
<li>Single backtick in link text needs to be escaped <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1515"">#1515</a></li>
</ul>
<h2>Fixes</h2>
<ul>
<li>Fix parentheses around a link <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1509"">#1509</a></li>
<li>Fix headings (issue <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1510"">#1510</a>) <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1511"">#1511</a></li>
</ul>
<h2>Tests</h2>
<ul>
<li>Run tests with correct options <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1511"">#1511</a></li>
</ul>
<h2>0.6.3</h2>
<h2>Fixes</h2>
<ul>
<li>Fix nested blockquotes <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1464"">#1464</a></li>
<li>Fix <code>&lt;em&gt;</code> issue with mixed content <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1451"">#1451</a></li>
</ul>
</tr></table> ... (truncated)
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/markedjs/marked/commit/416003b50daea11c698b4f12ca3b92ce7e67c5cb""><code>416003b</code></a> 0.8.0 (<a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1571"">#1571</a>)</li>
<li><a href=""https://github.com/markedjs/marked/commit/6612ed11854e7163bdca41993f02a4da7f87b701""><code>6612ed1</code></a> 0.8.0</li>
<li><a href=""https://github.com/markedjs/marked/commit/bef6137f803b2d56eef5e17fa953bdc07d2fb478""><code>bef6137</code></a> 🗜️ build [skip ci]</li>
<li><a href=""https://github.com/markedjs/marked/commit/c3ac5e14484697acfbc7b1957d3d5b6aa33c2244""><code>c3ac5e1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1581"">#1581</a> from UziTech/module-field</li>
<li><a href=""https://github.com/markedjs/marked/commit/45a9c4ae5dad5d5fefb29538c6915c22d191ebeb""><code>45a9c4a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1577"">#1577</a> from UziTech/build-user</li>
<li><a href=""https://github.com/markedjs/marked/commit/316a6d712e36ede3bf44e752af66fffab7a6e7da""><code>316a6d7</code></a> remove module field and update deps</li>
<li><a href=""https://github.com/markedjs/marked/commit/6a9c4c3d453786b5911872400ab0f68657d02ebd""><code>6a9c4c3</code></a> fix build user</li>
<li><a href=""https://github.com/markedjs/marked/commit/ed18cd58218ed4ab98d3457bec2872ba1f71230e""><code>ed18cd5</code></a> 🗜️ build [skip ci]</li>
<li><a href=""https://github.com/markedjs/marked/commit/edf87e3f806992ac92a01e7562ad343b4a58c111""><code>edf87e3</code></a> Remove static properties from helpers (<a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1575"">#1575</a>)</li>
<li><a href=""https://github.com/markedjs/marked/commit/81d3018e546f7160703a2fd60d0b75696477656a""><code>81d3018</code></a> Remove incorrectly used browser field (<a href=""https://github-redirect.dependabot.com/markedjs/marked/issues/1573"">#1573</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/markedjs/marked/compare/v0.3.3...v0.8.0"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~tonybrix"">tonybrix</a>, a new releaser for marked since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=marked&package-manager=npm_and_yarn&previous-version=0.3.3&new-version=0.8.0)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/OscarGodson/EpicEditor/network/alerts).

</details>",3277032
91,2020-03-12T19:10:55Z,2020-03-12T19:10:56Z,,,"Bumps [mime](https://github.com/broofa/node-mime) from 1.2.7 to 2.4.4.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/broofa/node-mime/releases"">mime's releases</a>.</em></p>
<blockquote>
<h2>v2.0.3</h2>
<ul>
<li>Fix RegEx DoS issue</li>
</ul>
<h2>v2.0.1</h2>
<ul>
<li>[<strong>closed</strong>] MIME breaking with 'class' declaration as it is without 'use strict mode' <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/170"">#170</a></li>
</ul>
<h2>v2.0.0</h2>
<p>Version 2 is a breaking change from 1.x, as the semver implies.  Specifically:</p>
<ul>
<li><strong>ES6 support required (node@&gt;=6)</strong></li>
<li><code>lookup()</code> renamed to <code>getType()</code></li>
<li><code>extension()</code> renamed to <code>getExtension()</code></li>
<li><code>charset()</code> and <code>load()</code> methods have been removed</li>
</ul>
<ul>
<li>[<strong>closed</strong>] woff and woff2 <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/168"">#168</a></li>
</ul>
<h2>v1.4.1</h2>
<ul>
<li>Fix RegEx DoS issue</li>
</ul>
<h2>v1.4.0</h2>
<ul>
<li>[<strong>closed</strong>] support for ac3 voc files <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/159"">#159</a></li>
<li>[<strong>closed</strong>] Help understanding change from application/xml to text/xml <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/158"">#158</a></li>
<li>[<strong>closed</strong>] no longer able to override mimetype <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/157"">#157</a></li>
<li>[<strong>closed</strong>] application/vnd.adobe.photoshop <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/147"">#147</a></li>
<li>[<strong>closed</strong>] Directories should appear as something other than application/octet-stream <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/135"">#135</a></li>
<li>[<strong>closed</strong>] requested features <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/131"">#131</a></li>
<li>[<strong>closed</strong>] Make types.json loading optional? <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/129"">#129</a></li>
<li>[<strong>closed</strong>] Cannot find module './types.json' <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/120"">#120</a></li>
<li>[<strong>V2</strong>] .wav files show up as &quot;audio/x-wav&quot; instead of &quot;audio/x-wave&quot; <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/118"">#118</a></li>
<li>[<strong>closed</strong>] Don't be a pain in the ass for node community <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/108"">#108</a></li>
<li>[<strong>closed</strong>] don't make default_type global <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/78"">#78</a></li>
<li>[<strong>closed</strong>] mime.extension() fails if the content-type is parameterized <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/74"">#74</a></li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/broofa/node-mime/blob/master/CHANGELOG.md"">mime's changelog</a>.</em></p>
<blockquote>
<h3><a href=""https://github.com/broofa/node-mime/compare/v2.4.3...v2.4.4"">2.4.4</a> (2019-06-07)</h3>
<h2><a href=""https://github.com/broofa/node-mime/compare/v2.4.2...v2.4.3"">2.4.3</a> (2019-05-15)</h2>
<h2><a href=""https://github.com/broofa/node-mime/compare/v2.4.1...v2.4.2"">2.4.2</a> (2019-04-07)</h2>
<h3>Bug Fixes</h3>
<ul>
<li>don't use arrow function introduced in 2.4.1 (<a href=""https://github.com/broofa/node-mime/commit/2e00b5c"">2e00b5c</a>)</li>
</ul>
<h2><a href=""https://github.com/broofa/node-mime/compare/v2.4.0...v2.4.1"">2.4.1</a> (2019-04-03)</h2>
<h3>Bug Fixes</h3>
<ul>
<li>update MDN and mime-db types (<a href=""https://github.com/broofa/node-mime/commit/3e567a9"">3e567a9</a>)</li>
</ul>
<p><a name=""2.4.0""></a></p>
<h1><a href=""https://github.com/broofa/node-mime/compare/v2.3.1...v2.4.0"">2.4.0</a> (2018-11-26)</h1>
<h3>Features</h3>
<ul>
<li>Bind exported methods (<a href=""https://github.com/broofa/node-mime/commit/9d2a7b8"">9d2a7b8</a>)</li>
<li>update to mime-db@1.37.0 (<a href=""https://github.com/broofa/node-mime/commit/49e6e41"">49e6e41</a>)</li>
</ul>
<p><a name=""2.3.1""></a></p>
<h2><a href=""https://github.com/broofa/node-mime/compare/v2.3.0...v2.3.1"">2.3.1</a> (2018-04-11)</h2>
<h3>Bug Fixes</h3>
<ul>
<li>fix <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/198"">#198</a> (<a href=""https://github.com/broofa/node-mime/commit/25ca180"">25ca180</a>)</li>
</ul>
<p><a name=""2.3.0""></a></p>
<h1><a href=""https://github.com/broofa/node-mime/compare/v2.2.2...v2.3.0"">2.3.0</a> (2018-04-11)</h1>
</tr></table> ... (truncated)
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/broofa/node-mime/commit/6479a848ac4699e9dc4049409aad99dbebc3f1da""><code>6479a84</code></a> chore(release): 2.4.4</li>
<li><a href=""https://github.com/broofa/node-mime/commit/ed52b27c3a90bd3f6b8d22796529d6f21ae0b141""><code>ed52b27</code></a> (chore) npm audit</li>
<li><a href=""https://github.com/broofa/node-mime/commit/2f595e4f000daa858f2c2611b56ec221545331f1""><code>2f595e4</code></a> chore(release): 2.4.3</li>
<li><a href=""https://github.com/broofa/node-mime/commit/3f336105fa9ef81f79d574ca627b3f6808225a27""><code>3f33610</code></a> Merge branch 'marlon360-master'</li>
<li><a href=""https://github.com/broofa/node-mime/commit/f348aba051b42b248e856da359d37561e5e9bf17""><code>f348aba</code></a> patch: build .js instead of .json for types. fixes <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/208"">#208</a>.</li>
<li><a href=""https://github.com/broofa/node-mime/commit/30ba26ddf43c11754cbb424d6d679d4c6a11cb34""><code>30ba26d</code></a> chore(release): 2.4.2</li>
<li><a href=""https://github.com/broofa/node-mime/commit/4d59d7687e565e154e29191aa252cdd6bd58c8b8""><code>4d59d76</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/broofa/node-mime/issues/225"">#225</a> from vladgolubev/patch-1</li>
<li><a href=""https://github.com/broofa/node-mime/commit/2e00b5c94a549926b3618d22a33d7c16c3359b74""><code>2e00b5c</code></a> fix: don't use arrow function introduced in 2.4.1</li>
<li><a href=""https://github.com/broofa/node-mime/commit/bd2795aae5b566893709d9afbf9e856ba7855e46""><code>bd2795a</code></a> chore: Update platforms tested in travis</li>
<li><a href=""https://github.com/broofa/node-mime/commit/e3f7a2bece1e20a4101df4f8b021ce49b26cf76d""><code>e3f7a2b</code></a> chore(release): 2.4.1</li>
<li>Additional commits viewable in <a href=""https://github.com/broofa/node-mime/compare/v1.2.7...v2.4.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mime&package-manager=npm_and_yarn&previous-version=1.2.7&new-version=2.4.4)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/OscarGodson/EpicEditor/network/alerts).

</details>",3277032
92,2020-03-12T19:10:54Z,2020-03-12T19:10:56Z,,,"Bumps [uglify-js](https://github.com/mishoo/UglifyJS2) from 1.3.3 to 3.8.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/mishoo/UglifyJS2/releases"">uglify-js's releases</a>.</em></p>
<blockquote>
<h2>v3.8.0</h2>
<p> </p>
<h2>v3.7.7</h2>
<p> </p>
<h2>v3.7.6</h2>
<p> </p>
<h2>v3.7.5</h2>
<p> </p>
<h2>v3.7.4</h2>
<p> </p>
<h2>v3.7.3</h2>
<p> </p>
<h2>v3.7.2</h2>
<p> </p>
<h2>v3.7.1</h2>
<p> </p>
<h2>v3.7.0</h2>
<p> </p>
<h2>v3.6.9</h2>
<p> </p>
<h2>v3.6.8</h2>
<p> </p>
<h2>v3.6.7</h2>
<p> </p>
<h2>v3.6.6</h2>
<p> </p>
<h2>v3.6.5</h2>
<p> </p>
<h2>v3.6.4</h2>
<p> </p>
<h2>v3.6.3</h2>
<p> </p>
<h2>v3.6.2</h2>
<p> </p>
</tr></table> ... (truncated)
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li>See full diff in <a href=""https://github.com/mishoo/UglifyJS2/commits/v3.8.0"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~alexlamsl"">alexlamsl</a>, a new releaser for uglify-js since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=uglify-js&package-manager=npm_and_yarn&previous-version=1.3.3&new-version=3.8.0)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/OscarGodson/EpicEditor/network/alerts).

</details>",3277032
93,2016-01-17T05:45:21Z,2016-01-17T12:37:28Z,,,"To check tab indent you should use the command
`git clone -b tab-indent --recursive https://github.com/Jonybang/EpicEditor.git`
for clone repo, because my variant of solution is using https://github.com/julianlam/tabIndent.js repo as an submodule(suggested by the @valx76).
I also had to significantly modify the code repository @julianlam https://github.com/julianlam/tabIndent.js for support editable container.
For this modification I created a fork 'adapted-for-epic-editor': https://github.com/Jonybang/tabIndent.js
",3277032
94,2014-04-25T18:40:22Z,2014-06-26T08:48:42Z,,,"Currently, pasting external content with sequences of whitespace into
the editor results in the whitespaces being collapsed into a single one
(which is the default behaviour for HTML elements). Instead we really
want all the whitespaces to be preserved and displayed correctly.

Note that this only applies when pasting content, since pressing the
space bar on the keyboard will produce `&nbsp;` which are not collapsed
in any case.

See http://www.w3schools.com/cssref/pr_text_white-space.asp for
more details.
",3277032
95,2013-10-12T08:33:19Z,2015-04-15T16:50:08Z,,,"Made callbacks optional thus it will avoid some errors or bugs
",3277032
96,2020-03-26T16:07:02Z,2020-03-26T16:07:02Z,,,"Continuing #5773: enable that flag and fix the issues it shows. Last commit for mingw is a bit drastic so could be left out; because what it means is that before this change, things like isnan would forward to a function with signature isnan(float) even if the argument is a double. Seems very wrong, so maybe there's a better fix.",15337142
97,2020-03-26T13:36:42Z,2020-03-26T13:36:42Z,,,Using a new option enabled in the uncrustify configuration.  Should fix #5802.,15337142
98,2020-03-26T12:09:51Z,2020-03-26T16:15:16Z,,,"This PR changes the esp8266 boards to use littlefs v2 as the filesystem, rather than FAT.  Since the esp8266 doesn't expose the filesystem to the PC over USB there's no strong reason to keep it as FAT.  Littlefs is smaller in code size, is more efficient in use of flash to store data, is resilient over power failure, and using it saves about 4k of heap RAM, which can now be used for other things.

This is a backwards incompatible change because all existing esp8266 boards will need to update their filesystem after installing new firmware (ie backup old files, install firmware, restore files to new filesystem).

As part of this PR the memory layout of the default board has changed.  It now allocates all 1M of memory-mapped flash to the firmware, so the filesystem area starts at the 2M point.  This is done to allow more frozen bytecode to be stored in the 1M of memory-mapped flash.  This requires an esp8266 module with 2M or more of flash to work, so a new board called `GENERIC_1M` is added which has the old memory-mapping (but still changed to use littlefs).

In summary there are now 3 esp8266 board definitions:
- `GENERIC_512K` for 512k modules, doesn't have a filesystem
- `GENERIC_1M` for 1M modules, 572k for firmware+frozen code, 396k for filesystem (littlefs)
- `GENERIC_2M` for 2M (or greater) modules, 968k for firmware+frozen code, 1M+ for filesystem (littlefs)

The plan is to have all 3 available for download at https://micropython.org/download",15337142
99,2020-03-25T17:38:41Z,2020-03-25T20:00:30Z,,,"- Allow `-d` as an alias for `--device`
- Allow defaults for `--device` and `--baud` to be set via
  `PYBOARD_DEVICE` and `PYBOARD_BAUD` environment variables.",15337142
100,2020-03-25T15:24:40Z,2020-03-25T19:19:22Z,,,Lock should raise a RuntimeError with an error message like CPython does.,15337142
101,2020-03-25T15:02:45Z,2020-03-25T21:59:56Z,,,"Support global exception handling to uasyncio according to CPython error handling: https://docs.python.org/3/library/asyncio-eventloop.html#error-handling-api

Adds the Loop methods (also changing all loop methods to be staticmethos or classmethods since there is only one loop) and a default exception handler. 

This is especially interesting since this new version of uasyncio doesn't throw exceptions to the caller of ""loop.run_forever()"" and therefore exceptions in other tasks are only printed to repl, where the user might never see it since the device will be deployed without logging the repl output. 
With a global exception handling a user can catch those exceptions and send them by mqtt or log them to a file on the device. 

The implementation preallocates a context dictionary so in case of an exception there shouldn't be any RAM allocations.

The used approach is compatible to CPython except for 2 problems:
1) There is no way to log the Exception traceback because ""sys.print_exception"" only prints the traceback to the repl. So there is no way to actually log the traceback, which would be very helpful. Hopefully this can be implemented. I understand that this might cause RAM allocation but a user might decide to use it anyway in a custom exception handler because it makes debugging a lot easier if you know in what file and line the error occured.
2) In CPython the exception handler is called once the task is finished which created the task that threw an uncaught exception, whereas in UPy the exception handler is called immediately when the exception is thrown. This makes a difference in the following testcase but is generally just a minor difference that shouldn't cause any abnormal behaviour.

```
async def test_catch_uncaught_exception():
    # can't work with a local return value because the exception handler runs after
    # the current coroutine is finished in CPython. Works in UPy though.
    res = False

    async def fail():
        raise TypeError(""uncaught exception"")

    def handle_exception(loop, context):
        # context[""message""] will always be there; but context[""exception""] may not
        print(context)
        print(context[""message""])
        print(context[""exception""])
        msg = context.get(""exception"", context[""message""])
        if mp:
            print(""Caught: {}{}"".format(type(context[""exception""]), msg))
        else:
            print(""Caught: {}"".format({msg}))
        nonlocal res
        print(""res is"", res)
        res = True
        print(""done"")

    t = asyncio.create_task(fail())
    loop = asyncio.get_event_loop()
    loop.set_exception_handler(handle_exception)
    await asyncio.sleep(0.1)
    await asyncio.sleep(0.1)
    print(""coro done"")
    return res
```",15337142
102,2020-03-25T06:10:07Z,2020-03-25T12:24:55Z,,,"PR #5558, and specifically commit 6cea369 updated the TinyUSB submodule to a version based on nrfx 2.0.0, which broke the NRF build for USB-enabled boards.

It's not really feasible to be using a different nrfx to TinyUSB, so this PR both fixes the (minor) TinyUSB changes and updates to nrfx 2.0.0.

I only have a limited amount of NRF dev boards (a 52840 (Xenon) and a 51822 (micro:bit)) so will do some testing when I get a chance.

Also added more boards to the Travis build to avoid breaks like this in the future.

@glennrub",15337142
103,2020-03-23T02:30:30Z,2020-03-24T14:08:25Z,,,"This adds the python files in the `tests/` directory to be formatted with `./tools/codeformat.py`.

In a few places `# fmt: off`/`# fmt: on` was used where the code had special formatting for readability or where the test was actually testing the specific formatting.",15337142
104,2020-03-22T23:58:59Z,2020-03-24T15:26:55Z,,,"The test tests/thread/thread_stacksize1.py sometimes crashes with a segmentation fault because of an uncaught NLR jump.

    $ ./ports/unix/micropython-coverage tests/thread/thread_stacksize1.py
    0
    0
    True
    0
    Unhandled exception in thread started by FATAL: uncaught NLR 0x7fc316d06500

Using a debugger, this exception message was found to be:

    ""maximum recursion depth exceeded""

To fix this, we add some additional checks in the test to give a bigger stack to ""desktop"" platforms that need it to avoid this crash.",15337142
105,2020-03-20T05:16:40Z,2020-03-25T16:05:05Z,,,"These were found by building the unix coverage variant on macOS (so clang compiler). Mostly, these are fixing implicit cast of float/double to mp_float_t which is one of those two and one mp_int_t to size_t fix for good measure.",15337142
106,2020-03-17T09:21:41Z,2020-03-17T23:27:26Z,,,"This is to fix issue #4212 with the minimum change possible.

It has to store a copy of the input float value before it gets divided out by powers of 10, but it runs slightly faster with this benchmark:

```Python
t0 = time.ticks_us();  max(str(float(x))  for x in range(500000, 510000));  (time.ticks_us()-t0)*1e-6
```
* New 10.1633 seconds
* Original: 10.84897 seconds

This is because the implementation from @dhylands  [https://github.com/dhylands/format-float](format-float) does a floating point multiplication (by ten) for each digit, and my fix deals with the integer part of the number using only integer arithmetic.  


*I think there is scope for an overall faster implementation just using int32 arithmetic, but one would have to start by decoding the bit layout of the float into its mantissa and exponent, rather than interacting with value using normal arithmetic functions that do not depend on its encoding -- but since MicroPython is already bit packing and unpacking these values, this wouldn't make it any more dependent.*

*One advantage of any float32 format conversion is it's possible to exhaustively test every single combination of bits (there's only 4 billion of them) in just a few hours.*",15337142
107,2020-03-15T14:13:43Z,2020-03-16T08:21:03Z,,,"By making `$(MPY_CROSS)` an order-only prerequisite of the various frozen files, it removes the need to remember to build `../../mpy-cross/mpy-cross` by hand on a clean checkout.

More info on [order-only prerequisites](https://www.gnu.org/software/make/manual/html_node/Prerequisite-Types.html).
",15337142
108,2020-03-13T17:34:02Z,2020-03-26T19:37:14Z,,,"Moves the Sensor class from the zsensor module to the zephyr module to
keep it together with other port-specific classes. This makes the zephyr
module more like the pyb module in other ports. Removes the now-empty
zsensor module.

Tested on the frdm_k64f board with the fxos8700
accelerometer/magnetometer sensor.",15337142
109,2020-03-13T12:45:18Z,2020-03-25T04:21:18Z,,,"Some SD cards, such as the Samsung 64GB EVO SDXC, check the CRC on all self.cmd() calls in sdcard.py driver and return a CRC error result if they are set to 0x00 resulting in the code failing.  Adding the CRC values does not affect cards that don't use them so there is no harm in having them.",15337142
110,2020-03-12T01:00:48Z,2020-03-13T00:23:39Z,,,"1. install_tar() used empty filename if no directory present in path.

Changed:
```
        fname = info.name
        try:
            fname = fname[fname.index(""/"") + 1 :]
        except ValueError:
            fname = """"
```
to:
```
        fname = info.name
        try:
            fname = fname[fname.index(""/"") + 1 :]
        except ValueError:
            pass
```
			

2. All errors were caught at highest level and resulted in a failure message printed to the console. No way to find out about errors programmatically. Added a module level variable (fail_reason) to store the exception causing the abort and None if there are no errors.

3. in url_open() the port number was hard coded as 443.  Port number is now dependent on proto and can also be suffixed to host.

4. In url_open the call to usocket.getaddrinfo() can also return empty list instead of exception.  EINVAL is now reaised in such cases, giving proper error message when there is no internet.

5. In there are multiple implementations of the same versions, upip used to abort. Now the one with packagetype == 'sdist' is used.",15337142
111,2020-03-11T21:34:32Z,2020-03-13T18:19:01Z,,,Board files for the WROVER module with SPIRAM (4 MB used) and 16MB Flash.,15337142
112,2020-03-06T02:19:29Z,2020-03-10T00:52:05Z,,,"A simple reproducer is:
```
async for x in():x
```

Before this change, it would cause an assertion error in mpy-cross.",15337142
113,2020-03-05T05:12:02Z,2020-03-25T01:02:27Z,,,"The mass erase command is currently not implemented in mboot due to the desire to not wipe the bootloader itself.

This PR adds a 'fake' mass erase command which erased sector-by-sector everything except the first mboot sector.

This change was originally included as part of https://github.com/micropython/micropython/pull/5309 but I've split it out as it grew into a significantly larger change-set than originally anticipated.

The erase command can take some time, on my stm32f765 with 2MB of flash it takes 8 to 10 seconds. This is normally enough to make pydfu fail on a timeout.

The DFU standard includes a mechanism for the dfu device to request a longer timeout as part of the get-status response just before starting an operation. This timeout functionality has been implemented here.

This PR required / is sitting on top of https://github.com/micropython/micropython/pull/5724 and https://github.com/micropython/micropython/pull/5728 github doesn't have and PR stacking yet so  these PR's commits are at the bottom of this one. Only the last two commits are relevant directly to this.",15337142
114,2020-03-05T04:04:47Z,2020-03-07T09:24:02Z,,,add OS detecting for building mpy-cross tool itself too. test under github action runner here: [mpy-cross](https://github.com/ccccmagicboy/MicroPython_fw_action/actions/runs/49871075),15337142
115,2020-03-05T03:51:35Z,2020-03-25T06:15:12Z,,,"In mboot, the ability to override the usb vendor/product id's was added back in https://github.com/micropython/micropython/pull/4584

However, when the main firmware is turned into a dfu file the default vid/pid are used there. `pydfu` doesn't care about this but `dfu-util` does and prevents its use.

This PR exposes `MBOOT_USB_VID` and `MBOOT_USB_PID` as make variables, for use on either command line or `mpconfigboard.mk`, to set vid/pid in both mboot and dfu files",15337142
116,2020-03-05T02:18:10Z,2020-03-22T22:47:25Z,,,"https://www.python.org/dev/peps/pep-0475/

This implements something similar to PEP 475 on the unix port.

There are a few differences from the CPython implementation:
- Since we call mp_handle_pending(), addition functions could be called  if `MICROPY_ENABLE_SCHEDULER` is enabled, not just signal handlers.
- CPython only handles signal on the main thread, so other threads will  raise `InterruptedError` instead of retrying. On MicroPython,  `mp_handle_pending()` will currently raise exceptions on any thread.",15337142
117,2020-03-04T04:33:58Z,2020-03-20T04:30:00Z,,,"This is my first document pull request that I am making at the suggestion of jimmo.

I would like to propose changes to the machine SPI module signature in order to add circular DMA functionality to the SPI module. The STM32 family is quite broad. I am working with the STM32L452RE specifically, but what I am discussing should apply to the STM32L4 family as the DMA controller is common. This would be implemented differently on the Pyboard D for instance as its DMA controller has double buffer mode. Here is what I am proposing:

Add the parameters:
**callback** - called when the SPI transfer is completed on a single transfer and repeatedly for circular dma.
**callbackhalf** - called when half of a transfer is completed on a single transfer and repeatedly for circular dma.
**callbackerror** - called if there was a transfer error
**dmamode** - NORMAL or CIRCULAR

If the mode is _NORMAL_, the three new keywords would not be allowed. Only if _CIRCULAR_ was specified, would the new callbacks be supported. 

**Problem**: Where will the information for circular, callbackhalf, callbackfull, callbackerror get stored. Currently, spi_t holds all the STM32HAL SPI type of parameters.

I propose to modify struct _spi_t (in ports/stm32/spi.h) to add the following member:

```
typedef struct _spi_t {
    SPI_HandleTypeDef *spi;
    const dma_descr_t *tx_dma_descr;
    const dma_descr_t *rx_dma_descr;
    ****const dma_mode_t      *dma_mode; // Null if normal blocking behavior****
} spi_t;
```

In order to add an optional DMA configuration structure. This will hold the DMA mode (CIRCULAR, callbackhalf, callbackfull, callbackerror). If NORMAL (default) is specified the dma_mode pointer would be NULL.

To support bigger parts, DMA mode could also include:
DUALBUFFER, etc.

Each of these modes would carry a union of parameters (some required, some optional) for each of the separate DMA modes. The definition of the union would be part specific depending upon the DMA modes supported and the settings in mpconfigport.h. By default, it could be disabled (no compiled changes to the code), and enabled by those that care about this mode (like me).

Please comment.

Thanks

Rich
",15337142
118,2020-03-03T05:50:15Z,2020-03-03T08:52:36Z,,,"(This PR is not ready yet.)
I'm trying to split the esp-idf v3 and v4 travis jobs to make it easier to see what is happening when there is a failure. The majority of the time is taken by the actual make process so the extra overhead of the double download seems minimal (and it's at travis' expense anyway).",15337142
119,2020-03-01T05:51:54Z,2020-03-03T05:15:25Z,,,"This PR builds on #5682 (and is similar to #5653). Additions:
- the `mp_port_fun_table` is populated automatically from the ESP-IDF documentation (#5682 left that out).
- the ESP32 Makefile is split in half so native modules that `#include` esp-idf header files can use the same definitions as those used for the firmware in the first place.
- the functions in `mp_port_fun_table` are dynamically linked using fix-ups, no explicit double-indirection via the `mp_port_table` necessary.

This PR is obviously a lot longer than #5682 but that is primarily due to the reworking of the Makefile and the generation of the `mp_port_fun_table` contents (both ""conveniently"" left out of #5682 ;-) ). IMHO the `mp_port_fun_table` is not usable without those two features. The dynamic linking fixup changes are pretty small after that...

Items left to do:
- add stdlib functions to `mp_port_fun_table`: for example, I needed `strlen` is a simple native module I wrote (update: done in 30eca7d52b099712cfde3225911fa842cc6bf6c8)
- write/update user documentation
- fix `mp_port_fun_table` contents for esp-idf v3 (there are a couple of functions in the table that don't exist)
- fix error handling in the dynamic linker: if an entry in the `mp_port_fun_table` is 0 or the index is out of bounds the import process should be aborted",15337142
120,2020-02-26T16:40:51Z,2020-03-22T02:21:52Z,,,"I've finally achieved my ambition [to put Micropython into a lightbulb](https://twitter.com/goatchurch/status/1232698764340727809)!

These  [AiLights](https://tinkerman.cat/post/ailight-hackable-rgbw-light-bulb) actually have a ESP8285, but the full Micropython with the mqtt-stack works fine.  The lighting controller is a my9291 chip with no documentation about its protocol, and the only implementation of it in Arduino-world [by bitbanging](https://github.com/xoseperez/my92xx).

I put the function into the same places as the `esp_neopixel_write()` function, which also is implemented by some some similar timed bitbanging.  I added some delays to keep the same time as the working arduino code.  Bitbanging directly from Micropython does not work: If the pulses are longer than 4microseconds the chip does not accept the signal.  

This is not the ideal function; it was originally meant to be 5 parameters, but the macro MP_DEFINE_CONST_FUN_OBJ_5 does not exist and it would have taken too many edits on the base code to put it in.  

So I'm putting this pull-request out here for comments about whether the function is adequate or in the right place, or whether a more general purpose function for bitbanging things like my9291 could be made (if there are any other chips like this).
",15337142
121,2020-02-26T13:28:48Z,2020-03-05T05:13:24Z,,,"This is a rework of #4731 based on https://github.com/adafruit/circuitpython/pull/2657

The idea is that a built-in module can add another module as a member of its globals dict (whereas the previous approach was to allow for built-in modules with dots in their name).

I think the main surprise with this approach is that

```
import foo
foo.bar.baz()
```

will work, without foo.bar ever being explicitly imported, however there's nothing stopping a regular Python package from doing this either via its `__init__.py`.   That said, if `MICROPY_MODULE_BUILTIN_INIT` is enabled, then foo.bar's init will not be called in the above example.

The net code size change for this PR is -44 bytes on PYBV11 (but this feature itself, i.e. the final commit, is +56 bytes).

@tannewt  @v923z",15337142
122,2020-02-25T21:59:13Z,2020-03-22T15:19:46Z,,,"As noted in #5696, there were issues with PWM for `Pin.OPEN_DRAIN` gpio output mode. However, open drain was not being enabled, it was only emulated with the `Pin.value()` function.  This adds calls `mp_hal_pin_open_drain()` to put the pin into true open drain mode and removes the emulation code from `Pin.value()`.

It also removes the code that was explicitly turning off the open drain output during PWM. Together these changes allow driving external transistor high-current switches.",15337142
123,2020-02-25T15:14:46Z,2020-03-10T16:27:06Z,,,"Use the 40MHz freq for SD card clk, tested on a esp32 module, and 30% read/write speed improve.",15337142
124,2020-02-22T18:21:52Z,2020-02-22T18:21:52Z,,,define MICROPY_HW_HID_POLLING_INTERVAL in mpconfigboard default is 8ms,15337142
125,2020-02-21T13:36:07Z,2020-02-21T18:59:20Z,,,"Basic definitions for the newer H743 board.
Some GPIO is relocated compared to the old(er) H743ZI boards
Also features the STLINKv3.
Notes some peculiarities that are good to know
Tested REPL, USB, SDCARD, DFU
",15337142
126,2020-02-20T11:33:01Z,2020-02-21T09:43:14Z,,,"Fixes #5677

This is +8 bytes on PYBV11.",15337142
127,2020-02-19T21:41:32Z,2020-03-13T10:43:53Z,,,"I needed to configure tx power so I added a 'txpower' parameter to WLAN.config method for setting and getting max access point transmitter power. I tested it and the changes are effective immediately after entering the command. The WiFi signal strength on my phone dropped from excellent to poor after setting it from maximum to minimum. Minimum is -19 for -10.5 dBm and maximum is 76 for 19 dBm.

Minimal working example:
```
import network as net
ap = net.WLAN(net.AP_IF)
ap.active(True)
ap.config(txpower=76)
print(ap.config('txpower') * 0.25, 'dBm')  # 19.0 dBm
```",15337142
128,2020-02-19T08:42:56Z,2020-02-22T08:51:36Z,,,"I have declared CAN1 and CAN2 pins in `mpconfigboard.h`. It has compiled well and without errors or warnings.
The only issue is that I can't bring it up. 
I have the Logic Analyser connected to CAN RX and CAN TX pins (also tried with TJA1050) which are PB8 and PB9. When running the code:
```py
from pyb import CAN
can = CAN(1, CAN.NORMAL)
# can = CAN(1, CAN.NORMAL, prescaler=2, sjw=1, bs1=14, bs2=6)
can.send('message!', 123)
```
I see no reaction.

I'm curious if I have missed something or It's not that easy to enable an extra interface.
PS. There was no Crystal soldered, later I have soldered one with 8MHz but nothing changed.",15337142
129,2020-02-18T11:20:12Z,2020-02-18T17:58:32Z,,,"This PR is inspired by https://forum.micropython.org/viewtopic.php?f=3&t=7662 and the native module example at https://github.com/jamesbowman/py-bteve/tree/2407c82f852937bdf430cb12469e2b59ab588b3e/mpy, and also CircuitPython's fix https://github.com/adafruit/circuitpython/pull/2550 (see https://github.com/adafruit/circuitpython/commit/81c3bc411fadd41890d4e432a204a12d0750955b and https://github.com/adafruit/circuitpython/commit/f6a635b102259c6bc7d0f163881eac5b5e50a117)

The aim is to allow Python classes to subclass native C classes (eg list) and for the C base class to then be able to call methods of the Python child instance.  Eg:
```python
class A:
    def foo(self):
        self.bar() # call inherited method
class B(A):
    def bar(self):
        print('B.bar')
b = B()
b.foo() # should eventually call b.bar()
```
except that we want to implement class `A` in native C code.

Currently this is not possible to do because native classes get passed their native instance, even if the top-level object is a derived user instance (eg as `b` is above).

One fix is to not extract out the native instance of derived user instances when invoking C methods, but instead pass the top-level instance to the C method.  The problem with this is that all C methods must now be aware that they could be passed a user instance and must handle it accordingly.

The PR here does it a different way, by adding a new type flag that is set only on C classes that can handle a user instance coming in as the ""self"" argument to their C method.  The advantage of this approach is that classes like tuple/list/dict that don't ever call methods of their inherited objects don't need to have this flag set and so don't need to change.  Only C classes that want to support this feature can enable the flag (there will be overhead in code size and execution time for the C methods to test and extract the native instance).

This PR also exposes the new API function to dynamic native modules, and provides a new example of a dynamic native module that uses this feature (see original forum post linked above).

@tannewt FYI",15337142
130,2020-02-17T00:35:43Z,2020-02-22T05:13:12Z,,,"This PR is a proof-of-concept for creating stubs that allow dynamically loaded native modules (.mpy files) to call platform-dependent functions. The goal is to make it easy to write native modules that call ESP-IDF functions by just adding the names of the needed functions to a list and is inspired by #5618, #5641, and #5643. Overall the approach taken here functions very similarly to the `mp_fun_table` with the following differences:

- engineered for platform-dependent functions instead of platform independent functions,
- everything is generated from a single list of functions (in `ports/esp32/plat_relo.py`),
- no typing information, relies on calling convention to pass up to 6 args through the stub,
- generates ASM stub to minimize the size of each stub (3 instructions / 8 bytes).

More details about the functioning can be found in `ports/esp32/plat_relo.py`. I am assuming that there will be some discussion about merging this stuff with the `mp_fun_table`.

A completely different approach that I did not investigate in detail would be to enhance the dynamic linker in the firmware so it can fix up the targets of the `CALL` instructions, i.e., perform proper linking instead of the whole stub stuff. It shouldn't be difficult because as far as I can tell external calls always use a 32-bit constant stored in a memory word. If that approach is desired I could put together a list of ""where do I implement X"" questions and then give it a shot.",15337142
131,2020-02-15T18:35:45Z,2020-02-16T12:13:31Z,,,"This modification concerns only runtime.c, and implements getters/setters for properties. The code is based entirely on circuitpython's runtime.c (https://github.com/adafruit/circuitpython/blob/6dfa527f79189b6a79a7055d718313f2a14288a4/py/runtime.c#L1158, https://github.com/adafruit/circuitpython/blob/6dfa527f79189b6a79a7055d718313f2a14288a4/py/runtime.c#L1023). 

The inclusion of the functions is determined by the 
``` 
CFLAGS_EXTRA += -DMICROPY_PY_BUILTINS_PROPERTY_GETTER=1
CFLAGS_EXTRA += -DMICROPY_PY_BUILTINS_PROPERTY_SETTER=1
```
compiler switches. Setting both flags adds 288 bytes to the firmware on the unix port. 

Broader context, and rationale can be found in the forum thread: https://forum.micropython.org/viewtopic.php?f=3&t=7762

Possible use case

```c
#include <stdio.h>
#include ""py/runtime.h""
#include ""py/obj.h""

typedef struct _propertyclass_obj_t {
    mp_obj_base_t base;
    mp_float_t x;
} propertyclass_obj_t;

const mp_obj_type_t propertyclass_type;

// lifted from objproperty.c
typedef struct _mp_obj_property_t {
    mp_obj_base_t base;
    mp_obj_t proxy[3]; // getter, setter, deleter
} mp_obj_property_t;

STATIC mp_obj_t propertyclass_make_new(const mp_obj_type_t *type, size_t n_args, size_t n_kw, const mp_obj_t *args) {
    mp_arg_check_num(n_args, n_kw, 1, 1, true);
    propertyclass_obj_t *self = m_new_obj(propertyclass_obj_t);
    self->base.type = &propertyclass_type;
    self->x = mp_obj_get_float(args[0]);
    return MP_OBJ_FROM_PTR(self);
}

STATIC mp_obj_t propertyclass_get_x(mp_obj_t self_in) {
    (void)self_in;
    printf(""in propertyclass_get_x()\n"");
    return mp_obj_new_float(1.0);
}

MP_DEFINE_CONST_FUN_OBJ_1(propertyclass_get_x_obj, propertyclass_get_x);

STATIC mp_obj_t propertyclass_set_x(mp_obj_t self_in, mp_obj_t value) {
    (void)self_in;
    (void)value;
    printf(""in propertyclass_set_x()\n"");
    return mp_const_none;
}

MP_DEFINE_CONST_FUN_OBJ_2(propertyclass_set_x_obj, propertyclass_set_x);

STATIC mp_obj_t propertyclass_del_x(mp_obj_t self_in) {
    (void)self_in;
    printf(""in propertyclass_del_x()\n"");
    return mp_const_none;
}

MP_DEFINE_CONST_FUN_OBJ_1(propertyclass_del_x_obj, propertyclass_del_x);

const mp_obj_property_t propertyclass_x_obj = {
    .base.type = &mp_type_property,
    .proxy = {(mp_obj_t)&propertyclass_get_x_obj,
              (mp_obj_t)&propertyclass_set_x_obj,
              (mp_obj_t)&propertyclass_del_x_obj},
};

STATIC mp_obj_t propertyclass_xsq(mp_obj_t self_in) {
    propertyclass_obj_t *self = MP_OBJ_TO_PTR(self_in);
    return mp_obj_new_float(self->x * self->x);
}

MP_DEFINE_CONST_FUN_OBJ_1(propertyclass_xsq_obj, propertyclass_xsq);

STATIC const mp_rom_map_elem_t propertyclass_locals_dict_table[] = {
    { MP_ROM_QSTR(MP_QSTR_xsq), MP_ROM_PTR(&propertyclass_xsq_obj) },
    { MP_ROM_QSTR(MP_QSTR_x), MP_ROM_PTR(&propertyclass_x_obj) },
};

STATIC MP_DEFINE_CONST_DICT(propertyclass_locals_dict, propertyclass_locals_dict_table);

const mp_obj_type_t propertyclass_type = {
    { &mp_type_type },
    .name = MP_QSTR_propertyclass,
    .make_new = propertyclass_make_new,
    .locals_dict = (mp_obj_dict_t*)&propertyclass_locals_dict,
};

STATIC const mp_map_elem_t propertyclass_globals_table[] = {
    { MP_OBJ_NEW_QSTR(MP_QSTR___name__), MP_OBJ_NEW_QSTR(MP_QSTR_propertyclass) },
    { MP_OBJ_NEW_QSTR(MP_QSTR_propertyclass), (mp_obj_t)&propertyclass_type },	
};

STATIC MP_DEFINE_CONST_DICT (
    mp_module_propertyclass_globals,
    propertyclass_globals_table
);

const mp_obj_module_t propertyclass_user_cmodule = {
    .base = { &mp_type_module },
    .globals = (mp_obj_dict_t*)&mp_module_propertyclass_globals,
};

MP_REGISTER_MODULE(MP_QSTR_propertyclass, propertyclass_user_cmodule, MODULE_PROPERTYCLASS_ENABLED);
```",15337142
132,2020-02-14T03:10:35Z,2020-02-20T04:37:54Z,,,"Basically just a copy-paste of all of the types in `obj.h` to allow access in native modules.

Related to https://github.com/micropython/micropython/issues/5609",15337142
133,2020-02-14T02:56:17Z,2020-03-08T08:24:06Z,,,"The WeAct v2.0 board (also sometimes known as the ""blackpill"") is a micropython-capable board based on the STM32F411CE (512kB flash, 128kB SRAM) that costs only a few US dollars and is widely available from various Chinese suppliers. It is a breadboard compatible breakout-style board that has reset/BOOT0/user switches, a user LED and a USB C connector, along with 25MHz and 32.768kHz crystals.

Although the board has an unpopulated flash footprint, I don't have any SPI flash ICs around to test it and add support, so this only supports internal flash for the time being. I have ordered some and will try to test the external flash when I get a chance.

moved from https://github.com/micropython/micropython/pull/5582 to a branch",15337142
134,2020-02-06T21:43:32Z,2020-02-14T04:11:21Z,,,change bluetooth to ubluetooth when relevant.,15337142
135,2020-02-06T00:28:31Z,2020-02-13T17:15:22Z,,,"Exposes basic compression support from uzlib. I originally wrote this nearly a year ago so don't really remember too much about it.

Pushed up to support #5590

Doesn't have any unit tests written... probably needs some first. Possibly some #define's to enable/disable the compress functionality?",15337142
136,2020-02-05T17:41:20Z,2020-02-07T16:30:09Z,,,"The two first commits are MicroPython related, the other three are a Python Websocket class that works both with WebREPL (ws) and WebREPL over SSL (wss).

_Related to **webrepl.py**_:

 * I use port 8833, but this can be changed to 8433 (or is there any 'official' port for this?)
 *  Name convention for key and cert: `'SSL_certificate{}.der'.format(hexlify(unique_id()).decode())`
I use the unique id to be able to have unique key-cert for each device.
 * Name for WebREPL over SSL: I use 'WebSecureREPL' just to differentiate both since Websockets over SSL are called Websockets secure, but I guess this doesn't really matters 

_Related to **websocket_helper.py**_:
* Just minor changes to allow both tcp sockets and ssl sockets.

_Related to **ws_protocol.py**, **ws_client_handshake.py** and **websocket_client.py**_:
These are not part of the PR really, just for testing (although they could be included in this or another PR).
* Both `ws_protocol.py` and `ws_client_handshake.py` are adaptations from https://github.com/danni/uwebsockets/tree/esp8266/uwebsockets, and there is no external dependency, just ""pure"" Python.
* `websocket_client.py` is a simple class to sends commands and receive output. ( for both ws and wss). This could be adapted or included in some way in `pyboard.py`
",15337142
137,2020-02-04T09:40:07Z,2020-02-08T15:36:19Z,,,"Hardware flow control will be enabled appropriately when rts or cts are defined. The rts-threshold is set 1, resulting in a rxbuf + 1, before rts is raised. Then still FIFO_size - 1 bytes can be received without data loss. The FIFO_size is 128.
Note: Setting rts_threshold to 0 has a strange side effect, that rts pulses with every received byte.",15337142
138,2020-02-03T16:08:00Z,2020-02-03T16:08:00Z,,,"This small patch to UPIP handles the error that occurs when the JSON from a package contains more than one option for downloads (wheels, tars, etc.). The index chosen by the package that has its ""python_version"" set to ""source"". I am uncertain if we need to check the value of ""idx"" before parsing (since this an embedded device application). I have tested this on my machine, but feel free to test this further before merging. Thanks! ",15337142
139,2020-02-01T06:46:15Z,2020-02-02T20:12:17Z,,,"This PR handles the timeout parameter in `thread_lock_acquire`.

It provides a set of compilation flags, tests, and an implementation for the unix and the esp32 ports. Other ports based on freertos should be easy to implement based on the esp32 port, because freertos lock_acquire already handles the timeout parameter. Unfortunately I do not have access to other hardware, so I think it is better to leave to others the task of replicating the functionality on other ports.

Let me just add a word about the relevance of handling the timeout parameter in lock_acquire. The only feature used by the current CPython implementation of threading.py that is nor yet supported by _thread is precisely a call to lock_acquire with a timeout parameter. In fact, a _thread_lock_acquire with timeout is issued in RLock and all subsequent classes in threading.py are based on RLock! Implementing the timeout parameter essentially enables a micropython version of Threading.",15337142
140,2020-01-26T15:19:02Z,2020-01-26T15:19:02Z,,,Notes for building on Linux 64-bit and running on WSL1,15337142
141,2020-01-26T10:48:35Z,2020-02-02T14:10:37Z,,,"The default base64 implementation adds a linefeed to the end of the string. To perform a base64url encoding we need to remove this, the padding and translate the two replaced characters. This is fine on a desktop, but on a resource constrained device this involves multiple copies of the string. This PR adds an optional parameter to the b2a_base64 and a2b_base64 that allow the caller to control the encoding with an const/enum defined bit flags. Also the a2b function allocates the correct output buffer size.",15337142
142,2020-01-23T18:01:58Z,2020-03-13T18:23:52Z,,,Give access to hardware flow control and RS485 half-duplex mode.,15337142
143,2020-01-22T13:38:48Z,2020-01-25T01:24:52Z,,,"This fixes #5538 (basically like #5557, I just needed to be based on the fix, we can merge the fixing commit from either PR).

After the simple fix, it adds a set of type checks to `mp_obj_is_type` to prevent such errors in the future.

TODOs:

- [x] Add some coverage tests for the bug fix (as Damien suggested in #5538 )
- [x] Figure out why this increases code size (apparently, making `mp_obj_is_type` a complex expression has a bad effect on GCC's optimizations of functions using it. I need to look into it. Worst case, we can enable these checks only for debug builds, so the CI will test it)
- [x] Possibly add runtime checks to `mp_obj_is_type` using some `assert`s.",15337142
144,2020-01-21T10:58:33Z,2020-03-09T07:33:19Z,,,"This is the minimum change to fix the example code so it actually runs.

Unfortunately documenting the RTC class is difficult because it has been implemented differently for each platform. I checked STM, ESP8266 and ESP32. All implement `datetime`. Implementation of `init` is platform dependent: STM accepts no args. ESP8266 does not implement it while ESP32 requires a datetime tuple. Further, each platform implements a different set of methods and some documented methods are not implemented on any of these platforms: for example the `now` method.

Methods such as `calibrate` are inherently hardware dependent but where a method is implemented across platforms its calling signature should (in my view) be consistent.

There are other platforms where I don't own hardware so can't test. I'm stumped as to how properly to document this class.",15337142
145,2020-01-16T07:43:08Z,2020-01-28T05:56:29Z,,,"This PR proposes to add support for PSK cipher suites to ussl, specifically for the esp32 but it should be supportable for other platforms that use mbedtls as well (there is nothing esp32-specific in this PR except for enabling the cipher suites in the mbedtls config, which is port-specific).
The PSK cipher suites are awesome because they do away with all the cert and key stuff. Instead each client can get an id and hex-key and use that for bidirectional auth when connecting to the server. Very useful for MQTT, for example.
Docs can be read at: https://micropython-tve.readthedocs.io/en/tls-psk/library/ussl.html",15337142
146,2020-01-15T23:19:39Z,2020-02-21T16:27:10Z,,,"From #5225, as described by @mirko 

> SPI allows word sizes of several bits, not necessarily rounded up to a multiple of 8.
> While I don't now about every platform / hardware, at least soft-SPI (GPIO bitbanged SPI) and the ESP IDF driven ESP32 SPI hardware support transferring single bits via SPI.
> Looking at the micropython code though, the whole SPI abstraction layer - HW backed or SW - assumes lengths of multiples of bytes, meaning, I can't just adjust the parts related to esp32 / gpio.
> 
> To provide a use case - and I indeed see this being an edge case, but keep in mind that it still conforms with the SPI spec: (ab)using SPI to speak SWD.
> 
> Suggestion / Feature request: Adjust the SPI code so that we can transmit single bits instead of multiples of bytes.
> 
> Happy to do it myself / help / assist / for discussion. However at first glance, the changeset apparently would be larger than anticipated and I'd be glad for opinions / input / help.",15337142
147,2020-01-13T18:17:48Z,2020-01-14T23:17:17Z,,,"See CPython bug https://bugs.python.org/issue39091 for more details.

The simplest example of the crash comes when you define `__new__` to return an int. The `mp_obj_t` for an integer value will generally look like the given integer value, left-shifted by a few bits. The VM will then try to dereference that value here: https://github.com/micropython/micropython/blob/1c849d63a86782f006b73a9d570d542cfd18538e/py/vm.c#L1424

It might also be a good safe idea to change instances of `((mp_obj_base_t*)nlr.ret_val)->type` to `mp_obj_get_type(nlr.ret_val)`, but even in that case we'd still start doing weird things once we reach https://github.com/micropython/micropython/blob/1c849d63a86782f006b73a9d570d542cfd18538e/py/vm.c#L1481 since `nlr.ret_val` wouldn't be an exception instance.

**Edit:** Updated links to vm.c code to be permalinks.",15337142
148,2020-01-13T06:34:46Z,2020-01-14T13:00:54Z,,,Based on: https://github.com/mcauser/VCC_GND_F407ZG,15337142
149,2020-01-13T06:34:28Z,2020-01-13T06:34:28Z,,,Based on: https://github.com/mcauser/VCC_GND_F407VE,15337142
150,2020-01-13T06:33:38Z,2020-01-13T14:09:14Z,,,Based on: https://github.com/mcauser/MCUDEV_DEVEBOX_F407VET6,15337142
151,2020-01-13T06:32:38Z,2020-01-13T14:11:55Z,,,Based on: https://github.com/mcauser/BLACK_F407ZE,15337142
152,2020-01-13T06:31:55Z,2020-01-13T13:57:29Z,,,Based on: https://github.com/mcauser/BLACK_F407VE,15337142
153,2020-01-12T21:13:03Z,2020-01-13T20:38:50Z,,,"Allow ports to provide a lazy load function for undefined globals.

Required for #5482 .

Continuing my explanation from the discussion in https://github.com/micropython/micropython/pull/5482#discussion_r363204762:

The rationale behind kernel symbols available as Python globals is to make kernel APIs calls as seamless as possible for the Python code.

Now, why do it lazily? I admit I didn't even try preloading them all, because I don't think it'll behave properly. First of all, since the number of symbols may be huge (e.g over 200k, depending on the kernel) it may slow down the initialization. More importantly, I assume it will induce a runtime performance hit - I don't believe MicroPython's dict lookup was ever meant to handle 200k dictionary entries. I also don't think we should fix it to handle such numbers. That's why doing it lazy makes sense - only those you need are actually loaded (and for simple scripts, you won't ever reach those huge numbers)

Also, not to mention that symbols can be added in runtime via modules, so preloading them once without any dynamic component is not an option).

Next, sliding to the discussion https://github.com/micropython/micropython/pull/5482#discussion_r363680363 about the global scope - as I said, I value typing speed and conciseness here, that's why symbols are available as mere globals.

In the kernel port I'll add a function `kernel_ffi.symbol(s: str) -> Symbol`. I'll also allow disabling the automatic global loads (as I explained here https://github.com/micropython/micropython/pull/5482#issuecomment-570621866). The `kernel_ffi.symbol` will be available in both cases. It'll also be used for symbols which are invalid Python identifiers and can't be loaded as globals either way (LTO symbols containing `.`'s, module symbols which are referenced with `modname:symname`, ...).

@stinos do you think this explanation (or part of it) fits anywhere in the code to justify this patch?",15337142
154,2020-01-10T03:16:19Z,2020-01-15T21:25:54Z,,,"The ESP32's DAC has the capability to generate constant waveforms. This
commit extends the machine.DAC interface of the ESP32 port to expose
this feature.

TODO:
- [ ] Move detailed DAC function description to docs/library/esp32.rst and update
- [x] Move `rtc_clk_div` to esp library
- [x] tone tone type
- [ ] KW args for constructor",15337142
155,2020-01-08T14:23:38Z,2020-01-10T16:34:35Z,,,"Sample for testing

import socket, struct, time
soc = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
soc.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
soc.setblocking(False)

def my_cb(s):
  msg, adr = s.recvfrom(1024)
  print('cb recv from:',adr, 'len:', len(msg))
  s, = struct.unpack(""!L"",msg[40:44])
  t = time.localtime(s - 36524 * 86400)
  print(t)
  soc.setsockopt(socket.SOL_SOCKET, 20, my_cb)

aa = socket.getaddrinfo('fr.pool.ntp.org', 123, socket.AF_INET)[0][-1]
print(aa)

msg = bytearray(48)
msg[0] = 27
soc.sendto(msg, aa)",15337142
156,2020-01-05T14:21:39Z,2020-01-05T14:21:39Z,,,"This implements the toniebox (commercial device for kids) board. It boots this way, uart, i2c is available and the sys led is flashing.

Sets the pins for the sys led and the safe boot port + makes all pins available.",15337142
157,2020-01-01T17:06:47Z,2020-01-23T23:54:42Z,,,"I've been working on this port in the past month. It started as a fun PoC but I realized its usefulness for kernel research & debugging so I kept expanding it. It shows how powerful MicroPython is, due to the relative ease of porting it.

I'd happily continue maintaining it in a fork, but I prefer mainlining if possible. I think it'll be more accessible for others to contribute. @dpgeorge it's up to you.

TODOs list before merge, as I see it:
- [ ] complete previous PRs required for this, and perhaps split out more unrelated commits into separate PRs.
- - [x]  #5420
- - [ ]  #5412 
- - [x]  #4928
- - [x]  #5521 
- - [ ]  #5522

- [x] create a convenient way to run MicroPython's tests on this port
- [x] actually run the whole test suite using the above method
",15337142
158,2019-12-29T15:36:16Z,2020-03-04T05:12:49Z,,,"This adds a working open drain mode for GPIO16. Looks like the original plan to overcome the lack of (apparently missing) control register for open drain driver was to switch between input and output mode with low state.
In general this solution works well but control logic for `GPIO_MODE_OPEN_DRAIN` in `set_pin() `function was missing.

There's also a minor cleanup in `mp_hal_pin_open_drain()`. Setting output register value won't hurt, but is unnecessary.",15337142
159,2019-12-29T05:54:09Z,2020-03-01T07:44:11Z,,,"This PR allows the power consumption of the esp32 to be tweaked. It enables:
- using dynamic frequency scaling allowing FreeRTOS to reduce the clock frequency when the processor is idle
- using listen interval on the WiFi STA interface to reduce the amount of time the radio is powered on
- using listen interval to keep the radio on permanently to reduce network latency

The punchline is that one can halve the power consumption for more battery life or double it for lower network latency.

These features are documented, see the PR files. I have not been able to preview the docs, however, so I assume there are issues. I need to figure out how to do that...

One caveat I'm just realizing is that I haven't tested with ESP-IDF v3....",15337142
160,2019-12-28T23:56:26Z,2020-02-02T20:40:10Z,,,"Follow up on @aykevl's work on providing a block device for the
nRF device's internal flash.

Updating the pca10056 target to use the block device for
VFS/FATFS.

Enabling MICROPY_PY_ARRAY_SLICE_ASSIGN, MICROPY_PY_SYS_STDFILES
and MICROPY_PY_UBINASCII to work with rshell.

Also updated the flash.c driver and ble_drv.c to support flash
access from the flash block device when SoftDevice is active.",15337142
161,2019-12-28T20:19:32Z,2020-02-18T19:56:51Z,,,"The nordic port lacks support for a milisecond / microsecond tick
counter (and basically most of the `time` module functionality..).
 
The ms tick counter is needed by asyncio and prevents the usage
of this module, which is my primary design goal.

So I had a go and enabled the systick irq with 1msec resolution.
This enables the usage of a 32 bit counter rather than
on relying on the hw's systick timer 24bit width. But it does
add a bit of overhead. 32bit would overflow after 50 days - although
the pyhton return value might be restriceted to only 31 bits (?). 24 bits take app.
5h to overflow, which might be suitable too.

Inreasing the counter's width to 64bit would eliminate any overflow
handling on the python side, but may add some overhead on passing
this value from C to python (but I'm not sure how much). 

Another option would have been to grab a separate HW timer unit, which could
probably be used in a better, power optimized manner and possibly
without irq's since they are 32bit width.
 
However I was reluctant to do this since for some MCU's a timer unit is precious.

So in summary, it was a surpring amount of factors to consider for 
such a small change. Looking forward to some inputs/comments.

",15337142
162,2019-12-28T15:50:21Z,2020-01-05T17:04:09Z,,,"This moves all delays into the Python code of the driver
and adds separate methods to send the start pulse and
later receive the measurement with minimal blocking for
use in event loops like uasyncio.

Quickref changes for esp8266 and esp32 are included.",15337142
163,2019-12-25T05:32:37Z,2020-02-07T05:28:33Z,,,"utime.adjtime() can be used to slew the system clock by a
given adjustment value (as an optional (sec, usec) tuple).
The system clock is not abruptly changed, but gradually
adjusts the boot time. The call immediately returns, but
a correction by 1 second will actually take 64 seconds in
the background. The system clock remains monotonic during
this time but will appear faster/slower. Called without
an argument or None it will return the remaining adjustment
from a previous call. If called with an adjustment value a
previously running adjustment is cancelled without being
undone.",15337142
164,2019-12-24T13:13:52Z,2020-02-07T06:14:47Z,,,https://docs.espressif.com/projects/esp-idf/en/stable/api-reference/peripherals/sigmadelta.html,15337142
165,2019-12-22T17:57:10Z,2019-12-29T15:42:02Z,,,"Hi, I'm making badges for a danish hacker camp and this year we're planning on using this RISC-V chip from GigaDevice. It has a bit more flash compared to the HappyGecko we used to use, so I thought it'd be fun to see if I could make MicroPython run on it.

For now it passes all tests but micropython/extreme_exc.py, but I haven't yet implemented any ""drivers"" for peripherals and such. I thought I'd send an RFC in early and see if you'd be interesting in merging this upstream at some point.

Unfortunately riscv toolchains for bare-metal aren't yet available in most distributions, but cross-compilers for Linux seem to be. So I've made it so that this port can actually be compiled with such a toolchain without any standard library. MicroPython already comes with implementations of memset, memcpy, printf etc., which is cool, so it just needs a few little extra patches for this to work that I hope you're fine with.

I've ordered the commits such that the ones up to ""travis: Compile test gd32vf103"" are needed to make the port compile in travis. The rest are mostly just fixes for warnings that I get because I enabled a little more compiler warnings (-Wall -Wextra -Wno-unused-parameter).

In the future it would be nice to also add support for SiFive's HiFive1 board which is also emulated by Qemu, such that the tests can be automatically run on a RISC-V platform by travis.

/Emil",15337142
166,2019-12-21T19:27:23Z,2019-12-25T10:46:41Z,,,"This is a proposal MicroPython 2.0.

As we know, MicroPython has many, many configuration options. The current method of using a combination of `mpconfigport.h` and `mpconfigport.mk` works reasonably well, but I find myself spending quite a bit of time jumping through the source code to figure out what options actually do and how they interact with each other.

Kconfig is a configuration system for software projects based on make and C. It comes from the Linux kernel and is used in many other large projects, like U-boot, Busybox, Zephyr, etc. It works by declaring configurations using the [Kconfig language](https://www.kernel.org/doc/html/latest/kbuild/kconfig-language.html). It provides a _very_ powerful way to express dependencies between configuration options. It also provides and easy way for users to build custom configurations using an interactive menu rather than having to edit text files.

Recently, a Python implementation of Kconfig called [Kconfiglib](https://github.com/ulfalizer/Kconfiglib) has been developed. It is tested against the Linux kernel and used in the Zephyr project (among others), so it quite stable and robust already.

So far, I have added basic support for Kconfig to the STM32 port and converted a few groups of configuration options to the new format. I've been quite happy with the results.

Here are some screenshots of what it looks like (there is also a text-based menu interface for those who don't like to leave the terminal or use the mouse :wink:):

![image](https://user-images.githubusercontent.com/963645/71312588-3bc44e00-23f2-11ea-89af-136a8374aec1.png)

This is the default view. The upper pane shows the selected configuration. Detailed information on each option is visible in the lower pane.

![image](https://user-images.githubusercontent.com/963645/71312601-58608600-23f2-11ea-94f7-4e36e920b3ee.png)

The tree format makes it easy to browse the options in an organized way and hides irrelevant options.

![image](https://user-images.githubusercontent.com/963645/71312611-74642780-23f2-11ea-8c8b-80dbe8d308bb.png)

For example, we have selected the STM32 port above, so only STM32 boards are listed.

![image](https://user-images.githubusercontent.com/963645/71312668-0f5d0180-23f3-11ea-913f-9c8fdc35ec8c.png)

The dependency of options is also shown. For example options that only affect the inline Thumb emitter are only visible/selectable if the parent option is selected.

![image](https://user-images.githubusercontent.com/963645/71312680-37e4fb80-23f3-11ea-9e2a-37e137c94ce7.png)

There are also lots of hidden options that are not user-selectable because they only depend on other selections. But these can be shown for debugging.

---

In addition to the menu system, Kconfiglib is also fully automatable (because it is a Python library), so it will be much easier for anyone that wants to automatically generate custom configurations to do so.

Changing the configuration system like this will of course be quite disruptive for anyone using custom configurations already (which is why I consider it a MicroPython 2.0 thing) and will undoubtedly come with some growing pains. But this will certainly make customizing MicroPython much easier for users. And if MicroPython is going to be around for many more years, this will be a great help in keeping it maintainable.

Also, please see the individual commit messages for more nitty-gritty details.",15337142
167,2019-12-18T15:02:46Z,2020-02-05T06:53:45Z,,,"# Changes

This pull requests adds:
- send
- recv
- do_handshake

methods to ussl (mbedtls version only) plus few exceptions.

The goal is to fully support non-blocking ssl sockets and reduce the number of call to poll by throwing the exact I/O error like `SSL_WANT_READ` or `SSL_WANT_WRITE`. the user has now the possibility to call `do_handshake()` later if `ussl.wrap_socket` was set with `do_handshake = False`

# Tests

successfully tested on micropython/ports/esp-32 (esp-ifd rev 6ccb4cf5b7d1fdddb8c2492f9cbc926abaf230df) and micropython/ports/unix

# Example

```py
# this snippet SHOULD be seen as an example
# on how to use these new methods and is not
# optimized.

import usocket
import ussl
import uselect

# [...]
# create socket and ussl_wrap(sock)
# [...]

def do_handshake(sock, is_ssl):
    if not is_ssl:
        return
    poller = uselect.poll()
    poller.register(sock)
    while True:
        try:
            sock.do_handshake()
            break
        except ussl.SSLWantReadError:
            poller.modify(sock, uselect.POLLIN)
            poller.poll(5000)
            continue
        except ussl.SSLWantWriteError:
            poller.modify(sock, uselect.POLLOUT)
            poller.poll(5000)
            continue
        except ussl.SSLInProgress:
            continue

def reader(sock):
    poller = uselect.poll()
    poller.register(sock)
    while True:
        try:
            buff = sock.recv(4096)
        except ussl.SSLWantReadError:
            poller.modify(sock, uselect.POLLIN)
            poller.poll(5000)
            continue
        except ussl.SSLWantWriteError:
            poller.modify(sock, uselect.POLLOUT)
            poller.poll(5000)
            continue
        except Exception:
            raise
        if not buff:
            break
        yield buff
    return []

def sender(sock, buffer):
    poller = uselect.poll()
    poller.register(sock)
    while buffer:
        try:
            sent = sock.send(buffer)
        except ussl.SSLWantReadError:
            poller.modify(sock, uselect.POLLIN)
            poller.poll(5000)
            continue
        except ussl.SSLWantWriteError:
            poller.modify(sock, uselect.POLLOUT)
            poller.poll(5000)
            continue
        except Exception:
            raise
        buffer = buffer[sent:]
```",15337142
168,2019-12-17T07:05:35Z,2019-12-19T06:18:31Z,,,"According to ```Supplement to the Bluetooth Core Specification v8 Part A 1.3.1```, to support BR/EDR, shouldn't we set the fifth bit (```Simultaneous LE and BR/EDR to Same
Device Capable (Controller)```) and fourth bit (```Simultaneous LE and BR/EDR to Same
Device Capable (Host)```) of the flag to ```1```? Currently these bits are set as ```0``` when ```br_edr``` is ```True```, this PR tried to fix this.",15337142
169,2019-12-11T22:13:57Z,2020-01-13T21:54:48Z,,,Use it to remain with the default MPZ_DIG_SIZE = 32 on 64-bit builds.,15337142
170,2019-12-08T04:26:30Z,2019-12-09T15:35:53Z,,,"Add LPUART1 as a standard UART. No low power features are supported.
LPUART1 is enabled as the next available UART after the standard U(S)ARTs.
STM32WB: LPUART1 = UART(2)
STM32L0: LPUART1 = UART(6)
STM32L4: LPUART1 = UART(6)
STM32H7: LPUART1 = UART(9)

LPUART1 is enabled by defining MICROPY_HW_LPUART1_TX and MICROPY_HW_LPUART1_RX in mpconfigboard.h",15337142
171,2019-12-04T07:00:21Z,2020-01-08T07:11:09Z,,,"Adding FROZEN_MANIFEST to the Makefile which is set to
boards/manifest.py by default.

Adding the boards/manifest.py that will include the ports
'freeze' folder.

Adding BOARD_DIR to the Makefile which can be referenced in
boards/<board>/mpconfigboard.mk to include a board specific
manifest.",15337142
172,2019-12-04T01:23:15Z,2019-12-08T20:17:18Z,,,"The ""import module"" vs ""import umodule"" is something of a FAQ, and it comes up on the forum and when I'm teaching MicroPython in-person.

In summary -- my experience has been that most people don't care about the subtle distinction between ""uos"" and ""os"". I understand and agree with the argument that the ""u"" is a reminder that it's the ""micro"" version, but I don't think it outweighs the confusion. It's one of the first things that you see in the documentation, but I don't think it's one of the first things you need to know as a beginner MicroPython programmer. Your existing Python code should just work, and the MicroPython documentation should match the idiomatic way to write code.

I think since #5241 was merged, we're in quite a good situation:
 - People can consistently use ""import foo"" across all ports. (with the exception of the minimal ports)
 - The ability to override/extend via ""foo.py"" continues to work well.

This PR updates the documentation such that:
 - All ufoo.rst is now foo.rst
 - Updates all internal references in the docs to exclusively use ""foo"" not ""ufoo"".
 - Updates library/index.rst to simplify the explanation of module naming and move the ""ufoo"" part to an extra detail at the end for people who care.

Note: the replacements were done with a quick script, so they aren't perfect and will need some manual fixups (e.g. I can see that the very first diff is ""requests"" which should probably be still ""urequests""...). But before I do the manual cleanup, I'd like to get some feedback on whether people think this is a worthwhile change.

Refs:
 - Recent forum thread: https://forum.micropython.org/viewtopic.php?f=2&t=7102
 - #5241 which made the ufoo->foo aliasing consistent on all ports.",15337142
173,2019-11-25T14:31:16Z,2019-12-01T21:41:04Z,,,Temperature reading on the nRF devices requires you to start the conversion and wait for its completion,15337142
174,2019-11-20T04:27:24Z,2020-02-05T06:55:07Z,,,"Fixes https://github.com/micropython/micropython/issues/5345

Always call `mp_hal_delay_ms` with >= 0 ms argument. This makes `sleep_ms(0)` useful when combined with https://github.com/micropython/micropython/pull/5346 for ESP32 and https://github.com/micropython/micropython/pull/5347 for STM32 allowing yielding a thread by looping like such:

```
while not condition_met:
  sleep_ms(0)
```

This properly frees the GIL so that other threads, tasks or scheduled events can satisfy the `condition_met`",15337142
175,2019-11-20T04:26:06Z,2019-11-21T00:45:09Z,,,"Related to https://github.com/micropython/micropython/pull/5346 and is the STM32 equivilent.

Call MICROPY_EVENT_POLL_HOOK even on very short delays so that busy loops that call `sleep_ms` still yield to events and other threads.",15337142
176,2019-11-20T04:24:59Z,2020-02-05T06:54:07Z,,,"Fixes https://github.com/micropython/micropython/issues/5344 

Ensure that `MICROPY_EVENT_POLL_HOOK` is always called when calling `utime.sleep_ms` so that scheduled events and thread switching occurs correctly.

`sleep_us` is not modified as it is expected to be fast and accurate.",15337142
177,2019-11-12T00:43:13Z,2020-03-25T00:35:48Z,,,"The behavior mirrors instance object __dict__ attribute where a copy of the local attributes are provided.

The function is only enabled if `MICROPY_CPYTHON_COMPAT` is set, the same as the instance version of this function.

This can be useful to get access to the attributes on a class, eg. for https://github.com/micropython/micropython/issues/5322",15337142
178,2019-11-12T00:43:09Z,2020-03-25T01:23:30Z,,,"No change to normal builds, but if `MICROPY_PY_MAP_ORDERED` is set in port/board config then the ordered flag is set for all new maps (`dicts`)

While I presume this has a performance impact it is useful behavior for some applications eg. https://github.com/micropython/micropython/issues/5322",15337142
179,2019-11-11T05:12:39Z,2020-03-05T07:07:24Z,,,"Following on from #5294, this PR adds a general neopixel bit-bang driver.  A port needs to implement the `mp_hal_delay_ns_calc_neopixel(ns, is_low_cycle)` function to use this driver.

Also included is a high-level `neopixel.py` wrapper, which can replace the one currently in esp8266/esp32's modules directory.",15337142
180,2019-11-08T13:26:46Z,2020-02-22T09:13:43Z,,,"This PR adds CAN Device added for ESP32.
see issue #5087 
",15337142
181,2019-11-08T06:06:19Z,2020-03-05T06:48:44Z,,,"This PR adds optional support for signed and encrypted dfu images in stm32 mboot.

This requires additional settings in the board config and requires `pyhy` python module to be installed into `python3` used when building mboot, eg:
```
    pip3 install pyhy
```
In addition to the standard changes made to mpconfigboard.mk to enable mboot, for encrypted support you also need to add:
```
    MBOOT_ENCRYPTED = 1
```
Also, alongside the existing `TEXT0_ADDR` setting the length of application 
flash space is needed, so for an F767 with 2MB of flash where the application 
starts after the 32K of mboot space, it will equal `2048K - 32K == 0x1F8000`:
```
    TEXT0_ADDR = 0x08008000
    TEXT0_LENGTH = 0x1F8000
```
You will also need to generate a compatible pair of public and private key files, which should be stored in the board definition folder (next to mpconfigboard.mk):
```
    python3 micropython/tools/mboot_generate_keys.py micropython/ports/stm32/boards/PYBD_SF6
    cd micropython/ports/stm32
    make BOARD=PYBD_SF6
```
Once you build the firmware, the `firmware.dfu` file will contain the encrypted and signed binaries.

There will also be an extra `firmware.ftr.bin` and `firmware.ftr.dfu` pair of files which contain an
un-encrypted copy of the footer with the encryption key, either of which can be flashed along with mboot to a fresh device to prepare it for decrypting the full `firmware.dfu`.

---

### Implementation details

The PR utilisies the encryption library [libhydrogen](https://github.com/jedisct1/libhydrogen) which provides both the asymetric signing and symetric encryption used in this PR in a high level fashion suitable for non-cryptography specialists to use safely. It's small enough to fit in the existing mboot flash space and uses modern secure ciphers.

This system works without needing any support from the application and without flash space for a second copy of the firmware. 

The encryption script included (`tools/mboot_signed_dfu.py`) breaks the firmware into chunks (16K by default) each of which is individually zipped, signed and encrypted. 
Each chunk is included in the dfu fiile and sent to the device using standard dfu tools, where it's first stored in ram, before its signature is checked for validation.
If that passes, the chunk is then decrypted. The decryption also included a hash behind the scenes to ensure it's valid.
If that passes, the chunk is un-zipped.
If that passes, the sector of flash is erased (if it hasn't already been erased by a prior chunk), then the chunk is written to flash.

Once all firmware chunks are transmitted a hash check is triggered. This confirms the sha256 of the entire firmware image as stored in flash. If that passes the validity bits at the start of the application flash are set. These are read my mboot at startup before jumping to the application.

When encryption is enabled, read support is disabled in mboot. 
The erase command in dfu is also ignored as the flash sectors are tracked and erased as needed only after a transmitted chunk has been validated. This does mean that chunks need to be sent in order, however standard dfu tools all seem to do this by default.

As mentioned in the previous section, there is also a footer included with the firmware. 
This footer contains the asymmetric public key, used to validate the signature and also used as the symmetric key for decryption.
The footer also contains a version number string (not explicitly used currently) and details about each fw image included (normally two sections for builds with internal flash storage, one otherwise) including its address, length and sha256 hash. 

Another potential future extension is to use the version number in the footer to prevent downgrades if desitred. This feature has been been investigated yet however.

---

### firmware footer location

It's currently stored in the final 96 bytes (0x60 hex) of flash on the chip. 
I initially planned to store it either in the final space of the mboot sector, or the start of the application flash space, but have ended up with this implementation. This is very much open to discussion however.

Storing it in mboot space meant it could not be updated with the application, thereby invalidating any of the other details such as version/length/crc etc. It would only be of use for the encrpytion key, but again, make that difficult to update in future if needed.

Storing the details at the start of application space required moving the start of the application forward by 512 bytes (0x200) as this appears to be a requirement for the interrupt ventor table system in the stm range, it needs to be aligned to blocks of this size in most if not all chips. This means you lose 416 bytes of flash, not insignificant on some parts.

I have also thought about storing these details inside the application space, just after the interrupt vector. This would mean I'd need to consider the vector table as one separate section of firmware, then slice in the header/footer data, then continue with the rest of the firmware. This may well be the best option and I'm still considering implementing it, but wanted to get the current working code up for review/discussion first.

---

Based on discussions in https://github.com/micropython/micropython/issues/5267",15337142
182,2019-11-07T04:15:15Z,2019-11-07T04:37:52Z,,,"ports: Add port pic32m to the PIC32M series microcontroller from Microchip.

This is an experimental port of MicroPython to the PIC32M series microcontroller from Microchip.
The experiment is done with PIC32MX170F256B in 28-pin DIP package for easy hand soldering.
Supported features include:
REPL (Python prompt) over UART1.
The pyb module with 1 Led and 1 Switch.",15337142
183,2019-11-05T06:29:20Z,2019-11-11T05:35:15Z,,,"This PR adds a ""general"" `machine.pixelbitstream(pin, timing, buf)` function which can be used to drive neopixels/ws2812/etc LEDs, using a software bit-banging approach.  Arguments are:
- pin -- the pin to output on (can be any pin)
- timing -- tuple of 4 values for T0H, T0L, T1H, T1L in nanoseconds
- buf -- buffer of bytes to output on the pin

The bytes are output according to the ""ws2812 scheme"", where each bit is encoded by a high pulse then a low pulse of a certain duration, specified by the timing tuple.

This should be general enough to support all variants of these kinds of LEDs, and tune the timing values in Python for any particular application.

Note that this uses a software implementation and IRQs are disabled during the output of the bits.  So long streams of bits will pause IRQs for a long time.  But it's still useful for the cases where hardware (eg SPI) can't be used.

This function should be able to be used without much effort on all ports, but it's only tested and tuned so far on stm32 (PYBv1.0, also tested on an F0 to show that it can work at low CPU freq).

See also #5117 ",15337142
184,2019-11-04T19:24:14Z,2019-11-11T11:32:54Z,,,"pend_throw() to unstarted generators prevents catching the injected
exception by the generator's code breaking existing code that relies on
being able to catch all exceptions. See https://github.com/micropython/micropython/issues/5242#issuecomment-549485156",15337142
185,2019-10-22T06:46:51Z,2019-11-06T00:29:25Z,,,"This PR aims to simplify the definition and use of filesystems in general, but most specifically making it easier to create filesystems on spi and qspi flash chips.

The interfaces to these filesystems has been extended both for access from micropython at runtime, and in C for board definitions.

For example:
``` python
>>> import machine, uos
>>> vfs = uos.VfsFat(machine.SPIFlash(machine.QSPI(), length=16*1024*1024))
>>> uos.mount(vfs, ""/mine"")
>>> uos.listdir(""/mine"")
['device_test', 'assays', 'results', 'System Volume Information']
```
The machine.SPIFlash() constructor also takes a `start` argument which lets you offset the start of a filesystem, making it easy to have multiple separate filesystems present on a single flash chip.

Example stm32 board definition
`bdev.c`
``` c
#include ""drivers/bus/qspi.h""
#include ""drivers/memory/spiflash.h""

extern const mp_qspi_proto_t qspi_proto;

// External SPI flash uses standard QSPI interface
STATIC mp_spiflash_cache_t spi_bdev_cache;

mp_spiflash_t spiflash_instance = {
    .qspi_proto = &qspi_proto,
    .cache = &spi_bdev_cache,
};
```
`mpconfigboard.h`
``` c
#define MICROPY_VFS_ROOT_FS_MOUNT MP_QSTR__slash_flash
#define MICROPY_VFS_ROOT_FS_FORMAT &mp_fat_vfs_type
#define MICROPY_VFS_ROOT_FS_BDEV mp_machine_spiflash_make_bdev( \
    /* spi */ &spiflash_instance,  \
    /* start_block */ 0,  \
    /* block_count */ (16*1024*1024)/MP_SPIFLASH_DEFAULT_BLOCK_SIZE,  \
    /* block_size */ MP_SPIFLASH_DEFAULT_BLOCK_SIZE \
)
```

In conjunction with https://github.com/micropython/micropython/pull/5228 changing the format of the boot or any runtime filesystem to LittleFS should be as simple as 

`mpconfigboard.h`
``` c
// #define MICROPY_VFS_ROOT_FS_FORMAT &mp_fat_vfs_type
#define MICROPY_VFS_ROOT_FS_FORMAT &mp_type_vfs_littlefs2
```
or
``` python
>>> vfs = uos.VfsLittleFS1(machine.SPIFlash(machine.QSPI(), length=16*1024*1024))
```

TODO: 
* Test / cleanup stm32 main with regard to internal flash usage
* Update other stm32 boards which have spiflash chips defined
* Finish updating ports other than stm32
* update documentation
",15337142
186,2019-10-09T04:01:31Z,2020-01-30T01:55:58Z,,,"PR Note: Not sure how controversial it is to remove the block printing by default. Open to suggestions here, but for 196 bytes I'm not sure how many people care. Would appreciate feedback on my assumption that people (who aren't debugging the GC) are mostly interested in fragmentation only.

Also open to suggestions on a better summary of the fragmentation. In my mind this captures the main issue with fragmentation -- there are enough total bytes available but allocations above a certain size are no longer possible. I can imagine some sort of equivalent to perf_bench where we can compare these stats for given test cases over time. I'd like to distil it down to a single number but not sure that's useful (and could be done in post-processing anyway).

Obviously the fragmentation stats only make sense immediately after calling `gc.collect()` but I don't think this method should initiate a collection by default.

Although no targets now use the block-table-only option, I have confirmed that it makes zero difference to the build size compared to before this change.

--- 

The previous behavior was (for ports that enable it via
`MICROPY_PY_MICROPYTHON_MEM_INFO`), that passing any argument to
`micropython.mem_info()` would print out the block table.

This adds an additional line to the end that shows basic fragmentation
statistics, i.e. how many allocations of a given size can succeed.

This also changes the default behavior to no longer print the block
table, and only prints the fragmentation stats (with the assumption
that fragmentation is the main reason to investigate the block table).
This saves ~196 bytes on PYBV11.

On the Unix port, show both (useful for debugging GC).

On small STM32 ports (L0, F0), don't show either. (Saves ~350 bytes)",15337142
187,2019-10-06T06:02:32Z,2019-10-09T05:18:34Z,,,"The changes only work for `esp32` port `GENERIC_SPIRAM` board
- We'd better enable `CONFIG_SPIRAM_ALLOW_BSS_SEG_EXTERNAL_MEMORY` by default, otherwise the others don't know how to enable it unless he is very skilled in `esp-idf`
- Link `esp32.extram.bss.ld` if enable `CONFIG_SPIRAM_ALLOW_BSS_SEG_EXTERNAL_MEMORY`
- The `EXT_RAM_ATTR` attribute can be used if you want to place the variable into psram.",15337142
188,2019-10-04T13:28:36Z,2019-10-08T05:19:14Z,,,"- If enable `MICROPY_DEBUG_VERBOSE`, `mp_thread_mutex_lock(&MP_STATE_VM(gil_mutex), 1)` and `mp_thread_mutex_unlock(&MP_STATE_VM(gil_mutex))` were called before `mp_thread_mutex_init(&MP_STATE_VM(gil_mutex))`.",15337142
189,2019-10-01T13:10:17Z,2019-10-10T05:55:47Z,,,,15337142
190,2019-10-01T07:24:09Z,2020-03-04T12:13:05Z,,,"I started looking into this idea independently, but was told the same thing had already been implemented in CircuitPython by @tannewt (see https://github.com/adafruit/circuitpython/issues/531 ) so this is inspired by that work (especially the very clever mechanism used there for doing the compile-time substitution).

The idea here is that there's a moderate amount of ROM used up by exception text. Obviously we try to keep the messages short, and you can enable terse errors, but it still adds up. See #5130 for some recent discussion about error text size. Listed below is the total string data size for various ports:

```
bare-arm 2860
minimal 2876
stm32 8926  (pybv11)
cc3200 3751
esp32 5721
```

This PR implements compression of these strings. It takes advantage of the fact that these strings are all 7-bit ascii and extracts the top 128 frequently used words from the messages and stores them packed (dropping their null-terminator), then uses `0x80 | index` inside strings to refer to these common words. Spaces are automatically added around words, saving more bytes.

Here's some example data (in genhdr/compressed.data.h)

```
MP_COMPRESSED_DATA(""doesn'\364can'\364objec\364mus\364argumen\364'%q\247.......""
MP_MATCH_COMPRESSED(""%%c needs int or char"", ""%%c\272\316\273char"")
MP_MATCH_COMPRESSED(""%q index out of range"", ""\306\234\303\220\257"")
MP_MATCH_COMPRESSED(""'%s' expects an FPU register"", ""\210\221\244FPU\307"")
MP_MATCH_COMPRESSED(""'%s' expects an address of the form [a, b]"", ""\210\221\244address\220the form [a, b]"")
```

This happens transparently in the build process (mirroring the steps that are used to generate the QSTR data). The `MP_ROM_COMPRESS` macro wraps any literal string that should compressed, and it's automatically decompressed in `mp_obj_new_exception_msg_varg`.

I looked in detail at the entropy coding scheme used in CircuitPython, and have implemented the compression side of that approach here too for comparison (using the same Huffman compression library). My results showed that the word compression gets better results. This is before counting the increased cost of the Huffman decoder. This might be slightly counter-intuitive, but this data is extremely repetitive at a word-level, and the byte-level entropy coder can't quite exploit that as efficiently. Ideally you'd combine both approaches.

For additional comparison I calculated the size of the raw data compressed with gzip and zlib (as a sort of proxy for a lower entropy bound). With this scheme we come within 15% on stm32, and 30% on bare-arm (i.e. we use x% more bytes than the data compressed with gzip -- not counting the code overhead of a decoder, and how this would be hypothetically implemented!). In other words, this scheme isn't bad!

There's one major thing I'd like to fix which is that it now requires the use of `mp_obj_new_exception_msg_varg` for all exceptions, whereas previously ones that didn't require formatting went through a non-allocating path in `mp_obj_new_exception_msg`. It would be neat to come up with a way to defer the decompression for these messages until they're actually printed or accessed.

Unlike CircuitPython's implementation this isn't additionally used to implement translation. That could potentially be added later though.

Here's a summary of the size decrease for selected ports:

```
   bare-arm:  -920 -1.388% 
minimal x86:  -816 -0.549% 
   unix x64: -2528 -0.508% 
unix nanbox: -2300 -0.518% 
      stm32: -3820 -1.051% 
     cc3200: -1320 -0.714% 
      esp32: -2292 -0.199% [incl -2440(data)]
```
",15337142
191,2019-09-29T21:48:04Z,2019-10-01T15:56:09Z,,,"The added `upside_down` static method causes the contents to be rendered with a 180° rotation.
If a display is to be run upside down, this method must be called prior to instantiating a `Writer` for this display.
This particular OLED command sequence was originally discussed [here](https://digistump.com/board/index.php?topic=1669.0).

A similar static method [only works for the `Cwriter` class](https://github.com/peterhinch/micropython-font-to-py/blob/master/writer/WRITER.md#221-static-method).",15337142
192,2019-09-28T21:46:54Z,2019-12-06T04:44:57Z,,,This PR is a WIP to support the built-in bootloader on the nrf Xenon board (currently the entire flash is overwritten with MicroPython firmware using an external programmer; using this PR allows to use the built-in USB DFU to download firmware).,15337142
193,2019-09-28T03:15:54Z,2020-03-17T02:03:14Z,,,Discard all data in the UART RX buffer.  Implemented with UART driver API call in ESP-IDF,15337142
194,2019-09-25T04:52:21Z,2019-10-17T01:48:22Z,,,"Integrate micropython and NXP's MCUs. Currently, enable i2c class spi class usart class based on cmsis driver. Provide led class and gpio class. Enable SDcard fatfs. For RTXXX enabled lcd feature.",15337142
195,2019-09-23T15:17:13Z,2019-10-04T11:35:26Z,,,"Modify the JSON loading code so it can parse the JavaScript floating
point representations NaN/Infinity/-Infinity, and support the allow_nan
keyword argument for dump() and dumps() which controls whether those
representations get created or else lead to raising a ValueError.
All of this is the same as CPython's implementation and when enabled
fixes the inconsistency in the current code which unconditionally
creates lowercase nan/inf strings but doesn't parse them.

This is a fix for #3511. It requires more changes than I initially anticipated, but I don't see another way than to pass the needed information into `float_print` via the `mp_print_kind` argument.
Also needs quite some extra code, enabled by default for a couple of ports but that was mainly to get CI feedback.
Flag is called MICROPY_PY_UJSON_ALLOWNAN but it's essentially about CPython compatibility so another name might be more suitable.",15337142
196,2019-09-22T02:51:26Z,2019-10-04T06:57:43Z,,,"http://flake8.pycqa.org

Error codes: http://flake8.pycqa.org/en/latest/user/error-codes.html",15337142
197,2019-09-19T20:04:45Z,2020-01-02T12:48:15Z,,,"This is here just in case you consider using Azure pipelines.

**Pros**:

- it is quite faster (10 vs ~5 Travis parallel jobs at a time);
- much less restrictive (I added automatic publishing of builds to github releases for example);

**Cons**:

- some setup is needed *outside* `yml`;
- for non-standard workflows, such as ESP*, using Travis and Pipelines will require a double effort to introduce build scenario changes;

**Set up**:

1. Create a separate github oAuth token in Pipelines;
2. Create a tag on github where latest builds go;
3. Change variables in `azure-pipelines.yml` accordingly

For me, the result looks like [this](https://github.com/pulkin/micropython/releases/tag/latest-build).

**Note**: coverage report was commented out here.",15337142
198,2019-09-18T12:38:26Z,2019-09-26T06:01:28Z,,,This aims to provide some further testing for issues with mpy generation discussed in #5059,15337142
199,2019-09-18T04:59:06Z,2020-03-02T07:16:33Z,,,"My neopixels were glitchy, and it turned out to be a timing issue, the previous code didn't account for register overflow, and didn't respect the 4 different state values. I've improved the C code for the neopixels to support the WS2811, as well as the more modern WS2812B and WS2812S modules timing. I've also opened up the tight timing function for raw calls from python, which frees up RAM held by the IRAM_ATTR flag, by allowing the non-critical code to be paged out.

I've also fixed the relevant bits of the docs where neopixels are mentioned, and a few bits which tripped me up on the initial install.",15337142
200,2019-09-17T00:26:12Z,2020-01-30T11:34:20Z,,,"One of the system include paths in emscripten changed in 1.38.42 which breaks the clang precompiling stage of the javascript port make process.

This change simply adds the extra include path as needed, leaving the previous ones in place so as to not break build with existing installations.

For further discussion see https://github.com/trzecieu/emscripten-docker/issues/51",15337142
201,2019-09-12T20:35:16Z,2019-10-16T12:31:53Z,,,"This patch adds a new submodule nrfxlib which contains a static
library for NFC on nRF52 devices. Currently, only Tag2 library has
been targeted.

The patch also introduce a basic NFC machine module which expose API for
starting and stopping the NFC library/peripheral and an API to
to set raw payload.

Example:

from machine import NFC
n = NFC()
payload = bytearray([0x03, 0x0F, 0xD1, 0x01, 0x0B, 0x55, 0x02]
payload += [ord(i) for i in ""google.com""])
n.payload_raw_set(payload)
n.start()
...
n.stop()",15337142
202,2019-09-04T15:13:41Z,2019-11-27T05:13:06Z,,,"Hi,

I wanted to implement fully CPython compatible `sys.excepthook` but what I ended up with is this redux.

Differences:
* In MicroPython it's not possible to create selectively assignable module attributes. Or I didn't figure-out how to do it. Meaning:
```Python
# in CPython you do this
sys.excepthook = handler

# in uPy you have to do this
sys.setexcepthook(handler)
```

* The handler is expecting 3 arguments (type, value, traceback). But for simplicity the _traceback_ is __None__ for now. Traceback argument is also omitted in already implemented `sys.exc_info` so I guess it's OK.

* For simplicity the error messages for assigning the incompatible handler object are simplified compared to CPython.

Also I can't decide on proper naming (again). The feature is wrapped in `MICROPY_PY_SYS_EXCEPTHOOK` ifdef but the API is `sys.setexcepthook`. So, let me know what do you prefer to make as less confusion as possible.

If somebody knows how to make ONLY `sys.excepthook` assignable in uPy sys module that would be the best.

Cheers!",15337142
203,2019-08-31T17:40:52Z,2019-09-02T06:23:50Z,,,"This aims to fix how frozen modules are handled/identified/distinguished.

It prefixes all frozen files with a ""virtual directory"", which is then added to sys.path (as opposed to before, where frozen files were found via the `''` current directory). This is essentially option #2 suggested in issue #2322.

The virtual directory is called `{frozen}`, a name chosen to be highly unlikely to ever be a real directory name. (The `:frozen:` name suggested in issue #2322 was not suitable, because the colon (:) character is used as the path separator in the string representation of sys.path)

While the initial fix for the unix port was quite easy (prefix all frozen filenames with `{frozen}/` and add `{frozen}` as the last entry in the default sys.path), it ended up being a bit of a rabbit hole, requiring more changes/fixes in the test suite and other ports, even revealing a potential bug which I will report/fix separately.

One issue I am not 100% happy about: some platforms use `pyexec_frozen_module` to run frozen py files on boot up. This function does not search paths defined in sys.path, and arguably shouldn't need to, since it uses the arrays with frozen files/strings and essentially ""knows"" where to find frozen files/modules. But due to the prefix of filenames in the array, it currently needs to be passed the prefix too. Changing this, so the function (and those it calls) internally skip over the prefix while matching file names is another rabbit hole, which I haven't yet gone into. So for now, `pyexec_frozen_module` must be given filenames with the prefix. I am happy for thoughts around this - maybe there is a nicer way to solve this.",15337142
204,2019-08-30T09:10:15Z,2019-09-10T01:17:59Z,,,"1.suport [E73](http://www.ebyte.com/product-view-news.aspx?id=239) series
2.ports/nrf bug fix

",15337142
205,2019-08-22T08:02:38Z,2019-08-23T18:54:18Z,,,"This PR moves the `re1.5`, `uzlib` and `crypto-algorithms` from `extmod/` to `lib/`.

The eventual goal I have in mind is to move to a situation where all 3rd-party code lives in the `lib/` or `drivers/` directories, and all other directories in this repo contain code original to this project.  It's also possible to have original code in `lib/` and `drivers/`.  But `py/` and `extmod/`, and to a large extent `ports/*/` should contain only original code.  (Also `tools/` has some 3rd-party code.)

That gives a clear distinction of what code goes where, and helps to separate licenses/copyright.

With this PR applied, everything in `extmod/` will now be original source (and `py/` is already that way).

Please comment/discuss if you think there's a better solution to this, if it's not worth the noise, etc.",15337142
206,2019-08-20T12:46:26Z,2019-12-24T05:26:14Z,,," -Add nxp MIMXRT1064 port.
 -Enable sdcard lcd lpi2c pinmux led",15337142
207,2019-08-20T03:30:33Z,2019-08-30T07:28:35Z,,,"This is a proof-of-concept to show how it's possible to reimplement parts of the MicroPython core in Python bytecode.  So far in this PR the builtin `sum(iterable, start=0)` function is changed to a pure Python implementation and ""hand frozen"" in to the firmware.

The main reason to do this is to reduce code size while retaining the same functionality.  The code size change with this PR is:
```
   bare-arm:   -16 -0.024% 
minimal x86:   +32 +0.021% 
   unix x64:   -96 -0.019% [incl +32(data)]
unix nanbox:  -172 -0.039% 
      stm32:    -8 -0.002% PYBV10
     cc3200:   -16 -0.009% 
    esp8266:    -4 -0.001% 
      esp32:   -24 -0.002% GENERIC [incl +32(data)]
        nrf:    -4 -0.003% pca10040
       samd:   -12 -0.012% ADAFRUIT_ITSYBITSY_M4_EXPRESS
```

That's only a small decrease but this principle would scale to reimplementing a lot of built in functionality (eg string methods) to get a decent reduction in code size.

Some points to note:
- eventually there'd be some preprocessing so the functions can be written in Python rather than bytecode by hand
- in general I'd expect a bytecode implementation to be smaller than the corresponding C implementation, although it might not always be the case
- in this PR there's some extra code added to the VM to handle traceback (or lack thereof) in builtin bytecode, a cost that only needs to be paid once
- passing in keyword args to `sum()` will crash the VM and needs a small check added to fix this (would add a bit of code but only once)
- the bytecode for `sum()` was generated with mpy-cross and can actually be optimised down by one byte
- the prelude for the bytecode is relatively large, 10 bytes compared with 15 bytes for the actual function; it would be possible to optimise the prelude for size which would reduce the size for all bytecode functions, builtin and user defined
- note that the bytecode for `sum()` includes a default argument
- of course performance would be reduced, so ultimately there could be an option for ""functions in C for speed"" vs ""functions in Python for size""",15337142
208,2019-08-11T12:30:51Z,2019-09-10T05:31:50Z,,,"This is a rework of loboris' wear leveling patch
https://github.com/micropython/micropython-esp32/pull/126

Signed-off-by: Michael Niewöhner <foss@mniewoehner.de>


Tested and running productive on my device",15337142
209,2019-08-11T05:07:14Z,2020-01-16T19:20:38Z,,,"> This is a near-identical PR to https://github.com/adafruit/circuitpython/pull/2054, which is where I originally implemented this functionality. Since none of it (except the localization stuff) was CircuitPython-specific, I'm opening this up so upstream can benefit as well. The actual diff between the two PRs is entirely translation-related.
>
> This refs https://github.com/micropython/micropython/issues/2415

This implements (most of) the PEP-498 spec for f-strings, with two
exceptions:

- raw f-strings (`fr` or `rf` prefixes) raise `NotImplementedError`
- one special corner case does not function as specified in the PEP
(more on that in a moment)

This is implemented in the core as a syntax translation, brute-forcing
all f-strings to run through `String.format`. For example, the statement
`x='world'; print(f'hello {x}')` gets translated *at a syntax level*
(injected into the lexer) to `x='world'; print('hello {}'.format(x))`.
While this may lead to weird column results in tracebacks, it seemed
like the fastest, most efficient, and *likely* most RAM-friendly option,
despite being implemented under the hood with a completely separate
`vstr_t`.

Since [string concatenation of adjacent literals is implemented in the
lexer](https://github.com/micropython/micropython/commit/534b7c368dc2af7720f3aaed0c936ef46d773957),
two side effects emerge:

- All strings with at least one f-string portion are concatenated into a
single literal which *must* be run through `String.format()` wholesale,
and:
- Concatenation of a raw string with interpolation characters with an
f-string will cause `IndexError`/`KeyError`, which is both different
from CPython *and* different from the corner case mentioned in the PEP
(which gave an example of the following:)

```python
x = 10
y = 'hi'
assert ('a' 'b' f'{x}' '{c}' f'str<{y:^4}>' 'd' 'e') == 'ab10{c}str< hi >de'
```

The above-linked commit detailed a pretty solid case for leaving string
concatenation in the lexer rather than putting it in the parser, and
undoing that decision would likely be disproportionately costly on
resources for the sake of a probably-low-impact corner case. An
alternative to become complaint with this corner case of the PEP would
be to revert to string concatenation in the parser *only when an
f-string is part of concatenation*, though I've done no investigation on
the difficulty or costs of doing this.

A decent set of tests is included. I've manually tested this on the
`unix` port on Linux and
things seem sane.",15337142
210,2019-08-10T10:14:03Z,2019-08-17T09:43:11Z,,,"- Add .exe extension to the STRIP input
- Add quotes around libgcc path",15337142
211,2019-08-10T07:46:00Z,2019-08-13T21:41:18Z,,,"also allow *simple* use of various standalone clang sdk precompiled toolchains as cross compilers by abusing the triplet with a path and setting a sysroot
eg with wasi-sdk : 
```make CLANG=1 CROSS_COMPILE=/opt/sdk/wasi-sdk/bin/ SYSROOT=""--sysroot /opt/sdk/wasi-sdk/share/wasi-sysroot""```",15337142
212,2019-08-07T08:20:03Z,2019-08-17T06:44:51Z,,,"An alternative to PR #4977 - just handle whitespace in the ustruct format specifiers.

My calculation is that this change grows the unix port by 124 bytes.",15337142
213,2019-08-05T11:18:17Z,2019-08-15T06:59:30Z,,,"Update struct docs, fix environment variable handling in doc Makefile.

",15337142
214,2019-08-02T13:09:33Z,2019-08-09T12:05:07Z,,,"This provides a simple and lightweight mechanism for getting class instance attributes that are defined in C.

The idea is to simplify the process of making `self->something` a readable attribute. By adding it to the `locals_dict` instead of writing custom attribute handlers. 

Below is a minimal example C-defined class that uses this feature. Everything in the example is standard practice. The only new thing at this higher level is the `something` entry in the `locals_dict` table. 

This is a simplified example to illustrate how it works; the main practical use case arises when `mp_obj_t something` is an instance of another class that is also written in C.

```c

// modulename.ClassName object structure
typedef struct _modulename_ClassName_obj_t {
    mp_obj_base_t base;
    mp_obj_t something;
} modulename_ClassName_obj_t;

// modulename.ClassName.__init__
STATIC mp_obj_t modulename_ClassName_make_new(const mp_obj_type_t *type, size_t n_args, size_t n_kw, const mp_obj_t *args ) {
    modulename_ClassName_obj_t *self = m_new_obj(modulename_ClassName_obj_t);
    self->base.type = (mp_obj_type_t*) type;

    // At this point, or in any other method, suppose that self->something
    // is initialized as an instance of a class that was written in c.
    // For the sake of this minimal example, we just make it an int.
    self->something = MP_OBJ_NEW_SMALL_INT(123);

    return MP_OBJ_FROM_PTR(self);
}

// modulename.ClassName.method
STATIC mp_obj_t modulename_ClassName_method(mp_obj_t self_in) {
    // This is just a method
    return mp_const_none;
}
STATIC MP_DEFINE_CONST_FUN_OBJ_1(modulename_ClassName_method_obj, modulename_ClassName_method);

// dir(modulename.ClassName)
STATIC const mp_rom_map_elem_t modulename_ClassName_locals_dict_table[] = {
    { MP_ROM_QSTR(MP_QSTR_method), MP_ROM_PTR(&modulename_ClassName_method_obj) },
    //
    // Everything in this example is standard. The following line is the only new thing.
    // It makes self->something accessible to the user using self.something
    //
    { MP_ROM_QSTR(MP_QSTR_something), MP_ROM_ATTRIBUTE_OFFSET(modulename_ClassName_obj_t, something) },
};
STATIC MP_DEFINE_CONST_DICT(modulename_ClassName_locals_dict, modulename_ClassName_locals_dict_table);

// type(modulename.ClassName)
STATIC const mp_obj_type_t modulename_ClassName_type = {
    { &mp_type_type },
    .name = MP_QSTR_ClassName,
    .make_new = modulename_ClassName_make_new,
    .locals_dict = (mp_obj_dict_t*)&modulename_ClassName_locals_dict,
};


```

The offset type in the `locals_dict` keeps the offset to the requested field that corresponds to that attribute. In turn, this is used by `mp_convert_member_lookup` to get the instance attribute as follows:

```c
    else if (MP_OBJ_IS_TYPE(member, &mp_type_offset)) {
        // return the instance attribute self->member as self.member
        if (self != MP_OBJ_NULL) {
            mp_int_t offset = ((offset_obj_t*)MP_OBJ_TO_PTR(member))->offset;
            dest[0] = *(mp_obj_t *) ((char *) self + offset);
        }
```

When called as a class attribute or when called if `self->something` is not (yet) defined, this returns that the attribute is not found, as expected.

It seems that `mp_obj_class_lookup` does something related, but I wasn't sure if that was suited for this problem. It is also entirely possible such a mechanism already exists and that I just failed to find it. In that case, please feel free to ignore this PR (although a hint to the right approach would be highly appreciated, thanks!)",15337142
215,2019-07-28T22:56:27Z,2019-09-22T11:24:30Z,,,"Dear MicroPython developers and community,

## Introduction
Coming from #4955 and building upon #3040 and #3057, we enabled `tools/mpy_cross_all.py` to invoke the `mpy-cross` program through the fine [`mpy-cross` distribution package](https://pypi.org/project/mpy-cross/).

## Setup
The operator will be able to decide to selectively install specific versions of `mpy-cross` like
```bash
source .venv2/bin/activate
pip install mpy-cross=1.9.4
```
into the Python environment running on her workstation.

## Usage

### Description
When running it from a Python environment where the `mpy_cross` modules is installed, `mpy_cross_all.py` will attempt to invoke `mpy-cross` from the `mpy_cross` distribution.

Otherwise, it will go down the established route of invoking `mpy-cross` directly, essentially expecting it to reside somewhere on `$PATH`.

### Synopsis
```bash
source .venv2/bin/activate
time python tools/mpy_cross_all.py --out dist-packages-mpy dist-packages

real	0m0.439s
user	0m0.152s
sys	0m0.247s
```

We hope you like this.

With kind regards,
Andreas.
",15337142
216,2019-07-27T20:34:47Z,2020-03-05T02:39:44Z,,,"When the REPL is waiting for user input, it is blocking-read from stdin. Micropython event on the same thread would have to wait for the user to interact

This change prevents read from blocking by first making sure there is something to read, otherwise it polls and handles Micropython pending events (mp_handle_pending)

This is in line with other port's REPLs such as ESP32, which do not block",15337142
217,2019-07-21T20:13:31Z,2019-07-31T12:49:01Z,,,Address ojbects are unsigned and thus should be instantiated with the uint variant.,15337142
218,2019-07-11T06:42:17Z,2019-07-26T06:15:16Z,,,"For discussion... I'd like to consolidate `py/ringbuf.h` with the ringbuf implementation in modbluetooth.c in #4893 written by @aykevl, so this PR merges the two implementations into py/ringbuf.h.
The benefit of @aykevl's implementation is that when the size of the ringbuf is divisible into 2^16 (i.e. `2**16 % size == 0`), we can make the code smaller and avoid a wasted byte in the buffer.

I'm unsure whether the requirement that the buffer is divisible into 2^16 is a problem. It means that if the user sets the `rxbuf` kwarg on ESP8266, they may get a slightly larger buffer than expected (the code rounds up to the nearest power of two).

I've also changed ringbuf to no longer inline get/put -- this is only a saving if each of get/put are called once (on ESP8266/ESP32 this is not the case). On NRF, LTO does this for us anyway. (And NRF will benefit further when this gets used in modbluetooth).

This reduces code size on ESP8266 (-124) and NRF (-84) ports, and marginal increase on ESP32 (+24).
",15337142
219,2019-07-08T13:12:58Z,2019-08-05T12:45:46Z,,,"This PR implements PEP 572, assignment expressions.

Note: this is here primarily for proof of concept and discussion.  There's no intention to merge it at this point.  See #4899 for the discussion.

The patch here may not be 100% compliant with PEP 572, I didn't check everything, but the basic cases work:
```python
(x:=4)
if x:=2: print(True)
min(4, x:=5)
```

",15337142
220,2019-06-30T14:17:30Z,2019-06-30T16:27:10Z,,,"Some simple edits to the standard framebuf module to support the idea of an MSB vertical mode.
",15337142
221,2019-06-27T19:48:26Z,2019-06-28T07:35:21Z,,,"This adds a 32-bit per pixel XRGB format to the framebuf module.
This format is seen in some Linux display drivers.",15337142
222,2019-06-25T15:00:33Z,2019-12-18T18:17:33Z,,,"because emcc looks by itself into that ports folders cache but clang -E cannot.

This way if a header is missing clang used as preprocessor won't tap by default in /usr/include.

It will break build and will force user to explicitly add 
-I$(EM_CACHE)/asmjs/ports-builds/****somelib*****/include for his libs.",15337142
223,2019-05-25T02:41:49Z,2019-05-27T08:49:29Z,,,"Builds on #4800 and #4363 

",15337142
224,2019-05-23T01:40:20Z,2019-06-05T04:44:30Z,,,添加了SM1432F405开发板的硬件支持,15337142
225,2019-05-21T11:37:52Z,2019-05-21T12:22:18Z,,,"This is to provide a summary of the licenses used by MicroPython.

- Add SPDX identifier for every directory that includes non-MIT-licensed content.
- Update copyright to 2019
- Add brief summary
- Update docs license to be more explicit.

This was partially automated and cross-checked with the work by @dlech in #4432   I like the approach outlined there but my aim here is to provide a simple ""at a glance"" summary of just the licenses used and clarify the overall purpose of the root-level LICENSE file.

Related to #4363 ",15337142
226,2019-04-30T12:43:37Z,2020-02-24T09:00:02Z,,,"The goal here is to make a built-in `unumpy`, and along with it `unumpy.fft` and `unumpy.linalg`.

Two main changes:
 - Make built-in module importing happen as part of the dotted path walking as for regular modules.
 - Rather than making the submodule an attribute on the package (which can't be done on a built-in module), find them in `mp_loaded_modules_dict`.

 Note: to make this work, the built-in submodule sets its `__name__` to (e.g.) `QSTR_unumpy_dot_fft`, with corresponding `Q(unumpy.fft)` in qstrdefs.",15337142
227,2019-04-26T01:23:40Z,2019-04-28T12:21:32Z,,,"This is something I was working on for a while, but only now got it to a point where it works well enough to be useful.

**The idea is to remove the need to scan the C stack and machine registers for root pointers, and instead track root pointers explicitly throughout the code by maintaining a stack of root pointers, a ""root stack"".**

The reason to look at it now is because of issues like #4652, #4705, and the problem with the Javascript port not being able to trace machine registers.  The patch here should be a full solution to those issues.

The code here is not really mergeable (yet) but instead shows what is necessary to do this, to track the root pointers manually.

Running unix coverage tests yields:

709 tests
709 passed
32 skipped

It also works on pyboard with pystack enabled there.

Some points to note:
- the patch here is mostly just a bunch of push/pop pairs at various places to make sure root pointers are reachable
- the feature can be completely disabled if not needed and traditional scanning of root pointers (using the C stack and machine registers) used instead
- to test, aggressive GC collection was enabled (collection at each opcode, at each memory allocation, and at some other locations)
- code size increases by about 3000 bytes
- an additional region of memory is needed for the root stack
- the GC is now much more precise and could be on the path to becoming 100% precise with this patch (and a lot of extra work)
- it may now be possible to do some very basic form of moving of objects in the heap to defragment it",15337142
228,2019-04-20T14:03:51Z,2019-10-26T12:14:48Z,,,"quick ref:
```
import esp32

esp32.nvs_set('testkey', 'testvalue')
esp32.nvs_get('testkey')
esp32.nvs_erase('testkey')
esp32.nvs_erase_all()
```",15337142
229,2019-04-18T15:12:06Z,2019-07-23T06:03:21Z,,,The filesystem is 26k in size.,15337142
230,2019-04-15T06:24:18Z,2019-04-18T03:57:23Z,,,"The patches in this PR add support of MICROPY_EMIT_X64 and MICROPY_EMIT_X86 for msvc toolchain in ports/windows. They are enabled by default if building with msvc toolchain, but not with mingw and cygwin toolchain. It includes following changes:

- Add Windows X64 calling convention
- Add assembly code (masm) to support nlr_push and nlr_jump because msvc doesn't support inline assembly for X64 code
- Add alloc.c and gccollect.c (tweaked from unix/alloc.c and unix/gccollect.c) to use Windows memory management for gc

The patches pass all test cases of tests/micropython/native_*,viper_* on Windows.",15337142
231,2019-04-08T11:48:10Z,2020-01-28T03:03:20Z,,,"W600 is an embedded Wi-Fi SoC chip which is complying with IEEE802.11b/g/n international standard and which supports multi interface, multi protocol. It can be easily applied to smart appliances, smart home, health care, smart toy, wireless audio & video, industrial and other IoT fields. This SoC integrates Cortex-M3 CPU, Flash, RF Transceiver, CMOS PA, BaseBand. It applies multi interfaces such as SPI, UART, GPIO, I2C, PWM, I2S, 7816. It applies multi encryption and decryption protocol such as PRNG/SHA1/MD5/RC4/DES/3DES/AES/CRC/RSA.

Currently only port modules with WiFi,GPIO, UART, software SPI, I2C, PWM, WDT and Timer，more module ports will be added in the future.

These chips are widely available and can be purchased from various major distributors like Seeed, Taobao, etc, or directly from WinnerMicro. 

W600 uses standard arm-none-eabi-gcc and openocd to compile and debug firmware.

W600 is available in the long term, and code are licensed under Apache license.

We will update the migration code frequently, especially when the SDK updates or fixes bugs.",15337142
232,2019-04-04T03:24:32Z,2019-05-28T15:44:01Z,,,,15337142
233,2019-03-13T18:03:13Z,2019-03-18T02:51:53Z,,,"This adds some functionality to the Javascript port:

- two way JS <-> Python communication using a js module in Python and emscripten eval / evali functionality
- adds code to wrapper.js to initialize the browser correctly, and find all `<script type=""script/micropython"">` tags and executes them
- another make target `make server` which builds and shows the `test.html` webpage to see a small example of micropython functionality in the browser",15337142
234,2019-03-12T23:34:03Z,2020-03-26T07:11:54Z,,,"This extends the uart irq support from  372e7a4d / #3971 to allow running the irq handler for `UART_FLAG_RXNE`, ie for every character received.",15337142
235,2019-03-10T12:00:00Z,2019-03-26T07:56:17Z,,,"This implements long-conceived function to automatically calculate offsets for uctypes structure definitions. This means that the order of field definition is important, and thus requires using OrderedDict for structure definition. And for that to continue having nice, convenient syntax, OrderedDict literal support, as was merged recently, is required.

There're also a couple of another commits implementing more features.


    To use this function, a structure descriptor should be done using OrderDict,
    and no offsets need to be specified, calc_offsets() will fill them in based
    on the layout type. For example:
    
    desc = OrderedDict((
    (""f1"", uctypes.UINT8),
    (""f1"", uctypes.UINT16),
    ))
    uctypes.calc_offsets(desc, ctypes.LITTLE_ENDIAN)
    
    While doing this, structure size calculation for native layout was also
    fixed - rounding up of structure size depends not on max field size, but
    on max field alignment. For example, on x86, alignment of UINT64 is 4,
    so a structure of UINT32 and UINT64 has size of 12 (and not 16, as was
    calculated previously).
",15337142
236,2019-02-21T22:35:31Z,2019-02-24T05:43:11Z,,,"`micropython-hmac` reuiqres extra attributes currently not implemented by `uhashlib`;
This patch enables them (and fixes #4500) if demanded (only for SHA256 though).",15337142
237,2019-02-10T22:10:34Z,2019-02-24T05:48:24Z,,,"Fixes #4119 .

Tested on unix and ESP32. On the ESP32, code size increase by 16 bytes. Worth it IMO to fix this very unintuitive problem.",15337142
238,2019-02-10T19:18:09Z,2019-02-20T09:09:47Z,,,"Contact bounce problem solved from Pin module. The problem is very popular, it makes no sense to solve it in python by user.",15337142
239,2019-02-07T22:56:01Z,2019-02-08T00:12:34Z,,,"Follows CPython's handling regarding error codes and prints.

#3975",15337142
240,2019-02-06T17:48:33Z,2020-02-08T03:03:28Z,,,"Usage guide and examples available at:
https://github.com/miketeachman/micropython-esp32-i2s-examples",15337142
241,2019-02-05T21:42:08Z,2019-03-31T21:47:17Z,,,"This has already been mentioned around, as we can see in:

https://forum.micropython.org/viewtopic.php?f=2&t=3298&sid=cbee627a8772945c10fc91b416489ec1#p23035

https://github.com/micropython/micropython/issues/1354

with funny tricks due to the lack of this feature: https://forum.micropython.org/viewtopic.php?f=2&t=3298&start=10#p23087

I wouldn't say the current solution is perfect, but that's the best I could hack and it's good enough IMHO.",15337142
242,2019-02-05T16:46:48Z,2019-02-26T06:41:54Z,,,"This PR is basically a fixed version of @mactijn [port](https://github.com/micropython/micropython/pull/3530) of @jhgoebbert [PR#218](https://github.com/micropython/micropython-esp32/pull/218) which had conflicts with master and haven't passed the CI check.

We've fixed issues, merged code and tested functionality on our ESP-32 boards, but I would kindly ask maintainers to properly review the code.

It can be used as follows:

```
import machine
import time
import network

button = machine.Pin(12, machine.Pin.IN, machine.Pin.PULL_UP)
wlan = network.WLAN(network.STA_IF)
wlan.active(True)
while True:
    if button.value() == 0:
        wlan.start_wps()
        print('start_wps')
        while wlan.status() == network.STA_WPS_PROBING:
            print(""probing with WPS"")
            time.sleep(0.5)

        if wlan.status() == network.STA_WPS_SUCCESS:
            print(""WPS successful"")
            print(""   ESSID:    "", wlan.config('essid'))
            print(""   Password: "", wlan.config('password'))
            wlan.connect(wlan.config('essid'), wlan.config('password'))
            print(""Waiting for connection..."")
            while not wlan.isconnected():
                machine.idle()
            print(""Connected."")

        elif wlan.status() == network.STA_WPS_FAILED:
            print(""WPS failed"")

        elif wlan.status() == network.STA_WPS_TIMEOUT:
            print(""WPS timeout"")",15337142
243,2019-01-21T18:46:31Z,2019-02-17T07:42:31Z,,,"This change enables to use the ESP32 (maybe also the ESP8266) with https and CA validation:
Example:
https://github.com/Kradxn/esp32ssltest
I also propose a complete rewrite of that file, because its implementation doesn't reflect the ussl documentation.
But for now this works.
`s = ussl.wrap_socket(s, ca_certs=cert, server_hostname=host)`
cert has to be (like the other cert) a string with a certificate in pem format
e.g. for google.com:

> -----BEGIN CERTIFICATE-----
MIIEXDCCA0SgAwIBAgINAeOpMBz8cgY4P5pTHTANBgkqhkiG9w0BAQsFADBMMSAw
HgYDVQQLExdHbG9iYWxTaWduIFJvb3QgQ0EgLSBSMjETMBEGA1UEChMKR2xvYmFs
U2lnbjETMBEGA1UEAxMKR2xvYmFsU2lnbjAeFw0xNzA2MTUwMDAwNDJaFw0yMTEy
MTUwMDAwNDJaMFQxCzAJBgNVBAYTAlVTMR4wHAYDVQQKExVHb29nbGUgVHJ1c3Qg
U2VydmljZXMxJTAjBgNVBAMTHEdvb2dsZSBJbnRlcm5ldCBBdXRob3JpdHkgRzMw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDKUkvqHv/OJGuo2nIYaNVW
XQ5IWi01CXZaz6TIHLGp/lOJ+600/4hbn7vn6AAB3DVzdQOts7G5pH0rJnnOFUAK
71G4nzKMfHCGUksW/mona+Y2emJQ2N+aicwJKetPKRSIgAuPOB6Aahh8Hb2XO3h9
RUk2T0HNouB2VzxoMXlkyW7XUR5mw6JkLHnA52XDVoRTWkNty5oCINLvGmnRsJ1z
ouAqYGVQMc/7sy+/EYhALrVJEA8KbtyX+r8snwU5C1hUrwaW6MWOARa8qBpNQcWT
kaIeoYvy/sGIJEmjR0vFEwHdp1cSaWIr6/4g72n7OqXwfinu7ZYW97EfoOSQJeAz
AgMBAAGjggEzMIIBLzAOBgNVHQ8BAf8EBAMCAYYwHQYDVR0lBBYwFAYIKwYBBQUH
AwEGCCsGAQUFBwMCMBIGA1UdEwEB/wQIMAYBAf8CAQAwHQYDVR0OBBYEFHfCuFCa
Z3Z2sS3ChtCDoH6mfrpLMB8GA1UdIwQYMBaAFJviB1dnHB7AagbeWbSaLd/cGYYu
MDUGCCsGAQUFBwEBBCkwJzAlBggrBgEFBQcwAYYZaHR0cDovL29jc3AucGtpLmdv
b2cvZ3NyMjAyBgNVHR8EKzApMCegJaAjhiFodHRwOi8vY3JsLnBraS5nb29nL2dz
cjIvZ3NyMi5jcmwwPwYDVR0gBDgwNjA0BgZngQwBAgIwKjAoBggrBgEFBQcCARYc
aHR0cHM6Ly9wa2kuZ29vZy9yZXBvc2l0b3J5LzANBgkqhkiG9w0BAQsFAAOCAQEA
HLeJluRT7bvs26gyAZ8so81trUISd7O45skDUmAge1cnxhG1P2cNmSxbWsoiCt2e
ux9LSD+PAj2LIYRFHW31/6xoic1k4tbWXkDCjir37xTTNqRAMPUyFRWSdvt+nlPq
wnb8Oa2I/maSJukcxDjNSfpDh/Bd1lZNgdd/8cLdsE3+wypufJ9uXO1iQpnh9zbu
FIwsIONGl1p3A8CgxkqI/UAih3JaGOqcpcdaCIzkBaR9uYQ1X4k2Vg5APRLouzVy
7a8IVk6wuy6pm+T7HT4LY8ibS5FEZlfAFLSW8NwsVz9SBK2Vqn1N0PIMn5xA6NZV
c7o835DLAFshEWfC7TIe3g==
-----END CERTIFICATE-----",15337142
244,2019-01-09T06:23:04Z,2019-05-23T02:13:19Z,,,"#3427 

```python
import smartconfig
import network
wlan = network.WLAN(network.STA_IF)
if not wlan.active():
    wlan.active(True)

smartconfig.set_type(smartconfig.ESPTOUCH)
smartconfig.start()
while smartconfig.status() != smartconfig.SC_STATUS_LINK_OVER:
    pass
smartconfig.stop()

print(smartconfig.get_ssid())
print(smartconfig.get_password())
print(smartconfig.get_phoneip())
```",15337142
245,2018-12-20T18:46:08Z,2018-12-20T21:26:10Z,,,"Constructor signature is extended to:

    memoryview(buf, offset, size)

This is equivalent to:

    m = memoryview(buf)
    m[offset:offset + size]

But allocates just 1 memoryview object instea of 2.

Also, .init(buf, offset, size) method added, which allows to reuse
(without allocation) existing memoryview object for new buffer object
(or to update ""window"" of memoryview into the buffer).

Change-Id: I1f864b908642b256305dc5caebf30662c306b1e0",15337142
246,2018-12-19T11:45:17Z,2018-12-20T08:21:52Z,,,The internal Pullup resistor can be enabled when needed.,15337142
247,2018-12-17T09:24:25Z,2019-05-30T07:16:22Z,,,,15337142
248,2018-12-15T06:17:07Z,2018-12-17T08:07:11Z,,,"This implements simple linear native inheritance (ie doesn't support multiple inherintance at the C level).  It does this by just looping over the search through `locals_dict`, searching all parents of the type.

The other two commits here use this to combine all common stream methods (read, readinto, readline, readlines, write, close) into a single C type which is a parent type for all other stream classes.

This allows for native inheritance (see issue #1159) and reduces code size for ports that have stream based objects.",15337142
249,2018-12-13T16:44:38Z,2019-02-01T15:49:12Z,,,"How it worked previously is that either ->attr() or ->local_dict was used.
But having it's exclusive like that is rather inflexible, so if ->attr
didn't look up anything, let's fallback to ->locals_dict.

Change-Id: I0e00aed827a3c73c4eca30be3c8a4e538098d249",15337142
250,2018-11-26T04:58:06Z,2018-12-06T08:46:34Z,,,"Works but not well tested.  It's likely that ussl doesn't work anymore due to different malloc/free.

",15337142
251,2018-11-24T09:43:58Z,2018-11-27T09:45:09Z,,,"Closes #4316.

On some systems, e.g. Debian Jessie, additional packages are required to sucessfully build micropython.",15337142
252,2018-11-11T20:43:31Z,2018-11-11T21:33:54Z,,,"The DC/DC enablement API is provided in a new machine
module, ""nrf"", specific to the nRF chip-series.

The API can be used to enable and disable the DC/DC
converter with or without Bluetooth stack enabled.

The patch also add a definition of ARRAY_SIZE needed
by nrfx HAL-layer.",15337142
253,2018-11-05T14:24:44Z,2018-12-04T06:28:07Z,,,"The JSON us mainly used for storage or network communications. Since micropython aims to be as unbloated as possible to be used for small applications like IoT, the JSON output should be as compact as possible.",15337142
254,2018-10-17T14:53:54Z,2018-10-18T00:18:27Z,,,"As discussed in forum thread https://forum.micropython.org/viewtopic.php?f=3&t=5332&p=30692#p30692

Because of the -Os optimization setting, the float() return values for ppc64le and x86_64 are calculated slightly differently because of the use of the Fuse Multiply-Add instructions. Adding the -ffp-contract=off compilation option will disable the use of the FMA instructions and make the values returned consistent across architectures(and generations) as desired under https://en.wikipedia.org/wiki/IEEE_754  ",15337142
255,2018-10-16T10:23:07Z,2019-05-22T20:44:12Z,,,Make programming with NeoPixels feel more like operating on an array.,15337142
256,2018-10-14T14:31:11Z,2018-10-21T01:59:47Z,,,"As discussed previously in #2283, it would be good to have a simple PWM class in the machine module to allow for generating PWM output in a way that is portable across the different ports.  Such functionality may already be available in one way or another (eg through a Timer object), but because configuring PWM via a Timer is very port-specific, and because it's a common thing to do, it's beneficial to have a top-level construct for it.

The proposal here aims to provide all required functionality in a minimal way.  Some points about it:
- you can set frequency, or period of the PWM output
- you can set the duty in time (eg microseconds for the pulse width) or as a percentage ratio (eg 50%)
- because for most PWM implementations, changing the frequency/period will alter the duty cycle, changing the frequency/period on the object also allows to re-set the duty cycle in one call, namely `pwm.init(freq=..., duty_u16=...)`; counter to this, there's no way to just change the frequency/period.

It might be interesting to compare this with the proposal for ADC, #4213, because in a way they are related.  With the PWM class I didn't go the route of adding a PWMBlock for further configuration, but instead showed an alternative to this, by having a `block` parameter to the constructor which would allow to have finer control over which underlying hardware generator was used for the PWM object.",15337142
257,2018-10-04T15:23:40Z,2019-09-05T12:24:10Z,,,"Based on the discussion in #3943 here is my proposal for a revised `machine.ADC` class which is intended to be implemented by all ports to make the ADC class more standardised.  The changes here include a new `machine.ADCBlock` class as well, which is used to allow further configuration of ADC if a port supports it.

In summary the new interface is:
```python
ADC(id, *, sample_ns, gain_mult, gain_div) # create ADC object
ADC.init(sample_ns, gain_mult, gain_div) # initialise
val = ADC.read_u16() # read value between 0-65535
val = ADC.read_v() # read voltage, float
val = ADC.read_mv() # read mV, integer

ADCBlock(id, *, bits) # create ADC peripheral object
ADCBlock.init(bits) # initialise
adc = ADCBlock.connect(channel) # connect to a channel
adc = ADCBlock.connect(source) # connect up a pin or other object
adc = ADCBlock.connect(channel, source) # connect a channel to a pin
```

The API is split up this way into two classes (ADC and ADCBlock) so that basic and common functionality is easily available in the ADC class, and extended functionality is in ADCBlock.  A given port only needs to implement ADC if that is all it can do, and already that gives 80% of the functionality.  The ADC class is the one that would be used most of the time.

If a port wants to expose more control, and the user needs to use it, then the ADCBlock class is there for that.  It allows to specify the resolution, and which channels are connected to which pins.

All existing ports should be able to fit into this model without a problem.  In particular the gain settings can be used by nrf and esp32.  stm32 can use the sample time.

It should be possible to update the ports in a backwards-compatible way to this new API because most of the methods are new and don't clash with existing ones.  ADCBlock is completely new so won't clash with anything.

There is room for extensions to this API: ADC can have additional methods like `read_u24()` and `read_uv()`, and ADCBlock might get methods to read internal channels, like voltage references and temperature.

Note: it might be easier to read the diff of this PR in split view.",15337142
258,2018-09-21T13:39:51Z,2019-10-16T02:41:22Z,,,"I had to change the stlink version to get openocd to talk to my board but I don't know if this change has to be done for all the users.

I2C is working with the fixed pin assignments.",15337142
259,2018-09-20T09:05:08Z,2019-05-01T16:33:34Z,,,"Purpose: implement RSA PKCS1 signature.

This PR implement PKCS #1 v1.5 signature and verification process with MD5 encoding method : md5WithRSAEncryption
 
Considering your comment I closed the PR #3795 and modify the API to be compliant with ucryptolib

I've test this PR only on ESP32 port. 

Usage : 
```
import ucryptolib
privRSA = ucryptolib.rsa(privKey)
signature = privRSA.PKCS1sign(message)

pubRSA = ucryptolib.rsa(pubKey)
pubRSA.PKCS1verify(message, signature)
```
With this API we can implement later crypt and decrypt functions into the rsa object.

Full example for testing
```
import ucryptolib
import ubinascii

pubKey = """"""
-----BEGIN PUBLIC KEY-----
MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDdlatRjRjogo3WojgGHFHYLugd
UWAY9iR3fy4arWNA1KoS8kVw33cJibXr8bvwUAUparCwlvdbH6dvEOfou0/gCFQs
HUfQrSDv+MuSUMAe8jzKE4qW+jK+xQU9a03GUnKHkkle+Q0pX/g6jXZ7r1/xAK5D
o2kQ+X5xK9cipRgEKwIDAQAB
-----END PUBLIC KEY-----""""""

privKey = """"""
-----BEGIN RSA PRIVATE KEY-----
MIICWwIBAAKBgQDdlatRjRjogo3WojgGHFHYLugdUWAY9iR3fy4arWNA1KoS8kVw
33cJibXr8bvwUAUparCwlvdbH6dvEOfou0/gCFQsHUfQrSDv+MuSUMAe8jzKE4qW
+jK+xQU9a03GUnKHkkle+Q0pX/g6jXZ7r1/xAK5Do2kQ+X5xK9cipRgEKwIDAQAB
AoGAD+onAtVye4ic7VR7V50DF9bOnwRwNXrARcDhq9LWNRrRGElESYYTQ6EbatXS
3MCyjjX2eMhu/aF5YhXBwkppwxg+EOmXeh+MzL7Zh284OuPbkglAaGhV9bb6/5Cp
uGb1esyPbYW+Ty2PC0GSZfIXkXs76jXAu9TOBvD0ybc2YlkCQQDywg2R/7t3Q2OE
2+yo382CLJdrlSLVROWKwb4tb2PjhY4XAwV8d1vy0RenxTB+K5Mu57uVSTHtrMK0
GAtFr833AkEA6avx20OHo61Yela/4k5kQDtjEf1N0LfI+BcWZtxsS3jDM3i1Hp0K
Su5rsCPb8acJo5RO26gGVrfAsDcIXKC+bQJAZZ2XIpsitLyPpuiMOvBbzPavd4gY
6Z8KWrfYzJoI/Q9FuBo6rKwl4BFoToD7WIUS+hpkagwWiz+6zLoX1dbOZwJACmH5
fSSjAkLRi54PKJ8TFUeOP15h9sQzydI8zJU+upvDEKZsZc/UhT/SySDOxQ4G/523
Y0sz/OZtSWcol/UMgQJALesy++GdvoIDLfJX5GBQpuFgFenRiRDabxrE9MNUZ2aP
FaFp+DyAe+b4nDwuJaW2LURbr8AEZga7oQj0uYxcYw==
-----END RSA PRIVATE KEY-----""""""

header = b'{""alg"": ""HS256"",""typ"": ""JWT""}'
payload = b'{""sub"":""1234567890"",""name"":""John Doe"",""iat"":1516239022}'
message = ubinascii.b2a_base64(header) + ""."" + ubinascii.b2a_base64(payload)

privRSA = ucryptolib.rsa(privKey)
signature = privRSA.PKCS1sign(message)


print(""Signature encoded base64 is {}"".format(ubinascii.b2a_base64(signature)))
print(""you can check at https://jwt.io/ select algoritm RS256"")

pubRSA = ucryptolib.rsa(pubKey)

pubRSA.PKCS1verify(message, signature)
pubRSA.PKCS1verify(message + ""."", signature)```",15337142
260,2018-09-20T00:02:47Z,2018-09-20T00:02:47Z,,,"Hi.
I've added SIGMA-DELTA signal generator peripheral support which can be used to generate square-wave signal around 40KHz-4MHz. There are several ESP8266 hardware features still not available in micropython, and this is one of them. Please consider adding this feature.

Best,
",15337142
261,2018-09-15T21:02:12Z,2018-09-20T10:04:43Z,,,"The native target ""mpy-cross"" is missing the "".exe"" filename extension on Windows.
Building the default STM32 port fails with a truncated command line during the link phase, due to the long list of object files in the stm32lib.
The proposed fix writes the linker input files to a response file. An alternative might be using a static library archive.

Tools used for Windows build:
* TDM-GCC (5.1.0 - MINGW64)
* GNU Arm Embedded Toolchain (7-2018-q2-update - 32bit)
* Git for Windows (2.1.7 - MINGW64)",15337142
262,2018-09-13T01:54:50Z,2019-12-13T12:35:45Z,,,"This is a proof of concept and work in progress to investigate the possibility of completely removing nlr (setjmp/longjmp-like exception handling) from the code base.

Instead of doing a longjmp, exception handling is now basically handled as follows:
- to raise an exception: create an exception the usual way and store it into `MP_STATE_THREAD(cur_exc)`, then return `MP_OBJ_NULL`
- to propagate an exception: if a function returned `MP_OBJ_NULL` then just return `MP_OBJ_NULL`
- to catch an exception: if a function returned `MP_OBJ_NULL` then access the exception in `MP_STATE_THREAD(cur_exc)` and clear this variable so the exception doesn't propagate further

For functions that don't return an `mp_obj_t` there are some additional rules about how to indicate an exception, but they are quite simple.  There are also some helper functions to make the above rules easier to follow (eg for iterating through iterables).  In a lot of cases code doesn't need to change much at all from the existing nlr scheme.

For this proof of concept the unix port is completely converted to non-nlr code.  All tests pass (basics, extmod, io, import, float, etc), excluding threading, and excluding those that use the native emitter (because it still uses nlr).

Change in code size wrt master (absolute bytes and percent bytes):
```
       bare-arm:  +900 +1.332%
    minimal x86: +1304 +0.831%
       unix x64: +3032 +0.623%
    unix nanbox: +1956 +0.446%
          stm32: +1732 +0.486%
         cc3200: +1352 +0.731%
        esp8266: +1812 +0.280%
          esp32: +1897 +0.178%
```

Performance seems to be unchanged, if anything slightly improved (only tested with pystone.py).

---

The benefits of removing nlr are:
- no need for any assembler in the core
- possible to port to architectures that don't have setjmp/longjmp and where it's not feasible to write custom nlr code in assembler
- less stack usage (eg for stm32, the VM stack usage decreases from 120 bytes to 72 bytes)
- much simpler catching and handling of exceptions
- easier to reason about the code because it will no longer arbitrarily do a longjmp
- easier and safer to call subsystem code (eg vfs code) from non-uPy contexts without worrying about nlr

The drawbacks of removing nlr are:
- all existing C code (eg stm32, other ports, 3rd party extensions, etc) must be rewritten to handle the new rules for raising exceptions
- increased existing code size
- all new C code that will be written in the future will be ~1% larger due to the need to explicitly handle exceptions/errors
",15337142
263,2018-09-10T09:27:19Z,2020-03-25T02:45:04Z,,,"ESP-Now enables direct communication from one ESP device to another.

This PR is originally based on issue micropython/micropython-esp32#197 and @nickzoic's [branch](https://github.com/nickzoic/micropython-esp32/tree/esp32-espnow).

I rewrote most of the functions to make it compatible between esp32 and esp8266.
Several workarounds were introduced to get rid of inherent bugs with the SDK.

#### SDK Ref
https://www.espressif.com/sites/default/files/documentation/esp-now_user_guide_en.pdf
https://www.espressif.com/sites/default/files/2C-ESP8266_Non_OS_SDK_API_Reference__EN.pdf
https://www.espressif.com/en/products/software/esp-now/overview


#### API Docs
```
espnow.init()
espnow.deinit()
```
> Initialize/deinitialize ESP-NOW
<br />

```
espnow.pmk(master_key)
```
> Setting the primary master key -- some sort of key management(?).
> Key must be 16 characters.
> According to the documentation, pmk is used to encrypt peer's lmk. Then the encrypted lmk will be used to encrypt the data frame.
> When transmitting between 2 peers, both have to have the same pmks.
<br />

```
espnow.lmk(peer_mac, local_key)
```
> Setting the local master key.
> 16 characters
> When transmitting between 2 peers, both have to have the same lmks.
> Setting the local_key = None to disable encryption.
<br />

```
espnow.add_peer(peer_mac, [local_key])
```
> Self-explanatory
<br />

```
def send_cb(peer_mac, success)
def recv_cb(peer_mac, msg)

espnow.send(peer_mac, msg)
espnow.on_send(send_cb)
espnow.on_recv(recv_cb)
```
> When peer_mac is set to None, broadcast to all peers
<br />

```
peer_count()
```
> Return (all_count, encrypted_count)
<br />

```
version()
```
> Return 1 for esp32, 0 for esp8266
<br />


#### Bugs/Caveats:
* Upon changing the pmk, all local peers' lmks have to be re-applied. Otherwise the system will continue to use the old encryption setup by the previous pmk.
* Role/interface index(esp8266)/channel setting in SDK don't have effect. Although you need to personally make sure both devices are on the same wifi channel.
* Device who add peer with lmk can still receive unencrypted message from the added peer
* There is no get_lmk() from peer because of bugs in the SDK.
* Other API bugs and their workarounds are documented in the code.


IMHO documentations from Espressif are terrible. Both SDKs are buggy as hell. API behave not as described. Many settings don't even have effect...
",15337142
264,2018-08-28T20:22:47Z,2018-08-28T20:22:59Z,,,"This patch adds basic bonding support for Bluetooth LE Central.

Return of peer encryption keys on connect if bond_data
is not set, else None. The user can store bonding data
to flash and subsequently use this for restoring the
bond upon re-connect.

Usage example using internal flash storage (MICROPY_HW_HAS_BUILTIN_FLASH=1):

bond_data = None
try:
    f = open(""bond.txt"", ""r"")
    bond = f.read()
    f.close()
except Exception:
    pass

c = p.connect(dev.addr(),
              addr_type=dev.addr_type(),
              pair=True,
              bond_data=bond)

if c:
    f = open(""bond.txt"", ""w"")
    f.write(c)
    f.close()",15337142
265,2018-08-27T21:19:12Z,2018-08-28T01:37:50Z,,,"This patch adds support for enabling notifications from
remote peripheral in case of Central GATT client.

Added implementation of Characteristic Descriptor objects which
are populated during service discovery (Central GATT client).
For GATT server (most likely Peripheral) the list is kept empty
for now. The list returned can be used to locate the for example
the CCCD descriptor and enabling the notifications by writing
[0x01, 0x00] to it.

Added method for retrieving the handle value of the Service,
Characteristic and Descriptor in case a python application wants
to match on handle value (typically in the python registered event
handler) where characteristic handle is passed instead of connection
handle.

In case of Central, the notification and indication events will be
propagated to the gattc handler registered in the ubluepy_peripheral.c.
Indications will be auto-replied on the return of event handler call.",15337142
266,2018-08-16T22:23:24Z,2018-08-17T05:38:15Z,,,"
Allow the reset to factory defaults while including an initial set of scripts into
the flash filesystem. The initial filesystem contents can be attached as a Gzip
compressed tarball.",15337142
267,2018-08-12T16:34:55Z,2018-09-11T01:14:24Z,,,"add it as machine.RTC().slow_memory(addr [, value])

This is helpfull for example to communicate with the ulp.",15337142
268,2018-08-08T10:50:02Z,2020-03-15T11:41:12Z,,,"Use getrandom function if available, otherwise read from /dev/urandom",15337142
269,2018-08-04T04:16:59Z,2018-12-15T03:43:50Z,,,"This is the less-fancy, but actually possible adjunct to https://github.com/micropython/micropython/pull/3995.

Basically, I'm working on a system which needs to communicate over a RS-485 bus.   

Ideally, we'd use the UART's ability to toggle the transmit/receive interface on the RS-485 line driver, but doing that involves updating the attached version of the ESP-IDF, which is more complicated then I thought. (again, see https://github.com/micropython/micropython/pull/3995). 

The simpler, but more hacky alternative is to just toggle the tx/rx line manually. Doing this means we need to be able to wait until the tx is done, and then call `pin.value(x)` in a prompt manner (so we don't lock up the bus for longer then needed).

Right now, serial.write() is non blocking. It just places the passed bytes in the TX buffer, and then returns. 

The ESP-IDF has a convenient `uart_wait_tx_done()` that let's us block until the TX buffer is empty, so this just exposes that, with an optional timeout parameter (that defaults to 50 milliseconds, unless overridden).


This has actually been tested on real hardware.",15337142
270,2018-08-03T10:18:25Z,2020-01-09T09:54:45Z,,,"This commit implements `bytes.hex()` and `bytes.fromhex()` functions. I think these are very useful e.g. for education as teaching to use the `binascii` module when there is already a function for that in the standard library is wrong IMHO.

We could also add `hex()`/`fromhex()` to `bytearray`, but this is also not included in this PR.

Let me know what you think.",15337142
271,2018-07-21T20:34:59Z,2018-07-21T20:34:59Z,,,,15337142
272,2018-07-01T14:21:36Z,2018-07-08T11:55:09Z,,,"Herby I propose to add a ticks_timer function, for esp32 port. 

The implementation is based on **esp_timer_impl_get_time()**, a 64 bit microsecond counter.
uint64_t with microseconds will overflow in 2^64 / (1e6 * 60 * 60 * 24 * 365) = 292471,21 year.

Note that nothing is changed to the current implementation.

With this implementation there is no need anymore to calculate time diffs with ticks_diff.
And far less cpu cycles is spend in calculating the ticks, and ticks diffs

Another advantage is that the value of ticks_timer will not make a jump in case one changes the date of the system. 

Note that ticks_ms and ticks_us will make a jump in case one changes the date of the system.

Testing of the microseconds timer can be done with next code:

```
import utime as time

def showtime(us):
	useconds = us % 1000000
	tseconds  = us // 1000000

	tminutes = tseconds // 60
	seconds  = tseconds % 60

	thours   = tminutes // 60
	minutes  = tminutes % 60

	tdays    = thours // 24
	hours    = thours % 24

	tyears   = tdays // 365
	days     = tdays %  365

	print (""years:%s  days:%s  h:%2s  m:%2s  s:%2s  us:%s  raw:%s""%(tyears, days,hours,minutes,seconds,useconds,us) )

while (True):
	us = time.ticks_timer()
	showtime(us)
	time.sleep(10)

```",15337142
273,2018-06-17T20:55:59Z,2018-10-24T16:52:23Z,,,"Somewhat related to #3843.  If we run into an error trying to `import` a module stored as a `.mpy` file, we never call `reader->close()` to release the open file handle.

This PR adds exception handling to `mp_raw_code_load()` and has it close the reader before re-throwing the exception.",15337142
274,2018-05-19T13:28:43Z,2018-05-24T23:37:33Z,,,This allows micropython to be built with the most efficient mode for afl-fuzz (afl-clang-fast + __AFL_INIT) and disables several built in modules for reasons discussed in that commit.,15337142
275,2018-05-10T17:31:48Z,2019-07-07T06:44:45Z,,,"The unit also has an UART interface, but because of the issue described in #3763 I'm unable to implement this for the time being.

I still think the driver can be useful with only the PWM interface though, as the only main difference between the PWM and UART interfaces is that with UART you can also programatically calibrate the unit.",15337142
276,2018-05-01T01:05:56Z,2018-05-01T05:44:23Z,,,"This PR came about after doing some research into size limits when converting various modules from micropython-lib to `.mpy` files on our device with a 32KB MicroPython heap.

I saw `base64.py` tripping us up, and `mp_compile_to_raw_code()` would throw a `MemoryError` if there was less than about 8,800 bytes of heap free after calling `mp_parse()`.  Oddly, if I retried the parse/compile cycle it would sometimes work (fail with 8,624 free after parsing, try again have 9,136 free after parsing, then 22,656 after compilation and 29,456 after saving `.mpy` to file system and releasing `mp_raw_code_t` structure).

As I explored the issue, I found `vstr_t` objects holding the docstrings, even after I had performed garbage collection.  I never figured out where the references were that kept them in place, but I do feel like I found a safe place to free them.

I looked for but did not find a function to free an `mp_obj_str_t`, so manually do it here.  That `m_del()` and `m_del_obj()` could become a simple function to delete a `mp_obj_str_t` along with its data.

For reference, here's the code I'm currently using in our build to create a `.mpy` file from a `.py` file, based on code from `mpy-cross`:

```C
STATIC mp_obj_t os_mpy(mp_obj_t file_in)
{
    const char *file = mp_obj_str_get_str(file_in);

    gc_collect();
    mp_micropython_mem_info(0, NULL);
    mp_printf(MP_PYTHON_PRINTER, ""Parsing %s...\n"", file);
    mp_parse_tree_t parse_tree = mp_parse(mp_lexer_new_from_file(file),
                                          MP_PARSE_FILE_INPUT);

    gc_collect();
    mp_micropython_mem_info(0, NULL);
    mp_printf(MP_PYTHON_PRINTER, ""Compiling...\n"");
    mp_raw_code_t *rc = mp_compile_to_raw_code(&parse_tree,
                                               qstr_from_str(file),
                                               MP_EMIT_OPT_NONE,
                                               false);

    gc_collect();
    mp_micropython_mem_info(0, NULL);
    vstr_t vstr;
    vstr_init(&vstr, 16);
    vstr_add_str(&vstr, file);
    vstr_cut_tail_bytes(&vstr, 2);
    vstr_add_str(&vstr, ""mpy"");
    mp_printf(MP_PYTHON_PRINTER, ""Saving %s...\n"", vstr.buf);
    mp_raw_code_save_file(rc, vstr_null_terminated_str(&vstr));
    vstr_clear(&vstr);

    rc = NULL;
    gc_collect();
    mp_micropython_mem_info(0, NULL);

    return mp_const_none;
}
MP_DEFINE_CONST_FUN_OBJ_1(mod_os_mpy_obj, os_mpy);
```

I was hopeful that I could actually find where the parser created the `mp_obj_str_t`, and have it identify it as a docstring at that point and just not create it in the first place, but it always came in a `RULE_atom` (IIRC) and lots of non-docstrings also followed that pattern.

So back to `base64.py`.  Without this patch, my `os_mpy()` failed to compile after `mp_parse()` with 8,624 bytes free on the stack.  With the patch, it succeeds with 12,928 bytes free on the stack after `mp_parse()`, a significant increase with a 32KB heap.

I doubt this is ready to just drop in, but hopefully it's a starting point for discussion.
",15337142
277,2018-04-08T22:57:48Z,2018-04-09T19:04:17Z,,,"This can be a replacement for UART in ports that want to have an alternative to UART output - think of small boards with hard to reach UART pins. It only works when a debugger is attached, otherwise it hangs at the first semihosting call (which is implemented as a special breakpoint).

Tested in OpenOCD and JLinkGDBServer.",15337142
278,2018-03-31T15:24:01Z,2018-03-31T16:17:25Z,,,"On my laptop with a 4-thread, 2-core CPU, this reduces the elapsed time taken to run the tests by about 50%:
```\
Elapsed time, seconds, best of 3 runs with each -j value:

before patchset: 18.1
            -j1: 18.1
            -j2: 11.3  (-37%)
            -j4:  8.7  (-52%)
            -j6:  8.4  (-54%)
```",15337142
279,2018-03-09T03:58:09Z,2019-07-10T02:58:19Z,,,"The get and set pixel methods on the 3 mono framebuf formats were very similar, so I combined them.

mono_horiz_setpixel() + mvlsb_setpixel() = **mono_setpixel()**
mono_horiz_getpixel() + mvlsb_getpixel() = **mono_getpixel()**

The combined mono get and set pixel methods now use the exact same logic for calculating `index` and `offset`.

**Index horizontal**
`size_t index = (x + y * fb->stride) >> 3;`

**Index vertical**
`size_t index = (y >> 3) * fb->stride + x;`

**Offset horizontal lsb**
`uint8_t offset = 7 - (x & 0x07);`

**Offset vertical lsb**
`uint8_t offset = 7 - (y & 0x07);`

**Offset horizontal msb**
`uint8_t offset = x & 0x07;`

**Offset horizontal lsb**
`uint8_t offset = y & 0x07;`",15337142
280,2018-02-23T19:34:05Z,2018-03-06T11:21:26Z,,,"When disabled, reduces code size (thumb2) by about 180 bytes and .bss size by 4 bytes.",15337142
281,2018-02-18T20:44:36Z,2018-07-17T18:42:17Z,,,"These changes are changes I made for my personal use but I suspect that something like them would be of general interest even though I don't think they are likely to be directly adopted by the project.

The problem is that with large enough arrays of pixels, there is insufficient memory (on the esp8266 at least) to maintain a copy of the pixel data to do temporary dimming, i.e. multiplying each pixel value by a fraction without losing the original value.

The approach herein is to provide a version of neopixel_write, neopixel_write_frac, which multipliles each pixel value by a fraction (passed in a parameter) as it is written to the neopixel array.

This was my first time poking my head into the code here; because this change adds a fourth argument I also had to add versions of several of the infrastructure definitions to accommodate this directly; I suspect that this may not have been the preferred way to go about things. The addition of the *_frac definitions is in parallel with the existing definitions for the relevant components, and this is also not efficient with respect to space in the firmware. However, I didn't want to muck around too much if the project is flatly uninterested in this contribution. I also didn't make any changes to ports besides the esp8266. If the project wants to adopt something like this, I'd welcome some discussion about the preferred approach and would likely be happy to perform the work (though the work itself is likely to be the most trivial aspect of this I suspect).",15337142
282,2018-02-16T09:46:32Z,2019-07-20T14:17:50Z,,,"2 commits to evaluate:
- one to solve #3615 in the way [dpgeorge](https://github.com/dpgeorge) suggested. I hope to have interpreted correctly what had to be done. It's just a bit of cleanup, by removing dependencies of esp32 port from stm32 and window port.
- one to introduce a new target in the esp32 Makefile, so that it is possible to produce static libs to include instead of the application.bin firmware image only. Solves issue #3618 .",15337142
283,2018-02-12T11:59:16Z,2019-08-12T22:00:06Z,,,"ESP32 has 16 PWM channels with 8 separate timers, but current PWM implementation
forces user to share single timer between all channels. This commit
allows to use all 8 timers and does not break backward compatibility.

API additions:
- PWM initializer takes two new optional keyword arguments:
    `pwm.init(..., timer=0, speed_mode=PWM.HIGH_SPEED_MODE)`
- PWM class defines two new constants:
    `PWM.HIGH_SPEED_MODE` and `PWM.LOW_SPEED_MODE`

Example:
```python
from machine import Pin, PWM

pwm1 = PWM(Pin(22), freq=440)
pwm2 = PWM(Pin(23), freq=880)
# old (unchanged) behaviour: pwm1 and pwm2 both share frequency 880hz as they
#   share the same high speed timer #0

pwm3 = PWM(Pin(2), freq=440, timer=0, speed_mode=PWM.LOW_SPEED_MODE)
pwm4 = PWM(Pin(15), freq=880, timer=1, speed_mode=PWM.LOW_SPEED_MODE)
# pwm3 has frequency 440hz and pwm4 880hz running on different timers
```

There are 4 low speed timers and 4 high speed timers on ESP32.
",15337142
284,2018-02-06T05:02:05Z,2018-02-06T05:02:05Z,,,This allows to dynamically change the type of an instance.  See #3592 for report about this feature.,15337142
285,2018-01-31T21:27:25Z,2018-02-18T02:02:32Z,,,"See: https://github.com/tralamazza/micropython/issues/122

This translates to this very short sequence (ARM Cortex M0):

```
00007b2c <fabs_funcf>:
    7b2c:       0040            lsls    r0, r0, #1
    7b2e:       0840            lsrs    r0, r0, #1
    7b30:       4770            bx      lr
```

Some background: https://www.doc.ic.ac.uk/~eedwards/compsys/float/nan.html",15337142
286,2018-01-27T14:34:57Z,2018-01-27T14:34:57Z,,,"I have implemented simple font size scaling as `framebuf_text_scaled`

usage from python size x 4
`framebuf.text_scaled('Ab', 0, 26, 4)`",15337142
287,2018-01-25T02:35:33Z,2018-01-25T09:17:54Z,,,"The parser attempts to allocate two large (~512 byte by default) chunks up
front. If it couldn't, then it would error out. This change will
cause it to try allocating half the previous attempt until its down
to two copies. This is ok upfront because later code checks bounds
and tries to extend the allocation if needed.",15337142
288,2018-01-24T20:31:17Z,2020-02-24T11:06:22Z,,,"Enable the addition of heap space at runtime. Advantages:
  - The ESP32 has a fragmented heap so to use all of it the heap must be split.
  - Support a dynamic heap while running on an OS, adding more heap when necessary.

Rewritten PR of #3533. The biggest difference is that multiple heaps support can now be disabled (and is disabled by default) to reduce code size. I hope it is also an more stable as I did the changes after [looking how the memory manager actually works](https://github.com/micropython/micropython/wiki/Memory-Manager#memory-structure).

With this code, I managed to extend the MicroPython heap to ~200kB on the ESP32:

```
MicroPython v1.9.3-241-gfbc575cd1-dirty on 2018-01-24; ESP32 module with ESP32
Type ""help()"" for more information.
>>> import micropython
>>> micropython.mem_info(True)
stack: 752 out of 15360
GC: total: 206976, used: 5200, free: 201776
 No. of 1-blocks: 30, 2-blocks: 7, max blk sz: 264, max free sz: 6936
GC memory layout; from 3ffb30a0:
00000: h=AhhBMh=DhhhDBBBBAhh===h===Ahh==h==============================
00400: ================================================================
00800: ================================================================
00c00: ================================================================
01000: =========================================h==Bh=ShShhThAh=h=Bh==B
01400: ..h.h=......h=..................................................
       (87 lines all free)
17400: ................................................
GC memory layout; from 3ffe4de0:
       (108 lines all free)
1b000: ........................
>>> 
```

This is necessary because by default, the esp32 does not have a contiguous memory area:

```
I (343) cpu_start: Pro cpu up.
I (344) cpu_start: Single core mode
I (344) heap_init: Initializing. RAM available for dynamic allocation:
I (347) heap_init: At 3FFAE6E0 len 00001920 (6 KiB): DRAM
I (353) heap_init: At 3FFDCE60 len 000031A0 (12 KiB): DRAM
I (360) heap_init: At 3FFE0440 len 00003BC0 (14 KiB): D/IRAM
I (366) heap_init: At 3FFE4350 len 0001BCB0 (111 KiB): D/IRAM
I (372) heap_init: At 4008FC7C len 00010384 (64 KiB): IRAM
I (379) cpu_start: Pro cpu start user code
I (172) cpu_start: Starting scheduler on PRO CPU.
```

I have tested using `tests/run-tests` and haven't seen a regression (both on unix and esp32).

Image size changes:

| port | change |
| --- | --- |
| unix | +14
| bare-arm | 0 (unchanged)
| minimal | +20
| stm32 | -116
| esp8266 | +136
| esp32 | +80 (without patch), +432 (with [patch adding multiheap support](https://github.com/aykevl/micropython/compare/multiheap-2...aykevl:multiheap-2-esp32))

I have tried to keep the image sizes unchanged, but some changed anyway for some reason. Maybe the optimizer is less effective on some ports than other ports. Most of these ports (with the exception of bare-arm) jumped around a lot during development, so I'm suspecting it's mostly just an inconsistent optimizer.",15337142
289,2018-01-14T11:17:29Z,2019-01-12T21:58:40Z,,,"android ffi modules require identification of platform as they use a different model.

ffilib.py would load unversionned lib*.so because android are not versionned like linux assumed default.

wasm platform use .wasm files for dlopen()


sys.platform would give ```'android'``` and at REPL:  ```MicroPython v1.9.3-240-ga275cb0-dirty on 2018-01-14; android version```

sys.platform would give ```'wasm'``` and at REPL:  ```MicroPython v1.9.3-240-ga275cb0-dirty on 2018-01-14; wasm version```

use case: https://github.com/pmp-p/micropython-ffigen

android => android

emscripten ( that's just the compiler)  => wasm ( is the standard )",15337142
290,2018-01-06T22:43:20Z,2018-03-12T19:23:55Z,,,"This adds support for 24bit RGB to the framebuf module, called RGB888 (following the naming convention of RGB565). This may be useful for neopixel based displays.

On the ESP8266 port it adds 340 Bytes of flash which is a lot.

Streamlining rgb888, rgb565 and gs8 support into generic functions would actually save flash. I've done this as an [exercise](https://github.com/hoihu/micropython/commits/feat-framebuf-rgb) on a separate branch and it reduced the size by 20 Bytes or 360 Bytes compared to this version. 

But I believe the performance penalty for rgb565 and gs8 was probably too high so I stayed with the existing design pattern.",15337142
291,2018-01-04T17:24:27Z,2018-01-04T17:24:27Z,,,"I needed to make my own ""board"" version of Unix port, so I added this.",15337142
292,2018-01-04T17:17:52Z,2018-01-04T17:17:52Z,,,"This allows boards to override as needed, see #3506 ",15337142
293,2018-01-02T12:47:21Z,2019-11-26T08:59:39Z,,,"The current behavior uses the CPU endianness, which I found surprising:

```
b = bytearray(2)
f = framebuf.FrameBuffer(b, 1, 1, framebuf.RGB565)
f.fill(0xabcd)
print(b)  # bytearray(b'\xcd\xab')
```

I would expect that to result in `bytearray(b'\xab\xcd')`. The RGB565
OLED that I'm using needs the bytes arranged big-endian, so currently
this means pushing the endianness-handling to the user of FrameBuffer.

This commits retains the existing behavior for backwards-compatibility
but adds two new modes `RGB565_BE` and `RGB565_LE` to allow the user
to explicitly set the behavior. The existing `RGB565` will use
whatever the CPU endianness is.",15337142
294,2017-12-30T16:54:15Z,2017-12-30T17:57:34Z,,,"backport of https://github.com/micropython/micropython-esp32/pull/218

- implement WPS support
- implement WLAN.status()",15337142
295,2017-12-27T10:31:53Z,2018-01-04T09:30:26Z,,,"Hello.

This pull requests contains mainly a Makefile and start-code for a bare-metal port of Micropython to the Raspberry Pi along with driver-code for the UART-interface to receive any output from the device. It does not contain additional modules and does not feature any sort of command prompt. 

This port works on the Raspberry Pi Zero (tested) and should also work on the Raspberry Pi 1. It will however probably not work out-of-the-box on the Raspberry Pi 2 or 3, as they feature a different processor. 

If you want to read more, I wrote a term paper [1] about porting Micropython to bare-metal Raspberry Pi (and adding modules to it).

[1] https://www.stefannaumann.de/en/2017/12/porting-micropython-to-bare-metal-raspberry-pi-2/

Regards,
Stefan Naumann",15337142
296,2017-12-26T11:28:06Z,2019-12-17T06:29:48Z,,,"Some fields will have undefined data otherwise, possibly leading to problems later on.

I discovered this potential problem while working on https://github.com/espressif/esp-idf/pull/1378. I don't have the actual hardware to test it, though, but initializing `network.LAN` works.",15337142
297,2017-12-20T16:26:08Z,2018-03-31T07:57:23Z,,,"- introduce new port config value, a macro: `MICROPY_HW_UARTn_IS_HALF_DUPLEX(n)`
- if true for a specific port, we call a different HAL init function that configures HALF duplex mode

`ports/stm32/mpconfigport.h`: provide a default value (False) for the macro
`ports/stm32/uart.c`: implement the change and provide readback

This change should be have no size impact to boards not using this feature. I didn't make it runtime configurable, but that could be a useful addition for some users.",15337142
298,2017-12-14T02:28:18Z,2018-09-17T14:43:28Z,,,"Implementation of hardware I2S for the ESP32.

This appears to be the first I2S implementation for MicroPython. I've followed the proposed [I2S `machine` API](https://github.com/micropython/micropython/wiki/Hardware-API#the-i2s-class) mostly, but did not follow it exactly. This is the current API / example code:

```python
import machine
i2s = machine.I2S([0,] bclk=4, ws=15, data_out=2, data_in=22, [samplerate=48000,] [bitdepth=16])
buffer = ... # generate sine wave or something
while True:
    i2s.write(buffer)

# also implemented
i2s.deinit()
i2s.init(...) # throws an error if initialized already
```

Not yet implemented, mostly due to lacking hardware:

 * communication format, e.g. MSB/LSB.
 * clock: the ESP32 has an APLL clock, but I'm not sure what it's purpose is
 * callbacks (for now, `i2s.write()` blocks if the buffer is full)
 * reading from the I2S bus
 * not setting the `data_in` pin (not sure if this is possible)
 * [change parameters](https://esp-idf.readthedocs.io/en/latest/api-reference/peripherals/i2s.html#_CPPv211i2s_set_clk10i2s_port_t8uint32_t21i2s_bits_per_sample_t13i2s_channel_t)
 * stop/start (without deinit) - by default it keeps looping existing data if the buffer isn't filled fast enough
 * internal ADC

Which of these (if any) should be implemented before it can be merged?

Documentation: https://esp-idf.readthedocs.io/en/latest/api-reference/peripherals/i2s.html",15337142
299,2017-11-13T22:08:06Z,2019-10-22T10:15:00Z,,,"The ""help"" module is disabled by default for the UNIX port, making it
difficult to explore the available modules (e.g. via the use of the
""help('modules')"" call).  This change enables it by default.",15337142
300,2017-11-07T17:24:09Z,2017-11-12T14:31:47Z,,,"The existing client handshake implementation is non-compliant with RFC6455
Sections 1.3 and 4.1, and is only sufficient for use with the existing server
handshake implementation.  This change increases the client handshake's
compliance with the RFC by fully supporting the ""Sec-WebSocket-Key"",
""Sec-WebSocket-Protocol"", ""Sec-WebSocket-Version"", and ""Sec-WebSocket-Accept""
HTTP headers.  The value of the ""Sec-WebSocket-Protocol"" response header is
returned to the caller for further handling.  To minimize the code footprint,
if a server returns a ""Sec-WebSocket-Accept"" response header and it has the
expected value, it is assumed that the HTTP connection has been successfully
upgraded to a websocket connection.  Other aspects of the HTTP response are
not validated (i.e. the response code, the ""Upgrade"" header, and the
""Connection"" header).",15337142
301,2017-11-05T04:35:25Z,2017-11-09T17:28:46Z,,,"This doesn't fix #2659, but it should make things less confusing by only catching exceptions that are raised when WebREPL isn't configured. ImportError is raised if webrepl_cfg.py doesn't exist, NameError is raise if it does exist but it doesn't contain the variable PASS.",15337142
302,2017-11-03T21:17:03Z,2018-01-19T07:57:10Z,,,"This patchset improves the support for the SSD1306 displays: the previous version used I2C ops available only on ESP8266, and as some of the I2C display modules have reset pin (but apparently not all of them), we also add optional support for it here. Finally now there is a test/demo script with some comments about wiring to show example about the usage of the driver.",15337142
303,2017-11-03T13:24:03Z,2017-11-16T00:32:17Z,,,"with a typical setup of 100 ws2812 leds in one strip,
this C implementation gives me a performance boost of about 35x.
it should be a pretty much compatible drop-in replacement for the
current python implementation.
works e.g. with the code from the ESP8266 NeoPixels tutorial.",15337142
304,2017-11-02T18:31:56Z,2017-11-05T10:25:19Z,,,Also some typo fixes.,15337142
305,2017-11-02T05:47:21Z,2017-11-05T18:28:17Z,,,"This change adds websocket client support as per RFC6455.  Section 5.1 states
that a websocket client must mask all frames that it sends to the server.
Further, section 5.3 states the masking key is a 32-bit value chosen at random
by the client unique to each frame.  These requirements are now implemented.
A non-compliant debug mask is also supported, allowing control of the masking
key.",15337142
306,2017-10-30T16:48:30Z,2019-10-29T06:15:21Z,,,"LPC port. Initial commit for LPC43xx support over educational board CIAA-NXP.

This PR clean the board initialization code populating `board.h` interface with common functions for all boards of the port. Additionally, It enable some basic uPy modules like ure, sys, gc, etc.

The next plan is to add support to [micromint lpc43xx boards](http://www.micromint.com/component/content/article/53-products/products/199-bambino210.html) and similars.

prev work: #3354
@ezequielgarcia some comments?
@RockySong The support of lpc541xx/lpc546xx is in my roadmap and in the future, the support of iMX-RT. Some suggestions to integrate your work? what is your rouadmap?
",15337142
307,2017-10-28T19:18:50Z,2017-10-28T19:40:39Z,,,,15337142
308,2017-10-28T14:52:30Z,2019-02-19T15:08:51Z,,,"__new__() method is present by definition in each class, because each class
inherits from ""object"". But due to effects of multiple inheritance and
subclassing native types, looking it up is tricky: object.__new__ should
be the last choice, if a more specific version is found (in one of multiple
bases, or in native type), that should be used.

This patch implements this behavior by wrapping existing attribute lookup
function, and looking inside ""object"" only if the otiginal function doesn't
find anything. This relies on ""object"" not being present explicitly in the
base class chain (otherwise multiple inheritance case will be broken -
object.__new__ will be found while following the very first inheritance
branch, while other branches may have more specific __new__).

This also leads to additional stack usage on each lookup due to extra
function call.",15337142
309,2017-10-21T12:16:05Z,2018-08-04T13:49:09Z,,,"These methods allow read/write binary packed data directly from/to
streams. That's quite a popular paradigm, and many programming
languages/libraries use that (Java, Node.js, Android, etc.) Python
doesn't support that natively, but such support would allow to implement
parser for complex binary structures with low memory overhead, which
would be beneficial for MicroPython.",15337142
310,2017-10-20T07:30:35Z,2019-12-13T01:40:37Z,,,"This PR is work-in-progress and the main aim is to begin incorporating the lwIP stack into the stm32 port, along with ussl and other networking components.

As a proof-of-concept in uses the Wiznet Ethernet module in MACRAW mode which allows to send and receive raw Ethernet frames.  This send/recv is hooked into the back of lwIP so that the TCP/IP stack is provided by lwIP itself (as opposed to the internal TCP/IP stack in the Wiznet module).

The benefits are that the Wiznet module now supports the full socket module interface and behaves exactly the same as esp8266.  The downside is reduced TCP throughput because the Wiznet doesn't have large enough Ethernet buffers to buffer the incoming frames before they get processed by lwIP.  But the performance loss is not that bad (roughly a third of the throughput) and the benefits outweight the reduced performance.

The PR also enables the ussl module for stm32, and adds some useful modules to the frozen bytecode.  The Wiznet W5500 chipset is enabled by default but can be changed to W5200 in stm32/mpconfigport.mk.

upip, urequests and uasyncio are all tested to work and are included in the frozen bytecode.

There is a script stm32/wiznet_connect.py which shows how to bring up the network.",15337142
311,2017-10-15T12:45:51Z,2017-10-16T13:33:06Z,,,"Continuation of #3310

py/mkenv.mk: Select whether to add .exe dependant of Target OS instead
    of Host OS
    This allows Windows port to be cross compiled under Linux and
    build micropython.exe to run under Windows. Fixes #3361.

py/mkrules.mk: Fix rule to build mpy-cross / mpy-cross.exe.

windows/Makefile: Add a default CROSS_COMPILE for Windows port.
                  Move PROG and CROSS_COMPILE before #include mkenv.mk

mpy-cross/Makefile: Move PROG before #include mkenv.mk

tools/mpy_cross_all.py: pass full mpy-cross path/name including .exe
    as argument from makefile. Use $(MPY-CROSS) from mkenv.mk.
    Convert slash to backslash for Windows cmd.

Document how to install and build with MSYS2 / Mingw under Windows.
Update README.md and windows/README.md for changes above.

With these changes all programs (mpy-cross and micropython.exe) and all
    Makefiles will run from a Windows cmd prompt. They don't need to be
    run from the MSYS cmd shell. Requires MSYS2 and Mingw to be
    installed as documented in the README.md files.",15337142
312,2017-08-07T20:19:13Z,2017-08-25T23:08:13Z,,,"This is my attempt of an ""API compatible"" sensor driver which may serve as a discussion base for #3218. It's a dual sensor device that measures humidity and temperature and can be configured in various ways. It has even an in-built heater. I believe it serves as a good test and discussion base for the new API. The datasheet is located here http://www.st.com/en/mems-and-sensors/hts221.html. 

The HTS221 sensor is present on the SenseHat board for the raspberry Pi (which can be easily reused to work with the pyboard).

The driver supports fixed and floating point targets, with the conversion functions that was proposed in #2093. I specifically paid attention to the precision of the output values (e.g. so that temperature are not returned with 10 digits precision). 

The buffer is preallocated in the constructor, so that during runtime there should be no memory allocation necessary.

I have not completly followed the guidelines in #2093, for the following reasons:
- the `fixed`statement that was proposed to be present for every `get_xxx`accessor method is replaced by an equivalent argument for the constructor of the driver (hence the method definiton is slightly shorter). This makes sense, since the user hardly wants to use both fixed and floating point support of the same driver for a given Platform
- the `get_temperature`and `get_humidity`accessor functions are included (not inherited from a `Sensor Base` class) since this allows introspection at the REPL and in general makes the code more readable IMO
-  I omitted the generic `config` method and just used e.g. a `set_heater`function - for the same reasons given above
 
The reasoning above is of course subject for discussing and just my point of view. Any feedback is very much welcome. I will upgrade my other drivers for the SenseHat once the Sensor API is considered stable.",15337142
313,2017-08-03T16:49:45Z,2017-08-03T19:26:48Z,,,"This PR is the result of a discussion in #2971. I've tried to keep the API as similar as possible to other peripherals such as SPI or I2C. The result is:

```python
Timer(id, period=val, mode=Timer.PERIODIC, irq=handler) # constructor
Timer.init(period=val, mode=Timer.PERIODIC, irq=handler) # reinitialise all parameters
Timer.start() # start timer
Timer.stop() # stop timer
Timer.period([period]) # get the period/set new period
```

Usually the other peripherals include a `deinit()` method, but in this case, I found it reasonable to call it `stop()`.",15337142
314,2017-07-07T12:45:54Z,2017-11-04T09:16:42Z,,,"`os.listdir` is more standard than `os.ilistdir` (https://docs.python.org/3/library/os.html, https://docs.micropython.org/en/latest/pyboard/library/uos.html), and for example implemented on the esp32, so it'd be nice to have it in the unix tree as well.",15337142
315,2017-07-01T09:23:46Z,2017-10-28T10:10:57Z,,,"Added a flag definition in modbtree
Added a test tests/extmod/btree_dup.py
modified btree.rst to describe duplicate key

The test actually triggers a coredump due to berkeleydb bt_delete design error (see gdb backtrace)
The issue and correction patch is reported https://github.com/pfalcon/berkeley-db-1.xx/issues/1

The correction will be provided in the next commit.

The dbm class used in the test is a candidate to be in dbm module in micropython-lib

Here is the gdb backtrace
gdb micropython
set args ../tests/extmod/btree_dup.py
run
bt
#0  0x00007ffff7173fff in ?? () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007ffff716e3be in ?? () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x0000000000458622 in __bt_dleaf (t=0x694040, key=0x7fffffffd520, 
    h=0x6954b0, index=0) at ../lib/berkeley-db-1.xx/btree/bt_delete.c:504
#3  0x0000000000457f3f in __bt_bdelete (t=0x694040, key=0x7fffffffd520)
    at ../lib/berkeley-db-1.xx/btree/bt_delete.c:317
#4  0x00000000004576d0 in __bt_delete (dbp=0x6942d0, key=0x7fffffffd520, 
    flags=0) at ../lib/berkeley-db-1.xx/btree/bt_delete.c:89
#5  0x0000000000456222 in btree_subscr (self_in=0x7ffff6f918e0, 
    index=0x7ffff6f91c40, value=0x0) at ../extmod/modbtree.c:258
#6  0x0000000000428ae3 in mp_obj_subscr (base=0x7ffff6f918e0, 
    index=0x7ffff6f91c40, value=0x0) at ../py/obj.c:448
#7  0x0000000000445504 in mp_execute_bytecode (code_state=0x7fffffffd650, 
    inject_exc=0x0) at ../py/vm.c:473
#8  0x000000000042e871 in fun_bc_call (self_in=0x7ffff6ee7880, n_args=2, 
    n_kw=0, args=0x7fffffffd7d0) at ../py/objfun.c:269
#9  0x00000000004245f6 in mp_call_function_n_kw (fun_in=0x7ffff6ee7880, 
    n_args=2, n_kw=0, args=0x7fffffffd7d0) at ../py/runtime.c:600
#10 0x000000000043cd48 in instance_subscr (self_in=0x7ffff6f8c3a0, 
    index=0x7ffff6f91a00, value=0x0) at ../py/objtype.c:720
#11 0x0000000000428ae3 in mp_obj_subscr (base=0x7ffff6f8c3a0, 
    index=0x7ffff6f91a00, value=0x0) at ../py/obj.c:448
#12 0x0000000000445504 in mp_execute_bytecode (code_state=0x7ffff6f8c300, 
---Type <return> to continue, or q <return> to quit--- 
    inject_exc=0x0) at ../py/vm.c:473
#13 0x000000000042e871 in fun_bc_call (self_in=0x7ffff6ee7660, n_args=0, 
    n_kw=0, args=0x7fffffffdb00) at ../py/objfun.c:269
#14 0x00000000004245f6 in mp_call_function_n_kw (fun_in=0x7ffff6ee7660, 
    n_args=0, n_kw=0, args=0x7fffffffdb00) at ../py/runtime.c:600
#15 0x0000000000445a96 in mp_execute_bytecode (code_state=0x7fffffffdad0, 
    inject_exc=0x0) at ../py/vm.c:941
#16 0x000000000042e871 in fun_bc_call (self_in=0x7ffff6ee7580, n_args=0, 
    n_kw=0, args=0x0) at ../py/objfun.c:269
#17 0x00000000004245f6 in mp_call_function_n_kw (fun_in=0x7ffff6ee7580, 
    n_args=0, n_kw=0, args=0x0) at ../py/runtime.c:600
#18 0x0000000000424533 in mp_call_function_0 (fun=0x7ffff6ee7580)
    at ../py/runtime.c:574
#19 0x00000000004524e3 in execute_from_lexer (source_kind=3, 
    source=0x7fffffffe2df, input_kind=MP_PARSE_FILE_INPUT, is_repl=false)
    at main.c:144
#20 0x0000000000452743 in do_file (
    file=0x7fffffffe2df ""../tests/extmod/btree_dup.py"") at main.c:296
#21 0x000000000045351b in main_ (argc=2, argv=0x7fffffffdf68) at main.c:612
#22 0x0000000000452b2e in main (argc=2, argv=0x7fffffffdf68) at main.c:418
",15337142
316,2017-05-23T20:51:42Z,2018-05-03T03:28:06Z,,,"I noticed a common code pattern for walking the elements of a map, saw a helper function specific to `mp_obj_dict_t`, and decided to generalize it for all maps.  See issue #3105.

I have only made changes to core files, but this should work for `extmod/moductypes.c`, `extmod/moduselect.c`, and `esp8266/modnetwork.c` as well, and I can update them for this pull request if desired.",15337142
317,2017-05-07T06:43:35Z,2017-09-21T01:36:02Z,,,"I noticed that esp8266 has a promiscuous mode.So I use this mode to write a sniffer function.This function sniffs the mac address of the device that is linked to the specified device.

#### Function definition:
>class wlan.network.sniffer(mac=*, ch=1, timeout=1)
>[(source mac, dest mac, Number of packets captured)]

#### Example:
```python
>> import network
>> ap = network.WLAN(network.AP_IF)
>> ap.active(False)  #First: Close AP mode
>> sta = network.WLAN(network.STA_IF)
>> sta.active(True) #Second: Open STA mode
>> sta.scan() #Scan all AP
[(b'Drone', b'\xa8\x15M@\xe98', 1, -35, 4, 0), (b'EXCEL', b'\x0cr,x\x88\xc0', 1, -62, 4, 0), (b'ics543', b'$ih\x8f\x8c\x8e', 1, -56, 4, 0), (b'ics542', b'\xa8\x15M\xe7\n\xf8', 1, -60, 4, 0), (b'TP-LINK_15C4', b'\xd0\xc7\xc0\x84\x15\xc4', 1, -57, 4, 0), (b'Jedi', b'\xd4\xee\x07\x15D\xd6', 1, -72, 4, 0)]
>>> sta.sniffer(mac= b'\xa8\x15M@\xe98', ch=1, timeout=10) #sniffs specified device 10s
[(b'\xa8\x15M@\xe98', b'\x8cpZ\xeeL`', 84), (b'\xa8\x15M@\xe98', b'`\x834\xbd\xf5:', 1)]
```
",15337142
318,2017-04-27T20:54:18Z,2017-06-24T14:34:13Z,,,"The wfi instruction puts the CPU into sleep mode unconditionally which means that it will go to sleep even if there is a pending interrupt. the result is that in some cases, pending interrupts will not be seviced until some other event wakes the CPU. Wfe on the other hand, does not put the cpu to sleep if there is a pending interrupt. So in most cases it is safer to call wfe instead of wfi.

It can be verified with the following code. It is simply a loop that wait for a timer interrupt to happen. Timer 2 is only used to measure the number of 10s of us that elapses between the interrupt and the execution of the main contents of the loop. Running this will eventually result in a maximum delay of 1ms. I guess that the situation is saved by the systick. Replacing pyb.wfi() with pyb.wfe() results in a maximum delay of 40 us even after an longer period of execution.

```python
import pyb
import gc
from pyb import Pin

flag = False
t1 = 0
t2 = 0

pin = Pin('X1', Pin.OUT_PP)
#10us
tim2 = pyb.Timer(2, prescaler=840, period=0x3FFFFFFF)
tim4 = pyb.Timer(4, freq=12)

def cb(t):
    global flag
    global t1
    t1 = tim2.counter()
    flag = True    

tim4.callback(cb)
tmax = 0
print('start')
while True:
    if not flag:
        pin.low()
        pyb.wfi()
        #pass
        pin.high()
    else:    
        t2 = tim2.counter()
        flag = False
        #t2 = tim2.counter()
        diff = t2-t1
        if diff > tmax:
            tmax = diff
        print(diff, tmax)
        gc.collect()

```
",15337142
319,2017-04-21T06:06:33Z,2019-10-18T02:17:04Z,,,"The aim of this tool is to allow easy and rapid development of programs that run on pyboards (in the general sense, ie anything that runs MicroPython and has a REPL available via a serial port).

The main feature is that the host PC's filesystem is mounted on the target pyboard.  This is kind of reverse to what @dhylands' rshell currently does (and also mpfshell and ampy).  Essentially the PC becomes a (huge) filesystem on the pyboard (with data coming in over the serial connection) and all filesystem commands work transparently.

Using the tool is very easy: you just run it and optionally specify the serial port to connect to.  Then you get a normal REPL running directly on the board, just like with picocom/miniterm/etc.  But before you get access to the REPL a script is run on the pyboard which installs a hook in the pyboard's filesystem so that the pyboard has access to the PC's filesystem (the directory that you run the tool from).

So at the REPL if you do `os.listdir()` you'll see the contents of the PC's current directory.  You can also stat and open and read and close files.

Ultimately this can be extented to allow you to *import* scripts from your PC without ever copying them to the pyboard.  This would allow for very fast workflow to develop an entire program on your PC and run it on the pyboard without ever copying any scripts.

This tool is currently only a proof-of-concept and there are a few things that need to be implemented on the firmware side before everything works (eg importing doesn't yet work).",15337142
320,2017-02-28T11:26:24Z,2017-06-24T14:34:12Z,,,"This PR is mostly copied code from the cc3200 Launchpad port of micropython as the hardware is basically the same (1MB Flash at least, but lots of sensors attached via I2C). Not sure what to make of the pin.csv as i have yet no schematic at hand to label them as DP[0-12] so the old ones were kept. The ""fix"" in the bootloaders main is due to the fact that the the ""Power"" button Sensortag has inverted levels but is probably the nicest solution if no Debugger DevPack is attached (any better fix is welcome).

For those that got their hands on one: Attach a Debugger DevPack to the Sensortag (break out the protector over the JTAG first). SOP2 is on DP3 on the Debugger DevPack pin header and can easily be shorted to VDD on the same connector to enter ""flash"" mode. Now press reset on the Debugger DevPack and flash as you would the Launchpad (Uniflash or cc3200tool).

According to the schematic of the Debugger DevPack it should be possible to flash without shorting out anything, but as of yet TI has not released any amount of documentation.

As for pins:
GP11=power button
GP4=user button
GP10=green led
GP23=red led
i2c pins GP13,GP12",15337142
321,2017-02-24T17:38:01Z,2017-06-24T14:34:12Z,,,"This PR adds to the ESP8266 tutorial instructions on how to enter programming programming mode.
",15337142
322,2017-02-06T23:37:33Z,2017-06-24T14:34:11Z,,,Based on #1757 PR,15337142
323,2016-12-29T01:52:54Z,2019-11-21T06:50:34Z,,,,15337142
324,2016-12-20T22:49:23Z,2017-06-24T14:34:10Z,,,"If the high speed external oscillator fails/glitches, this patch will restart the board in an attempt to recover. Without this patch, in my testing the board hangs indefinitely (or at least longer than I bothered to measure!)

Board runs on internal oscillator to process the callback for this event.

Resolves #2683 ",15337142
325,2016-11-21T18:56:51Z,2017-06-24T14:34:10Z,,,,15337142
326,2016-11-14T22:47:37Z,2018-04-17T13:34:26Z,,,"**This PR adds support for :snowman: Frosted :snowman:**
Please comment on this pull request and/or consider for inclusion upstream.

Frosted (https://github.com/insane-adding-machines/frosted) is a Free embedded OS providing POSIX calls. 

For this reason, this initial port has been initially based on the existing UNIX port. The idea is to extend the support later on to have full working sockets and threads.

- minimal configuration compiles and works fine
- `sys` module OK
- `usocket`/`socket` modules loading fine, with still some minor glitches to fix (Allocation on `socket.bind()`)

How to test:
- grab the latest arm-frosted-eabi- toolchain from https://github.com/insane-adding-machines/crosstool-ng/releases/latest - or compile it yourself starting from [this repository](https://github.com/insane-adding-machines/crosstool-ng)
- go to the frosted directory and type `make`
- include the resulting flat binary `micropython` onto your board xipfs",15337142
327,2016-11-08T20:59:23Z,2017-06-24T14:34:09Z,,,"see also https://github.com/esp8266/Arduino/issues/1624

not knowing about the issues of AP_IF when STA_IF is scanning was failing a demonstration... let's save other people from embarrassment ;-)",15337142
328,2016-10-16T00:00:20Z,2017-06-24T14:34:08Z,,,"This assumes that PR #2519 has been applied
",15337142
329,2016-10-15T22:13:18Z,2017-06-24T14:34:08Z,,,"This adds support for the sdcard, which will be mounted as /sd if a card is plugged in when booting.
",15337142
330,2016-10-13T19:34:30Z,2017-06-24T14:34:08Z,,,"- Updates the core directory to the latest
- Introduces a boards subdirectory similar to stmhal
- Adds modmachine
- Adds TEENSY_3.5 and 3.6
- Adds uart support
",15337142
331,2016-10-13T10:13:08Z,2017-06-24T14:34:08Z,,,"If an esp8266 wants to connect to many, many different networks over its lifetime,
writing the config to the same location in the flash each time will wear it out and significantly
shorten the device life.

I have bricked only 1 esp-12 module so far doing this :)

This patch adds an extra parameter to the connect() function, save_to_flash, which defaults to true, so it's backwards compatible.

I don't know why there were previously up to 5 optional ignored parameters to connect(), they were never documented but are gone now.
",15337142
332,2016-09-09T11:40:17Z,2017-06-24T14:34:07Z,,,"I added ""errno"" as an alias for args[0] for exception objects with baseclass OSError in similar fashion to how StopIteration gets ""value"".
",15337142
333,2016-08-01T01:01:16Z,2017-06-24T14:34:07Z,,,"This is based on esp8266 implementation. Is this also correct for wipy?

Is the wipy `duty()` range 0-1023 or 0-10000?

Is that line about `all pins except Pin(16)` valid for wipy?
",15337142
334,2016-07-23T04:40:20Z,2017-06-24T14:34:06Z,,,"This adds proper locking for the serial port on linux and OSX.

If a program like picocom or minicom has the serial port open and you try to run pyboard, you'll now get an error message.
",15337142
335,2016-07-17T21:19:52Z,2017-06-24T14:34:06Z,,,"This patch changes the way `MICROPY_BUILD_DATE` is set so that it
defaults to the date of the last commit in a clean code tree instead of
always using today's date.  Optionally it can also extract version data
(minus the commit hash) from _CHANGELOG.txt_ if this file is tracked in
git as part of the release process in the future.

This should provide more deterministic builds as discussed in #2161.

If the code tree is dirty at the time of the build, the build date is
always set to today's date.  This is the same as the current behavior.

In case git(1) is unavailable, the patch falls back to extracting
version data from _CHANGELOG.txt_ (provides git tag, date of last
commit).  This file is currently not tracked in git but can be generated
with `tools/gen-changelog.sh`.  This tool however depends on git(1) so
it's mostly useless unless CHANGELOG.txt is included in git and updated
as part of the release process.  Git's RFC2822 date is parsed with the
`email.utils` module which is available since Python 2.5, and works in
Python 3 too.

When _CHANGELOG.txt_ is missing it falls back to extracting version data
from `docs/conf.py`.  This file only contains the git tag as part of the
_release = x.y.z_ directive, so the build date is therefore set to
today's date (no change from current behavior).
",15337142
336,2016-06-06T12:49:15Z,2017-06-24T14:34:06Z,,,"This is not yet styled according to the guidelines or feature complete, more of a proof of concept that I'd like some feedback on.

As https://github.com/micropython/micropython/pull/1884 ran into the issue that byte code is assumed to be correct, this will first compile any input (making the fuzzer slower of course) and then execute the result. The benefit is that the compiler is fuzzed too, the downside is the slowdown due to compilation. It is however possible to write a second fuzzer with the same instrumentation to explicitly fuzz just bytecode.

ASAN and UBSAN do really not like your code as your memory management is more ""hands-on"" and I have to research more into what checks to disable to still make them trigger on useful errors. For now, only LSAN is enabled.
I also likely did stuff horribly wrong in python_fuzzer.cc (e.g. not setting up sys.argc/sys.argv properly) and it would be great if someone could look over it and tell me where I'm wrong or how to improve.

The basic idea of libfuzzer is to provide some random bytes that then get used as input by whatever is being fuzzed. Similar to AFL, libfuzzer then will check which parts of the code were active in processing the input and then modify it accordingly, creating the next input.

It is possible to bootstrap the fuzzer using the existing test cases, at the moment I seem to fail a couple of them on my machine though, so the more radical approach of just letting the fuzzer figure out the whole syntax on its own is used.

Unlike AFL, libfuzzer will stop once a timeout or crash is reached. The -jobs parameter decides how many such fragments will be collected until the process ends. Timeouts will happen frequently while fuzzing randomly mutated input into a programming language, since already the small program ""9**99999"" will run for quite a while.

""make consolidate"" will run over the existing corpus and reduce it to useful test cases, so if you later provide test cases with very high coverage manually, you can still keep using fuzzed results but will get rid of a lot of tiny noisy test cases.

""make coverage"" should in the future generate a html report similar to lcov. Maybe it might be a better approach to just build an actual gcov enabled binary and do ""proper"" coverage reporting with lcov, I didn't find a lot of eye candy options for sancov, also the html stuff is a relatively new feature.

Looking forward to your comments! :)
",15337142
337,2016-05-28T09:27:23Z,2017-06-24T14:34:06Z,,,"This PR adds a ""port"" with the following features:
- convert uPy source to add a custom prefix to all functions
- convert uPy source to add the state structure as the first argument to all functions
- amalgamate uPy source into a single .c and .h file
- build libmicropython.a from the amalgamated source
- provide a simple embedded example

The outputs are:
- upy.c and upy.h: a completely self-contained distribution of the core+extmod components
- libmicropython.a: just a compiled versionu of upy.c (with specific options from mpconfigport.h)
- embed: a demo, built from embed.c and libmicropython.a
",15337142
338,2016-05-28T01:09:32Z,2017-06-24T14:34:05Z,,,"Build and install library and pkg-config file on `make install`

Allows one to keep separate micropython and ones own code when embedding micropython on unix. 
",15337142
339,2016-05-26T14:58:54Z,2017-07-22T14:22:04Z,,,,15337142
340,2016-05-07T00:27:38Z,2017-07-22T14:22:26Z,,,"The beginnings of an re-implementation of the RC switch library. I've seen a number of other people yearning for this, as was I. I'll keep working on it, but I hope by starting this off, hopefully others who have been eager for it will help get the library more fleshed out. 
",15337142
341,2016-02-15T08:05:54Z,2017-06-24T14:34:04Z,,,"On slower processors, (like the 401) sending large blobs of python to the raw-repl can result in dropped characters. Allowing the timeout to be increased allows this to be addressed.
",15337142
342,2016-01-25T01:37:30Z,2018-10-02T09:37:41Z,,,"What I have coded so far seems to be working, although it needs some more testing. The next step after this is to hook up zipfiles into the import mechanism so that you can add a zipfile to sys.path.

Part of this adds mpfile.c/.h which gives a nice C API for accessing files or ""file-like"" objects. For example, a python script contained within a zipfile would be read using a ""file-like"" object (in particular an instance of the ZipExtFile object). File-like objects could also be written in python (see the ByteFile class in tests/extmod/zipfile1 for an example).

Using mpfile, it would allow us to remove the os-specific lexers and instead create an mp-file based lexer.

To support importing from a zipfile, I think that I need to extend mp_raw_load_code_load_file and mp_lexer_new_from_file to support reading from a file or file-like object.

Using a compressed zipfile typically doubles the effective amount of storage that you have, and it also eliminates the average 256 bytes that are wasted per file on the regular filesystem.

On the unix build, this adds about 5.3K and on stmhal it adds about 2.4K

I've coded this so that it should work on a big-endian MCU, but I don't have anything to test it on.

One caveat to be aware of is that uzlib doesn't seem to support partial decompressing (or streaming), so the code needs to allocate enough memory for both the compressed and uncompressed data. The compressed data is freed as soon as the decompression is done.
",15337142
343,2016-01-20T15:51:12Z,2017-06-24T14:34:03Z,,,"tried to resolve some todos from the spi module:
- added missing documentation of already implemented options (nss, dir)
- added constants for direction (dir) and slave select (nss) options
- updatet spi unit tests
- printout of dir and nss options

adds 348 bytes - mainly due to the printout (may be simplified or optimised)
",15337142
344,2015-11-07T19:23:53Z,2017-06-24T14:34:02Z,,,"This is the pull request for making the memory manager more pluggable -- i.e. separate the gc from the heap manager to allow advancements on both separately.

This is part of the solution for #1168 and is a rework of several PR attempts:
- #1234
- #1320
- #1321

This PR attempts to consolodate the advice from those failed PR's and make a change that is as minimally invasive as possible to the existing code base and meets the coding guidlelines as much as possible.

The pull request uses the existing infrastructure to allow each build to select which garbage collector implementation it wants, either the original or the ""basic"" as the pluggable versions are being called. Eventually more gc implementations will be added, the next planned one is one that simply uses unix's malloc/free.

In addition, an `astyle.fmt` file has been added to the `tools/` directory that should define a fair number of micropython's coding conventions so that new contributors can automatically get their code formatted correctly and painlessly. This file may be a work in progress.
",15337142
345,2015-11-06T04:40:21Z,2017-06-24T14:34:01Z,,,"The CC3200 used in the WiPy boards supports WPA-Enterprise with 802.1x authentication but this functionality is currently not exposed in the Python API.  This PR takes a stab at fixing that by extending `WLAN.connect()` and adding a bunch of new class constants.

Size changes as reported by `arm-none-eabi-size` for a release build of git master (af3e4541) vs. this PR for WPA-Enterprise support (7690423d)

| branch | text | data | bss | dec | hex | filename |
| --- | --- | --- | --- | --- | --- | --- |
| git master | 184840 | 1208 | 76096 | 262144 | 40000 | build/WIPY/release/application.axf |
| wpa-enterprise | 185416 | 1208 | 75520 | 262144 | 40000 | build/WIPY/release/application.axf |
|  | +576 |  | -576 |  |  |  |

I have some reservations about what the best way is to implement support for the additional 802.1x parameters, hence the RFC.

Using the current Python API for the WiPy board, connections to networks may be established like this ([docs here](http://micropython.org/resources/docs/en/latest/wipy/library/network.html#id7)):

``` python
wlan = WLAN(mode=WLAN.STA)
# Prototype: wlan.connect(ssid, *, auth=None, bssid=None, timeout=None)
wlan.connect('Free WiFi SSID')
wlan.connect('my-home-ssid', auth=(wlan.WPA2, '1234567890'))
```

With this patch I've simply extended the tuple in the `auth` kwarg to expect five items when `WLAN.WPA_ENT` is used in `wlan.connect()`.  Example:

``` python
wlan.connect(WLAN.WPA_ENT, auth=(
      'enterprise-ssid-802.1x',  # SSID
      'username',                # Identity
      'password',                # Password
      'anonymous ID',            # Anonymous identity (may be: None) 
      WLAN.EAP_PEAP0_MSCHAPv2    # EAP phase 1 and 2 methods (details: drivers/cc3100/inc/wlan.h)
))
```

I'm not entirely happy with a long list of unnamed arguments, where the second one is also not of the same kind (identity vs. key) as in the other security protocols supported.  Feedback is welcome on how to make this API friendlier.

Additionally, I included QSTRs for all of the EAP authentication methods the CC3100/CC3200 support, which add to the code size.  In practise, I guess the most popular mechanisms are EAP-TLS (client certs) and PEAPv0/EAP-MSCHAPv2 (common in the Windows world), so it would be possible to trade a few bytes for less flexibility.
",15337142
346,2015-09-15T20:05:06Z,2017-06-24T14:34:00Z,,,"Hello. The purpose of this commit is to create the Altera nios2 processor port.
This family of processors use a soft-core architecture (FPGA based).
",15337142
347,2015-05-11T10:07:15Z,2020-01-17T21:37:43Z,,,"This PR adds initial support for the [RIOT](https://github.com/RIOT-OS/RIOT) operating system.

RIOT is a nice, portable, small but feature rich OS for small embedded devices, with small meaning from 4k RAM and up. The focus is on IoT applications, with a full-featured IPv6/6LoWPAN/RPL/... network stack nearing completion. It runs on 8bit, 16bit and 32bit platforms, sporting an O(1) preemptive scheduler, fast IPC and syncronization and nicely abstracted hardware support.

This port has been PRed for integration in RIOT as https://github.com/RIOT-OS/RIOT/pull/2968. (Update: merged)

~~It cannot do much as no library has been ported.~~

TODO:
- ~~there's a bug that eats the parentheses when entering ""help()"" on upy's command line. But e.g., ""print()"" works fine. don't know why. (works fine on RIOT's native linux port)~~ (seems to be pyterm related)
- ~~the garbage collector doesn't consider register contents, so it will probably not work correctly~~ fixed
- there needs to be either a mapping for riot C libs -> micropython libs or an adaption of micropythons ""pyb."" lib

This PR contains some cleanup commits:
- one for accepting both 0xa and 0xd as newline for readline, needed to support our native port's console input
- one that fixes obobject.c when not using `MICROPY_CPYTHON_COMPAT` (a .locals_dict had a broken definition when setting that flag)
- one that changes a function pointer from void\* to void(*)(void) to make it ISO C
- one to make mp_binary_get_size unsigned as otherwise later comparisons trigger a sign-compare warning
",15337142
348,2020-02-16T00:17:43Z,2020-03-17T06:06:27Z,,,"I ran the editor for over eight hours, no crashes.
Ran a bunch of Python scripts. Nothing seemed to be broken.

OS: Windows 10
Python: 3.6.0",65116537
349,2019-12-18T05:40:26Z,2020-01-10T22:21:57Z,,,"Most changes are simple. I also changed methods that have deprecation warnings. Disabled the following functions

py_ue_fmenu_builder_add_asset_actions
The menu build system has been refactored.  Needs more work to figure out how to port this correctly.

py_unreal_engine_reload_blueprint
Reload functionality has been removed from the engine.
",65116537
350,2019-10-29T12:12:01Z,2019-10-29T12:12:01Z,,,,65116537
351,2019-10-05T06:26:32Z,2019-10-09T04:53:22Z,,,These snippets were crashing Unreal for me. Adding .clone() fixed it. Found the solution from issue #77,65116537
352,2019-07-02T14:39:02Z,2019-07-02T14:39:02Z,,,"If a component is removed and then re-added with the same name this
will cause a crash since the old name will still be in use. Copied
the node removal code from the editor to add renaming to avoid this",65116537
353,2019-06-19T21:04:50Z,2019-06-19T21:04:50Z,,,"If you have an FVector and multiply it by a number, you get the expected results (a new vector scaled by the given number). But if you reverse the order of the arguments (and do number * FVector), the returned vector is garbage.

I verified that `ue_py_fvector_mul` in UEPyFVector.cpp is being called in both scenarios, but the problem is that that function assumes that the 'self' parameter will always be the FVector object, which is not the case, unfortunately. The [Python docs](https://docs.python.org/3/c-api/typeobj.html#number-structs) say:

> Note Binary and ternary functions must check the type of all their operands, and implement the necessary conversions (at least one of the operands is an instance of the defined type). If the operation is not defined for the given operands, binary and ternary functions must return Py_NotImplemented, if another error occurred they must return NULL and set an exception.

This patch changes the multiplication function to handle either case, and does the same for FVector2D. It's likely that other wrapper objects that implement the Python number protocol will have to change too.",65116537
354,2019-06-07T20:07:56Z,2019-06-07T20:07:56Z,,,,65116537
355,2019-05-03T23:35:56Z,2019-05-03T23:35:56Z,,,"Hi, 

when porting some of my code to python, i noticed that my Actor was rotating the wrong way, according to https://api.unrealengine.com/INT/API/Runtime/Core/Math/FRotator/index.html the arguments order of `FRotator` function should be
```cpp
FRotator
(
    float InPitch,
    float InYaw,
    float InRoll
) 
```

instead of `Yaw, Pitch, Roll`

Best regards,
F0x.",65116537
356,2019-05-01T00:49:58Z,2019-12-15T18:10:15Z,,,This test fails for me unless I add the submitted line. I'm surprised it ever worked without it. Or should it be working?,65116537
357,2019-04-30T08:40:06Z,2019-04-30T11:52:18Z,,,The proper include path for the ModuleInterface.h header includes its Modules folder as seen in other source files for 4.22.,65116537
358,2019-04-01T16:03:48Z,2019-04-01T16:03:48Z,,,No idea if this is a proper fix but this fixed my packaging error in 4.22 (UWorld set current level error).,65116537
359,2019-01-12T20:24:22Z,2019-01-12T20:24:22Z,,,"Hi,
These changes are for 4.20+ compatibility, and fix crashes when setting ini values for Home and ProgramName in DefaultEngine.ini
Also, a bit of windows specific path setting is now in a windows specific block.",65116537
360,2019-01-04T05:02:17Z,2019-01-04T05:02:17Z,,,"When analyzing a graph node's pins, it's really helpful to know which direction the pin is, so this patch adds read support via pin.direction.

Also, I found that many pins in existing BPs that have a structure for their type have category = 'struct' but sub_category=None, default_object=None, etc. - there's no good way (that I could find at least) to programmatically figure out the pin's structure type.

In the debugger, however, I noticed that the structure is available via pin.PinType.PinSubCategoryObject, so this patch also exposes read access to that as pin.sub_category_object.",65116537
361,2018-12-22T04:59:32Z,2018-12-27T22:39:39Z,,,"This PR builds on PR #626 and adds support for array parameters as input parameters, output parameters, and return values. I can resubmit it if/when that PR is accepted, but for now it's diffed against master so the commit looks bigger than it actually is.

A test project with many tests is available at https://github.com/dfb/uepy_test_prjs/tree/master/array_params

In order to get the tests to pass, I had to also implement a fix for bug #632.",65116537
362,2018-12-14T06:12:44Z,2018-12-14T06:12:44Z,,,This resolves the issue #289.,65116537
363,2018-12-12T23:01:08Z,2018-12-27T22:28:40Z,,,"See issue #621 - this patch makes it so that Python can properly call C++ or BP methods with one or more output parameters as well as C++ methods that have both output parameters and a return value. Further, it makes it so that in Python you can override and implement methods that have both return values and output parameters. A side effect of this patch is that so far it appears to have fixed #622.

Note that when combining out params and a return value, the return value needs to come last in the type annotation info, e.g. given a C++ base class method like this:
```c
    UFUNCTION(BlueprintCallable, BlueprintNativeEvent) float Func(int i, int& oi);
```

you'd implement it in Python like this:
```py
    def Func(self, i:int) -> (int, float):
        return 5, 12.34 # 5 is the out param, 12.34 is the return value
```

In terms of lines of code, the biggest change is moving property creation to ```new_property_from_pyobject``` since it is needed in more places (and was getting unwieldy anyway).

Given that this patch affects some pretty fundamental code, I also created a project that runs through a large set of test scenarios: https://github.com/dfb/uepy_test_prjs/tree/master/output_params
",65116537
364,2018-11-13T16:42:37Z,2018-11-14T11:01:36Z,,,"I have added the support for iOS platform, using the Python 3.6.6's static libs from repo(https://github.com/pybee/Python-Apple-support/tree/3.6).

**How to use**:

1. Making a folder named ""Lib"" inside the ""Content"" folder.
2. Copy the python36.zip from ""Plugins/UnrealEnginePython/python/python36/ios/Python/Resources/lib"" into the ""Lib"" folder that is created right now, and rename it as ""stdlib.zip"".
3. Configure the ""package"" setting in the UE4 project, adding the ""Lib"" to the ""Additional Non-Asset Directories To Copy"".
4. Launching or Packaging.",65116537
365,2018-10-22T20:19:14Z,2018-11-17T08:19:48Z,,,"Took longer than expected to get the time to make the pull request, but as per request https://github.com/20tab/UnrealEnginePython/issues/181#issuecomment-400681489

This variant will allow you to pass in a variable such as a python object in the callback. Example use case here 
```python
def train_blocking(self):
	...
	#python object
	summary = {}
	summary['elapsed'] = stop-start

	#call back with results on game thread
	ue.run_on_gt(self.training_complete, summary)

...
#actual function getting called on game thread with data
def training_complete(self, summary):
	#not related, but forward summary python object to blueprint layer as json string
	self.uobject.OnTrainingCompleteFunction(json.dumps(summary))

```

https://github.com/getnamo/tensorflow-ue4/blob/master/Content/Scripts/TensorFlowComponent.py#L164

Note that this particular call uses an alias defined here: https://github.com/getnamo/UnrealEnginePython/blob/b652cbfd759da6045a2f89c4d4080526b33d3c47/Source/UnrealEnginePython/Private/UEPyModule.cpp#L501, alias not required for functionality and it's not included in the pull request. Instead you would write:

```python
ue.create_and_dispatch_when_ready(self.training_complete, summary)
```

For the other route (game thread->run something on background thread) it's probably better to use python's Thread model (see: https://github.com/getnamo/UnrealEnginePython/blob/master/Content/Scripts/upythread.py for an example)",65116537
366,2018-09-20T01:40:59Z,2020-03-04T10:31:59Z,,,"1. This embeds python 3.7 pre-built libs and dlls on x64 platform inside the plugin directory that UBT can easily discover it. 
2. This automatically copies all the necessary files required in the right binary folder using relative path locations from binary. 
3. This fixes the paths when you don't have any python installed and makes the plugin truly independent and self contained. 

I was trying to push into this branch but I am getting permissions denied. Let me know if you want this pull request. ",65116537
367,2018-06-22T09:09:30Z,2018-06-22T09:09:30Z,,,"### Features: Sequencer & Slate widgets/extensions
- Lots of slate widget extensions, lots of memory corruption fixes
- Lots of sequencer extensions and editor support
- Robust support for struct.ref() around native structs

This is a painful PR so to make it easier, I made several merge points from at logical points to chunk the integration and help track changes.  This doesn't include the latest merge with the threading refactor because it deadlocks easily (from mainbranch) so couldn't verify my merged changes work correctly. I left it up though here: https://github.com/kitelightning/UnrealEnginePython/tree/buggy-threading

### Specific questions/feedback request
**UEPySPythonComboBox.cpp: 170**
//TODO: ikrimae: #ThirdParty-Python: #BUG: We are on purpose not doing Py_DECREF(values) because we're stealing the reference from _GetIter
//But we never decref values in the dealloc function. We should store a py_ref to the python list
//Ask roberto for the new refactored way for this

**UEPySPythonListView.cpp: 155**
//TODO: ikrimae: #ThirdParty-Python: #BUG: We are on purpose not doing Py_DECREF(values) because we're stealing the reference from _GetIter
//But we never decref values in the dealloc function. We should store a py_ref to the python list
//Ask roberto for the new refactored way for this

**UEPyModule.cpp:2590:**
//TODO: ikrimae: #ThirdParty-Python: Not sure if this will auto cleanup when the function parameters are destroyed or if the GWorld owner will force it to keep alive
**UEPyModule.cpp:2608:**
//TODO: ikrimae: #ThirdParty-Python: Not sure if this will auto cleanup when the function parameters are destroyed or if the GWorld owner will force it to keep alive

**PythonHouseKeeper.h:275**
//TODO: ikrimae: #ThirdParty-Python: #BUG: This implementation memory leaks. These delegates never get cleaned up",65116537
368,2018-05-16T20:53:56Z,2018-05-30T08:33:48Z,,,"Fixes these issues during the build:

```
------- Build details --------
  Using clang (/usr/bin/clang++) version '6.0.0' (string), 6 (major), 0 (minor), 0 (patch)
  Using bundled libc++ standard C++ library.
  Using lld linker
  Using llvm-ar : /usr/bin/llvm-ar
  Using fast way to relink  circularly dependent libraries (no FixDeps).
  ------------------------------
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonConsole/Private/PyFbxFactory.cpp(1): error: Expected PyFbxFactory.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonConsole/Private/PythonConsoleModule.cpp(1): error: Expected PythonConsoleModule.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonConsole/Private/PythonScriptFactory.cpp(1): error: Expected PythonScriptFactory.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonConsole/Private/SPythonConsole.cpp(1): error: Expected SPythonConsole.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonConsole/Private/SPythonLog.cpp(1): error: Expected SPythonLog.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/DirectoryScanner.cpp(1): error: Expected DirectoryScanner.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PYRichTextSyntaxHighlighterTextLayoutMarshaller.cpp(1): error: Expected PYRichTextSyntaxHighlighterTextLayoutMarshaller.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonEditorCustomization.cpp(1): error: Expected PythonEditorCustomization.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonEditorStyle.cpp(1): error: Expected PythonEditorStyle.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonProject.cpp(1): error: Expected PythonProject.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonProjectEditor.cpp(1): error: Expected PythonProjectEditor.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonProjectEditorCommands.cpp(1): error: Expected PythonProjectEditorCommands.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonProjectEditorToolbar.cpp(1): error: Expected PythonProjectEditorToolbar.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonProjectItem.cpp(1): error: Expected PythonProjectItem.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/PythonSyntaxTokenizer.cpp(1): error: Expected PythonSyntaxTokenizer.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/SProjectViewItem.cpp(1): error: Expected SProjectViewItem.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/SPythonEditableText.cpp(1): error: Expected SPythonEditableText.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/SPythonEditor.cpp(1): error: Expected SPythonEditor.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/SPythonProjectEditor.cpp(1): error: Expected SPythonProjectEditor.h to be first header included.
  /home/user/temp/HostProject/Plugins/UnrealEnginePython/Source/PythonEditor/Private/WhiteSpaceTextRun.cpp(1): error: Expected WhiteSpaceTextRun.h to be first header included.
  ERROR: Build canceled.

```",65116537
369,2018-03-17T02:32:10Z,2018-03-17T02:32:10Z,,,"1.  Fixed `TrimEnd` `TrimStart`
2. Fixed Project vs Game `ContentDir` and `SavedDir`
3. Other 4.18 -> 4.19 migrations",65116537
370,2018-02-21T21:51:51Z,2018-02-21T21:52:10Z,,,"# Major: 
- Struct Ref handled properly everywhere: global support for returning original data ptr for ref struct or not. Can disable it globally now by just changing py_ue_uscriptstruct_get_data()
    to return the new data
- Making PyFVectorm, PyFTransform,PyFRotator,PyFQuat   to be children of ue4's native FVector & FTransform to allow for seamless support of struct ref. Should have perfect backcompat


# Minor:
- SPythonTreeVIew Extensions
- Ability to set styleset with slatestyle widgets
- UEPyEngine, UEPyEditor, UEPyModule: Added console exec function to UEPyEngine and removed it from UEPyEditor so that it's usable in standalone scripts.
-  save_package_helper: More robust than save_package
- checks using TBaseStructure<FGuid>() instead of searching for FGuid struct by name
- ability to pass flags when creating new uobject using class name e.g. AnimMetaData('name', packge, outer, RF_PUBLIC|RF_STANDALONE)

# Bug Fixes:
- Add clear_event function for multicasting
-  Multicast delegate property should reference pointer in container, not value. Accidentally making copies and not updating the actual delegate
-  GetPostGarbageCollect() does not exist in UE4.17; changing to PostGarbageCollect
",65116537
371,2018-02-12T13:34:00Z,2019-10-09T13:08:59Z,,,Expose use alpha / SRGB flags and texture compression settings.,65116537
372,2017-09-08T21:03:54Z,2018-08-02T20:46:48Z,,,Fixes compile error on Ubuntu 16.04 latest ,65116537
373,2017-04-11T17:46:27Z,2017-04-11T18:44:18Z,,,Created to resolve #142 ,65116537
374,2017-04-05T18:54:57Z,2017-05-15T09:09:44Z,,,"Also adds add_image_brush and a basic style.

This is not complete yet but I would like to get your eyes and thoughts. So far it only supports the SkeletalMeshEditor but should be able to be extended to support the other editors.

Please let me know what you think and if there are changes that should be made before adding the other editors. I am also unsure of what should be passed to the python callbacks. In the case of the SkeletalMeshEditor I am making an assumption and only passing the USkeletalMesh instance which is what I needed for my present use case.",65116537
375,2017-04-05T18:51:02Z,2017-04-14T14:37:01Z,,,More completely and properly wraps UAssetImportData. Also adds wrapping for FAssetImportInfo and FAssetImportInfo::FSourceFile.,65116537
376,2017-04-05T18:49:30Z,2017-10-24T01:29:09Z,,,Simple change that adds a new method wrapping the built in GetAllTextureParameterNames method.,65116537
377,2020-03-17T03:50:52Z,2020-03-17T04:27:00Z,,,"Added 3 test cases:

1. The first test case was added to the h2/test/scripts/datatypes/int.sql file. Here we are checking if casting a character value as integer throws a Data Conversion exception.

2. The second test case was added to file h2/test/db/TestViewAlterTable.java. In this test case, we are checking if the application is throwing referential integrity constraint violation error.

3. The third test case was added to file h2/test/db/TestIndex.java. This test case tests what happens when null is inserted as a value for the primary key column (which should be not null).",33745913
378,2020-03-14T05:27:46Z,2020-03-14T06:17:00Z,,,"Fix for whitespaces issue #2407 

Created a new method getWithoutRightTrim in ValueChar.java to account for proper handling of right trailing whitespaces when using H2.

Right trailing whitespaces are removed only for MYSQL and PostgreSQL modes as mentioned.",33745913
379,2020-03-05T07:59:14Z,2020-03-05T07:59:14Z,,,"Took the else out as mentioned and checked if the cluster session is enabled, but the  cluster database is disabled, then throw an exception.",33745913
380,2020-01-31T06:22:09Z,2020-02-17T00:48:06Z,,,,33745913
381,2019-11-13T07:24:42Z,2019-11-13T07:24:42Z,,,add space.,33745913
382,2019-08-08T09:40:55Z,2020-02-01T15:29:25Z,,,"In the method readStoreHeader() of MVStore, the opening procedure of the mvstore is very redundant and poor performance(see #2048). Actually the newest is the last chunk, otherwise the store is corrupted by H2 bug, a rogue thread or process.

It's unnecessary that verifying the all chunk validity in the meta of last chunk candidates:
1) If the store corrupted by a rogue thread or process and we fall back to the older chunk,
 then the data lost, it's very bad. We should suggest recovering the store by tool to user or enabling recoveryMode.
2) And if the newest chunk valid(both header and footer valid), the all chunks referenced 
 in the meta of the newest also valid, otherwise why is the newest valid?, or the store corrupted.
3) The bug of database corruption by partial write and the store not closed when fatal error
occurs in H2 has been fixed.

And  fix error code 90020 issue for closing database incorrectly in Engine close().
",33745913
383,2019-06-13T03:58:27Z,2019-07-15T18:00:35Z,,,Provides client socket connection information,33745913
384,2019-06-13T00:03:42Z,2019-06-13T00:03:42Z,,,Provide method to list current listening ports,33745913
385,2019-04-22T08:39:25Z,2019-04-22T08:39:25Z,,,Signed-off-by: Li Zhiming <lizhiming@zuihuibao.com>,33745913
386,2019-03-15T14:34:39Z,2019-03-22T14:48:13Z,,,"Hello!
Here I've implemented :
- JSON data type processing based on fasterXML/jackson library
- Functions to work with documents
- Special operations for querying with Postgres syntax

Also here are some queries shows how it works.

Unfortunately, I've got some problems with memory and network tests.
I'll glad to discuss their decision.",33745913
387,2019-02-21T13:03:17Z,2019-03-09T12:08:16Z,,,,33745913
388,2019-01-29T17:34:17Z,2019-04-08T06:25:50Z,,,,33745913
389,2018-10-20T13:43:35Z,2018-12-23T19:43:13Z,,,"Lucene supports the concept of an ""analyzer"" - an abstraction of text parsers suited for different type of text input. Some of them are designed for natural languages, other for machine text, some are customized for specific languages.

It would be nice if H2 provided the user an ability to set a custom version of the analyzer, not only the standard one. This would allow the user to tune the full-text search engine for specific data and issues like #1482",33745913
390,2020-01-07T21:41:14Z,2020-03-14T21:39:44Z,,,"Duktape is great for embedded environments, and so I wanted to try and run it in Intel SGX. There is some special configuration needed and refactoring string formatting in a few places, but otherwise works just fine.

Summary of changes:

1. Add a new platform `platform_intelsgx`.
The order is important to be immediately above Linux and Windows. Intel SGX enclaves are compiled under Linux or Windows with a special C library (tlibc; trusted libc) but otherwise are indistinguishable from other object files. Therefore the Linux and Windows detection will trigger.
2. Automatic detection that we're compiling an enclave is really tricky. 
There is no official documentation that describes if there is a macro you can check to see if compiling against tlibc; I did manage to find `_TLIBC_CDECL_` and a few others from `sys/cdefs.h` which _might_ be used for this purpose but I decided it's best to prefer manual versus automatic detection. In order to hint that this is the Intel SGX build either define `INTELSGX` manually or use `--platform=intelsgx` in the `configure.py` invocations.
3. Intel SGX enclaves do not have access to syscalls, and therefore they can't get information about the current time and locale timezone offset. This makes it impossible to run Duktape without any intervention, but luckily this boils down to defining two macros `DUK_USE_DATE_GET_NOW` and `DUK_USE_DATE_GET_LOCAL_TZOFFSET`. These are mandatory and well documented, and compilation fails with a preprocessor error if they are not added. 
4. Intel SGX's tlibc does not include the ""unsafe"" string parsing and formatting functions. It only uses the ""safe"" ones. Meaning that all uses of `DUK_SPRINTF` needed to be refactored into `DUK_SNPRINTF`, but that was an easy affair. In general it's my opinion that going forward the unsafe functions be completely ""banned"" from the Duktape code, and be replaced with safe ones. 
5. Add `DUK_USE_STANDARDIZED_POINTER_ENCODING` option (default: false) that encodes all pointers in a ""standardized"" way i.e. in lowercase hexadecimal encoding as the value is laid out in memory. In order to implement this, the functions `duk_encode_pointer_cstr` and `duk_decode_pointer_cstr` were added to `duk_util_misc.c`. They have also been replaced wherever the `%p` format specifier was used directly or indirectly (except for debug statements, of course). By enabling this option, Duktape no longer uses `DUK_SSCANF`.
6. Added a few things to `.gitignore`, most importantly `runtests/package-lock.json` which is added by npm when tests are run locally. It may be a good idea to remove this from `.gitignore` if we want to pin down versions.
7. Changed invocation of `python` within `runtests/runtests.js` to `python2.7` since running the `ecmatest` with Python 3 failed with error. These days Python 3 is behind `python`, while 2.7 can be invoked with `python2.7`.

This PR is not complete I'm still testing and changing things, but discussions can begin IMO.

Remaining things to complete:
- `apitest` fails when `DUK_USE_STANDARDIZED_POINTER_ENCODING` because of the hardcoded expectation for `0xdeadbeef`. `ecmatest` succeeds, tho. Possible solutions:
  1. Test expectations get passed through `jade` or some other preprocessor so they can be configured before being run.
  2. All `0xdeadbeef` occurrences in expectations within `tests/api` are replaced with a configurable value.
  3. Change the standardized format, though I really like the simplicity of 1:1 memory layout in hex.
- Add new doc page for how to compile for Intel SGX.
- Write instructions for testing.",15852088
391,2019-11-15T09:05:57Z,2019-11-15T09:05:57Z,,,"I am using duktape in an environment where it may be asked to run untrusted code as part of a platform as a service, and the function ``duk__match_regexp()`` can potentially run for a very long time if an abusive or broken regular expression is passed to it. This is somewhat mitigated by the value of ``DUK_RE_EXECUTE_STEPS_LIMIT``, lowering this can solve the problem but it seems this cannot be lowered from duk_config.h, and i would have to edit my duktape.c to fix it.

Based upon this i decided on this fix instead - i am already using ``DUK_USE_EXEC_TIMEOUT_CHECK`` with an interrupt function to prevent cpu consumption and various forms of resource abuse, but it seems the timeout function is not called from within the ``duk__match_regexp()`` function.

This PR adds support for calling the interrupt function from within the loop, this doesnt change any specification i'm aware of, as the docs say just that the interrupt function is 'called periodically' while running the script. 

Please consider either merging this PR in some form, or allowing user configuration of ``DUK_RE_EXECUTE_STEPS_LIMIT`` and ``DUK_RE_COMPILE_TOKEN_LIMIT``.

Thanks!",15852088
392,2019-10-07T01:46:19Z,2019-10-07T02:09:07Z,,,"This PR is an early attempt to add and API for externally handled stack values, as mentioned in #2190 

This is preliminary work to see if such a change is viable to be merged into this project.

Basic idea is that we have an additional stack value type with a tag `DUK_TAG_EXTVAL`, available only for an unpacked stack value representation (as it requires 16 byte length for stack values).
Whenever a type/conversion of such value is needed, external API (modeled as a number of function pointers in `duk_hthread` struct) is used. At the moment a few performance penalties were introduced (like in `duk_get_type_tval`) in form of an additional condition.

This code was not tested, and it is definitely not ready to be merged. It is only meant to provide a background for a discussion, whether such an API has its place in duktape, and whether I should proceed with this development.

Regards.",15852088
393,2019-06-25T19:22:08Z,2019-07-05T22:23:09Z,,,"This changes the Makefiles so that they now build incrementally. Previously if you wanted to rebuild an example yo would have to manually delete the binary, and rebuild the entire example, including duktape. This will only rebuild the files that have changed, so duktape will no longer be rebuilt every time, as well, as no longer requiring the user to delete the output binary manually when they want to rebuild the example. It changes the name of the output binary of ```Makefile.dukdebug``` from ```duk``` to ```dukd``` so that the command line example and the debug command line example don't produce the same binary.",15852088
394,2018-12-30T20:35:06Z,2019-06-02T21:50:28Z,,,"When deploying Duktape as a DLL it is sometimes useful to bundle some extra functionality, compared to what vanilla `duktape.h` provides. In my case I wanted to be able to deploy `duktape.dll` with support for Node.js modules and debugging out of the box . However, it seems that these extra modules are not ready to be used that way because of missing `__declspec` specifiers.

I understand I could put these modules in separate DLLs (like `duktape-module-node.dll` etc), but it seems a bit overkill, and even then I would need to resolve `__declspec` specifiers, which would require me to modify sources that come with Duktape, which isn't perfect from maintenance perspective.",15852088
395,2018-08-14T09:23:10Z,2018-08-15T09:28:08Z,,,"This is a little bit of a subtle issue. The way NixOS/Nixpkgs work, they typically
wrap binaries (such as the compiler) with more complicated wrappers to handle
the paths established in Nixpkgs store and other features. In this case, the feature
that's interfering with normal flow is hardening. Without going into too much detail,
there's no way to disable _FORTIFY_SOURCE as it is always passed after any passed
arguments. Something like `gcc <PARAMETERS> -D_FORTIFY_SOURCE`.

However, this doesn't play well with musl (see https://wiki.musl-libc.org/future-ideas.html)

Solution: disable `_FORTIFY_SOURCE` if glibc is not present

---

I've been using this patch for quite a while in SIT https://github.com/sit-fyi/sit/blob/master/sit-core/src/duktape/duktape.h#L144-L146 but I keep transferring it during upgrades and this isn't particularly robust.

I am not sure this is the best way to solve but at least it have worked for a good while. 

Any thoughts?",15852088
396,2018-07-22T19:23:12Z,2018-08-06T22:31:48Z,,,"Up to now Duktape has intentionally rejected a Proxy as either a Proxy target or a Proxy handler object; both cases cause more potential for native recursion and are relatively rare in practice. ES2015+ does not place such a limitation on Proxies. This pull removes the current limitation and allows Proxies as both target and handler.

Tasks:
- [ ] Remove Proxy check for target/handler in Proxy creation
- [ ] Proxy chain support for getprop
- [ ] Proxy chain support for putprop
- [ ] Proxy chain support for delprop
- [ ] Proxy chain support for hasprop
- [ ] TBD: enumeration etc
- [ ] Testcase coverage
- [ ] Releases entry

This is currently work in progress, to be merged after 2.3.",15852088
397,2018-04-14T21:23:43Z,2018-04-28T21:01:24Z,,,"(At this point just some quick testing, not sure if this approach will be merged.)

All constructable functions have a `.prototype` property. It points, by default, to an object whose `.constructor` property points back to the function, creating a reference loop. This reference loop prevents most function objects, especially inline callbacks, from being refcount freed. There are several approaches to allow refcount collection of such function objects.

One of them is to postpone creation of the `.prototype` property until it is actually observed somehow and we must commit to the property's existence. Relevant situations include:
- Reading the property: value must be created.
- Writing the property: since `.prototype` is writable but not configurable, the new value can be written without creating the object prior to the (over)write.
- Existence check: `prototype in MyConstructor` must return true; does not require creation of the object.
- Deleting the property: `.prototype` is non-configurable so delete must fail; does not require creation of the object.
- Object.getOwnPropertyNames() or duk_enum() with ""include non-enumerable"": requires listing the ""prototype"" key but doesn't require creation of the object (except for duk_enum() with both keys and values requested). Enum order has a few issues.
- Object.defineProperty(): some cases might be handled without triggering creation, but safest would be to create the property if Object.defineProperty(MyConstructor, ""prototype"", { ... }) is called.

This approach allows refcount collection of a few basic cases, in particular anonymous functions which are not captured by an outer scope, e.g.:
```javascript
setTimeout(function () { ... }, 1000);
```

Unfortunately if the function is given a name, this currently creates another kind of reference loop (scope object containing the function name binding points to the function, and the function points to the scope) so this doesn't get refcount collected:

```javascript
setTimeout(function mycb() { ... }, 1000);
```

This case could be allowed to work by reworking the function name binding scope handling. But other cases will still remain.

Tasks:
- [x] Property get
- [ ] Property set
- [ ] Property has
- [ ] Property delete
- [x] Object.getOwnPropertyNames() and other enumeration cases
- [x] Object.defineProperty()
- [ ] Treatment of Duktape/C functions - allow them to have an on-demand .prototype now? (This would be the behavior by default without an explicit internal flag which doesn't yet exist.)
- [ ] Testcase coverage
- [ ] Short internal document
- [ ] Releases entry

Future work:
- [ ] Fix .prototype enumeration order so it is stable (as if created when instance was created)",15852088
398,2017-08-29T10:39:57Z,2017-08-29T10:42:17Z,,,"Follow-up to #1683: expose direct control over pause flags in debugger Resume command. Adds the ability to e.g. pause after a single opcode step, and to decide freely whether to pause on a caught/uncaught error. 

Deprecate StepXxx commands in documentation (but only in documentation) because the Resume command with flags can now be used to implement all stepping modes, and more.

Fixes #1682.

Work in progress.",15852088
399,2017-08-25T22:11:50Z,2017-09-03T20:09:42Z,,,"A little experiment to see how string interning could handle automatic surrogate pair combination. This would be necessary if moving into an internal representation where surrogate pairs were combined into UTF-8 so that C API would always see UTF-8 even if Ecmascript code saw surrogate pairs.

This is not useful to merge in its current form, just a bit of experimentation:

```
// Individual codepoints can be represented (x, y) but are merged when
// a valid high-low pair is encountered.
duk> x = '\ud800'; y = '\udc00'; z = x + y;
= ""\U00010000""
duk> x = '\udbea'; y = '\udfcd'; z = x + y;
= ""\U0010abcd""

// Invalid pair (not high-low) is not combined.
duk> z = y + x;
= ""\udfcd\udbea""

// When joining strings, join point may need surrogate pair combination
duk> x = 'foo\udbea'
= ""foo\udbea""
duk> y = '\udfcdbar'
= ""\udfcdbar""
duk> z = x + y
= ""foo\U0010abcdbar""
```

If extended to work correctly in all cases, this could be put behind a config option. Even without a change to an internal WTF-8 representation (which involves ensuring Ecmascript sees combined surrogates as separate, ""as if"" the internal representation was CESU-8) this might be a useful change for some applications where getting UTF-8 outputs where possible is more important than having standard Ecmascript string behavior.",15852088
400,2017-07-10T02:57:02Z,2017-07-10T20:24:02Z,,,"With the explicit DUK_HOBJECT_FLAG_CALLABLE it's now possible to create functions that are constructable but not callable as normal functions. This is a prototype branch to see how that would work out in practice for built-in functions. The upside would be that no explicit `duk_require_constructor_call()` would be required which is smaller (and slightly faster). It would then be possible to expose a public API to create non-constructor and construct-only functions.

Work in progress.",15852088
401,2017-06-15T20:31:29Z,2017-11-29T22:50:43Z,,,"Add minimal support for getOwnPropertyDescriptor Proxy trap to support virtualized enumeration.

Tasks:
- [x] Add Proxy passthrough for reading a descriptor when a getOwnPropertyDescriptor trap doesn't exist
- [ ] Add Proxy passthrough for Object.defineProperty() and variants
- [ ] Add getOwnPropertyDescriptor trap call, minimally to handling enumeration at least
- [ ] Check propdesc call sites; especiall e_idx + a_idx assumptions
- [x] Test coverage for passthrough
- [ ] Test coverage for trap call
- [x] Specific test for virtualized enumeration
- [ ] Releases entry",15852088
402,2017-03-27T16:46:57Z,2019-07-28T19:17:57Z,,,"Proposal from IRC: https://github.com/mamod/JavaScript-Duktape/pull/23/commits/91f0ef29096f19991186a27a268d92521ff7d983.

Changes:
- [x] For Windows target, when compiling with MinGW, use __builtin_{setjmp,longjmp}() to avoid a potential crash issue
- [x] Identify Cygwin target as ""cygwin"", not ""windows"", for clarity
- [x] Releases entry",15852088
403,2017-03-17T15:14:20Z,2018-05-19T07:57:53Z,,,"Add `DUK_USE_EXTBC_CHECK()` which allows an application to map the bytecode of a function to an external data area. This allows Ecmascript function bytecode to be e.g. copied to memory-mapped flash which reduces actual RAM usage; usefulness depends on the target architecture.

This is a very early experimental version: DUK_USE_EXTBC_CHECK() is called and if it returns a non-NULL pointer the bytecode is used from the pointer provided. There's no GC integration: the application must ensure that the external pointer remains valid for the lifetime of the Ecmascript function (without having any hook to know that).

Tasks:
- [ ] Working prototype
- [ ] duk_hcompfunc.h review; conditional fields? size fields?
- [ ] Documentation
- [ ] Ajduk example
- [ ] Releases entry",15852088
404,2017-01-16T04:36:39Z,2017-08-11T19:54:32Z,,,"The test script should exercise usual code paths for all built-ins so that the performance profiling data accurately reflects the relative frequency of most practical code paths. Current PGO test set in the Makefile is a dummy placeholder.

- [ ] Come up with a test set as a separate test file or as sequence of individual tests
- [ ] The full tests/ecmascript test run could be useful (execute with runtest.py), but might be too heavy for practical Makefiles
- [x] Add Octane to profiling set
- [ ] Document that `duktape.c` can be profile optimized with a dummy main (e.g. ""duk"") and the profile then used in an application build
- [ ] Consider bundling the PGO test file into the distributable along with a PGO example",15852088
405,2017-01-14T21:58:13Z,2017-06-21T21:54:08Z,,,"Add a heap-wide property slot cache:
- Lookup key is a combination of `duk_hobject *` and a key string hash.
- Lookup value is a possible property slot (integer).

Property lookup changes:
- If object has hash part, use the hash part without using the slot cache.
- Otherwise, look up the slot cache using object/key.
- Validate the returned slot index: check that it's within the object's property table, and check that the key matches. If so, use the slot as is.
- Otherwise do the usual linear scan to find the key. When found, overwrite the property slot cache entry with the slot index.

The upsides of this approach are that:
- Unlike hash tables, it emphasizes actually looked up object/key pairs. No upfront work is done like with hash tables.
- There is no GC impact in ensuring the entries are valid (compare to the relatively tricky generation-based validity handling in the property cache prototype). The slot index is always just a best guess, and is always validated.
- The slot cache entry is just an integer. If hash table size limit is 256 properties, the integer can be only 8 bits. Compared to the property cache approach (where the entry is 16+ bytes) this allows a much larger lookup for the same memory cost.

There are downsides too:
- If an application has a hot path accessing a few object/key pairs repeatedly, and they happen to map to the same lookup entry, performance will suffer because linear scans will happen for both objects. This is not very likely, but still possible, and there's no easy defense against it except maybe switching the lookup index computation from time to time.
- If an object is very large, and most of its properties are accessed continuously, it takes initial linear scans for each property to populate the cache (and the entries may later be overwritten) which is expensive compared to a hash table which is a dedicated structure. So, a property/slot cache is not a substitute for a hash table in general.

See also: https://github.com/svaarala/duktape/pull/1284#issuecomment-272655765.

Tasks:
- [ ] Rebase after hash algorithm merge
- [ ] Add the slot cache logic
- [ ] Add minimal stats when debug enabled, log in mark-and-sweep for example
- [ ] Skip the slotcache lookup/overwrite for tiny objects (say <= 4 properties) because scanning is just as fast and reduces slot cache traffic
- [ ] If the minimum slotcache limit is e.g. 4 and hash part limit is also relatively low (say 8) the slotcache will have minimal impact in the default configuration and can maybe be disabled; it would still be useful for low memory targets where hash parts can be globally disabled but it may be possible to use e.g. a 256-byte slotcache instead (it's fixed size and thus easy to manage)
- [ ] Configuration changes, zero size disabled slotcache
- [ ] Low memory config could include a small cache
- [ ] Internal documentation
- [ ] Releases entry",15852088
406,2017-01-03T12:15:31Z,2017-08-16T22:20:04Z,,,"- [x] Add valgrind memory measurement to `runtest.py`
- [x] Add ""definitely leaked"" parsing to valgrind in general, useful for --valgrind runs
- [ ] Memory commit test",15852088
407,2016-12-20T02:46:32Z,2017-07-30T02:03:37Z,,,"Implement an initial version of property caching where the property cache key is a (generation, object, key) triple. The cache is implemented in GETPROP (the most common property read operation) and the object in the triple is for the starting point of a property lookup. The generation count is a quick way of invalidating the whole cache on any property write or other operation risking cache integrity: entries can be invalidated by a single heap-level generation counter increment without touching the entries themselves. The generation is checked on a cache lookup; no hash chaining is used, and each property lookup hash has only a single slot.

So far this is pretty experimental and some invalidation cases are still missing. The goal is to try to figure out if the approach is workable given all the low level details. Quite possibly some small detail may prevent this from being finished as a viable feature.

Initial results are reasonable however:
- tests/perf/test-array-read-lenloop.js (whose main point is a `for (j = 0; j < arr.length; j++) {...}` loop) runs 2.1 seconds from master and 1.5 seconds with caching.
- tests/perf/test-fib.js runs 7.1 seconds from master and 6.3 seconds with caching.
- tests/perf/test-assign-proprhs.js runs 3.7 seconds from master and 1.7 seconds with caching.
- tests/perf/test-prop-read-long-inherit.js runs 6.9 seconds from master and 0.3 seconds with caching. The speedup here is rather unrealistic, as this microbenchmark just demonstrates performance of looking up a long inheritance chain for which caching is (quite obviously) particularly effective.

Tasks:
- [ ] Finalize design
- [ ] Compare to other alternatives like ""own property"" caching, other cache key/hash models, etc
- [ ] Add config option for feature and property cache size
- [ ] Make invalidation calls macro based (works better in separate sources build)
- [ ] With 64-bit types the generation count rollover might not need to be checked
- [ ] Leave index writes out of caching altogether; must be applied to arrays/typedarrays, but also to all other objects because they may inherit index properties from arrays
- [ ] Debug stats, dump in mark-and-sweep?
- [ ] Test coverage for all invalidation locations; stress test?
- [ ] Assertion coverage for property lookups: when using cached value/location, assert that it's the right one
- [ ] Performance config examples, documentation
- [ ] Releases entry

One simple short term improvement is to allow property cache to store a property location (`duk_tval *`) and attributes. Property writes can then be processed without doing an ancestor lookup. If only writable properties are cached, no attribute check is needed either.",15852088
408,2016-12-13T11:47:43Z,2016-12-13T11:48:36Z,,,"For example, currently `duk_concat()` creates a fixed buffer for the final result size and writes all string parts into it. The result is then string converted. This means, in practice, that the final string exists in RAM in both the temporary buffer and the final `duk_hstring` for a brief period.

Improve this so that internal call sites can push a `duk_hstring` allocated to a certain size but with uninitialized data. The string would also not be tracked in the string table. The calling code could then write to the string data part e.g. as part of `duk_concat()`. Once the data part is done, the same `duk_hstring` allocation can be finished and be interned into the string table, and then becomes immutable.

If an error is thrown, garbage collection must deal with a string that needs to be freed but without existing in the string table. Other issues to deal with:
- When the final string has been built, it may already be in the string table but this can't be known beforehand. Must allow the string just built to be discarded.
- When using low memory ""external strings"", the external string can only happen when the string is finished. It may then be necessary to switch to an external string.

Tasks:
- [ ] Come up with a useful internal API idiom
- [ ] Convert current call sites needing this (concat, encoding, etc)
- [ ] Maybe expose in the public API; how?
- [ ] Releases entry",15852088
409,2016-12-05T17:13:28Z,2018-05-12T15:24:02Z,,,"Placeholder for now.

Basic idea is to store `_Source` in the compiler when source support is enabled. Then, in `Function.prototype.toString()`, if source is available, use it as the toString() result directly.

So it's up to the compiler to come up with a useful `_Source` that matches ES6 requirements.

Later on it'd make sense to use some form of compression on the source code, e.g. bit packing optimized for ASCII and RLE compressing white space.

Or maybe an actual compression algorithm: for example, a 1kB footprint for a compression/decompression algorithm would be worth it if the ~3kB strings and built-ins init data was reduced to 2kB. Also, the more strings and built-ins are present (which increases over time), the better this trade-off would be.",15852088
410,2016-12-02T11:14:06Z,2016-12-23T03:16:24Z,,,"Accept also `null` type for `duk_set_prototype()` to better align with `Object.create()`.

- [ ] Code change
- [ ] Testcases
- [ ] API documentation
- [ ] Releases entry",15852088
411,2016-11-25T00:14:15Z,2016-12-13T15:08:13Z,,,"Some follow-ups:

- [ ] Command line option cleanup
- [ ] Automatic Node.js comparison
- [ ] Change runtests.js to rely on runtest.py for test preparation and execution
- [ ] Remove util/prep_test.py
- [ ] Remove old known issues metadata",15852088
412,2016-11-13T03:24:53Z,2016-12-16T04:25:33Z,,,Some testing of whether a duk_tval type mask based approach works better for the non-equal-types case.,15852088
413,2016-10-27T19:26:22Z,2016-12-28T02:44:57Z,,,"Currently `duk_push_boolean()` returns void; change it to return `(duk_ret_t) 1` so that one can:

``` c
return duk_push_boolean(ctx, x == y);
```

This allows tailcalls to also be used internally which should reduce footprint. It's also convenient in user code, so the change could be added to the public API. At least the following API functions which now return void could return 1 to facilitate tail calls:
- duk_push_undefined()
- duk_push_null()
- duk_push_boolean()
- duk_push_true()
- duk_push_false()
- duk_push_number()
- duk_push_nan()
- duk_push_int()
- duk_push_uint()
- duk_push_pointer()

A corresponding change has already been made for `duk_error()` and throwers:

``` c
return duk_error(ctx, ...);
```

The downside of the change is some additional compiler output for loading the (often unused) result. The result values of the pusher API calls will also be a little bit inconsistent in that some return a value related result (for example, a `const char *` for a pushed string) while others return a dummy tailcall-facilitating value. The result values are thus driven by convenience rather than being strictly consistent.

This pull is a small test in what the impact of making such a change is. If it works internally to reduce footprint, the API change can be avoided by simply using an API macro and casting to void. So the API decision is separate.
",15852088
414,2016-09-30T12:54:22Z,2016-12-20T19:17:58Z,,,"Duktape currently uses codepoints up to 32 bits for RegExp bytecode, but if that dependency is removed, supporting codepoints only up to U+10FFFF (4 byte sequences) would be enough. This pull is to see what the overall changes are:
- [ ] Add a different variable integer encoding for RegExp bytecode; it can be simpler than UTF-8 because it doesn't have the same decoding resynchronization etc goals.
- [ ] Remove extended codepoint support from duk_unicode_support.c. CESU-8 needs to remain, and since UTF-8 4-byte sequences technically encode up to U+1FFFFF maybe keep them rather than rejecting?
- [ ] Rework old implementation and provide a size optimized variant and a table driven performance oriented variant (default)
- [ ] Testcase fixes
- [ ] Internal ocumentation updates
- [ ] Website updates
- [ ] 2.0 migration notes
- [ ] Releases entry

It would be nice if this change would make it easier to support strict UTF-8 encoding and decoding, and conversions between CESU-8 and UTF-8 needed in #975, with little code overlap.

Some motivation: https://github.com/svaarala/duktape/pull/975#issuecomment-250650051.
",15852088
415,2016-09-28T23:25:07Z,2016-12-19T19:46:31Z,,,"Draft of an approach where internal properties are hidden from user Ecmascript code even when the correct (internal) key is used. Internal properties can only be accessed using the C API, which should fulfill sandboxing requirements for protecting the internal properties securely.
- [ ] Related potential change: remove global and thread stashes, because internal properties on the global object and the thread object can be used instead (and will be inaccessible from Ecmascript code)
",15852088
416,2016-09-17T23:08:51Z,2016-12-16T04:18:49Z,,,"- [x] Remove explicit error aware summarization variants; be error aware always
- [x] Internal primitive for side-effect free lookup of a concrete property
- [ ] Improve summarization of errors
- [ ] Improve summarization of functions; functions with empty (inherited) name?
- [ ] Improve summarization of buffer objects / views
- [ ] Improve summarization of plain buffers
- [ ] String objects, Boolean objects, Date objects?
- [ ] Config option for minimal size summarization (drop error awareness etc) for low footprint targets
- [ ] Testcases for summarization (including corner cases like unsafe .name etc); needs #922 because the calls are internal now
- [ ] Test fatal error uncaught error message manually
",15852088
417,2016-08-28T02:48:55Z,2017-09-06T18:53:33Z,,,"**Work in progress**:

Add some simple configuration profiles to the distributable. A profile consists of: `genconfig.py` configuration options, `genbuiltins.py` built-in metadata changes, and any other `prepare_sources.py` options. The existing example files (config/examples, util/remove_bufferobject_properties.yaml, etc) are relocated into the profiles directory.

The profiles are expressed as plain Makefile commands. Ultimately a profile is a `prepare_sources.py` run with certain options followed by GCC compilation.

Tasks:
- [x] Relocate existing config and builtins YAML metadata examples to profiles
- [ ] Add a first profile Makefile
- [ ] Add profiles to dist
- [ ] Fix dist for new location of examples
- [ ] Git grep moved files and fix any refs
- [ ] Releases note
- [ ] Testrunner coverage for building all profiles and getting their compiled sizes
- [x] Move makeduk, ajduk, etc configuration files from util to profiles?
- [ ] Testrunner runs for x86 and ARM sizes for low memory configs

Implements parts of #845.

Future work:
- Remove ajduk entirely: there's now an equivalent pool allocator in extras so AJ checkout dependency can be avoided.
- Add a profile where the pointer compression macros are inlined as intended for production use.
- Add NULL-optimized inline pointer compression.
- Make 'duk' default build very memory conscious to make it more useful for benchmarking.",15852088
418,2016-07-25T20:05:22Z,2016-12-16T04:19:01Z,,,"ES6 specifies new behavior for typed arrays when a numeric index is detected but it is out of bounds with respect to the typed array: in this case the property is not considered to be present; reads report `undefined`, writes are ignored, HasProperty reports not present. Negative zero string (`""-0""`) is considered a numeric index but never present (not equated with `""0""`).

Work in progress, doesn't yet work. When done, fixes #257.
",15852088
419,2016-05-25T23:58:31Z,2016-12-17T02:21:17Z,,,"Currently layouts 1 and 2 are used and layout 3 is not. Layout 3 would provide natural alignment without padding on a majority of common platforms, but is a bit slower than layout 1 and 2.

Another option would be to add direct property allocation pointers by default (to make the layout differences irrelevant) and drops these fields only for low memory builds. Yet another option would be to store direct pointers and use the pointers to dynamically compute values like `e_next` which are currently explicit fields.
- [ ] Performance tests layouts 1-3 on x64 and x86 at least
- [ ] Source changes
- [ ] Config changes
- [ ] 2.x migration notes if necessary
- [ ] Releases entry
",15852088
420,2016-05-15T12:13:50Z,2016-12-13T15:08:11Z,,,"Now that the fatal error handler accepts a (heap) userdata argument, the userdata argument should be last in `duk_create_heap()`. This follows the prevailing convention that when callbacks are registered userdata follows the relevant callback(s) (and when the callbacks are called, userdata is first).

Related issues:
- `duk_create_heap_default()` doesn't have a fatal error handler which is not ideal because the default fatal error handler gets used. This in turn leads to user confusion about segfaults (which is intentional behavior).
- Should fatal error handler be a mandatory argument to minimize the chances of user code relying on the built-in default handler?
- Rewrite website fatal error parts
- Add a portability checklist or getting started checklist? That could include a fatal error note.
",15852088
421,2016-04-29T15:34:14Z,2016-12-13T15:08:11Z,,,"Fixes #714.
",15852088
422,2016-04-20T14:11:55Z,2016-12-13T15:08:11Z,,,"Operator overloading has been requested multiple times. The basic downside of adding it to Duktape is that it's not available in (all) other engines which causes a lock-in which would be nice to avoid. On the other hand, Duktape is used in some environments where the ability to manipulate domain specific objects using operator overloading is convenient (for example, vector and matrix calculation) and may even be a blocker to using Duktape if missing.

This pull contains an example of how operator overloading could be added to Duktape with a minimal impact. The example approach is to add an operator overload check to arithmetic bytecode opcodes (ADD, etc) which is done after fast path checks (e.g. number+number addition for ADD) and only if operator overloading config option is enabled (disabled by default).

To avoid getting drawn into the specifics of how operator overloading is handled (for which there are multiple options; for example, does the first or the second argument govern which overload function is called, how to handle mixed arguments, errors throwh, etc) the example simply checks if `Duktape.add()` exists and if so, offloads the operation to that function.

This pull is mostly for discussion, it's not merge ready but provides some concreteness on a possible approach so that it's easier to figure out if adding operator overloading support would be worth it.

Previous feature requests and discussion: https://github.com/svaarala/duktape/issues/282 https://github.com/svaarala/duktape/issues/104.
",15852088
423,2016-03-21T00:03:11Z,2016-12-13T15:08:11Z,,,"The explicit portability requirements for C standard library wrappers like `DUK_(V)SNPRINTF()` are not documented explicitly. This is important especially for library functions which have concrete variance across platforms (e.g. snprintf() NUL termination and return value variance, malloc() alignment guarantees, free() handling of NULL argument, etc).

Add self tests for the important guarantees where possible.

Duktape internals also don't make the same assumptions everywhere. For example, some code assumes that if the return value from `DUK_SNPRINTF()` is smaller than the buffer size given, the buffer is correctly NUL terminated (which is in practice guaranteed by all platforms). However, other code has explicit NUL termination even for these cases which is unnecessary.
",15852088
424,2016-02-18T12:58:18Z,2016-12-13T15:08:10Z,,,"Some user code needs to deal with standard Ecmascript strings where non-BMP characters are represented as surrogate pairs. Add some utility functions to decode surrogate pairs into raw UTF-8 and vice versa so that C code can work with the raw UTF-8 form conveniently.
- [ ] CESU-8 to UTF-8 surrogate pair decoding
- [ ] UTF-8 to CESU-8 surrogate pair encoding
- [ ] If this goes into extra, maybe examples/codepage-conv could also become an extra (string preallocation, 3x input, is the current limitation re: production readiness)
",15852088
425,2016-02-07T00:15:18Z,2016-12-13T15:08:10Z,,,"Implement the new API call described in #130. Basic approach is to hide the property initializer structure (so it's not a public part of the API) and use initializer macros to define property keys and values. This makes the API easier to version; new fields and macros can be added without breaking syntax compatibility as is the case with `duk_put_function_list()` and `duk_put_number_list()`. The initializer macro approach uses union initializers when possible (C99 and some C++ compilers) and falls back to portable struct initializers.

Tasks:
- [x] Add DUK_USE_UNION_INITIALIZERS config option and baseline detection for supported compilers
- [x] Add public API struct/union format and initalizer macros
- [ ] Initializer for function-with-magic, or include magic always?
- [ ] Initializer variants which contain property attributes too?
- [ ] Add public API call `duk_def_prop_list()` and implement the initialization code
- [ ] API test case
- [ ] API documentation
- [x] Update module example, grep for other refs to API calls
- [ ] Extras and example fixes
- [x] Deprecation note for duk_put_function_list() and duk_put_number_list(), ensure these calls are in Duktape 2.x removal list => 2.0 pull for removal #892
- [x] Open issue: should property attributes be included in the property description? If so, proper API call name would maybe be `duk_def_prop_list()` => Yes.
- [ ] Open issue: ability to provide property keys through value stack for special values?
- [ ] Open issue: should function call get property count or should a sentinel be used instead? Sentinel is more footprint expensive
- [ ] Open issue: support fixed/dynamic/external buffer variants?
- [ ] Open issue: support for bufferobjects directly?
- [ ] Open issue: while lightfunc push API call `duk_push_c_lightfunc()` always takes a function, nargs, length, and magic, maybe the initializer should omit virtual length and magic and default length from nargs and set magic to 0; a separate initializer variant could then take all the fields? Not all lightfuncs need e.g. magic, and this would match behavior of ordinary native functions.
- [ ] Automatic .prototype for functions (flag?): https://github.com/svaarala/duktape/issues/732#issuecomment-216939398
",15852088
426,2016-01-28T23:07:00Z,2016-12-13T15:08:10Z,,,"Ecmascript semantics differentiate between the current value and the initial value of certain built-ins. For example for [Array constructor](http://www.ecma-international.org/ecma-262/5.1/#sec-15.4.2.1):

> The [[Prototype]] internal property of the newly constructed object is set to the original Array prototype object, the one that is the initial value of Array.prototype (15.4.3.1).

Duktape implements this internally by keeping an internal array (`thr->builtins[]`) of built-in object references needed to implement correct semantics.

This is a current limitation in sandboxing however: there's no way to replace these internal references which means that even if sandboxing code replaces e.g. `Array.prototype` with a custom value, the original Array prototype may still be referenced when one creates an Array literal.

This pull request is a possible solution: add an API call which copies current values of the important built-in references from a target object into the internal reference array. For example, `obj.Duktape` would be copied to `thr->builtins[DUK_BIDX_DUKTAPE]`.

Compared to other alternatives this is nice because the internal structure, the array model or its indices, is not exposed. Adding or removing values from the internal array has no API impact, but will still correctly update any new internal references required for new semantics.

Open issues:
- [ ] Target object could be the new global object, so that this call would also deprecate `duk_set_global_object()` and resolve its limitations.
- [ ] Most internal values can be looked up through the global object, but not all: what about e.g. global environment record? Should user code provide it, or should it be automatically recreated as an internal implementation detail?
- [ ] What to do if copying fails due to an error? (Most likely: leave a partially updated array in place.)

Tasks:
- [ ] Finalize API model
- [ ] Implement new API, copy list can be a sequence of (stridx, bidx) pairs (plus maybe a few exceptions)
- [ ] API testcases
- [ ] API documentation
- [ ] Sandboxing documentation
- [ ] Sandboxing example
- [ ] Figure out what to do about `duk_set_global_object()`: can it be deprecated (and removed in Duktape 2.x) with this API call in place?
- [ ] Releases
",15852088
427,2016-01-14T15:41:51Z,2016-12-13T15:08:10Z,,,"- [ ] Add a test file with various const-to-nonconst cast alternatives
- [ ] Check if `DUK_LOSE_CONST` fill-in could cast through a union to avoid dependency on `(u)intptr_t` type which is not guaranteed to exist (see https://github.com/svaarala/duktape/issues/530#issuecomment-171674359)
- [ ] Update code issues: best practice for losing const, note that intptr_t are not guaranteed to exist so avoid them
- [ ] Open a pull for the remaining intptr_t usages to remove remaining dependencies on the type
",15852088
428,2016-01-02T12:11:08Z,2018-05-28T12:35:30Z,,,"- [x] Finalize handling for error throw when no catcher is active: for setjmp/longjmp the situation is detected based on jmpbuf pointer being NULL; #635 added the necessary state to do the same for C++, but as things are now, C++ uncaught exception handling is invoked instead of the Duktape fatal error handler
- [ ] Try to avoid duplication in user exception catch blocks => #1915
- [ ] Add some public API exposed define (`DUK_CPP_EXCEPTIONS`) for checking that C++ exceptions are supported, so that user code can #ifdef check and avoid silent errors if Duktape options are incorrect for code depending on C++ automatic cleanups
- [x] Testcase coverage: either custom test target, or add C++ support for runtests (and run them with DUK_USE_CPP_EXCEPTIONS)
- [ ] Config option handling: now platform fill-ins will provide `DUK_SETJMP` even when it's not needed with `DUK_USE_CPP_EXCEPTIONS`, maybe worth fixing
",15852088
429,2015-12-07T23:26:06Z,2016-12-17T02:22:11Z,,,"- [ ] Accept any buffer object as a duk_push_buffer_object() base value; new buffer object will a previous offset into account so that it effectively creates a slice against the existing buffer object.
- [ ] When creating typed arrays and the base value is `ArrayBuffer`, should the result `.buffer` be the argument ArrayBuffer, or a fresh ArrayBuffer with the same backing buffer? In other words, should ArrayBuffer be the only special argument which doesn't trigger creation of a fresh ArrayBuffer?
- [ ] Behavior for plain buffer arguments: as is
- [ ] Behavior for ArrayBuffer arguments
- [ ] Behavior for Node.js Buffer and Duktape.Buffer arguments
- [ ] Behavior for typed array arguments
- [ ] Behavior for DataView arguments
- [ ] Behavior of offset clamping when the argument is a slice: should original slight length be respected (clamped or otherwise)?
- [ ] API testcase updates: basic cases
- [ ] API testcase updates: range/wrap checks
- [ ] Website update
- [ ] Internal document update
- [ ] Wiki update
- [ ] Releases
",15852088
430,2015-10-19T18:48:41Z,2016-12-13T15:08:09Z,,,"For now this is a quick prototype branch for adding property multi get/put API calls, so that there's something concrete to reflect on.

Issues:
- [ ] Jansson API provides keys as va_args too (e.g. ""s:s"" -> key string, value string) which is more flexible but less literal
- [ ] What should be the ""get"" operation: should it be a ""duk_to_int"" vs. ""duk_get_int"" for integers, for example? Lowercase for ""get"", uppercase for ""to""?
- [ ] What should happen when a property is not found? Error? Write a default value (e.g. zero for number, false for boolean, empty string for string)? Write nothing, so that caller can pre-assign default?
- [ ] What should happen if no coercion is used and the property has the wrong type? Ignore? Error? Use default value?
- [ ] Characters for all relevant types
- [ ] Ability to specify property attributes (would be useful for internals where attributes are often important)
- [ ] Finalize get and put operations
- [ ] Find at least a few internal call sites for each to offset footprint impact
- [ ] API documentation, link to wiki examples
- [ ] API testcases
- [ ] Releases entry
",15852088
431,2020-03-26T16:05:22Z,2020-03-26T17:25:13Z,,,"In a typical Jitsi Meet setup, this plugin can be used to limit the number of occupants in a meeting room, while ignoring ""utility"" users. Such a configuration could be:

    muc_max_occupants = 2
    muc_access_whitelist = {
        ""focus@auth.meet.jitsi"";
    }

It would be expected that this configuration allows two users to attend the meeting room, but in practice only one is allowed, because the whitelist is not honoured.

This commit fixes it by actually updating the `user` and `domain` variables being checked. After this change, the scenario above works just fine.",15225670
432,2020-03-25T21:32:07Z,2020-03-26T19:10:45Z,,,,15225670
433,2020-03-25T11:36:26Z,2020-03-26T13:50:24Z,,,,15225670
434,2020-03-25T11:32:39Z,2020-03-25T13:23:52Z,,,,15225670
435,2020-03-25T11:18:49Z,2020-03-25T11:20:58Z,,,,15225670
436,2020-03-25T11:15:16Z,2020-03-25T11:20:21Z,,,"""toggle camera"" is to switch front to rear or rear to front.
The french translation said ""on/off camera"", it's not exactly that",15225670
437,2020-03-25T10:16:37Z,2020-03-25T10:20:16Z,,,"Fix ""toggleCamera"" description. switch instead of turn off/on",15225670
438,2020-03-25T09:30:52Z,2020-03-25T09:30:52Z,,,,15225670
439,2020-03-24T23:24:46Z,2020-03-24T23:39:38Z,,,Added Ukrainian language code,15225670
440,2020-03-24T12:46:59Z,2020-03-24T12:50:15Z,,,New JSON properties cloned from main.json,15225670
441,2020-03-24T12:27:24Z,2020-03-24T12:27:24Z,,,@saghul @damencho ,15225670
442,2020-03-24T11:59:43Z,2020-03-24T14:58:44Z,,,"- manage recording audio notifications through config

@saghul @damencho ",15225670
443,2020-03-23T16:46:51Z,2020-03-23T19:22:34Z,,,Full translation to Estonian language,15225670
444,2020-03-23T12:02:20Z,2020-03-24T08:17:20Z,,,"lodassh's startCase asscii-fiess everything, removing umlauts and accents, for
example.

Fixes: https://github.com/jitsi/jitsi-meet/issues/5223",15225670
445,2020-03-23T02:17:39Z,2020-03-24T14:20:02Z,,,"- removed paragraph about old Debian Wheezy, the link is broken, and Wheezy doesn't even get security updates anymore, so seems unlikely anyone would do a new install with it.
- clarified that Let's Encrypt script uses only the HTTP challenge.
- added links to a few things that newbies might want to look up (nginx, apache, jetty, SIP, FQDN, Let's Encrypt, etc.
- added some basic debugging starting points, based on my experience
- some minor grammatical tweaks
- other minor tweaks",15225670
446,2020-03-22T00:59:18Z,2020-03-23T21:56:03Z,,,"I realized that the change for Mute Everyone Else doesn't have the spanish dialogues, I added it and also some another typos.

Signed-off-by: Esteban Badilla A <ebadilla10@gmail.com>",15225670
447,2020-03-20T01:40:26Z,2020-03-20T21:02:40Z,,,"For sites that focus on collaborative editing during meetings, add
an option which, when set, will automatically open etherpad when a
participant joins.",15225670
448,2020-03-19T19:05:43Z,2020-03-26T11:10:46Z,,,Worldwide users will profit from the change to auto-detect the browser language and to startup the interface with their language.,15225670
449,2020-03-19T10:35:42Z,2020-03-19T19:06:20Z,,,"This is specially useful in europe where you have to provide a link to legal information
and your privacy policy. There are still a couple of things to discuss:

- [ ] Rename option?
- [ ] SCSS vars for margin and color?
- [ ] Maybe add option to add to conference screen?
- [ ] Translation?

Screenshot:
![2020-03-19 11 31 42 localhost a9f4fe4d87d0](https://user-images.githubusercontent.com/2974196/77058104-44b6c280-69d5-11ea-9ec9-3050c07bb907.png)
",15225670
450,2020-03-19T02:46:27Z,2020-03-21T04:02:56Z,,,":-) hacks to support android screen sharing.

1. implements  mediaDevices.getDisplayMedia

2. tricks lib-jitsi-meet to accept using mediaDevices.getDisplayMedia to obtain screen stream.

3. hajack WebRTCModule and its js scripts, add support to create screen stream.

4. feeds screen frames to the deliverer at a fixed framerate(interpolate frames with generated timestamp) to avoid connection problems.

5. adjust toggle camera button behaviors.(hide in screen sharing mode)

6. do not mute video stream and set lastN to 1 in android screen sharing mode when go background.

![QQ图片20200311153930](https://user-images.githubusercontent.com/16893158/76393505-a44a1800-63ae-11ea-9ae9-0e6a2e9d1dcf.jpg)

 :-) i haved tesed that feature on my android phone. one thing i figured is that hangingup in screen shareing mode and return to the welcomepage,  the backgroud is the output of screen video stream. i will optimize it later.",15225670
451,2020-03-18T13:31:09Z,2020-03-19T10:57:27Z,,,Thank you for your work!,15225670
452,2020-03-18T12:55:50Z,2020-03-18T19:17:49Z,,,"General principles followed while creating these changes:

- Simplify language and length of sentences where possible, while retaining the same meaning
- Replace lengthy related documentation with shorter commands where possible
- Recommend easier approaches (for example, hosted Jitsi) to reduce user effort
- Arrange the document so that users can follow it in-order and get confirmation of a working system early
- Commit each documentation change individually to allow easy reviews & reverts

I've tested the process locally using Ubuntu 19.10.  It'd be good to confirm that `/etc/issue` and `apt-add-repository` exist as far back as Debian Jessie if this is still to be indicated as the oldest supported version.

I haven't modified any of the 'advanced' or 'uninstall' sections.",15225670
453,2020-03-17T22:39:50Z,2020-03-19T07:23:12Z,,,This PR fixes both https://github.com/jitsi/jitsi-meet/issues/5209 and https://github.com/jitsi/jitsi-meet/issues/5000,15225670
454,2020-03-13T23:57:36Z,2020-03-20T10:16:39Z,,,"Bumps [acorn](https://github.com/acornjs/acorn) from 5.4.1 to 5.7.4.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/acornjs/acorn/commit/6370e90067552022710190319cbbbd8c43001957""><code>6370e90</code></a> Mark version 5.7.4</li>
<li><a href=""https://github.com/acornjs/acorn/commit/fbc15b1344f6dfb992f67b4bbf1357436247c8a0""><code>fbc15b1</code></a> More rigorously check surrogate pairs in regexp validator</li>
<li><a href=""https://github.com/acornjs/acorn/commit/910e62bbda199ce7acc5de10d374afa0f6fcf7d6""><code>910e62b</code></a> Mark version 5.7.3</li>
<li><a href=""https://github.com/acornjs/acorn/commit/3442a80d2cdfa672ae2b6ccd6c2bd5c167914db4""><code>3442a80</code></a> Make generate-identifier-regex capable of rewriting src/identifier.js</li>
<li><a href=""https://github.com/acornjs/acorn/commit/22b22f36330d41a20225f26aab314d3e9d5452bd""><code>22b22f3</code></a> Raise specific errors for unterminated template literals</li>
<li><a href=""https://github.com/acornjs/acorn/commit/1461c7c5778933514126216fb3ec22d8dfc57feb""><code>1461c7c</code></a> Fix a lint error</li>
<li><a href=""https://github.com/acornjs/acorn/commit/0c12f63f171d8a6c8b354de54a7ff4a8d5fa486e""><code>0c12f63</code></a> Fix tokenizing of regexps after .of</li>
<li><a href=""https://github.com/acornjs/acorn/commit/832c3081da0df0a586cfc3ea96040f64252088b7""><code>832c308</code></a> Fix 404 url</li>
<li><a href=""https://github.com/acornjs/acorn/commit/95ca55c7863fafd8bf6d446a0098325388ff9f1c""><code>95ca55c</code></a> Mark version 5.7.2</li>
<li><a href=""https://github.com/acornjs/acorn/commit/bba80abc23ed67337a6502b8b0f22675c4b22303""><code>bba80ab</code></a> Remove another fixed test from the 262 whitelist</li>
<li>Additional commits viewable in <a href=""https://github.com/acornjs/acorn/compare/5.4.1...5.7.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=acorn&package-manager=npm_and_yarn&previous-version=5.4.1&new-version=5.7.4)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/jitsi/jitsi-meet/network/alerts).

</details>",15225670
455,2020-03-13T12:19:04Z,2020-03-25T08:10:50Z,,,Relates to https://github.com/jitsi/jitsi-meet/pull/5124,15225670
456,2020-03-10T12:05:01Z,2020-03-25T14:32:45Z,,,First part of a two-part feature that makes chat push the content to the side rather than display over it. The large-view implementation is underway.,15225670
457,2020-03-06T14:57:59Z,2020-03-06T17:31:34Z,,,,15225670
458,2020-01-24T16:59:03Z,2020-01-25T07:42:30Z,,,"excluding special locations (bosh, xmpp, legacy lib).
addresses #3811",15225670
459,2020-01-10T17:48:33Z,2020-01-15T15:47:01Z,,,"The PR fixes a potential NPE due to calling `getActivity()` when it could be null while running the execution of `onCreateView()`.

The fragment itself seems to be of little value to an end user dev:

- The view is harder to access as in the demo Activity the current fragment has to be checked if it is an instance of the JitsiMeetFragment (a code smell unto its self) then multiple code paths need to exist to handle the possibility of null.

- The nature of inheritance means I am forced as a dev to use the JitsiMeetFragment as the base class, which in turn uses Android X's own Fragment (not necessarily a bad thing). This does cause problems however when an existing project has its own base fragment class.

- The lifecycle callbacks can be handled safely within the activity with no risk of the method getActivity() being null as they will be called from the activity itself.

- The Activity's `getJitsiView()` is brittle as from the Activity's point of view it does not have any guarantees that the Fragment returned is going to be the casted type, which could lead to a Cast related exception. Unlikely in the current setup admittedly but could easily be missed in future code changes.

- While it is fine the Fragment handles `onActivityResult()` I debate the value of having the static method called from there as the Activity will be called first then the Fragment. Before I made any changes it already handled this.

- Without `setRetainInstance(true)` set on the Fragment `onDestroy` should always occur after `onDestroyView()` the changes in the PR reflect this by calling JitsiView's `dispose()` method in the Activity's `onDestroy()`. A potentially better change is that given the current paradigm - Android View's have an overridable method called `onDetachedFromWindow()`, which would be called around `onDestroy()`, which means we *could* move the `dispose()` method internal to `Jitsiview` and abstract it completely.

- Minor point but the layout file is now simpler as the FrameLayout is unnecessary and has been removed. This should produce a negligible performance boost with redraws. ",15225670
460,2019-10-03T19:01:36Z,2020-01-07T14:05:09Z,,,"If phone number to be invited into the conference ends with a comma then
the following part will be stored in redux state and sent later as DTMF
tones after Jigasi connects to the conference.",15225670
461,2019-08-28T10:48:15Z,2020-02-18T19:48:15Z,,,"Added a way to enable/disable Toolbar and overlay options from native.
Added toolbar.buttons flag to enable/disable buttons. Now whatever buttons we pass in 'toolbar.buttons' from native, will get enabled.
Added DEFAULT_TOOLBAR_BUTTONS, So if toolbar.buttons did not passed from native then this default value will work.
For recording in android 'toolbar.buttons' will work and for iOS, it will check previous flag(ios.recording.enabled) and 'toolbar.buttons' both.",15225670
462,2019-05-06T21:03:09Z,2019-11-12T11:25:55Z,,,,15225670
463,2018-10-08T09:49:07Z,2020-03-26T10:13:45Z,,,"Allow jitsi meet to run on a mobile browser based on a config parameter in the ""interface_config.js"".

This topic came up a couple of times in the mailing list and the current solution as suggested  [here](https://github.com/jitsi/jitsi-meet/issues/1662#issuecomment-329813550) is not ideal.

This feature is really useful for audio only requirements in apps that integrate with jitsi meet through the external api.

**Note:** Running jitsi meet in the browser of a device is useless where webrtc is not supported.  ",15225670
464,2019-11-12T21:11:14Z,2019-11-12T21:20:55Z,,,"Issue this pull request references: #481

Changes proposed in this pull request:

 - implemented unit test which is validating whether a lambda from Chaiscript could return a boolean value without throwing any exception,
 - the same test case is checking also whether lambda with boolean return value
could be called peacefully from Chaiscript.
 
After pull request #503 will be resolved, this test will pass; for now it's producing 2 failed checks:

```
/home/draghan/programming/ChaiScript/my/ChaiScript/cmake-build-debug/compiled_tests

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compiled_tests is a Catch v2.2.2 host application.
Run with -? for options

-------------------------------------------------------------------------------
Lambdas can return boolean
-------------------------------------------------------------------------------
/home/draghan/programming/ChaiScript/my/ChaiScript/unittests/compiled_tests.cpp:53
...............................................................................

/home/draghan/programming/ChaiScript/my/ChaiScript/unittests/compiled_tests.cpp:63: FAILED:
  CHECK_NOTHROW( result = chai_function() )
due to unexpected exception with message:
  bad any cast

/home/draghan/programming/ChaiScript/my/ChaiScript/unittests/compiled_tests.cpp:65: FAILED:
  CHECK( result == true )
with expansion:
  false == true

Hello World
Object_Copy_Count_Test()
Object_Copy_Count_Test(Object_Copy_Count_Test &&)
~Object_Copy_Count_Test()
~Object_Copy_Count_Test()
10
10
Test
15
15
making vector
adding config item
returning vector
St6vectorI25Returned_Converted_ConfigSaIS0_EE
Info: 1 0x1bfc240
num_iterations 5
something_else 10
a_string string
a_function 3
1.3
found at 1, 2
A
ok
5
===============================================================================
test cases:  51 |  50 passed | 1 failed
assertions: 190 | 188 passed | 2 failed


Process finished with exit code 2
```",1226823
465,2019-11-10T17:25:07Z,2019-11-10T17:25:07Z,,,"When a script function returning a boolean is called from C++ code, ChaiScript tries to initialize a `Boxed_Number` with the returned value. A *bad any cast* exception is then raised.

The proposed modification checks if the return value is a (possibly *cv-ref* qualified) `bool`, before instantiating the `Boxed_Number` (leading to a `boxed_cast` instead).
",1226823
466,2019-04-23T16:41:06Z,2019-04-26T07:05:10Z,,,"Issue this pull request references: https://github.com/ChaiScript/ChaiScript/issues/477

Changes proposed in this pull request

 - Handle the \u escape inside the json string parser
 
",1226823
467,2019-04-21T18:13:33Z,2019-04-21T18:29:14Z,,,"Issue this pull request references: [Discussion in forum thread](http://discourse.chaiscript.com/t/convert-complex-chaiscript-types-e-g-map-of-map-to-user-defined-types/143/7)


Changes proposed in this pull request

 - add a `pair_conversion()` registration helper, analogous to the existing `vector_conversion()` and `map_conversion()` helpers.
 - implement a compiled unit test for the new feature.
 ",1226823
468,2019-04-21T10:21:40Z,2019-04-21T11:05:13Z,,,"Issue this pull request references: #321 

Changes proposed in this pull request

- add `operator bool()` cast to test if an Assignable_Proxy_Function has a callable.
- add `clear()` to reset/empty the callable function.
- include new compiled test case to work with (setting, testing, calling and clearing) callback functions in C++ objects.
",1226823
469,2018-03-05T18:07:08Z,2018-12-28T20:50:48Z,,,"…tatement to compare destroyed objects

I added a Function_Push_Pop to save the match_value and the value from evaluating the case statement. This makes the code look like Fold_Right_Binary_Operator_AST_Node::do_oper, which does not have the same defect behavior.

Issue this pull request references: #421

Changes proposed in this pull request

 - chaiscript_eval.hpp: Switch_AST_Node::eval_internal
 
",1226823
470,2020-03-26T03:31:50Z,2020-03-26T03:59:47Z,,,"The cmake build emits errors similar to here: [1] when
the CMAKE_SIZEOF_VOID_P variable is not defined. Not sure
why it's not defined in some cases, but this is an easy fix.

    CMake Error at CMakeLists.txt:77 (if):

        if given arguments:

        [...........]

    Unknown arguments specified

[1] https://stackoverflow.com/a/39733128",13352949
471,2019-04-18T23:54:04Z,2019-04-20T19:59:51Z,,,__DATE__ causes builds to be non-reproducible and should be avoided.,13352949
472,2019-03-07T11:26:27Z,2019-11-02T20:35:52Z,,,Adds new API allowing to customize client HTTPS connections.,13352949
473,2019-02-17T19:26:56Z,2019-08-05T11:54:36Z,,,"Fixes #378

- modified v8::Date::DateTimeConfigurationChangeNotification to take second parameter which can be used to fix this issue
- modification is now in V8 master, so should be included in next release (>7.4)
- the fix and test are enabled when building with V8 version >=7.5
- modification in code can be enabled manually by defining V8JS_V8_TIME_ZONE_REDETECTION_SUPPORTED=1 to be able to use the fix with current V8 master

Please let me know if there's a better way to handle the compatibility with different V8 versions.",4160039
474,2020-01-17T21:24:04Z,2020-01-24T18:36:35Z,,,"As noted in https://github.com/terralang/terra/issues/422#issuecomment-574390811, LuaJIT 2.0 is broken in macOS Catalina. Rather than following Homebrew and maintain custom patches for 2.0, just upgrade to 2.1 where the problem does not exist in the first place.",5939005
475,2019-10-25T21:07:41Z,2020-01-08T05:00:33Z,,,"Adding syntax for a switch statement to the language.
The chosen syntax is
 ```
switch expr do
  case expr then
    block
  case expr then
    block
  else
    block
end
```
This includes the addition of two new keyword tokens `switch` and `case`, but avoids the addition of any other keywords that most implementations would use such as `default`.
This syntax is still up for discussion.

There is no case fallthrough by default; adding optional case fallthrough is future development.",5939005
476,2019-06-22T20:23:32Z,2020-01-22T00:23:50Z,,,"I think I managed to grab all the changes for the variable synthesis and nothing else.
This fixes a bug where accessing the self parameter of an iterator multiple times can cause unexpected behavior.",5939005
477,2019-02-12T23:55:55Z,2019-10-11T16:45:31Z,,,"This is an initial implementation of #324 

Only the basic syntax is implemented, so using commas to chain annotations doesn't yet work.",5939005
478,2019-02-02T14:47:48Z,2019-04-20T09:36:15Z,,,some minor improvements found by [luacheck](https://github.com/mpeterv/luacheck/).,5939005
479,2018-12-11T00:36:49Z,2019-08-20T22:17:41Z,,,"Current status:

 - [x] Regent
 - [x] Rigel

Deferred:

 - Opt

Others?",5939005
480,2018-11-16T17:51:15Z,2020-01-29T20:02:06Z,,,"This branch adds support for compiling Terra against PUC Lua (i.e. the original Lua implementation). Support for LuaJIT is preserved and existing users should be unaffected. Currently Lua version 5.1 is required.

To test, build as follows:

```
TERRA_USE_PUC_LUA=1 LUA_VERSION=5.1.5 make
```

The current support is sufficient to define Terra functions, and to call `terralib.saveobj`. Directly calling Terra tasks from within the same process is not supported. The limiting factor here is that the `ffi` library for Lua is not portable, so this support needs to be reimplemented in a portable way. In theory, this should be doable by JIT'ing the necessary glue code from Terra, but this is not yet implemented.

This branch is most beneficial on architectures like PPC64le, where LuaJIT is currently unsupported.",5939005
481,2016-08-24T18:55:21Z,2019-09-19T07:05:05Z,,,"Added some more cases for asvalue() and a unit test that I find useful in what I am doing (line 871 ..).
About all the line changes, my emacs config automatically removes trailing whitespaces; let me know if this is too annoying and I'll submit another PR without those.
",5939005
482,2016-06-27T05:31:30Z,2016-06-27T05:31:30Z,,,"NOTE: Pull request is broken. Only providing the patch for discussion.

See https://www.lua.org/manual/5.1/manual.html#pdf-debug.traceback - The override of debug.traceback in terralib does not respect the thread parameter.

You get something like this:

```
$ terra

Terra -- A low-level counterpart to Lua

Stanford University
zdevito@stanford.edu

> = debug.traceback(coroutine.running(), 'on noez!', 2)
src/terralib.lua:433: attempt to perform arithmetic on local 'level' (a string value)
stack traceback:
    src/terralib.lua:433: in function <src/terralib.lua:431>

```

Compare to Lua:

```
~/Projects/plop $ lua
Lua 5.2.4  Copyright (C) 1994-2015 Lua.org, PUC-Rio
> = debug.traceback(coroutine.running(), 'on noez!', 2)
on noez!
stack traceback:
    [C]: in ?
> ^D
```

I tried to fix the definition of debug.traceback in terralib, but the obvious solution produced 'error in error handling' for some non-obvious reason. I'll take another look at it soon if you don't have an idea offhand.
",5939005
483,2015-09-19T09:36:50Z,2015-09-19T09:36:50Z,,,"Two commits here, the first is the multiarch updates you requested.
Unfortunately I ran into a bit of a problem, it seems that the clang-dev and llvm-dev packages aren't actually multarch aware yet (for ""jessie"").  Nevertheless, as all except the final link works correctly I expect it will happen quickly after the packager decides that it needs doing ""now"". 

The result is that it _should_ compile using ""make TARGET_ARCH=-m64"" as soon as the libraries become available, but right now the only completely tested part of these changes is actually running the 64bit executable on a, mostly, 32bit system. (which now works correctly for all your tests)

The second commit is a minor tidy-up of the .gitignore files.
",5939005
484,2020-03-25T00:06:43Z,2020-03-26T19:37:36Z,,,"* Enchance Database’s close() and delete() to stop active replicators and live quries befoer closing the database.
* Changed Database’s delete() to call close() then use static delete() to delete the database.
* Fixed live query stop logic to wait until the pending query’s execution or refreshing is done before removing itself from the database’s active live queries list.
* Not allow to start a new replicator and a live query when database is closing.",7948548
485,2019-12-03T17:28:39Z,2020-01-05T21:01:06Z,,,"**Description**
Optinal Fix decoder hangups reported in #763 
**Purpose**
Add an optimal preprocessor definition #SKIP_OMX_CLEANUP  (controlled by a cmake option) 
if we generate the project with cmake  p
`cmake ../<source_code_dir> -DSKIP_OMX_CLEANUP `
then the SKIP_OMX_CLEANUP symbol will be defined and  some omx  decoder methods will not be called during cleanup. This fixe our decoder freezing issues  with GFE 3.17 that we reported in  #763 .
Since this is a dirty workaround for us, we have decided not to enable it by default and leave current behaviour as is. If nobody reports any drawbacks, it would be interesting to have it on by default.",15691240
486,2020-03-03T06:46:39Z,2020-03-03T06:53:24Z,,,,6905493
487,2020-03-12T14:10:14Z,2020-03-24T00:46:41Z,,,"All platforms use: `typedef uint64_t uint64;` so the rest should be defined the same way
or 
use stdint fixed width types instead without defining own types  (since stdint fixed width types is part of C since C99  and iwasm depends on them anyway on all platforms)

`grep -r 'typedef .* uint64': `

    core/shared/platform/android/bh_platform.h:typedef uint64_t uint64;
    core/shared/platform/riot/bh_platform.h:typedef uint64_t uint64;
    core/shared/platform/zephyr/bh_platform.h:typedef uint64_t uint64;
    core/shared/platform/linux/bh_platform.h:typedef uint64_t uint64;
    core/shared/platform/vxworks/bh_platform.h:typedef uint64_t uint64;
    core/shared/platform/linux-sgx/bh_platform.h:typedef uint64_t uint64;
    core/shared/platform/darwin/bh_platform.h:typedef uint64_t uint64;
    core/shared/platform/alios/bh_platform.h:typedef uint64_t uint64;
",184654298
488,2020-03-26T16:45:50Z,2020-03-26T16:52:13Z,,,"### Pull Request Overview
Add notes from today's meeting.

### Testing Strategy

This pull request was tested by...


### TODO or Help Wanted

This pull request still needs...


### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
489,2020-03-25T16:38:03Z,2020-03-26T09:20:37Z,,,"### Pull Request Overview

This pull request adds a [Cargo workspace](https://doc.rust-lang.org/book/ch14-03-cargo-workspaces.html) at the top-level directory to make build reproducible (see the analysis in https://github.com/tock/tock/issues/1666#issuecomment-603863887).


### Testing Strategy

This pull request was tested by:
- Duplicating the Tock directory (two identical copies in `/path/to/tock` and `/path/to/tock2`), and running `make allboards`, checking that the SHA-256 checksum match.
- Travis-CI.


### TODO or Help Wanted

This pull request still needs:
- [ ] Fixing netlify.
- [ ] A bit of cleanup throughout Makefiles. For now I made just enough changes in `boards/Makefile.common` for `make ci-travis` to work, but other make rules should be checked.
- [ ] I had to remove the `tools/check_wildcard_imports.sh` in `make ci-travis` because otherwise it reported the following error. The tool would need some refactoring.
  ```
  Wildcard import(s) found in ..
  Tock style rules prohibit this use of wildcard imports.
  
  The following wildcard imports were found:
  libraries/tock-register-interface/src/macros.rs:                use super::super::*;
  tools/check_wildcard_imports.sh:        if $(git grep -q 'use .*\*;' -- ':!src/macros.rs'); then
  tools/check_wildcard_imports.sh:                git grep 'use .*\*;'
  ```
- [ ] Cargo complained that the `[profile.dev]` and `[profile.release]` rules must be in the top-level workspace. I put them there given that all boards had the same profiles, but it's something to keep in mind if we want to use custom workspace for specific boards. I'm also not sure what's the impact of these profiles on the other libraries in the workspace.


### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
490,2020-03-22T19:14:02Z,2020-03-24T00:09:37Z,,,"### Pull Request Overview

This pull request adds a small rewrite proposal of the alarm capsule, virtual alarm mux and timer to try to fix issues like #1513, #1651, #1691.

The problem is that the alarm system sometimes deadlocks and/or generates alarms in a wrong order and uses a timer that can overflow. The changes proposed are based on the following assumptions:

1. alarms guarantee that they don't fire earlier than the number of tics, but might fire a little later (they are not real time)
2. the alarm does not keep a monotonic timer
3. the mcu timer should not be set to a value in the past, so that is has to overflow

The algorithm that I started from is the following:
1. the alarm is set to fire after n tics (usually 1)
2. every time the alarm fires, the mux informs all the client alarms that a number of tics have elapsed (using the update function)
````rust
pub trait AlarmClient {
    // ...
    /// Inform the alarm that a number of tics have elapsed
    /// empty function if it is ignored
    fn update(&self, _tics: usize) {}
}
````
3. every alarm subtracts from its expiration times the number of tics
  - if it finds an expiration time that should be negative or is 0, it schedules the callback
4. the mux resets the timer and repeats steps 1 to 4

This algorithm has no race as no one interacts with the actual times setup, it just fires after a certain period.

This is not very efficient, as the alarm fires continuously just for subtracting some tics. The following optimization is applied:
1. the mux schedules the alarm to fire after the minimum number of tics of its alarm clients
 steps 2 and 4 are the same

Here we have two race conditions:
  1. when an alarm requires a new timeout (might be smaller than the current alarm)
  2. when an alarm requires a stop

To solve these ones, the timer is disabled temporarily while taking these actions. This will push the fired event a little later, but it is within the assumptions.

This tries to be somehow backward compatible for the user space, preserving alarm syscall number 4, but there might be some issues, as `now` always resets.

### Testing Strategy

This pull request was tested with a nucleo f429zi.

### TODO or Help Wanted

This pull request still needs code review and feedback, testing and adapting other chips to use it.

### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
491,2020-03-18T22:24:57Z,2020-03-26T16:21:24Z,,,"### Pull Request Overview

This PR is the initial attempt to add HMAC support to Tock and OpenTitan.

Currently the HMAC API is similar to the AES API.

Until https://github.com/lowRISC/opentitan/issues/1276 is addressed we just have to write all the data. Once the issue is fixed we can use interrupts to asynchronously write the data (similar to UART).

### Testing Strategy

It builds

### TODO or Help Wanted

I wanted to get some feedback on the API. It seems like the AES API isn't accessible from userspace. Do we want the same for HMAC or should I add a capsule that can expose HMAC to userspace?

### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [X] Ran `make formatall`.
",36428094
492,2020-03-18T20:09:05Z,2020-03-25T17:23:12Z,,,"### Pull Request Overview

This pull request adds two scripts and modifies Travis so that PRs are automatically updated with ""statuses"" (shown at the bottom of the PR) on how they affect flash/memory use by the Kernel (as reported by @phil-levis script (#1673) .

Currently, this is configured to only run on PR builds (not push builds), and so will only run on PRs that are currently mergeable (don't need rebase). It reports the difference in size between the target branch before and after merging in the PR. This information is reported in the `after_success` block `.travis.yml`, and so is only reported after travis has successfully completed. A side-effect of this is that any failure in this script will not result in a failure of travis reporting the status of the build (instead, the only result of a failure is that these diffs will not be reported).

Notably, the script only reports size changes for boards where this value has changed! So if a PR only affects Nordic boards, the size changes will only be reported for those boards.

This PR does not report size differences for RISC-V boards, as the size reporting script does not support analyzing RISC-V binaries.

To observe the results of this script, please see #1695 , (click ""show all checks"") which has an example PR that modifies 3 boards.


### Testing Strategy

This pull request was tested mostly using #1695 . For PRs with small modifications, it only seems to increase Travis build times by about 30 seconds.


### TODO or Help Wanted

This pull request currently includes a copy of Phil's `print_tock_memory_size.py` script, which will need to be removed once #1673 is merged.

Currently, status posting is enabled by using an OAuth Personal Token that I generated which is set as a hidden environment variable available in Travis CI (when printed to the Travis CI log it is redacted). This token only grants the ability to post commit statuses. As a result, my Github profile image shows up next to every status. I tried for awhile and could not figure out how to get it to work using the Travis-CI identity -- as far as I can tell Travis does not expose its token in the shell environment. It might make sense to change this token to be one generated by @alevy or @bradjc , and I am happy to change it if that is preferred.

Also, my shell scripting abilities leave plenty to be desired, so any comments there are welcome..

### Documentation Updated

- [ ] Should I document this somewhere?.

### Formatting

- [x] Ran `make formatall`.
",36428094
493,2020-03-18T18:29:25Z,2020-03-25T17:21:58Z,,,"### Pull Request Overview

This pull request adds a charter for the core working group. This is a bit of a formalization of the existing CoreTeam.md document.


### Testing Strategy

n/a


### TODO or Help Wanted

Comments


### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
494,2020-03-18T18:05:38Z,2020-03-25T17:21:20Z,,,"### Pull Request Overview

Fixes #1634


### Testing Strategy

hello_loop on hail still works.


### TODO or Help Wanted

n/a


### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
495,2020-03-17T20:21:13Z,2020-03-22T13:02:49Z,,,"This is an example PR to show how #1701 will work once merged into master.

The example PR here modifies 3 boards. It removes the RNG from Imix and Hail, and increases the APP_MEMORY size for a nucleo board by 20kB. Because APP_MEMORY is not counted as part of kernel memory, there is no diff shown for the nucleo board.

Click ""see statuses"" to see the reported diff of code size / memory for each board.",36428094
496,2020-03-14T13:15:22Z,2020-03-18T16:48:01Z,,,"### Pull Request Overview

Following the discussion for #1675, this pull request adds the possibility to add None gpio pins, basically preserving pin index numbers when some of the gpio pins are not exported.

I make a change to:
- the gpio capsule, taking Option<&InterruptValuePin>
- the gpio_component_helper macro, so that boards may declare None pins

The format is a little strange, boards need to declare
````
Some => pin
// or
None => any_expression_here
````

Is there any way to check inside a macro if the value supplied is None (textual None) or an expression?

Any feedback is welcome.",36428094
497,2020-03-11T14:00:38Z,2020-03-16T16:12:06Z,,,"### Pull Request Overview

This pull request adds a Platform trait fn for filtering syscalls, and an enum for representing the filtering decision.  This is the first part of a solution for #1350, which I think is a good incremental piece.  It will also flexibly allow trying new filtering ideas without mandating them across platforms.

### Testing Strategy

This pull request was tested by `make allcheck`, no device testing.

### TODO or Help Wanted

This pull request still needs eyes on the design.

### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [X] Ran `make formatall`.
",36428094
498,2020-03-08T12:39:56Z,2020-03-14T11:10:16Z,,,"### Pull Request Overview

This pull request adds to the gpio capsule the api necessary to search a
pin index based on the pin id supplied by the board (usually PORT << 4 | PIN_NUMBER).

Some boards (like the STM Discovery kit) do not have gpio pins numbered in a
continuous order on the PCB print. Most of the boards print something similar
P_PORT_XX. If a user writes an app without knowing the exact order in which pins were
set up by the board file, it is difficult to implement portable apps. Any change in the board
file must be reflected by a change in the app's source code.

With this patch, users that write apps are able to use _command_ syscall with function 10,
supply a pin id (the same as provided in the board support) and get the index on which the
pin was registered. Then they can than safely use the pin index. If there is any change in the way
pins are registered by the board, the search function will just return a different 
index (or EINVAL).

I have also submitted a patch with the new corresponding API to libtock-c.

### Testing Strategy

This pull request was tested with a nucleo f429zi board

### TODO or Help Wanted

Any feedback is very much appreciated.

### Documentation Updated

- [x] Updated the relevant files in `/docs`

### Formatting

- [x] Ran `make formatall`.
",36428094
499,2020-03-07T12:11:15Z,2020-03-26T17:23:34Z,,,"### Pull Request Overview

This pull request adds initial support for the stm32f3xx chip and the stm32f3discovery board.
It is useful as the stm32f3discovery boards are very useful for use in class being inexpensive and having most of the features required for mcu labs and trainings.

Features:
  * Button
  * LEDs
  * USART1 console writing 
  * GPIO
  * EXTI
  * alarm (for delay)

Still in progress: usart via dma, reading from usart, adc and other peripherals.

This was inspired from the stm32f4xx chip and stm boards.

Any feedback would be greatly appreciated.

### Testing Strategy

This pull request was tested with an stm32f3 discovery kit.

### Documentation Updated

- [x] Updated the relevant files in `/docs`.

### Formatting

- [x] Ran `make formatall`.
",36428094
500,2020-03-03T17:31:42Z,2020-03-10T19:44:46Z,,,"### Pull Request Overview

This commit removes the crate_visibility_modifier unstable pragma. The
upgrade path is a slightly nuanced variant of `s/crate/pub(crate)/g`, so
this change is a trivial noop.

### Testing Strategy

This change is a noop, so `make allcheck` is sufficient.

### TODO or Help Wanted

N/A

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
501,2020-03-03T17:02:56Z,2020-03-11T15:23:56Z,,,"### Pull Request Overview

This change is effectively `s/Unique/NonNull/g`, and is the supported upgrade path out of `ptr_internals`; it is effectively a no-op.

### Testing Strategy

`make allcheck` passes; presumably unit tests will catch any other silliness.

### TODO or Help Wanted

N/A

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
502,2020-03-03T16:48:06Z,2020-03-13T15:32:28Z,,,"### Pull Request Overview

For some reason, e310x uses the exclusive_range_pattern pragma to use a `a..b` pattern, though given context this appears to be a mistake, and should be an inclusive range (`a...b`) instead.

### Testing Strategy

See TODO.

### TODO or Help Wanted

This PR needs some kind of testing strategy, since it is not a no-op. I strongly believe that the missing period is a typo, since current implementation seems to just ignore the 31st GPIO pin.

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
503,2020-03-03T16:11:41Z,2020-03-04T15:40:37Z,,,"### Pull Request Overview

This commit removes the use of the unstable pragma ""in_band_lifetimes"" everywhere. The main culprit turned out to be the `capsules` crate.

### Testing Strategy

This change is a noop, since it consits of either adding required lifetime annotations, or changing exlicit lifetimes `'a` to placeholder liftimes `'_`. `make allcheck` should be sufficient to show this change is correct. In general, I tried to make the change that required minimal changes to the AST.

### TODO or Help Wanted

N/A

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
504,2020-02-28T02:10:45Z,2020-03-23T22:55:02Z,,,"### Pull Request Overview

This pull request adds a threat model to Tock's documentation.

This threat model gives a concrete description of the isolation guarantees Tock OS intends to provide. There are a few differences between Tock OS' current implementation and the isolation described in this threat model:

1. `tockloader` does not currently validate the TBF `total_size` field

2. TBF header parsing is not currently robust against hostile headers

3. The current virtualization/multiplexing does not provide the non-starvation property requested by this threat model.

### Testing Strategy

Manually tested that links work. No other testing should be necessary as this is a docs-only change.

### TODO or Help Wanted

I think this should be linked from [doc/README.md](https://github.com/tock/tock/tree/master/doc), but it's unclear which heading it fits under. Should it be under ""Overview and Design of Tock""? ""Tock Implementation""? ""Interface Details""?

### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [X] Ran `make formatall`. No change.
",36428094
505,2020-02-26T17:41:14Z,2020-02-26T17:41:14Z,,,"## Pull Request Overview

This pull request is a proof-of-concept of what it would mean to have a generic lifetime for the `Kernel` object, rather than it being `'static`. It is in the spirit of https://github.com/tock/tock/issues/1074 (generic lifetimes for kernel HILs).

I created this mostly to open the discussion. I made it a pull-request so that it's easier to compare the code, but it's essentially a draft and you can see it as an RFC, to see whether more generic lifetimes (beyond https://github.com/tock/tock/issues/1074) could be useful or on the contrary detrimental.

## Motivation

### When can `'static` be problematic?

There are multiple downsides with `'static` lifetimes.

- They sometimes lead to restrictions in the code, forcing many dependencies to also be `'static`, as highlighted in https://github.com/tock/tock/issues/1074.
- The Rust compiler has a hard time analyzing the memory safety of static data structures (especially mutable ones). It considers that mutable static data can be aliased and accessed concurrently - violating Rust's aliasing rules. This requires the `static_init` macro to be `unsafe` code (and rightfully so, given that calling `static_init` code twice, such as in a loop, would initialize it again without cleaning up old data).
- A corollary of the two previous points is that a lot of code using `'static` lifetimes must be marked as `unsafe`. Broadly speaking, all boards are initialized in large `unsafe` blocks. This means that the compiler cannot help us detect unintended memory safety issues in these large `unsafe` blocks.

### What are some pros and cons of generic lifetimes (non exhaustive list)?

Generic lifetimes can bring:

- More flexibility as seen in https://github.com/tock/tock/issues/1074.
- More fine-grained borrow checking. This can mean more efforts for developers to figure out how to spell the lifetimes constraints correctly. Aside that, the benefits in our case are not so clear - as borrow checking on `'static` lifetime works well.
- The ability to create board components directly on the stack, without `static_init`, i.e. without `unsafe` code.
- A downside of the previous point could be that the linker might not be able to check at compile time that all data structures will fit in memory (are static buffers on the contrary stored in the `.bss` section?). There could be a stack overflow at runtime instead.
- Generic lifetimes require many more annotations. Although Rust has done a great job at allowing elision of lifetimes in simple cases, all structures (recursively) containing a generic-lifetime reference must annotate it. It can become non-trivial to understand where to put these annotations in complex cases involving many objects and traits for example.


## This proof-of-concept

This proof-of-concept boils down to replacing `'static` lifetimes in the `Kernel` scheduler by a generic `'ker` lifetime. In practice, this lifetime will outlive anything useful because the `kernel_loop` function never terminates (unless one resets the board, in which case the board initialization starts from the beginning anyway). So it's ""almost static"", except that this generic lifetime could allow more flexibility, better borrow checking by the Rust compiler, and hopefully fewer `unsafe` code.

As you can see, this has a lot of consequences throughout the code-base:
- All kernel structures referencing the `Kernel` object are affected, in particular `Callback`, `Grant` and `AppId`. The `Driver` trait as well.
- In turn, all capsules, because they need to implement `Driver` and/or store `Callback`s. Those that don't have callbacks (`Led`) require much less refactoring.
- On top of that, lifetimes have to be added to the components.
- Last, the boards must include the new lifetime as well. I tried a few boards and managed to make them compile end-to-end.


### Beyond that?

1. I had a brief look at what would happen if one tried to instantiate the `board_kernel` as a non-static object. For now, the main limitation seems to be that kernel HILs (in particular `set_client` methods) require `'static` references. So further work in that direction would currently be blocked on https://github.com/tock/tock/issues/1074.
1. Generic lifetimes could also be applied to the `Chip` references throughout the kernel.


## Testing Strategy

This pull request was NOT tested at the moment.


## TODO or Help Wanted

This pull request still needs discussion.


## Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

## Formatting

- [ ] Ran `make formatall`.",36428094
506,2020-02-25T03:24:11Z,2020-03-04T00:23:51Z,,,"### Pull Request Overview

This pull request attempts to implement the idea suggested in #1568. 

### Testing Strategy

This pull request was tested by... well, you're looking at it. I've successfully demonstrated with this branch that an OS X build is correctly not yet triggered, but linux builds are. Then the question will be if/when we use bors to merge this whether an OS X build runs first.

### TODO or Help Wanted

If someone's more a travis guru than me and sees a flaw, holler, but I think this is right.

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
507,2020-02-23T17:47:39Z,2020-03-13T15:30:26Z,,,"### Pull Request Overview

This pull request is an attempt to address https://github.com/tock/libtock-rs/issues/133 by adding a syscall to allow an app to notify the kernel that an app has panicked. ~The app will not be resumed anymore neither will there be callbacks scheduled~.  The app will be stopped/restarted depending on the first on only parameter of the syscall (0=stop, 1=restart).


### Testing Strategy

This pull request was tested by flashing the `panic` example of https://github.com/torfmaster/libtock-rs/tree/feature/panic-syscall to verify that the syscall is triggered and the app is not resumed.

### TODO or Help Wanted

The implementation is quite raw and there are some questions to be clarified.
Open questions are:
 
 * How to handle panicked apps? I'm in favour of letting the app die and maybe even let the kernel panic because no possibility to recover an app from a ""panicked"" state than restarting the whole system
 * ~Do we need parameters? I find it hard to squeeze the cause for a panic into some bytes so I would not pass parameters to the syscall~

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
508,2020-02-21T14:28:52Z,2020-03-16T18:29:51Z,,,"## Pull Request Overview

### Context

While writing my first components in https://github.com/tock/tock/pull/1556, I hit some difficulties in how to design things.

This pull request is an RFC to refactor the components interface, with the goals of (1) being less verbose and (2) more difficult to use incorrectly. It contains:
- New ways of initializing static objects, in `kernel/src/common/utils.rs`.
- An example of how the refactoring would look like on the component side (`boards/components/src/alarm.rs`) as well as the board side (`boards/imix/src/main.rs`). I picked the alarm component, which uses the `static_init_half` pattern, and therefore things should generalize well to the other components as far as I understand it. But please let me know if there are more complex cases that components can handle.

### Refactoring of `static_init`

#### Current rationale for `static_init_half`

In principle, static objects in kernel boards are initialized with the `static_init` macro.

However, this relies on defining a `static` buffer inline in the current function, which doesn't work in Rust when the `static` type depends on a generic type of the function (because the compiler would somehow have to instantiate a distinct `static` object for each type of the function - which may not be well-defined in general).

This led to splitting `static_init` into `*_helper` macros defined in components to create `static` buffers with concrete types, and a `static_init_half` macro that initializes the buffer with some value. Besides creating some confusion about what this and that half mean, I don't think exposing the internal details of `static_init` *in this way* is very robust, as it relies on too many assumptions.

- `static_init_half` expects a `MaybeUninit<T>` buffer that contains `uninit`. Giving it an already initialized buffer would be incorrect as it would erase the previous value without notice. However, the current API of `static_init_half` just takes a `MaybeUninit<T>`.
- The `*_helper` macros return a `&mut MaybeUninit<T>`, which doesn't prevent the buffer from being used directly, or passed to various `static_init_half`. The API should only allow to pass such a buffer to `static_init_half` and only once.
- `static_init_half` doesn't have to be a macro, it can be implemented as a function. The only part that needs to be in a macro is the `static mut BUF: MaybeUninit<$T> = MaybeUninit::uninit();`, because that cannot be put in a function generic on `$T` (due to Rust rules). But this part is already in the `*_helper` macros.

#### Proposed new API for static initialization

Instead, I propose the following API (see the changes in `kernel/src/common/utils.rs`).

- An `uninit_static_buf` macro, which takes a type and instantiates inline a `static mut` buffer, containing `MaybeUninit::uninit()`. The role of this macro is similar to the `*_helper` macros in components.
- The result of it is stored in a new `UninitBuf` type, that *privately* wraps the uninitialized `MaybeUninit` - preventing anyone else from initializing it. This wrapper is `repr(transparent)`, and just here to guarantee that the contents really are uninitialized. The only way to construct it is via a `new()` function which takes care of calling `MaybeUninit::uninit()`.
- Another new type is `StaticUninitRef`, which *privately* wraps an `UninitBuf` into a `&'static mut` reference. This is so that `uninit_static_buf` returns this wrapper instead of a plain `&mut BUF` that could be misused.
- The `StaticUninitRef` wrapper has a single public method, `initialize`, which *consumes* the uninitialized `self`, stores a value in it, and returns the `&'static mut T` reference. This provides the same functionality as the previous `static_init_half` (i.e. doing the actual initialization), but:
  - this prevents double initialization, because `self` is consumed,
  - this prevents non-initialization, because the only way to get a `&'static mut T` reference is to actually initialize it via `StaticUninitRef::initialize`.

Then, the `*_helper` macros in components can use `uninit_static_buf` instead of directly using `MaybeUninit`. This removes some code duplication as the components don't have to create a `MaybeUninit::uninit()` and cast the reference, they just need to call `uninit_static_buf!($T)`. I also suggest to rename `*_helper` macros into `*_buf` macros, because all that these helpers really do is creating uninitialized static buffers.

The `static_init` macro is also a straightforward combination of the `uninit_static_buf` macro and the `initialize` *function*.


### Refactoring in components

I find the `Component` trait itself quite weird.
- The idea is that it is generic with a `finalize()` method. But in practice components need to add a `new()` method as well to pass arbitrary parameters, and this `new()` method is not part of the interface.
  - This leads to expressions of the form `ComponentFoo::new(some, parameters).finalize(other, parameters)` instead of a more straightforward single-function call `ComponentFoo::create(some, parameters, other, parameters)`.
  - When defining the components themselves, a lot of verbosity happens as well in copying things in `new()` and `finalize()`. Defining a single `create()` function instead would decrease the number of lines of code.
- The `finalize` method in `Component` is ill-defined. It takes a `&mut self` parameter, but the documentation explains that this method may only be called once. A better API to enforce this constraint is to *consume* the component by taking a `self` parameter instead of a reference. This is an issue I've hit while trying to define my own components (https://github.com/tock/tock/pull/1556#issuecomment-583515623).
- The `Component` trait doesn't mean much in itself. It requires a `finalize` method taking an arbitrary input type and returning an arbitrary output type, without any constraints on the input and output. Pretty much any function can be turned into this `finalize` interface.
- Although the `Component` trait brings genericity, it's never called in a generic context. Combined with the previous remark, I think that this trait mostly adds verbosity.
- The component objects are only constructed (`new()`) and `finalized()` (thereby returning a reference to something else). Other than that their value isn't used as an object. The only reason to have an object is so that it implements the `Component` trait.

#### Alarm example

As an example, I refactored the alarm component to get rid of the component interface, and this divides the number of lines by two.

A simpler API can also make it easier for everyone to define components. I was quite confused when defining my own components for the first time about what should be put in `new()` vs. in `finalized()` - and I think making it easy for anyone to get acquainted to the concept of components so that they can write their own components is important.


## Misc

### Testing Strategy

Not much at this stage. It's mostly an RFC on the design.


### TODO or Help Wanted

This pull request still needs comments on the design.


### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [ ] Ran `make formatall`.
",36428094
509,2020-02-03T22:51:30Z,2020-03-10T20:03:35Z,,,"
### Pull Request Overview

This pull request adds a capsule that provides a ""UART"" interface using semihosting. Fixes #1576.


### Testing Strategy

This pull request was tested by.. me??

### TODO or Help Wanted

Currently uses an external dependency, we could do [this](https://github.com/tock/tock-stm32/blob/793001c07386ced452f91db5e3deb0b7b9b41a02/boards/stm32f4discovery/src/semihosting.rs) instead??

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
510,2020-01-28T22:06:18Z,2020-03-04T12:56:29Z,,,"### Pull Request Overview

Travis wasn't actually enforcing the no warnings policy for test builds before (the `CI=true` -> deny warnings is a feature of board Makefiels, we need to `-D warnings` explicitly for other builds). This should prevent stuff like #1567 in the future.

This skips enum_primitive in the short term.

### Testing Strategy

Compiling.

### Documentation Updated

- [x] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.

---------

### TODO

This surfaces some questions in its current form, for example:

```
   Compiling stm32f4xx v0.1.0 (/Volumes/code/helena-project/tock/chips/stm32f4xx)
warning: unused import: `generic_isr`
  --> src/lib.rs:27:16
   |
27 | use cortexm4::{generic_isr, hard_fault_handler, svc_handler, systick_handler};
   |                ^^^^^^^^^^^
   |
   = note: `#[warn(unused_imports)]` on by default

warning: unused import: `generic_isr`
  --> src/lib.rs:27:16
   |
27 | use cortexm4::{generic_isr, hard_fault_handler, svc_handler, systick_handler};
   |                ^^^^^^^^^^^
   |
   = note: `#[warn(unused_imports)]` on by default

    Finished test [unoptimized + debuginfo] target(s) in 8.28s
     Running target/debug/deps/stm32f4xx-cd9d3f9bd364c650
```

This kind of stuff is a pain to maintain, as we're going to have weird `cfg` on/off imports for tests?


Also, because of the whole Travis + Mac is slow thing, we've managed to let a breaking for Mac on testing slip in again:

```
[-bash] Tue 28 Jan 14:10 [[test-all-libs $] ~/code/helena-project/tock/chips/ibex]
$ cargo test
   Compiling ibex v0.1.0 (/Volumes/code/helena-project/tock/chips/ibex)
LLVM ERROR: Global variable '_start_trap_vectored' has an invalid section specifier '.riscv.trap_vectored': mach-o section specifier requires a segment whose length is between 1 and 16 characters.
error: could not compile `ibex`.
warning: build failed, waiting for other jobs to finish...
LLVM ERROR: Global variable '_start_trap_vectored' has an invalid section specifier '.riscv.trap_vectored': mach-o section specifier requires a segment whose length is between 1 and 16 characters.
error: could not compile `ibex`.

To learn more, run the command again with --verbose.
```

If we keep adding more host-compiled testing, this is only going to get worse.",36428094
511,2020-01-20T16:25:59Z,2020-03-11T14:10:36Z,,,"### Pull Request Overview

This pull request adds a new `ConstPtr32<T>` wrapper type (name subject to bikeshedding). As the name goes, this type wraps as `*const T` on architectures where a pointer is 32-bit wide.

With `register_structs` (https://github.com/tock/tock/pull/1410) and `cargo test` on chips (https://github.com/tock/tock/pull/1393) now merged, we can migrate more structs to `register_structs`, with automated tests that addresses and sizes are what they claim to be.

However, some register structs use a raw pointer, such as `EndpointRegisters` in `chips/nrf52/usb`.

https://github.com/tock/tock/blob/8bb3fc1fa3d1b3fe66f2ed0e85860d229df0af7c/chips/nrf52/src/usbd.rs#L265-L267

The unit tests generated by `register_structs` will output some code checking the size of the pointer (i.e. `core::mem::size_of::<VolatileCell<*const u8>>()`). The problem is that the pointer size of the target architecture of Tock (usually 32-bit) may be different than the size on the desktop it runs on (usually 64-bit nowadays).

This new `ConstPtr32` wrapper is guaranteed to have a size of 4 bytes on all architectures, so that the unit tests behave as expected in all cases. Further, it wraps a real pointer on archs with 32-bit pointers, and a dummy value in other cases (with `unimplemented` methods to prevent mistakes).

When defining registers on a specific chip, the pointer width is fixed an known, so one can use `ConstPtr32<T>` as a replacement for `*const T` in that case. If the wrong pointer width is assumed, accesses to it will `panic` at runtime (in the meantime the layout of the struct is as declared by the `register_structs` macro as long as the unit tests pass - so potential accesses to other fields of the same struct shouldn't trigger unexpected behavior).

**Note**: In principle, not all `*const T` have the target pointer width, for example if `T = dyn U`, then `*const dyn U` will be a ""fat pointer"" containing a regular pointer + a vtable pointer. In that case the size would be wrong, however `ConstPtr32` would only accept such dynamic types if there was a `T: ?Sized` bound in the definition.
So in the current form it shouldn't be possible to have `size_of::<ConstPtr32<T>>()` be anything else than 4 bytes. Besides, I don't see any use case for dynamic types in register structs.


### Testing Strategy

This pull request was tested by:
- Checking that it compiles.
- Running `make ci-travis` with a ported version of `EndpointRegisters` on `chips/nrf52/usb`.

The migration of `chips/nrf52/usb` is not done here to avoid blocking https://github.com/tock/tock/pull/1543 in the meantime.


### TODO or Help Wanted

This pull request still needs:
- [ ] To decide whether the wrapper type should be backed by `VolatileCell`, or if it's up to the caller to wrap the pointer in a volatile cell if they want to.
- [ ] To agree on the name of the module, and of the pointer wrapper type.
- [ ] Is `ConstPtr64` needed at this point?


### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
512,2020-01-06T16:28:09Z,2020-03-11T16:58:01Z,,,"### Pull Request Overview

This pull request modifies the time HIL to support various width of clock ticks, as an alternative proposal to https://github.com/tock/tock/pull/1413. In particular, support for 24-bit and 32-bit ticks are added, but it could easily be extended to other widths in the future as needed.

- Added a `Ticks` associated type for the `Time` trait, in lieu of the currently unused `W` parameter. This is more consistent with the `Frequency` associated type and is more convenient to work it through dependencies.
- The `Ticks` trait represent a type encapsulating a ticks value (i.e. a 24-bit or 32-bit integer), with support for wrapping arithmetic and conversion to/from `u32`/`usize`.
- Removed the `Time::max_tics(&self)` function. This was unused. Instead, `Ticks::max_value` is now available (and doesn't take any parameter, as it is a constant of the type).
- Added the `Ticks::expired` primitive, to unify an implementation that was duplicated in various capsules.
- Added `Time::ticks_from_ms` and similar utility functions, to avoid the need for dealing with frequencies in all the capsules. This centralizes the arithmetic logic in one place, to reduce code duplication.
- Added a new `Alarm::set_alarm_from_now` function, to support the common `self.set_alarm(self.now().wrapping_add(duration))` pattern and reduce code duplication.


### Testing Strategy

This pull request was tested with:
- `ci-travis`
- new unit tests added in `kernel::hil::timer`.

I haven't done much more tests for now, to first gather feedback on the implementation.


### TODO or Help Wanted

This pull request still needs:
- [ ] Checking that the widths are correct for all clocks.
- [ ] Double-checking that the affected capsules are still correct.


### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.",36428094
513,2019-12-17T14:47:22Z,2020-02-12T20:38:55Z,,,"### Pull Request Overview

This pull request adds `cargo test` for the `capsules` crate to the Makefile.

I added a simple test in the virtual alarm capsule, but in general I think that capsules should be of great interest for functional unit tests, due to the non-trivial logic and the abstraction provided by HILs. In particular, one can write mock implementations of HILs to simulate various behaviors and test that the capsules react as expected.


### Testing Strategy

This pull request was tested by running `make ci-travis` and checking that unit tests indeed appear in the log.


### TODO or Help Wanted

- This pull request still needs fixing a bunch of doc tests in capsules.
- I hope that we can agree on the usefulness of such tests now that a lot of discussion happened on https://github.com/tock/tock/pull/1393. 


### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
514,2019-11-25T21:47:29Z,2020-03-10T21:17:06Z,,,"### Pull Request Overview

This pull request changes the capabilities to use simple unforgeable types that only the `kernel` crate can construct safely but that do provide unsafe public constructors to be used by trusted code.

This seems to be a reasonable simplification compared to unsafe traits as a single object possessing multiple capabilities seems to be unused. It also removes the issue of the `create_capabilities!` macro being callable from `#![forbid(unsafe_code)]` crates as this constellation does not prevent `unsafe` blocks inside the macros. 

### TODO

This pull request is very much work in progress as it is meant to solicit feedback on the chosen design and I currently only adjusted the code for the `arty-e21` board and did not yet update any code comments or design documents.

### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [x] Ran `make formatall`.
",36428094
515,2019-11-23T17:12:23Z,2020-03-25T16:08:20Z,,,"### Pull Request Overview

This completely re-writes how TBF headers are parsed. The major results:

1. kernel/src/tbfheader.rs no longer uses `unsafe`.
2. To make 1 work I couldn't figure out how to support a variable number of writeable flash regions in the header. Right now I set the max number of WFRs to 4.
3. The TBF header parsing code uses `Result`, and therefore load_processes also returns a Result now.

I tried to reduce/eliminate the ability for the tbf parsing to panic.


### Testing Strategy

Blink on Hail works, but more testing is needed.


### TODO or Help Wanted

There might be ways to do this better.

I also need to update all of the boards.

### Documentation Updated

- [ ] Updated the relevant files in `/docs`, or no updates are required.

### Formatting

- [ ] Ran `make formatall`.
",36428094
516,2019-11-18T12:35:18Z,2020-03-10T20:24:16Z,,,"### Pull Request Overview

The purpose of this driver is to provide low-level access to the embedded flash of nRF52 boards to allow applications to implement flash-aware (like wear-leveling) data-structures. The driver only permits applications to operate on their writeable flash regions. The API is blocking since the CPU is halted during write and erase operations.

### Testing Strategy

In addition to `make ci-travis`, this pull request was tested on the nrf52840dk board by implementing in libtock-rs:
- a syscall interface
- a multi-set data-structure
- an example application similar to `blink.rs` but with a persistent counter

And updating the linker script.

### TODO or Help Wanted

Which driver number should be used?

The following boards could be tested:
- nRF52833
- nRF52811
- nRF52810

### Documentation Updated

- [x] No updates are required. This is a chip-specific driver, not a generic syscall driver.

### Formatting

- [x] Ran `make formatall`.
",36428094
517,2020-02-04T22:33:30Z,2020-03-26T19:50:22Z,,,,40078838
518,2019-08-24T17:42:11Z,2019-09-29T05:46:21Z,,,"## Description
Adds a `time` module to the standard library which exposes the functionality of Rust's `std::time`.

## Status

**In Development**

### Outstanding design questions
- [x] ~~How should `std.time` be structured -- `std.time.Instant.now`, `std.time.instant_now`, `std.instant.now`, or something else?~~ (`std.time.Instant.now`)
- [x] ~~Should `std.time` be behind a feature? Should that feature be default?~~ (not behind feature)

### To Do
- [x] Implement all functionality in `std::time`
  - [x] Implement types
  - [x] Implement functions
  - [x] Implement implicit interfaces (`Eq` and `Ord`)
- [ ] Add documentation
  - [ ] Generated std lib docs
  - [ ] Examples
  - [x] ~~In Rust code?~~ (no need)
- [x] ~~Add tests~~ (no need)

## Future Directions
- Add more full-featured date-and-time functionality to the standard library? [Chrono](https://github.com/chronotope/chrono)?",40078838
519,2019-05-25T01:17:07Z,2019-05-25T01:37:20Z,,,"## Description
Adds a `Streamlike` (name TBD) interface which generalizes the concept of a collection from which values can be extracted.

## Related PRs
Similar concept to the Parsable interface (#687)

## Status
**In Development**

### Outstanding design questions:
*None currently*

### To Do
- [ ] Add useful functions
- [ ] Add implementations for standard types
- [ ] Add inline documentation
- [ ] Add documentation in the book?

### Prior Art
- [Streaming library](https://github.com/haskell-streaming/streaming)
- *Iterators and Streams in Rust and Haskell.*

## Future Directions
- `Streamlike` + ""Finite"" -> Foldable (& Traversable)
- Build generic `Streamlike` instance for all [`Indexable`](#738)? (i.e. [Indexable a] -> Streamlike a)
  - override-able for lists?
- Maybe a streaming library built like https://github.com/haskell-streaming/streaming, instead of this library's stream-processor-based design?
  - How would Streamlike adapters pass around Streamlikes? Rust-like? Haskell-like? Closure-based?",40078838
520,2019-03-03T22:31:57Z,2019-04-13T21:17:18Z,,,Uses https://github.com/Marwes/pretty.rs/pull/45 and https://github.com/Marwes/pretty.rs/pull/44 to remove edge cases and make formatting more predictable with regard to existing newlines. Will likely also need https://github.com/Marwes/pretty.rs/issues/46,40078838
521,2019-02-12T21:00:16Z,2019-05-26T06:30:03Z,,,"## Description
Adds a `Parsable` interface and a parser combinator library based on it to replace the current one.

## Related PRs
Depends on #686.

Similar concept to the Streamlike interface (#737)

## Status
**In Development**

### Outstanding design questions:
- [x] ~~How should parser handle errors and custom error types?~~ (It will use its own error type. No customization for now.)
- [ ] How to cleanly handle types that don't naturally lend themselves to StateT sequencing (String and Array)? (Most likely a wrapper, like in the current parser.)

### To Do
- [x] Get [StateT](https://github.com/Etherian/gluon/blob/statet/std/statet.glu) to a run without errors to begin debugging.
- [ ] Add useful functions
- [ ] Add implementations for standard types
- [ ] Add inline documentation
- [ ] Add documentation in the book?

## Prior art
- *Revisiting 'Monadic Parsing in Haskell'* and [yoctoparsec](https://github.com/mniip/yoctoparsec/blob/master/src/Control/Monad/Yoctoparsec.hs)
- [nom](https://github.com/Geal/nom)
- [Megaparsec](https://github.com/mrkkrp/megaparsec/)

## Future Possibilities
- Build `Parsable` on top of `Streamlike` or otherwise take advantage of their relatedness.
- `Indexable` -> `Parsable`?",40078838
522,2018-07-31T11:39:40Z,2018-08-07T10:12:04Z,,,"Removes the indentation aware syntax and instead forces explicit `in` tokens to be inserted to separate `let/type/do` bindings from their body. By some tweaks in the grammar `in` is not required to separate the bindings itself.

```f#
type Test = Int
let id x = x
and id2 y = y
do action
let x = id 2
in
wrap (x + 1)
```
(Could also be written as)

```f#
type Test = Int
in
let id x = x
and id2 y = y
in
do action
in
let x = id 2
in
wrap (x + 1)
```

I feel like this could be a good compromise between a non-indentation based syntax while also avoiding the verboseness of `in` everywhere (I think this is more or less how OCaml is structured, but it still avoids a concept of top-level).

Since blocks are indentation aware they were also removed so it is no longer possible to sequence two function calls.

```f#
f x
g y z

// Now parses as
f x g y z
```

`match` expressions can no longer be nested directly as that causes ambiguities.

```f#
let x = match 1 with
    | 2 ->
        match () with // Error
        | _ -> 1
    | _ -> 0
```
To fix this the inner `match` must be wrapped in parentheses
```f#

let x = match 1 with
    | 2 ->
        (match () with
        | _ -> 1)
    | _ -> 0
```

Before and after of part of the standard library https://github.com/gluon-lang/gluon/pull/596/commits/b5cfc7476359801c73a81e1165d7244aa151de4a

cc #495 cc @OvermindDL1",40078838
523,2019-03-02T16:38:59Z,2019-03-03T00:10:54Z,,,"Allows to change the default name (PHPSESSID) of the cookie.

This allows personalization of the cookie, improves security, since it makes it difficult for the attacker to infer what language we use on the server",4237727
524,2017-07-22T22:48:56Z,2017-07-22T22:48:56Z,,,"I did a simple example passing a parameter to identify the pagination ID.

I use : 
mysite.com/product/2   (It'sn works, printed 1)

but just works if I using /index/ 

mysite.com/product/index/2 (It's works, printed 2)

My ProductController.php is

https://pastebin.com/aYVEqvjK

With this pull request solved the problem.",4237727
525,2017-05-16T01:55:13Z,2017-05-16T01:55:13Z,,,,4237727
526,2017-05-11T22:21:54Z,2017-05-11T22:33:33Z,,,"[VAGRANT]
I'was creating a system for uploading users' files to the server. For this purpose I coded a script that creates a personal folder with `755` permissions. This was working, but when I was trying to move a file via `move_uploaded_file()` to the folder I wasn't able to write anything. 

So I decided to check the php user, and it was running by `vagrant` user. Also I checked the owner of the files and it was `vagrant` too. At the end, I decided to try adding the `www-data` user to `vagrant's group`. This let me upload files to the folders with `755` permissions.  Of course, it also applies to other folders, including Avatars folder. In reference with issue #143.

`sudo usermod -a -G vagrant www-data`
",4237727
527,2016-09-18T18:15:29Z,2017-04-15T13:44:40Z,,,"I'm using Huge as a part of a larger setup, and in my setup, these relative path includes did not work for me — they're relative to the including file, not the included file. I fixed the file paths to be relative to the included file, and thus work no matter what the setup.
",4237727
528,2016-01-10T13:36:03Z,2017-02-04T00:27:00Z,,,"I like @OmarElGabry Encrypt user_id on account verification from #774 however not quite like the ""long and ugly"" url's so this is a bit other way to get this work with no ""long and ugly"" url's

In short:
- Hash user's id and user's activation hash together and send to user.
  The link will be looks like:
  http://127.0.0.1/register/verify/hashed_user_id_and_user_activation_hash/user_activation_hash
- then get user's id and user's activation hash from database by user_activation_hash (second parameter in activation link)
- hash user's id and user's activation hash from database the same way as sent to user by email. This should give as the same hash as in first parameter
- check both hashes that they are identical 
",4237727
529,2016-01-08T23:35:11Z,2016-01-16T19:03:06Z,,,"These are changes to address a potential attack method revealed in discussion within #776 

These changes make it so that if an attack were to try at guessing a user's reset password verification hash they would only have one chance to do so.

These changes assume that one bad guess at a verification code is an attempted attack. A better solution might include keeping a tally that way if users click on old link by mistake they don't have to start the process over, but that probably requires using altering the database structure slightly and I don't know if that would be desired, but can be easily added into here if its.

Steps need incorporate a tally system:
1. Add field in database users table for number of attempts
2. Add value in config file for max number of attempts
3. Make setPasswordResetDatabaseToken set number of attempts to 0
4. make expirePasswordReset read the current number of attempts.
5. either of the following depending on if there are any attempts remaining or not
5.a. make expirePasswordReset update number of attempts
5.b  make expirePasswordReset update the timestamp to make it expired
",4237727
530,2016-01-05T12:37:38Z,2017-11-13T17:28:25Z,,,"Instead of passing user_id in the URL as action method argument, passing the encrypted version of user_id in query parameter will work just fine. The link looks long and ugly :smile:  but in case you want a solution for #728
",4237727
531,2015-11-13T04:54:09Z,2015-12-12T09:22:37Z,,,"Created a template view to use for friendly redirection.
Made Redirect class methods render the redirect view then exit to prevent other views from rendering.
Replaced uses of header('location: ...') with Redirect::to().
",4237727
532,2020-02-02T14:05:22Z,2020-02-02T14:05:26Z,,,"General copy editing: Corrected spelling (ref. <https://en.wikipedia.org/wiki/WordPress> and <https://en.wikipedia.org/wiki/AWK>, expanded (ref. <https://en.wikipedia.org/wiki/Visual_Basic> and <https://en.wikipedia.org/wiki/Internet_Explorer>), etc.",34408310
533,2020-01-07T16:22:09Z,2020-02-25T13:11:40Z,,,Add Verilog support based on https://www.verilog.com/VerilogBNF.html#REF170,34408310
534,2019-11-17T00:06:34Z,2019-11-17T16:43:22Z,,,Updated patch provided in issue #312.,34408310
535,2019-10-01T13:26:09Z,2019-10-01T13:26:09Z,,,"I appreciate we can't have all the keywords in this. I've reviewed the current Perl language documentation and added the most commonly used keywords based on my experience as a long-term contributor to the Perl tag on Stack Overflow, where this library is in use.",34408310
536,2019-06-14T20:57:04Z,2019-06-14T21:01:40Z,,,,34408310
537,2019-05-22T17:53:26Z,2019-05-24T15:15:47Z,,,"This is pretty basic, just handles Windows-style ini files.

I use Asterisk a fair bit as well, so added their config format in. The only real difference is it's got `=>` as a separator instead of `=`.",34408310
538,2019-05-17T19:36:03Z,2019-10-04T17:59:30Z,,,"I noticed on websites using this a lot of keywords, old and new, were missing proper highlighting. Went ahead and added everyone I could think of. If I missed anything or made a mistake, please let me know! Here's a link describing the usage of each keyword I added/modified:

[deferred](https://dart.dev/guides/language/language-tour#lazily-loading-a-library)
[export](https://dart.dev/guides/libraries/create-library-packages)
[enum](https://dart.dev/guides/language/language-tour#enumerated-types)
[mixin](https://dart.dev/guides/language/language-tour#adding-features-to-a-class-mixins)
[on](https://dart.dev/guides/language/language-tour#catch)
[rethrow](https://dart.dev/guides/language/language-tour#catch)
[yield](https://dart.dev/guides/language/language-tour#generators)
[covariant](https://dart.dev/guides/language/sound-problems#the-covariant-keyword)
[external](https://stackoverflow.com/questions/24929659/what-does-external-mean-in-dart)
[with](https://dart.dev/guides/language/language-tour#adding-features-to-a-class-mixins)
[dynamic](https://dart.dev/guides/language/language-tour#important-concepts)
[Function](https://dart.dev/guides/language/language-tour#functions)",34408310
539,2019-03-22T21:41:38Z,2019-04-23T15:15:20Z,,,"Without this, the ol.linenums section won't expand to
fill its pre parent if we set the parent to overflow:scroll.
This change fixes that bug.",34408310
540,2019-03-15T02:42:21Z,2019-03-15T02:47:18Z,,,"This PR add support for the Chapel Language. Chapel is a modern programming language that is
- parallel
- productive
- portable
- scalable ",34408310
541,2019-02-24T00:57:25Z,2019-02-24T00:57:25Z,,,the example makes it look like the code needs to bump against the pre tags,34408310
542,2019-01-26T20:37:07Z,2019-02-12T04:17:14Z,,,"From https://virustotalcloud.appspot.com/static/prettify/lang-yara.js

close #533",34408310
543,2018-11-15T03:27:03Z,2018-11-15T03:29:14Z,,,"Adds monokai style.
![screenshot from 2018-11-15 08-58-45](https://user-images.githubusercontent.com/2943609/48528386-b39d7c00-e8b4-11e8-994e-a40ce2759928.png)
",34408310
544,2018-10-30T19:26:16Z,2020-03-17T19:05:20Z,,,"JavaScript files to scan Eiffel code are provided together with HTML tests with expected output.

To my knowledge, all current lexical constructs are supported except for Unicode symbols beyond ASCII that were not tested and may not work correctly.",34408310
545,2018-10-07T20:09:27Z,2019-03-29T19:47:14Z,,,"Currently, the syntax highlighting code for the [Elixir language](https://elixir-lang.org/) uses `ex` not `elixir` which is incorrect, has caused a lot of confusion and does not implement highlighting for the language in almost 100% of the cases where the language is inferred from the name/tag.

The biggest example is Stackoverflow itself:

 - [SE feature request was opened back in 2013](https://meta.stackexchange.com/questions/208528/elixir-syntax-highlights)
 - [Elixir support was added in 2017](https://github.com/google/code-prettify/pull/478)
 - But almost [zero of the Elixir code on the website](https://stackoverflow.com/questions/tagged/elixir) is automatically highlighted
 - To highlight manually, we have to set the language to `ex`; which again, is incorrect

Renaming this to `lang-elixir` will fix the syntax highlighting issue through out the ecosystem.",34408310
546,2018-08-03T13:07:44Z,2018-08-03T13:16:06Z,,,,34408310
547,2018-07-31T05:19:52Z,2018-07-31T05:34:25Z,,,Just some text reviews and improved readability for other users.,34408310
548,2018-05-22T10:50:23Z,2019-06-20T16:18:23Z,,,"Delphi is similar to pascal but has some differences

- Delphi have line comment syntax
- And more reserver words

I attach a separate color scheme, but it is fully compatible with the ""Pascal"" scheme and, perhaps, you just need to replace the Pascal scheme

[lang-delphi.js.zip](https://github.com/google/code-prettify/files/2026241/lang-delphi.js.zip)
",34408310
549,2018-05-14T13:17:04Z,2019-03-09T17:49:45Z,,,,34408310
550,2018-04-17T18:49:56Z,2018-04-17T18:49:56Z,,,Here are some tests for the regex used: <https://regex101.com/r/X60Zp8/2/tests>,34408310
551,2018-04-04T20:45:12Z,2018-04-04T20:45:12Z,,,"Basic support for Coq, based on the ML syntax and the [highlight.js](https://github.com/isagalaev/highlight.js/blob/master/src/languages/coq.js) support for Coq.",34408310
552,2018-03-24T07:10:22Z,2018-07-23T03:27:36Z,,,"The reference list of C# keywords is available at https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/

I've been through the list, and we were missing three keywords:
* `explicit`
* `namespace`
* `using`

Following @mikesamuel instructions on #525:
* I made the changes to `js-modules/prettify.js`
* I kept it 80 chars per line to follow the existing layout
* I ran `JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home npm install && npm run grunt`
",34408310
553,2018-02-13T16:50:42Z,2018-03-07T18:29:06Z,,,,34408310
554,2017-12-18T04:19:13Z,2019-03-06T19:13:44Z,,,"@bradcray Sir, I have made pull request kindly review it ",34408310
555,2017-11-27T14:41:43Z,2018-03-05T02:36:30Z,,,,34408310
556,2017-11-27T14:39:43Z,2018-06-01T14:09:53Z,,,"It would be nice to resolve both variants
```
class=""lang-kotlin""
```
and 
```
class=""lang-kt""
```
as ""kt"" is most-commonly used file extension for Kotlin source code.",34408310
557,2017-05-03T10:11:18Z,2018-12-28T02:37:50Z,,,"Adds a ""lang-x86.js"" lexer that enables syntax highlighting for Intel x86 assembly language.
(See commit description and/or comments in file for additional information.)

Although I am not an experienced JavaScript developer, nor do I have much experience with writing regular expressions, I did have this code reviewed by the Stack Exchange community (https://codereview.stackexchange.com/questions/152836/adding-x86-assembly-language-syntax-highlighting-to-google-prettify) and received positive feedback.

I have made a few changes since then, optimizing the code for performance, and I have been very happy with the results in my own personal use. I'd like to get this merged into the master repository so others can start using it, too!

I have a Google Individual Contributor License Agreement on file for this email address already. Please let me know if there's anything else I need to do or change.",34408310
558,2017-02-12T22:20:35Z,2017-11-09T07:22:29Z,,,As per #451 the required changes to add cql extension. I basically made a copy of the sql extension and replaced the keywords with those from cassandra. The tests are copied over also but with a `usernames` table instead of `users` because the latter is a reserved keyword in cql. ,34408310
559,2017-02-10T18:30:26Z,2017-03-13T15:52:20Z,,,could also consider adding .cls file extension (export of a VBA class object),34408310
560,2016-12-29T19:30:44Z,2019-09-27T08:28:06Z,,,Solidity is the main language for contracts on the Ethereum platform. Support is desired by the community on ethereum.stackexchange.com.,34408310
561,2016-10-19T17:42:40Z,2017-03-13T15:53:35Z,,,,34408310
562,2016-10-18T14:00:38Z,2017-03-13T15:53:49Z,,,"Add all Keywords from the current language, including NameOf.

We should consider adding some of the Unreserved Keywords not already mentioned, but that's debatable. I've only included the Keywords listed in the VS2015 MSDN, plus NameOf, not already mentioned.
",34408310
563,2016-07-23T12:05:05Z,2019-11-24T06:13:43Z,,,"Should work for most standard versions of Fortran, from 77 to 2008. Doesn't work so well for fixed-form source, e.g. ""C"" in the first column for comments.

Also, not sure how to generate the ""correct"" annotated output for the test case. Is there a tool in the repo?
",34408310
564,2016-07-21T17:50:26Z,2017-06-15T02:46:10Z,,,"Theme inspired by [vscode IDE](https://code.visualstudio.com)
",34408310
565,2016-07-19T13:11:31Z,2017-03-13T15:54:38Z,,,"This is a PR for issue #367 
",34408310
566,2016-07-09T15:06:45Z,2017-03-13T15:55:10Z,,,"…ctives

All reserved words in object-pascal should be included in the pascal keyword list. Also included should be the non-obsolete directives.
Source: http://docwiki.embarcadero.com/RADStudio/Seattle/en/Fundamental_Syntactic_Elements 
as well as: http://wiki.freepascal.org/Reserved_words  

Finally in addition to `{}` and `(**)` comments `//...` comments are also allowed.  
",34408310
567,2016-06-21T16:10:25Z,2017-03-13T15:55:27Z,,,"replace named define with anonymous define. It's better because the name doesn't have to match the filename.
",34408310
568,2016-04-28T20:43:42Z,2017-03-13T15:55:42Z,,,,34408310
569,2016-04-27T18:13:15Z,2017-03-13T15:56:00Z,,,,34408310
570,2016-04-19T14:43:01Z,2019-12-07T02:36:16Z,,,"I've created lang-sv.js based off of lang-vhdl.js, and modified as appropriate. Please consider taking this PR, as I use [Perforce Swarm](https://www.perforce.com/collaboration) and it uses code-prettify as its syntax highlighter.

It also appears my editor's desire to trim all trailing whitespace caused other differences. I hope that's ok.

Thank you,
BooneJS
",34408310
571,2016-04-12T18:27:44Z,2017-03-13T15:56:43Z,,,,34408310
572,2016-03-14T15:50:04Z,2017-03-13T15:56:59Z,,,"…when dynamically prettifying code.

When prettifying code that has been dynamically inserted into the `<pre>` block when line numbering is enabled, blank lines (only consisting of a newline and/or carriage return) are erroneously removed from the DOM, when they should actually be preserved and converted into `&nbsp` elements to prevent browsers from not displaying them, which causes inconsistencies with the line numbering. Here is an example:

Original python script:

``` python
# Script Name   : test.py
# Author        : Wheeler Law
# Created       : 2 March 2016
# Last Modified : 
# Version       : 1.0

# Modifications : 

# Description   : Sample python script to test the script uploader/syntax highlighter. 

import sys      # Import the Modules
import os       # Import the Modules

# Readfile Functions which open the file that is passed to the script

def readfile(filename):
    line = open(filename, 'r').read()
    print line

def main():
  if len(sys.argv) == 2:        # Check the arguments passed to the script
    filename = sys.argv[1]      # The filename is the first argument
    if not os.path.isfile(filename):    # Check the File exists
      print '[-] ' + filename + ' does not exist.'
      exit(0)
    if not os.access(filename, os.R_OK):    # Check you can read the file
      print '[-] ' + filename + ' access denied'
      exit(0)
  else:
    print '[-] Usage: ' + str(sys.argv[0]) + ' <filename>' # Print usage if not all parameters passed/Checked
    exit(0)
  print '[+] Reading from : ' + filename    # Display Message and read the file contents
  readfile(filename)

if __name__ == '__main__':
  main()
```

This is the output:

![image](https://cloud.githubusercontent.com/assets/3081566/13750197/03263402-e9ca-11e5-9d1f-10e71266280c.png)

You'll notice that the lines in the script that do not have any content in them are removed from the DOM, which causes inconsistencies with the line numbering. 
",34408310
573,2015-11-23T19:44:41Z,2017-03-13T15:57:13Z,,,"#### Preview

![preview](https://i.imgur.com/1cXNYkj.png)
",34408310
574,2015-11-19T13:36:35Z,2017-03-13T15:57:28Z,,,"Ensure that styles are only applied to the contents of `.prettyprint`.
",34408310
575,2015-11-08T13:13:16Z,2017-03-13T15:57:44Z,,,"Add a simpler definition for ini/properties files than the one suggested in issue number #223.
",34408310
576,2015-10-26T02:34:28Z,2017-03-13T15:58:04Z,,,"if we cannot visit cdn.rawgit.com or google-code-prettify.googlecode.com, this change works well.
",34408310
577,2015-09-23T19:43:28Z,2018-05-11T22:03:25Z,,,"Basically, this is a way of dealing sensibly with systems that correctly
allow users to mark the language of a code block as ""lang-[whatever]"",
but are overly aggressive in automatically adding the ""prettyprint""
class to code blocks.
",34408310
578,2019-10-16T15:53:48Z,2019-10-16T15:53:48Z,,,"Allows installing the package using the PHP package manager ""Composer"".",37743219
579,2019-02-08T15:11:26Z,2019-02-08T15:11:26Z,,,Note that other icons set could be easily added.,37743219
580,2019-02-07T10:51:28Z,2019-02-07T10:51:28Z,,,"Set `sanitize` marked option to **true** by default.

Fix #657 and #730",37743219
581,2019-02-06T15:50:11Z,2019-02-06T15:50:11Z,,,"Currently we get an error when typing the `gulp` command, because the gulpfile is outdated.

This PR updates the gulpfile to be compatible with gulp4.

Also, it disables `no-useless-escape` eslint rule, which is too aggressive and returns a lot of errors in current base-code.",37743219
582,2018-11-30T09:27:11Z,2018-11-30T09:27:11Z,,,"Since the character counter still seems to not have been implemented, as seen in #603 , I added this functionality by simply adding an else if statement. It sets the innerHTML to the length of the value inside the editor. This should fix the mentioned problem in #603 ",37743219
583,2018-11-29T07:20:15Z,2019-02-27T03:08:05Z,,,"In my project, I need to use the image upload. At first, I used the custom toolbar. Later, I thought if I could add a feature.

So here's my code, I hope it can help others.
```
var simplemde = new SimpleMDE({
    status: [""lines"", ""words""],
    spellChecker: false,
    element: document.getElementById(""sin-markdown""),
    promptURLs: true,
    uploadUrl: '/index/image/upload',
    toolbar: [""upload-image""]
});
```

Add `upload-image` to toolbar, then custom `uploadUrl` which is the server url for uploading images.

If the upload is successful, will type like this:`![response.name or file.name](response.url)`
",37743219
584,2018-11-07T04:08:59Z,2018-11-07T04:08:59Z,,,,37743219
585,2018-11-01T01:17:24Z,2018-11-01T01:17:24Z,,,,37743219
586,2018-01-05T06:33:30Z,2018-01-05T06:33:30Z,,,"Fixes #174 by copying `marked.js`'s default implmentation of handling links and modifying it to include `target=""_blank""` in the output.
",37743219
587,2017-12-04T10:47:13Z,2019-06-15T18:35:30Z,,,"Added compatibility for FontAwesome 5 by creating a seperate element for the icon and nesting it inside the button element instead of putting the classes on the button element. This makes sure that the button and all its properties stays intact when FontAwesome 5 changes elements to `<svg>` for their icons.

FontAwesome 4 works with this change as well. There are no visual differences except that the icon has shifted 1px up, probably because of some centering by FontAwesome.

Fixes #664 ",37743219
588,2017-09-25T02:38:26Z,2017-09-25T02:38:26Z,,,"I added a class to codemirror wrapper in the javascript, and I added this class to all the CSS rules regarding .Codemirror. If you don't you cannot display correctly a classic Codemirror instance and a simplemde on the same page.",37743219
589,2017-09-09T21:49:16Z,2019-04-08T06:02:36Z,,,"Markdown editors like [HackMD](https://hackmd.io/EYUwTA7ADAhiDMBaAJsgrANkQFngRmEWHgE5scBjKNKADnjQomDyA===?both) already do it : the preview method must not alter inchanged nodes or the writing experience becomes impossible as the preview zone is rendered again and again with iframes being destroyed and recreated again...
A virtual dom solution is not an easy solution in our case as very few markdown parsers do generate a virtual dom representation.
Google `incremental-dom` package is a better solution to the problem : it effectively updates only the required nodes.
A demonstration of the new `renderPreview()` implementation is available here : https://zipang.github.io/markdown-bundle/
In this page, the user can type new text while an embedded video in the preview is playing.
whereas the same document is rendered here with the CDN version of SimpleMDE : https://zipang.github.io/markdown-bundle/demo/simplemde.html

",37743219
590,2017-09-05T11:10:09Z,2017-09-05T11:10:09Z,,,"[jsDelivr switched to a fully automated system](https://www.jsdelivr.com/features), that can serve files from npm and GitHub. This means all future releases will be available automatically, but will use a new link structure.

I updated the links now so you don't forget to do it when you release a new version.

You can find links for all files at https://www.jsdelivr.com/package/npm/simplemde.

Feel free to ping me if you have any questions regarding this change.",37743219
591,2017-07-31T04:18:25Z,2017-07-31T04:18:25Z,,,"When dealing webiste with headers.
It could be tricky to hide the headers when simpleMDE is full screen.
Adding a callback will largely simplify the case",37743219
592,2017-07-18T17:07:01Z,2019-02-21T15:08:38Z,,,"Provide a ability that can customize some toolbar-button(I read documentation, just support customize the entire toolbar, that not enough), and provide a hook 'whenEleCreate' for every toolbar-button.",37743219
593,2017-07-11T04:23:28Z,2017-07-11T04:23:28Z,,,"SimpleMDE can now be disabled through initial configuration, or disabled / re-enabled using a method dynamically. `README.md` documentation has been updated.

In addition to this, there was a typo in the SimpleMDE JavaScript file, where ""Tootlip"" was used (consistently). This was fixed as well.

A demo of the functionality can be found at http://sweltering-verse.surge.sh

I tried to be as ""accommodating"" as I could when adding this, keeping existing components as intact as possible. Hopefully what I have is at least a good baseline on which improvements can be made.",37743219
594,2017-05-10T08:44:57Z,2018-01-02T09:22:59Z,,,"If somebody want select or upload image to server before drawImage, He can  set options onDrawImage.
example:
`   var simplemde = new SimpleMDE({`
`        element: document.getElementById(""Id""),`
`        onDrawImage: function() {`
`        //do select and uploadImage`
`         simplemde.drawImage(""imageUrl"")`
`     }`
`  });`",37743219
595,2017-04-27T07:34:05Z,2019-02-09T18:13:59Z,,,"Clear autosave timeout in submit handler to prevent reinserting data to
local storage after the submit. Also, prevent attaching the same submit
handler in every autosave call.",37743219
596,2017-04-05T15:50:17Z,2017-09-22T15:57:42Z,,,"I have a custom `previewRender` function that makes an Ajax call to my server's API which then returns the HTML result of the parsed markdown so I was taking a look at the network tab of the developer tools and I noticed that when I clicked the preview button in the toolbar again to **disable** it another request to my API would fire.

Now, I only gave a quick look to the code and after a quick inspection I saw no reason for this so... I guess I'm not breaking anything here.",37743219
597,2017-04-01T12:44:14Z,2017-04-01T12:44:14Z,,,"Add `drawImage` option and `drawLink` option to make this editor more flexible. For example, one want to insert a image, but he don't want to use the default prompt dialog.Then he can use the drawImage option to what he want to do when click the Insert Image button, and call the callback function when the work flow is finished.",37743219
598,2017-03-09T15:33:48Z,2017-04-03T15:14:29Z,,,for non-english users or other uses.,37743219
599,2016-11-16T17:59:29Z,2016-12-11T14:25:51Z,,,,37743219
600,2016-10-20T19:51:21Z,2019-05-14T07:22:51Z,,,"Added the ability to pass innerHTML text for toolbar icon anchors.
",37743219
601,2020-02-27T09:37:43Z,2020-02-28T13:38:24Z,,,Resolves: #106,16514887
602,2020-01-28T20:45:39Z,2020-01-28T20:53:16Z,,,"NewGlob function allows filter files in filesystem.
It useful when some files served from an http.FileSystem, but other ones are internal resources that used in program, but don't exposed outside.",16514887
603,2019-11-01T19:36:29Z,2019-12-14T20:39:31Z,,,Use of this flag can improve determinism of builds. In my employer's environment the use of git across linux/osx hosts can produce different results for the mode (particularity the 'group' and 'other' permission bits).,16514887
604,2019-09-02T13:44:16Z,2019-09-02T13:51:14Z,,,"This is a simple replace for statik.go to make the tool vendorable.
With this change one can setup a `gen.go`:

```
package main

import (
	""github.com/rakyll/statik/cmd""
)

func main() {
	cmd.Main()
}
```

and use that in the `go generate` command:

```
//go:generate go run ./gen/gen.go -src=./public -tags !dev

```

This way one can control with gomodules which tag/commit of the tool they want to use.",16514887
605,2019-08-06T20:11:52Z,2019-11-04T16:18:44Z,,,"Fix #80

Signed-off-by: Robert-André Mauchin <zebob.m@gmail.com>",16514887
606,2019-07-18T09:24:19Z,2019-07-18T09:24:19Z,,,,16514887
607,2019-07-13T21:52:54Z,2019-07-13T22:08:48Z,,,"This change wouldn't require people to depend on net/http

binary size:
without net/http: 2.4M
with net/http: 6.7M

Note: this would break existing user code(see example/main.go)",16514887
608,2019-03-24T02:39:52Z,2019-07-23T02:44:32Z,,,"follow on #63 

Currently, only dot files are skipped, files inside dot directory are not skipped.

I do not know if this is the intended behavior, but I implement that skips the collection of files inside dot directory with using filepath.Skipdir.

Also, I create new Option ziptree.IncludeDotfiles for collecting dotfiles and utilize it in statik.go for adding flag ""-dotfiles"" to zip dotfiles.",16514887
609,2019-03-23T18:47:43Z,2019-03-23T18:47:43Z,,,"Currently, the force flag is effective only when os.Rename fails. That is, if os.Rename succeeds, statik will overwrite the file regardless of the force flag.

Is this the intended behavior? As I feel it is not intuitive, I fix it.",16514887
610,2019-03-23T13:06:43Z,2019-07-23T02:43:50Z,,,"Currently, there are almost the same code for zipping is written in statik.go and fs_test.go, and it is difficult to prove the correctness of the test.

Therefore, I create the ziptree package to share code and utilize it in statik.go and fs_test.go.

Also, the ziptree package's public interfaces are useful for writing custom code for ""go generate"" to Register original data and create New http.FileSystem, for example, when we want to create multiple file systems.

How do you think?",16514887
611,2018-10-30T03:00:30Z,2019-03-11T18:47:34Z,,,"Current implementation's `Readdir` returns all sub-directories contents
",16514887
612,2018-10-02T15:46:48Z,2018-10-02T15:46:48Z,,,"Recently I needed to include some hidden files into my static bundle and had to add this flag to avoid those files from being ignored.

Since `go fmt` re-indented all the flags, I've sorted the flag variables by name (OCD).",16514887
613,2019-10-27T13:24:40Z,2019-10-27T13:25:27Z,,,test it,17839346
614,2018-04-10T11:26:33Z,2018-04-19T00:53:17Z,,,"Corrections over the pom.xml file and checkstyle issues on the project. 

For dependencies versions, I'm not quite sure if I should specify them in Kaa parent pom.xml file. In this PR, I specified them in HBase log appender pom.xml file. 

I also set apache avro version as the specified version on Kaa -  ${avro.version} - which is the 1.7.5 version. But for some reason, in my local machine I can only build the project with version 1.7.7 
Hope it works with 1.7.5 version too.   
",17839346
615,2017-11-06T08:00:46Z,2018-03-26T22:58:39Z,,," 1. Accroding the ""http://kaaproject.github.io/kaa/docs/v0.10.0/Administration-guide/System-installation/Docker-deployment/"" to bulid my project;
2. when i use the command ""python launch-kaa.py mariadb-mongodb 3"" that prompting ""ZooKeeper JMX enabled by default"";
3. use the ""docker logs c21d3d39276c | grep error"" to check the logs of the zk node, shows me ""ZooKeeper JMX enabled by default; Using config: /opt/zookeeper/bin/../conf/zoo.cfg""; 

please help me to solve the problem!
",17839346
616,2017-02-28T15:50:46Z,2018-03-26T22:58:39Z,,,,17839346
617,2016-12-04T10:38:48Z,2018-12-30T08:33:59Z,,,I have been working on adding CoAP transport support to Kaa project. Now I pushed final results of my work. Hope to receive your comments about it.,17839346
618,2020-01-21T16:18:53Z,2020-01-21T16:18:53Z,,,"Updates [com.typesafe.sbt:sbt-native-packager](https://github.com/sbt/sbt-native-packager) [from 1.5.2 to 1.6.0](https://github.com/sbt/sbt-native-packager/compare/v1.5.2...v1.6.0).
[Release Notes/Changelog](https://github.com/sbt/sbt-native-packager/blob/master/CHANGELOG.md)

I'll automatically update this PR to resolve conflicts as long as you don't change it yourself.

If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below.

Have a fantastic day writing Scala!

<details>
<summary>Ignore future updates</summary>

Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:
```
updates.ignore = [ { groupId = ""com.typesafe.sbt"", artifactId = ""sbt-native-packager"" } ]
```
</details>

labels: sbt-plugin-update, semver-minor",1951336
619,2020-01-24T13:47:31Z,2020-03-17T19:31:19Z,,,"This PR will add enough conditional compilation to support running tests with miri. So far, I have disabled use of the process's PID, turned off the body of try_lock(), and ignored the quickcheck tests, since they would take far too long to run. Miri is slow as tar, so using it would only be useful for spot-checking for unsoundness, not a CI job or anything.

Miri requires additional shims for mkdir and rmdir before this will work, I have changes in progress for that as well.

The first issue I've discovered thus far is that `crossbeam-epoch` has an unsound use of `std::mem::uninitialized`, creating a `std::Mem::ManuallyDrop<T>`. There is a PR at crossbeam-rs/crossbeam#458 that will fix this soon.

Relevant commands:
* Run a test: `cargo +nightly miri test --features=testing -- -Zmiri-disable-isolation -- bug_22`
* Install miri from source: `cargo +nightly install --path . --force --locked --offline`",49401416
620,2019-12-28T17:51:19Z,2020-03-08T12:49:16Z,,,"This adds batch operations to `test_tree_failpoints`. I'm aware that batches will be overhauled in light of #897, so it's too early to merge this just yet.

I've noticed two classes of failures from running this:

* When the batch is applied, a FailPoint error bubbles up inside `<Reservation as Drop>::drop` and gets unwrapped. Should this use `global_error` instead of unwrapping?
* Some test runs will report `failed to make_stable after 30 seconds.` I haven't dug into this much yet.",49401416
621,2020-03-24T05:14:56Z,2020-03-24T05:14:57Z,,,"Bumps [github.com/xanzy/go-gitlab](https://github.com/xanzy/go-gitlab) from 0.27.0 to 0.29.0.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/629ba2b4e4b35b20d6313dcbb4ceae764a583771""><code>629ba2b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/xanzy/go-gitlab/issues/800"">#800</a> from xanzy/svh/f-rate-limit</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/ef77af76b70d55d55f662219a577b092f51038d5""><code>ef77af7</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/xanzy/go-gitlab/issues/791"">#791</a> from xanzy/svh/f-soft-delete</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/390fda840a9c8b0df450defb6d2d01d5d1bb710b""><code>390fda8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/xanzy/go-gitlab/issues/802"">#802</a> from giorgioazzinnaro/deploy-tokens</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/c74479a83c8c67035bd613f79771d90160f9953f""><code>c74479a</code></a> feat(DeployTokensService): Service to manage deploy tokens</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/d8bb0b4522eed51a265ffa0f44a291403ed4d85d""><code>d8bb0b4</code></a> Implement a rate limiting stategy</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/26c48095fc312a49c137bc5e6c59b2a13b127793""><code>26c4809</code></a> Add a <code>pending_delete</code> field to projects and groups</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/e1bb384182208faf27e46d132ab711f9343dcef1""><code>e1bb384</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/xanzy/go-gitlab/issues/799"">#799</a> from tanordheim/ci-git-depth</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/3dab725257b44a6b960bae28f17150db25884e61""><code>3dab725</code></a> Add support for ci_default_git_depth</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/cd9dd1926e61383c6bf823acda6c009ee0bf61bb""><code>cd9dd19</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/xanzy/go-gitlab/issues/795"">#795</a> from squiddy/extend-project-deployments-options</li>
<li><a href=""https://github.com/xanzy/go-gitlab/commit/2a6d473b37833b4593e3c7c548f68af66cc897f4""><code>2a6d473</code></a> Add four more options to ListProjectDeployments call</li>
<li>Additional commits viewable in <a href=""https://github.com/xanzy/go-gitlab/compare/v0.27.0...v0.29.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=github.com/xanzy/go-gitlab&package-manager=go_modules&previous-version=0.27.0&new-version=0.29.0)](https://dependabot.com/compatibility-score/?dependency-name=github.com/xanzy/go-gitlab&package-manager=go_modules&previous-version=0.27.0&new-version=0.29.0)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",140680839
622,2020-03-15T18:33:48Z,2020-03-15T18:33:48Z,,,,140680839
623,2020-03-14T15:53:36Z,2020-03-22T12:53:55Z,,,"This PR introduce a new parser/compiler for the query DSL, with an intermediary representation in the form of an AST. By breaking down the previously single step into multiple stages (lexer/parser/compiler), it's now easier to test and improve, but more importantly, it's now possible to compile the AST into different target (bug matcher for the cache, query for a remote bugtracker in a bridge ...).

@cheshirekow it's a good first step towards https://github.com/MichaelMure/git-bug/pull/241. Could you have a look an see if you like it ?",140680839
624,2020-03-13T20:59:47Z,2020-03-13T20:59:48Z,,,"Bumps [acorn](https://github.com/acornjs/acorn) from 5.7.3 to 5.7.4. **This update includes a security fix.**
<details>
<summary>Vulnerabilities fixed</summary>
<p><em>Sourced from <a href=""https://github.com/advisories/GHSA-7fhm-mqm4-2wp7"">The GitHub Security Advisory Database</a>.</em></p>
<blockquote>
<p><strong>Moderate severity vulnerability that affects acorn, minimist, and svjsl</strong>
There are high severity security vulnerabilities in two of ESLints dependencies:
- <a href=""https://app.snyk.io/vuln/SNYK-JS-ACORN-559469"">acorn</a>
- <a href=""https://app.snyk.io/vuln/SNYK-JS-MINIMIST-559764"">minimist</a></p>
<p>The releases 1.8.3 and lower of svjsl (JSLib-npm) are vulnerable, but only if installed in a developer environment. A patch has been released (v1.8.4) which fixes these vulnerabilities.</p>
<p>Identifiers:</p>
<ul>
<li><a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-7598"">CVE-2020-7598</a></li>
<li>SNYK-JS-ACORN-559469 (doesn&amp;#39;t have a CVE identifier)</li>
</ul>
<p>Affected versions: &lt; 5.7.4</p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/acornjs/acorn/commit/6370e90067552022710190319cbbbd8c43001957""><code>6370e90</code></a> Mark version 5.7.4</li>
<li><a href=""https://github.com/acornjs/acorn/commit/fbc15b1344f6dfb992f67b4bbf1357436247c8a0""><code>fbc15b1</code></a> More rigorously check surrogate pairs in regexp validator</li>
<li>See full diff in <a href=""https://github.com/acornjs/acorn/compare/5.7.3...5.7.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://api.dependabot.com/badges/compatibility_score?dependency-name=acorn&package-manager=npm_and_yarn&previous-version=5.7.3&new-version=5.7.4)](https://dependabot.com/compatibility-score/?dependency-name=acorn&package-manager=npm_and_yarn&previous-version=5.7.3&new-version=5.7.4)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language
- `@dependabot badge me` will comment on this PR with code to add a ""Dependabot enabled"" badge to your readme

Additionally, you can set the following in your Dependabot [dashboard](https://app.dependabot.com):
- Update frequency (including time of day and day of week)
- Pull request limits (per update run and/or open at any time)
- Out-of-range updates (receive only lockfile updates, if desired)
- Security updates (receive only security updates, if desired)



</details>",140680839
625,2020-03-05T22:46:14Z,2020-03-18T11:10:22Z,,,"It sounds like @MichaelMure has a plan for the ""correct"" thing to do. But this was easy and it got me unblocked. It allows an `identity` to be specified in the metadata of a credential (e.g. in the git config). 

Fixes: #351 
",140680839
626,2019-11-24T02:34:18Z,2020-02-29T22:10:15Z,,,"For issue #48
- [x] Add marking bug as favorite for termui
- [x] Add ""isFavorite"" field to graphql schema 
- [x] Add new filter in the query language",140680839
627,2019-11-01T22:03:54Z,2019-11-07T23:58:44Z,,,"This pull request contains only a design document / plan-of-attack. I did a scan through the code and tried to come up with what I think is a reasonable implementation of this feature. I wrote up a some notes which can be found in this pull request. I would greatly appreciate it if someone familiar with the internals and bridge system could comment on the document and point out any issues with or suggestions for my plan before/while I dig in and try to implement it. 

Here's a quick link to the [github-rendered markdown][1]. Please feel free to comment inline directly on the document source using this pull request. Thank you for your time!

[1]: https://github.com/cheshirekow/git-bug/blob/cheshirekow-sync-label/doc/sync-label.md",140680839
628,2019-09-18T23:57:42Z,2020-02-29T22:10:14Z,,,"- this is for issue #99
- adds command line switch -L to ""git bug ls"" to search by inverse label
- adds query ""inverselabel"" in termui for the same",140680839
629,2019-06-08T10:07:05Z,2020-02-29T22:10:13Z,,,fix https://github.com/MichaelMure/git-bug/issues/12,140680839
630,2019-04-16T16:30:22Z,2020-02-29T22:10:13Z,,,"Gives users the option to edit a comment
by specifying the comment Id

Closes https://github.com/MichaelMure/git-bug/issues/108",140680839
631,2018-10-05T22:25:14Z,2019-03-31T19:51:24Z,,,"Adds some code to read and write gitconfig files, and uses it to enable default remotes.

This is based off code at [go-gitconfig](https://github.com/tcnksm/go-gitconfig). I would have just used that code, but the project seems abandoned, and it is licensed as MIT.

Closes #11.",140680839
632,2020-03-21T09:10:19Z,2020-03-21T09:10:19Z,,,"Fixes: b8af168151fe0147fb06557029002ae226dcc549
Fixes: #1965",6376337
633,2020-03-19T15:30:15Z,2020-03-19T15:31:32Z,,,"```
In file included from /data/mwrep/res/osp/Poco/JSON/20-0-0-0/include/Poco/JSON/Object.h:22:
In file included from /data/mwrep/res/osp/Poco/JSON/20-0-0-0/include/Poco/JSON/Array.h:23:
In file included from /data/mwrep/res/osp/Poco/Foundation/20-0-0-0/include/Poco/Dynamic/Var.h:26:
In file included from /data/mwrep/res/osp/Poco/Foundation/20-0-0-0/include/Poco/Dynamic/VarHolder.h:22:
In file included from /data/mwrep/res/osp/Poco/Foundation/20-0-0-0/include/Poco/NumberFormatter.h:22: 
/data/mwrep/res/osp/Poco/Foundation/20-0-0-0/include/Poco/NumericString.h:220:31: error: comparison of integers of different signs: 'unsigned long' and 'char' [-Werror,-Wsign-compare]                              
                                if ((limitCheck - result) < add) return false;
                                     ~~~~~~~~~~~~~~~~~~~  ^ ~~~ 
/data/mwrep/res/osp/Poco/Foundation/20-0-0-0/include/Poco/NumericString.h:229:31: error: comparison of integers of different signs: 'unsigned long' and 'char' [-Werror,-Wsign-compare]                              
                                if ((limitCheck - result) < add) return false;
                                     ~~~~~~~~~~~~~~~~~~~  ^ ~~~ 
/data/mwrep/res/osp/Poco/Foundation/20-0-0-0/include/Poco/NumericString.h:240:31: error: comparison of integers of different signs: 'unsigned long' and 'char' [-Werror,-Wsign-compare]                              
                                if ((limitCheck - result) < add) return false;
                                     ~~~~~~~~~~~~~~~~~~~  ^ ~~~ 
/data/mwrep/res/osp/Poco/Foundation/20-0-0-0/include/Poco/NumericString.h:249:31: error: comparison of integers of different signs: 'unsigned long' and 'char' [-Werror,-Wsign-compare]                              
                                if ((limitCheck - result) < add) return false;
                                     ~~~~~~~~~~~~~~~~~~~  ^ ~~~
4 errors generated.
```",6376337
634,2020-03-18T15:37:10Z,2020-03-18T15:41:41Z,,,"Before this commit using Poco::URI class to parse specific URIs that had
percent-encoded fragment identifier resulted in the loss of information
concerning the way the fragment identifier was encoded. There could be the cases
when the  result of Poco::URI object serialization to string did not match the
original URI string Poco::URI object was created from.

In this commit we change the internal logic of fragment processing in Poco::URI,
so that the fragment is stored inside the class in raw form (the same way as
query string). The methods getFragment and setFragment work the old way (with
percent-decoded fragment values), new methods getRawFragment and setRawFragment
are added to get access to the original fragment representation.",6376337
635,2020-02-26T17:21:37Z,2020-03-09T21:18:10Z,,,"…verting int into float

Example of warning (error when using -Werror) we get with clang 10:

/remote/intdeliv/components/osp/Poco/Foundation/19-0-0-6/include/Poco/Dynamic/VarHolder.h:444:14: error: implicit conversion from 'int' to 'float' changes value from 2147483647 to 2147483648 [-Werror,-Wimplicit-int-float-conversion]
                if (from > std::numeric_limits<T>::max())
                         ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/remote/intdeliv/components/osp/Poco/Foundation/19-0-0-6/include/Poco/Dynamic/VarHolder.h:332:4: note: in instantiation of function template specialization 'Poco::Dynamic::VarHolder::checkUpperLimitFloat<float, int>' requested here
                        checkUpperLimitFloat<F,T>(from);
                        ^
/remote/intdeliv/components/osp/Poco/Foundation/19-0-0-6/include/Poco/Dynamic/VarHolder.h:2175:3: note: in instantiation of function template specialization 'Poco::Dynamic::VarHolder::convertToSmaller<float, int>' requested here
                convertToSmaller(_val, val);
                ^",6376337
636,2020-02-25T13:06:33Z,2020-02-25T18:04:28Z,,,"`Poco `is available as a port in [vcpkg](https://github.com/microsoft/vcpkg), a C++ library manager that simplifies installation for `poco `and other project dependencies. Documenting the install process here will help users get started by providing a single set of commands to build `poco`, ready to be included in their projects.

We also test whether our library ports build in various configurations (dynamic, static) on various platforms (OSX, Linux, Windows: x86, x64, UWP) to keep a wide coverage for users.

I'm a maintainer for vcpkg, and [here is what the port script looks like](https://github.com/microsoft/vcpkg/blob/master/ports/poco/portfile.cmake). We try to keep the library maintained as close as possible to the original library.",6376337
637,2020-02-21T16:49:43Z,2020-02-21T16:49:43Z,,,"fix build issue '#error This file requires compiler and library support for the ISO C++ 2011 standard.' make version 4.1, g++ 5.4, ubuntu 16.04",6376337
638,2020-02-17T16:15:05Z,2020-02-17T16:56:33Z,,,"Zip and SevenZip do not depend on Util, XML, JSON",6376337
639,2020-02-17T16:00:40Z,2020-02-17T16:00:40Z,,,Fix assigned value to wrong pointer,6376337
640,2020-02-12T07:08:43Z,2020-02-12T07:08:43Z,,,"In TLS 1.3 session resumption is enabled by default: we can disable to keep shutdown working as is, otherwise we should change the way shutdown close connection.
related issue: [#2776](https://github.com/pocoproject/poco/issues/2776)",6376337
641,2020-02-06T14:22:29Z,2020-02-18T11:17:16Z,,,"Based on:
https://sources.debian.org/patches/poco/1.9.0-5/0006-fp-support-environments-without-hardware-floating-po.patch/

Fix issue:
https://github.com/pocoproject/poco/issues/2904",6376337
642,2020-01-14T17:22:05Z,2020-01-14T17:22:05Z,,,Was not sure if implementation should be put in .cpp or in .h with inline. So I did the same thing as the two operators that was already there.,6376337
643,2020-01-01T07:32:42Z,2020-01-01T07:32:42Z,,,"> fix a dead lock when called unregisterConnector twice in same time.
> 
> lock 1:
> When socket connected:
> NObserver::notify(Notification* pNf) <- lock
> SocketConnector::onWritable(WritableNotification* pNotification)
> SocketConnector::onConnect()
> SocketConnector::unregisterConnector()
> SocketReactor::removeEventHandler(const Socket& socket, const Poco::AbstractObserver& observer) <- wait to unlock
> 
> When delete SocketConnector:
> SocketConnector::~SocketConnector()
> SocketConnector::unregisterConnector() <- lock
> SocketReactor::removeEventHandler(const Socket& socket, const Poco::AbstractObserver& observer)
> SocketNotifier::removeObserver(SocketReactor* pReactor, const Poco::AbstractObserver& observer)
> NotificationCenter::removeObserver(const AbstractObserver& observer)
> NObserver::disable() <- wait to unlock
> 
> Test code maybe execute only on my machine.
> I will remove test code if you don't need it.
> 

from #2874 .
It changed source and destination branch.",6376337
644,2019-12-01T11:31:40Z,2020-02-04T11:22:33Z,,,"I noticed that in function of CheckFlag at
poco/SevenZip/src/CpuArch.c:13, an inline assembly statement is used
but didn't declare the side effect, this may corrupt the normal data
flow under some context. I produce the bug case below:

```
int __attribute__((noinline)) set_val(int v) { return v; }

int main() {
  int a = set_val(0);
  int b = set_val(1);
  int c = set_val(2);
  a = a + b; b = b + c; c = c + a;
  int d = CheckFlag(0);
  printf(""%d, %d, %d, %d\n"", a, b, c, d);
  return 0;
}
```
Assume CheckFlag return 0, the above code should produce output 1, 3, 3,
0, replace the invocation of CheckFlag by 0 will indeed output these four
numbers. But if the above code is unchanged and compiled with -O2 flag, the output
will be wrong. In my PC (gcc-8 -O2), the above code will output 514, 1, 514, 0.
The root cause of the wrong output is that inline assembly needs user to
declare extra side effect, as mentioned in GNU specification
https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html#Clobbers-and-Scratch-Registers,
""In order to inform the compiler of these changes, list them in the
clobber list.""",6376337
645,2019-11-29T12:59:15Z,2020-02-04T11:22:33Z,,,EVP_CIPHER_CTX_block_size was used in CryptoTransformImpl::setPadding. This looks like an copy paste from previous function. New implementation uses EVP_CIPHER_CTX_set_padding.,6376337
646,2019-11-27T13:06:12Z,2020-02-04T11:22:33Z,,,"- Added MinGW support
- Fixed ApacheConnector errors",6376337
647,2019-11-02T00:56:51Z,2020-02-04T11:22:33Z,,,Signed-off-by: Khem Raj <raj.khem@gmail.com>,6376337
648,2019-10-30T13:06:41Z,2020-02-04T11:22:33Z,,,"Add new class HPPURI, which overload an URI and provide a way to set http headers.
Enhance HTTP(S)StreamFactory to add http headers provided by HTTPURI
Add unit tests

This PR comes to fix #2820",6376337
649,2019-10-04T11:20:45Z,2020-01-22T11:20:16Z,,,"* In Data/MySQL/src/SessionHandle.cpp changed calling of mysql_reset_connection() to query FLUSH
* previously used mysql_reset_connection() caused issues with encoding
* see comment in Data/MySQL/src/SessionHandle.cpp:181 SessionHandle::reset() for more info

# Related issues
https://github.com/pocoproject/poco/issues/2546
https://github.com/pocoproject/poco/issues/2800",6376337
650,2019-10-02T14:44:22Z,2020-02-04T11:22:33Z,,,Fixes https://github.com/pocoproject/poco/issues/2222,6376337
651,2019-08-30T18:45:52Z,2020-02-04T11:22:34Z,,,"During the configuration phase in a cross compilation scenario (at least with wine + msvc),
`include(InstallRequiredSystemLibraries)` fails even if
`MSVC_REDIST_DIR` is provided with the error message 
`cmake_host_system_information does not recognize <key> VS_15_DIR`.

This should not be an hard error, in case someone wants to
compile/use the library, and not package it.

As explained on https://reviews.llvm.org/D41220, the most sensible fix
is to include `InstallRequiredSystemLibraries` only on a Windows host.",6376337
652,2019-08-08T02:22:30Z,2020-02-04T11:22:34Z,,,"a. Fix Makefiles so as not to use ""dl"" library because it's included in C library in QNX SDP7.0
b. Fix File_UNIX.cpp so as it include sys/statvfs.h instead of sys/statfs.h",6376337
653,2019-06-24T12:09:31Z,2019-06-24T12:09:31Z,,,"Few months ago, I try to use Poco with conan but without much success. Then I found [Hunter](https://docs.hunter.sh/en/latest/)
Since that I use/build Poco with Hunter and I also build a POC for macchina.io https://github.com/macchina-io/macchina.io/pull/71
Poco was also used in Hunter before (PocoCPP) but they patched ""Poco cmake build system."" See also here: https://github.com/ruslo/hunter/pulls?utf8=%E2%9C%93&q=is%3Apr+is%3Aclosed+PocoCPP

**Hunter is only optional and as default it is off. So the current cmake build system is not affected.** If you switched it on with the cmake parameter:
```
cmake -Hpoco -Bbuild-poco -DHUNTER_ENABLED=ON
```

First time, it will take a time, because hunter is building the third-party libraries. After third-party are build, it is only building Poco. 
With Hunter you can add Poco easily in your project without installing any new ""dependencies"". Hunter is based on cmake only.",6376337
654,2018-05-21T14:17:04Z,2019-10-23T08:37:48Z,,,"Those are changes necessary to build Poco Library with BoringSSL instead of OpenSSL. 
I tested that it's works on MacOs. ",6376337
655,2018-01-30T14:16:41Z,2020-01-22T11:11:45Z,,,"Trying to find a certificate using **certificateName** turned out to be really difficult. It's always giving **Failed to find certificate** error, so I added the possibility to search a certificate using its SHA1 hash.",6376337
656,2016-11-27T00:34:45Z,2016-11-27T00:34:45Z,,,"(cherry picked from commit 08a748dae166e9aa735ae90fc5d91a420dc132f2)

This is an invaluable member to WebSocket as it avoids communicating frame sizes in advance, or setting a limit. Only thing missing is a cap on the maximum buffer size. Otherwise, it's a great improvement over the lack of any way to determine a frame size in advance of reading it.

Cherry-picked from develop branch.",6376337
657,2016-11-21T08:41:06Z,2016-11-22T11:45:50Z,,,,6376337
658,2016-11-21T08:34:33Z,2016-11-22T13:27:28Z,,,,6376337
659,2020-03-26T09:51:32Z,2020-03-26T12:51:26Z,,,,104208128
660,2020-03-26T09:42:14Z,2020-03-26T09:53:20Z,,,"The `x_grad_data` ptr is not initialized when declaring it, which causes a segmentation error when running it kernel. Now we initialize it to nullptr.",104208128
661,2020-03-25T11:57:04Z,2020-03-26T09:29:48Z,,,,104208128
662,2020-03-25T11:19:13Z,2020-03-25T11:19:17Z,,,增加XPU通过kernel方式接入PaddleLite,104208128
663,2020-03-25T08:40:12Z,2020-03-26T15:50:54Z,,,"# 状态：等待review

## 主要内容

1. 修复demo/cxx/mobile_light的编译问题；
2. 修复opencl elemul/instanceNorm kernel；
3. 支持CopyToCpu/CopyFromCPU的int64；
4. 增强opencl runtime获取信息，加入新接口CLRuntime::GetDeviceInfo方便kernel开发者使用；
",104208128
664,2020-03-25T07:00:07Z,2020-03-26T10:27:00Z,,,"我们都知道，PaddleLite可以做移动端预测，事实上PaddleLite支持在移动端做模型训练。本文给出使用PaddleLite做训练的例子，这一例子对应的任务是“波士顿房价预测”，又称作“fit-a-line”。
  
  你可以通过book库中的[文档](https://paddlepaddle.org.cn/documentation/docs/zh/user_guides/simple_case/fit_a_line/README.cn.html)和[源码](https://github.com/PaddlePaddle/book/tree/develop/01.fit_a_line)进一步了解“波士顿房价预测”这一任务的定义及其建模过程，其使用线性回归（Linear Regression）模型做建模。本PR将其迁移至Paddle-Lite, 在移动端进行训练。",104208128
665,2020-03-23T09:44:02Z,2020-03-23T11:38:13Z,,,"- 新增fc_int8的bridge(暂时跑不了)
- 新增fc_int8的单测",104208128
666,2020-03-22T16:45:06Z,2020-03-26T11:48:12Z,,,"【问题描述】：使cxx_predictor->clone()得到的Predictor共享权重参数
【进度】：编译通过，单测测试暂未通过 （执行`Cloned_Predictor->Run`，执行成功，但执行后报segmentarion fault：预估可能原因`programdesc`需要修改为share_ptr格式、`scope`加入读取锁）
【todo】：
              1、cxx_api.h： 将Predictor->programdesc修改为share_ptr格式，需要共享，较多关联函数需要修改
              2、lite/core/scope.cc中添加读取线程锁。（当前加入了写入线程锁）
             ",104208128
667,2020-03-18T12:19:07Z,2020-03-20T17:14:23Z,,,paddle js new code PR,104208128
668,2020-03-17T03:57:09Z,2020-03-18T06:44:55Z,,,"【问题描述】：之前Paddle-Lite动态库，将所有lite_cc_library 和`cc_library`注册的lib的源文件都打包到 full_api_shared.so中。  出现问题：动态库中的源文件不易控制，`full_api_shared.so`中容易出现redefination （两个`lite_cc_library`注册的库文件定义了相同的变量时）
【本PR修改】将full_publish下 full_api_shared.so和light_api_shared.so改为从指定的lib中打包。避免编译出冲突并减少体积

对full_publish动态库体积的影响：
修改前：
![image](https://user-images.githubusercontent.com/45189361/76837387-6d23ad00-686d-11ea-9b95-c6f920caf5b8.png)

修改后：
![image](https://user-images.githubusercontent.com/45189361/76843893-6f8b0480-6877-11ea-9a0a-89acbd2005db.png)
",104208128
669,2020-03-16T03:16:31Z,2020-03-25T12:08:00Z,,,"- 新增shape, gather, lookup_table的npu bridge。
    - shape在ddk320才支持，所以相关编译都先注释掉。
    - gather, lookup_table在新rom上才可以用，因此对应```USE_SUBGRAPH_BRIDGE```都注释掉
- shape arm kernel修改为host kernel
- 优化compare代码。减少重复代码。arm kernel移动到host kernel。
- 增加reshape的host单测",104208128
670,2020-03-15T06:25:33Z,2020-03-15T06:55:55Z,,,,104208128
671,2020-03-12T06:36:25Z,2020-03-26T02:26:57Z,,,,104208128
672,2020-03-09T11:14:56Z,2020-03-10T03:48:45Z,,,"* 处理fake_quant_dequant_op，支持所有无权重的op进行量化
* 使用输入tensor的名字来表示scale，避免同一个op多个输入tensor的scale重名
* 兼容所有以前训练的量化模型

训练端量化代码： [PR](https://github.com/PaddlePaddle/Paddle/pull/22869)
* Quantized ops with weight have attrs: is_quantized_with_weight, activation_bits, weight_bits, activation_quantize_type, weight_quantize_type
* For quantized ops without weight have attrs: is_quantized_without_weight, activation_bits
* All quantized ops have the input threshold (KL threshold or abs_max value), the name of input threshold is the intput var name of fake_quant/fake_quant_dequant.
",104208128
673,2020-03-06T13:30:26Z,2020-03-23T12:39:41Z,,,"(1) 添加接口`GetMutableTensor(name)`
【问题描述】NLP业务需要在加载模型后修改模型终端权重参数，之后再运行。需要接口： GetMutableTensor(name)返回一个可修改的张量
【方案设计】在模型加载后修改权重在多线程下有风险，可能导致不确定输出；且当前只有x86 平台下提出该需求，不推荐一般用户使用
【本PR工作】设计一个内部develop接口，Cxx_predictor->GetMutableTensor(std::string “varname”)。该接口只有cxx_predictor可以调用，而且不对外开放使用文档。为内部调试接口。

(2) 添加接口 `const std::vector<std::string> Predictor::GetParamNames()`
【方案设计】接口只输出模型的权重参数的名称，不输出`输入变量`、`输出变量`、`中间变量`和`feed/fetch`名称
【本PR工作】设计一个内部develop接口，`const std::vector<std::string> Cxx_predictor->GetParamNames()`。

该接口只有cxx_predictor可以调用，而且不对外开放使用文档。为内部调试接口。",104208128
674,2020-03-02T11:41:17Z,2020-03-06T10:17:32Z,,,Signed-off-by: Tiffany Lin <tiffany.lin@mediatek.com>,104208128
675,2020-03-02T11:30:17Z,2020-03-03T05:41:32Z,,,Add unittest for post quantization without data,104208128
676,2020-02-24T05:00:14Z,2020-02-26T02:49:26Z,,,Add reduce sum test when the input dimension is 3,104208128
677,2020-02-21T09:04:37Z,2020-02-21T09:04:37Z,,,,104208128
678,2020-02-20T08:30:49Z,2020-03-24T07:18:51Z,,,lite cuda集成多流，开发测试中。,104208128
679,2020-02-14T06:50:51Z,2020-03-04T09:25:50Z,,,FPGA support quantitative model,104208128
680,2020-02-10T07:49:47Z,2020-02-20T01:28:30Z,,,"Replace reduce_sum Eigen with c implementation in steprnn.

StepRNN的性能改进：

| develop | this PR |
|---|---|
| 0.0174215ms| 0.0166304 ms |",104208128
681,2020-02-03T14:25:01Z,2020-02-13T03:20:38Z,,,"1. Move equal, not_equal, less_than, less_equal, greater_than, greater_equal, conditional_block, while, increment, lod_reset, read_from_array, write_to_array  from arm to host.
2. Support picking kernels for the Ops which are defined in the sub block of the conditional_block/while op.
3. Fix the declaration of op kernels(including the data type and data layout).",104208128
682,2020-01-15T03:53:17Z,2020-01-15T08:46:06Z,,,"# 状态：WIP单测出错正在看，等review

## 更新后

多出以下：

- 打印维度信息（input、filter、output）；
- Kernel具体方法（如direct、gemm、depthwise）；
- Kernel相关的参数信息remark（具体参数）；
- GOPS。

```shell
===== Detailed Profiler Summary: N/A, Exclude 0 warm-ups =====
Operator Type             Kernel Name                              Remark       Input        Filter       Output       GOPs         Avg (ms)     Min (ms)     Max (ms)     Last (ms)
calib                                                                                                                  0.000000     0.025390     0.023000     0.051000     0.026000
conv2d                    direct/arm/int8_t/NCHW                   3x3s2p1g1    1x3x128x128  8x3x3x3      1x8x64x64    0.001769     0.144360     0.140000     0.217000     0.140000
conv2d                    gemm/arm/int8_t/NCHW                     1x1s1p0g1    1x8x64x64    8x8x1x1      1x8x64x64    0.000524     0.052840     0.050000     0.129000     0.052000
conv2d                    depthwise/arm/int8_t/NCHW                3x3s1p1g8    1x8x64x64    8x1x3x3      1x8x64x64    0.000590     0.055860     0.054000     0.066000     0.057000
conv2d                    gemm/arm/int8_t/NCHW                     1x1s1p0g1    1x8x64x64    4x8x1x1      1x4x64x64    0.000262     0.027500     0.027000     0.036000     0.027000
conv2d                    gemm/arm/int8_t/NCHW                     1x1s1p0g1    1x4x64x64    24x4x1x1     1x24x64x64   0.000786     0.122690     0.118000     0.154000     0.122000
conv2d                    depthwise/arm/int8_t/NCHW                3x3s2p1g24   1x24x64x64   24x1x3x3     1x24x32x32   0.000442     0.056950     0.054000     0.140000     0.056000
conv2d                    gemm/arm/int8_t/NCHW                     1x1s1p0g1    1x24x32x32   6x24x1x1     1x6x32x32    0.000295     0.020630     0.019000     0.030000     0.021000
calib                                                                                                                  0.000000     0.003530     0.003000     0.005000     0.004000
conv2d                    gemm/arm/int8_t/NCHW                     1x1s1p0g1    1x6x32x32    36x6x1x1     1x36x32x32   0.000442     0.053050     0.051000     0.108000     0.052000
conv2d                    depthwise/arm/int8_t/NCHW                3x3s1p1g36   1x36x32x32   36x1x3x3     1x36x32x32   0.000664     0.073620     0.070000     0.129000     0.078000
```",104208128
683,2020-01-13T03:07:28Z,2020-03-04T08:17:50Z,,,"add bitmain backend 
support resnet50 on BM1682",104208128
684,2020-01-13T02:25:47Z,2020-02-03T02:04:46Z,,,test=develop,104208128
685,2020-01-06T07:07:38Z,2020-01-06T07:23:22Z,,,,104208128
686,2019-12-25T08:51:54Z,2020-02-11T11:16:52Z,,,test=develop,104208128
687,2019-12-23T07:30:07Z,2019-12-26T05:52:27Z,,,…obile,104208128
688,2019-12-20T06:30:53Z,2019-12-20T06:30:53Z,,,,104208128
689,2019-12-12T02:14:06Z,2019-12-12T02:14:06Z,,,make convert_arm_sdot_to_machine_code.py be compatible with python2 test=develop,104208128
690,2019-11-26T04:23:26Z,2019-11-26T04:38:04Z,,,"# 状态：WIP，开发中


## 说明

给CXX和Mobile的Predictor添加`GetOutput`接口，并添加对应单测",104208128
691,2019-11-18T04:40:30Z,2019-11-19T03:45:30Z,,,,104208128
692,2019-11-12T06:32:27Z,2019-11-27T04:18:51Z,,,,104208128
693,2019-10-31T02:35:58Z,2019-10-31T02:35:58Z,,,,104208128
694,2019-10-22T11:47:18Z,2019-10-23T07:30:01Z,,,"build commad 
./lite/tools/ci_build.sh build_test_server_nv",104208128
695,2019-10-22T10:53:18Z,2019-10-23T11:42:42Z,,,,104208128
696,2019-09-19T02:59:10Z,2019-09-19T02:59:10Z,,,,104208128
697,2019-09-17T03:03:50Z,2019-09-17T03:03:50Z,,,,104208128
698,2019-08-22T03:28:04Z,2020-03-10T09:07:07Z,,,,104208128
699,2020-02-29T04:30:46Z,2020-02-29T04:30:46Z,,,"**Summary:** [summary of the change and which issue is fixed here]
  Begin of Refactor to make some of the managed classes loosely coupled to allow for greater test-ability.

**Changes:** [specify the structures changed] 
   - Extracted interfaces for internal implementations
   - Replace `WeakReference` with `WeakReference<T>` for cleaner code.
      
## How Has This Been Tested?
TODO:


## Types of changes
<!--- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->
- [x] Code Cleanup
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Updated documentation

**Checklist:**
- [ ] Tested the code(if applicable)
- [x] Commented my code
- [x] Changed the documentation(if applicable)
- [x] New files have a license disclaimer
- [x] The formatting is consistent with the project (project supports .editorconfig)
",1135454
700,2019-12-26T00:52:12Z,2020-01-23T12:08:13Z,,,"Fixes [issue-number] 
   -  Fixes #1535

**Summary:**
   - Implement PerMonitorV2 dpiAwareness

**Changes:**
   - Add a hook to handle `WM_DPICHANGED` message.
   - Change dpiAwareness to PerMonitorV2 in `app.manifest`.
      
## How Has This Been Tested?
I tested it on a 4k screen with dpi from 100% to 350%, and it works fine.
And I tested it at a computer with two screen which has different dpi, and it also works fine when moving between screens.

## Screenshots (if appropriate):

## Types of changes
- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to change)
- [ ] Updated documentation

**Checklist:**
- [x] Tested the code(if applicable)
- [ ] Commented my code
- [ ] Changed the documentation(if applicable)
- [ ] New files have a license disclaimer
- [x] The formatting is consistent with the project (project supports .editorconfig)
",1135454
701,2019-03-13T13:41:04Z,2019-10-05T03:52:28Z,,,"For instance, this image is necessary to give feedback (content displayed alongside cursor while dragging).",1135454
702,2018-08-21T09:31:44Z,2020-02-04T14:04:51Z,,,"This pull request adds basic UI automation support. Accessibility tree parsing was implemented using `cefclient` source code as a reference:
https://bitbucket.org/chromiumembedded/cef/src/ea0e213bef0367edfedb7cf0a487e04e8c6cdf00/tests/cefclient/browser/osr_accessibility_node_win.cc?at=master&fileviewer=file-view-default
Chromium sources were also used:
https://cs.chromium.org/chromium/src/ui/accessibility/ax_tree_source.h?dr=C&g=0
Windows Narrator and inspect.exe (part of Windows SDK) were used for testing. 
Three steps are required to enable UI automation support:

1. Pass `force-renderer-accessibility` flag as a command line argument
2. Replace `ChromiumWebBrowser` with `ChromiumWebBrowserWithAccessibilitySupport` 
3. Set AccessibilityHandler for the browser control 

The accessibility support is very basic at this point and doesn't handle cases like text selection, node attribute updates and so on. ",1135454
703,2018-04-09T11:17:32Z,2019-10-05T03:52:29Z,,,"The extension method `TaskExtensions.TrySetResultAsync` has non-deterministic results when called twice on the same instance, even on the same thread: it creates one task for each call, which may not run in their creation order.
This PR adds a wrapper class around `TaskCompletionSource` (`AsyncTaskCompletionSource`), that takes care of calling `TrySetResult` in an async fashion while ensuring that only the first call is executed. I would really recommend using it instead of `TaskCompletionSource` each time `TaskExtensions.TrySetResultAsync` is used (even if it is called only once in any logical workflow), because this non-determinism can cause very subtle and hard-to-track bugs.

This PR also updates the test case that could be violated with the previous behavior (but that was hard to trigger with only one test).",1135454
704,2018-01-10T20:05:50Z,2019-10-05T03:52:29Z,,,"When an object is registered with the BindingOptions.CamelCaseJavascriptNames on, this setting is not completly honored. Before the fix, this setting only converts the names of the object being registered but not the names of the objects that cross managed boundaries.

This changes that behavior and honors the setting provided.
If you think that this change might great impact on existing consumers I can add an extra property. What do you think?",1135454
705,2020-03-26T17:53:19Z,2020-03-26T17:54:06Z,,,"In the current implementation, sst file checksum is calculated by a shared checksum function object, which may make some checksum function hard to be applied here such as SHA1. In this implementation, each sst file will have its own checksum generator obejct, created by FileChecksumGenFactory. User needs to implement its own FilechecksumGenerator and Factory to plugin the in checksum calculation method.

Test plan: tested with make asan_check",6934395
706,2020-03-26T17:49:58Z,2020-03-26T17:52:14Z,,,"Although there are tests related to locking in transaction_test, this new test directly tests against TransactionLockMgr.

Test Plan:
make transaction_lock_mgr_test && ./transaction_lock_mgr_test",6934395
707,2020-03-25T22:02:30Z,2020-03-26T18:24:51Z,,,"Summary:
The patch adds a couple of classes to represent metadata about
blob files: `SharedBlobFileMetaData` contains the information elements
that are immutable (once the blob file is closed), e.g. blob file number,
total number and size of blob files, checksum method/value, while
`BlobFileMetaData` contains attributes that can vary across versions like
the amount of garbage in the file. There is a single `SharedBlobFileMetaData`
for each blob file, which is jointly owned by the `BlobFileMetaData` objects
that point to it; `BlobFileMetaData` objects, in turn, are owned by `Version`s
and can also be shared if the (immutable _and_ mutable) state of the blob file
is the same in two versions.

In addition, the patch adds the blob file metadata to `VersionStorageInfo`, and extends
`VersionBuilder` so that it can apply blob file related `VersionEdit`s (i.e. those
containing `BlobFileAddition`s and/or `BlobFileGarbage`), and save blob file metadata
to a new `VersionStorageInfo`. Consistency checks are also extended to ensure
that table files point to blob files that are part of the `Version`, and that all blob files
that are part of any given `Version` have at least some _non_-garbage data in them.

Test Plan:
`make check`",6934395
708,2020-03-25T21:41:01Z,2020-03-25T21:50:10Z,,,"Summary:
Add `encrypt_data_time` and `decrypt_data_time` perf_context counters to time encryption/decryption time when `EnvEncryption` is enabled.

Test Plan:
CI",6934395
709,2020-03-24T23:08:38Z,2020-03-26T16:50:07Z,,,"Summary: Production CPU profiles show a lot of time in
LRUHandleTable::FindPointer, though this appears to be speculative
execution while waiting for lock, confirmed by profiling db_bench
with varying -cache_numshardbits. Currently, the max inferred
num_shard_bits is 6 (64 shards), for any capacity over 32MB. And that
doesn't even pass the sniff test for a machine running 80 hardware
threads.

Presumably, the primary hazard of too many cache shards is ""clustering,""
wherein a too-big combination of hot data ends up in a single shard.
IMHO, the best way to balance parallelism and clustering is using square
roots. If the number of shards is kept a bit below the square root of
the expected number of entries, you're unlikely to be burned by either.

Capacity: Old shard bits -> New shard bits
8MiB: 4 -> 4
1GiB: 6 -> 8
16GiB: 6 -> 10

Test Plan: Updated unit test, and with 16 threads, db_bench shows about
10% higher readrandom ops/s for 10 shard bits vs. 6.",6934395
710,2020-03-24T21:43:06Z,2020-03-26T15:31:52Z,,,"The ObjectRegistry is now a member variable of the DBOptions and ConfigOptions.  This allows a registry to be on a per-configuration basis.

The ObjectRegistry was also made into a Configurable object.  The registry can now be saved to and from a string.  This change allows the object registry to be read and written to the options file.

The ObjectLibrary was expanded to include a ""Local"" and a ""Dynamic"" library subclass.  The ""Dynamic"" library is initialized from a shared library.  The ""Local"" library is initialized from an in-process method.

The loading of Customizable objects was changed to use the variables in the options class.",6934395
711,2020-03-24T21:16:17Z,2020-03-26T15:21:56Z,,,"The Customizable class is an extension of the Configurable class and allows instances to be created by a name/ID.  Classes that extend customizable can define their Type (e.g. ""TableFactory"", ""Cache"") and  a method to instantiate them (TableFactory::CreateFromString).  Customizable objects can be registered with the ObjectRegistry and created dynamically.

Future PRs will make more types of objects extend Customizable.",6934395
712,2020-03-24T19:38:21Z,2020-03-24T19:39:23Z,,,"The debug is supposed to print out two keys to show the value mismatch, which was compared just a few lines above.

However, the actual print-out is the same values (so they obviously won't be mismatched)",6934395
713,2020-03-24T19:07:01Z,2020-03-26T17:51:17Z,,,"1. If expiration_time is non-positive, no need to call NowMicros, save a syscall.
2. expire_time should only be set when expired is false.

Test Plan:
make check",6934395
714,2020-03-24T19:03:59Z,2020-03-26T02:21:56Z,,,"The refactored logic is easier to read.

Test Plan:
make check",6934395
715,2020-03-24T18:22:45Z,2020-03-25T19:04:43Z,,,"Summary: Memtable bloom filter is useful in many use cases. A default value on with conservative 1.5% memory can benefit more use cases than use cases impacted.

Test Plan: Run all existing tests.",6934395
716,2020-03-24T17:30:34Z,2020-03-24T20:14:16Z,,,"Adding solid support for multiple architectures was initially triggered by RocksJava users. As such I would like to keep the CI for RocksJava on all architectures, to ensure we don't break backwards compatibility.

@pdillinger okay let's see how long it takes to complete Travis-CI with this one...",6934395
717,2020-03-24T05:48:51Z,2020-03-24T05:53:40Z,,,"Summary: as title. This PR also tests the recently-added `VersionEditHandler` intensively.

Test Plan (devserver):
```
make check
COMPILE_WITH_ASAN=1 make check
```",6934395
718,2020-03-24T04:28:54Z,2020-03-24T04:29:07Z,,,,6934395
719,2020-03-24T02:32:34Z,2020-03-24T02:32:51Z,,,"1. stats_history_test: one slice of stats history is 12526 Bytes, which is greater than original assumption. 
![image](https://user-images.githubusercontent.com/17753898/77381970-5a611a80-6d3c-11ea-9d64-59d2e3c04f79.png)
2. table_test: in VerifyBlockAccessTrace function, release trace reader before delete trace file.
",6934395
720,2020-03-23T06:25:57Z,2020-03-23T23:59:12Z,,,The last key may hit index of out bound exception when id = 9.,6934395
721,2020-03-22T18:26:01Z,2020-03-24T07:24:55Z,,,"This PR exposes the `Iterator::Refresh` method to the Java API by adding it on the `RocksIteratorInterface` interface. There are three concrete implementations: `RocksIterator`, `SstFileReaderIterator`, and `WBWIRocksIterator`. For the first two cases, the JNI side simply delegates to the underlying `Iterator::Refresh` method; in the last case, as it doesn't share an ancestor, and per the discussion in #3465, a `Status::NotSupported` exception is thrown.

As the last PR had no activity in a while, I'm opening a new one - I'm completely fine with merging the previous PR if it gets completed before this is reviewed.

Let me know if there's anything missing or anything else I can do :+1: ",6934395
722,2020-03-21T23:28:29Z,2020-03-25T10:34:58Z,,,"Compilation of rocksdb fails because -lpthread flag is needed by gtest

**Before modification** :
/usr/bin/c++   -W -Wextra -Wall -Wsign-compare -Wshadow -Wno-unused-parameter -Wno-unused-variable -Woverloaded-virtual -Wnon-virtual-dtor -Wno-missing-field-initializers -Wno-strict-aliasing -std=c++11 -march=native -Werror -fno-builtin-memcmp -g -DROCKSDB_USE_RTTI   CMakeFiles/table_reader_bench.dir/table/table_reader_bench.cc.o  -o table_reader_bench -Wl,-rpath,/develop/src/rocksdb/build librocksdb.so.6.8.0 libtestharness.a /usr/lib/x86_64-linux-gnu/libgflags.so third-party/gtest-1.8.1/fused-src/gtest/libgtest.a -lpthread

**After modification** :
/usr/bin/c++   -W -Wextra -Wall -Wsign-compare -Wshadow -Wno-unused-parameter -Wno-unused-variable -Woverloaded-virtual -Wnon-virtual-dtor -Wno-missing-field-initializers -Wno-strict-aliasing -std=c++11 -march=native -Werror -fno-builtin-memcmp -g -DROCKSDB_USE_RTTI   CMakeFiles/table_reader_bench.dir/table/table_reader_bench.cc.o  -o table_reader_bench -Wl,-rpath,/develop/src/rocksdb/build librocksdb.so.6.8.0 libtestharness.a /usr/lib/x86_64-linux-gnu/libgflags.so -lpthread third-party/gtest-1.8.1/fused-src/gtest/libgtest.a",6934395
723,2020-03-19T19:36:05Z,2020-03-19T19:36:21Z,,,"Hi Team, 
  I am from Cohesity while I was trying rocksdb6.4.6 APIs I found that if the size of the sorted_files is 0  it will lead to a SEG FAULT as in the for loop it's checking if i <  sorted_files.size() -1 .
If  sorted_files.size() ==0 then  sorted_files.size()-1 is a positive number as it is of the type size_t which is unsigned. Hence to avoid this I have added a safer continue option to continue when a  sorted_files.size() is less than or equal to 1.",6934395
724,2020-03-19T17:23:27Z,2020-03-24T18:47:56Z,,,"Summary: Create a thread in DeleteScheduler only when delete rate limit is set
	 because when there is no rate limit on deletion, a thread per DeleteScheduler
	 consumes unnecessary resources.

Task Id: T64154614

Test Plan: make -j64 check",6934395
725,2020-03-19T03:55:31Z,2020-03-20T20:22:35Z,,,"We're seeing iterators with `ReadOptions::read_tier == kBlockCacheTier` sometimes doing file reads. Stack trace:

```
rocksdb::RandomAccessFileReader::Read(unsigned long, unsigned long, rocksdb::Slice*, char*, bool) const
rocksdb::BlockFetcher::ReadBlockContents()
rocksdb::Status rocksdb::BlockBasedTable::MaybeReadBlockAndLoadToCache<rocksdb::ParsedFullFilterBlock>(rocksdb::FilePrefetchBuffer*, rocksdb::ReadOptions const&, rocksdb::BlockHandle const&, rocksdb::UncompressionDict const&, rocksdb::CachableEntry<rocksdb::ParsedFullFilterBlock>*, rocksdb::BlockType, rocksdb::GetContext*, rocksdb::BlockCacheLookupContext*, rocksdb::BlockContents*) const
rocksdb::Status rocksdb::BlockBasedTable::RetrieveBlock<rocksdb::ParsedFullFilterBlock>(rocksdb::FilePrefetchBuffer*, rocksdb::ReadOptions const&, rocksdb::BlockHandle const&, rocksdb::UncompressionDict const&, rocksdb::CachableEntry<rocksdb::ParsedFullFilterBlock>*, rocksdb::BlockType, rocksdb::GetContext*, rocksdb::BlockCacheLookupContext*, bool, bool) const
rocksdb::FilterBlockReaderCommon<rocksdb::ParsedFullFilterBlock>::ReadFilterBlock(rocksdb::BlockBasedTable const*, rocksdb::FilePrefetchBuffer*, rocksdb::ReadOptions const&, bool, rocksdb::GetContext*, rocksdb::BlockCacheLookupContext*, rocksdb::CachableEntry<rocksdb::ParsedFullFilterBlock>*)
rocksdb::FilterBlockReaderCommon<rocksdb::ParsedFullFilterBlock>::GetOrReadFilterBlock(bool, rocksdb::GetContext*, rocksdb::BlockCacheLookupContext*, rocksdb::CachableEntry<rocksdb::ParsedFullFilterBlock>*) const
rocksdb::FullFilterBlockReader::MayMatch(rocksdb::Slice const&, bool, rocksdb::GetContext*, rocksdb::BlockCacheLookupContext*) const
rocksdb::FullFilterBlockReader::RangeMayExist(rocksdb::Slice const*, rocksdb::Slice const&, rocksdb::SliceTransform const*, rocksdb::Comparator const*, rocksdb::Slice const*, bool*, bool, rocksdb::BlockCacheLookupContext*)
rocksdb::BlockBasedTable::PrefixMayMatch(rocksdb::Slice const&, rocksdb::ReadOptions const&, rocksdb::SliceTransform const*, bool, rocksdb::BlockCacheLookupContext*) const
rocksdb::BlockBasedTableIterator<rocksdb::DataBlockIter, rocksdb::Slice>::SeekImpl(rocksdb::Slice const*)
rocksdb::ForwardIterator::SeekInternal(rocksdb::Slice const&, bool)
rocksdb::DBIter::Seek(rocksdb::Slice const&)
```

`BlockBasedTableIterator::CheckPrefixMayMatch` was missing a check for `kBlockCacheTier`. This PR adds it.

Test plan: deployed it to a logdevice test cluster and looked at logdevice's IO tracing.",6934395
726,2020-03-18T22:17:25Z,2020-03-18T22:28:15Z,,,"Detect if libatomic should be linked in or compiler and platform can
provide the needed atomic instrinsics, this helps build on certain
platforms like mips or clang/i386

Fixes

| /mnt/b/yoe/build/tmp/work/mips32r2-yoe-linux/rocksdb/6.6.4-r0/recipe-sysroot-native/usr/bin/mips-yoe-linux/mips-yoe-linux-ld: librocksdb.so.6.6.4: undefined reference to `__atomic_exchange_8'
| /mnt/b/yoe/build/tmp/work/mips32r2-yoe-linux/rocksdb/6.6.4-r0/recipe-sysroot-native/usr/bin/mips-yoe-linux/mips-yoe-linux-ld: librocksdb.so.6.6.4: undefined reference to `__atomic_fetch_or_8'
| /mnt/b/yoe/build/tmp/work/mips32r2-yoe-linux/rocksdb/6.6.4-r0/recipe-sysroot-native/usr/bin/mips-yoe-linux/mips-yoe-linux-ld: librocksdb.so.6.6.4: undefined reference to `__atomic_compare_exchange_8'
| /mnt/b/yoe/build/tmp/work/mips32r2-yoe-linux/rocksdb/6.6.4-r0/recipe-sysroot-native/usr/bin/mips-yoe-linux/mips-yoe-linux-ld: librocksdb.so.6.6.4: undefined reference to `__atomic_fetch_sub_8'
| /mnt/b/yoe/build/tmp/work/mips32r2-yoe-linux/rocksdb/6.6.4-r0/recipe-sysroot-native/usr/bin/mips-yoe-linux/mips-yoe-linux-ld: librocksdb.so.6.6.4: undefined reference to `__atomic_load_8'
| /mnt/b/yoe/build/tmp/work/mips32r2-yoe-linux/rocksdb/6.6.4-r0/recipe-sysroot-native/usr/bin/mips-yoe-linux/mips-yoe-linux-ld: librocksdb.so.6.6.4: undefined reference to `__atomic_store_8'
| /mnt/b/yoe/build/tmp/work/mips32r2-yoe-linux/rocksdb/6.6.4-r0/recipe-sysroot-native/usr/bin/mips-yoe-linux/mips-yoe-linux-ld: librocksdb.so.6.6.4: undefined reference to `__atomic_fetch_add_8'

Signed-off-by: Khem Raj <raj.khem@gmail.com>",6934395
727,2020-03-18T14:52:22Z,2020-03-19T21:20:47Z,,,"This PR separates the OptionTypeInfo maps into two -- one containing the mutable options and one for the immutable ones.  This separation will make it easier to manage the maps going forward -- there is no need to keep track of if an object is mutable or not.  Additionally, it means that the options map points to only one structure -- either the mutable or immutable one -- eliminating any confusion over which one to use.

The old methodology could lead to some confusion, especially when dealing with nested objects.  For example, the options of the cache had to all be marked as mutable so that they would be picked up by some other method.  This separation will eliminate any confusion.

The kMutable flag was not removed, as it might have utility in the future.

Some methods were added as ""bridge"" methods until the Configurable class is completed and merged.",6934395
728,2020-03-16T20:12:11Z,2020-03-16T20:12:59Z,,,"Summary:
As the first step of reintroducing eviction statistics for the block
cache, the patch switches from using simple function pointers as deleters
to function objects implementing an interface. This will enable using
deleters that have state, like a smart pointer to the statistics object
that is to be updated when an entry is removed from the cache. For now,
the patch adds a deleter template class `SimpleDeleter`, which simply
casts the `value` pointer to its original type and calls `delete` or
`delete[]` on it as appropriate. Note: to prevent object lifecycle
issues, deleters must outlive the cache entries referring to them;
`SimpleDeleter` ensures this by using the (""leaky"") Meyers singleton
pattern.

Test Plan:
`make asan_check`",6934395
729,2020-03-16T16:36:34Z,2020-03-26T19:28:17Z,,,"(Based on Yanqin's idea) Add a new field in readoptions as lower timestamp bound for iterator. When the parameter is not supplied (nullptr), the iterator returns the latest visible version of a record. When it is supplied, the existing timestamp field is the upper bound. Together the two serves as a bounded time window. The iterator returns all versions of a record falling in the window.
",6934395
730,2020-03-16T07:18:07Z,2020-03-18T00:24:04Z,,,"Adding a simple timer support to schedule work at a fixed time.

Test Plan:
TODO: clean up the unit tests, and make them better. ",6934395
731,2020-03-13T23:06:17Z,2020-03-26T19:26:46Z,,,"This PR implements a fault injection mechanism for injecting errors in reads in db_stress. The FaultInjectionTestFS is used for this purpose. A thread local structure is used to track the errors, so that each db_stress thread can independently enable/disable error injection and verify observed errors against expected errors. This is initially enabled only for Get and MultiGet, but can be extended to iterator as well once its proven stable.

Test plan:
crash_test
make check",6934395
732,2020-03-09T07:52:50Z,2020-03-09T19:32:12Z,,,Add WAL write duration metric  for WriteToWAL and  ConcurrentWriteToWAL ,6934395
733,2020-03-07T00:43:25Z,2020-03-07T00:43:35Z,,,,6934395
734,2020-03-06T17:54:31Z,2020-03-09T22:53:16Z,,,"For Issue #6471 

Add function `GetStringFromCompactionReason(...)` to get a string value from compaction reason, similar to compression type in `convenience.h`. 

PS: In `options_helper.h`, `compression_type_string_map` was declared outside an `#ifndef ROCKSDB_LITE` block in one place, but was defined inside an `#ifndef ROCKSDB_LITE` block in another place, so I assumed that it was supposed to be defined outside, and moved it out.",6934395
735,2020-03-06T17:29:21Z,2020-03-10T23:26:05Z,,,"Hi, I understand MultiGet now uses `io_uring` APIs from linux kernel, which can bring significant speed up to queries. I have created this PR to make C multiget API more uniform. Following things are added:

* Expose variants of `MultiGet` methods from `Transaction` to C API.
* Expose function to return base db of `transactiondb`, which is currently only present for `optimistictransactiondb`.
* Added unit tests.
* Refactor `c_test` utilities.
* discovered a bug where `rocksdb_transactiondb_open_columnfamilies` function is not exported via `extern` keyword",6934395
736,2020-03-06T00:32:14Z,2020-03-25T19:59:31Z,,,"In the current code base, we use Status to get and store the returned status from the call. Specifically, for IO related functions, the current Status cannot reflect the IO Error details such as error scope, error retryable attribute, and others. With the implementation of #5761, we have the new Wrapper for IO, which returns IOStatus instead of Status. However, the IOStatus is purged at the lower level of write path and transferred to Status.

The first job of this PR is to pass the IOStatus to the write path (flush, WAL write, and Compaction). The second job is to identify the Retryable IO Error as HardError, and set the bg_error_ as HardError. In this case, the DB Instance becomes read only. User is informed of the Status and need to take actions to deal with it (e.g., call db->Resume()).

Test plan: Added the testing case to error_handler_fs_test. Pass make asan_check",6934395
737,2020-03-04T06:37:25Z,2020-03-04T06:38:03Z,,,"Replace `-o /dev/null` by `-o test.o` when testing for C++ features such as
-faligned-new otherwise tests will fail with some bugged binutils
(https://sourceware.org/bugzilla/show_bug.cgi?id=19526):

```
output/host/bin/xtensa-buildroot-linux-uclibc-g++ -faligned-new -x c++ - -o /dev/null <<EOF
            struct alignas(1024) t {int a;};
            int main() {}
EOF
/home/fabrice/buildroot/output/host/lib/gcc/xtensa-buildroot-linux-uclibc/8.3.0/../../../../xtensa-buildroot-linux-uclibc/bin/ld: final link failed: file truncated

```
Signed-off-by: Fabrice Fontaine <fontaine.fabrice@gmail.com>",6934395
738,2020-03-03T06:32:24Z,2020-03-03T06:32:33Z,,,"Summary:
Some tests are failing when EncryptedEnv is enabled in test. Fixing some by make them use `env_` instead of `Env::Default()`. Disable others that don't have apparent fix. Also add CI to run some of the tests with `ENCRYPTED_ENV=1` env variable set.

Test Plan:
run `ENCRYPTED_ENV=1 make check`",6934395
739,2020-02-28T11:01:49Z,2020-02-28T11:01:58Z,,,"This allows distributions like Debian to inject build hardening flags like `-D_FORTIFY_SOURCE=2`

Thanks!",6934395
740,2020-02-22T05:13:48Z,2020-02-25T20:15:55Z,,,"Primary goal of this PR is to support `kBlobIndex` type in merge operator. We add value type to merge operation input and output for that purpose, so that user can take value with different types and mutate value type through merge. 
Currently `kDeletion` is not supported as output type.",6934395
741,2020-02-21T20:53:14Z,2020-02-25T00:21:38Z,,,"Summary:
Right now, not filling cache is not covered in db_stress. Randomly set read_options.fill_cache to cover scenario. To increase coverage to the cache behavior, sometimes repeat Get() or MultiGet() for the same keys.

Test Plan: Run ""make crash_test_with_atomic_flush"" and ""make crash_test"" for a while.",6934395
742,2020-02-18T18:56:12Z,2020-03-04T17:48:11Z,,,"Summary: Adds a new option BlockBasedTableOptions::filter_block_space_costing

TODO: finish summary and update test plan

TODO/WIP: unit tests for new options

Test Plan:

    $ # Baseline (with internal fragmentation, 6k-14k keys per filter)
    $ /usr/bin/time -v ./filter_bench -impl=2 -quick -m_keys_total_max=100 2>&1 | egrep 'FP rate|Bits/key|Maximum res'
    Bits/key actual: 10.0297
    Predicted FP rate %: 0.943184
    Average FP rate %: 0.957801
    Maximum resident set size (kbytes): 147648
    $ # Reclaim internal fragmentation for higher accuracy (same memory usage)
    $ /usr/bin/time -v ./filter_bench -impl=2 -quick -m_keys_total_max=100 -optimize_for_memory_allocation 2>&1 | egrep 'FP rate|Bits/key|Maximum res'
    Bits/key actual: 11.0191
    Predicted FP rate %: 0.638648
    Average FP rate %: 0.658422
    Maximum resident set size (kbytes): 147680
    $ # Target baseline accuracy on average, minimize actual memory usage
    $ /usr/bin/time -v ./filter_bench -impl=2 -quick -m_keys_total_max=100 -optimize_for_memory_allocation -tune_in_aggregate 2>&1 | egrep 'FP rate|Bits/key|Maximum res'
    Bits/key actual: 10.0646
    Predicted FP rate %: 0.953123
    Average FP rate %: 0.959306
    Maximum resident set size (kbytes): 136168
    $ # Not too different from baseline
    $ /usr/bin/time -v ./filter_bench -impl=2 -quick -m_keys_total_max=100 -tune_in_aggregate 2>&1 | egrep 'FP rate|Bits/key|Maximum res'
    Bits/key actual: 10.0043
    Predicted FP rate %: 0.953181
    Average FP rate %: 0.967174
    Maximum resident set size (kbytes): 147308

Also, the new CPU cost of estimating FP rates etc. at build time appears to be negligible, even for building filters with only ~1k keys:

    $ ./filter_bench -impl=2 -quick -m_keys_total_max=100 -average_keys_per_filter=1000 2>&1 | grep 'Build avg'
    Build avg ns/key: 32.2438
    $ ./filter_bench -impl=2 -quick -m_keys_total_max=100 -average_keys_per_filter=1000 -optimize_for_memory_allocation -tune_in_aggregate 2>&1 | grep 'Build avg'
    Build avg ns/key: 34.2075
",6934395
743,2020-02-16T04:13:07Z,2020-03-19T17:59:25Z,,,Added code for generically handing structs to OptionTypeInfo.  A struct is a collection of variables handled by their own map of OptionTypeInfos.  Examples of structs include Compaction and Cache options.,6934395
744,2020-02-16T03:27:26Z,2020-03-19T20:04:22Z,,,"The OptionTypeInfo::Vector method allows a vector<T> to be converted to/from strings via the options.  

The kVectorInt and kVectorCompressionType vectors were replaced with this methodology.

As part of this change, the NextToken method was added to the OptionTypeInfo.  This method was refactored from code within the StringToMap function.

Future types that could use this functionality include the EventListener vectors.
",6934395
745,2020-02-16T03:08:14Z,2020-03-19T16:45:26Z,,,"Add methods and constructors for handling enums to the OptionTypeInfo.  This change allows enums to be converted/compared without adding a special ""type"" to the OptionType.  

This change addresses a couple of issues:
- It allows new enumerated types to be added to the options without editing the OptionType base class (and related methods)
- It standardizes the procedure for adding enumerated types to the options, reducing potential mistakes
- It moves the enum maps to the location where they are used, allowing them to be static file members rather than global values
- It reduces the number of types and cases that need to be handled in the various OptionType methods",6934395
746,2020-02-16T03:01:46Z,2020-03-19T16:25:05Z,,,"Added functions for parsing, serializing, and comparing elements to OptionTypeInfo.  These functions allow all of the special cases that could not be handled directly in the map of OptionTypeInfo to be moved into the map.  Using these functions, every type can be handled via the map rather than special cased.

By adding these functions, the code for handling options can become more standardized (fewer special cases) and (eventually) handled completely by common classes.",6934395
747,2020-02-14T14:24:49Z,2020-03-05T19:11:13Z,,,"RocksDB exposes `sst_file_manager` as a public option: https://github.com/facebook/rocksdb/blob/29e24434fec91cbeae1deb6cd96319af1b308716/include/rocksdb/options.h#L424.
However, internal implementation uses `static_cast` to cast to `SstFileManagerImpl`, which means if user passes in Custom SST File Manager, it will crash since this is `static_cast`.

Use `dynamic_cast` in this case to have a runtime check to prevent such scenario.",6934395
748,2020-02-12T20:55:00Z,2020-03-11T05:08:22Z,,,"It's a potential t/o txn-mgr, the implementation of proposal  https://github.com/facebook/rocksdb/issues/6281, which highly depends on the fundamental apis currently under development by @riversand963.
Some api names are not compatible with rocksdb's current master branch, and will be fixed in the future commits.
the proposal is added into the public user-timestamp related google doc, which can be found here:https://docs.google.com/document/d/1FcDjOM8-pJzCajCa9waQkox6DKJIWZAHm36buK4wfqs/edit#
",6934395
749,2020-02-08T05:05:24Z,2020-03-24T13:04:41Z,,,The methods in convenience.h are used to compare/convert objects to/from strings.  There is a mishmash of parameters in use here with more needed in the future.  This PR replaces those parameters with a single structure.  ,6934395
750,2020-02-03T20:34:59Z,2020-02-28T23:11:10Z,,,"Previously, the flushes triggered by `WriteBufferManager` could affect
the same CF repeatedly if it happens to get consecutive writes. Such
flushes are not particularly useful for reducing memory usage since
they switch nearly-empty memtables to immutable while they've just begun
filling their first arena block. In fact they may not even reduce the 
mutable memory count if they involve replacing one mutable memtable with
one arena block with a new mutable memtable with one arena block.
Further, if such switches happen even a few times before a flush finishes,
the immutable memtable limit will be reached and writes will stall.
    
This PR adds a heuristic to not switch memtables to immutable for CFs 
that already have one or more immutable memtables awaiting flush. There
is a memory usage regression if the user continues writing to the same
CF, that DB does not have any CFs eligible for switching, and flushes
are not finishing. Before it would grow by switching nearly empty
memtables until writes stall. Now it would grow by filling memtables
until writes stall.
    
Test Plan:
    
- Command:
    
`rm -rf /dev/shm/dbbench/ && TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=fillrandom -num_multi_db=8 -num_column_families=2 -write_buffer_size=4194304 -db_write_buffer_size=16777216 -compression_type=none -statistics=true -target_file_size_base=4194304 -max_bytes_for_level_base=16777216`
    
- `rocksdb.db.write.stall` count before this PR: 175 
- `rocksdb.db.write.stall` count after this PR: 0
",6934395
751,2020-01-14T01:47:36Z,2020-01-14T01:47:50Z,,,Added missing ROCKSDB_LIBRARY_API decorator to rocksdb_transaction_get_for_update.,6934395
752,2020-01-12T14:02:07Z,2020-02-21T00:57:35Z,,,"I noticed some `rocksdb_transactiondb_*` are missing from `c.cc`. This patch adds:

- `rocksdb_transactiondb_drop_column_family`
- `rocksdb_transactiondb_property_value`
- `rocksdb_transactiondb_property_int`
- `rocksdb_transactiondb_property_int_cf`
- `rocksdb_transactiondb_property_value_cf`
- `rocksdb_transactiondb_approximate_sizes`
- `rocksdb_transactiondb_approximate_sizes_cf`",6934395
753,2020-01-06T09:41:30Z,2020-03-26T18:15:39Z,,,"This PR adds support for pipelined & parallel compression optimization for `BlockBasedTableBuilder`. This optimization makes block building, block compression and block appending a pipeline, and uses multiple threads to accelerate block compression. Users can set `CompressionOptions::parallel_threads` greater than 1 to enable compression parallelism.",6934395
754,2020-01-02T19:16:21Z,2020-01-13T23:41:35Z,,,"Preliminary user-timestamp support for delete.

If [""a"", ts=100] exists, you can delete it by calling `DB::Delete(write_options, key)` in which `write_options.timestamp` points to a `ts` higher than 100.

Test plan (dev server)
```
make check
```",6934395
755,2019-12-20T18:32:35Z,2020-02-04T16:15:25Z,,,"Summary: Test EnvPosixTestWithParam::DecreaseNumBgThreads sometimes fail. One theory is that the sleep is not long enough. In this commit, we make the sleep limit longer but check periodically to exit earlier.

Test Plan: Run the test and see it fail. Watch CI",6934395
756,2019-12-19T18:25:40Z,2019-12-19T20:04:57Z,,,,6934395
757,2019-12-19T01:05:22Z,2020-01-29T15:55:39Z,,,"New memory technologies are being developed by various hardware vendors (Intel DCPMM is one such technology currently available). These new memory types require different libraries for allocation and management (such as PMDK and memkind). The high capacities available make it possible to provision large caches (up to several TBs in size), beyond what is achievable with DRAM.
The new allocator provided in this PR uses the memkind library to allocate memory on different media.


**Performance**

We tested the new allocator using db_bench.
- For each test, we vary the size of the block cache (relative to the size of the uncompressed data in the database).
- The database is filled sequentially. Throughput is then measured with a readrandom benchmark. 
- We use a uniform distribution as a worst-case scenario.

The plot shows throughput (ops/s) relative to a configuration with no block cache and default allocator.
For all tests, p99 latency is below 500 us.

![image](https://user-images.githubusercontent.com/26400080/71108594-42479100-2178-11ea-8231-8a775bbc92db.png)


**Changes**

- Add MemkindKmemAllocator
- Add --use_cache_memkind_kmem_allocator db_bench option (to create an LRU block cache with the new allocator)
- Add detection of memkind library with KMEM DAX support
- Add test for MemkindKmemAllocator


**Minimum Requirements**

- kernel 5.3.12
- ndctl v67 - https://github.com/pmem/ndctl 
- memkind v1.10.0 - https://github.com/memkind/memkind


**Memory Configuration**

The allocator uses the MEMKIND_DAX_KMEM memory kind. Follow the instructions on[ memkind’s GitHub page](https://github.com/memkind/memkind) to set up NVDIMM memory accordingly.

Note on memory allocation with NVDIMM memory exposed as system memory.
- The MemkindKmemAllocator will only allocate from NVDIMM memory (using memkind_malloc with MEMKIND_DAX_KMEM kind).
- The default allocator is not restricted to RAM by default. Based on NUMA node latency, the kernel should allocate from local RAM preferentially, but it’s a kernel decision. numactl --preferred/--membind can be used to allocate preferentially/exclusively from the local RAM node.


**Usage**

When creating an LRU cache, pass a MemkindKmemAllocator object as argument.
For example (replace capacity with the desired value in bytes):

```
#include ""rocksdb/cache.h""
#include ""memory/memkind_kmem_allocator.h""

NewLRUCache(
    capacity /*size_t*/, 
    6 /*cache_numshardbits*/,
    false /*strict_capacity_limit*/, 
    false /*cache_high_pri_pool_ratio*/,
    std::make_shared<MemkindKmemAllocator>());
```

Refer to [RocksDB’s block cache documentation](https://github.com/facebook/rocksdb/wiki/Block-Cache) to assign the LRU cache as block cache for a database.",6934395
758,2019-12-17T07:34:49Z,2019-12-18T04:11:29Z,,,"add a percentile999 field in HistogramData of rocksdb statistics. and add interface in c.h and c.cc. then `make format`.

Signed-off-by: fredchenbj <cfworking@163.com>",6934395
759,2019-12-17T05:17:28Z,2020-03-24T23:02:59Z,,,"This is a predecessor to the Configurable PR.  This change moves the OptionTypeInfo maps closer to where they will be used.

When the Configurable changes are adopted, these values will become static and not associated with the OptionsHelper.",6934395
760,2019-12-16T16:20:42Z,2019-12-16T21:52:20Z,,,"This change allows the LoadEnv to work properly without leaking Env structures.  As previously implemented, a LoadEnv called for loading from the DBOptions might leak an Env structure if the Env was not a static object.",6934395
761,2019-12-15T14:55:56Z,2019-12-15T15:21:27Z,,,"- Do not compile static library for Android since JNI works there with a shared library.
- Rename Shared Library from rocksdbjni-shared to rocksdbjni only for Android so it gets picked up by loadLibrary code.
- Replace LIBS to more specific THIRDPARTY_LIBS and SYSTEM_LIBS dependency for shared library so the RocksDB static library does not need to be compiled. This much reduces the compile work and thus time.
- Disable JAVA_AWT_LIBRARY, JAVA_JVM_LIBRARY, JAVA_INCLUDE_PATH2 and JAVA_AWT_INCLUDE_PATH which do not exist in Android CMake Java module

See https://github.com/marykdb/rocksdb-android which is already based on this CMake adaptions.",6934395
762,2019-12-15T07:40:46Z,2019-12-16T19:09:22Z,,,Replaced links pointing to old wiki pages with respective new pages.,6934395
763,2019-12-13T15:20:08Z,2020-03-25T14:39:42Z,,,Highly experimental ;-),6934395
764,2019-12-11T04:14:23Z,2019-12-12T01:19:54Z,,,,6934395
765,2019-12-10T02:29:02Z,2020-01-20T16:16:50Z,,,"Hi all,

According to our daily usage, when CPU-intensive compression algorithm like
ZSTD is adopted, current single-threaded compression logic becomes the
bottleneck of overall write throughput in memory-to-L0 flushing and L0-to-L1
compaction. Although sub-compaction has introduced some parallelism in L0-to-L1
compaction, it's effect is limited.

We propose pipelined & parallel compression optimization and pipelined load &
sort optimization for BlockBasedTable to enhance the parallelism in the two
cases above.

- Pipelined & parallel compression optimization

  This optimization contains two parts. The first is to decouples in-memory
  block building, block compression and block appending in by making them a
  pipeline. The second is to use multiple threads to accelerate compression.
  Compression jobs are in terms of blocks, i.e. one block is independent from
  other blocks, so we just assign block-wise compression jobs to a compression
  thread pool.

- Pipelined load & sort optimization:

  This optimization decouples block loading and multi-way merging in compaction
  process by making them a pipeline. This optimization has significant effect
  only when the former optimization is enabled.

We evaluated our optimization using db_bench modified to use customized data
pattern. Two metrics are mainly considered in our evaluation:
- Throughput
  Maximum write throughput without write stall/stop given limited CPU cores.
  If the flushing and compaction are faster, application should be able to write
  faster without having to stall/stop.
- Disk usage
  Disk usage under non-stall/stop write throughput.
  If the compaction is faster, data will be pumped into cooler layers faster,
  causing less temporary file and less repeat keys, thus saving disk usage.

Our evaluation settings are:

- Hardware
  - CPU: Intel E5-2698 v3 x 2, 16x2=32 physical cores
  - RAM: 256GB
  - Disk: Intel Optane 900P 280GB (Maximum read/write I/O during evaluation
    were around 1GB/s)
- Software
  - Linux Kernel: 4.13.0-36
  - RocksDB: master
  - Filesystem: ext4
- Data pattern
  - Dataset A, about 0.2 compression ratio, value size 150KB
  - Dataset B, about 0.3 compression ratio, value size 30KB

For each round, we first use fillrandom to fully fill the database, and then
perform overwrite over it for 1 hour. We used 8 threads for compression in
each SST building phase.

The evaluation results are:

- Throughput
  For dataset A, the original RocksDB reached about 80MB/s maximum write
  throughput when physical cores \>= 4, and the optimized RocksDB reached about
  260MB/s when physical cores = 16. There is no gap between two versions of
  RocksDB when physical cores \<= 4.
  For dataset B, the original reached about 75MB/s maximum when physical cores
  \>= 6, and the optimized reached about 210MB/s when physical cores = 15. Also
  there is no gap between them when physical cores \<= 6.
- Disk Usage
  For dataset A, the optimized RocksDB can save around 40% disk usage at 80MB/s
  throughput.
  For dataset B, the optimized RocksDB can save around 23% disk usage at 75MB/s
  throughput.

We also did the similar evaluation with default db_bench, the results are
similar.

We changed the default options to check whether all unit tests can pass. All
unit tests succeeded, except for the ones that need sync BlockBasedTableBuilder
information, like current file size or current status. This is because that
the optimizations has an async behavior, such information is not updated until
things got done in the write thread. We're planning to write separate unit
tests for such cases, but please give us comments if you guys think there is
a better way.

Thanks!

Regards,
Ziyue Yang

",6934395
766,2019-12-03T18:27:34Z,2020-03-20T10:36:04Z,,,"a race can occur when an archived logfile is first found by
env->GetChildren, but then later removed by a concurrent thread
while iterating over the list of found files. in this case,
iteration was aborted with an IOError, but it seems it is expected
to happen in case of bad luck. this change makes the iteration
just ignore this particular type of error and go on without
bothering about that particular archived logfile.",6934395
767,2019-11-30T15:43:57Z,2020-03-13T18:56:36Z,,,"This changeset contains a few fix about forward declaration of classes. There a lot of fixes needed for utilities class but I'd prefer to fix them not at once.

Please review these changes. ",6934395
768,2019-11-28T12:14:50Z,2019-12-18T04:11:52Z,,,"For outer plugins, they may want to store its statistics into Rocksdb's statistics to leverage the cache-friendly optimization. So making `StatisticsImpl` as a template to let outer users reserve a larger place in `StatisticsData`.

The changes are:
- make `StatisticsImpl` as a template
- remove internal stats due to https://github.com/facebook/rocksdb/pull/4714
",6934395
769,2019-11-22T21:49:47Z,2020-03-03T03:45:16Z,,,"Currently, the following interleaving of events can lead to SuperVersion containing both immutable memtables as well as the resulting L0. This can cause Get to return incorrect result if there are merge operands. This may also affect other operations such as single deletes.

```
  time  main_thr  bg_flush_thr  bg_compact_thr  compact_thr  set_opts_thr
0  |                                                         WriteManifest:0
1  |                                           issue compact
2  |                                 wait
3  |   Merge(counter)
4  |   issue flush 
5  |                   wait
6  |                                                         WriteManifest:1
7  |                                 wake up
8  |                                 write manifest
9  |                  wake up
10 |  Get(counter)
11 |                  remove imm
   V
```

Test plan (devserver)
```
$make merge_test
$./merge_test --gtest_filter=MergeTest.MergeWithCompactionAndFlush
$make check
```",6934395
770,2019-11-13T12:43:56Z,2019-11-19T22:06:20Z,,,,6934395
771,2019-11-13T06:31:10Z,2019-11-20T18:30:29Z,,,"Merge should always pass nullptr as `existing_value` instead of empty string when the key is not present (https://github.com/facebook/rocksdb/blob/master/include/rocksdb/merge_operator.h#L57). 
Fix related inconsistency.

Signed-off-by: tabokie <xy.tao@outlook.com>",6934395
772,2019-11-08T13:52:52Z,2020-01-31T19:32:51Z,,,"**Check-in is not yet complete**

## Summary

Propose adding Prefix oriented compaction to RocksDB's core feature set. The new code would either use the existing PrefixTransform or another construct of same type. Memory buffer flushes would segregate keys into multiple level zero .sst files by prefix. This technique has shown to decrease total ingest time and reduce write amplification in the example case from 5.82 to 3.74.

## Example case

ArangoDB has several column families that currently use the Prefix Seek API because it naturally fits our key designs and search needs. An example key in one column family looks like this:

<pre>
struct {
    int64_t collection_id; // big endian binary format
    int64_t document_id; // big endian binary format
};
</pre>
An ArangoDB collection is the equivalent of an SQL table. Similarly a document could be lightly compared to an SQL row. Each write to our ""document"" column family RocksDB uses the above key along its data (a JSON document).

Both our internal code and user code may write to several different collection_id keys. The example case is where our internal code writes to its statistics collection every ten seconds while the user's code is busy importing 303 million documents (records) into another collection. The user's collection has a collection_id that is greater than the statistics collection_id. Assume the document_id portion of the key is being incremented with each write.

The current RocksDB implementation, as well as the original Google leveldb implementation, writes all keys from a memory buffer into a single level 0 .sst file. The example case therefore will often have both a new statistics key and many user keys within one level 0 .sst file. The current compaction logic for level 0 will gather all available level 0 .sst files, find the containing range of all those files, then compact against all level 1 .sst files that overlap the same range. The one statistics key compares to being below every user key. And the level 0 user's keys compare above all or almost all user key in level 1 since the document_id of the user's key is incrementing. The result is that often all .sst files in level 1 become part of the compaction with level 0. What was really needed was for the statistics key to compact with the sole level 1 .sst file containing the statistics keys (or simply move to level 1 by trivial move). And the user's keys in the level 0 .sst files only needed to merge with the level 1 .sst file containing the highest keys (or simply moved to level 1 by trivial move).

Note: our import code has a multithreaded source so user keys do often overlap several document_id keys toward the end of the already imported key space. This is why there are some necessary compactions with the last level 1 .sst file in the example case. A single threaded import might achieve zero compactions between level 0 and level 1 for the user's documents when using prefix compactions.

## Example case execution

### Existing RocksDB code

The example case was executed on a 32 core server with 64G ram and a physical Raid 10 with 4 SATA drives. The existing RocksDB code had many compactions like:

Compacting 18@0 + 70@1

Compacting 12@0 + 37@1

Compacting 21@0 + 22@1

Compacting 12@0 + 10@1

Compacting 14@0 + 51@1

9 x ""trivial_move"" (destination level: 1)

465 x ""trivial_move"" (across all compaction levels)

The import utility measured 7 stalls of 10 seconds or more. The worst stall was 132.8 seconds. The entire import ran for 78 minutes 15 seconds. Write amplification was 5.82.

### Proof of concept code

The proof of concept code executed the same import in 62 minutes 30 seconds. Write amplification was 3.74. The worst stall 5.25 seconds. The single worst compaction was:

Compacting 4@0 + 1@1 files
The remaining were:

38 x Compacting 3@0 + ?@1 files

649 x Compacting 2@0 + ?@1 files

3,982 x Compacting 1@0 + ?@1 files

1,440 x ""trivial_move"" (destination level: 1)

2,810 x ""trivial_move"" (across all compaction levels)

File change discussion
",6934395
773,2019-11-02T00:55:40Z,2019-11-05T23:45:43Z,,,"In the current trace/replay, we only collect the query type, key, the time. In order to collect the analyze the response latency of each query in detail, a new set of trace types are added. It stores the latency as a new record. The original record traced at the beginning and the new record traced at the end share the same record_guid. The analyzing process is able to match the query to its latency. In order to be compatible to the old trace format (v0.1), the trace header is parsed. For the trace file with trace_at_end option enabled during tracing, its format is v0.2.

Test plan: added the unit test to db_test2. tested with real workload traces of v0.1 and v0.2. pass make asan_check ",6934395
774,2019-11-01T17:57:39Z,2019-11-07T20:07:49Z,,,,6934395
775,2019-10-22T23:59:20Z,2019-10-23T00:07:17Z,,,"Summary:
Right now, in compaction readahead, readahead size includes size to return, so that readahead_size = 2MB will generate exact 2MB I/O, while in non-compaction workloads, it is bytes_to_read + 2MB. We consolidate to the former case to make the code easier to maintain.

Test Plan: make all check",6934395
776,2019-10-16T11:20:56Z,2019-10-16T12:08:45Z,,,"Summary:
The display of ""rocksdb.dbstats"":
** DB Stats **
Interval WAL: written: xx.xx MB

Correct unit of ""written"" from ""interval_wal_bytes / GB"" into MB",6934395
777,2019-10-15T00:56:57Z,2020-01-24T19:38:34Z,,,"Summary: Prefix extractor needs to be invoked for a key only when it is in domain. However, when prefix_same_as_start = true, this assumption is broken. The fix is to add InDomain() check before any Transform() call when prefix_same_as_start = true.

Test Plan: Add a unit test to cover prefix_same_as_start = true with seek keys and keys on DB not in domain.",6934395
778,2019-10-12T02:13:43Z,2019-10-17T03:55:54Z,,,…expressive and informative,6934395
779,2019-10-11T21:31:36Z,2019-10-14T16:42:35Z,,,"Summary:
When we call SwitchMemtable in the write thread, we do not need to call
cfd->Ref() before SwitchMemtable because DropColumnFamily() will be blocked
outside the write thread even if db mutex is released.

Test Plan:
```
COMPILE_WITH_ASAN=1 make all && make check
```",6934395
780,2019-10-09T23:14:42Z,2019-10-09T23:15:27Z,,,"* add a merge operator for parition meta data (currently partition
  deletion info only)
* read partition deletion in cassandra compaction filter and drop rows
  if it's partition has been deleted",6934395
781,2019-10-08T23:06:34Z,2020-03-20T10:35:01Z,,,"The individual commits in this PR should be self-explanatory.
All small and _very_ low-priority changes.
",6934395
782,2019-10-07T18:40:51Z,2019-10-15T10:21:14Z,,,Just bumping version to latest for rocksdb and zstd ,6934395
783,2019-10-04T00:10:43Z,2019-10-09T17:22:09Z,,,"Add TableOption IndexShorteningMode and kBinarySearchWithFirstKey.

Test Plan: make jtest and tested with Rocksandra",6934395
784,2019-09-27T15:25:08Z,2019-10-01T18:39:54Z,,,"ensures ""util/build_version.cc"" when generated.",6934395
785,2019-09-26T16:57:08Z,2020-01-17T14:50:14Z,,,"This is proposed fix for #4946 as stated in comment

> this fix probably has invalid formatting and might have few issues, but it seems to be compiling,
> (I haven't checked ROCKSDB_LITE ifdef branch though).
> The fix consists of fairly simple changes:
> 1. promotes InternalCFStatsType and InternalDBStatsType to top rocksdb namespace
> 2. turns both enums into enum classes
> 3. fixes usage
> (this is on top of 6.2.fb branch, but it should be fairly trivial to rebase if needed)",6934395
786,2019-09-23T11:06:29Z,2020-01-31T19:22:56Z,,,,6934395
787,2019-09-22T19:54:48Z,2019-11-18T22:05:42Z,,,"Use a dynamically allocated array for reuse_table, since msvc does not
support stack-allocated arrays whose size is unknown at compile time.
Add a couple of explicit casts to avoid numeric conversion warnings.

N.B. I have not been able to test this change properly since I can't get the tests to run successfully using ""make check"" on Linux. Please let me know if there is a better way to do this.",6934395
788,2019-09-18T21:41:00Z,2019-11-08T18:51:44Z,,,"Summary:
Source code path in info log is not truncated to the correct length. Fixing it. 

Test Plan:
Build and run db_bench. Before:
```
2019/09/18-21:32:34.631181 7fdd42df6700 [_impl/db_impl_write.cc:1654] [default] New memtable created with log file: #9. Immutable memtables: 0.
```
After:
```
2019/09/18-21:36:09.226532 7f141b5f6700 [/db_impl/db_impl_write.cc:1654] [default] New memtable created with log file: #9. Immutable memtables: 0.
```",6934395
789,2019-09-18T19:50:29Z,2019-09-26T14:59:35Z,,,"Ingesting a file from a file system that doesn't
support hard links or from a network location, returns
an error that wasn't handled correctly and the result was
IO error instead of Not Supported status.

Fixes cockroachdb/cockroach#38789",6934395
790,2019-09-18T06:02:22Z,2019-09-23T21:17:13Z,,,,6934395
791,2019-09-17T22:18:28Z,2019-10-01T21:10:45Z,,,"The following patches will make output of the `sst_dump` parseable:
- the first patch will print the whole string, by using `size()`, before the part after `\0` will be ignored
- the second patch introduces `--output_safe` option, under which `\n` will be replaced with `\0` byte to avoid extra line splitting (i.e. always one line for key/value at a time)",6934395
792,2019-09-16T02:34:21Z,2019-09-17T19:04:44Z,,,"Improve #5728, use unique_ptr in writebatch hint to make ownership more clear.",6934395
793,2019-09-13T18:55:03Z,2020-01-10T18:11:24Z,,,,6934395
794,2019-09-10T11:04:45Z,2019-09-12T18:40:43Z,,,this pr was discuss by https://github.com/facebook/rocksdb/pull/3930#issuecomment-529622604,6934395
795,2019-09-09T18:58:27Z,2019-09-12T20:59:33Z,,,,6934395
796,2019-09-04T23:30:16Z,2019-09-05T17:04:24Z,,,"Per offline discussion, default value of memtable_whole_key_filtering is now set to true 

Test plan: make check",6934395
797,2019-08-28T11:02:15Z,2020-03-26T15:17:36Z,,,"This PR merges the functionality of making the ColumnFamilyOptions, TableFactory, and DBOptions into Configurable into a single PR, resolving any merge conflicts",6934395
798,2019-07-26T09:08:06Z,2019-12-06T17:58:16Z,,,Few functions from options added to C-api,6934395
799,2019-07-21T07:45:14Z,2020-01-19T02:59:49Z,,,,6934395
800,2019-07-16T05:20:07Z,2019-09-10T00:42:07Z,,,"```
TEST_F(DBTest, RowCache2) {
  Options options = CurrentOptions();
  options.row_cache = NewLRUCache(8192);
  options.merge_operator.reset(new rocksdb::StringAppendTESTOperator(','));
  DestroyAndReopen(options);

  ASSERT_OK(Put(""foo"", ""foo""));
  ASSERT_OK(Flush());

  ASSERT_OK(db_->DeleteRange(WriteOptions(), db_->DefaultColumnFamily(),
            ""foo"", ""foo_""));
  ASSERT_OK(Merge(""foo"", ""bar""));
  ASSERT_OK(Flush());

  ASSERT_EQ(Get(""foo""), ""bar"");
  ASSERT_EQ(Get(""foo""), ""bar""); // FAIL
}
```",6934395
801,2019-07-03T12:16:26Z,2019-09-10T00:35:01Z,,,"Signed-off-by: Little-Wallace liuwei@pingcap.com

When the iterator read keys in reverse order, each Prev() function cost O(log n) times. So I add prev pointer for every node in skiplist to improve the Prev() function.
Here is bench result.
```
time ./db_bench --db=./data --write_buffer_size=128000000 --num=320000 --benchmarks=fillseq,seekrandom --seek_nexts=100 --reads=1000000 --reverse_iterator=true
```
**master**:
```
DB path: [./data]
fillseq      :      14.732 micros/op 67881 ops/sec;    7.5 MB/s
DB path: [./data]
seekrandom   :     730.041 micros/op 1369 ops/sec;   15.2 MB/s (1000000 of 1000000 found)


real    12m14.817s
user    12m10.258s
sys     0m2.636s
```
**prev-skiplist**:

```
DB path: [./data]
fillseq      :      14.507 micros/op 68930 ops/sec;    7.6 MB/s
DB path: [./data]
seekrandom   :      83.699 micros/op 11947 ops/sec;  132.1 MB/s (1000000 of 1000000 found)


real    1m28.374s
user    1m26.872s
sys     0m1.318s
```",6934395
802,2019-06-26T01:11:51Z,2019-09-10T00:46:42Z,,,"When the `RangeDelAggregator` contains a range tombstone that is
newer than all keys in a file being scanned by a
`BlockBasedTableIterator`, we can seek the table iterator to the
range tombstone endpoint. During forward iteration, this means seeking
the iterator to a key at or after the range tombstone end key (recall
range tombstones are end-key exclusive). During reverse iteration, this
means seeking the iterator to a key before the range tombstone start
key. This seeking optimization can be more efficient than iterating
over point keys and checking whether each one is covered, especially for
wider range tombstones.

The implementation consists of a few significant parts.

(1) A new data structure, `PartialRangeTombstoneEndpoint`. A
`BlockBasedTableIterator` caches one of these endpoints. It holds state
about the next range tombstone endpoint the iterator needs to know
about. For example, consider the iterator shown below, which is
positioned between two range tombstones, and moving in the forward
direction.

```
a---e
       h---l
     ^
     iterator at ""f""
```

Its `PartialRangeTombstoneEndpoint` will satisfy the below conditions.

- `endpoint() != nullptr && *endpoint() == ""h""`
- `is_valid() == true`
- `dir() == RangeDelPositioningMode::kForwardTraversal`
- `seq() == 0`: this indicates the keys between the current key and ""h"" are not covered

(2) `RangeDelAggregator::GetEndpoint()` function. This function returns
a `PartialRangeTombstoneEndpoint` like shown above. Note that this
function and `ShouldDelete()` share a common internal state for tracking
forward/backward movement. That means interleaved calls to
`ShouldDelete()` and `GetEndpoint()` with the same argument for
`RangeDelPositioningMode` need to be very careful to pass keys in a
consistent order (non-decreasing for
`RangeDelPositioningMode::kForwardTraversal`, or non-increasing for
`RangeDelPositioningMode::kBackwardTraversal`).

(3) `BlockBasedTableIterator` uses `GetEndpoint()` to obtain a range
tombstone endpoint. To satisfy the ordering requirement mentioned in
(2), when `Seek*()` is called, it simply provides the target key. In
`Next()` or `Prev()` calls, it provides the key the iterator is
positioned at before moving, as we know that key is at the top of the
merging iterator's heap, so there is no way for a future call to provide
an out-of-order key, unless the iterator's direction changes (that case
is handled by refreshing the range tombstone endpoint).

Most importantly, `BlockBasedTableIterator` uses its endpoint when
possible to skip over ranges of keys that are entirely covered by a
range tombstone. In `Seek*()`, that is done by adjusting the target key
when we know in advance it is covered by a range tombstone newer than
the file. In `Next()` and `Prev()`, that is done by performing a seek
when `GetTombstone()` tells us the current key is overlapped by a range
tombstone. In case of `Next()` the seek will be to the range tombstone's
end key, whereas in case of `Prev()` it would be to the range
tombstone's start key.

Test Plan:

- added unit tests
- ran modified `db_stress` (ajkr@49a0581) that verifies each operation in `TestIterate()`:

```
$ python ./tools/db_crashtest.py blackbox --simple \
	--write_buffer_size=524288 --target_file_size_base=524288 \
	--max_bytes_for_level_base=2097152 --compression_type=none \
	--max_background_compactions=8 --value_size_mult=33 --max_key=5000000 \
	--interval=10 --duration=7200 --delrangepercent=1 --delpercent=9 \
	--iterpercent=10 --writepercent=80 --readpercent=0 --prefixpercent=0 \
	--num_iterations=1000 --range_deletion_width=100
```",6934395
803,2019-06-18T21:00:59Z,2019-06-22T18:11:23Z,,,Update version and history for 6.3.0 branch cut.,6934395
804,2019-06-18T18:55:49Z,2019-06-21T20:27:51Z,,,"Summary:

Trigger a compaction if the number of reads to any SST file exceeds a
threshold. Currently the threshold is hardcoded, there's a TODO to
potentially calculate the threshold based on file size (TBD).

Test Plan:

- existing unit tests pass
- with triggering compaction on every read, some tests fails, have to
  look into those
- should add a new test",6934395
805,2019-06-13T22:21:21Z,2019-09-30T16:28:28Z,,,"DBOptions should be validated before CFOptions. This is the logical way in which the code should be laid out, as CFOptions are validated by comparing to DBOptions but not the other way around. Doing this change would also make the code similar to the structure in `SanitizeOptions`. 

It also helps slightly improving the validation speed when there are incompatible DBOptions and many column families (though I have not personally validated it). Reversing the checks for validating CFOptions and DBOptions makes it possible to fail fast when some DBOptions are not compatible, before even looking at every CF's Options.

Test Plan:
`make check`",6934395
806,2019-06-06T23:07:48Z,2019-09-06T00:21:12Z,,,"Summary:
In case application fall in crash loop, RocksDB generates a new info log file on each restart, and purge useful old logs even when `keep_log_file_num` is set. In these cases the new log files are usually small and useless for debugging. In such cases we can instead keep large enough info log files. Adding two new options `keep_large_log_file_num` and `large_info_log_size` for the purpose.

Test Plan:
Run db_bench and kill manually, and observe large info logs are kept.",6934395
807,2019-05-30T16:23:29Z,2019-06-19T01:06:20Z,,,"As #4990 describes, MANIFEST sync can fail but its newly appended entries may still exist when the process restarts and tries to recover. If the latest entry is flush or compaction, the db will try to access non-existing SST files because these files have been deleted after the previous MANIFEST sync failure. One possible fix is to truncate the MANIFEST to its last-synced size upon sync failure. However we are not going to take this approach because file truncation may not be supported on certain file systems. Instead, we disable deletion of obsolete files once RocksDB fails to write or sync MANIFEST.
This PR provides a unit test that simulates this scenario by manually overwriting the return status of a sync after the actual MANIFEST is persisted.
Test plan (on my dev machine)
```
$make clean && make -j32 db_basic_test
$./db_basic_test --gtest_filter=DBBasicTest.DisableFileDeletionAfterManifestWriteOrSyncFailure
```
All existing unit tests must pass too.
",6934395
808,2019-05-29T21:39:03Z,2019-05-31T00:59:10Z,,,"Summary:

Sample number of reads to MemTable and trigger a flush when number of
reads reaches a threshold. This is intended to improve read performance
for read-heavy workloads.

Test Plan:

- Ran db_test and db_test2 with kSampleRate=1 and kNumReadsUntilFlush=1.
  Worked apart from a few exceptions where assumptions about flushes are
  made.
- 'make check' fails a bunch of tests with above settings due to
  assumptions about flushes. Flushing based on reads will be off by
  default in the final version when there are proper options (there's a TODO).
- Should add a new unit test.",6934395
809,2019-05-23T09:28:34Z,2019-09-10T00:32:42Z,,,"**Summary：**
This pull request adds a merge operator for bytes append operation, append the bytes in the end of the value. If the value is empty, the merge operation just like put. 


**motivation:** 
if we want add some bytes in the end of the value which is a fixed length element ( e.x uint32)array, there's no need separator, because you know the size of the element. 
when we use the bytes append merge operator, it's same as adding an elements to the end of the value. When we want to get the elements, no need to convert the elements step by step, you can convert the pointer directly. 
More over, we may want to add the bytes just in the end of the value with no separator, it's also very efficient.

**usage :**

    **C++ code:**
        ColumnFamilyOptions options = ColumnFamilyOptions();

        options.merge_operator = MergeOperators::CreateBytesAppendOperator();

        std::vector <ColumnFamilyDescriptor> column_families = std::vector<ColumnFamilyDescriptor>();
        column_families.push_back(ColumnFamilyDescriptor(kDefaultColumnFamilyName, options));
        DBOptions dbOptions;
        dbOptions.IncreaseParallelism();
        dbOptions.create_if_missing = true;
        dbOptions.create_missing_column_families = true;
        rocksdb::DB *db;
        std::vector < ColumnFamilyHandle * > handles = std::vector<ColumnFamilyHandle * >();

        Status s = DB::Open(dbOptions, ""rocksdb_test"", column_families, &handles, &db);
        if (!s.ok()) {
            std::cout << s.ToString() << std::endl;
            exit(1);
        }
        std::string key = ""test_key"";
        uint64_t x = 318158018811;
        uint64_t y = 318158018812;
        (db)->Merge(WriteOptions(), Slice(key), Slice(static_cast<char *>(static_cast<void *>(&x)), sizeof(long)));
        rocksdb::PinnableSlice result;
        // value is a array of element long
        (db)->Get(ReadOptions(), handles[0], Slice(key), &result);
        long *array = (long *) result.data();
        std::vector<long> v(array, array + result.size() / sizeof(long));
        for (long i : v) {
            std::cout << i << std::endl;
        }
        delete db;
        return 0;

    **java code:**
        ....

        new ColumnFamilyOptions().setMergeOperatorName(""bytesappend"");
        or 
        new ColumnFamilyOptions().setMergeOperator(new BytesAppendOperator())

        ....

",6934395
810,2019-05-16T22:56:45Z,2019-05-16T22:59:45Z,,,"Summary: It's not uncommon for memtable reseek to end up with the same position. If it happens three times, find the previous node and use it as a hint for the next time.

Test Plan: Add some unit test coverage.",6934395
811,2019-05-10T23:54:09Z,2019-05-20T22:21:14Z,,,"Summary:

Modified FindIntraL0Compaction to stop picking more files if total
amount of compensated bytes would be larger than max_compaction_bytes
option.

Test Plan: make check so far - will look into adding a unit test

Reviewers:

Subscribers:

Tasks:

Tags:",6934395
812,2019-04-30T20:41:45Z,2020-01-03T21:33:45Z,,,"This adds a new hash table implementation that is generally more memory friendly, and faster than HashMap or std::unordered_map. This replaces the global lock table, as well as the tracked_keys data structure.

On a single threaded workload where GetForUpdate + Put(assume_tracked) is called in batches of 100k keys:
std::unordered_map: 265691.8 / s
HashMapRB: 298957.6 / s

12.5% improvement",6934395
813,2019-04-17T12:54:25Z,2019-09-10T00:34:37Z,,,"When I create my own implementation of Logger, 
and try to link it into my executable, I get the error

```
undefined reference to `typeinfo for rocksdb::Logger'
```

I am using rocksdb built in release mode, which seemingly
is built with no RTTI. I got it by calling
`sudo apt-get install librocksdb-dev`.

This change allows folks using such release builds
to successfully link their applications.

It is similar to #3008",6934395
814,2019-04-17T10:21:28Z,2019-09-11T22:07:24Z,,,"https://github.com/facebook/rocksdb/issues/5206

In the case of a shutdown or other reasons in which a flush may
not complete, OnFlushCompleted is not called because the Status is
not OK. Instead, pass the status through to the event listener via the
FlushJobInfo and allow the listener to deal with any failure as they
see fit.",6934395
815,2019-04-16T22:03:05Z,2019-09-10T00:48:17Z,,,"Summary:
Introduce an interface to customize how compaction cuts output file. Currently compaction output is cut based on size only, controlled by `target_file_size_base` and `target_file_size_multipler`. Potential use case of the interface include:
1. application can choose to fine-tune file boundaries between different levels, reducing non-overlapping potion between input level and output level for a compaction job, to reduce compaction IO. An example would be the ""guards"" described in this paper: http://www.cs.utexas.edu/~vijay/papers/sosp17-pebblesdb.pdf
2. some application shard its data and store multiple shards in a single rocksdb instance. Such application can choose to cut SST by shard boundary. When it want to drop a shard and reclaim space with `DeleteFilesInRange`, it can drop data more precisely. Without cutting files at shard boundary, some files can overlap with two adjacent shards, and cannot reclaim by `DeleteFilesInRange`.

Other potential use of the interface:
1. It can be used as a callback for each output key from a compaction.
2. It may be further extend to customize other aspect of the compaction algorithm.

Test Plan:
Pending. Will add test if the interface look okay.",6934395
816,2019-03-29T17:08:34Z,2019-03-29T17:11:11Z,,,"Blob files were not counted in DB size by SstFileManager. As a result, blob files are always subject to background file deletion rate limiting in DeleteScheduler. Normal SST files bypass the rate limiter if trash/db size ratio is above a certain threshold, which limits disk utilization due to accumulated trash. 

This PR fixes it by adding Blob files size to the total DB size in SstFileManagerImpl::GetTotalSize(). Since blob file size increases on every blob write, we provide SstFileManagerImpl with a pointer to the blob file size atomic counter that it can look at in GetTotalSize(), otherwise it would be too much overhead to update SstFileManagerImpl on every blob write.

Test:
Add a new test in blob_db_test
make check",6934395
817,2019-03-27T21:11:43Z,2019-11-27T17:08:13Z,,,"### Notes
We are prototyping to use rocksdb as our next-gen storage engine. One problem that we have encountered is that rocksdb doesn't provide a good way to utilize multiple disk mounts evenly on our hosts. We didn't really like the raid idea, which was mentioned in [the rocksdb FAQ](https://github.com/facebook/rocksdb/wiki/RocksDB-FAQ): our current prod software is running on these hosts with multiple equal-sized disk mounts; using a raid would require a risky disk setup before the data migration.

This change introduces a dynamic path choose class (`DbPathSupplier`) when creating output files. It is built on top the already-existing feature of cf_paths. The original behavior of using paths (gradually moving cold data to towards the end of paths list) is kept as the default path placement strategy. We are introducing a new random placement strategy to allow us distribute sst files evenly on our disks. 

### Major changes
* Added a set of classes to (`DbPathSupplier`) to provide dynamic db_path picking logic to replace the original fixed path_id logic
* Added an `db_path_supplier_factory` option in DBOptions
* Modified the `FileDescriptor` struct: removed 2 higher bits from the `packed_number_and_path_id` that used to represent file_num. This allows us to increase the limit of `path_id` from `3` to `15`
* Modified the flush: instead of always using path 0, now it dynamically chooses a path to create the output file
* Modified the compaction: instead of using the pre-chosen path for all output files in a compaction, dynamically choose a path (using `DbPathSupplier`) for every single output file.
* Modified the java interface to include the db_path_supplier_factory options
* Modified the java interface to include cf_paths options, which were not added in previous changes
* Removed the limitation of 4 path_ids in manifest serialization

### Testing
* All unit tests passed
* We have been doing some basic load tests with these changes in our test environment (involving a small fleet consisting of dozens of hosts) for a few weeks and haven't discovered major issues.
",6934395
818,2019-03-05T15:59:27Z,2020-03-03T00:39:48Z,,,"Add support for Pessimistic transactions to do Range Locking.

First version, will probably be updated",6934395
819,2019-02-05T18:46:26Z,2019-09-10T00:51:23Z,,,"
The issues with using level_and_file.second->num_deletions > 1 instead are:

it doesn't trigger compaction when there's one deletion, which could
be a range deletion covering a lot of keys in the file

it doesn't trigger compaction when there are many overwritten
keys. Some MyRocks use case actually doesn't use Delete but instead
calls Put with empty value to ""delete"" keys, so we'd like to be able
to trigger compaction in this case too.

Add flag to prevent double calling the callback in test.

Test plan:
 - make check
 - ./db_bench",6934395
820,2019-01-23T01:57:42Z,2019-02-08T17:27:12Z,,,"Switch to using `RepeatableThread` in BlobDB instead of `TimerQueue`. 

- We were using TimerQueue in BlobDB to run tasks at fixed intervals. With the introduction of `RepeatableThread`, we no longer need to rely on `TimerQueue` code.
- Remove all reference to `TimerQueue`.
 
Test Plan:
Run all tests using `make check`. Test with clang as well using: `USE_CLANG=1 make all` ",6934395
821,2018-12-21T23:08:31Z,2019-09-10T00:54:33Z,,,,6934395
822,2018-12-20T17:05:34Z,2019-11-24T20:59:54Z,,,"This PR extend StringAppendTESTOperator class to use `std::string` delimiter instead of `char`. `char` becomes then a custom case of `std::string`. This allows for delimiter of variable length, including zero length if delimiter is not needed at all and space can be saved. The PR also extends `StringAppendOperator` in Java API.",6934395
823,2018-12-20T12:54:03Z,2020-02-27T13:11:06Z,,,"Support for merge operator in java. 

Add AbstractAssociativeMergeOperator and AbstractMergeOperator which allow to implement merge operators in java. The MergeOperator class in java now inherit from RocksCallBacksObject and existing merge operators have been rewritten accordingly. In c++, AssociativeMergeOperatorJniCallback and MergeOperatorJniCallback inherit from JniCallback.

This PR is based on [https://github.com/facebook/rocksdb/pull/3432](https://github.com/facebook/rocksdb/pull/3432) but without thread JNI management neither loader management for static variables. Performances are slow since jni thread must be attached/detached at each call.

resolve #2282 ",6934395
824,2018-12-18T19:27:59Z,2019-07-10T01:04:29Z,,,"Prepopulate data blocks to block cache at Flush time. A new BlockBasedTable option, `prepopulate_data_blocks`, has been added to control this feature (default: turned off).

This piece is part of a larger feature which we have been calling ""Cache Warming"". 

This helps in improving the block cache hit rate leading to less IO incurred in reading back the flushed blocks from device, especially when using Direct IO, and thereby also reducing some tail latency (if it is due to flush/compaction block invalidations). 
Workloads which exhibit high temporal locality would especially benefit for it. 
Example: Before flush most of the recently written data is in mem-tables, and after flush some data gets written out to the device. If a lot of reads are still to the data that recently got flushed, your service would incur IO to bring those recently flushed blocks back into memory. With this feature, those blocks are already prepopulated to the block cache. 

Notes:
This could end up evicting blocks which are already at the tail end of the LRU block cache though. Also, this pre-population is done even before the new L0 file is added to the LSM manifest ... so there is a slight chance that the added blocks are invalid if the Flush fails/aborts (which rarely happens I believe)

For future:
- Index and filter blocks could also be pre-populated in the same way.
- Data blocks from higher levels which are already in memory could be pre-populated (replaced with newly created data blocks) during compactions as they would become invalidated at the end of a compaction.
- Maybe a background thread to go about evicting invalidated data blocks.

Test Plan:
Added a new test `DBBlockCacheTest. WarmCacheWithL0DataBlocks`.",6934395
825,2018-11-29T20:29:51Z,2019-09-10T00:55:11Z,,,"Currently the BackupInfo object exposes limited, aggregated information about
the content of a backup. We extend the information currently available by
exposing a set of metadata for each file in the backup that includes:
 - filename;
 - file size;
 - checksum.

For consistency, I have renamed FileInfo to FileMeta. BackupMeta and the
newly renamed FileMeta class are internal implementation details, whereas
BackupInfo and the newly created BackupFileInfo are part of the public interface
(this way, *Meta is consistently used in the private implementation, and *Info
is part of the public interface).

In previous conversations with @ajkr we discussed exposing the extra information conditionally, subject the value of a new GetBackupInfo parameter. I eventually decided to make the file-level information always available because they are fetched at BackupEngine initialization time anyway, so they can be exposed at no extra cost (save for the additional memory).",6934395
826,2018-11-05T21:56:01Z,2019-10-07T00:09:33Z,,,"If the trace is very large or user want to sample the trace first based on the sampling ratio, user can set the sample_ratio to partially analyze the trace. It is based on every X query of one type, analyze one query. X = <int>(1.0/sample_ratio).

Test plan: tested through the trace analyzing and test",6934395
827,2018-10-19T22:59:52Z,2019-10-07T00:09:32Z,,,"Count the number of Next or Prev called in the iterator by Seek or SeekForPrev. Analyze the trace with the corresponding content.

Test plan: test by db_bench and real workload",6934395
828,2018-10-04T20:56:55Z,2019-10-07T00:09:33Z,,,"When user use trace_replay (PR #3837 )and trace_analyzer (PR #4091 ) get the key access distribution and prefix access distribution, they can use Matlab to fit the distribution to 2 terms exp distribution model. By input the four parameters of the model to the simulator class, use can use it to generate the synthetic workload of Get under 'ReadRandom' which will be close to the real world workload. 
User can also model the QPS variation of their workload of Get via A*sin(B*x+C)+D and use the four parameters to control the front end QPS changing. In this way, both the access count and the QPS are stimulated in the synthetic workload.

Status
Added GenerateTwoTermExpKeys class to transfer the uniform access to the access patterns that satisfy the two-term exponential distribution. Support multi-threads. Added the sine_read_rate_limit to control the front end QPS of get.

Test
Tested with trace_replay and trace_analyzer",6934395
829,2018-09-19T09:27:53Z,2019-09-20T04:10:40Z,,,"This pull request improves MemTable design, it fixed several MemTable drawbacks:
1. `Factory` mechanism is not powerful enough
   * We can set `options.memtable_factory` to plugin a new MemTable without change RocksDB code
   * We **can not** set MemTable **by name**(factory name) without change RocksDB code
      * **Solution**: introducing `Abstract Factory` and factory register mechanism, and keep existing **name<->factory** mapping unchanged
1. MemTable in `WriteBatchWithIndex` is hard coded as `SkipList`
   * **Solution**: Add `WriteBatchEntryIndexFactory` with factory register mechanism.
1. KeyValue encoding in MemTable is hard coded as prefix-length encoding, in some MemTable implementation, Key is not required to be prefix-len encoded.
   * **Solution**: Replace `InsertKey(encoded_kv)...` by `InsertKeyValue(Slice k, Slice v)...`, let default `InsertKeyValue` to encode kv and calling existing `Insert()...`

Additional: We will pull-request our array based RBTree MemTable implementation later, which show the need for this refactory.",6934395
830,2018-09-19T07:50:51Z,2019-11-12T14:33:33Z,,,"Summary:

There are sveral FALGS duplicated definition in `prefix_test.cc`
and `cuckoo_table_reader_test.cc`. This would not cause compile error,
but if run `make test`, two tests can not run (run it manually either).
it would raise: `ERROR: xxx was defined more than once`.

For example:

```
root@603462448c35:/opt/rocksdb/build# ./cuckoo_table_reader_test
ERROR: flag 'identity_as_first_hash' was defined more than once (in files '/opt/rocksdb/tools/db_bench_tool.cc' and '/opt/rocksdb/table/cuckoo_table_reader_test.cc').
root@603462448c35:/opt/rocksdb/build# ./prefix_test
ERROR: flag 'write_buffer_size' was defined more than once (in files '/opt/rocksdb/tools/db_bench_tool.cc' and '/opt/rocksdb/db/prefix_test.cc').
```

With this change, `prefix_test` and `cuckoo_table_reader_test` works again.

Signed-off-by: JiYou <jiyou09@gmail.com>",6934395
831,2018-08-10T06:39:43Z,2018-08-25T00:38:39Z,,,"When user use trace_replay (PR #3837 )and trace_analyzer (PR #4091 ) get the key access distribution and prefix access distribution, they can use Matlab to fit the distribution to 2 terms exp distribution model. By input the four parameters of the model to the simulator class, use can use it to generate the synthetic workload of Get under 'readrandom' which will be close to the real world workload.

**Status**
Added GenerateTwoTermExpKeys class to transfer the uniform access to the access patterns that satisfy the two-term exponential distribution. Support multi-threads

**Test**
Tested with trace_replay and trace_analyzer",6934395
832,2018-07-24T00:33:28Z,2018-07-25T21:19:59Z,,,This PR is for commits related to changes required for sysbench support in the Rocksdb Config Optimizer.,6934395
833,2018-06-29T07:22:11Z,2019-09-10T01:03:50Z,,,#4036 showed the introduction of compile errors. Lets include a basic build test for these more recent compilers.,6934395
834,2018-06-25T21:45:15Z,2019-04-23T23:33:19Z,,,"**Note:**
This is still a poc and NOT ready for submission, as I haven't thought though all the cases where it might cause performance regression (too many cases to think through). 

Things I might be missing so far:
- IndexReader might need its own FilePrefetchBuffer, during compactions. ie. pass along `for_compaction` to `NewIndexIterator` in `BlockBasedTable::NewIterator`. Otherwise we are not doing any readahead for indexes, which would be pretty bad. 
- Compaction reads with buffered IO will pollute page-cache.
- Is Special handling needed when `use_mmap_reads=true` ? 

**Summary:**
Remove ReadaheadRandomAccessFile usage in `TableCache::GetTableReader`.  Instead let BlockBasedTableIterator and FilePrefetchBuffer handle all the readahead logic. 

Test Plan:
make check -- all tests succeed. 
`DBIteratorTest.ReadAhead` test failed since it wasn't aware of Prefetch. It started passing once I added `Prefetch` to `CountingFile`. ",6934395
835,2018-06-21T08:45:19Z,2019-09-10T00:29:33Z,,,Change provides support for adding C API to RocksDB Lite. Remove global #ifndef ROCKSDB_LITE wrapper then wrap structs and functions unsupported in lite mode to be skipped.,6934395
836,2018-06-17T08:52:54Z,2019-09-10T01:04:27Z,,,Added a void cast for unused function parameter to fix TARGET_OS=IOS make static_lib build. ,6934395
837,2018-05-30T03:19:14Z,2019-09-09T19:09:09Z,,,"An internal user asked about migrating from non-dynamic to dynamic level compaction, and the answer was unfortunately the nonempty levels that become unnecessary after the migration will never be automatically drained. Draining levels is also useful for dynamically changing `max_bytes_for_level_multiplier` to be effective, or to reduce read-amp after users delete data and the DB shrinks.

This PR:

- Finds levels to drain that are nonempty and above the ideal base level. Those levels are assigned target size 0.
- Levels with target size 0 have their compaction score computed differently to ensure it's always at least 1.0.

Test Plan:

- `make check -j64`
- use db_bench to verify levels are emptied after migration from non-dynamic to dynamic. Before this PR, running the below commands caused all of L0-L6 to contain data. After this PR only L0, L4-L6 contain data.
```
$ TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=fillrandom  -num=1000000 -write_buffer_size=1048576 -target_file_size_base=1048576 -max_bytes_for_level_base=4194304 -compression_type=none -max_background_jobs=12 -benchmark_write_rate_limit=1048576
$ TEST_TMPDIR=/dev/shm ./db_bench -benchmarks=overwrite -use_existing_db=true -num=1000000 -write_buffer_size=1048576 -target_file_size_base=1048576 -max_bytes_for_level_base=4194304 -compression_type=none -max_background_jobs=12 -benchmark_write_rate_limit=1048576 -level_compaction_dynamic_level_bytes=1
```",6934395
838,2018-05-18T21:34:10Z,2019-10-11T16:21:49Z,,,"To support partition deletion in Rocksandra, we created a separated partition meta cf in each database and passing db and cf handle into the compaction filter. The compaction filter is in charge of dropping the deleted data based on deletion info it read from the partition meta cf. This PR is the first step just for releasing the disk space. Next step would change in cassandra merge operator to convert partition deleted rows into tombstones.

* add a merge operator for parition meta data (currently partition
  deletion info only)
* read partition deletion in cassandra compaction filter and drop rows
  if it's partition has been deleted
* `make format` for cassandra related test files",6934395
839,2018-05-15T23:20:33Z,2018-07-25T21:19:58Z,,,"Fixes #3816 
",6934395
840,2018-04-29T20:02:09Z,2019-09-09T22:25:05Z,,,Let me know if I should update/add any tests!,6934395
841,2018-03-30T07:09:53Z,2019-10-09T00:08:20Z,,,DeleteFilesInRange is quite useful for immediately release disk pressure. Add Java support so that we can use it in Cassandra cleanup process.,6934395
842,2018-03-16T13:56:52Z,2020-03-02T21:00:44Z,,,"This is a new merge operator which allows you to store a collection of records within the value of a key/value pair.

A record is just a fixed length byte string. Features include:

1. Options for controlling the collection semantics, supporting both:
   1.  a Set like collection of records where each record is unique, and,
   2. a Vector like collection where there may be duplicate records.

2. The Collection Merge Operator also optionally supports ordering, where a Comparator can be provided to ensure the ordering of records.

A simple example of vector like behaviour without ordering would look like:

```C++
DB* db;
Options options;
options.create_if_missing = true;

auto collection_merge_operator = std::make_shared<CollectionMergeOperator>(4);
options.merge_operator = collection_merge_operator;

Status status = DB::Open(options, ""/tmp/testdb"", &db);
assert(status.ok());

Slice key1(""key1"");

Slice add1(std::string(""100020003000).insert(0, 1, CollectionOperator::kAdd));
db->merge(key1, add1);

Slice remove1(std::string(""2000).insert(0, 1, CollectionOperator::kRemove));
db->merge(key1, remove1);

assert(db.get(key1) == Slice(""10003000"");
```",6934395
843,2018-03-07T23:34:04Z,2018-07-25T21:19:58Z,,,"Summary: Some cache implementation controls memory allocation too. In here we provide a small implementation change enabling experiments to these caches in limited scenario: data blocks in SST files with compression disabled.

Test Plan: Add a unit test",6934395
844,2018-02-05T20:20:30Z,2020-03-17T21:30:18Z,,,"Ported Iterator::Refresh functionality to RocksJava. This was originally introduced in the C++ API by @siying in #2621. 

This should reduce GC pressure particularly in use-cases that frequently create and destroy large number of iterators just to get to the latest snapshot of data.

The API can be invoked by calling `RocksIterator::refresh()`.
`WBWIRocksIterator::refresh()` is not implemented and would throw a not-supported exception for now. 

Test Plan:
Added Unit tests. ",6934395
845,2018-01-29T15:34:42Z,2019-12-13T18:54:53Z,,,"This pull request add AbstractAssociativeMergeOperator and AbstractNotAssociativeMergeOperator in java. These classes are abstract permitting to implement the merge operator in java code. 

This pull request introduces also 2 important performance improvements(they are generic applicable to all jni classes): 
1) The JNI Thread attachment is a expensive operation. Doing it after every api operation can reduce performance in significant way. This patch introduces a automatic management for attachment/detachment: the attachment will be executed once and the detachment will be executed just before thread termination in automatic way. 
2) Many static variables actually are loaded on the fly inside the jni api. This patch introduce a loader/unloader management for preloading all static/global variables for the jni modules when JVM is loaded. This permits to remove the loading time inside the jni api. For Adding a loader/unloader in a JNI class  is very simple: this is a example 
```
 funcInit(JNIEnv* env){
   load symbols , jclasses,methodids,fieldids, globalRefs
 }
 funcDestroy(JNIEnv* env){
   unload globalRefs
 }
   initialize {

rocksdb::setLoader( &funcInit);
rocksdb::setUnloader( &funcDestroy);

}
```

The thread attachment management and loading management are used by merge operator for optimizing the execution time
",6934395
846,2018-01-08T15:57:14Z,2019-09-23T19:40:57Z,,,"Similar to `AbstractCompactionFilterFactory` and `AbstractComparator`, this diff contains an abstract base class for `rocksdb::CompactionFilter` written in Java. It uses a similar set of techniques to cache relevant field / method IDs at startup, passes scalars back into Java and relies on threadlocals to avoid `DirectSlice` finalize churn.

Using this implementation we've been able to run a Java compaction filter under Manhattan production workloads with a ~10% performance reduction.  It's not free but is good enough for some usecases.

There are a few unresolved issues with this implementation that I wanted to discuss with the community. They're marked with `TODO(benclay)` below.

- Detaching compaction threads after every callback is extremely expensive. On our OpenJDK8 JVM the `DetachCurrentThread` call internally serializes on a mutex while releasing monitors, causing compactions and thus writes to eventually stall.  As a result, in this diff **we are not detaching at all**.  However, I am concerned about upstreaming this as-is this because folks might explicitly take locks in their CompactionFilter implementations and need those monitors to be automatically released.  I am looking for feedback from the community on this problem.  There are a few solutions from Rocks side I can think of, but am open to more ideas:
  - Add a lifecycle hook (perhaps to CompactionFilterFactory?) when the compaction thread is shutting down. At that point we can detach the thread from the JVM.  This still risks the thread crashing and never detaching though.
  - Implement a batching interface to CompactionFilter so we aren't making so many roundtrips and the detach cost is amortized.  This would help performance more generally but is probably more invasive - I haven't looked into the implications on Rocks side.
  - Detach every Nth call - this seems very racy and doesn't guarantee that the thread detaches on the final call, so it seems like a non-starter.
- I couldn't take advantage of @adamretter 's `RocksCallbackObject` regime because Java disallows multiple inheritance and I needed to inherit from `AbstractCompactionFilter`.  Right now that class and its C++ companion `JniCallback` are fairly basic, but over time could export some useful performance enhancements.  I thought about shimming a new `ICompactionFilter` interface **below** `AbstractCompactionFilter` and have that be the primary unit for interacting with `ColumnFamilyOptions`. Upon further examination that will somewhat break the tradition of having abstract base classes with package-private `nativeHandle_` member variables, which is how `ColumnFamilyOptions` is binding the `CompactionFilter` handle on the C++ side.  Open to suggestions here as well.

@sagar0 @adamretter 
 
EDIT: The unit tests hang forever because in RocksJunitRunner.java we just return from main instead of `System.exit()`. The JVM by default will wait for all non-daemon threads to die before exiting using return-from-main, which means that it's waiting for these never-detached background compaction threads.  Switching the attach calls to `AttachCurrentThreadAsDaemon` is a non-starter because it allows the JVM to prematurely start GCing things like `ColumnFamily` objects that are still being compacted.  As a result, we'll need some auto-detach solution here (IE https://github.com/facebook/rocksdb/pull/3432) before landing this.",6934395
847,2017-10-13T05:54:46Z,2020-01-31T19:30:46Z,,,"in kSkipAnyCorruptedRecords mode, continue to replay the log.",6934395
848,2017-10-05T20:25:56Z,2019-09-11T19:02:43Z,,,"identify the thread using the output of `gettid()` syscall on Linux, which is a system-wide unique ID, unlike `pthread_self()`. Also changed from hex to decimal to be compatible with tools like `top`.

Test Plan:

- make check -j64
- run db_bench and correlate `top` entries with log entries

```
$ top -H
...
782508 andrewkr  20   0  319272  47864   8884 R 99.7  0.0   0:04.18  4 db_bench
...
```

```
$ grep '782508' /dev/shm/dbbench/LOG | head -1
2017/10/05-13:23:17.517942 782508 [db/db_impl_write.cc:1162] [default] New memtable created with log file: #6. Immutable memtables: 0.
```",6934395
849,2017-09-08T18:51:27Z,2019-12-13T15:39:34Z,,,"This PR adds another variant of the put-method to SstFileWriter, namely with the signature `put(ByteBuffer, ByteBuffer)`.
This allows for the most efficient data transfer from Java to rocksdb.
See issue #2668 for a detailed motivation.",6934395
850,2017-09-04T02:37:34Z,2019-09-10T17:12:55Z,,,"    This is to implement the idea: http://pad.ceph.com/p/rocksdb-wal-improvement
    Add a new flush style called kFlushStyleDedup which users can config by setting
    flush_style=kFlushStyleDedup. When flush is triggered, it dedups the key/value
    pairs in the oldest memtable against other memtables before flushing the
    oldest memtable into L0.

    The flush solution benefits for the data which are duplicated between memtables.
    With this flush, it can decrease the data flushed into L0 a lot.

    Signed-off-by: Xiaoyan Li <xiaoyan.li@intel.com>",6934395
851,2017-08-21T19:08:34Z,2019-09-10T00:07:58Z,,,"WAL files could be huge which will cause stalls if they are deleted quickly.
This patch update SstFileManager to also rate limit the deletes for WAL files",6934395
852,2017-07-25T07:32:20Z,2019-09-10T00:14:31Z,,,"fix isuues:
  1.  ``` children_.emplace_back(iter); ```, elements in ``` minHeap_ ``` will be invalid after ```children_```'s capacity changed.
  2.  ``` new_wrapper ``` is a stack object , add its address to ``` minHeap_ ``` will produce undefined behavior.

this fix is not graceful enough, but it should work...",6934395
853,2017-07-04T11:37:31Z,2019-09-10T18:56:33Z,,,"In my opinion, L0->L0 compaction is used to reduce small sst files count in L0 that making unreasonable stall harder to reach. But current L0->L0 compaction mechanism:
1) May generate a [big sst file](https://github.com/facebook/rocksdb/issues/2530). This will cause a very big L0->L1 compaction job which need a long time to finish.
2) Simply compact [0,n) sst files of L0.

This pr:
1) Only compact small sst files;
2) Add a size limitation for L0->L0 compaction;
3) Can compact [n, m) sst files of L0.

@ajkr PTAL
",6934395
854,2020-03-23T11:07:37Z,2020-03-23T11:07:37Z,,,"## Status
**READY/IN DEVELOPMENT/HOLD**

## Description
Describe what is changed by your Pull Request. If this PR is related to the open issue (bug/feature/new module) please attach issue number.

## Verification
Provide steps to test or reproduce the PR.
 1. Start `./rsf.py`
 2. `use exploits/routers/dlink/dsl_2750b_rce`
 3. `set target 192.168.1.1`
 4. `run`
 5. ...

## Checklist
- [ ] Write module/feature 
- [ ] Write tests ([Example](https://github.com/threat9/routersploit/blob/master/tests/exploits/routers/dlink/test_dsl_2750b_rce.py))
- [ ] Document how it works ([Example](https://github.com/threat9/routersploit/blob/master/docs/modules/exploits/routers/dlink/dsl_2750b_rce.md))
",55058317
855,2019-12-06T21:37:47Z,2019-12-31T09:37:49Z,,,"## Status
**READY**

## Description
This pull request adds support for Windows by initializing colorama when loading the interpreter module, so colored output can be printed to Windows's command prompt, and by using pyreadline on Windows systems as a replacement for Linux's readline module.
Closes [Issue #619 ](https://github.com/threat9/routersploit/issues/619)

## Verification
Provide steps to test or reproduce the PR.

1. Clone `git clone https://github.com/threat9/routersploit && cd routersploit`
2. Install `python3 setup.py install`
3. Execute `rsf`


## Checklist
- [X] Write feature
- [X] Document [Additional requirements](https://github.com/threat9/routersploit#Additional-requirements-for-Windows) and [Installation on Windows](https://github.com/threat9/routersploit#Installation-on-Windows)
",55058317
856,2019-11-18T11:46:45Z,2019-12-15T00:42:26Z,,,"## Status
**READY for #576**

## Description
Module exploits Cisco RV320 Remote Command Injection vulnerability in the web-based certificate generator feature.

## Verification
Provide steps to test or reproduce the PR.
 1. Start `./rsf.py`
 2. Do: `use exploits/routers/cisco/rv320_command_injection`
 3. Do: `set target [TargetIP]`
 4. Do: `set command [Remote Command]`
 5. Do: `run`
 6. If router is vulnerable, it should be possible to execute command on operating system level.

## Checklist
- [x] Write module/feature
- [x] Write tests
- [x] Document how it works
",55058317
857,2019-11-13T16:05:19Z,2019-12-15T00:42:05Z,,,"## Status
**READY**

## Description

Module exploits unauthenticated remote code execution occurs in D-Link products such as DIR-655C, DIR-866L, DIR-652, and DHP-1565.

## Verification Steps

  1. Start `./rsf.py`
  2. Do: `use exploits/routers/dlink/dir_655_866_652_rce`
  3. Do: `set target [TargetIP]`
  4. Do: `run`
  5. ...
## Checklist
- [x] Write module/feature 
- [x] Write tests
- [x] Document how it works
",55058317
858,2018-06-19T23:59:08Z,2018-06-28T16:12:47Z,,,"## Status
**IN DEVELOPMENT**

## Description
Adds support for CVE-2017-17215, RCE in the Huawei HG532

## Verification
Provide steps to test or reproduce the PR.
 1. Start `./rsf.py`
 2. `use exploits/routers/huawei/hg532_rce`
 3. `set target 192.168.1.1`
 4. `run`
 5. ...

## Checklist
- [x] Write module/feature 
- [ ] Write tests ([Example](https://github.com/threat9/routersploit/blob/master/tests/exploits/routers/dlink/test_dsl_2750b_rce.py))
- [ ] Document how it works ([Example](https://github.com/threat9/routersploit/blob/master/docs/modules/exploits/routers/dlink/dsl_2750b_rce.md))
",55058317
859,2018-04-25T02:59:46Z,2018-06-02T09:59:46Z,,,"Three modules to exploit vulnerabilities in HooToo TripMate series:
- Unauthenticated Remote Code Execution in /sysfirm.csp
- Multiple Instances of Unauthenticated Operating System Command Injection in open_forwarding
- Unauthenticated Arbitrary File Upload

I am not entirely sure that I am using `shell()` correctly so feel free to tell me what to change in those modules :)

They are still unpatched as of today, as far as I can tell, despite attempting to report them since October, 2017.",55058317
860,2020-03-12T21:04:53Z,2020-03-12T21:04:53Z,,,"My GOPATH is`/home/jsteuer/go:/home/jsteuer/go_dev`. If I run packr2 the generated `*-packr.go` contains the following bad import.

    // +build !skippackr
    // Code generated by github.com/gobuffalo/packr/v2. DO NOT EDIT.

    // You can use the ""packr clean"" command to clean up this,
    // and any other packr generated files.
    package template_index

    import _ ""_dev/src/github.com/jsteuer/myproject/packrd""

Because both paths are sharing the substring `/home/jsteuer/go` the algorithm to calculate the `.Import` path for `diskImportTempl` is depending on the order of the GOPATH. (If `GO111MODULE=on` the problem does not appears - thanks to #183). I think this is bug, so sorting the entries of the GOPATH solves this issue for me:

    // +build !skippackr
    // Code generated by github.com/gobuffalo/packr/v2. DO NOT EDIT.

    // You can use the ""packr clean"" command to clean up this,
    // and any other packr generated files.
    package template_index

    import _ ""github.com/jsteuer/myproject/packrd""

",85126896
861,2020-03-03T05:54:14Z,2020-03-10T06:12:16Z,,,,85126896
862,2019-10-01T21:54:09Z,2019-10-05T11:52:49Z,,,"This is an attempt to solve the problem from #222
In its previous version, packr2 used the current working directory as
its default disk resolver. This commit tries to use the development
directory instead.

---

I'm not sure about this PR, it may need some additional testing :)",85126896
863,2019-09-04T18:16:49Z,2019-12-16T15:55:41Z,,,"It appears that `GoFiles` from [`Package`](https://godoc.org/go/build#Package) is _NOT_ module aware. Therefore the check in `v2/jam/parser/finder.go:87` would always return
and not find files. The only way in which I think we can reliably check
if a project is using modules is to check for the presence of `go.mod`
in the package root. Thus, I have added the guard to check for `go.mod`
before we rely on `pkg.GoFiles`.

This should address #195 and #228",85126896
864,2019-05-12T19:51:10Z,2019-08-28T17:50:03Z,,,"When dependencies are vendored (not stored in GOPATH or GOROOT), packr is not able to find Boxes. This Change allows locating boxes in vendor directory (excluding github.com/gobuffalo/packr)",85126896
865,2019-09-21T21:27:36Z,2019-09-23T04:04:24Z,,,"This will be helpful for colab users and people who are not able to compile ELL on their system. 

@lovettchris I have one more tutorial planned of Key Word Spotting, in which I have taken care of adding background noise and mixing silent noise with the audio. You can find the colab notebook on this [link](https://colab.research.google.com/drive/1pSjCLZnw6CEptNcCEUKuGJAJfma215dk). I need to format and comment it properly. Which can help people generate KWS models using ELL and deploy it on microcontrollers.",69389961
866,2019-05-07T00:38:10Z,2019-06-10T18:34:40Z,,,"Also warn about non-symmetric padding and strides, until support is added.",69389961
867,2019-11-19T09:56:37Z,2019-11-19T09:56:37Z,,,"<!--
Thanks for contributing to Blynk library :-)

Please provide the following information for all PRs.
Replace [brackets] and placeholder text with your responses.
-->

### Description
My use case is using a self-signed certificate and its fingerprint for validation.

This PR makes the following code use the fingerprint and work as expected:
> Blynk.begin(auth, ssid, pass, ip, port, fingerprint);

otherwise the `WiFiClientSecure::connect()` method fails to validate the SSL connection and returns the following error if debug messages are enabled or silently fails otherwise:
> BSSL:Couldn't connect. Error = 'Chain could not be linked to a trust anchor.'

A workaround, without applying this PR is:
>  _blynkWifiClient.setFingerprint(fingerprint);
>  Blynk.begin(auth, ssid, pass, ip, port, fingerprint);

### Issues Resolved
Using the fingerprint fails to establish an SSL connection.
",32791821
868,2019-07-01T09:23:27Z,2019-08-19T02:27:28Z,,,"<!--
Thanks for contributing to Blynk library :-)

Please provide the following information for all PRs.
Replace [brackets] and placeholder text with your responses.
-->

### Description
I made odroid-series arduino core.
I want to write blynk code on the Arduino platform even if on the embedded Linux.


### Issues Resolved
Until now, for using blynk, the code with blynk was compiled using command line tools on the embedded Linux.

If you merge BlynkSimpleLinuxSocket.h, to use blynk is much easier on the embedded Linux with Arduino.
",32791821
869,2019-04-03T05:46:53Z,2019-04-03T05:46:53Z,,,"hi @vshymanskyy 

### Description
Implemented the support file, required to make works Blynk with WizFi250:

Implemented the the header file BlynkSimpleWizFi250.h;
Implemented the the header file src\Adapters\BlynkWizFi250.h;
Implemented the example examples\Boards_WiFi\WizFi250\WizFi250.ino


WizFi250 is a lower version module of the WizFi310.

BylnkWizFi250 is almost the same as the WizFi310.
WizFi250 library is available download from the library manager :)

reference : https://www.wiznet.io/product-item/wizfi250/

There was nothing wrong with the test.
thanks!

",32791821
870,2019-09-30T00:13:36Z,2020-02-20T04:25:15Z,,,"Add qtcreator-generic IDE template.  Fixes #3046 

Since Qt Creator can default to running `make` for generic targets, this template also adds a `Makefile` that will allow Qt Creator to automatically build the project without having to manually modify the project settings to launch `platformio`.

This `qtcreator-generic` IDE template diverges from the `qtcreator` template in that it doesn't require a Qt Kit to be setup that contains `qmake`.  It also outputs compiler flags so that detail from custom scripts that alter the compiler flags can be captured by the code model in Qt Creator.  It does, however, lose the `HOMEDIR` isolation of include paths that the `qtcreator` template provides -- this is because I see no good way to do it with the generic project mechanism since it's not parsed by `qmake`.

Run with: `platformio init --ide qtcreator-generic`
",19606299
871,2020-03-26T17:10:16Z,2020-03-26T19:13:31Z,,,"Basic cleanup preparatory to addressing https://github.com/zephyrproject-rtos/zephyr/issues/21392#issuecomment-604488737, specifically to update checkpatch to be closer to current Linux, and verifying `.clang-format` is consistent with Zephyr needs.

FWIW, our `.clang-format` and LInux differ only in the ForEachMacros list. clang-format transforms those to add a space after the macro name, which gets diagnosed as a style error by checkpatch.  The Linux clang-format also makes changes that are rejected by Linux checkpatch (ForEachMacros and other whitespace diagnostics).  So it's not clear that clang-format is actually used by Linux.",59771425
872,2020-03-26T14:36:05Z,2020-03-26T15:17:56Z,,,,59771425
873,2020-03-26T14:16:50Z,2020-03-26T14:16:50Z,,,"UART1 Rx and Tx pins were assigned the wrong GPIO periperal.

Signed-off-by: Vincent van der Locht <vincent@vlotech.nl>",59771425
874,2020-03-26T14:12:20Z,2020-03-26T16:25:53Z,,,"Use the new devicetree API in a file which cross-checks dt reg base
addresses with values from the vendor HAL.
",59771425
875,2020-03-26T13:52:41Z,2020-03-26T13:55:05Z,,,"This updates the Xtensa HAL revision to latest master,
which includes updating the HAL to version 12.08, and
making it a named module.

Signed-off-by: Daniel Leung <daniel.leung@intel.com>",59771425
876,2020-03-26T13:14:30Z,2020-03-26T13:24:24Z,,,"Fix ticker to avoid catch up of periodic timeouts in case of
large ISR latencies like in case of flash erase scenarios.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
877,2020-03-26T13:10:08Z,2020-03-26T13:20:25Z,,,"Fix regression in cancelling slave latency during Connection
Update Procedure.

Slave latency should not be applied between the ack of a
Connection Update Indication PDU and until the instant.
When caching was introduced, implementation missed this
consideration.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
878,2020-03-26T13:08:45Z,2020-03-26T13:18:08Z,,,"Fix regression in cancelling slave latency during Connection
Update Procedure.

Slave latency should not be applied between the ack of a
Connection Update Indication PDU and until the instant.
When caching was introduced, implementation missed this
consideration.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
879,2020-03-26T12:48:10Z,2020-03-26T14:43:49Z,,,"This commit updates `west.yml` to point to the `hal_atmel` commit that
fixes the incorrect GMAC priority queue register offsets for SAMV71.

Signed-off-by: Stephanos Ioannidis <root@stephanos.io>",59771425
880,2020-03-26T12:44:55Z,2020-03-26T13:47:01Z,,,Renaming of nRF91 DK in the tree (board target names and documentation),59771425
881,2020-03-26T09:05:43Z,2020-03-26T16:25:05Z,,,"Warnings are generated with newlibc about incorrect format specifier (%d for long int) because newlibc defines off_t as long int. Change %d format specifier to %ld for logging of offsets and cast offset to long int to support both newlibc and the minimal c library which defines off_t as int.

Signed-off-by: Thomas Schmid <tom@lfence.de>",59771425
882,2020-03-25T23:46:19Z,2020-03-26T15:36:01Z,,,"Add driver for nRF AES Electronic CodeBook (ECB) peripheral

Signed-off-by: Maciej Fabia <maciej.fabia@nordicsemi.no>",59771425
883,2020-03-25T22:58:49Z,2020-03-26T01:05:06Z,,,"* Implement missing verification handler
* Fix two implementation handler names
* Pass struct by reference in syscall APIs

Fixes: https://github.com/zephyrproject-rtos/zephyr/issues/23750",59771425
884,2020-03-25T21:23:44Z,2020-03-26T17:44:54Z,,,"And implement DT_ANY_INST_ON_BUS() in terms of it.

This makes some error messages quite a bit shorter by avoiding
UTIL_LISTIFY(), which has a nasty temper and tends to explode if not
treated gently.
",59771425
885,2020-03-25T17:21:49Z,2020-03-26T18:50:46Z,,,,59771425
886,2020-03-25T16:35:03Z,2020-03-26T16:23:39Z,,,"Fix warning ""Failed to add IRK to controller"" during pairing procedure.

Move runtime keys flag out of the key storage area.",59771425
887,2020-03-25T16:19:09Z,2020-03-25T16:56:36Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
888,2020-03-25T16:18:42Z,2020-03-25T20:55:21Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
889,2020-03-25T16:18:29Z,2020-03-25T16:18:29Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
890,2020-03-25T15:38:55Z,2020-03-25T16:17:39Z,,,"PWM and other flags were missing for PCA10059.
Aligned also RAM and Flash while comparing the files.

Signed-off-by: Markus Becker <markus.becker@tridonic.com>",59771425
891,2020-03-25T15:31:14Z,2020-03-26T17:26:10Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
892,2020-03-25T15:30:33Z,2020-03-26T17:27:08Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
893,2020-03-25T15:26:39Z,2020-03-25T15:28:56Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
894,2020-03-25T15:26:01Z,2020-03-25T15:28:08Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
895,2020-03-25T15:23:24Z,2020-03-26T17:29:30Z,,,"Convert older DT_INST_ macro use the new include/devicetree.h
DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
896,2020-03-25T13:46:17Z,2020-03-25T15:18:02Z,,,"Convert older DT_INST_ macro use in arm_cmsdk/arm drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
897,2020-03-25T12:19:02Z,2020-03-25T22:30:24Z,,,"Split script into a callable exe and a module with all classes and remove usage
of arguments as globals where possible to make testing with pytest easier.",59771425
898,2020-03-25T11:35:25Z,2020-03-25T13:44:07Z,,,"Introduce TX mode parameter in the `tx` API:
* Existing drivers will use `IEEE802154_TX_MODE_DIRECT` if they did not report CSMA/CA capability or `IEEE802154_TX_MODE_CSMA_CA` if they did.
* Add CSMA/CA support to `ieee802154_nrf5`.
* Use the new feature in OpenThread.",59771425
899,2020-03-25T11:20:45Z,2020-03-26T19:04:18Z,,,These commits adds support for the MCP3204/MCP3208 12-bit ADCs from Microchip.,59771425
900,2020-03-25T10:19:15Z,2020-03-25T10:33:41Z,,,"Unit tests for the time calculations in the DLE update procedure.
This is a first implementation, optimisation is possible

Signed-off-by: Andries Kruithof <Andries.Kruithof@nordicsemi.no>",59771425
901,2020-03-25T09:33:46Z,2020-03-26T08:46:18Z,,,,59771425
902,2020-03-24T21:29:47Z,2020-03-25T22:01:32Z,,,"No check of the driver object was being performed for two
APIs.

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>
Signed-off-by: Flavio Ceolin <flavio.ceolin@intel.com>",59771425
903,2020-03-24T21:23:44Z,2020-03-25T11:33:20Z,,,"Convert older DT_INST_ macro use in sifive drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
904,2020-03-24T21:16:17Z,2020-03-26T14:13:15Z,,,"Convert older DT_INST_ macro use in nrf drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
905,2020-03-24T21:01:44Z,2020-03-25T02:13:24Z,,,"Convert older DT_INST_ macro use in litex drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
906,2020-03-24T21:01:22Z,2020-03-25T21:43:09Z,,,"Make some sample changes as well.

Tested with two devices at the same time, one on each bus.",59771425
907,2020-03-24T20:54:38Z,2020-03-24T23:16:50Z,,,"Convert older DT_INST_ macro use in atmel sam drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
908,2020-03-24T20:51:51Z,2020-03-25T17:41:00Z,,,"Convert older DT_INST_ macro use in atmel sam0 drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
909,2020-03-24T20:51:19Z,2020-03-24T21:07:18Z,,,"Convert older DT_INST_ macro use in openisa drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
910,2020-03-24T20:49:32Z,2020-03-26T19:43:30Z,,,"No driver object checks were being performed for 3 APIs.

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>
Signed-off-by: Flavio Ceolin <flavio.ceolin@intel.com>",59771425
911,2020-03-24T20:48:30Z,2020-03-25T02:14:12Z,,,"Convert older DT_INST_ macro use in microchip drivers to the new
include/devicetree.h DT_INST macro APIs.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
912,2020-03-24T20:23:39Z,2020-03-24T20:26:36Z,,,,59771425
913,2020-03-24T19:00:18Z,2020-03-24T21:04:49Z,,,"Example how to use enc28j60 Ethernet controller.

Signed-off-by: Jukka Rissanen <jukka.rissanen@linux.intel.com>

As agreed in API meeting, here is a sample for enc28j60 Ethernet controller. This initial version is using black_f407ve board as that was the only one that I had setup to use enc28j60. Other boards can be added by placing proper config files to board directory and adding whitelisting entries to sample.yaml file.",59771425
914,2020-03-24T17:32:44Z,2020-03-26T16:12:41Z,,,"Document the meaning of the pin numbers by providing a reference to
the underlying HAL function used to decode them.
",59771425
915,2020-03-24T16:51:16Z,2020-03-24T16:58:46Z,,,,59771425
916,2020-03-24T15:10:29Z,2020-03-26T14:43:42Z,,,"- added SERIAL_SUPPORT_INTERRUPT in Kconfig.xlnx
- fixed UART_XLNX_PS_IRQ_CONF_FUNC macro which only worked for UART0,
  but not for UART1.

Interrupt support is required for test cases using the UART_PIPE feature
on the upcoming Cortex-A9 targets (QEMU/Zynq-7000).

Signed-off-by: Immo Birnbaum <Immo.Birnbaum@weidmueller.com>",59771425
917,2020-03-24T12:26:21Z,2020-03-26T17:03:53Z,,,"Add possibility to change the measurement modes
of the temperature and humidity measurements to
continuous or single-shot mode or switch them off.

Signed-off-by: Christian Hirsch <christian.hirsch@tuwien.ac.at>",59771425
918,2020-03-24T08:40:45Z,2020-03-24T08:47:10Z,,,"Updated sample config to allow emulation of 8-bit write block.
(because the nRF Flash driver has changed its default write block size
 to 32-bit aligned)

Signed-off-by: Perkowski, Maciej <Maciej.Perkowski@nordicsemi.no>",59771425
919,2020-03-24T07:51:10Z,2020-03-24T19:27:09Z,,,"Fix thread fault, on user mode, when reading variable rt_clock_base.
For the moment, clock_settime is left without system call:
we don't want to expose clock_settime without figuring out access
control

Signed-off-by: Julien D'Ascenzio <julien.dascenzio@paratronic.fr>",59771425
920,2020-03-24T07:37:15Z,2020-03-26T10:14:55Z,,,"Fix implementation to handle back-to-back and duplicate
LENGTH_REQ PDU reception.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
921,2020-03-24T07:35:20Z,2020-03-26T10:10:19Z,,,"Fix implementation to handle back-to-back and duplicate
LENGTH_REQ PDU reception.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
922,2020-03-24T07:32:25Z,2020-03-26T10:54:36Z,,,"Add validation of channel map and hop increment value
received in CONNECT_IND PDU.

Zero bit count leads to controller assert or divide-by-zero
fault.

Hop increment shall be between 5 and 16 by BT Specification.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
923,2020-03-24T07:30:52Z,2020-03-26T10:53:38Z,,,"Add validation of channel map and hop increment value
received in CONNECT_IND PDU.

Zero bit count leads to controller assert or divide-by-zero
fault.

Hop increment shall be between 5 and 16 by BT Specification.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
924,2020-03-23T19:54:04Z,2020-03-24T22:22:08Z,,,"A proof of concept for showing footprint data of a binary using
puncover.

First, install puncover:
```
pip3 install git+https://github.com/nashif/puncover
```

Then build some application using west...

and finally run:
```
west footprint
```

This will run a temporary webserver on the host system. Copy and paste
the address and browse the footprint information.",59771425
925,2020-03-23T16:51:56Z,2020-03-25T21:01:32Z,,,"ISR locking was missing in the UART driver for x86_64. This PR adds a spinlock mechanism to interrupt related services in the driver.

Fixes #23026 ",59771425
926,2020-03-23T14:12:02Z,2020-03-24T03:24:04Z,,,"edma rt series support. tested on mimxrt1060_evt
MEMORY_NOCACHE is needed

Signed-off-by: Hake Huang <hake.huang@oss.nxp.com>",59771425
927,2020-03-23T10:54:25Z,2020-03-24T08:57:41Z,,,"Add support for nested IRQs, enable the interrupts tests but blacklist
the qemu_cortex_a53 platform for unsupported tests.

Tested against the interrupt nested test by @stephanosio at #23636",59771425
928,2020-03-23T10:42:51Z,2020-03-24T09:51:52Z,,,,59771425
929,2020-03-23T08:48:27Z,2020-03-26T15:32:15Z,,,"Add driver and example for Infineon DPS310 temperature and pressure sensor.

This is a rebased version of #20187, since that PR went stale.

Signed-off-by: Christoph Reiter christoph.reiter@infineon.com",59771425
930,2020-03-23T07:45:54Z,2020-03-26T08:06:20Z,,,"Adds support for `stm32l433Xb`.
And add `I2C_1` and `CAN` pin of L4 series.

Signed-off-by: Kwon Tae-young <tykwon@m2i.co.kr>",59771425
931,2020-03-22T16:11:48Z,2020-03-22T19:20:30Z,,,"Per [request](https://github.com/zephyrproject-rtos/zephyr/pull/22087#issuecomment-580879560) this provides two features in font generation, described below.  I can't find the commits that actually used this to support displays that don't have a rotated natural orientation.

##  scripts: gen_cfb_font_header: extend to additional representations
    
The default vertical tiling is designed for displays that are rotated 90 or 270 degrees from normal orientation.  Devices where pixel data advances first horizontally then vertically requires horizontally-tiled data.

Similarly when generating upright text on a row-major-order monochrome display the most significant bit may encode the pixel at the lowest horizontal position.

Add options to control horizontal vs vertical tiling, and msb vs lsb pixel order.

The commit also generates the representation of the glyph in comments at each row.

##  subsys/cfb: move MSB_FIRST down to font capabilities
    
Font capabilities currently indicate whether font data is packed horizontally or vertically, and this is used to control frame buffer updates.  The font bit ordering should likewise be recorded in the font description, and any reversal to match the display applied when text is being set in the frame buffer.

## Example

I haven't included the patch that updates the generated fonts, but it would basically add comments like this alongside the glyph data.  Let me know if you want that.

```
        /* 38 (&) */
        {
                0x00,0x00,   /*                  */
                0x00,0x00,   /*                  */
                0x00,0x0e,   /*          ###     */
                0x70,0x19,   /*     ### #  ##    */
                0x88,0x10,   /*    #   #    #    */
                0xc8,0x13,   /*    #  ####  #    */
                0x70,0x0c,   /*     ###   ##     */
                0x00,0x1f,   /*         #####    */
                0x00,0x10,   /*             #    */
                0x00,0x00,   /*                  */
```

",59771425
932,2020-03-22T13:44:02Z,2020-03-22T13:46:13Z,,,Fix test cases to work with the loopback interface.,59771425
933,2020-03-22T13:33:46Z,2020-03-22T13:43:14Z,,,"Now there's an audio reference section move the i2s docs there
as the audio section is a better fit.

Signed-off-by: Peter Robinson <pbrobinson@gmail.com>",59771425
934,2020-03-22T05:47:48Z,2020-03-25T14:44:15Z,,,"Hello,

This PR adds initial LoRaWAN support to Zephyr by using the loramac-node library from Semtech. This LoRaWAN support is added as a subsystem and sits on top of existing LoRa so that the underlying radio drivers get reused. While doing so, I found that the original RTC/Counter implementation doesn't fit as most of the Counter drivers in Zephyr works with 1s granularity which is not enough for LoRaWAN stack. So, `k_timer` calls are used in place of Counter's alarm and `k_uptime_get` calls are used in place of Counter's time keeping. 

With the current support, a node can configure and send data to the network server via a gateway and also receive Acks in predefined window slots. A sample application is also included in this PR which demonstrates the CLASS-A functionality.

This PR has been verified using 96Boards Wistrio board and a SAMD21 board with SX1276 LoRa modem. Also, this has been tested in IN865 and EU868 region wherein EU868 the duty cycle restrictions are more strict so the sample application may not work correctly as it sends data in 5s interval.

**TODO:**
1. Add ABP join support 
2. Add CLASS-B and C support with sample application/documentation
3. Improve LoRaWAN support by detecting Tx notification for both confirmed and unconfirmed messages.
4. Add Socket support with a suitable compression/fragmentation method. For this, I've started [libschc](https://github.com/Mani-Sadhasivam/libschc) project.
5. Add tests for LoRa and LoRaWAN

This LoRaWAN project is a collaborative work and following developers deserve explicit acknowledgments for their commendable contributions:

**Kwon Tae Young** - https://github.com/KwonTae-young
**Kuba Sanak** - https://github.com/KubaFYI

For more discussions other than this PR, please join #zephyr-lorawan slack channel.

Thanks,
Mani",59771425
935,2020-03-21T20:22:47Z,2020-03-26T08:08:24Z,,,"With the STM32F4 I2C driver I ran into two problems;
1) the bug described in #22751 
2) EMC spikes cause the driver to hang so bad only a device reset can fix it.

Especially the resetting of the device is tricky, because it also resets all settings like bitrate. 

The fixes in these commits fix my problem, the hardware ran more than 300 hours nonstop with 10 I2C transactions per second. Without the fixes it doesn't last more than a few minutes before it hangs. 

The EMC problem only happened about every 30 hours, so a pain to debug, until I found out short circuiting SDA to GND will trigger it on command.

Fixes #22751.",59771425
936,2020-03-21T14:49:11Z,2020-03-24T16:35:23Z,,,Change the API status of the HWINFO API from unstable to stable.,59771425
937,2020-03-21T11:58:52Z,2020-03-23T21:00:05Z,,,"Created as separate PR from PR #21245 per request in https://github.com/zephyrproject-rtos/zephyr/pull/21245#pullrequestreview-378610271.

First two commits are directly from PR #21277 

@galak Please review. Thanks!",59771425
938,2020-03-21T10:25:12Z,2020-03-26T18:32:48Z,,,"Added device tree nodes and associated headers for
defined uarts on the stm32g0 and stm32g07x 8x parts.

Tested with uart on stm32g071rb disco board with usart3 going to stlink.
Using shell.

needs https://github.com/zephyrproject-rtos/zephyr/pull/23657 pinmux

Signed-off-by: Kieran Levin <ktl@frame.work>",59771425
939,2020-03-21T10:17:41Z,2020-03-26T15:47:19Z,,,"JEDEC compatible spi nor devices are not required to have a
standard page and sector size as well as supported erase sizes. The
JEDEC SFDP headers supports up to four erase types with configurable
size and op-code.
Make page size and erase types configurable. The defaults reflect the old
behaviour. None default parameters are added to spi_nor.c and are
enabled by a second devicetree compatible string with exact device name
(e.g. compatible: ""cypress,s25fl512s"",""jedec,spi-nor"").

Remove has-be32k property because it is never read.

Fixes  #23322
Fixes  #23673

Signed-off-by: Thomas Schmid <tom@lfence.de>",59771425
940,2020-03-21T03:09:46Z,2020-03-26T20:10:27Z,,,"Add complete definitions for pinmux alt functions for these series of parts. 

Tested with uart on stm32g0 disco board. 
Files generated from datasheet. 
Signed-off-by: Kieran Levin <ktl@frame.work> ",59771425
941,2020-03-20T21:14:48Z,2020-03-23T11:36:51Z,,,Backporting #23239 to v2.1 branch,59771425
942,2020-03-20T18:35:12Z,2020-03-21T11:02:02Z,,,"The following logs show up when trying to connect:

  uart:~$ wifi connect xxxxxx xxxxxxxxxx
  Connection requested
  [00:00:13.654,968] <dbg> net_wifi_mgmt.wifi_connect: (0x20000500): xxxxxx 6 255 1 xxxxxxxxxx 10
  [00:00:14.655,029] <err> log: argument 6 in source net_wifi_mgmt log message ""%s: (%p): %s %u %u %u %s %u"" missinglog_strdup().
  [00:00:14.655,029] <err> log: argument 2 in source net_wifi_mgmt log message ""%s: (%p): %s %u %u %u %s %u"" missinglog_strdup().
  Connected
  uart:~$

Fix that by using LOG_HEXDUMP_DBG() to print SSID and PSK.

Signed-off-by: Marcin Niestroj <m.niestroj@grinn-global.com>",59771425
943,2020-03-20T18:21:13Z,2020-03-26T19:42:08Z,,,"The third argument in memmove can possible be greater than remaining
buffer size. Just ensuring that memmove will changes bytes only inside
the string buffer and nothing else.

Signed-off-by: Flavio Ceolin <flavio.ceolin@intel.com>

Backporting #23304 to 2.1 branch",59771425
944,2020-03-20T16:57:54Z,2020-03-23T19:24:41Z,,,"This adds utility functions to irq.h in accordance with zephyr's
multi-level irq numbering schema. Functions that are added will
get the zephyr IRQ's level and provide functions to return the
interrupt number at a particular level.

Fixes issue #20338

Signed-off-by: Jaron Kelleher <jkelleher@fb.com>",59771425
945,2020-03-20T16:56:43Z,2020-03-26T20:00:31Z,,,"    Remove the dts_fixup.h with a DTS app overlay file instead.  We have
    sensors that show up on both the I2C and SPI busses, and we comment out
    the sensor to match how the tests work currently.
    
    The app.overlay utilizes the testing dts bindings to create test nodes
    that should not conflict with any existing SoC nodes.  Thus allowing the
    test to run on any platform.
",59771425
946,2020-03-20T13:43:32Z,2020-03-26T10:44:50Z,,,"```
arch: arm: aarch32: Rework non-Cortex-M context preservation 

The current context preservation implementation saves the spsr and
lr_irq registers, which contain the cpsr and pc register values of the
interrupted context, in the thread callee-saved block and this prevents
nesting of interrupts because these values are required to be part of
the exception stack frame to preserve the nested interrupt context.

This commit reworks the AArch32 non-Cortex-M context preservation
implementation to save the spsr and lr_irq registers in the exception
stack frame to allow preservation of the nested interrupt context as
well as the interrupted thread context.

Signed-off-by: Stephanos Ioannidis <root@stephanos.io>
```

Includes the commits from #23518 and #23614.

Closes #22670.",59771425
947,2020-03-20T13:35:57Z,2020-03-20T13:46:59Z,,,"Add an optional weighted average filter to the ADC readings in the NXP Kinetis temperature sensor driver as recommended in NXP AN3031.
   
Improve the code readability and traceability towards NXP AN3031 by using the same variable name as in the application note. Separate the multiplication to millidegrees from the adcr_1000m multiplication.
",59771425
948,2020-03-20T10:53:23Z,2020-03-20T13:23:15Z,,,"Use a smaller ordinal type than int to hold the global index identifying devices that support power management.

Use an upper bound instead of an array of flags to identify the devices that were successfully suspended.

Only attempt pm on devices that provide a non-default pm control function.

Use shorter more descriptive names for state variables.",59771425
949,2020-03-20T10:44:13Z,2020-03-24T08:19:10Z,,,"These functions must be defined as system calls.
That permits global variable rt_clock_base to be read correctly on user mode.",59771425
950,2020-03-20T10:20:56Z,2020-03-23T16:56:55Z,,,"Unaligned read-out capability become fact among all drivers.
Let's cut this in stone as API requirement.

fixes #16439

Signed-off-by: Andrzej Puzdrowski <andrzej.puzdrowski@nordicsemi.no>",59771425
951,2020-03-20T09:07:37Z,2020-03-26T14:30:36Z,,,"In order to de-duplicate 2 macros with the same use,
one of which is discouraged/deprecated, merge
BUILD_ASSERT(), BUILD_ASSERT_MSG() into one macro
and drop BUILD_ASSERT_MSG().

Previous PR: https://github.com/zephyrproject-rtos/zephyr/pull/23437

@carlescufi @utzig @nvlsianpu @anangl @nashif

If there's still an interest, let's proceed:

1. Upgrade mcuboot JuulLabs-OSS/mcuboot#682
2. Upgrade hal_nordic zephyrproject-rtos/hal_nordic#29
3. I could then drop the manifest changes in this PR.",59771425
952,2020-03-19T21:32:55Z,2020-03-25T18:29:34Z,,,"The ft5336 has an interrupt that can be used instead of polling
this commit adds support for using it but as an option to maintain
compatibility. Tested on the stm32f746g_disco board.

Signed-off-by: Mark Olsson <mark@markolsson.se>",59771425
953,2020-03-19T20:20:15Z,2020-03-20T09:31:29Z,,,"This is expected to work on all platforms.

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>",59771425
954,2020-03-19T17:26:53Z,2020-03-26T10:48:58Z,,,"The current nested interrupt test implementation is both buggy and
fundamentally flawed because it does not trigger a higher priority
interrupt from a lower priority interrupt context and relies on the
system timer interrupt, which is not fully governed by the test;
moreover, the current implementation does not properly validate the
test results and can report success if no interrupt is triggered and
serviced at all.

This commit reworks this test to have the following well-defined
and logical procedure:

1. [thread] Trigger IRQ 0 (lower priority)
2. [isr0] Set ISR 0 result token and trigger IRQ 1 (higher priority)
3. [isr1] Set ISR 1 result token and return
4. [isr0] Validate ISR 1 result token and return
5. [thread] Validate ISR 0 result token

The reworked test scenario ensures that the interrupt nesting works
properly and any abnormal conditions are detected (e.g. interrupts not
triggering at all, or ISR 1 not being nested under ISR 0).

Signed-off-by: Stephanos Ioannidis <root@stephanos.io>

Closes #23593",59771425
955,2020-03-19T16:42:19Z,2020-03-26T10:00:54Z,,,"The first commit adds support for the ft5336 touch panel on the stm32f746g_disco board. It enables the driver and adds the relevant device tree config. It's dependent on the I2C_3 device so this is enabled also.

The second commit adds a sample application so it can be tested. It's tested on the stm32f746g_disco board, but should work on other boards for example the mimxrt1060_evk.",59771425
956,2020-03-19T14:45:54Z,2020-03-26T09:38:10Z,,,"This commit makes cdc class to omit notifications about
interfaces swap that may happen if cdc is configured together
with audio.

Signed-off-by: Johan Carlsson <johan.carlsson@teenage.engineering>
Signed-off-by: Emil Obalski <emil.obalski@nordicsemi.no>",59771425
957,2020-03-19T13:55:43Z,2020-03-23T15:22:23Z,,,"Applies the example PAN58 workaround code from Nordic document:
nRF52832_Rev_2_Errata_v1.4.pdf

Requires the user to config which PPI and GPIOE channels the workaround uses
for each SPIM.

Replaces the previous kconfig symbol
SOC_NRF52832_ALLOW_SPIM_DESPITE_PAN_58 which enabled the SPIMs despite
PAN58 but didn't apply a workaround for the issue with NRF52832_SPIM_PAN58_WORKAROUND.",59771425
958,2020-03-19T13:33:00Z,2020-03-26T14:53:46Z,,,"Custom commands must depend on both the input files and the wrapper
targets for the input files.

See Sam Thursfield's blog post about ""CMake: dependencies between
targets and files and custom commands"" for why.

This fixes #23562",59771425
959,2020-03-19T12:59:21Z,2020-03-24T16:57:45Z,,,"This PR separates generic resource management updates that appear to be nearly stable from #23229.  The changes are:

* refactors the onoff service to reduce space by putting static configuration data into a separate structure;
* extracts the async notification infrastructure from the on-off service into a self-contained structure that can be used anywhere asynchronous operations may be used;
* recasts the on-off service as a manager that is to be used by services (including API changes to make it more consistent with other managers to come);",59771425
960,2020-03-19T09:41:57Z,2020-03-25T10:17:31Z,,,"Add a new test to measure the smallest possible memory footprint zephyr application


Signed-off-by: peng1 chen <peng1.chen@intel.com>
",59771425
961,2020-03-19T07:54:34Z,2020-03-21T20:52:00Z,,,"
Fixes #23482.

There is a bug in calculation of time for the DLE procedure:
the preamble size is incorrect for the 2M phy

This is for the legacy code, see PR #23570 for the split controller

Signed-off-by: Andries Kruithof <Andries.Kruithof@nordicsemi.no>",59771425
962,2020-03-19T07:17:52Z,2020-03-26T14:20:56Z,,,"This PR is based on #20386 and tries to showcase pinctrl implementation that is closer to the way pinctrl subsystem is implemented on Linux.

In this proposal the pinmux database is kept away from the SoC level DTS. Configuration is done fully within the board dts.

Three different examples of how pin configuration data could be encoded in `pinctrl` node are presented.",59771425
963,2020-03-18T21:43:17Z,2020-03-26T18:57:53Z,,,"- Enables PWM support for H7 series.
- Enables PWM on NUCLEO H743ZI board using the built-in red LED.",59771425
964,2020-03-18T19:07:01Z,2020-03-25T13:17:04Z,,,"Here is a quick draft to gather first comments on the idea.

Basically, this tries to address the necessary grounds for fixing #22941 point 4 and 5. Have a look there.

The proposed commits are not _functioning_ : no device data protection (master lock), no test, no real implementation on any of the device drivers etc... (you'll see why below)

My main concern here is how to make use of the proposed API. (namely: device_init_status(), device_call_status and device_check_status()).
- either each and every driver use it relevantly: i.e. `return device_init_status();` would be called by all device driver's init function, `return device_call_status();` by all their exposed API functions and finally `if (device_check_status()) ...` at the beginning of all the exposed API functions.
- or having something like the userland system, adding wrapping function around each of these functions.

First solution would be the most obvious one, though it would mean changing all existing drivers _and_ make sure all new one do not forget these. Feasible but tedious.
Second solution is imo too heavy, it would raise the stack usage of each and every API functions etc... Plus, it would be messing up where the userland design has its marks and that's a no-go.

Any idea of another possible solution?

That's why  I did not went further than this. If the approach is wrong, better not to do too much useless stuff.

This would also help to fix #22941 point 7. The dev->device_api pointer should be constant and stay that way. And thus each and every struct device would be also constant. That would help to push stuff into ROM etc... ",59771425
965,2020-03-18T15:14:08Z,2020-03-26T08:33:04Z,,,"A bug in the PKT_US resulted in wrong calculations for the 2M phy.
Fixes the bug, verified on EBQ.
Also adds some defines for improved readability.

See also PR #23557 which is for the master branch

Fixes #23482

Signed-off-by: Andries Kruithof <Andries.Kruithof@nordicsemi.no>",59771425
966,2020-03-18T14:32:23Z,2020-03-19T13:47:21Z,,,"When mode is GPIO_INT_MODE_DISABLED, icr be set to 0.
If gpio is low level, will contiune go into int.
The flow is error.
Only disable it and exit.

Signed-off-by: Frank Li <lgl88911@163.com>",59771425
967,2020-03-18T13:16:48Z,2020-03-24T22:19:53Z,,,"This PR is the first from a series of PRs related to the EOS S3 ecosystem.

EOS S3 is a Cortex-M4-F based platform with an FPGA and a sensor processing subsystem.

The series will add support for the SoC itself, for the boards and several drivers.

More to read:

- QuickLogic EOS S3 description: https://www.quicklogic.com/products/eos-s3/
- QuickFeather board press release: https://antmicro.com/blog/2020/03/quickfeather-release/

The series will consist of the following PRs:

- [x] EOS S3 SoC
- [x] QuickLogic Chandalar board
- [ ] QuickLogic QuickFeather board
- [ ] GPIO support
- [ ] SPI support
- [ ] on-board FPGA support",59771425
968,2020-03-18T13:11:10Z,2020-03-26T10:58:21Z,,,"Update implementation of master and slave LLL's to correctly
handle event counter values when latencies introduced due to
connection events cancelled by active events operating in
unreserved time space.

When an active radio event extends into unreserved time
space, and a connection event prepare is scheduled but at
the time of pre-emption timeout if the connection event is
cancelled then the event count and latencies needs to be
continiued to get acummulated.

In the current controller usecases the above scenarios does
not get exercised, the changes in this commit is needed for
future roles that can extend into unreserved time space and
would cancel a scheduled connection event.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
969,2020-03-18T12:41:15Z,2020-03-26T16:12:31Z,,,"Add a disk access driver for the stm32 sdmmc component. The driver is
based around the stm32 cube HAL and uses the blocking API.

Signed-off-by: Anthony Brandon <anthony@amarulasolutions.com>",59771425
970,2020-03-18T12:24:03Z,2020-03-18T12:27:06Z,,,"The ""net stacks"" shell command support was just removed, but
the net_stacks linker section was left around.

Signed-off-by: Jukka Rissanen <jukka.rissanen@linux.intel.com>",59771425
971,2020-03-18T12:18:00Z,2020-03-24T14:55:01Z,,,"Add support for TI BQ27421 fuel gauge sensor

Signed-off-by: Parthiban Nallathambi <parthiban@linumiz.com>

Based on https://github.com/zephyrproject-rtos/zephyr/issues/2542#issuecomment-400299162",59771425
972,2020-03-18T11:31:34Z,2020-03-26T08:34:02Z,,,"This PR fixes #23482. The preamble size for a 2M phy was incorrect.

There is a bug in calculation of time for the DLE procedure:
the preamble size is incorrect for the 2M phy

This is for the legacy code, see PR #23557 for the split controller
Fixes #23482

Signed-off-by: Andries Kruithof <Andries.Kruithof@nordicsemi.no>",59771425
973,2020-03-18T09:47:04Z,2020-03-26T07:12:37Z,,,"DEPENDS ON:
~~https://github.com/zephyrproject-rtos/tinycbor/pull/13~~
~~https://github.com/apache/mynewt-mcumgr/pull/74~~
~~https://github.com/zephyrproject-rtos/mcumgr/pull/18~~
~~https://github.com/JuulLabs-OSS/mcuboot/pull/688~~


Update provides fix for TinyCBOR include paths not being added into
compilation, unless MCUMGR has also been selected.

Addresses GH issue: #23324

Signed-off-by: Dominik Ermel <dominik.ermel@nordicsemi.no>

NOTE: This PR replaces https://github.com/zephyrproject-rtos/zephyr/pull/23342, from branch incorrectly pushed to zephyrproject.",59771425
974,2020-03-18T09:38:06Z,2020-03-24T20:15:46Z,,,"This work add support for first STM32 Cortex-M33 based Series.
Support for board nucleo_l552_q is also added with minimum peripheral support for now.",59771425
975,2020-03-18T05:28:23Z,2020-03-26T11:00:39Z,,,"Fix regression in handling invalid packet sequence in the
first packet in a connection.

This relates to commit 62c1e1a52bcf (""Bluetooth: controller:
split: Fix assert on invalid packet sequence"")

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>

--------------

Backport of #23516",59771425
976,2020-03-18T03:20:42Z,2020-03-25T07:17:52Z,,,"1. With CONFIG_KERNEL_DEBUG enabled, kernel debug message will be output
    by printk. However this sample has logging enabled also, so enable
    LOG_PRINTK to have logging system processing printk.
2. Abort thread when finish testing to keep next testing clean.

Fixes: #23274",59771425
977,2020-03-17T22:11:47Z,2020-03-23T20:40:06Z,,,"Adding support for nRF9160 based InnBlue board V2.1. Supports both
Secure and Non-Secure configurations along with various sensors
(lis2dh12 / hts221) and devices(i2c / pwm).

Signed-off-by: Oleh Lozynskyy <olsky@users.noreply.github.com>",59771425
978,2020-03-17T18:14:49Z,2020-03-19T19:02:24Z,,,"These are now indexed by CPU.

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>",59771425
979,2020-03-17T17:25:12Z,2020-03-18T07:51:09Z,,,"This is now done as soon as we swap into the main thread
entry, since we are no longer on the IRQ stack.

This simplifies arch code, with the caveat that there is
a brief window where interrupts are delivered before
the stack is initialized, and the stack usage of these
interrupts will not be measured.

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>",59771425
980,2020-03-17T14:24:33Z,2020-03-25T15:13:08Z,,,"Hi,
I'm working on a RTC driver for stm32. Currently in Zephyr, RTC is used as a counter. In my project, I would like to use it at a real clock time to timestamp my data. I also integrated this driver in  clock_[get/set]time. I'm open to all suggestions to improve it. In the future, I would like to integrate also alarm",59771425
981,2020-03-17T13:19:23Z,2020-03-25T21:36:58Z,,,"The nRF52840 DK board target, so far known as nrf52840_pca10056, is renamed to nrf52840dk_nrf52840.
Its documentation and all references to its name in the tree are updated accordingly. Overlay and configuration files specific to this board are also renamed, to match the new board name.

In the same manner nrf52811_pca10056 (which in fact uses nRF52840 DK for emulation of nRF52811) is renamed to nrf52840dk_nrf52811.

This PR contains also a slight update of the nRF52840 DK documentation and its picture.",59771425
982,2020-03-16T18:58:59Z,2020-03-24T12:50:37Z,,,"UP should just use _kernel.cpus[0].

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>",59771425
983,2020-03-16T18:00:58Z,2020-03-26T19:42:50Z,,,"blt is signed comparsion, if r6 is a negative number created by
malicious code, it will pass the check, bring a secure risk.

use blo (unsinged comparison) to do the check.

Signed-off-by: Wayne Ren <wei.ren@synopsys.com>
Signed-off-by: David Brown <david.brown@linaro.org>

(backport of #23328)",59771425
984,2020-03-16T17:43:24Z,2020-03-17T18:05:07Z,,,Backport pr23323 to v2.1.,59771425
985,2020-03-16T17:02:26Z,2020-03-24T10:42:56Z,,,"The ""User LD2"" led is connected to pin PE1 and its color is yellow on the nucleo_h743zi board.
Connections in the dts file are fixed.

Signed-off-by: Juan Vega juan.vega25@gmail.com",59771425
986,2020-03-16T14:18:39Z,2020-03-18T19:19:08Z,,,"Extended onoff to be capable of canceling requests/releases at any point, for any client.
After this change, cancel behave the same way for each client. By now, last client was left in the difficult position since his operation could not be cancelled.
It supports also double cancellation (cancellation of cancellation).
There is always at least one client to notify about operation error.

With this feature, implementation of notifier becomes trivial. Updated notifier.

Modified notifier API to always return result through callback and aligned tests.

Notifier tests are passing after this change. On another branch (with onoff from master) there are tests for onoff cancelation extension which are passing.

This PR in this form is not intended to be merged, it's only for discussion.

Note: notifier implementation is in draft case (e.g. atomic flags access missing, etc.), mainly to showcase capabilities of onoff cancel feature.",59771425
987,2020-03-16T10:13:05Z,2020-03-25T10:52:03Z,,,"- Added notification callback to radio api and implemented TX started notification for nrf radio.
- Created worker thread for OpenThread
- Made radio TX run in worker thread to allow alarms handling in main ot thread while tx is pending.
- Implemented TX started notification for open thread (needed for radios not supporting ACK timeouts)
- Reworked OpenThread task to use msgq instead of semaphores to pass arguments with the event and process events in order they appear.",59771425
988,2020-03-16T09:58:12Z,2020-03-19T13:18:18Z,,,"Rework scsi cb handling.
- add header for mandatory command set
- fix inquiry command
- add basic sense data handling (ASC and ASCQ)
- work towards to pass MSC CV and scsi_mandat without warnings",59771425
989,2020-03-16T02:43:24Z,2020-03-24T14:24:56Z,,,"Adding RFC1350 compliant support for TFTP Client in Zephyr. The
current implementation is minimal and only supports the ability
to get a file from the server.

Things for the future include support for putting files to
server and adding support for RFC2347.

Signed-off-by: Oleh Lozynskyy <olsky@users.noreply.github.com>",59771425
990,2020-03-15T22:46:36Z,2020-03-16T11:19:34Z,,,"In two cases where we use the interrupt stack
in cortex-m reset.S, namely
- when we initialize the interrupt stack, and
- when we set PSP to the beginning of it
we should be considering the actual size of the stack, i.e.
including the MPU Stack Guard when applicable. By fixing
that in this commit we are able to use a bit of more
space during Zephyr boot (in normal kernel operation
the whole interrupt stack is used anyways).

Signed-off-by: Ioannis Glaropoulos <Ioannis.Glaropoulos@nordicsemi.no>

That's a _very_ minor enhancement only.",59771425
991,2020-03-15T14:09:10Z,2020-03-16T11:31:20Z,,,"Allows users to change the timeout for connection initiation at run-time, while retaining current interfaces and behavior.

Removing the const qualifier from bt_le_create_conn is not ideal, but issue #22834 needs to be solved before it can be reverted.

Tested against out-of-tree repo.

Fixes #23468",59771425
992,2020-03-15T13:45:24Z,2020-03-16T19:25:55Z,,,Signed-off-by: Mohammad Jamal Mohiuddin <md.jamalmohiuddin@gmail.com>,59771425
993,2020-03-14T14:04:16Z,2020-03-16T15:27:34Z,,," For the timer cases, original test case is
only validate monotonic timer's clock calibration for 1 second,
so added 3 new test cases below for timer test with 1ms.

1.Validates monotonic timer's clock calibration for 1 ms
2.Validates one shot timer's clock calibration for 1 ms
3.Validates period timer's clock calibration for 1 ms

Signed-off-by: xuhao <hao.xu@intel.com>",59771425
994,2020-03-14T11:18:50Z,2020-03-21T09:20:10Z,,,"Add Virtual LAN support to enc424j600 Ethernet driver.

Signed-off-by: Jukka Rissanen <jukka.rissanen@linux.intel.com>",59771425
995,2020-03-13T23:37:52Z,2020-03-20T10:03:16Z,,,"The driver issues a READREQ for every access to the COUNT register which causes 180us of delay.  This is a large delay that causes several problems with other systems including i2c and power management.

This commit uses continuous read requests (RCONT) to optimize accessing the COUNT register.  This reduces (but does not eliminate) the time spent synchronizing the COUNT register.

This commit also prevent interrupts from corrupting COUNT and COMP register access.

The kernel does not like it when the RTC does not tick after waking from sleep. RCONT enables continuously syncing the COUNT register but after sleep, we need to wait for a new read request to complete. However, the SYNCBUSY flag is not set when RCONT is enabled so we cannot use that to do the sync. So, we wait for the RTC COUNT register to begin ticking again by reading the COUNT register.

We should wait a minimum of the TICK_THRESHOLD which is the amount of time it takes to sync the register.

Fixes #21549
Fixes #21114
Fixes #21092
",59771425
996,2020-03-13T23:04:54Z,2020-03-26T19:43:04Z,,,"During DFU_UPLOAD, the host could requests more data
as stated in wTransferSize. Limit upload length to the
size of the request buffer (USB_REQUEST_BUFFER_SIZE).

Signed-off-by: Johann Fischer <j.fischer@phytec.de>
Signed-off-by: David Brown <david.brown@linaro.org>

Backport #23190",59771425
997,2020-03-13T22:43:22Z,2020-03-21T20:49:45Z,,,"Check if LBA is in range of the memory size.

Signed-off-by: Johann Fischer <j.fischer@phytec.de>
Signed-off-by: David Brown <david.brown@linaro.org>

backport #23240",59771425
998,2020-03-13T21:14:43Z,2020-03-26T15:07:49Z,,,"As a prerequisite for enabling LTDC on STM32, this pull request enables using the external SDRAM on the STM32f746g_discovery board as the main memory. It does this by configuring it at boot and then jumping to the zephyr code.

Closes #15944

Signed-off-by: Mark Olsson <mark@markolsson.se>",59771425
999,2020-03-13T19:26:39Z,2020-03-24T08:48:12Z,,,"Dear all,

I would like to add one of our nrf91 boards to main.

please review and accept.
thank you",59771425
1000,2020-03-13T18:05:00Z,2020-03-26T10:13:24Z,,,,59771425
1001,2020-03-13T14:59:56Z,2020-03-17T18:02:43Z,,,"Added libgit2 to required tools, and added a note to clarify
how to ensure that Python 3 is used.

Signed-off-by: Ruth Fuchss <ruth.fuchss@nordicsemi.no>",59771425
1002,2020-03-13T13:30:05Z,2020-03-13T14:22:41Z,,,Add example API for #23441.,59771425
1003,2020-03-12T21:38:54Z,2020-03-20T19:25:51Z,,,"This change adds full shared floating point support for the RISCV
architecture with minimal impact of threads with floating point
support not enabled.

Signed-off-by: Corey Wharton <coreyw7@fb.com>",59771425
1004,2020-03-12T12:51:10Z,2020-03-17T14:11:32Z,,,"This is still WIP as there is some issue to talk to modem after the DLCIs have been established with the modem. Continuing this in public hoping to get some hints what is wrong in the code.

@mike-scott the mux and modem iface code looks quite convoluted atm. The function interface to the modem_iface is a bit awkward to use so we could improve something in this front. Probably it could be a good idea to create proper APIs for the modem connectivity in the future.

We would also need a way to read/write other channels than PPP from userspace, like sending/receiving SMSs, reading location data etc. One option for this could be to enhance the BSD socket API to support something like this.",59771425
1005,2020-03-11T18:01:13Z,2020-03-26T17:41:06Z,,,"Original struct device was only meant for actual devices. But its infrastructure has been then used also for non-hardware based boot-time critical piece of software. Though this was a simple solution, it brought the device concept to non-device systems. 

So refactoring all of this in order to get rid of struct device from these systems, as well as clarifying the struct device as well. 

This leads to some bytes saved from both ROM and RAM.",59771425
1006,2020-03-11T14:32:51Z,2020-03-25T21:36:34Z,,,"Add a driver that can handle several instances of AT45D family chips, which are enabled by specifying DT nodes for them with the ""compatible"" property set to ""adesto,at45d"" and other required properties like JEDEC ID, chip capacity, block and page size etc. configured accordingly.

The driver is only capable of using ""power of 2"" binary page sizes in those chips and at initialization configures them to work in that mode (unless it is already done).

A sample application is also provided, intended to present capabilities of the driver and to serve as a reference of how to make use of the driver.",59771425
1007,2020-03-11T14:03:26Z,2020-03-20T07:51:36Z,,,"Implemented:
- automatic detection of modem type (Sara R410 or Sara U201)
- automatic setting of APN, depending on inserted SIM card

Automatic detection of the modem type:

After hardware initialisation of the modem, the type of modem
is detected. After this, further initialisation and functionality
is chosen depending on the detected modem type.

To enable this functionality, set following bool in Kconfig:
   MODEM_UBLOX_SARA_AUTODETECT_VARIANT

Automatic setting of APN:

During communication initialisation, the IMSI of the inserted SIM
card is evaluated to determine the APN. This is done by comparing
the first 5 characters of the IMSI to a list of known providers.
The list can be given in Kconfig.

To enable this functionality, set following bool in Kconfig:
   MODEM_UBLOX_SARA_AUTODETECT_APN

To set a list of providers, set following string:
   MODEM_UBLOX_SARA_AUTODETECT_APN_PROFILES

If the provider can not be found in the list, the APN given in
following entry is used as a fallback:
   MODEM_UBLOX_SARA_R4_APN

Signed-off-by: Hans Wilmers <hans@wilmers.no>",59771425
1008,2020-03-11T13:45:15Z,2020-03-25T15:57:01Z,,,"Test application and example configuring the spi  peripheral as a client of the dma.
In case the stm32 soc has a dma multiplexer, the peripheral request is defined by the client and any dmamux channel is used for transfer. 
In case the stm32 has no multiplexer, the dma channels and the requests are fixed by the client.
The DT is filled with parameters to set the peripheral request on the dmamux or the dma (if no mux)
The dma or dmamux channels used for the client transfer (rx, tx) are assigned by the DT among the total nb of channels.
Tested on nucleo_wb55rg board
Also tested on nucleo_l476rg board, where the dma requests are fixed (no multiplexer)
Also tested on nucleo_f411re board, where the dma V1 requests are fixed (no multiplexer)

Requires https://github.com/zephyrproject-rtos/zephyr/pull/23157
Requires #22021
Requires https://github.com/zephyrproject-rtos/zephyr/pull/23155/

Fix https://github.com/zephyrproject-rtos/zephyr/issues/20825

Signed-off-by: Francois Ramu francois.ramu@st.com",59771425
1009,2020-03-11T11:05:11Z,2020-03-26T10:55:59Z,,,"When enabled, instead of erasing entire flash page at once, page will
be erased in defined time slices. Erasing single page stalls CPU
for significant time share (~80ms) and partial erase divides the
operation in to the shorter time periods, resuming CPU operation in
meantime and enabling better scheduling of time sensitive operations.

Signed-off-by: Dominik Ermel <dominik.ermel@nordicsemi.no>",59771425
1010,2020-03-11T10:12:50Z,2020-03-12T16:59:42Z,,,"Added SPI flash definition on SPI1.

Signed-off-by: Richard Osterloh <richard.osterloh@gmail.com>",59771425
1011,2020-03-10T20:57:29Z,2020-03-24T21:41:21Z,,,"Big (but less so than the first version) API rework to make timeouts an opaque type, allowing for  their specification in alternate representations like 64 bit types, higher precision units and absolute/uptime values.

See #21305 for the RFC detailing the changes.",59771425
1012,2020-03-10T15:24:29Z,2020-03-26T14:26:21Z,,,"More work on encryption
Cleanup
Fixes",59771425
1013,2020-03-10T12:10:27Z,2020-03-20T14:34:38Z,,,"### PR content:

- Proposed extension to i2c API:
  - It's is mainly addition of `i2c_single_transfer(dev, msg, add, callback, user_data)`.
  - ~~Extending `i2c_msg` flags to contain milliseconds delay field which can be used within sequence to delay message execution.~~
  - ~~Added helper macros for initializing set of message, e.g. `I2C_MSG_TXRX()`~~
  - Added function for getting `i2c_async` instance associated with given device: `i2c_get_async(dev)`
   
- Added new module `drivers/i2c/i2c_async` which wraps `queue_operation_manager` and `async_seq_manager` to provide safe and managed, asynchronous access to i2c.
  - Module is a fairly simple wrapper which binds those two modules together and finally uses `i2c_single_transfer()` to execute item within the sequence.
  - I2C sequence may consist of many `i2c_async_msg` items and may be constant, e.g. whole sensor initialization procedure can be stored in flash.
  - There are 3 message types:
    - transfer which contains `struct i2c_msg`
    - delay - sequence is delayed for milliseconds
    - pause - user provides function which is called when message is executed. Sequence is resumed using `i2c_async_resume()`.
  - `i2c_async` is a generic part and vendor specific driver implements only single transfer functionality (along with configure and getting async instance). This way specific driver is only focused on it's core functionality, all access management, semaphores, etc. is removed from the driver. It is in opposition to current state where each driver is implementing own mechanisms for access control.
  - `i2c_async` implements `z_i2c_async_sync_transfer` which is used to provide backward compatibility (it is called by `i2c_transfer`).

- Modified `i2c_nrfx_twim` driver to implement `i2c_single_transfer`

- Modified `hts221` sensor driver to show how to use i2c_async. This is temporary of course, just to show new way.

### How to control I2C using `i2c_async`?

Asynchronous access to i2c does not happen through i2c API because there can be multiple context accessing same i2c device. Access must be managed. `queued operation manager` is created to handle that generic task (see #23333) thus user is actually talking to `queued operation manager` API using handle to the manager associated with given i2c device. The manager works with `queued operations` object so i2c operation must contain queued operation structure. i2c operation consists of one or more `i2c_msg`. Messages build a sequence which is executed by the queue operation manager. Completion of the i2c operation is notified using `async notify` object (see #23229) which is part of the i2c operation. `async notify` standardizes methods of notification of completion of asynchronous operation.

Scheduling of asynchronous i2c is performed in following steps:
- create i2c operation (see `struct i2c_async_op` in `i2c_async.h`). Helper macros can be used to create it. Operation contains queued operation object and pointer to the sequence (pointer because sequence can be in flash and operation must be in rw memory).
- get `i2c_async` object to use. Use `i2c_get_async(dev)`.
- initialize `async_notify`. Use `i2c_async_get_notify(op)` to get async notify from the operation.
- submit operation `queue_operation_submit(mngr, op, PRI)`
- wait for notification about the completion

Example code:
```
/* create an operation with sequence */
I2C_ASYNC_OP_DEFINE(op, I2C_SENSOR_ADDRESS,
		I2C_ASYNC_MSG_TXRX(&reg_who_i_am, 1, &who_i_am, 1),
		I2C_ASYNC_MSG_PAUSE(who_i_am_validate),
		I2C_ASYNC_MSG_TX(reg_ctrl1, 2),
		I2C_ASYNC_MSG_DELAY(3),
		I2C_ASYNC_MSG_TXRX(&reg_conv, 1, conv_data, sizeof(conv_data))
	);

/* async instance */
struct i2c_async *i2c_async = i2c_get_async(i2c_dev);
struct async_notify *anotify = i2c_async_get_notify(&op);

/* get callback notification */
async_notify_init_callback(anotify, i2c_callback);

/* submit operation */
err = queued_operation_submit(i2c_async_get_qop_mgr(i2c_async), &op.op,
					QUEUED_OPERATION_PRIORITY_APPEND);
if (err < 0) {
	return err;
}
```

### Benefits
- operations can be submitted from interrupt context
- backward compatibility
- driver code focused on its functionality (single transfer)
- no need to extend i2c API with generic API (queued operation manager API used directly)
- similar approach can be applied to spi
- standardized asynchronous notification (async_notify)
- possibility to combine mulitple i2c operations into a sequence (e.g. init)
- possibility to pause a sequence (not added yet to i2c_async) which allows to combine operation like trigger sensor, wait for data rdy pin, read sensor into a single sequence.
- possibility to have single sensor implementation for spi or i2c bus with wrapper for creating messages (e.g. `SENSOR_BUS_MSG_TXRX()`, `SENSOR_BUS_OP_DEFINE`)

### misc

PR is based on unmerged work:
- `async_notify` #23229 
- `queued_operation` #23333
- `async_seq` #23075 

hts221 sensor changes commit will be removed from final PR

",59771425
1014,2020-03-10T11:12:34Z,2020-03-20T08:56:27Z,,,"Combined RX and TX time calculation for different PHY cases

Signed-off-by: Dag Bjarvin <Dag.Bjarvin@nordicsemi.no>",59771425
1015,2020-03-09T13:39:50Z,2020-03-26T08:56:03Z,,,"This pull request contains the recommendations from the Process Improvement Forum for minor amendments to the Zephyr TSC Project Roles section. 

To be merged, the PR requires approval by the TSC.",59771425
1016,2020-03-08T22:25:00Z,2020-03-13T21:01:22Z,,,This series of patches adds program download support for CANopen by implementing the CAN in Automation (CiA) 302-3 Draft Standard Proposal (DSP).,59771425
1017,2020-03-08T14:49:32Z,2020-03-20T11:28:29Z,,,"This PR supersedes #22853, providing a manager abstraction for a prioritized sequence of exclusive transactions on a service.  It is based on #23229.  Only the top few commits are specific to this PR; please comment on the onoff manager and async notification service changes/additions in #23229.

There is likely little point in spending time reviewing this until at least the initial commits of #23229 have enough approval to warrant a real PR.",59771425
1018,2020-03-06T19:29:00Z,2020-03-06T19:51:19Z,,,"This is the updated version for this PR which was closed:
https://github.com/zephyrproject-rtos/zephyr/pull/22848

Currently IO APIC is working in physical destination mode, fixed delivery, and the destination fields in  IOREDTBL is fixed to 0xff, which seems a invalid configuration. By definition, in this setting, IO APIC interrupt can be delivered to one single local APIC whose LAPIC ID is 0xff.

This patchset is intended to fix the IO APIC delivery issue on SMP systems:

- change IO APIC from physical mode to logical destination mode so it's possible to deliver IO APIC interrupts to multiple local APICs.
- HPET timer interrupt needs to run in fixed delivery mode
- other device drivers are good to run in lowest priority mode

Tested:
1) sanitycheck -p qemu_x86
2) sanitycheck -p qemu_x86_64
3) Successfully ran samples/subsys/console/echo (test UART driver) and tests/kernel/queue (test timer interrupts) on these platforms:
- ACRN (x2apic)
- up_squared (both xapic and x2apic, SP and SMP)
- qemu_x86 (xapic)
- qemu_x86_64 (xapic, SP and SMP)

Can't test X2APIC with QEMU due to following warning:
qemu-system-x86_64: warning: TCG doesn't support requested feature: CPUID.01H:ECX.x2apic [bit 21]

fixes #21156",59771425
1019,2020-03-06T08:15:49Z,2020-03-06T08:25:33Z,,,This pull request is useing a forked repo to create pr based on #22087,59771425
1020,2020-03-05T17:20:38Z,2020-03-10T16:12:48Z,,,"This PR includes a series of commits to support the GMAC Ethernet peripheral on the Atmel SAM0 family devices, and enable Ethernet support on the Atmel SAM E53 and E54 SoCs.

This PR includes the commits from #23045 (GMAC device tree), #23031 and #23289 (Fix UART console for testing with shell).

Closes #23001.

NOTE: This patch has been tested and verified working on the `atsame54_xpro` board using the `samples/net/dhcpv4_client` sample.",59771425
1021,2020-03-05T11:57:16Z,2020-03-26T17:38:51Z,,,"Extract flash buffered write functionality from flash_img to a general module.

Why:
- This code is useful in non-mcuboot and non-dfu contexts as well

Goals:
- Don't break API of flash_img

Some topics we need to discuss:
- Can we use the 'fbw' abbreviation as is done here?
- Should we expose the `progressive_erase` function from fbw? This is needed by flash_img, and maybe other similar modules.
- Should the unit test be updated so that most of what is in the flash_img test today is moved to its own fbw test, and then the flash_img test can be much simpler?",59771425
1022,2020-03-04T19:09:49Z,2020-03-20T20:11:29Z,,,"The mabi and march options of the compiler and linker commands
were previously hardcoded and depended only on the 64BIT config
option. This update allows these flags to be set by the config
options currently available, plus an additional option to
specify the compressed ISA.

Signed-off-by: Jaron Kelleher <jkelleher@fb.com>",59771425
1023,2020-03-04T16:35:13Z,2020-03-26T20:02:13Z,,,"This updates the stm32cube/stm32xx

Requires https://github.com/zephyrproject-rtos/hal_stm32/pull/47

Signed-off-by: Francois Ramu <francois.ramu@st.com>",59771425
1024,2020-03-04T15:53:53Z,2020-03-10T04:09:49Z,,,"Stack size analyzer is simple module that helps in printing
stacks usage statistics.

Add debug configuration for RTT for HCI_UART sample.

Remove all bluetooth stack size analysis for various threads.
    
",59771425
1025,2020-03-04T11:25:25Z,2020-03-11T23:51:11Z,,,"In order to use it's serial peripheral SERCOMs SAMD socs require their
pins to be configured with pinmux. Currently pins are muxed only for the
boards' default serial interfaces. The pinmux code is written to throw
a compiler error if a user tries to use any sercom in a way it wasn't
pre-defined to be used.

This commit changes compiler errors to warnings so that user can provide
custom pinmuxing code in their app.

Fixes #23133

Signed-off-by: Kuba Sanak <contact@kuba.fyi>",59771425
1026,2020-03-04T10:28:35Z,2020-03-20T13:27:39Z,,,"User reported a flaw in the current algorithm which fails when Zero
Latency Interrupts (ZLI) are used. Ported algorithm from
counter_nrfx_rtc.c which covers all cases. Algorithm is lockless so
no distinction for ZLI is needed.

Fixes #23187.

Algorithm is ported with modifications from `counter_nrfx_rtc.c` and should cover all corner cases when setting RTC compare register.

I've run tests from `tests/kernel/timer` and `tests/kernel/tickless/tickless_concept`.


Signed-off-by: Krzysztof Chruscinski <krzysztof.chruscinski@nordicsemi.no>",59771425
1027,2020-03-03T18:04:48Z,2020-03-09T11:20:40Z,,,"The UART driver for samd0 was is missing the .configure
functionality expected from api for serial driver. This commit
fixes this by providing basic configuration.

Note, using the function will briefly switch the peripheral off
taking the data line low.

Signed-off-by: Kuba Sanak <contact@kuba.fyi>",59771425
1028,2020-03-03T16:46:16Z,2020-03-05T12:40:47Z,,,"Add the possibility to use heap to emulate internal flash driver more
closely.

Signed-off-by: Sigvart Hovland <sigvart.hovland@nordicsemi.no>",59771425
1029,2020-03-03T16:30:29Z,2020-03-20T13:03:22Z,,,"PR tracks changes to #23601 and supplies changes to #23333

This PR separates generic resource management updates in #22853 from the new queued operation API, and adds an extension to the onoff manager intended to satisfy the use case of #22974 without having to change how cancellation is implemented.  It is intended as something like a rebaseable topic branch where the earlier commits are on a path to stabilization but are still impacted by changes in functionality and API due to evolution of later commits.

The PR branch:
* refactors the onoff service to reduce space by putting static configuration data into a separate structure;
* extracts the async notification infrastructure from the on-off service into a self-contained structure that can be used anywhere asynchronous operations may be used;
* recasts the on-off service as a manager that is to be used by services (including API changes to make it more consistent with other managers to come);
* reworks the API to support a change to how cancellation works, providing an ability for the last client waiting for an operation to cancel that operation, using techniques inspired by #23087 and prototyped in #23512;
* reworks and extends API to support handling behavioral issues related to cancelling operations, by providing a monitor facility for synchronous notification of state changes in the underlying service;
* adds an intermediary that converts asynchronous request and release API to synchronous requests and releases with callback notification when the desired state has been reached, which is an alternative approach that avoids cancellation but satisfying the use case of #22974.",59771425
1030,2020-03-03T15:07:26Z,2020-03-18T13:39:35Z,,,"Add support for Microchip MCP23008 I2C GPIO expander.
Tested with a single MCP23008 I2C chip.
Tested all pin configurations and irq configurations.
Assumptions/Requirements: Hardware reset line is connected.

Signed-off-by: Ioannis Papamanoglou <iopapamanoglou@gmail.com>",59771425
1031,2020-03-02T17:42:05Z,2020-03-04T08:49:03Z,,,"This add support for for the following features:

- L2CAP: Add support for Enhanced Credit Based Flow Control
- ATT/GATT: Add Enhanced ATT support
- ATT/GATT: Add Notify Multiple and Read Multiple Variable Length procedures",59771425
1032,2020-03-01T11:10:30Z,2020-03-10T09:43:14Z,,,"This commit adds the QEMU Cortex-M4 emulation platform (qemu_cortex_m4)
based on the new `netduinoplus2` machine added in the QEMU 5.0.

The QEMU `netduinoplus2` machine emulates the Netduino Plus 2 hardware
that includes the STM32F405 SoC.

Signed-off-by: Stephanos Ioannidis <root@stephanos.io>

Fixes #22870

NOTE:
1. This PR must be merged after the QEMU 5.0 is released, integrated into the Zephyr SDK (zephyrproject-rtos/sdk-ng#192), and the CI is updated to use the new SDK.
2. In order to test this PR, follow the instructions below:
    1. Check out the following branch (which has all the necessary patches pre-applied):
        https://github.com/stephanosio/qemu/commits/zephyr_stm32f405_emu
    2. Build QEMU `arm-softmmu` target (`configure --target-list=arm-softmmu` `make`)
    3. Set`QEMU_BIN_PATH` to the directory that contains the `qemu-system-arm` built above.",59771425
1033,2020-02-28T09:40:04Z,2020-03-25T12:53:18Z,,,"to support the spi as a client of the dma

test on nucleo_l476zi board

The DT is filled with parameters to set the peripheral request on the dmamux.
The dma channels used for the client transfer (rx, tx) are assigned by the DT among the total nb of dma channels (ex.7 per dma instance)

Requires https://github.com/zephyrproject-rtos/zephyr/pull/22100

Signed-off-by: Francois Ramu francois.ramu@st.com",59771425
1034,2020-02-28T09:23:52Z,2020-03-25T15:49:15Z,,,"Initial work to support the spi as a client of the dmamux

test on nucleo_wb55rg board 
The DT is filled with parameters to set the peripheral request on the dmamux.
The dmamux channels used for the client transfer (rx, tx) are assigned by the DT among the total nb of dmamux channels (ex.14)
Also tested on nucleo_l476rg board, where the dma requests are fixed (no multiplexer)
Also tested on nucleo_f411re board, where the dma V1 requests are fixed (no multiplexer)

Requires https://github.com/zephyrproject-rtos/zephyr/pull/23157
Requires https://github.com/zephyrproject-rtos/zephyr/pull/22021

Signed-off-by: Francois Ramu francois.ramu@st.com",59771425
1035,2020-02-27T22:54:17Z,2020-03-06T16:05:57Z,,,"This commit addresses an issue where the GCLK2 divider is incorrectly
set to 31.  The correct divider is 32 which yields a frequency of
1024 Hz.  Referring to section 15.8.4 of the datasheet, the correct
configuration of the GCLK2 divider is GENCTRL.DIVSEL = 1 and
GENDIV.DIV = 4.

",59771425
1036,2020-02-27T22:41:33Z,2020-03-23T12:16:03Z,,,"The sam0 RTC driver determines CYCLES_PER_TICK as a function of
the GCLK0 frequency.  This is not correct in the following
situations:
1.  GCLK0 is not used as the source for the RTC
2. The RTC is configured to use a prescaler

This commit fixes this issue by determining the RTC frequency using
the values of the clock-generator and prescaler properties specified
in the device tree.

This commit also configures the oscillators to run during low power
standby to enable sleeping the MCU.

",59771425
1037,2020-02-27T22:27:43Z,2020-03-04T11:11:04Z,,,"SDK HAL is deprecated for Intel ADSP SoCs so fix and use local HAL
module.

Signed-off-by: Daniel Leung <daniel.leung@intel.com>
Signed-off-by: Liam Girdwood <liam.r.girdwood@linux.intel.com>

Depends on https://github.com/zephyrproject-rtos/sdk-ng/pull/193 and https://github.com/zephyrproject-rtos/hal_xtensa/pull/10",59771425
1038,2020-02-27T20:52:57Z,2020-03-06T16:06:10Z,,,"After power on, the device specifies a start up time.
This change adds a start up time consistent with the
device datasheet.  Fixes #21707

There are several additional bit fields defined for the
CONFIG register.  The bit fields have been added and
an attr_set() function has been added to enable
setting the sample frequency.

",59771425
1039,2020-02-27T17:49:52Z,2020-03-06T16:06:21Z,,,"After power on or reset, the device datasheet specifies a delay.
This change adds a power on and reset delay consistent with
the device datasheet.

",59771425
1040,2020-02-27T17:22:17Z,2020-02-27T17:24:38Z,,,"With the new RI-2018.0 XCC, xt-gdb complains about not being able
to find register f0. Turns out that xt-gdb needs to be told which
file to look at (the file command) before a load command can be
issued. So swap these two commands in the load_elf.txt file.

Signed-off-by: Daniel Leung <daniel.leung@intel.com>",59771425
1041,2020-02-27T11:56:25Z,2020-03-05T06:51:27Z,,,"According to the API k_delayed_work_cancel() returns next values:
0: Work item countdown canceled.
-EINVAL: Work item is being processed.
-EALREADY: Work item has already been completed.
I created a test that shows -EALREADY can be returned by function
even when work item is not completed.
My test uses two semaphores and in the middle of the execution
of the handler function I call k_delayed_work_cancel and check return
value. I expect to receive -EINVAL, but instead I receive -EALREADY,
when work item is not completed yet and handler function is still
running. @pabigot that PR is about our conversation on Slack.

Signed-off-by: Maksim Masalski <maksim.masalski@intel.com>",59771425
1042,2020-02-27T09:10:27Z,2020-03-24T09:40:35Z,,,Tested with `samples/drivers/counter/alarm/` on `b_l072z_lrwan1`,59771425
1043,2020-02-27T05:16:34Z,2020-02-27T14:01:26Z,,,"commit 129ae378c0 breaks the installed path setting by CLANG_ROOT_DIR
because CLANG_ROOT is not set. Remove CLANG_ROOT and just use
CLANG_ROOT_DIR to fix this bug.

Signed-off-by: Jim Shu <cwshu@andestech.com>",59771425
1044,2020-02-27T02:17:47Z,2020-02-27T02:20:25Z,,,"Adds a new shim driver for the flexcomm i2c, and enables it on lpcxpresso55s69 and lpcxpresso54114 boards.

Depends on zephyrproject-rtos/hal_nxp#33

Fixes #22701",59771425
1045,2020-02-26T23:00:40Z,2020-02-27T17:53:25Z,,,"drivers: bme280: Add delay during boot

After power on, many devices specify a start up time.
This change adds a start up time consistent with the
device datasheet.",59771425
1046,2020-02-26T21:09:11Z,2020-02-27T14:08:32Z,,,"The wdt CLEAR register is a write synchronized register.
To avoid a bus stall, a check of the status of SYNCBUSY before accessing the register must be done.

This PR checks the status of SYNCBUSY before access the CLEAR register.",59771425
1047,2020-02-26T20:54:01Z,2020-02-28T02:01:52Z,,,"This PR replaces PR #21347

The PR addresses an issue with the sam0 flash driver. The flash driver writes data to the flash page using 32 bit long words. This will generate a hard fault if the source address for a flash write is not aligned to a 32 bit word boundary. This PR fixes this issue.

This PR uses the UNALIGNED_GET() macro instead of the flash_sam0_read_unaigned_u32() function to ensure word alignment.",59771425
1048,2020-02-26T11:18:35Z,2020-03-19T08:47:53Z,,,Commits in this PR are manual cherry-pick of commits based on differences in ctrl.c file.,59771425
1049,2020-02-25T21:14:23Z,2020-03-25T19:41:41Z,,,"Initial code for support using H4 over bulk endpoints which has the following advantages over the standard H2:
 - Race free since everything is serialized.
 - Has support for ISO packets (0x05) in the standard

This can be used both with  a dedicated PID (hci_usb_h4) or with the existing hci_usb, for the later the host must enable it using the new vendor command Set Host Transport Mode (0x0010).",59771425
1050,2020-02-25T14:18:51Z,2020-03-24T13:26:03Z,,,"Introducing asynchronous sequence manager (also referred as transaction manager in the issue) as specified in #22498.

Manager is capable of performing sequence of asynchronous operations and notify user once sequence is completed (successfully or with error).

Following features are supported:
- sequence can optionally has setup and teardown function. 
- ~~sequence can be paused and resumed~~ discarded
- manager is used `async_notify` to notify completion
- aborting sequence (sequence is aborted on next item completion)

~~Following features are not yet supported but considered:~~
- ~~support for delay between items in the sequence~~ discarded

Sequence manager can execute only one sequence at the time and returns busy error if sequence is in progress. It can be combined with `queued_operation_manager` to provide support for enqueueing asynchronous requests from multiple contexts.

See #22498 for potential use cases. Documentation will be added later.

This PR is based on #22853.",59771425
1051,2020-02-25T10:04:44Z,2020-03-26T12:56:09Z,,,Adding net_if awareness of PM state.,59771425
1052,2020-02-24T15:28:22Z,2020-03-26T18:32:54Z,,,"This PR introduces Zephyr Config package for CMake.

Today, working with Zephyr / CMake requires users to always set `ZEPHYR_BASE`.
This can be done in a couple of different ways, depending on OS and shell being used (manually sourcing zephyr-env.sh, sourced in bashrc, running zephyr-env.cmd, etc.)

Or when using `west build` then `ZEPHYR_BASE` is set automatically.

Unfortunately, using an environment variable in the build system has a couple of flaws.

A couple of examples, see further down for details:
- `west build` is incompatible with command line `ninja` if user does not set `ZEPHYR_BASE` after running `west`
- `cmake -G'Eclipse CDT4 - Ninja'` and Eclipse, requires re-launching of Eclipse if switching to another project that uses a different Zephyr base.
- Having multiple Zephyr directories bears the risk of forgetting to set another (correct) Zephyr base.
- Zephyr base is changed between CMake and ninja invocation
- Probably more.


------
`west build` Example (`zephyr-env.sh` not sourced as that is not required for `west`):
```
$ cd <projects>/zephyr/samples/hello_world
$ west build -bnrf52840_pca10056
$ cd build
$ touch ../CMakeLists.txt
$ ninja
[0/1] Re-running CMake...
CMake Error at CMakeLists.txt:5 (include):
  include could not find load file:

    /cmake/app/boilerplate.cmake

CMake Error at CMakeLists.txt:8 (target_sources):
  Cannot specify sources for target ""app"" which is not built by this project.
```
------
Terminal 1)
$ cmake -G'Eclipse CDT4 - Ninja' -DBOARD=nrf52840_pca10056

Terminal 2 or Desktop shortcut (not sourcing `zephyr-env.sh), Eclipse error:
```
15:39:45 **** Incremental Build of project hello_world@build ****
/usr/bin/ninja all 
[0/1] Re-running CMake...
CMake Error at CMakeLists.txt:5 (include):
  include could not find load file:

    /cmake/app/boilerplate.cmake

-- Eclipse version is set to 3.6 (Helios). Adjust CMAKE_ECLIPSE_VERSION if this is wrong.
-- Configuring incomplete, errors occurred!
```

----
Having multiple Zephyrs and sourcing wrong one
```
/projects/zephyr-alt/zephyr/samples/hello_world/build$ cmake -GNinja -DBOARD=nrf52840_pca10056 ..
-- Zephyr version: 2.1.99
-- Found PythonInterp: /usr/bin/python3.6 (found suitable version ""3.6.8"", minimum required is ""3.6"") 
-- Selected BOARD nrf52840_pca10056
-- Found west: /home/tora/.local/bin/west (found suitable version ""0.7.1"", minimum required is ""0.6.0"")
-- Loading /projects/ncs/zephyr/boards/arm/nrf52840_pca10056/nrf52840_pca10056.dts as base
Devicetree configuration written to /projects/zephyr-alt/zephyr/samples/hello_world/build/zephyr/include/generated/devicetree.conf
Parsing /projects/ncs/zephyr/Kconfig
Loaded configuration '/projects/ncs/zephyr/boards/arm/nrf52840_pca10056/nrf52840_pca10056_defconfig'
Merged configuration '/projects/zephyr-alt/zephyr/samples/hello_world/prj.conf'
Configuration saved to '/projects/zephyr-alt/zephyr/samples/hello_world/build/zephyr/.config'
```
as seen, the Zephyr base was wrong, but everything worked.
This might give unexpected results later.

-----
Zephyr base changed between CMake and Ninja invocation.
This could happen to someone running CMake and ninja in a projectA.
Change into projectB to do some work, and sets `ZEPHYR_BASE` to projectB.
Switch back to projectA, forgetting to set `ZEPHYR_BASE` and execute `ninja`
```
$ echo $ZEPHYR_BASE
/projects/ncs/zephyr
$ cmake -GNinja -DBOARD=nrf52840_pca10056 ..
-- Zephyr version: 2.1.99
...
$ cd <projectB>
$ source zephyr-env.sh
$ cd <projectA>/build
$ ninja -v
$ ninja
[0/1] Re-running CMake...
-- Zephyr version: 2.2.0-rc1
-- Selected BOARD nrf52840_pca10056
-- Found west: /home/tora/.local/bin/west (found suitable version ""0.7.1"", minimum required is ""0.6.0"")
-- Loading /projects/ncs/zephyr/boards/arm/nrf52840_pca10056/nrf52840_pca10056.dts as base
Devicetree header saved to '/projects/ncs/zephyr/samples/hello_world/build/zephyr/include/generated/devicetree_unfixed.h'
Parsing /projects/zephyr-alt/zephyr/Kconfig
/projects/zephyr-alt/zephyr/scripts/kconfig/kconfig.py: /projects/ncs/nrf/subsys/bootloader/Kconfig:25: '/projects/zephyr-alt/zephyr/../nrf/subsys/partition_manager/Kconfig.template.build_strategy' not found (in 'source ""${ZEPHYR_BASE}/../nrf/subsys/partition_manager/Kconfig.template.build_strategy""'). Check that environment variables are set correctly (e.g. $srctree, which is set to '/projects/zephyr-alt/zephyr'). Also note that unset environment variables expand to the empty string.
CMake Error at /projects/zephyr-alt/zephyr/cmake/kconfig.cmake:216 (message):
  command failed with return code: 1
Call Stack (most recent call first):
  /projects/zephyr-alt/zephyr/cmake/app/boilerplate.cmake:464 (include)
  CMakeLists.txt:5 (include)
```

In this case, an error was printed to user, but in case the two Zephyr's are very close, it could happen that everything worked, and in that case harder to detect when things break.

-----
Fixes in this PR:
- Cache `ZEPHYR_BASE`, the `ZEPHYR_BASE` that was set for the first CMake invocation in current build folder should be sticky, that is if CMake is re-invoked due to changes in any file, then the same `ZEPHYR_BASE` should be used.
- Allow `west build` and `ninja` to work better together.
- Remove the requirement to set `ZEPHYR_BASE` for majority of users
- Be backward compatible with current `ZEPHYR_BASE` and allow it to support advange use-cases

With this PR, Zephyr now has a CMake config package.
A one-time install must be done in a Zephyr. (multiple install are allowed but not required).
To do this install, run:
```
west zephyr-export
```

Once installed, users can now do:
```
$ echo $ZEPHYR_BASE

$ cmake -GNinja -DBOARD=nrf52840_pca10056 ..
Including boilerplate (in-zephyr-tree): /projects/ncs/zephyr/cmake/app/boilerplate.cmake
-- Zephyr version: 2.2.0-rc1
```
as seen, no `ZEPHYR_BASE` was set.

and also out-of-tree builds are supported this way:
```
$ echo $ZEPHYR_BASE

tora@ubuntu:/projects/oot/hello_world/build$ cmake -GNinja -DBOARD=nrf52840_pca10056 ..
Including boilerplate (out-of-worktree): /projects/ncs/zephyr/cmake/app/boilerplate.cmake
-- Zephyr version: 2.2.0-rc1
```

Using `ZEPHYR_BASE` and enforcing another Zephyr is also possible:
```
$ ZEPHYR_BASE=/projects/zephyr-alt/zephyr cmake -GNinja -DBOARD=nrf52840_pca10056 ..
Including boilerplate (zephyr base): /projects/zephyr-alt/zephyr/cmake/app/boilerplate.cmake
-- Zephyr version: 2.2.0-rc1
-- Found PythonInterp: /usr/bin/python3.6 (found suitable version ""3.6.8"", minimum required is ""3.6"") 
-- Selected BOARD nrf52840_pca10056
-- Found west: /home/tora/.local/bin/west (found suitable version ""0.7.1"", minimum required is ""0.6.0"")
-- Loading /projects/zephyr-alt/zephyr/boards/arm/nrf52840_pca10056/nrf52840_pca10056.dts as base
```

Creating a project also becomes much cleaner, all a user has to do, is to use `find_package`.
To create an application, you'll write:
```
find_package(Zephyr 2.0.0 HINTS $ENV{ZEPHYR_BASE})

project(hello_world)
target_sources(app PRIVATE src/main.c)
```
This has some additional benefits, such as requesting only to compile against an exact match:
```
find_package(Zephyr 2.0.0 EXACT HINTS $ENV{ZEPHYR_BASE})
```
or simply accept any Zephyr:
```
find_package(Zephyr HINTS $ENV{ZEPHYR_BASE})
```

To install Zephyr as a package, do the following:
```
west zephyr-export
```

Or manually:
```
$ cd <project>/zephyr/share/zephyr-package/cmake/
$ cmake .
Zephyr and ZephyrUnitTest (/projects/github/ncs/zephyr/share/zephyr-package/cmake)
has been added to the user package registry in:
~/.cmake/packages/Zephyr
~/.cmake/packages/ZephyrUnitTest
-- Configuring done
-- Generating done
-- Build files have been written to: /<project>/zephyr/share/zephyr-package/cmake
```

Example of `west` / `ninja` fix:
```
$ west build -bnrf52840_pca10056
$ cd build
$ touch ../CMakeLists.txt
$ echo $ZEPHYR_BASE
$ ninja
[0/1] Re-running CMake...
Including boilerplate (in-zephyr-tree): /projects/ncs/zephyr/cmake/app/boilerplate.cmake
-- Zephyr version: 2.2.0-rc1
-- Selected BOARD nrf52840_pca10056
...
```

Things still ToDo:
[X] - Update documentation to described workflow (depends on feedback to this PR)
[X] - Create `west` extension command to make easy Zephyr config package install (instead of `cmake .`)",59771425
1053,2020-02-24T07:03:34Z,2020-03-26T14:50:03Z,,,"This PR adds the device tree binding for the Atmel SAM GMAC Ethernet and converts the existing compatible SoCs (SAM E70 and V71) and boards (`sam_e70_xplained` and `sam_v71_xult`) to use it.

Includes commits from #23031 and #23055.

Fixes #22997.",59771425
1054,2020-02-24T04:04:57Z,2020-03-26T16:29:06Z,,,Use fixed fifo to save the BR / EDR link key to settings_subsys.,59771425
1055,2020-02-24T02:21:10Z,2020-02-24T02:42:03Z,,,"Add variants of k_delayed_work_submit and k_delayed_work_submit_to_queue
that take a delay in ticks, which is the actual base time unit used for
delays.",59771425
1056,2020-02-24T02:21:09Z,2020-03-01T03:45:00Z,,,"Allow C++ code to evaluate time base conversion routines at compile time
by marking them as constexpr where possible.",59771425
1057,2020-02-23T09:37:45Z,2020-03-13T10:51:55Z,,,"zephyr/include/device.h unconditionally includes syscalls/device.h
Adding syscalls/device.h to the ztest include path allows unit testing of code that includes device.h, but does not rely on the generated syscalls.

The example use case is a subsystem that relies on an underlying device, but that device is mocked for testing purposes.

Signed-off-by: Jordan Yates <jordan.yates@data61.csiro.au>",59771425
1058,2020-02-22T04:25:49Z,2020-02-24T20:43:04Z,,,"Add a new macro that uses gcc nonnull attribute to generate warnings when a NULL parameter is given to a function that declares that that parameter should not be NULL.

This macro is set to all include/kernel.h functions. One caveat on using this macro is that was needed to turn off the flag ""Wnonnull-compare"" otherwise the compiler will warn when finds a comparison with NULL for a parameter set with that macro. That's is a small convenience that in the worst case just ignore a useless check but the benefit is that if someone wrongly pass a explicit NULL pointer a warn will be raised and we avoid further problems. 

For example, `k_pipe_get(struct k_pipe *pipe, void *data, size_t min_xref, s32_t timeout)` crashes if pipe or data are NULL. With this patch, a warning will be generate in compile time with `k_pipe_get(NULL, &data, min_xref, timeout)`.

Note that this does not change anything in runtime and if the warning is ignored it will crash as well.

",59771425
1059,2020-02-22T00:52:22Z,2020-03-24T03:25:04Z,,,"This PR add all missing pieces to fix and enable SAM4E Ethernet port.
This PR uses some commits from #23045 and extends device tree options.

The changes were tested on SAM4E and SAMV71 boards using samples/net/telnet. Tests are conducted using DHCPv4, collecting stats and ping 8.8.8.8

Blocked by #23045, will need rebase once that PR is finalised/merged.",59771425
1060,2020-02-21T04:40:39Z,2020-03-12T11:12:44Z,,,"This adds information about the SPU hardware  with the number of
lockable regions and granularity to the SPU node in the device tree.

Signed-off-by: Sigvart Hovland <sigvart.hovland@nordicsemi.no>",59771425
1061,2020-02-20T15:20:06Z,2020-02-20T16:18:39Z,,,"This PR is just to show the starts of getting Zephyr for ARM platform.  The idea is to first utilize LLVM/CLANG for compiling and utilizing GNU as/linker.

There builds on several platforms, has shown some issues on some various HALs and other places.

According to the devel list this does NOT run on qemu currently.  This is believe to be due to some inline asm code being optimized out w/LLVM.",59771425
1062,2020-02-18T21:59:18Z,2020-03-17T12:43:39Z,,,"Added I2C driver for [Bosch's BMP388 Pressure Sensor](https://www.bosch-sensortec.com/products/environmental-sensors/pressure-sensors/pressure-sensors-bmp388.html#documents).
Also added a sample using the [Adafruit BMP388 breakout](https://www.adafruit.com/product/3966) on top of [Nucleo L073RZ](https://docs.zephyrproject.org/latest/boards/arm/nucleo_l073rz/doc/index.html).",59771425
1063,2020-02-18T15:49:25Z,2020-02-18T15:52:05Z,,,"Posting this so we have it around, but the intent is these conversions should really be using DT_INST and the vast majority of cases.",59771425
1064,2020-02-18T14:52:04Z,2020-02-26T08:50:39Z,,,"changes:
1. add cpu time in sanity-check for qemu thread
2. Enable icount mode for mps2_an385, mps2_an521 and qemu_x86, icount shift
    value should be selectd based on cpu clock frequency of every platform.
    The virtual cpu will execute one instruction every 2^shift ns of virtual
    time.
3. remove CONFIG_QEMU_TICKLESS_WORKAROUND for some timer test cases.
4. In Qemu icount mode, busy wait will cause lots of wall time and it's
    very easy to get sanitycheck timeout(this case will be successful if
    given enough timeout value for sanitycheck), so reduce test interval
    to save execution time.

have done:
- already test this PR on Unbuntu18.04 with sanity-check running at the same time on 10 different folders, some of which apply the patch and others don't, and see a lot of failed cases in the not enable icount folders, see very very little timeout cases on icount enabled folders(but I'm sure they will success if given large timeout value in sanity-check script).

need address:
- [x] tests/kernel/mem_protect/stack_random/kernel.memory_protection.stack_random always fail on qemu_x86 platform. I take a look the file rand32_timestamp.c used by x86 platform, not familiar with rdtsc instruction(__asm__ volatile(""rdtsc"" : ""=a"" (rv) : : ""%edx"");), maybe I need take a look x86 doc and review qemu code to see how qemu handle this on x86 platform, appreciate any help.
- [ ] 7 test cases fail on qemu_x86_64 platform with latest commit.
- [ ] find very little timeout cases when icount enabled, that's maybe because on very heavy machine the cpu time is not accurate, maybe we can give large timeout value in sanity-check. 
- [x] tests/kernel/context/kernel.common always fail on qemu_cortex_r5 platform.
- [x] tests/kernel/mem_slab/mslab_threadsafe/kernel.memory_slabs.threadsafe always timeout on qemu_cortex_m0
- [ ] only platform qemu_nios2 doesn't work well for icount mode.
- [x] will test this PR with same method on Fedora. 

Related to #14173",59771425
1065,2020-02-18T14:09:48Z,2020-03-09T06:24:01Z,,,"Make the UART configuration (instance and interrupt driven) conditional
on the serial subsystem being enabled.

Fixes #22892.

Signed-off-by: Carles Cufi <carles.cufi@nordicsemi.no>",59771425
1066,2020-02-18T13:48:30Z,2020-02-18T14:31:44Z,,,Build with xtensa HAL removing __SPLIT__ macros,59771425
1067,2020-02-18T10:37:39Z,2020-02-21T21:16:17Z,,,"add the possibility to have up to 4 tmp112 on the same board

Signed-off-by: Ismael Fillonneau <ismael.fillonneau@stimio.fr>",59771425
1068,2020-02-17T14:57:05Z,2020-03-26T09:26:46Z,,,For now this is only a RFC to discuss the aarch64 switch to the new `arch_switch` API.,59771425
1069,2020-02-17T14:31:01Z,2020-03-12T09:29:05Z,,,Moves device.h header from ipm.h to the right places.,59771425
1070,2020-02-16T13:03:24Z,2020-03-20T14:55:00Z,,,"Add CODE_SEMC to support nxp-rt series
code run in external sdram.

Signed-off-by: Frank Li <lgl88911@163.com>",59771425
1071,2020-02-16T12:20:00Z,2020-03-19T08:12:48Z,,,"This implements a file descriptor used for event notification that
behaves like the eventfd in Linux.

The eventfd supports nonblocking operation by setting the EFD_NONBLOCK
flag and semaphore operation by settings the EFD_SEMAPHORE flag.

The major use case for this is when using poll() and the sockets that
you poll are dynamic. When a new socket needs to be added to the poll,
there must be some way to wake the thread and update the pollfds before
calling poll again. One way to solve it is to have a timeout set in the
poll call and only update the pollfds during a timeout but that is not
a very nice solution. By instead including an eventfd in the pollfds,
it is possible to wake the polling thread by simply writing to the
eventfd.",59771425
1072,2020-02-16T08:57:40Z,2020-03-10T17:58:29Z,,,"Add htu21d humidity and temperature sensor driver and a sample using it on the hexiwear board.

EDIT: Changed to sht21 driver because htu21d (and si7021) are clones, as pointed by @pabigot ",59771425
1073,2020-02-14T15:25:26Z,2020-03-23T22:17:03Z,,,"This PR is a proposal for making the CAN API to support CAN-FD.
The stm32fd driver is currently empty and serves dummy implementation for testing device-tree generation.",59771425
1074,2020-02-14T14:28:01Z,2020-02-27T17:09:09Z,,,"The usb device is now deinit. As well the
usb endpoints are getting closed.

After deinit the usb periphal wil go to deepsleep.
That might save some power.

Signed-off-by: Stefan Jaritz <stefan@kokoontech.com>",59771425
1075,2020-02-14T14:20:07Z,2020-03-09T12:55:04Z,,,"Related to my comment here:
https://github.com/zephyrproject-rtos/zephyr/issues/22803#issuecomment-585887641

I think this utility function would complement the API and would have been possible to use to handle #22756, since the cancel return value was not working as expected.

Would love some feedback if this is useful or correct.

Add k_delayed_work_pending similar to k_work_pending to check if the
delayed work item has been submitted but not yet completed.
This would compliment the API since using k_work_pending or
k_delayed_work_remaining_get is not enough to check this condition.
This is because the timeout could have run out, but the timeout handler
not yet processed and put the work into the workqueue.

",59771425
1076,2020-02-14T14:14:05Z,2020-02-15T14:55:22Z,,,Just remove the 2nd of duplicate includes.,59771425
1077,2020-02-14T10:19:20Z,2020-02-14T13:08:13Z,,,"Fix serveral cases in `subsys/settings` where a possible uninitialized variable may be used.
In some of these it cannot happen, but gcc still complains (if `-Wextra` is given) with:

```
'rc' may be used uninitialized in this function [-Werror=maybe-uninitialized]
```
",59771425
1078,2020-02-13T15:34:04Z,2020-03-12T15:26:01Z,,,"When the NUM_PREEMPT_PRIORITIES is changed to 0 without deleting the
build directory the thread priorities will silently become invalid.

To resolve this we apply the same fix as we did for
BT_HCI_TX_STACK_SIZE. We add a ""prompt guard"", which ensures that the
priority is only set manually when it is explicitly configured to be
so.

The same mechanism was used successfully in this PR:
https://github.com/zephyrproject-rtos/zephyr/pull/20702

This fixes #13436",59771425
1079,2020-02-13T13:03:33Z,2020-02-14T15:09:06Z,,,"MPU_GAP_FILLING and FLOAT are taking up too much space in the top
level menu. To resolve this we expand the scope of the ""General
Architecture Options"" menu.

This has no effect other than on menu layout.

Signed-off-by: Sebastian Bøe <sebastian.boe@nordicsemi.no>",59771425
1080,2020-02-12T20:19:50Z,2020-03-11T17:52:12Z,,,"This converts the Kinetis GPIO driver to be based on DT_INST defines.  We base this on PR #22770 as we utilize the phandle support to connect the GPIO controller node and PINMUX port nodes together.

Additionally we now utilize the device tree to determine which GPIO controller instances should be enabled and thus remove such config from Kconfig.",59771425
1081,2020-02-12T09:22:42Z,2020-03-20T10:55:48Z,,,"Add support for ST VL53L1X TOF sensor.

Signed-off-by: Pablo Garrido pablogs9@gmail.com",59771425
1082,2020-02-11T19:29:51Z,2020-02-24T10:41:11Z,,,"After enabling CONFIG_NET_IF_LOG_LEVEL_DBG=y, I started to see
constant stream of these messages. The system prints two msg
every millisecond.

<dbg> net_if.prefix_lifetime_timeout: Waiting for 2147483547 ms
<dbg> net_if.address_lifetime_timeout: Waiting for 2147483547 ms

Not sure what has changed in the system but refactoring the
check fixes the issue.

Fixes #22732

Signed-off-by: Jukka Rissanen <jukka.rissanen@linux.intel.com>",59771425
1083,2020-02-11T16:13:05Z,2020-03-09T09:57:03Z,,,"Toying with the idea, so hacked something to show the ability to generate struct's from DT nodes.  Not sure if this is useful or not, but wanted to put it out there for thought.",59771425
1084,2020-02-11T14:23:28Z,2020-03-26T09:33:48Z,,,"Add IPM ADSP driver, DT configuration, ipm_echo sample, IPM console and documentation.",59771425
1085,2020-02-11T08:03:59Z,2020-03-25T11:46:28Z,,,add [MAX31855](https://datasheets.maximintegrated.com/en/ds/MAX31855.pdf) cold-junction compensated thermocouple-to-digital converter sensor driver and sample,59771425
1086,2020-02-11T03:53:41Z,2020-03-10T17:07:55Z,,,"*(This PR is not adding any new aliases. See the commit message and the explanation in a separate comment. It's a standalone improvement, which will make later improvements much easier.)*

scripts/dts/gen_defines.py currently generates prefixes from properties
in aliases/ in two formats:

    DT_ALIAS_<property>_*
    DT_<compatible of pointed-to node>_<property>_*

For example, 'aliases { usart-0 = &usart0; }' generates

    DT_ALIAS_USART_0_*
    DT_NXP_LPC_USART_USART_0_*

when the &usart0 node has 'compatible = ""nxp,lpc-usart""'.

The second form exists for backwards compatibility. It's spammy and hard
to read, and easy to confuse for DT_\<compatible>\_\<unit address>_*, which
also gets generated for devicetree nodes.

The code in gen_defines.py that generates the deprecated form has a
'# TODO: See if we can remove or deprecate this form' Comment over it.

Update all macros that come from /aliases to use the DT_ALIAS_* form,
for macros prefixed with DT_NORDIC_*.",59771425
1087,2020-02-10T07:43:12Z,2020-02-28T21:08:01Z,,,"The `TEXT_SECTION_OFFSET` symbol is used to specify the offset between
the beginning of the ROM area and the address of the first ROM section.

This commit renames `TEXT_SECTION_OFFSET` to `ROM_START_OFFSET` because
the first ROM section is not always the `.text` section.

Signed-off-by: Stephanos Ioannidis <root@stephanos.io>",59771425
1088,2020-02-10T06:56:30Z,2020-03-23T13:16:56Z,,," - extend ili9340 driver to use config from dts
 - add posbility to use single driver for ili9xxx displays
 - create generic sheild for the ili934x based boards
",59771425
1089,2020-02-10T04:59:46Z,2020-03-26T08:54:11Z,,,testing,59771425
1090,2020-02-10T03:58:42Z,2020-03-19T14:49:14Z,,,"This PR contains Synopsys' work on supporting C-lang/llvm based metaware toolchain support in Zephyr.

As Zephyr toolchain work group is kicked off, we share our work here and welcome review.

Now can we compile lots of zephyr examples and tests with metarware toolchain, but still a lot work of to do:
    * C++ support
    * compile options mapping from GCC to mwdt
    * binutils transfer.
    * corner cases

# update of 2020-03-05
Here is a summary of mwdt support in Zephyr..
## Current status

Now, most of non-USERSPACE samples can be built with MWDT and run in nsim. For USERSPACE samples, because of address alignments requirement, there are a lot of issues for MPUv2 configurations. The result of MPUv3 (nsim_sem) is better than MPUv2, as v3’s requirement of address alignment is weaker.

## Background

MWDT is SNPS’s new generation LLVM/C-lang based toolchain. Although Zephyr already has some support of llvm/c-lang toolchain, but MWDT has different interface (compile options), linker, assembler. Therefore, the exist llvm/c-lang support in zephyr cannot be reused for MWDT, everything must be done from the scratch.

The work can be divided into 4 parts:

## PART I build system

   Zephyr build system is cmake based with lots of python tools. The general flow is in https://docs.zephyrproject.org/latest/guides/build/index.html. The goal of this part is to pass the configuration of cmake. In this part, we need to set up the toolchain related cmake files for mwdt. GNU toolchain’s cmake files are good reference. The challenges of this part are

 * Basic understanding of zephyr’s build flow and knowledge of cmake
 * Compiler options check where “zephyr_check_compiler_flag(C """" toolchain_is_ok)” is very important. It requires the correct setting of CMAKE_REQUIRED_FLAGS
 * Generation of device tree related files. Execute_process @line 122 of dts.cmake will call c compiler to preprocess the dts files. It works for gcc, but failed for mwdt. As a workaround, host gcc can be used. The root cause of this issue may be in the assembler or preprocessor of mwdt.

## PART II: compilation
The goal of this part is to compile the source code successfully

* Compile options. In Zephyr, lots of compile options are used, covering generic options, optimization, path, processor specific, etc. This compile options are GNU centric. It requires mapping from gnu compile options to mwdt compile options. But for some options, there are no corresponding mwdt options. I suggest Zephyr needs to list what options are critical, what are optional. Here are a list of options not supportted in MWDT
  * gcc specific coverage related options, this affect the coverage test of zephyr
  * no -std=c++14, -std=c++17 -std=c++2a
  * no -fsanitize=undefined
  * no mstack-protector-guard=global
  * no security_fortify related options

* Language feature, extension and builtins. The language (C/C++/Assembly) extensions used in Zephyr are GCC-centric. It requires a mapping between gcc and mwdt. For C/C++, luckily, as MWDT is llvm/c-lang based, so most of language feature, extension and builtin can be reused (there are still some corner cases); For assembly, more work is required. Because assembly is more low-level specific and architecture specific, it has few impact on application, API but may require lots of changes in exist assembly codes.

## PART III: Linkage

The goal of this part to link the compiled object files, archive files into the final elf file.

MWDT’s linker and link script is fully different with gnu’s. Compared with gnu’s linker, the features of MWDT’s linker and ld script are limited. Meanwhile, the linker script used by Zephyr is very complex, has lots of symbols and sections, especially when USER SPACE is configured. The linkage support is the most challenging work in MWDT support. Here are the challenges:

* Map Zephyr’s gnu linker script into MWDT’s linker script
* Lots of GNU linker primitives are not supported by MWDT, including, SORT, SORT_BY_NAME, operation on PC counter (.), LOG2CEIL (which is required by the power of 2 alignment of ARC MPU v2), ASSERT
 * Lots of symbol are gnu specific, e.g. C++

What’s more, even the final elf file is linked. It may be a wrong result because of address alignment, gapping etc.

## PART IV: binutils

The goal of this part is to generate different kind of output files(.bin, .hex, .S record), dump symbols or sections from the elf which may be used by 2nd linkage, mem footprint, etc.

Compared with MWDT, the features of gnu binutils, are rich and strong, especially the objcopy cmd. Required by USERSPACE feature, section rename of objcopy is used. But we can’t do section rename with MWDT, so still rely on using arc gnu’s objcopy to process the files generated by MWDT.

Lots of python tools in Zephyr are designed based on gnu binutils. This means these tools cannot be directly used by MWDT.

# update of 2020-03-19
  * can run sanitycheck with metaware toolchain
  * testes can be built with metaware toolchain (build only)
      * tests/kernel, covering USERSPACE
  * testes can pass with metaware toolchain
      * tests/kernel, without USERSPACE.
      * because ARC MPUv3 only requires 32 bytes alignment, so USERSPACE with ARC MPUv3 also can pass
      * suggestions for toolchain tests
         * STEP1 : hello world
         * STEP2 : philosopher for context switch and systick
         * STEP3 : tests/kernel  without USERSPACE for core kernel features
         * STEP4 : tests/kernel with USERSPACE  for complete kernel features

 






",59771425
1091,2020-02-08T19:16:20Z,2020-03-12T11:59:10Z,,,"Re-Open of https://github.com/zephyrproject-rtos/zephyr/pull/11406

Tested on atsamd20 evaluation board connected to a MCP23S17.
I have the I2C version on hand as well MCP23017, wouldn't it be nice to let the exist in the same driver? Maybe called mcp23x17?

Credits to @pveierland for spotting an issue reading inputs correctly.",59771425
1092,2020-02-07T14:05:30Z,2020-03-26T12:09:32Z,,,"Add support for discovery of vendor specific UUID128 and reading
the data associated with that service. If permissions require
authentication / encryption then raise the security level of the
connection.
The Central_HR can now work together with the Peripheral sample
which exposes both standard services (HRS) and a vendor specific
created with UUID128. If the peripheral sample is compiled with
a fixed passkey option, the scanning and connection between these
devices happen automatically.

Signed-off-by: Cristi Caciuloiu <cristian.caciuloiu@nxp.com>",59771425
1093,2020-02-07T13:26:45Z,2020-03-06T20:22:54Z,,,I was not able to fully test this as the board was constantly crashing shortly after boot. I also saw crashes without these patches so the culprit is most likely elsewhere.,59771425
1094,2020-02-07T11:12:07Z,2020-02-20T13:04:31Z,,,"This PR adds support for Privacy on the VEGA Board

Depends on https://github.com/zephyrproject-rtos/hal_openisa/pull/4",59771425
1095,2020-02-06T11:49:09Z,2020-02-28T21:09:38Z,,,"Add burner for pyocd to support:
west flash
west debug
west debugserver

Signed-off-by: Frank Li <lgl88911@163.com>",59771425
1096,2020-02-05T22:21:55Z,2020-02-13T06:12:11Z,,,"Update `flash` shell commands to take a device argument, similar
to the `eeprom` shell command, instead of using the chosen flash device.

Signed-off-by: Ivo Clarysse <ivo@bcdevices.com>",59771425
1097,2020-02-05T14:56:03Z,2020-02-05T15:07:11Z,,,"Update mbedTLS commit along with the following fixes:

* Fix naming inconsistencies in some cipher modes, to match core mbedTLS
  configs
* Add Kconfig to enable CTR cipher mode

Fixes #22421

Signed-off-by: Robert Lubos <robert.lubos@nordicsemi.no>",59771425
1098,2020-02-05T11:13:32Z,2020-03-19T15:08:49Z,,,"When the system is powered directly a measurement of Vdd provides the battery voltage.  This requires a different ADC configuration and level curve.

Originally provided as an alternative to support #22414, now updated to replace that PR.",59771425
1099,2020-02-05T10:26:19Z,2020-02-25T05:42:26Z,,,"Integrated temperature sensor sample fetch and use of the value
in the GATT indications.

Use CONF_FILE=nrf5.conf on nRF5 Series SoCs to use die
temperature sensor values.

Added central sample to read die temperature value from peripheral
device

Signed-off-by: Charan Pudiyaneravana Venkatesh <charan.pv@sixoctets.com>",59771425
1100,2020-02-05T09:49:50Z,2020-02-07T10:54:14Z,,,Signed-off-by: Steve Osselton <steve@iotechsys.com>,59771425
1101,2020-02-04T19:47:27Z,2020-03-26T14:13:16Z,,,This series of patches adds support for the NXP Kinetis Low Power Timer (LPTMR) present in e.g. the NXP KE1xF SoC series.,59771425
1102,2020-02-04T13:59:03Z,2020-02-21T10:56:07Z,,,"Use the device-tree to define which RTC should be used
by the LoRa driver.",59771425
1103,2020-02-04T11:33:17Z,2020-03-17T11:57:15Z,,,"Added feather header pinout and updated an example board using it.

![nRF52 Feather Pinout](https://cdn-learn.adafruit.com/assets/assets/000/043/921/original/microcontrollers_nRF52Pinout.png?1500272417) ",59771425
1104,2020-02-04T08:27:24Z,2020-02-10T07:06:46Z,,,"Implement driver for Ilitek ili9163
",59771425
1105,2020-02-03T14:27:38Z,2020-03-17T14:25:04Z,,,"Attempting to mount, as FAT, unformatted volume would invoke formatting.
The formatting would fail for volumes that are too big to be handled
by FAT12, which has been selected as only allowed format.
This patch allows driver to select smallest possible FAT format that
can handle the volume size.

Signed-off-by: Dominik Ermel <dominik.ermel@nordicsemi.no>",59771425
1106,2020-02-03T11:58:57Z,2020-02-15T04:19:29Z,,,"Introduce support for the Cortex-A ""APU"" CPU embedded into the Xilinx ZynqMP SoCs.

| ./scripts/sanitycheck -p qemu_cortex_a53_zynqmp
| ...
| Total complete:  191/ 191  100%  skipped:   43, failed:    0

Signed-off-by: Carlo Caione <ccaione@baylibre.com>",59771425
1107,2020-02-03T07:39:24Z,2020-02-18T17:40:05Z,,,"A draft showing how to handle external API with devices.

Short summary:
- device structure gets additional field - a pointer to extension api structure which contains mask of capabilities and pointer to data. if more than one extension is supported then data is an array of pointers associated with each api. https://github.com/zephyrproject-rtos/zephyr/blob/47ec30148aeedc61dcce6d2d1da3f3b0873473b6/include/device.h#L302
- device.h gets internal api for checking if device supports given extension (`z_device_ext_api_supported(dev, bitmask)`) and getting data associated with that extension (`z_device_ext_api_get_data(dev, bitmask)`) https://github.com/zephyrproject-rtos/zephyr/blob/47ec30148aeedc61dcce6d2d1da3f3b0873473b6/include/device.h#L328 
- external api (onoff service in that example) implements simple inline like `device_get_onoff_service(dev, &srv)` https://github.com/zephyrproject-rtos/zephyr/blob/47ec30148aeedc61dcce6d2d1da3f3b0873473b6/include/sys/onoff.h#L434

Example:
```
err = device_subsys_get_onoff_service(clock, subsys, &srv);
if (err < 0) {
    LOG_ERR(""Failed to get device onoff service (err: %d)"", err);
}

err = onoff_request(srv, &client);
```

Signed-off-by: Krzysztof Chruscinski <krzysztof.chruscinski@nordicsemi.no>",59771425
1108,2020-01-31T16:39:27Z,2020-02-03T08:29:40Z,,,,59771425
1109,2020-01-31T12:51:43Z,2020-02-06T21:40:26Z,,,"This PR is created to focus on API review. It is extracted from #21641 which contains reference implementation on nRF SPIM peripheral.

A draft of SPI API extension. Following API introduces:
- transaction concept. Transaction consists of SPI configuration and messages
- transaction can be scheduled and canceled
- multiple control pins support to allow:
  - controlling cmd/data pin for displays
  - transaction for multiple devices (with the same configuration)
- message is simplex (one direction) and with additional flags it configures:
  - cs0 control (set/nop on start, clear/nop on end)
  - direction
  - delay
  - pausing after completion (e.g. to wait for rdy pin, spi_resume() resumes)
  - optional cs1 control (e.g. to control cmd/data pin)
- two driver specific functions:
  - `spi_single_transfer()` - asynchronous raw spi transfer
  - `spi_configure()` - spi configuration
- generic spi functions (vendor agnostic)
  - `spi_schedule()`
  - `spi_cancel()`
  - `spi_resume()`
- helper macros for creating set of spi messages

Note that:
- `qop_mngr` is queued operation manager. A module which will be responsible for managing execution of asynchronous operations which are requested by multiple asynchronous users.
- `async_client` is a generic asynchronous client see `struct onoff_client` in `include/sys/onoff.h`

Adding this extension brings following improvements:
- spi transfers can be scheduled from any context
- reduced cpu usage (test shows ~20% gain) since less context switches occurs
- simpler transfer setup (see demo sample https://github.com/nordic-krch/zephyr/blob/i2c_async/samples/drivers/spi_async/src/main.c)
- setting typical simplex transfers (like TX followed by TX or RX) require less memory (2 vs 4 messages)
- support for driving data/cmd pin often seen in displays.
- support for pausing/resuming transactions (e.g. pend on rdy pin) - removing the need for lock/release feature
- ability to setup multi message transaction and get notification once whole is completed (or error occurs), e.g. sensor setup sequence. Messages can be then in flash.
- vendor specific functions simplified

Signed-off-by: Krzysztof Chruscinski <krzysztof.chruscinski@nordicsemi.no>",59771425
1110,2020-01-31T06:34:45Z,2020-03-19T09:34:31Z,,,"Dear all,

I placed this pull request for as request of comments. I will gladly edit this futher, but before doing more work i would like to ask your opinion on the subject.

As far as i know, there is currently no way to define ""default"" UART parity from the device tree. I need the feature to work with certain (HC-05) bluetooth adapter that i want to keep in certain settings (15200 8E1 - same as stm32 system bootloader - whose settings cannot be modified).

Now i am pretty sure the setting should be at device tree, and actually not on stm32 bindings, but on general uart bindings. Now the pull on general bindings sounds so large i am sure i have no time, so this is suggestion of adding the support to stm32 only.

In addition this commit has edited fixup (`soc/arm/st_stm32/stm32f1/dts_fixup.h`)only for STM32F1 (that seems to be required for compile ok) - i am not sure are those fixup files meant for manual editing

Thanks for your time,
Pauli",59771425
1111,2020-01-29T12:33:47Z,2020-02-03T07:48:16Z,,,"Use existing functions to compute the start of the TCP header. Add a check on CONFIG_HEAP_MEM_POOL_SIZE in order to have memory for k_{c,m}alloc used by tcp2.c.

DNM until tested.",59771425
1112,2020-01-28T16:09:56Z,2020-02-12T14:27:16Z,,,"Propose an alternative solution for to use with blank_led and
fade_led samples when no on-board PWM connected LED is available
on the targeted board.
User will have to provide an overlay file matching his
own set up using a LED connected to a PWM pin on his board.
An example of overlay, tested onnucleo_f401re is provided.

This solves the error reported by user that can't use PWM basic
sample due to board limitations.

Fixes #22091

Signed-off-by: Erwan Gouriou <erwan.gouriou@linaro.org>",59771425
1113,2020-01-28T09:42:34Z,2020-01-31T13:31:12Z,,,"Example shows how to use settings with NVS backend.
It shows usage of save and save_one + set/export handlers.

Signed-off-by: Bartłomiej Żarnowski <bartlomiej.zarnowski@intive.com>",59771425
1114,2020-01-28T07:18:42Z,2020-02-22T08:16:59Z,,,"A set of edtlib.py enhancements that proved useful to implement an OOT pin controller driver, clock controller driver, flash driver, gpio leds driver (using code generation). 

This makes edtlib more complete. It should also simplify defines generation in gen_defines.py, especially for pin controllers and clock controllers. 

Comments welcome.

dts: edtlib: enable bindings for special nodes without compatibles
--------------------------------------------------------------------------------------
```
Associate a default compatible to special nodes that by specification
do not have or can not have a compatible.
The default compatible allows to use bindings for nodes that otherwise
can not be controlled by a binding.

Default compatible for special DTS nodes:
  - '/aliases' node                       : 'aliases'
  - '/chosen' node                        : 'chosen'
  - pin controller pinctrl state node     : 'pinctrl-state'
  - pin controller pin configuration node : 'pincfg'
  - fixed partition node                    : 'fixed-partition'
  - gpio led node                              : 'gpio-led'

Default compatibles are only associated if no compatible is given.
```

dts: edtlib: allow binding override by binding file name
-----------------------------------------------------------------------
```
Allow to override a binding by file name. Take the first file
given by the binding directories provided to edtlib.

This allows applications and out of tree drivers to amend
a binding already given by Zephyr.

Warn in case there are duplicate binding file names.
```

dts: edtlib: allow extraction of gpio-ranges properties
---------------------------------------------------------------------
Handling of 'gpio-ranges' is a must to implement pin controllers.  
```
gpio-ranges properties expect a phandle value list.
Extend _standard_phandle_val_list() to also work on gpio-ranges.
```

dts: edtlib: extract pinctrl state and pin configuration nodes
-----------------------------------------------------------------------------
```
Extract the pin controller child nodes for pinctrl state and pin
configuration.

Extract gpio ranges controlled by the pin controller.

Provide a PinCfg object that represents the pin configuration
data for easy access.

Extend the Node class with properties for:

  pinctrl_states:
    A list with the Node instances for the 'pinctrl-state' children of
    a pin controller node. The list is empty if the node does not have any
    pinctrl state children.

  pincfgs:
    A list of PinCfg objects for the 'pinctrl-state' node. The list is
    empty if the node is not a 'pinctrl-state' node.

  pinctrl_gpio_ranges:
    A list of ControllerAndData objects of the gpio ranges a pin controller
    controls. The list is empty if the node is not a pin controller or no
    'gpio-ranges' are defined by the gpio nodes.

  pin_controller:
    The pin controller for the node. Only meaningful for nodes representing
    pinctrl states.
```

dts: edtlib: extract clock inputs and clock outputs
----------------------------------------------------------------
```
Extract clock inputs ('clocks') and clock outputs ('clock-output-names')
properties.

Extend the Node class with properties for:

  clocks:
    A list of ControllerAndData objects for the clock inputs on the
    node, sorted by index. The list is empty if the node does not have a
    clocks property.

  clock_outputs:
    A list of ControllerAndData objects for the clock outputs on the
    node, sorted by index. The list is empty if the node does not have a
    \#clock-cells property.
```

dts: edtlib: extract partitions nodes
---------------------------------------------
```
Extract the partitions child node of flash nodes.

Extend the Node class with properties for:

  partitions:
    A list of Partition objects of the partitions of the 'partitions'
    node of a flash. Only meaningful for nodes representing a flash -
    otherwise an empty list.
```
dts: edtlib: extract gpio led nodes
-----------------------------------------

```
Extract the gpio led child node of gpio leds controller nodes.

Extend the Node class with properties for:

  gpio_leds:
    A list of ControllerAndData objects of the leds a gpio leds
    controller controls. The list is empty if the node is not a
    gpio leds controller or it does not have gpio led children.
```

dts: edtlib: issue same warning only once
-------------------------------------------------------
Repeating the same warning is just an annoyance.
```
Issue a warning only on first occurence. Suppress all following
warnings having the identical warning text.
```",59771425
1115,2020-01-27T12:58:58Z,2020-03-19T12:12:42Z,,,"Add implementation to support ADV_EXT_IND PDU with AuxPtr. Changes in this commits prepares the ADV_EXT_IND PDU in the primary channel, prepares the AUX_ADV_IND PDU in the auxiliary channel.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>",59771425
1116,2020-01-27T12:58:49Z,2020-01-30T15:15:22Z,,,"Add test script for cdc_acm sample.
The script simply sends a block to the device and
expects the same block back.",59771425
1117,2020-01-27T10:01:50Z,2020-03-25T19:14:01Z,,,"Newest mcuboot uses move swap instead of scratch
for nRF devices

Share the leftover scratch flash between image 0 and image 1.
For trustzone enabled devices, give the non secure
partitions the extra space.

Adjusted test overlays to above changes.

[EDIT]
removed manifest upgrade from the patch content
manifest upgrade is here #22369 
merge after that PR.

Signed-off-by: Håkon Øye Amundsen <haakon.amundsen@nordicsemi.no>
Signed-off-by: Andrzej Puzdrowski <andrzej.puzdrowski@nordicsemi.no>",59771425
1118,2020-01-23T19:00:33Z,2020-02-07T00:43:18Z,,,"Using --number-of-runs <int> we now can run a single test multiple times
to test for reproducibility and to catch sporadic failures.

The output looks like this:

```
i9:zephyr(rerun_sc): sanitycheck -p mps2_an385 -T tests/kernel/tickless/tickless_concept/ --number-of-runs 10
Renaming output directory to /home/nashif/Work/zephyrproject/zephyr/sanity-out.17
INFO    - JOBS: 20
INFO    - Building initial testcase list...
INFO    - 1 test configurations selected, 0 configurations discarded due to filters.
INFO    - Adding tasks to the queue...
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (1/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (2/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (3/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (4/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (5/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (6/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (7/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (8/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (9/10 100.00% passrate): passed
INFO    - Ran mps2_an385/tests/kernel/tickless/tickless_concept/kernel.tickless.concept (10/10 100.00% passrate): passed
INFO    - Total complete:    1/   1  100%  skipped:    0, failed:    0
INFO    - 1 of 1 tests passed (100.00%), 0 failed, 0 skipped with 0 warnings in 54.65 seconds
INFO    - In total 1 test cases were executed on 1 out of total 219 platforms (0.46%)
```
",59771425
1119,2020-01-23T14:02:24Z,2020-02-26T15:21:06Z,,,,59771425
1120,2020-01-23T13:09:29Z,2020-01-23T21:20:05Z,,,"Added module for handling reset reason. It reads out hardware register
and clears it. Actual reset reason can be retrieved using
nrf_reset_reason API.

I've put include file in`soc/arm/nordic_nrf` since there is no `include\soc` so far (should be?). Maybe it's intentional to keep `soc` includes away from main include folder.

General idea: read reset reason once and clear register, users can access reset reason through api.

Special cases
- nrf53. it seems (i did not test it) that `NRF_RESET->RESETREAS` contains application only reason for application and application+network on network. Because of that on network core reasons are being masked to only read/clear network specific reasons
- bootloader: it does not clear reset reason since it's likely that application expects reset reasons (e.g. gpio, nfc wakeup, pin reset, et.c). Bootloader reads them but do not clear them as it also may need to use it (e.g. skip hash checking on gpio wakeup). Because of that it may happen that there will be 2 reset reasons set (e.g. wakeup from gpio, before it is cleared pin reset occurs). In order to avoid confusion user can use `nrf_reset_reason_primary_get()` to get only one bit set, the most LSB bit assuming that they are ordered by ""relevance"" in the register. In case watchdog reset occurs in bootloader, application will start with primary reset reason being `watchdog` which might be confusing but it is a result of bootloader not clearing the reset reason. It's then bootloader responsibility to manually clean watchdog reset reason if it is aware of triggering it.

Signed-off-by: Krzysztof Chruscinski <krzysztof.chruscinski@nordicsemi.no>",59771425
1121,2020-01-23T01:23:24Z,2020-01-29T15:48:45Z,,,"Commit 80aec783e5 (""boards: frdm_kw41z: set VREF to alternate source"")
changed the default configuration for frdm_kw41z to set
CONFIG_ADC_MCUX_ADC16_VREF_ALTERNATE=y, but that does not prevent the
selection from being changed to CONFIG_ADC_MCUX_ADC16_VREF_DEFAULT=y.

Another issue is that the warning below printed when ADC_MCUX_ADC16 is
not enabled, because ADC_MCUX_ADC16_VREF_ALTERNATE depends on it:

    warning: the choice symbol ADC_MCUX_ADC16_VREF_ALTERNATE (defined at
    drivers/adc/Kconfig.mcux:45) was selected (set =y), but no symbol
    ended up as the choice selection. ...

Refactor things so that ADC_MCUX_ADC16_VREF_DEFAULT can't be chosen on
frdm_kw41z, using a helper symbol. That gets rid of the warning and
makes things a bit more robust.

Select the helper symbol with 'imply' instead of 'select', just to save
an '... if ADC_MCUX_ADC16' on the 'select'. 'imply' works like a
'select' that respects dependencies.",59771425
1122,2020-01-22T14:04:08Z,2020-03-23T14:14:37Z,,,"Changes:
- Added all required board files in /boards/arm/96b_aerocore2
- Modified pinmux for stm32f4
- Add stm32f427 support based on previous work done for the stm32f429.
- Rework currunt stm32f429 implimentation to now be based on stm32f427.
- Introduce dedicated dtsi for the VI variant of both stm32f427 and stm32f429. This is done to prevent stm32f4.dtsi from being included twice.

Most of the changes in this PR is based on reverse-engineering the PCB
layout and following commits in the PX4 firmware repository for the
same board. The manufacturer does not provide and or generate schematics
and pinout tables for this board.

This PR includes almost all of the interfaces connected to the STM32
MCU, the only thing not included is the J9 and J8 headers that connect
to a 96Boards baseboard. These headers are not vital to the functionality
of the Aerocore2.

Signed-off-by: Sahaj Sarup <sahaj.sarup@linaro.org>",59771425
1123,2020-01-20T13:53:10Z,2020-01-20T17:30:03Z,,,"Breathe and sphinx_rtd_theme generate some new deprecation warnings with
Sphinx 1.8. Suppress them.

There's an upstream fix for the sphinx_rtd_theme issue, but it's not in
a sphinx_rtd_theme release yet. See the comment.",59771425
1124,2020-01-20T07:49:06Z,2020-01-31T18:32:04Z,,,"The reference to the modules guide was broken in the 'Application Development/Source Tree Structure' . This should fix it.

Signed-off-by: Jens Peter Schroer <jens@blixt.tech>",59771425
1125,2020-01-17T16:08:09Z,2020-03-25T15:48:26Z,,,"Enable peripheral to memory or memory to peripheral dma operations through the DMAMUX on STM32xx. 
It upgrades the dma driver, with the new dmamux controller for the soc which supports the feature.
Tested on nucleo_wb55rg for mem-to-mem  ans peripheral to/from memory transfers.
The periph-to/from-mem transfer has a fixed configuration to be updated depending on the client cell.
During dma transfer with dmamux, the dma drivers does not handle the Half Transfer IRQ (ht).

Requires the spi_dma https://github.com/zephyrproject-rtos/zephyr/pull/23157

Signed-off-by: Francois Ramu <francois.ramu@st.com>",59771425
1126,2020-01-17T14:31:13Z,2020-03-26T15:39:41Z,,,"Add extended advertising API. The use-cases that are included in this
are Extended Advertising Data, connecting using Long Range feature, and
multiple advertisers.

----
The new advertising API and the options for scanning and creating connections should be backwards compatible. The advertising set API is modeled to be similar to the connection API.

I intend to keep the old advertising API in addition to the new advertising set API when Extended Advertising Feature is enabled. The use-case for this is to continue with the old Advertising API while using the new Extended Advertising HCI commands. This has the advantage of enabling advertising with a different Identity while scanner/initiator uses the default Identity. In this case the stack will keep an advertising set internally and manage this without giving away the advertising set reference.

Periodic advertising has not been considered yet. But I think this feature can be made as an addition on top of the advertising set API. I'm not sure if we should include periodic advertising in this PR, but if we don't then we should atleast make sure that it can be added without requiring changes to the advertising set API.

Following changes to the existing API:
 - Remove BT_LE_SCAN_FILTER_EXTENDED (not functional, and shouldn't have been added in the first place).
 - Renamed scan filter_dup to options in struct bt_le_scan_param 
 - Renamed scan filter options enum values prefix from BT_LE_SCAN to BT_LE_SCAN_OPT.
 - Removed BT_LE_ADV PDU types defined in hci.h and introduced new defines in gap.h
 - Rename bt_conn_create_le to bt_conn_le_create, this changes to return error code instead and having the conn object as out parameter, and additional parameters to control scan parameters and scan options of the initiator.
 - Rename bt_conn_create_slave_le to bt_conn_le_create_slave, this changes to return error code and having th econn object as out parameter.

Note about privacy and OOB data.
There is only a single RPA timer, this has the implication that if one RPA address needs to be cycled by the host, then all RPA addresses are cycled and RPA timeout reset. Addresses are cycled by the host in the following cases:
 - RPA timeout  (normal case)
 - Generating OOB data
 - Calling `bt_conn_le_create` close to the RPA timeout (3 seconds is default).

To handle the case where duration and num_events are used as advertising parameters > 0, this type of advertiser is defined as a ""limited"" advertiser, meaning it will be stopped by controller once a limit has been reached.
A limited advertiser is not bound by the RPA timeout, instead it generates a new RPA address each time it is started, and cannot be active for longer than the RPA timeout value. In a sense it has its own RPA timer.
To get the OOB data for central role, or an advertiser started using `bt_le_adv_start` then `bt_le_oob_get_local` should be used.
To get the OOB data for advertisers started using`bt_le_ext_adv_create` then `bt_le_ext_adv_oob_get_local` should be used.

Currently I have decided to leave out the following features:
The use of period.
Channel MAP (also not present in old API).

Features that will be improved later:
Limited functionality to only one advertising set.
Extendend advertising data fragmentation and re-assembly.

Fixes: #18047
Fixes: #18046
Fixes: #18050

Fixes: #23247",59771425
1127,2020-01-14T09:09:59Z,2020-01-14T12:33:43Z,,,"When using UART for ""asynchronous"" communication,
the echo of the input may break the output to read.

With the introduction of a new config option
CONFIG_UART_CONSOLE_SUPPRESS_ECHO,
the echo may be suppressed if needed.

Signed-off-by: Stefan Diewald <dwld@users.noreply.github.com>",59771425
1128,2020-01-14T08:00:31Z,2020-01-14T08:22:53Z,,,"Due to current cursor/end being uint8, setting the parameter CONFIG_CONSOLE_INPUT_MAX_LINE_LEN above 255 has no effect and even leads to strange effects by means of cut off lines.",59771425
1129,2020-01-13T23:44:13Z,2020-02-13T13:22:30Z,,,"Disable display update mode 2 by default,
ssd16xx, allow to use WS from OTP memory,
Add support for GDEH0154D67 display",59771425
1130,2020-01-13T22:06:14Z,2020-01-19T03:17:25Z,,,"Show that a user thread holding the CPU can be interrupted due to
a timer interrupt, and survive context across the servicing of
that interrupt.

Do this twice, to be sure.

At the end, verify that we're still in user mode.

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>",59771425
1131,2020-01-13T12:39:28Z,2020-03-11T17:44:20Z,,,"Sample tries to estimate maximum number of messages that can be
logged. It was using two system cycles and counting number of
messages logged in that window. It did not take into account the
fact that clock frequency may vary and logging speed also varies
(especially if LOG_IMMEDIATE is enabled). Presented results may
be faulty and misleading.

Fix is attempting to adjust window size to increase precision of
the measurement.

Fixes #21801 .

Signed-off-by: Krzysztof Chruscinski <krzysztof.chruscinski@nordicsemi.no>",59771425
1132,2020-01-10T19:23:47Z,2020-01-12T10:35:11Z,,,"By resetting the reel board (pressing user button with the reset button) the write protection is disabled and the displayed text will be erased. With active write protection the board remains in mesh-mode and there is no possibility to access it via bluetooth.

Signed-off-by: Juergen Koerner <juergen.koerner@t-online.de>",59771425
1133,2020-01-10T13:51:07Z,2020-03-13T08:29:01Z,,,"Port advanced scheduling implementation from legacy
controller.

This implementation schedules
- non-overlapping scan window when there are simultaneous
central connections active
- central connection establishment with similar connection
intervals be placed in a non-overlapping  group, temporally
- connection parameter request with calculated window offset
hints to have non-overlapping BLE radio events.

Signed-off-by: Vinayak Kariappa Chettimada <vich@nordicsemi.no>

![tempsnip](https://user-images.githubusercontent.com/6350656/72157527-73526480-33b8-11ea-9d85-1e46e9f50859.png)
",59771425
1134,2020-01-09T21:19:02Z,2020-03-20T13:49:51Z,,,"Fixes #3076. 

Here is a suggestion to implement the DAC driver.

As it is the first time I'm implementing a driver for Zephyr, please be forgiving if something was not done the usual or correct way. Just let me know what can be improved.

I tested the driver with an STM32L073RZ Nucleo board. As soon as we agree on the API, i can also add additional STM32 MCUs. I've got a board with STM32G431 for testing aswell.

Unfortunately, I don't know very much about DAC features of other manufacturer's MCUs. I decided not to include special STM features like sawtooth wave generation into the generic API (not sure if that's a typical feature). Also DMA is currently not supported. The only configuration is whether a channel should be buffered or not.

Similar to the ADC driver, the resolution is defined for each write request rather than once per channel at the beginning.",59771425
1135,2020-01-08T10:51:05Z,2020-02-12T17:03:15Z,,,"Provide board support for the Seeed Wio LTE Cat.1
 - http://wiki.seeedstudio.com/Wio_LTE_Cat.1/

This is an early pull-request marked as RFC, to kick off review, and try and get the tests running and of course see what else I need to do for integration.

I am aware of the lack of documentation, so I'm fully aware this isn't ready yet, that's next - but any comments on anything specific in the board support would be welcome.

Signed-off-by: Kieran Bingham <kbingham@kernel.org>",59771425
1136,2020-01-07T15:14:15Z,2020-03-07T12:37:26Z,,,"fix bss section be copy to binary

Signed-off-by: Frank Li <lgl88911@163.com>",59771425
1137,2020-01-06T00:52:27Z,2020-01-09T16:15:36Z,,,"This patch allows to retrieve available drivers for certain
types of devices based on the prefix in the name.

If the name is formed according to the rule TYPE_DEVICE then
a subsystem can find a appropriate drivers/devices
without additional configuration.

For example: a display could have the name DISPLAY_SSD1306,
a IEEE802154 transceiver the name 802154_MCR20A,
and a temperature sensor TSENSOR_HDC1010.

TODO: add test to `tests/kernel/device`
",59771425
1138,2020-01-03T14:54:45Z,2020-01-28T19:17:56Z,,,"In drivers/spi/spi_oc_simple.c, the following array with 11 elements is defined:
```c
u8_t DIVIDERS[] = { 0x00,       /*   2  */
		    0x01,       /*   4  */
		    0x10,       /*   8  */
		    0x02,       /*  16  */
		    0x03,       /*  32  */
		    0x11,       /*  64  */
		    0x12,       /* 128  */
		    0x13,       /* 256  */
		    0x20,       /* 512  */
		    0x21,       /* 1024 */
		    0x22,       /* 2048 */
		    0x23 };     /* 4096 */
```
Which is later used as:
```c
/* Set clock divider */
	for (i = 0; i < 12; i++)
		if ((config->frequency << (i + 1)) >
		    CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC) {
			break;
		}
	sys_write8((DIVIDERS[i] >> 4) & 0x3, SPI_OC_SIMPLE_SPER(info));
	spcr |= (DIVIDERS[i] & 0x3);
```

If the condition in the for loop isn't true, the variable ""i"" will be 12 when DIVIDERS is indexed, which will be out of bounds",59771425
1139,2020-01-03T14:18:10Z,2020-01-09T14:37:20Z,,,"Extended internal temperature sensor on nrf5 platform to support
custom, asynchronous API.

Internal sensor is mainly used by clock calibration and sensor API
is inconvenient since it cannot be called from interrupt context.

Signed-off-by: Krzysztof Chruscinski <krzysztof.chruscinski@nordicsemi.no>",59771425
1140,2020-01-01T03:30:33Z,2020-03-07T18:58:20Z,,,"Hey all. As suggested by @cvinayak , I'm making a PR to see if I can get some more eyes on the issues. Currently ADV_IND / SCAN_REQ / SCAN_RSP works as well as receiving CONNECT_IND. Finally, we are receiving ""event 1"" in the transmit window and establishing an anchor. Receiving LL_FEATURES_REQ, but improperly sending an empty Data PDU in response.

It's suggested to add `CONFIG_LOG_BUFFER_SIZE=24580` to `samples/bluetooth/ipsp/prj.conf` and to use that as a test application.

If you have an oscilloscope handy, you can use pins 30, 5, 23, and 24 to observe TX, RX, ISR, and BLE TX Window events, respectively.

- [ ] Fix copyrights / board & vendor references in comments (@cvinayak)
- [ ] Refactor CMakeLists.txt for separate SoC vendor (@alexandru-porosanu-nxp)
- [ ] Come to a consensus about the RTC interrupt (@vanti, @bwitherspoon)

",59771425
1141,2019-12-27T15:46:47Z,2020-02-05T20:48:15Z,,,"Having no 'required:' key for a property works the same as having
'required: false' at the moment, though it's undocumented.

Instead, require properties to have 'required: true/false'. Almost all
bindings already seem to assume it's required.

Could have turned a missing 'required:'  into a warning instead of an
error as well, but I think it might be overkill since so few places
skipped it.

Also list 'type:' before 'required:' in dts/binding-template.yaml, to
match what most bindings do.",59771425
1142,2019-12-27T08:42:07Z,2020-03-24T15:52:42Z,,,"This PR adds the ARM CMSIS-DSP (digital signal processing) library integration to the Zephyr RTOS.

```
ext: hal: Add CMSIS-DSP library

This commit adds the initial port of the ARM CMSIS-DSP library for
use with the Zephyr RTOS.

The following is the list of the changes from the official CMSIS-DSP
library available in the upstream CMSIS distribution.

1. CMake build files (CMakeLists.txt) were re-written to be used as
  part of the Zephyr CMake build system.

2. The existing CMake-based configuration options were re-structured
  and re-written using Kconfig (menuconfig is fully supported).

There is no change from the upstream CMSIS-DSP distribution in terms
terms of the library implementation source code (*.c, *.h files).

Derived from the following commit in ARM-software/CMSIS_5:
b72a77cab226167186858a5fab0423fdc66e2193

Signed-off-by: Stephanos Ioannidis <root@stephanos.io>
```

This PR includes the commits from #21636.

Closes #21636 if merged before.",59771425
1143,2019-12-26T06:54:54Z,2020-01-06T03:44:36Z,,,"The alignment of the data segment should be determined by the
data segment itself, rather than relying on the previous segment
fix #21554 

Signed-off-by: ZhongYao Luo <LuoZhongYao@gmail.com>",59771425
1144,2019-12-23T12:44:01Z,2020-02-13T17:07:01Z,,,"This PR adds leds gpio driver which is used to control the LED devices attached to the GPIO pins through the LED API. The driver support `led_on` , `led_off` and `led_blink`. The blink feature is realized by using software timer and can be disabled from compilation. Driver can handle all LEDs defined in DTS which contains id field. The `led_set_brightness` is not supported and I see no need to add it in case of the GPIO.

There are plans in feature to extend this driver to support power management.

Generation of the common static initializers for child-bindings is needed for this driver. It is provided in the #21393 PR. The first three commits come from there and driver will be rebased if #21393 will be merged, so them are not a part of this PR. Also driver needs additional id field in the DTS led description. This filed is not required to to ensure backward compatibility and it should be added to use this driver.",59771425
1145,2019-12-20T10:32:05Z,2019-12-20T14:27:42Z,,,"Add kconfig option for the Bluetooth disable API. When this option is
enabled the interrupts in the controller should be configured as dynamic
interrupts so that the application can re-use these interrupts when
bluetooth controller has been disabled.

This is based on top of #21516 so only the last commit is part of this PR",59771425
1146,2019-12-19T15:15:57Z,2020-03-26T12:21:42Z,,,"Tested on nRF52840 only, may not work for other platforms.

Two sample apps attached:
-> headphones + microphone
-> headset

Both apps perform loopback. See README.rst for details.

Fixes: #12775",59771425
1147,2019-12-19T12:11:53Z,2020-01-16T19:24:51Z,,,"The aim of this PR is to utilize the functionalty provided by newlib for thread-safety. 

RFC #21519

## Relevant Links

### Documentation
[Newlib Documentation on __malloc_lock](https://sourceware.org/newlib/libc.html#g_t_005f_005fmalloc_005flock)

[Newlib Documentation on Reentrancy](https://sourceware.org/newlib/libc.html#Reentrancy)

### Mailing Lists
[Newlib discussion on `--enable-newlib-retargetable-locking`](https://newlib.sourceware.narkive.com/s5jTeAUp/patch-newlib-allow-locking-routine-to-be-retargeted)

[[PATCH, newlib] Allow locking routine to be retargeted](https://sourceware.org/ml/newlib/2016/msg01165.html)

[What are the __retarget_lock functions?](http://sourceware-org.1504.n7.nabble.com/What-are-the-retarget-lock-functions-td531854.html)",59771425
1148,2019-12-19T04:13:05Z,2020-02-13T17:54:10Z,,,"Remove almost all special-casing for `clocks = ...` properties and
handle them with the generic phandle-array code. The commits
below make the required changes to C and header files.

These output inconsistencies were fixed to able to reuse the
phandle-array code:

 - Properties like `pwms = ...` and `*-gpios = ...` generate identifiers
   with `PWMS` and `GPIOS` (note the -S), while `clocks` generated
   `CLOCK`.

 - A non-indexed `*_CLOCK_<clock-cells entry>` identifier (as opposed to
   `*_CLOCK_<clock-cells entry>_0`) was always generated, regardless of
   how many clocks there were. Properties like `pwms = ...` only
   generate a non-indexed identifier if there's a single entry in the
   phandle-array.

   (In practice, no `clocks = ...` has more than one entry in Zephyr.)

The only special-casing that remains is for `fixed-clock`:
`write_clocks()` is now `write_freq()`, which writes the `clock-frequency`
from any controller in `clocks` that's compatible with `fixed-clock`.

Besides reducing code duplication and making things less surprising and
easier to understand, this change has two nice side effects:

 - `description:` texts now show up for clocks now show up in the output

 - Static initializers like

       #define ..._CLOCKS {""SIM"", 0, 4152, 20}

   now get generated.

Also add a check for `clocks` being a phandle-array in `write_freq()`.

Using the old macros now generates a warnings saying to use `*_CLOCKS_*' instead of `*_CLOCK_*`, via these commits:

```
scripts: gen_defines.py: Add out_dev() flag for deprecated macros

Add a 'deprecation_msg' string/flag to out_dev(). When 'deprecation_msg'
is passed, all generated macros include

    _Pragma(""GCC warning \""<deprecation_msg>\"""")

which prints a customizable warning if the macro is used.

Meant to be used when improving the output format.
```

```
scripts: dts: Generate deprecated clock #defines with warnings

Add back generation of the the non-phandle-array-consistent clock
defines, but generate deprecation warnings for them if they're used,
with a message saying to use *_CLOCKS_* instead of *_CLOCK_*.
```

Fixes in C code:

```
devicetree: dts_fixup.h: Remove unused *_CLOCK_{BITS,BUS}_0 macros

Copy-pasted around. Not used anywhere in the code. Equivalent to
*_CLOCK_{BITS,BUS} without an index.

I'm adapting all clock code to the preceding gen_defines.py change, and I'd
rather remove unused identifiers than fix them.
```

```
devicetree: dts_fixup.h: Use *_CLOCK_{BITS,BUS} without _0 suffix

Correct as long as there's a single clock in 'clocks = ...', which there
always is at the moment.

Makes the code compatible with write_phandle_val_list_entry().

Adapting all clock code to the preceding gen_defines.py change.
```

```
devicetree: s/CLOCK/CLOCKS/ in references to generated macros

gen_defines.py generated macros with 'PWMS' and 'GPIOS' in them for
'pwms = ...' and '*-gpios = ...', but 'clocks = ...' generates 'CLOCK',
with no -S. Replace 'CLOCK' with 'CLOCKS' to fix the inconsistency.

Adapting all clock code to the preceding gen_defines.py change.

I was careful to not change any macros defined in dts_fixup.h files
(which are currently also prefixed with 'DT_').
```",59771425
1149,2019-12-18T14:21:23Z,2020-01-07T16:23:10Z,,,"Redesign of USB transfers.

This is draft for rework on USB transfers.
Split off #21350 and still based on it.",59771425
1150,2019-12-16T13:45:34Z,2019-12-16T13:51:22Z,,,"This is a draft PR which demonstrates multidomain logger on two cpu cores using openamp.
Sample is located in `samples/boards/nrf53/logging` and it consists of two parts (`app`, `net`). Network core has openamp backend which passes log messages to the application core. On application core `openamp` link is receiving messages from another domain and mix them together will local log messages. Application has shell enabled and logger on both domains can be controlled (e.g. `log enable wrn net/app` to set warning level for `app` log module on net domain). Logs on remote domain are controlled in shell the same way as on local, including autocompletion.

This PR is based on #19778 and #19718 ",59771425
1151,2019-12-16T13:07:46Z,2019-12-17T12:11:49Z,,,I would really like to get read of dedicate pool for string duplicates and use logger message pool. RAM usage is very inefficient and it's hard to tune actual buffer size. It would be much better to keep those strings in the message pool but that means that they are stored in fragmented chunks and straight forward string format specifier processing won't handle that. This PR enables forwarding strings to the logger. Logger based on the address determines if it is a string duplicate and if yes processes it else do nothing.,59771425
1152,2019-12-16T08:28:08Z,2019-12-16T08:28:34Z,,,It's using PR #21241 and PR #21406 as a dependency,59771425
1153,2019-12-16T08:26:47Z,2020-01-09T08:01:17Z,,,It's using PR #21241 as a dependency ,59771425
1154,2019-12-14T23:05:20Z,2020-03-16T21:37:06Z,,,"Split pull request, #20293. 

This pr moves from the orignal pwm driver to the mfd timer. ",59771425
1155,2019-12-14T00:35:45Z,2020-01-30T10:38:27Z,,,"Documentation (from the updated `dts/binding-template.yaml`):

```
If 'generate-child-initializer: true' appears in the binding for a node, then
static initializers will be generated for the child nodes of the node, along
with a static initializer for an array with the child nodes.

As an example, take the following devicetree. Assume that the binding for
'foos' contains 'generate-child-initializer: true', and that it gives the
foo_0 and foo_1 nodes a binding via 'child-binding:' (see below).

    / {
            foos@0 {
                    compatible = ""foos"";
                    foo_0 {
                            int = <0>;
                            string = ""foo"";
                    };
                    foo_1 {
                            int = <1>;
                            array = <2 3>;
                    };
            };
    };

These additional static initializers will then be generated, along with
aliases. The order of the properties in the initializer matches the order in
the devicetree.

    /* Initializer for foo_0 */
    #define DT_FOOS_0_FOO_0_INIT   {DT_FOOS_0_FOO_0_INT, DT_FOOS_0_FOO_0_STRING}
    /* Initializer for foo_1 */
    #define DT_FOOS_0_FOO_1_INIT   {DT_FOOS_0_FOO_1_INT, DT_FOOS_0_FOO_1_ARRAY}
    /* Initializer for the children of foos@0 */
    #define DT_FOOS_0_INIT         {DT_FOOS_0_FOO_0_INIT, DT_FOOS_0_FOO_1_INIT}

The referenced macros initialize each property (note that these are always
generated):

    #define DT_FOOS_0_FOO_0_INT    0
    #define DT_FOOS_0_FOO_0_STRING ""foo""
    #define DT_FOOS_0_FOO_1_INT    1
    #define DT_FOOS_0_FOO_1_ARRAY  {2, 3}
```

Main commit:

```
dts: gen_defines.py: Support generating static initializers for nodes

Add a new 'generate-child-initializer' flag to bindings. When 'true',
static initializers will be generated for all child nodes of the node,
along with an initializer for an array that includes all the child
nodes.

This can be used to statically initialize structures and arrays derived
from devicetree data, e.g. for a list of LEDs.

See the updated documentation in doc/binding-template.yaml for more
information.

Fixes: #21239
```

Misc. refactoring:

```
dts: gen_defines.py: Add should_write() helper for properties

should_write() returns False for properties that are skipped in
write_properties().

Helps shorten write_properties() a bit. Want to keep it manageable when
adding some new stuff.
```

```
dts: gen_defines.py: Add helper for outputting {} initializers

The

    ""{"" + "", "".join(...) + ""}""

pattern is in a bunch of places now. Add an out_dev_init() helper for
it, with the same parameters as out_dev().
```",59771425
1156,2019-12-13T15:28:19Z,2020-02-07T13:44:21Z,,,,59771425
1157,2019-12-13T11:35:56Z,2019-12-16T10:18:50Z,,,"Power down PHY in eth_mcux driver and set carrier off.

Signed-off-by: Andrei Gansari <andrei.gansari@nxp.com>

Depends on zephyrproject-rtos/hal_nxp#24",59771425
1158,2019-12-13T05:05:30Z,2020-02-24T02:25:08Z,,,"Add an optional work queue that runs on the main thread after the
application's main() function returns, to allow for the reuse of stack
memory allocated for initialization.

Resolves #21322.

Signed-off-by: Josh Gao <josh@jmgao.dev>",59771425
1159,2019-12-11T23:47:23Z,2020-01-30T10:38:26Z,,,"For `type: string` properties, generate an additional macro

    #define DT_..._ENUM_<value> 1

This allows the value to be tested in the preprocessor.

For example, `maximum-speed = ""high-speed""` will generate

    #define DT_...MAXIMUM_SPEED_ENUM_HIGH_SPEED 1",59771425
1160,2019-12-11T22:51:56Z,2020-01-30T10:38:26Z,,,"For each `type: string` property, generate an additional `*_UNQUOTED`
macro that with an unquoted value. This can be useful with token pasting
and the like.

Motivated by https://github.com/zephyrproject-rtos/zephyr/issues/21273,
where there's this:

    variant:
        type: string
        required: true
        enum:
            - ""epd1p54""
            - ""epd1p54b""
            - ""epd1p54c""
            - ""epd4p2""
            # ...

Depending on the selection, an identifier like `epd1p56b_init` should be
generated.

The macros below now get generated, where the `*_UNQUOTED` version could
be token-pasted to generate `epd1p56b_init`.

    #define DT_..._VARIANT ""epd1p54b""
    #define DT_..._VARIANT_UNQUOTED epd1p54b

Something like `*_ID` could've been used instead of `*_UNQUOTED` too, but
`*_UNQUOTED` is nice in that it's greppable and makes the magic stick out
more.

Supporting commit:

```
Rename str2ident() to to_upper_ident() and add a new to_ident() function
that just replaces non-alphanumeric characters with underscores, without
uppercasing the string.

to_ident() will be used in the next commit.

Also simplify the underscore replacement a bit with a regex, and explain
why '+' is replaced with 'PLUS'.
```",59771425
1161,2019-12-11T20:15:40Z,2020-02-05T20:24:13Z,,,"Add timeout to I2C read/write functions in interrupt
mode.

Get timeout value from DT.

i2c_ll_stm32_v2: Add transaction timeout to polling 
mode.

Fixes #21293

Signed-off-by: Yannis Damigos <giannis.damigos@gmail.com>",59771425
1162,2019-12-11T08:24:23Z,2020-02-07T10:53:39Z,,,"Added support for hardware flow control in EFM32 UART driver.

Tested with samples/hello_world on efm32pg_stk3402a and further low level tests with uart_poll_in() and uart_poll_out() as in tests/drivers/uart/uart_basic_api/.

Signed-off-by: Timo Dammes <timo.dammes@lemonbeat.com>",59771425
1163,2019-12-10T18:09:02Z,2020-03-12T11:04:27Z,,,,59771425
1164,2019-12-10T06:31:02Z,2019-12-31T05:08:38Z,,,"Add board support for frdm_k32l2b3

Add board specific pinmux, doc and dts.
Tested with hello_world, synchronization, philosophers, basic/blinky and basic/button. 

Depends on zephyrproject-rtos/hal_nxp#22",59771425
1165,2019-12-09T13:16:55Z,2020-03-21T12:06:33Z,,,"This fixes the driver to be fully configured from DTS, and puts
the GIRQ and valid pin configuration to DTS also. This makes the
driver more suitable for other SoCs in the same family.

Also read and write functions are fixed to not use peripheral
base address from HAL, but from DTS.

This is in preparation for supporting CEC1702.

@scottwcpg @franciscomunoz @galak ",59771425
1166,2019-12-06T13:01:49Z,2020-01-28T07:30:56Z,,,"I've been working on support for STM32F105xx series parts. Please consider this a WIP... I'll be updating it as I go, but I'd like feedback on what I consider some fairly critical / core changes that I've made.

My todo list:

- [x] Clock Tree
- [x] USB Device
- [x] CAN1 Support
- [ ] ~~CAN2 Support (probably not a small task - shared mailboxes, etc...)~~ - I'll look into this later
- [ ] ~~ADC Support (I expect the clock configuration to need work)~~ - I'll look into this later

I'm not sure about some of my changes, and would appreciate input from others... mainly:

- a3df0d4 - this feels very wrong to me. I couldn't get the `SystemCoreClock` variable to get a sensible value via the Zephyr code, however using `SystemCoreClockUpdate()` sets it correctly.
- 0d504b2 - I'm not 100% about some of my changes in `clock_stm32_ll_common.c` and their suitability for other parts... Please review it carefully and test this on other parts.

Unfortunately the board I'm targeting isn't open, so I can't expect others to have the same platform as myself... It should be largely irrelevant though.",59771425
1167,2019-12-05T20:02:16Z,2019-12-05T21:31:41Z,,,"The SMP model for timer drivers has a somewhat odd requirement that
the z_clock_announce() call be made on every CPU so that it can manage
timeslicing, even though only one CPU will see a positive tick count
and invoke the timeout callbacks.  In practice this is hard to make
work in a portable way for devices like HPET which are a single
device.

Instead, let the announce call be made on any CPU and invoke the
existing sched_ipi to prod the other CPUs.  Overhead is minimal (the
slice_ticks count needs to become a 64 bit expiration time, and the
IPI handler needs an extra test), and the timer drivers don't need to
worry about odd interrupt delivery settings.

Signed-off-by: Andy Ross <andrew.j.ross@intel.com>",59771425
1168,2019-12-05T03:08:49Z,2020-03-10T09:06:14Z,,,"add basic support for  GPIO and UART with no
interrupt, in axs board, IPs in mother board use
a second-level interrupt which currently not supported.
currently, we can use the debug uart and gpio buttons,
leds and seven-segment deisplays.
",59771425
1169,2019-12-04T09:04:23Z,2020-01-29T21:00:59Z,,,"at24c04, at24c08 and at24c16 have a special data address representation,
the high-order bits are inserted into the device address.

Signed-off-by: fengch <i@fengch.me>",59771425
1170,2019-12-03T03:06:14Z,2020-03-13T15:02:13Z,,,"This commit makes behavior enabled previously via SYS_PM_STATE_LOCK Kconfig option the default and removes the option. Upon boot all power states are disabled and need to be explicitely enabled by the application or the power management subsystem by calling sys_pm_ctrl_enable_state function.

More information is provided in the updated documentation of `sys_pm_ctrl_enable_state()`, `sys_pm_ctrl_disable_state()` functions.

All in-tree references to SYS_PM_STATE_LOCK were removed.

Fixes #11908, #20775 and partially #20792.",59771425
1171,2019-11-29T07:20:50Z,2020-03-26T11:06:53Z,,,"```
Many chips have only one serial port. When the serial port is occupied
by other devices, there is a lack of a console to output debugging
information. Semihosting can provide a console. The disadvantage of
semihosting is that a debugger must be connected, so it can only be
used for online debugging.

Signed-off-by: ZhongYao Luo <LuoZhongYao@gmail.com>
```",59771425
1172,2019-11-26T17:44:19Z,2019-12-18T19:45:10Z,,,"Add video ELCDIF driver
DISPLAY to VIDEO shim layer for backward compatibility (lvgl)
Add capture_and_display_sample

depend: https://github.com/zephyrproject-rtos/hal_nxp/pull/21",59771425
1173,2019-11-26T08:36:30Z,2020-02-21T16:14:12Z,,,"Ttesting kerenl/timer/timer_API with LPTIM on stm32L4R5 with nucleo_l4r5zi board,
the test_timer_duration_period fails w""
test_timer_duration_period: tdata.expire_cnt == 4 is false""

- changed z_timer_cycle_get_32() function to have better value returned in nb of HW cycles
- changed the calculation for next timeout in case of short delay
- source LPTIM with  LSE clock for better accuracy
- reduce tick freq to 1000 per sec

Fix https://github.com/zephyrproject-rtos/zephyr/issues/20991

Signed-off-by: Francois Ramu <francois.ramu@st.com>",59771425
1174,2019-11-25T17:10:00Z,2020-03-08T11:57:48Z,,,"Hello,

This PR adds support for Actions Semi ATB1103 MCU and its evaluation board. ATB1103 is part of the  Low power Bluetooth MCUs family (ATB110X) from Actions Semi. The target applications for this MCU are BLE Voice Remote, Smart wearable devices, Smart Home sensors, and BT Mesh device applications. The EVB (Golden board) is designed and manufactured by Actions Semi for their internal use but there are few commercial target boards available for this MCU as well.

This PR is based on the initial code support for the MCU and board developed by Actions Semi and hence the copyrights are shared based on the contributions.

Thanks,
Mani",59771425
1175,2019-11-25T17:02:03Z,2019-12-05T16:01:26Z,,,This makes it possible to perform `mcumgr` operation like DFU over ethernet instead of bluetooth or serial. The `mcumgr` tool already has support for UDP transport.,59771425
1176,2019-11-25T11:03:54Z,2020-01-10T14:29:49Z,,,"Some Kconfig defined devices may be defined using dt_chosen_label
function. Since there is no way to ensure a device enabled in dts
is also defined in Kconfig, it may happen that instance is not
actually defined.
In this case device_get_binding might return 0, leading to undefined
behavior in the function that calls it.
When not already done, systematically check return of function
device_get_binding on devices defined through dt_chosen_label macro.
Trigger ASSERT when required and return error when possible.

Fixes #20068

Signed-off-by: Erwan Gouriou <erwan.gouriou@linaro.org>",59771425
1177,2019-11-24T14:54:43Z,2020-02-12T14:27:16Z,,,"- Cleanup headers in kernel files.
- debug: move k_DEBUG to use LOG_DBG",59771425
1178,2019-11-21T08:45:42Z,2020-02-12T14:27:15Z,,,"This is an alternative approach to solving the problem addressed also by #19703 and described in https://github.com/zephyrproject-rtos/zephyr/pull/19703#issuecomment-539929845.

---

Instead of hard-coded values for interrupt priorities in DT nodes, use
a macro that additionally can be overridden at the board or application
level. This allows, for instance, changing the interrupt priorities for
all but one peripheral without using a lengthy overlay file.

Signed-off-by: Andrzej Głąbek <andrzej.glabek@nordicsemi.no>",59771425
1179,2019-11-20T20:00:03Z,2020-02-12T14:27:15Z,,,"This commit moves the semaphore for a blocking call from
the driver implementation to the stack of the caller.
It reduces the complexity of the drivers and saves some RAM.

Fixes #22379",59771425
1180,2019-11-19T16:39:23Z,2019-12-05T14:15:38Z,,,"Aim of the test is to enforce compliance to default board configuration guidelines on in tree boards (out of tree boards are filtered out).
Test is build_only and error is generated if any driver is enabled aside from basic gpio, pinmux, clock_control, serial or any subsystem other than console.

Tested Kconfig symbols are drivers and subsystems.
Each new flag will need to be added manually and I can't find a clever way to automate that, unless we add a new level of info to identify Kconfig flags role (peripheral, subsytem, ...) and level (zephyr top level, soc level, peripheral driver level, vendor peripheral driver level, ..). So this test will have to be maintained and updated manually, similarly as we do on `tests/drivers/build_all`

Fixes #19116

Signed-off-by: Erwan Gouriou <erwan.gouriou@linaro.org>",59771425
1181,2019-11-16T19:28:06Z,2019-12-19T04:21:38Z,,,"    Preliminar port for FRDM-KL46Z: board files, pinmux, uart, gpio,
    and device tree files (starting from what present for frdm-kl25z).
    Hello world and i2c_scanner successfully tested on hardware.

Signed-off-by: Michele Jr De Candia <mdecandia@gmail.com>",59771425
1182,2019-11-14T20:02:12Z,2019-11-15T23:14:39Z,,,"Some kernel objects only need to go in dedicated sections
if CONFIG_OBJECT_TRACING is enabled. Unfortunately this
defeats gc-sections, and we are doing this unconditionally.

Fixes: #20663

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>",59771425
1183,2019-11-12T08:33:35Z,2020-01-29T17:34:34Z,,,"Standard flash write changed to word aligned write,
Use relative addresses instead of absolute,
Simplified writing in time slice setup,
Added Kconfig option `CONFIG_SOC_FLASH_NRF_OVERRIDE_WBS` that overrides the standard word size and sets it back to 1 byte alignment

Fixes: #20423,
Fixes: #20425 
Fixes: #20472 
Alternative to: #19720, #20471

Signed-off-by: Laczen JMS <laczenjms@gmail.com> 

",59771425
1184,2019-11-11T22:41:42Z,2020-03-19T13:12:39Z,,,"A script/library I've been working on with input from aescolar (who also
wrote most of the MAINTAINERS.yml file).

Please try it out and give feedback. There's a detailed --help text, and
the top of MAINTAINERS.yml explains the file format.

MAINTAINERS.yml needs to be fleshed out. To be done in future PRs after this one (skeleton) is merged

This probably won't be the final location of the script, but making a PR
against the Zephyr repo makes it easier to try out and update.

Some examples:

* Identify the subsystem(s) for a path:

      $ ./get_maintainer.py path arch/arc/Kconfig
      ARC arch
              status: maintained
              maintainers: ruuddw
              collaborators: vonhust
              inform:
              labels: area: ARC
              description:

      Kconfig
              status: maintained
              maintainers: ulfalizer
              collaborators:
              inform:
              labels: area: Kconfig

* Identify the subsystem(s) for a commit range:

      $ ./get_maintainer.py commits HEAD~5..
      Flash
              status: maintained
              maintainers: nvlsianpu
              collaborators:
              inform:
              labels: area: Flash
              description:

      Kconfig
              status: maintained
              maintainers: ulfalizer
              collaborators:
              inform:
              labels: area: Kconfig

* List all files in a subsystem:

      $ ./get_maintainer.py list ""ARC arch""
      arch/arc/CMakeLists.txt
      arch/arc/Kconfig
      arch/arc/core/CMakeLists.txt
      arch/arc/core/arc_connect.c
      arch/arc/core/arc_smp.c
      arch/arc/core/cache.c
      ...

* List all orphaned files (files not in any subsystem):

      $ ./get_maintained.py orphaned
      .checkpatch.conf
      .clang-format
      .codecov.yml
      .editorconfig
      .gitattributes
      .github/ISSUE_TEMPLATE/bug_report.md
      .github/ISSUE_TEMPLATE/enhancement.md
      ...

Older versions of the script had flags instead of sub-commands, like
get_maintainer.pl, but it gets a bit messy with subcommand-specific
flags.",59771425
1185,2019-11-11T19:27:22Z,2020-01-28T02:56:45Z,,,"This shield adds digital sensors to a TI LaunchPad development kit. It
is useful for exercising the I2C interface.

This commit depends on #16392 and the relevant commit is `boards: shields: add TI BOOSTXL-SENSORS`.",59771425
1186,2019-11-09T15:43:50Z,2020-03-25T05:54:22Z,,,"Hello,

This is the second attempt on adding UNISOC UWP5661 SoC and 96Boards IVY5661 board support to zephyr. The first attempt was made by UNISOC (#10626) but the PR was closed and discontinued. Now, UNISOC has no intention to do the upstream by themselves but they are open for community contributions. Hence with their approval, I'm posting this PR and taken over the codebase from their previous PR. I've added my copyright for files I modified/created.

**About SoC:**

Unisoc UWP5661 is a highly integrated connectivity single chip which offers the lowest BOM in the industry for smart phone, PC, STB, OTT, IoT and automotive applications. This chip includes 2.4GHz and 5GHz WLAN IEEE 802.11 a/b/g/n/ac, Bluetooth 5.0 with supporting high power mode, Direction Finding and Long Range.

**About Board:**

96Boards IVY5661 is one of the IoT boards of the 96Boards family manufactured by UCRobotics. This board features UWP5661 SoC in 96Boards IoT form factor. More information about this board can be found in 96Boards website: https://www.96boards.org/product/ivy5661

The corresponding PR to add HAL is here: https://github.com/zephyrproject-rtos/hal_unisoc/pull/1",59771425
1187,2019-11-09T02:52:57Z,2020-02-08T12:18:49Z,,,"Add DMA test support for 'loop_transfer', 'chan_blen_transfer' on
NUCLEO_F091RC/F103RB/F207ZG/F302RF8/F401RE/F746ZG/L073RZ/L476RG.

Signed-off-by: Song Qiang <songqiang1304521@gmail.com>",59771425
1188,2019-11-08T14:42:01Z,2020-02-12T07:01:14Z,,,"1. Allow CPU_HAS_FPU_DOUBLE_PRECISION on Cortex-R4 and Cortex-R5, as
   the optional VFPv3-D16 is, by default, a double precision unit.

2. Add GCC compiler support for Cortex-R4F and Cortex-R5F floating
   point unit. The FPU type on these cores is fixed to VFPv3-D16,
   which supports double precision by default. While later revisions
   of Cortex-R5F can have single precision VFPv3-D16, GCC does not
   have a separate type for it.

Signed-off-by: Stephanos Ioannidis <root@stephanos.io>

NOTE: Separated out from #19698 for timely review and merging.",59771425
1189,2019-11-08T06:15:36Z,2019-12-10T10:06:12Z,,,"Clarify k_sleep parameter range (non-negative or K_FOREVER).
Clarify k_usleep parameter range (non-negative).
Added assert to k_(u)sleep to fail on negative numbers (except
K_FOREVER in k_sleep).

Signed-off-by: Krzysztof Chruscinski <krzysztof.chruscinski@nordicsemi.no>
",59771425
1190,2019-11-06T22:37:31Z,2020-01-06T09:33:23Z,,,"Some idea's on how to represent the pinmux info in DTS on Kinetis to allow us to auto-generate the info from DTS.

Need to see how we'd convey a pin is used for GPIO and how we'd possibly pass through GPIO config to pinmux (if at all).",59771425
1191,2019-11-06T15:08:13Z,2020-03-19T08:07:18Z,,,"Introduce Linux like dts bindings for stm32 devices.
Reason for this change is described with more detail in dedicated commit.

Ultimate goal is to generate -pinctrl.dtsi files from STM23CubeMx GPIO IP database (which is available for download to all users). Scripts could then be used for generation and correctness verification.

While the number of GPIO IPs to describe is limited (54 GPIO IPs for 988 MCUs according to latest database in CubeMx 5.4), I'd like we could re-use the current inclusion/inheritance model currently in use in `dts/arm/st/*`. This means that each stm32f/l/g(/...)xxx.dtsi would include a matching stm32f/l/gxxx-pinctrl.dtsi describing the pin configuration of the peripheral described in stm32f/l/gxxx.dtsi. Aim is to minimize pinctrl file sizes (and information redundancy, potential errors, ..)
Alternative option would be to provide stm32f/l/gxxx-pinctrl.dtsi de-correlated from stm32f/l/gxxx.dtsi but describing various GPIO IPs and using its own inclusion/inheritance schema. This should further reduce the number of duplicates, but would require additional verification effort (which might be feasible with appropriate tooling)


EDIT: Aim of this draft PR is to get early feedbacks on the direction
",59771425
1192,2019-11-05T11:39:59Z,2019-11-13T22:08:21Z,,,"Add a table that documents that aliases we utilize in zephyr for samples
& tests.

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
1193,2019-11-05T04:16:29Z,2020-03-24T17:44:54Z,,,"Hello,

This PR adds SoC and board support for NXP i.MX8M Mini SoC. NXP has a wide variety of i.MX8 series SoCs with different configurations. So I'm not exactly sure how to model the SoC hierarchy here. But what I have done is to create a separate `mimx8mm_m4` SoC directory for i.MX8M Mini SoCs.

And the board support is added for the i.MX8M Mini LPDDR EVK board. The model name for this board is `8MMINILPD4-EVK` but since we can't use that name directly, I have added it as `mimx8mm_evk`.

The corresponding PR for adding SDK support to NXP module is here: https://github.com/zephyrproject-rtos/hal_nxp/pull/16

Signed-off-by: Manivannan Sadhasivam <mani@kernel.org>

Fixes #17814",59771425
1194,2019-11-04T19:40:17Z,2019-11-11T19:31:47Z,,,"Add a new document describing the list, tree and ring buffer data
structures under lib/os.  We had doxygen references for this stuff,
but never had an overview document.

Signed-off-by: Andy Ross <andrew.j.ross@intel.com>",59771425
1195,2019-11-04T14:49:56Z,2019-11-05T08:40:48Z,,,"Added selection of MPU_ALLOW_FLASH_WRITE.
Using nRF flash driver while MPU is enable without
this option on doesn't make sense at all.

Signed-off-by: Andrzej Puzdrowski <andrzej.puzdrowski@nordicsemi.no>",59771425
1196,2019-11-03T13:48:53Z,2020-03-20T19:31:08Z,,,"So, I was a bit upset due to extensibility of the timer driver for the stm32 within Zephyr.
I opened up an enhancement issue #20262. And started digging around how Linux does this.

So I got inspired by by the MFD driver for stm32-timers, see [stm32-timers](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/Documentation/devicetree/bindings/mfd/stm32-timers.txt?h=v5.4-rc5).

I'm using the stm32f4 series as a motorcontroller (with hall sensors and field oriented control). And the timer can do a pretty good job here. But I want to use the timer as a base for other modules, like hall sensors and 3 phase generation. So I got it to work, and changed it only for the F4 series (all is based on the original drive, but I moved from the bulky HAL driver to to LL driver).

Also I moved from the DTS fixups to the instance based implementation. But it still needs more cleanup.

So I would like to hear from you, if it's useful I will cleanup things further so it can be merged.

**TODO's**
- Fix DTS files for complete stm32 series
- Cleanup dts_fixups
- Test on more platforms ",59771425
1197,2019-11-02T12:31:42Z,2020-01-30T10:40:02Z,,,"This is a step towards #19904.  The motivation is removing redundant bindings from `dts/` that aren't associated with their own driver implementation, and eliminating the annoying checkpatch warnings when an unspecified compatible is added in a commit.

Knowledge of the variants may also assist in addressing #20287.",59771425
1198,2019-11-01T06:53:45Z,2019-12-11T13:36:09Z,,,"Three samples: simple, lvgl and wgl.",59771425
1199,2019-10-31T05:10:53Z,2020-01-09T16:48:18Z,,,"This is prototype based on conversations at ELC-E 2019 on how we can make the device api be dt aware.  

The idea here is that we'd use a unique identifier (Zephyr Device ID/ZDID) for each device tree node that would correspond to how we name the `struct device` for that device.  We can then generate various DT defines like `DT_INST_0_SILABS_GECKO_I2C_ZDID`.  These defines allow us to construct direct access to the `struct device`.  This PR show changes to the silabs i2c gecko driver and a hacked up change to the i2c_scanner to show but the changes on the driver side (how a `DEVICE_AND_API_INIT_DT` would look like, and how `device_get_dt_binding` would work.

There's at least one issue that needs to be figured out on how / where to do an `extern struct device __device_<ZDID>`.",59771425
1200,2019-10-29T10:13:11Z,2019-12-18T18:31:29Z,,,"Use the C LibYAML parser and dumper when available, like in
https://github.com/zephyrproject-rtos/zephyr/pull/20206.

Haven't profiled it, so not sure if worthwhile yet. Not sure what flags
I should pass to exercise it the best.",59771425
1201,2019-10-29T06:09:21Z,2019-12-19T19:43:29Z,,,"For SMP case, if a thread is already dead/terminated, because
e.g. thread exits, and other cores want to terminate this thread,
z_sched_abort just returns and no need to do further work, e.g.
raise an ipi interrupt as the target thread is already dead.

It's an optimization, especially for SMP case.

What's more, have we ever considered the cases of multi k_thread_abort/k_thread_create on the same
thread?

Signed-off-by: Wayne Ren <wei.ren@synopsys.com>",59771425
1202,2019-10-28T15:17:25Z,2020-02-10T21:22:51Z,,,"UBlox Sara U2/R4 Localisation info commands

Uses the UBlox cellular location sensor (CellLocate®)
+ULOCCELL

May have issues with the R4 as UBlox were problems with original firmware
",59771425
1203,2019-10-28T11:44:40Z,2019-11-06T12:21:07Z,,,"Add SWD interface API and bit-bang driver.
Add CMSIS-DAP compatible controller and USB HID interface.

Short description: it works, you can use it if you have appropriate hardware. I will update the description after ELCE.",59771425
1204,2019-10-28T10:16:36Z,2019-12-20T16:40:14Z,,,"Several functions in i2s requires driver to be in a given state. Have included API to get driver state

Signed-off-by: Kristoffer Rist Skøien <kristoffer.skoien@nordicsemi.no>",59771425
1205,2019-10-25T15:35:33Z,2019-12-18T17:39:18Z,,,"Work In Progress (Is functional)
Initial ESP32 AT WiFi Modem using WIFI_OFFLOAD

Including particle Argon config
Particle Argon does require ESP32 firmware rest instructions are available using Circuit Python [https://learn.adafruit.com/adding-a-wifi-co-processor-to-circuitpython-esp8266-esp32/program-particle-argon]

Has not been tested with IPv6, may need work to include
",59771425
1206,2019-10-25T13:52:16Z,2020-02-12T14:27:14Z,,,"This patch enables the low power Mode for the stm32wb soc. 
It uses the LPTIM timer as tickless timer. 
This PR requires Implementation on L4 series (#18582) and Extend to other LP series (WB: #19881 
The SLEEP (0,1,2) modes are supported on this device.
Only the HSE clock is restored after sleep Mode.
This PR requires an update of the hal_stm32  https://github.com/zephyrproject-rtos/hal_stm32/pull/24

Signed-off-by: Francois Ramu francois.ramu@st.com",59771425
1207,2019-10-25T06:03:21Z,2019-10-25T10:54:59Z,,,"Fixed repeated call initialization should return `-EALREADY`

Signed-off-by: Lingao Meng <mengabc1086@gmail.com>",59771425
1208,2019-10-25T02:19:46Z,2020-01-30T11:13:42Z,,,"Kconfig.defconfig files are for adding board-specific defaults to
symbols. Board-specific options go in boards/<board>/Kconfig, which is
source'd from boards/Kconfig and shows up in the Board Options menu.

Found with a script. NRF_TIMER_TIMER was only defined in a
Kconfig.defconfig file.",59771425
1209,2019-10-23T15:21:45Z,2019-12-12T17:55:01Z,,,"Adds QSPI API

Signed-off-by: Kamil Lazowski <Kamil.Lazowski@nordicsemi.no>

**Clarification on PR content:**
Author intention is to introduce API for the `Serial Memory Protocol Engine` with serial back-end using 4 line SPI. The peripheral of `Serial Memory Protocol Engine` gives huge acceleration in I/O operation.
Wort to emphasize that such a peripheral not necessarily allow to RAW access to SPI bus at all.

Such peripherals are incorporated into some of nRF, NXP, STM and Microchip SoC.",59771425
1210,2019-10-23T14:47:18Z,2019-11-06T14:11:42Z,,,Extend the doc for repo structure and modules.,59771425
1211,2019-10-22T21:01:06Z,2020-02-12T14:27:14Z,,,"In #19679, the can bus state can be monitored. So this PR is based on #19679 .
This is an update for the socketcan driver, to send error frames to userspace.
And enabling support for filtering on error frames.
",59771425
1212,2019-10-21T14:14:11Z,2020-02-18T14:08:48Z,,,"This PR enables CI checks to pass for TF-M, and introduces build support to automatically pull in the external TF-M repository and all dependencies, and perform a build of TF-M as part of a standard Zephyr sample app build procedure. It is based on TF-M 1.0-rc2.",59771425
1213,2019-10-21T10:57:59Z,2019-12-16T13:47:15Z,,,"Extended logger core to handle multiple domains in terms of getting names, filtering level of sources. Setting runtime filter level, etc. Added test for new features.

Introduce new concept to the logger: `link`. Link creates a pair with backend on the side. Application can have multiple links and each link can handle multiple domains (e.g. ipc link to another core which has trustzone and thus has 2 domains). Remote domains are controlled through link API. Link is using heap to allocate memory for domain names in the link and optionally runtime filtering settings for log sources in that link. Runtime filtering will allow control of remote log sources logs in the same way as the local one.

This PR does not add any link, potential link implementations may include following:
- link to second core (implemented over open amp)
- link to secure domain (trustzone)",59771425
1214,2019-10-21T00:25:35Z,2020-01-03T05:09:09Z,,,"Board definition for PineTime DevKit0 by Pine64 vendor. It is based on information published in https://wiki.pine64.org/index.php/PineTime

Signed-off-by: Rafa Couto <caligari@treboada.net>",59771425
1215,2019-10-19T17:06:02Z,2019-12-09T10:26:28Z,,,"Hard-coded value of 1000 microseconds is too low for some I2C slave devices,
operating in the master hold mode (otherwise known as clock stretching).
One of such devices, Si7006 RH/T sensor requires up to 11 ms when
sampling temperature and humidity.

Idea is to control such timeout via Kconfig.

The timing diagram shows a real use-case:

![17_ms_reading_time](https://user-images.githubusercontent.com/5261821/67148750-9edb1c80-f2ab-11e9-83d6-56815da5645f.png)

That's consistent with the datasheet of Si7007:

![conversion_time_si7006](https://user-images.githubusercontent.com/5261821/67148768-d2b64200-f2ab-11e9-9c36-975c34818cd4.png)



",59771425
1216,2019-10-18T18:28:26Z,2020-03-20T20:14:17Z,,,"The driver was incorrectly converting the temperature samples. According
to Si7006-A20 rev. 1.2 datasheet, section 5.1.2. Measuring Temperature,
the offset -46.85 must be applied.

![forgotten_offset](https://user-images.githubusercontent.com/5261821/67118710-25312900-f1ee-11e9-8970-1791032b5ccc.png)

Additionally, the same section says that:

""Each time a relative humidity measurement is made a temperature
measurement is also made for the purposes of temperature compensation of
the relative humidity measurement. If the temperature value is required,
it can be read using command 0xE0; this avoids having to perform a
second temperature measurement.""

![combined_rh_t_measurements](https://user-images.githubusercontent.com/5261821/67118749-34b07200-f1ee-11e9-86e5-9562f6892a1d.png)

Respective improvement is implemented.

Fixes #22907",59771425
1217,2019-10-18T07:47:09Z,2019-10-23T03:51:36Z,,,"PR #16645 streamlined stdint.h type definitions. This has an unfortunate side effect that any legacy code which assumed default, compiler provided types will now generate warnings any time type mismatch is detected during the compilation process. Redefining stdint types also significantly increases porting effort when building an existing bare metal application with Zephyr.

This PR makes redefinition of stdint types optional.

I wasn't sure if the Kconfig option should go into ""C library"" or ""Compiler Options"" sub menu. For now it's in the ""C library"".",59771425
1218,2019-10-15T23:50:49Z,2020-01-30T10:45:13Z,,,"Main commits:

```
scripts: edtlib: Automatically include base.yaml in all bindings

This removes some boilerplate from bindings and makes things more
consistent. One downside is that all properties declared in base.yaml
can now appear on all nodes, including on nodes where they don't make
sense, but it's probably worth it.

base.yaml is moved to scripts/dts/base.yaml, and is considered part of
edtlib internals.

The automatic base.yaml inclusion is documented in
dts/binding-template.yaml and in the legacy syntax section of
doc/guides/dts/index.rst.

'include: base.yaml' is still accepted, but is ignored, and makes edtlib
print a deprecation warning. The warning mentions the new location of
base.yaml.

Remove a 'clocks' declaration from dts/bindings/clock/fixed-clock.yaml,
which declares it as 'type: array'. It clashes with the declaration for
'clocks' in base.yaml, which has it as 'type: phandle-array'. No 'clocks
= <(number) (number) ...>' assignments exist anywhere, which is the form
of assignment expected for 'type: array'.

Piggyback some binding consistency nits and a small bugfix that allows
empty files to be included (the crux is that PyYAML returns None instead
of an empty dict for them).

The empty file fix is needed because of dts/bindings/mmc/mmc.yaml, which
turns empty besides some comments if the 'include: base.yaml' is
removed. Maybe it should be removed instead.
```

```
dts: bindings: Remove base.yaml includes

base.yaml is now included automatically, so it doesn't need to be
included explicitly.
```

Piggybacked nit:

```
scripts: edtlib: Fix some *-map-mask/*-map-pass-thru typos in comments

The ""map"" part got lost.
```",59771425
1219,2019-10-10T14:52:43Z,2020-03-03T12:25:52Z,,,"To support thread-safe, one-time initialization of function scope
variables that have non-trivial constructors, the compiler will
generate calls to the following functions, __cxa_guard_acquire,
__cxa_guard_release, and __cxa_guard_abort.

Those functions make sure that the initialization is only done
one time, by using a global zephyr mutex.

Signed-off-by: Erwin Rol <erwin@erwinrol.com>",59771425
1220,2019-10-09T13:29:20Z,2019-12-16T13:47:29Z,,,"Add api to extend hexdump log message. Extending may include allocating additional chunks. It enables appending data to log message on the fly which will be used in multi-domain context.

Extended log_output module to allow conversion from standard or hexdump log message to extended log message. Extended log message contains formatted string message (source name and formatted string with arguments). Extended log message gets all metadata from original log message (e.g. source id, timestamp, level).

Extended message is self contained in a sense that it can be transferred between domains and formatted on another side (domain name is needed). Extended messages will be used in multi-domain logger.",59771425
1221,2019-10-09T07:13:25Z,2020-02-12T14:26:21Z,,,"This PR implements a timeout for outgoing CAN frames.

~~At the moment only the stm32 driver implements the new functionality. Other drivers will follow by the end of the week.~~

It fixes issue #19502",59771425
1222,2019-10-07T13:45:31Z,2020-02-07T08:54:52Z,,,"This PR adds an ADC driver for the Silicon Labs Gecko series.

For now, this driver is enabled only for the EFM32PG12B as this is the only board I have that is available in Zephyr, but it also works on my EFM32GG11B and probably works for most of the Gecko series ADCs.

This PR also requires a change in module `hal_silabs`: in `hal_silabs/gecko/CMakeLists.txt` the following line needs to be added:

`zephyr_sources_ifdef(CONFIG_SOC_GECKO_ADC          emlib/src/em_adc.c)`",59771425
1223,2019-10-04T02:06:20Z,2019-10-25T20:25:24Z,,,"Not really for merging yet.

This is based on the initial work from @andyross found in PR #17628.

I'm using this PR as a placeholder for the current state of my work so
others could look at it and ... maybe get inspired.

Comments also welcome.",59771425
1224,2019-10-03T23:28:50Z,2019-10-04T18:08:10Z,,,"More evacuees from #17155 that can stand on their own.  These aren't related to the timeout work per se, except insofar as the bugs are sensitivities to timing.  See commit notes for details.

Note that two of the patches were written above the new conversion API, so they require #19591 to be merged before they will build in CI. ",59771425
1225,2019-10-03T20:56:22Z,2019-11-12T15:57:25Z,,,"This PR addes a new attribute wrapper, __no_sanitize_address, to tell address sanitizer (ASAN) that it should not instrument some code; this attribute warper can be applied to functions and global variables.

Further this PR adds __no_sanitize_address to variables placed in a section to prevent instrumentation of the variables by the clang address sanitizer. If the variables would be instrumented with red zones and the code assumes that the variables are back-to-back this would break the code.

For more info see: google/sanitizers#1028",59771425
1226,2019-09-30T12:58:08Z,2020-03-26T17:21:00Z,,,"Remove prompts from Kconfig options `SPI_x_NRF_SPI*` that select the
type of nrfx driver (for SPI, SPIM, or SPIS peripheral) to be used
for a given instance. This prevents the options from being modified
in configuration files.
Instead, make one of these options selected by default according to the
""compatible"" property set for the corresponding SPI node in devicetree.

This eliminates the need of changing both the ""compatible"" property in
devicetree and the Kconfig option selecting the driver type when a user
wants to switch between SPI, SPIM, and SPIS for a given instance.

Since all `SPI_x_NRF_SPI*` options are made ""hidden"" by this commit,
all their occurrences in configuration files are removed.

Same changes are done to Kconfig options `I2C_x_NRF_TWI*` and `UART_x_NRF_UART*`.",59771425
1227,2019-09-27T13:24:26Z,2020-02-21T09:38:33Z,,,"
[I2S Machine State.pdf](https://github.com/zephyrproject-rtos/zephyr/files/3662906/I2S.Machine.State.pdf)

",59771425
1228,2019-09-20T20:27:12Z,2019-09-27T22:24:28Z,,,"See https://github.com/zephyrproject-rtos/hal_nordic/pull/6

Signed-off-by: Marc Herbert <marc.herbert@intel.com>",59771425
1229,2019-09-16T21:01:56Z,2019-09-23T21:28:26Z,,,"Another documentation PR bringing the timeout subsystem up to date with current code and adding a few pages detailing the various data structures we provide in lib/os.

As before, this reflects my preschool-level understanding of RST and is going to need significant technical cleanup before merge.  And there are a few diagrams (that I also need to get help on) that need to be added in a few spots too.",59771425
1230,2019-09-16T12:00:12Z,2019-09-16T19:17:18Z,,,"Add I2C/SPI/PWM to supported hardware features.

Signed-off-by: Loic Poulain <loic.poulain@linaro.org>",59771425
1231,2019-09-15T19:31:07Z,2019-09-16T14:39:33Z,,,"Simple example with OpenThread and LWM2M IPSO Push button on Nordic nRF52840-PCA10056 board.

Build:
west build -s samples/net/lwm2m_client -d build-lwm2m_client -b nrf52840_pca10056 -- -DCONF_FILE=overlay-ot.conf

Sign:
west sign -t imgtool -d build-lwm2m_client -- --key root-rsa-2048.pem --header-size 512 --version 1.2.3

Flash:
west flash -d build-lwm2m_client --hex-file build-lwm2m_client/zephyr/zephyr.signed.hex
",59771425
1232,2019-09-09T15:14:59Z,2020-03-26T08:14:02Z,,,"This patch enables the low power Mode for the stm32l4r5 soc. The SLEEP (0,1,2) and DEEP_SLEEP (0,2) are supported on this device.

Signed-off-by: Francois Ramu francois.ramu@st.com",59771425
1233,2019-09-09T03:12:25Z,2020-01-30T11:01:13Z,,,Please reference the hal_nxp PR https://github.com/zephyrproject-rtos/hal_nxp/pull/9,59771425
1234,2019-09-05T03:16:33Z,2019-12-18T17:36:25Z,,,"* Espressif ESP8266 is cheap, easy to get and wildely used UART-based wifi module with AT cmds.
* It's meaningful to add its support in Zephyr as it's more popular than exsit WiFi modules in Zephyr
* This PR is update and bug fix of PR #10539
   *  based on latest zephyr code
   *  bug fixes and optimizations
   *  add server sockets support
* This is a initial work, hope more people can join in and make it better.

",59771425
1235,2019-09-04T18:29:39Z,2019-09-05T18:24:53Z,,,"In `log_strdup` a 2-character terminator `~\0` is added to the `buf` in `log_strdup_buf`, but the size of buf is 1 (`CONFIG_LOG_STRDUP_MAX_STRING+1`, where `CONFIG_LOG_STRDUP_MAX_STRING==0`).  This increases the termination padding to 2 so that  `sizeof(dup->buf) - 2` ([as calculated in `log_strdup()`](https://github.com/zephyrproject-rtos/zephyr/blob/ee57741c8c4060724eae3f4963a05cfed5b79d8f/subsys/logging/log_core.c#L872)) is never negative.

Signed-off-by: Terri Oda <terri.oda@intel.com>",59771425
1236,2019-09-02T12:46:21Z,2019-12-02T13:01:44Z,,,"This PR adds suport for the Cortex R5 CPU in the Xilinx Zynq MP SoC on Enclustra's Mercury XU* Modules.

It also adds possibility to disable ECC checking in the Cortex R Tightly Coupled Memory (TCM)",59771425
1237,2019-08-29T11:05:58Z,2020-01-30T10:58:37Z,,,"Adds Zephyr platform driver for VL51L1X TOF sensor,
based on ST's driver API (see UM2356)",59771425
1238,2019-08-28T14:25:43Z,2020-02-12T14:26:21Z,,,"For some reason we start measurement of latency a little bit late, after quite some instructions are already executed.

Move read_timer_start_of_isr() to the real entry of generic interrupt handler. And with that we do see some difference on `benchmarks/timing_info`.
```
Before: Interrupt latency    :  20 cycles ,    40 ns
After:  Interrupt latency    :  62 cycles ,   124 ns
```",59771425
1239,2019-08-26T16:52:15Z,2019-08-26T17:14:24Z,,,"This commit adds a proof of concept tool that runs qemu-based
sanitycheck output in a modified context where CPU load is firmly
constrained, so as to avoid qemu timing warps from host CPU load.

It's intended as a significant performance boost for ""try these tests
on an unloaded system"" workloads, which still exploits as much
parallelism as possible, keeps run logs in a saner way than ""ninja
run"", and produces easily interpreted log output on stdout.  You can
put this script in a loop overnight and come back to tens of thousands
of individiual test run results.

Signed-off-by: Andy Ross <andrew.j.ross@intel.com>",59771425
1240,2019-08-23T19:55:20Z,2020-01-31T12:41:18Z,,,"Currently, calling `shell_uninit` leaves the shell_backend running while it should be disabled.",59771425
1241,2019-08-21T10:25:11Z,2020-01-30T10:58:03Z,,,"This binding is meant to specify gpios in the device-tree that are not leds
or buttons.

Signed-off-by: Tobias Svehagen <tobias.svehagen@gmail.com>",59771425
1242,2019-08-20T10:12:02Z,2020-02-12T14:26:21Z,,,"To save code space when making constrained applications, since
mempool automatically adds code even when not used.

In my test (pca10090, hello_world) it saves 288 bytes.",59771425
1243,2019-08-16T17:26:35Z,2019-08-19T23:02:00Z,,,,59771425
1244,2019-08-16T17:10:37Z,2020-02-12T14:26:20Z,,,"MISRA-C rule 17.7 says that the return value of a non-void must be
checked. For memcpy/memset there is no error handling or checking we
can do with the return value, so it is just casting it to void to
explicitly ignore while adhering to MISRA-C.

This patch was generated using the coccinelle script
ignore_return.cocci

Signed-off-by: Flavio Ceolin <flavio.ceolin@intel.com>",59771425
1245,2019-08-09T14:05:28Z,2019-09-29T07:29:43Z,,,"Instead of the whole `--elf-file`/`--hex-file`/`--bin-file` thing, just have ONE TRUE FILE ARGUMENT

e.g:
```
west flash -f build/zephyr/zephyr.signed.hex
```",59771425
1246,2019-08-08T14:01:25Z,2019-11-28T09:19:48Z,,,Signed-off-by: Connor King <SIGSTACKFAULT@gmail.com>,59771425
1247,2019-08-08T12:11:29Z,2019-11-27T16:57:50Z,,,"struct k_thread *current is only defined for !SMP platforms
leading to the following build-time failure:

| openocd.c:39:35: error: 'struct z_kernel' has no member named 'current'
|  [OPENOCD_OFFSET_K_CURR_THREAD] = offsetof(struct z_kernel, current),
                                   ^~~~~~~~

Disable calculation of meaningless offset then.

Fixes https://github.com/zephyrproject-rtos/zephyr/issues/18124.",59771425
1248,2019-08-02T12:45:42Z,2020-02-29T08:43:40Z,,,"This PR is to add SPARC architecture to Zephyr RTOS.  This PR is only for QEMU target.

It's my first PR to add new architecture to Zephyr.  Please let me know if there is any procedure I should follow to.

This PR needs #16950 to be merged before.

Hoping to be merged for version 2.0.

",59771425
1249,2019-08-02T12:02:31Z,2020-01-30T10:54:59Z,,,,59771425
1250,2019-07-31T14:31:41Z,2019-11-21T16:37:23Z,,,"depends on #16119
Prepare HTS221 driver based on zio interface.
This sensor component does not have an internal hardware FIFO. Nevertheless
I defined a s/w fifo of length==1. I will try later on with other sensors with h/w fifo.

In order to test it on the x_nucleo_shield3 is rebased on master and not topic-sensors.
I can later switch it if needed",59771425
1251,2019-07-31T06:04:19Z,2020-01-30T10:54:28Z,,,"Fixed two problems with spi flash w25qxxdv
1. Device-related configuration exists in both Kconfig and dts.
    For example, the switch definition of spi cs is defined in
    the Kconfig pin parameter in dts.
2. The driver is for the w25qxx family. The parameters of w25q16 in
    dts are fixed instead of using w25qxx.
Now, device-independent configuration is in Kconfig,
    other configurations use dts configuration, and device names in
    dts are updated to w25qxx

Signed-off-by: Findlay Feng <i@fengch.me>",59771425
1252,2019-07-30T11:53:00Z,2020-01-30T10:54:03Z,,,"These appear in .dts files but are unused as of writing. Add them just
so that we can require that all device tree properties are declared in
bindings.

See commit b023fbf938 (""dts/bindings: Remove pinctrl from bindings"") as
well.",59771425
1253,2019-07-30T10:00:15Z,2019-08-01T18:34:29Z,,,"Unused in Zephyr. There's some documentation for device_type at
https://elinux.org/Device_Tree_Linux, which says that it's deprecated.

Trying to get rid of properties that appear on device tree nodes but
aren't declared in bindings.

Removal was done with

    git ls-files '*.dts' '*.dtsi' | xargs sed -i '/device_type/d'",59771425
1254,2019-07-25T12:58:44Z,2019-08-01T22:42:38Z,,,"Add a kernel timer driver for the MEC1501 32KHz RTOS timer.
This timer is a count down 32-bit counter clocked at a fixed
32768 Hz. It features one-shot, auto-reload, and halt count down
while the Cortex-M is halted by JTAG/SWD. This driver is based
on the new Intel local APIC driver. The driver was tuned for
accuracy at small sleep values. Added a work-around for RTOS
timer restart issue. RTOS timer driver requires board ticks per
second to be 32768 if tickless operation is configured. Because a
32KHz timer cannot provide the 1us resolution for the kernel's
busy wait API we use a 32-bit high speed peripheral timer for
this purpose in the SoC layer.

Signed-off-by: Scott Worley <scott.worley@microchip.com>",59771425
1255,2019-07-20T16:38:40Z,2019-09-03T18:19:36Z,,,"GCC contains warning flags that can partially help spot MISRA-C violations. This pr is enforcing checks for rules:

8.2, 8.3, 8.4, 16.1 and 16.3",59771425
1256,2019-07-18T11:33:42Z,2019-08-12T08:31:29Z,,,"The driver starts up the display, sets low brightness
and runs a simple animation.
Tested with PCA10040, but should be compatible with
any zephyr-supported board with SPI.

Signed-off-by: Łukasz Hejnak <lukasz.hejnak@nordicsemi.no>",59771425
1257,2019-07-18T00:35:20Z,2019-08-26T20:24:51Z,,,"Unlike the previous and reverted attempt that redefined
CMAKE_<LANG>_CREATE_STATIC_LIBRARY (2371679528f8, PR #17549), this one doesn't break incremental
builds.

Warning from: https://gitlab.kitware.com/cmake/cmake/issues/19474

    The rule variables are actually pseudo-public as described here:
    projects can set them but are responsible for keeping up with
    changes to CMake.  The main variable(s) documentation could use
    updates for this.

Quoting GNU man page:

 'D'

    Operate in deterministic mode.  When adding files and the archive
    index use zero for UIDs, GIDs, timestamps, and use consistent file
    modes for all files.  When this option is used, if ar is used with
    identical options and identical input files, multiple runs will
    create identical output files regardless of the input files' owners,
    groups, file modes, or modification times.

    If 'binutils' was configured with '--enable-deterministic-archives',
    then this mode is on by default. It can be disabled with the 'U'
    modifier, below.

Signed-off-by: Marc Herbert <marc.herbert@intel.com>",59771425
1258,2019-07-17T22:28:10Z,2020-03-23T10:30:03Z,,,"This PR provides support for the [Maxim DS3231 TCXO RTC](https://www.maximintegrated.com/en/products/analog/real-time-clocks/DS3231.html), a high-precision real-time clock peripheral with support for battery backup.

This is implemented as a counter, but the DS3231 has significant functionality enhancements beyond a general RTC API.    Also, as an I2C peripheral it has limitations that are incompatible with assumptions about how a counter can function.  Most users of its advanced functionality will interact with it through device specific API provided in a driver-specific header following the approach summarized in #17072.  Consequently the interface file is placed in the (existing) `include/drivers/rtc` directory, and the extension functions are named based on it being a specialization of a (no longer existing) `rtc` driver class.

There is a question of where to collect the documentation.  Because it's device specific, it really should be its own page at API Reference : Peripherals : RTC : DS3231.  For now I've just put it under (newly created) RTC.

As more infrastructure is added to support management of civil time tracking in Zephyr some of the functionality in this driver may need to be generalized. For example, the `rtc_ds3231_syncpoint` structure should probably be generalized and placed in the recently created `<sys/timeutil.h>` header long with functions that support generic conversion from a synchronization point and local time to RTC and back.
",59771425
1259,2019-07-17T21:01:39Z,2019-12-03T15:30:30Z,,,"This is the new heap implementation and test rig I've been talking about.  See commit logs and comments for design notes.

Specifically note that the heap code itself is dirt simple (mostly, once you get your head around the field accessor API), and that more than half the added code here is in the validation and test rigs. @andrewboie will be happy to see that coverage on the new files is effectively 100% (there's some cleanup to do with some of the validation lines, mostly ""return false;"", which obviously don't fail and don't get hit).

It passes everywhere right now except for riscv32 and nios2 (no idea yet, haven't had a chance to look).

This is just the new code.  I still need to finish up wrapper APIs for sys/k_mem_pool before this can go in.  I was hoping to have that done today, but it might stretch another day.  And even then we'll likely leave both implementations in place and make them switchable via kconfig for a version. 

On top of those, I should also turn the existing stress rig into a proper benchmark and add that so we can track performance with a real usage simulator.",59771425
1260,2019-07-16T23:42:13Z,2019-07-16T23:47:49Z,,,"As reported in https://gitlab.kitware.com/cmake/cmake/issues/19474, this
commit... almost works. It seems flawless as far as 'ar' is concerned,
but then ranlib runs without ""-D"" and timestamps the table of symbols
right after 'ar', this ""spoils"" the entire .a file.

diffoscope lib_before_ranlib.a lib_after_ranlib.a
--- lib_before_ranlib.a
+++ lib_after_ranlib.a
├── file list
│ @@ -1,2 +1,2 @@
│ - ----------   0   0   0     14 1970-01-01 00:00:00.000000 /
│ + ----------   0   0   0     14 2019-07-16 02:05:07.000000 /
│   ?rw-r--r--   0   0   0   8868 1970-01-01 00:00:00.000000 main.c.obj

Running ranlib is most likely pointless when using GNU bintutils and
simple cases like this, however CMake is unlikely to ever make a
particular case and optimize this away, the added complexity wouldn't
save much time.

See discussion in PR #17549 (commit 2371679528f8) for more background
and details.

Signed-off-by: Marc Herbert <marc.herbert@intel.com>",59771425
1261,2019-07-16T10:18:17Z,2020-01-13T10:50:14Z,,,"Add example for reel board that turns it into digital thermometer
with option to read its value through BLE.

Add python code for linux host with TICK stack to log all data
into TSDB.

Example is optimized for low power operation.",59771425
1262,2019-07-15T09:19:11Z,2019-12-19T18:46:45Z,,,"PR contains changes in 3 areas:
- extending `util.h` with macro `NUM_VA_ARGS_LESS_2`
- extending ztest with test spawning. The idea is that there is a list of instances on which same test has to be performed (e.g. device instances). So far, a solution was to do single test function which was iterating over the list of objects. This approach has some drawbacks: failure terminates full tests, some instances may not support all features thus test should be skipped for those instances. There is no option to communicate that if all instances are tested in single test function. Proposed solution is using preprocessor  to create set of functions based on provided list of objects.
- refactoring counter test to use new ztest feature

Example:
```
 #define DEVICE_LIST DT_TIMER_0_LABEL, DT_TIMER_1_LABEL, DT_TIMER_2_LABEL,
 const char *devlist[] = { DEVICE_LIST }
 
void foo(u32_t idx) {
 	const char *name = devlist[idx];
 	test_foo_on_instance(name);
 }
 
ztest_unit_tests_from_list_create(foo, DEVICE_LIST)

void test_main(void)
{
	ztest_test_suite(test_foo ,
		ztest_unit_tests_from_list(foo, DEVICE_LIST)
	);
	ztest_run_test_suite(test_foo);
}
```
Preprocessor will resolve to:
```
 #define DEVICE_LIST DT_TIMER_0_LABEL, DT_TIMER_1_LABEL, DT_TIMER_2_LABEL,
 const char *devlist[] = { DEVICE_LIST };
 
void foo(u32_t idx) {
 	const char *name = devlist[idx];
 	test_foo_on_instance(name);
}

void test_foo_0(void) {
 	foo(0);
}
void test_foo_1(void) {
 	foo(1);
}
void test_foo_2(void) {
 	foo(2);
}

void test_main(void)
{
        ztest_test_suite(test_foo ,
            ztest_unit_tests_(test_foo_0),
            ztest_unit_tests_(test_foo_1),
            ztest_unit_tests_(test_foo_2)
        );
        ztest_run_test_suite(test_foo);
}
```
",59771425
1263,2019-07-12T01:57:38Z,2019-09-02T06:28:43Z,,,"Post process libraries if find_program(strip-nondeterminism) succeeds,
do nothing otherwise.

This has been successfully tested on Ubuntu 18.04 with a full
sanitycheck run including all the default samples/ and tests/

Two very important caveats:

1. This required a couple of fixes on top of ""apt-get install
   non-determinism"" version 0.040-1.1~build1. These fixes are available
   at https://salsa.debian.org/reproducible-builds/strip-nondeterminism/merge_requests/4

2. The entire ar.pm handler has been removed in more recent (1.0.0+)
   strip-nondeterminism releases! The commit message 366d60c9cc16 says:
   ""Drop .ar handler; binutils is reproducible"". The corresponding bugs
   and discussions seem to show a concern than ar.pm could hide bugs in
   binutils or llvm-ar. Supporting older or non-debian systems doesn't
   seem to be desired.

So the preferred alternative is to use a toolchain like the Zephyr SDK
that supports creating deterministic .a files and (if not the default)
pass the -D option to (GNU) ar thanks to
CMAKE_LANG_CREATE_STATIC_LIBRARY

Signed-off-by: Marc Herbert <marc.herbert@intel.com>",59771425
1264,2019-07-09T19:37:09Z,2019-07-10T17:41:05Z,,,"The original code is not portable to R4 due to its mode bits being
much different from M-class CPUs.  By using z_arch_is_user_context(),
this difference is abstracted to the CPU-specific implementation.

Signed-off-by: Phil Erwin <erwin@lexmark.com>",59771425
1265,2019-07-09T18:08:41Z,2020-03-12T16:15:07Z,,,"A DMA friendly Stream API for zephyr.
    
Provides a way to define a driver which provides an output FIFO of
blocks. Blocks are allocated from a specified block allocator. These blocks are
easily used for DMA transfers.
    
Some convenience functions for storing and retrieving primitive types
in the blocks is provided.
    
Blocks are meant to be placed into the output fifo based on a policy
describing time or number of entries since the block began being filled. If
the block is full it is meant to be immediately pushed into the FIFO.
    
The use case in mind is high rate sensors with hardware FIFOs and SPI
interfaces where DMA transfers from these sensors would save a great
deal of CPU time avoiding the high rate of interrupts and small SPI
transfers that would otherwise occur. Other uses are certainly possible,
I imagine audio and video have similar requirements.

For sensors an added interface to iterate over sample sets from a block is provided allowing for lazily converting sample set values into numerical values of varying types. To start only float is available but certainly the current sensor_value (int/int pair), cmsis-dsp friendly q value types, or other numerical formats could be provided.
",59771425
1266,2019-07-02T10:47:58Z,2019-07-02T13:58:06Z,,,"This macros is an incrementation and modulo operation into one. It
replaces the ""ticker_next_elapsed()"" function and is also used in other
places ticker_start()/ticker_stop/etc functions to replace similar code.

This implementation does not add any performance penalty while reducing
the number of lines of code and adds clarity.

Signed-off-by: Radu Alexe <radu.alexe@nxp.com>",59771425
1267,2019-06-28T12:59:20Z,2019-09-13T07:35:30Z,,,"Add the support for the x_nucleo_cca02m1 microphone shield with a sample to test it.
This sample is making use of both the 2 x MP34DT01 on-board microphones in stereo mode.
To achieve this result the sample is using AN5027 suggestion (paragraph 2.1.2) to use a timer 
to provide a clock which runs at double the frequency of I2S sampling time.

NOTES (IMPORTANT):: (see #15429)
To make the sample working I had to make customization to Nucleo F411 re files
(boards/arm/nucleo_f411re/), which I think it is NOT the correct way. I'm asking the support
of someone to explain how to move those info in the shield part.

In more details:
1. in nucleo_f411re/Kconfig.defconfig I defined the I2S part, especially the I2S PLL configuration.
    Also TIM and DMA.
    The right place should be in the shield definition I guess, or in sample.

2. In nucleo_f411re/nucleo_f411re.dts I defined arduino_i2s and timer3.
    time3 should be moved in shield or in sample.

3. In nucleo_f411re/pinmux.c I defined I2S and timer clock pinmuxing.
    Again this should be provided in shield or sample.


Can #14057 help us here?",59771425
1268,2019-06-21T15:52:28Z,2020-03-26T18:14:39Z,,,"This pull request proposes an implementation of the RPMSg protocol based on a resource table. 
The resource table can be use  to declare resources shared between the main and coprocessor. It is integrated in the  co-processor firmware in a specific section. This section can be recognized and parsed by the Linux OS kernel to initialize shared resources such as trace and RPMsg protocol.

Based on this resource table, the objective is to propose a sample that is platform agnostic and that answers to the Linux rpmsg client sample integrated in the Linux kernel distribution.

For time being  this pull request only implements the co-processor side, and could be extended in future to also implement the master part.",59771425
1269,2019-06-15T09:35:57Z,2019-06-15T09:41:13Z,,,"Wait for SCL to actually read high when setting the gpio pin value.

Also fix bug in i2c_read_bit where the sda line was read too early
when slave uses clock stretching.

Signed-off-by: Joerg Fischer <turboj@web.de>",59771425
1270,2019-06-13T13:13:28Z,2020-01-30T10:51:50Z,,,"Adds driver for the BH1749 color sensor.

https://www.rohm.com/datasheet/BH1749NUC/bh1749nuc-e",59771425
1271,2019-06-07T06:06:51Z,2020-03-14T08:03:29Z,,,"Since ""Initial support for microchip cec1702 #5383"" got closed and had lot of cruft. I decided to make new PR. This is essentially the same set of changes rebased on top of current master. One commit was merged earlier, and it's removed. The other commits were updated to reflect changes in current master.",59771425
1272,2019-06-07T05:52:55Z,2020-01-30T10:51:15Z,,,"This is just a cleaned up branch from #15271. I squashed the changes into a single commit. 

Signed-off-by: Michael Pollind <polli104@mail.chapman.edu>",59771425
1273,2019-06-06T10:55:02Z,2019-06-13T11:44:52Z,,,"This PR contains all the commits from #16514 with 2 additional commits that are draft of further extensions resulting in the new timing infrastructure in kernel.

Changes:
- Elimination of tick concept.
- Absolute timeouts.
- Direct usage of counter interface.",59771425
1274,2019-05-30T14:40:13Z,2019-06-04T16:37:50Z,,,"This PR presents counter-based system timer. The whole idea is described in https://github.com/zephyrproject-rtos/zephyr/issues/12068.

Practical information:
- This PR contains changes form: https://github.com/zephyrproject-rtos/zephyr/pull/14794, https://github.com/zephyrproject-rtos/zephyr/pull/16469, https://github.com/zephyrproject-rtos/zephyr/pull/16591 as well as https://github.com/zephyrproject-rtos/zephyr/pull/16445. The actual implementation of the #12068 idea is in the last 2 commits.
- The code shows the concept. I have tried to make it as solid as possible, but please note that there is no optimization as well as some corner cases could be not handled correctly.

How to test it on your board:
1. Check if you have at least one counter device avaiable. If so, enable it.
2. Make sure, that your counter driver is initialized at PRE_KERNEL_1 level.
3. Enable CONFIG_COUNTER_TIMER and disable the old timer driver.
4. Add ""zephyr,clock-source = <&ref-to-your-counter>"" to choosen node of your board.
5. Compile and run the choosen test/sample. If you see assertions on startup, this means that the counter device you selected does not have all required features. In such case you have to enable CONFIG_COUNTER_GENERIC and instantiate it in the DTS. Use last commit from this PR as a reference.",59771425
1275,2019-05-30T12:42:13Z,2020-02-04T09:14:01Z,,,"This PR unifies the implementation of the conversion mechanism from string to integer type.

It also adds two missing functions: `strtoll` and `strtoull`.",59771425
1276,2019-05-29T21:00:41Z,2019-05-30T09:04:14Z,,,"Add a simple serial driver that only supports writing output to
a single register

Signed-off-by: Olof Kindgren <olof.kindgren@gmail.com>",59771425
1277,2019-05-28T14:30:47Z,2019-06-06T17:59:22Z,,,This PR adds the definitions for `strcspn` and `iscntrl` to the minimal libc library (strings).,59771425
1278,2019-05-28T09:13:08Z,2019-06-03T18:33:52Z,,,"POSIX 1003.1 spec allows creating pthreads with attrib as NULL. In that
case, the stack needs to be auto-allocated.

Signed-off-by: Tomasz Gorochowik <tgorochowik@antmicro.com>",59771425
1279,2019-05-27T18:47:54Z,2019-05-28T09:58:08Z,,,"This allows 3rd-party projects to access mbedTLS headers, among
other things.

Signed-off-by: Paul Sokolovsky <paul.sokolovsky@linaro.org>",59771425
1280,2019-05-27T17:41:26Z,2019-08-21T03:25:23Z,,,"Add function z_clock_update() in the system clock driver.
This function is a void function that must be called if the CPU clock frequency is changed.
The function will calculates and updates the new tick units from the system core clock.
The CONFIG_TIMER_READS_ITS_FREQUENCY_AT_RUNTIME symbol must be defined.",59771425
1281,2019-05-23T12:33:21Z,2019-05-30T18:48:12Z,,,"**WIP, do not merge.**

Provided for discussion purposes only during the next API call.

## Design Goal

This PR is an attempt to provide an instrumentation framework to allow reasonably accurate measurement of execution time for arbitrary blocks of code. 

The initial back-end for this will be the [CoreSight `DWT`](http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0314h/Chdiicbc.html) peripheral block, which is standard on Cortex M3/M4/M7 and higher cores.

The goal, however, is to have a hardware-agnostic framework that can fall back to less reliable system timers or architecture/device-specific options where appropriate.

## Why is this needed?

There is currently a [Tracing API](https://docs.zephyrproject.org/latest/guides/tracing/index.html) in Zephyr, but this is targetted more at tools like Segger SystemView and while it is very useful for tracing tasks in the system, it isn't necessarily appropriate to instrument arbitrary chunks of code when trying to optimise mathematical functions, etc.

Making use of dedicated peripheral blocks like CoreSight and DWT provide a far more accurate view of real execution time, with less processing and tool overhead, and no proprietary tool dependencies.

Instrumenting a section of code with `DWT` is as simple as resetting the cycle counter, executing the code in question, then reading the cycle counter to know how many clock cycles it took (with a margin of error in the tens of clock cycles for processing overhead):

```
// Macro to initialise, reset and enable the cycle counter.
// This can be used for rough timing and performance tests
// by resetting the cycle counter before a function, and
// then reading the value after with ""int count = DWT->CYCCNT""
//
//    DWT_RESET_CYCLECOUNTER;
//    ... do something
//    int count = DWT->CYCCNT;

#define DWT_RESET_CYCLECOUNTER    do { CoreDebug->DEMCR = CoreDebug->DEMCR | 0x01000000;  \
                                       DWT->CYCCNT = 0;                                   \
                                       DWT->CTRL = DWT->CTRL | 1 ; } while(0)
```

## Open Questions

### Timing source for platform-agnostic backend

How should timing backends for instrumentation be handled on non M3/M4/M7/M23/M33 systems that don't have an equivalent to DWT? 

Presumably we can fall back to a high accuracy timer as a worst-case but universal option, even if this has a higher margin of error, but provides a global option plus `DWT` as an architecture-specific example.

### Integrate `stats` into the Instrumentation API?

Zephyr already has a [`stats`](https://github.com/zephyrproject-rtos/zephyr/tree/master/subsys/stats) module that provides high-quality instrumentation data for field-debugging, tracking the number of times user-defined events occur on the system (sensor reads, bus errors, etc.). While this is different than the aim of the instrumentation API, which is accurately measuring clock cycles for code optimisation efforts, `stats` does fall in the instrumentation domain.

Should stats and clock cycle counts be merged into a single `instrument` API?
",59771425
1282,2019-05-16T12:55:38Z,2019-06-24T07:40:41Z,,,"Add NXP usb device khci controller driver, it is one shim of the NXP SDK kinetis USB device controller driver. The default kinetis device controller driver use the usb_dc_kinetis.c, user can select to use this driver by setting CONFIG_USB_KINETIS=0 and setting CONFIG_USB_DC_NXP_KHCI=1",59771425
1283,2019-05-15T22:22:32Z,2020-02-03T12:25:34Z,,,"subsys/storage/CMakeLists.txt and subsys/storage/Kconfig just pass
everything through to subsys/storage/flash_map/. Simplify things by
removing subsus/storage/flash_map/ and putting the files directly in
subsys/storage/ instead.

Also remove the ""Storage"" Kconfig menu, which was in the old
""pass-through"" subsys/storage/Kconfig. It showed up even with FLASH_MAP
disabled.

This puts FLASH_MAP in the top-level menu and gets rid of one menu level
(without making the top-level menu longer, because FLASH_MAP is a
'menuconfig' symbol).",59771425
1284,2019-05-13T20:00:27Z,2019-07-26T20:32:29Z,,,"Put the scripts from the [ci-tools](https://github.com/zephyrproject-rtos/ci-tools) repository in `scripts/ci` in the main Zephyr
repository, where they used to be.

Here's why I think it's a good idea:

 1. A single PR can change both Zephyr code and CI code, e.g. to add a new test
    related to the PR, or modify the whitelist for a test

 2. It makes people more likely to notice CI changes

 3. It makes the CI scripts easier to discover

 4. It makes the CI scripts easier to run. No need to clone a separate
    repository.

 5. It means you automatically get the corresponding CI checks when you
    check out a particular Zephyr version, which are guaranteed to pass

Use a merge commit (with `--allow-unrelated-histories`) so that the `ci-tools`
history is preserved.",59771425
1285,2019-05-13T09:36:28Z,2019-06-04T12:41:02Z,,,"This adds driver for this ambient light sensor which uses i2c.

Signed-off-by: Vaishali Pathak <vaishali@electronut.in>",59771425
1286,2019-05-09T08:51:10Z,2019-06-28T15:37:23Z,,,"Adding a die temperature demo specific to NORDIC nRF5 serie SoC.

Signed-off-by: Aaron Tsui <aaron.tsui@outlook.com>

Already tested on nrf52840_pca10056, nrf52_pca10040 and nrf51_pca10028",59771425
1287,2019-05-09T06:50:50Z,2020-02-05T15:45:24Z,,,"disable STM32's usb irq and clock.

Trying to fix the issue #16023 
Signed-off-by: Jun Li <jun.r.li@intel.com>",59771425
1288,2019-05-03T17:33:16Z,2019-05-10T03:41:13Z,,,"Add one more bitfield to support buf configuration, thus
to support using circular buffer config.

And implement circular buffer support for STM32 SoCs.

The PR will be the one of dependencies for PR #14916 

Signed-off-by: Jun Li <jun.r.li@intel.com>",59771425
1289,2019-04-25T13:16:14Z,2019-09-29T16:54:19Z,,,"Adds ""-Wc++-compat"" compiler option to W1 warning level.
This option warn about ISO C constructs that are outside of the common subset of ISO C and ISO C++.

One of the biggest issue is the size of the empty structure.
An empty struct (or union) has size 0 in C, but size 1 in C++.

For example, in some case struct k_spinlock can be empty. k_spinlock is used in Message Queue Structure (struct k_msgq), and the struct k_msgq doesn't have the same size. That generates an alignment mismatch beetween C and C++.",59771425
1290,2019-04-23T14:16:25Z,2020-03-19T06:59:07Z,,,"**tests: drivers: counter: Add nrf9160_pca10090 board**

Add board with nrf9160 to counter tests.

**tests: drivers: counter: Add clock stabilization in test setup for nRF**
    
Xtal LF clock source starts hundreds of milliseconds. When it is
not start, test may fail due to wrong timing. Added pending
on LF clock being start in test setup.
    
",59771425
1291,2019-04-21T14:20:05Z,2020-03-04T09:43:23Z,,,"This series moves the clocking for SAMD2x to be entirely controlled by the device tree.  This is similar to the ongoing work being done for #15363 but here the process is more invasive (it requires an clock provider definition) and the result is that the clock is controlled by the device tree too.

The primary motivation for the change was that the SAM0 peripherals tend to have relatively limited built in clock prescalers, but the SAM0 chip itself has a flexible clock generation system.  So it makes sense to make the chip clocking available in a more generic way.  For example, the SERCOM in I2C mode only has an 8-bit clock divider, so if using normal speed mode, this effectively limits the CPU frequency if it's clocked from the undivided core clock (e.g. SAMD5x).  Similarly, the ADC has only a few powers of two divisors available, so achieving near its rated conversion rate means using an alternate clock than the CPU clock.  In a case where at the least description is needed is the RTC (system timer) where SAMD2x can clock it at the full speed, SAMD5x is limited to a 32kHz clock.

## Device Tree Update

The first change made is to describe the existing clock structure with the device tree.  The clock definitions use the [Linux bindings](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/plain/Documentation/devicetree/bindings/clock/clock-bindings.txt) for clock control.  Basically these define a `clocks` parent node with various nodes for each individual clock provider/oscillator.  See [here](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/arm/boot/dts/lpc32xx.dtsi#n34) for an example.  

For SAM0, there isn't a direct central clock controller like in the above example, instead each individual GCLK is defined separately and the peripherals reference the originating GCLK directly.  This approach was chosen because each GCLK can have its own separate frequency, so specifying them all would get quite verbose.

So a sample of the SAM0 DTS ends up looking like:
```DTS
clocks {
	dfll: dfll {
		compatible = ""fixed-clock"";
		clock-frequency = <48000000>;
		clocks = <&gclk1>;
		#clock-cells = <0>;
		label = ""DFLL"";
	};

	gclk0: gclk0 {
		compatible = ""fixed-clock"";
		clock-frequency = <48000000>;
		clocks = <&dfll>;
		#clock-cells = <0>;
		label = ""GCLK_0"";
	};
};
soc {
	sercom0: sercom@42000800 {
		compatible = ""atmel,sam0-sercom"";
		reg = <0x42000800 0x40>;
		status = ""disabled"";
		label = ""SERCOM0"";
		clocks = <&gclk0>;
	};
};
```

The above describes two clocks, the DFLL that provides a 48MHz ""source"" clock, with its own (not shown) reference clock input and GCLK0, which is what peripherals can actually reference directly.  The SERCOM peripheral then uses GCLK0 as the clock input to the device.

This series incrementally converts SAM0 to use this kind of device tree.  Initially the clock setup is only described with the device tree.  Then peripherals are converted to use information from it, instead of simply assuming a constant setup.  Finally, the SoC setup code is changed to actually allow for re-configuration of the clock tree based on the device tree.

## Implementation

The first part of the implementation is simply describing the clock tree as it is used in the various boards.  Since there are Kconfig options that change this somewhat, the initial setup assumes the board defaults.  Thankfully, these Kconfig options have no peripheral visible effects, so there are no inconsistent behaviors.

Then a `clock_control` driver is implemented that can be used to query and manipulate peripheral GCLK connections.  This can be used to replace the current hard coded GCLK enables that all peripherals use.  It also has a frequency query that will be used to replace the current static defines that the peripherals use.

Next, peripherals are converted to use the clock control driver.  Since the current clock setup simply describes the existing GCLK tree (i.e. nearly everything hangs off GCLK0), this has no current behavior change.

Finally, the SoC setup is re-written to use the DTS generated information to actually generate the clock tree.  The resulting clock tree should be identical to the currently used one, since the DTS is set to describe it already.  So the final result of the series is no functional changes, but much greater flexibility.

## Dynamic Control

After this series, it becomes possible to control the clocks from DTS overlays to allow for more flexibility.  As a toy example, the below changes the main SoC clock to use a 48MHz clock generated by the FDPLL from the calibrated 32kHz RC oscillator:
```DTS
&osc32k {
	status = ""ok"";
};

&gclk1 {
	clocks = <&osc32k>;
	clock-frequency = <32768>;
};

&fdpll {
	status = ""ok"";
	clock-frequency = <48000000>;
	clocks = <&gclk1>;
};

&gclk0 {
	clocks = <&fdpll>;
};
```

This example first turns on the calibrated oscillator, then changes GCLK1 to use it as the input, and finally enables the FDPLL (the multiplier is calculated automatically) and tells GCLK0 to use it.

## Future Work

During work on this series, one thing I noticed was that the manual specifies the maximum input clock for the DFLL in closed loop mode as 33 kHz (section 37.6, table 37-7, page 985).  However the current default clock setup for any SAMDx board without a 32kHz crystal is to use the undivided 8MHz RC oscillator as the reference.  This does appear to ""work"", but I'm not sure it's actually using the reference (i.e. it's probably operating in (un-calibrated) open loop mode with the ""reference stopped"" logic kicking in).  This appears to have been carried over/cargo culted from various online forums, where, as far as I can tell, the initial recommendation of adding a divisor to GCLK1 before using it as the reference got lost at one point.  So in the future the clock setup should either be changed to use a divided OSC8M, to simply use the internal 32kHz RC oscillator, or to simply operate in open loop mode explicitly (like it's probably doing already).

Another candidate for some clock related work is enabling USB clock recovery for the DFLL.  This is Microchip's recommendation if using the chip for USB with no crystal present, but the current setups do not do that on the boards without crystals.  That is, they simply operate in closed loop mode from the internal oscillator, which may not even work (above).  So in the future, an option could be implemented to allow for operating in this mode.

These issues are not part of this series, since the goal of it was no functional changes.

## Alternative Implementations

One possible alternative implementation uses `clock_control` drivers for all possible clocks on the SoC and relies on the init priority to handle sequencing.  This has the advantage of abstracting the clocks entirely, but ends up being rather hard to follow.  Additionally, most of the clocks (i.e. anything other than a GCLK) is basically unused after SoC startup, since the peripherals do not interact with them directly.  I have an example of this kind of implementation at Sizurka/zephyr#3.

Another possibility is to enhance the DTS parsing to extract information about the parent clocks directly.  This can allow the needed information to configure the clocks at compile time, but could be limited in some cases (e.g. if a device needed to know about the source of its source clock it becomes awkward quickly).  For strictly SAM0 devices, I tend to favor this approach, but it's also more implementation specific, so the above is my attempt at a best of both worlds approach (e.g. clock setup is mostly compile time calculated but peripherals use the device abstraction).  My original implementation of this is at Sizurka/zephyr#4.

One notable disadvantage of the device based approaches is that the clock frequency is unavailable at compile time.  So any checks/asserts on it have to be runtime where they may be missed.  Additionally this complicates counter drivers, which require their frequency to be available at compile time.  So for those, it will be necessary to assume that the requested frequency is correct, then calculate the actual frequency at run time and warn if the two don't match.",59771425
1292,2019-04-16T15:34:05Z,2019-04-29T14:10:50Z,,,"Only nRF51 does not implement the systick timer.
User can use systick to drive the timer in nRF52/nRF91 series if
they need higher resolution timer.",59771425
1293,2019-04-16T02:56:46Z,2020-02-12T14:26:19Z,,,"When preemption is enabled, we define K_LOWEST_THREAD_PRIO as
CONFIG_NUM_PREEMPT_PRIORITIES, which is limited from 0 to 128 by
kernel/Kconfig.  Unfortunately, using the number of priorities as the
thread priority is wrong.  The range of the priority for preemptible
threads must be 0 to 127.

K_LOWEST_THREAD_PRIO == 128 is currently used to create the idle
thread in init_idle_thread() when CONFIG_NUM_PREEMPT_PRIORITIES is
128.  The number 128 is passed down to z_setup_new_thread() ->
z_new_thread() -> z_new_thread_init() -> z_init_thread_base(), and
finally assigned to thread_base->prio which is type of s8_t.

Assigning 128 of type int to s8_t results in -127, which in turn means
now that the idle thread is the highest priority thread of all.  We
didn't notice this because we had special check for the idle thread in
should_preempt(), which is removed by the commit bd049626c5b04.

This patch only changes the definition of K_LOWEST_THREAD_PRIO but it
might be better to have some range check before the assignment to
thread_base->prio in z_init_thread_base() and z_thread_priority_set().

Signed-off-by: Yasushi SHOJI <y-shoji@ispace-inc.com>",59771425
1294,2019-04-11T15:07:49Z,2020-03-12T15:49:11Z,,,"This driver enable to use the external flash on the i.MX RT
MCU. For now the driver only support the default flash device on
the mimxrt1050_evk dev-board. The board offers an alternative
flash memory that can be use by changing soldered jumpers. This
driver does not support it for now but is planed to do so.

Note that this driver use CONFIG_CODE_DATA_REOLCATION.

This driver operate a combination of the exernal flash controller
in the MCU and the controller in the flash device. It was imposed
to do so because the MCU's flash controller, despite being a SPI
maste, is operating in a particualr way that can not fit with
existins Zephyr's driver models (SPI, UART, etc..).

Signed-off-by: Antoine <antoine@riedonetworks.com>",59771425
1295,2019-03-30T14:25:00Z,2019-11-13T12:27:33Z,,,"This driver supports TCP/UDP client on ehs6 module, which supports IPV4
internet connection with AT commands. This driver has been tested on a
frdm_k64f board.

Signed-off-by: Song Qiang <songqiang1304521@gmail.com>",59771425
1296,2019-03-29T12:57:01Z,2020-01-30T10:48:55Z,,,"This change enables configuration of generic gpio for inputs and outputs similar to gpio-leds and gpio-keys.

Signed-off-by: Bo Kragelund <bokr@prevas.dk>",59771425
1297,2019-03-29T10:14:08Z,2019-06-17T23:50:37Z,,,"   The Unisoc UWP5661 is a highly integrated 2-in-1 connectivity
    single chip which offers the lowest RBOM in the industry for
    smart home, IoT, industrial control and automotive applications.
    
    This patch is to upload Unisoc UWP Wi-Fi driver.
    It's Wi-Fi stack offload and based on Ethernet L2.


Signed-off-by: Bub Wei <bub.wei@unisoc.com>",59771425
1298,2019-03-26T15:33:58Z,2020-02-12T14:26:19Z,,,"By using DMA transfer, implement UART Async API for STM32F4 boards. So far, it is still under development and some issues still exist:
- [x] Test TX
- [x] Implement missing APIs.
- [ ] validate with `/tests/drivers/uart/uart_async_api`
- [ ] Remove self test application
- [ ] Rebase and clean up

So, the current one is just for review and to get suggestions. 

The test vehicle is a NUCLEO F429ZI board. 

The PR is trying to resolve the issue: #13955, and base on PR #14809 and PR #14854 
Also, parts of the implementation referred to [the implementation](https://github.com/StefJar/zephyr_stm32_uart3_dma_driver) from @StefJar. 
",59771425
1299,2019-03-25T14:35:46Z,2019-10-21T13:07:10Z,,,"This adds support for the three Idle modes and the Deep Sleep mode on the Atmel SAM0 SoCs.

I originally included this in #13494 but it makes more sense to keep this a separate pull request.
",59771425
1300,2019-03-20T16:30:58Z,2019-07-29T08:53:28Z,,,"We can build the openamp library configured with VirtIO master
support, VirtIO slave support, or both.  By default both master
and slave code is enabled.  We can reduce code footprint by only
build master or slave as needed.

Expose Kconfig options for Master & Slave and set them accordingly in
the sample.

Here's the code reduction we see:

For the total image we see as 1260 byte reduction:
Memory region         Used Size  Region Size  %age Used
 FLASH [Master & Slave]:       30308 B       256 KB     11.56%
 FLASH [Master only]   :       29048 B       256 KB     11.08%

On the remote side we see a 828 byte reduction:

Memory region         Used Size  Region Size  %age Used
 FLASH [Master & Slave]:       11564 B        64 KB     17.65%
 FLASH [Slave only]    :       10736 B        64 KB     16.38%

Signed-off-by: Kumar Gala <kumar.gala@linaro.org>",59771425
1301,2019-03-20T12:45:06Z,2020-01-28T15:23:26Z,,,"Adds RPMsg-Lite 2.2.0 library support and a sample application into Zephyr on NXP LPC54114 SoC/board. It can work also on i.MX 6SoloX and i.MX7 SoCs' M4 cores, but it will require a separate sample application as the other core is running usually Linux there. Perhaps we can base the sample on @diegosueiro's Remote Echo sample application [here](https://github.com/diegosueiro/zephyr/commit/70dda5ec5d1768dc21ec4f348bd6e26eb8821a5d).

Based on #5960 which was rejected in past due to RPMsg-Lite having the Clear-BSD license. As per @MarekNovakNXP's discussion with @nashif and @carlescufi at Embedded World conference, it has been agreed to put this into Zephyr now that the license is back to BSD-3-Clause.

To be merged only after 1.14 is released.",59771425
1302,2019-03-15T23:40:20Z,2019-12-21T13:49:43Z,,,"This PR includes a sample operating on [4D Systems uCAM-III](https://www.4dsystems.com.au/product/uCAM_III/) camera module. Currently, I haven't found anaything similar in Zephyr, so I've decided to write the drivers in the scope of a sample.

There can be a discussion on how we can support camera modules. One though is to probably, integrate camera modules into the sensor API. Or maybe define a new API?

My tasks for this PR include:

- [x] Take JPEG snapshots
- [ ] Take RAW snapshots
- [ ] Maybe shoot video, although it's not of main interest for me, for now

..and whatever comes out of discussion.",59771425
1303,2019-03-15T06:28:51Z,2019-06-13T23:08:15Z,,,"This script tests whether any unexpected changes occur
between symbol addresses in zephyr_prebuilt.elf and
zephyr.elf.

TODO:

- Document more what parts of memory do change
  between builds, a diagram or two would help

- Lots of stuff in shift-whitelist. Consider defining
  new linker symbols indicating regions where
  contained symbols may move, and define the whitelist
  in terms of that instead.

- Run this script for all builds where CONFIG_ASSERT
  is enabled.

Signed-off-by: Andrew Boie <andrew.p.boie@intel.com>",59771425
1304,2019-02-22T20:27:50Z,2019-04-19T09:08:32Z,,,The only way provided by the current ADC API to toggle between differential and single-ended acquisition is to call adc_channel_setup at the ADC controller level while at least some of the ADC controllers are rather conceived to enable differential acquisition on a channel to channel basis. This pull request provides an option to enable or not differential conversion per channel in the adc_sequence structure without going through adc_channel_setup. It’s not enabled by default so it shouldn’t break anything that doesn’t explicitly enable the API. It has been enabled and tested through the mcux driver.,59771425
1305,2019-02-21T22:23:59Z,2019-09-19T17:18:10Z,,,"This is a very preliminary test for C++ exceptions and therefore C++ standard library.

It works fine on a nucleo_l432kc board using either the Zephyr 0.10.0 SDK or the Debian toolchain. It also works on a sam_e70_xplained board with the Debian toolchain but it fails to build with the Zephyr 0.10.0 SDK.

The idea is to add more exceptions test, like triggering an `std::length_error `exception by using `substr` on a string with an out of bound position or a `std::out_of_range` exception by using `at` on a vector. This currently doesn't work as `ztest.h`include `util.h` with `extern C`, while it defines a template function.",59771425
1306,2019-02-15T12:12:35Z,2019-04-30T16:24:17Z,,,"""STRINGIFY"" is the default name for this macro for every other
project out there. Using such with Zephyr will lead to macro
redifinition warning, which can easily become errors with -Werror.

For reference, a specific case where this happened is with open62541
project.

Fixes: #12935

Signed-off-by: Paul Sokolovsky <paul.sokolovsky@linaro.org>",59771425
1307,2019-02-13T09:15:18Z,2019-09-19T17:23:16Z,,,"**Description**
Sanitycheck test:

_tests/benchmarks/latency_measure/benchmark.latency_

does not pass on every Cortex-M platform with _CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC_ exceeding 24 bits. In the test there is a config value:

_CONFIG_SYS_CLOCK_TICKS_PER_SEC=1_

which could be changed to 10 using e.g:

`set(small_freq_divider_frdm_k64f TRUE)`

this is fine as far as the _CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC_ does not exceed 167772159. Unfortunately, STM32F4 Discovery has this config set to 168000000. This could mess up with _cortex_m_systick.c_ because _CYC_PER_TICK_ will exceed 24 bit as well:

`#define CYC_PER_TICK (CONFIG_SYS_CLOCK_HW_CYCLES_PER_SEC    \
            / CONFIG_SYS_CLOCK_TICKS_PER_SEC)
`

so in this case this will result in unhandled writes to SysTick Reload Value Register which can store only 24 bits (http://infocenter.arm.com/help/topic/com.arm.doc.dui0553b/DUI0553.pdf#page=250).

The proposed check verifies the _CYC_PER_TICK_ value in compile time, causing the mentioned test not to compile when this situation occurs. Also proposed changes handle platforms different frequency values and calculate _CONFIG_SYS_CLOCK_TICKS_PER_SEC_ to be the least value which will not exceed 24 bit for Cortex-M devices. I am open to suggestions on another approaches to fix the test itself for platforms with higher frequencies.",59771425
1308,2019-02-01T16:50:08Z,2019-06-18T16:37:19Z,,,"Basic requirements:
1. It should be possible to control whether include/posix/ is
added to include search path or not.
2. It should be possible to use individual parts of POSIX API,
without bringing in everything else. For example, if user is
interested in just sleep(), should be possible to enable just
that.
3. Keep existing CONFIG_POSIX_API as ""master switch"", which
enables ""a lot of POSIX APIs"".

Fixes: #12965

Signed-off-by: Paul Sokolovsky <paul.sokolovsky@linaro.org>",59771425
1309,2019-01-31T21:28:01Z,2020-01-17T09:40:02Z,,,"OpenThread currently uses the 4 last pages of the flash memory to store
its data. This does not work correctly when a bootloader is used (either
MCUboot or nRF5 bootloader) as this area is used for other purpose.

This patch therefore move the OpenThread flash area to the storage area.
In the long term it should be better to use the settings subsystem
instead of the OpenThread flash platform system, but that is a more
complicated change.

Signed-off-by: Aurelien Jarno <aurelien@aurel32.net>",59771425
1310,2019-01-29T17:56:45Z,2019-12-24T09:42:09Z,,,"Add support for Fanstel EV-BT832X board.

Signed-off-by: Vinayak Kariappa Chettimada <vinayak.chettimada@sixoctets.com>",59771425
1311,2019-01-20T00:21:17Z,2019-04-16T20:53:02Z,,,"Some toolchains default to RV64, so this is necessary.

Please review extra carefully, because this is my first PR in this project and I didn't even know this existed yesterday. Nice project, btw! :+1: ",59771425
1312,2019-01-16T08:57:47Z,2020-02-24T11:56:23Z,,,"Changes the linker sections to follow the
[ELF Spec](http://refspecs.linuxbase.org/elf/elf.pdf)
instead of using sections without `.` infront for special
sections.

Fixes #12490

Signed-off-by: Sigvart M. Hovland <sigvart.hovland@nordicsemi.no>",59771425
1313,2019-01-15T17:49:06Z,2019-09-18T11:29:10Z,,,"[For discussion, mostly.  This is a quickly thrown together version of the change I expected to see in #12485, modifying the interpretation of k_timer_start() arguments only without trying to get into a rework of the way timeout queuing is done.]

When tickless is enabled and we have a delayed tick announcement, the
timeout callback will of course be late.  Some existing code wants to
reschedule callbacks relative to when the timeout ""should"" have
occurred, while some apps are going to naturally expect the timeout is
a realtime quantity relative to the true current time.

Split these conventions by some careful redocumentation of the
difference between the ""duration"" (initial timeout) and ""period""
arguments to k_timer_start(), and a flag passed to _add_timeout().

Signed-off-by: Andy Ross <andrew.j.ross@intel.com>",59771425
1314,2018-12-18T14:12:12Z,2019-04-16T20:52:55Z,,,"To be able to pass or retain information between multiple images such as a
boot loader and a zephyr application a shared RAM section needs to be available.
This commit adds a shared memory region called `SHARED_SRAM` which the linker
script then can use in anyway it wants. Like using the `custom-section.ld` file
to place a custom section in a shared region; of course this needs to be
configured for both the boot loader and application. Or use the available `zephyr_code_relocate` function in CMake and place data in a shared region.

### Rationale
This is an RFC because I'm really unsure if this is something Zephyr wants to support but it's useful in code sharing between a boot loader and application(if desired) 

### Use case
Keeping persistent debug info/buffer when developing with a boot loader.  When you do a jump from the boot loader to an application and you are doing deferred logging in the boot loader and application the log buffer could be lost because you are switching to another image before the logs are outputted through the back-end, those logs are lost and non-recoverable.

You could also use this space to store other useful information which you want to retain from the boot loader to the application.

### Point of discussions
People could just derive their own linker-script from `linker.ld` and add the memory regions they want themselves. So why is this needed?

> @sigvartmh: It could be nice to have a configurable region already available so that most use-cases are covered. This way a lot of use-cases don't have to derive a `custom linker-script.ld`then track any upstream changes done to this file.

Signed-off-by: Sigvart Hovland <sigvart.m@gmail.com>",59771425
1315,2018-12-14T13:00:11Z,2020-03-21T09:10:27Z,,,"There are a lot of Power Management ICs featuring multiple capabilities like boost mode output, fuel gauging and battery charging. This adds a base driver for these.

Why multiple APIs in driver api? Take the TI BQ24295 for example, it's a battery charger with some alerts (like a fuel gauge), also has adjustable boost output voltage and adjustable charging voltage / current. So it's API-wise a 3-in-1 device. ",59771425
1316,2018-12-13T15:07:22Z,2020-01-30T10:47:53Z,,,"Virtually all of the SoCs require part number information to compile the code. Originally this information was provided by a Kconfig option. After introduction of the DT some part number dependent configuration settings such as RAM and flash size were moved to DT. Consequently we need to maintain and set part number information twice, once in Kconfig and once in DT.

This PR adds DT bindings to allow to obtain SoC part number from the device tree. The corresponding Kconfig options can be removed.

Zephyr DT is supposed to be compatible with Linux DT, however Linux DT does not seem to contain part number information. Following proposal is Zephyr specific.

Since the DT root node is supposed to represent the board I propose to attach the part-number property to the soc node. The proposal needs to be carefully reviewed.",59771425
1317,2018-12-07T12:03:20Z,2019-09-18T15:42:04Z,,,"Introduces the OpenAMP Remote Echo Sample to have Linux and Zephyr communicating in i.MX7/6SX SoCs.

Note that this PR depends on #11355.",59771425
1318,2018-11-30T16:25:59Z,2020-01-23T16:27:09Z,,,,59771425
1319,2018-11-21T06:52:01Z,2020-01-30T03:39:51Z,,,"1. Change ""just the image"" of the board with the image which shows
component location (taken from user guide PDF). This is especially
useful, as the board doesn't have descriptive silkscreen labels,
only component numberings, e.g. there're 3 microUSB connectors
labeled just Jxx, Jyy, Jzz.
2. Mention more MCU features useful to a user.
3. Elaborate the ""Memory"" section, to describe memory structure to
provide complete enough picture to a user.
4. Explicitly mention that the board (currently) doesn't have any
means to program flash, and the only way to run apps is by running
them via debugger.
5. Explicitly mention that a fresh board received requires installing
different USB bootloader firmware.
6. Standardize on referring to ""ninja"" as a build tool, as the rest
of the docs does.
7. Other minor changes and clarifications.

Signed-off-by: Paul Sokolovsky <paul.sokolovsky@linaro.org>",59771425
1320,2018-11-19T15:01:44Z,2019-05-21T19:20:43Z,,,"For not all applications the poll_signal interface is a practical solution to tell upper layers an asynchronous transfer is completed.
To allow different types of synchronization, a composite interface is made. Allowing semaphore (give), mutex (unlock), alert (send) and poll (signal) to be used depending on the application one of the given methods can be used.  

An additional method could be added, which is a callback function with the device as argument. This is not added to this composite interface yet. 

In case this is seen as a practical way of handling asynchronous callbacks, it could be extended to a generic implementation for all I/O drivers. 

Signed-off-by: Vincent van der Locht <vincent@vlotech.nl>",59771425
1321,2018-10-27T17:15:10Z,2020-01-30T10:45:59Z,,,"# Overview

Use Codegen #10885 for device instantiation.

This PR includes parts of PR #10885. It is the successor to #9163.

# Motivation for or Use Case

Demonstrate the usage of Codegen and the included devicedeclare module for device instantiation.

# Design Details

The following drivers are adapted to use codegen for device instantiation:
  - I2C: i2c_ll_stm32.c (commit: drivers: i2c: stm32: use codegen driver instantiation)
  - SPI: spi_ll_stm32.c (commit: drivers: spi: stm32: use codegen driver instantiation)
  - SERIAL: uart_stm32.c: (commit: drivers: serial: stm32: use codegen driver instantiation)
  - CAN: stm32_can.c: (commit: drivers: can: stm32: use codegen driver instantiation)
  - PWM: pwm_stm32.c (drivers: pwm: stm32: use codegen driver instantiation)
  - INT: exti_stm32.c (drivers: interrupt: stm32: use codegen driver instantiation)

Codegen #10885  provides two device declaration functions in it's devicedeclare module.
  - devicedeclare.device_declare
    Provides a sophisticated device declaration API. It is transferred from @erwango 's work in #8561.
  - devicedeclare.device_declare_single/multi
    Provides a more raw device declaration API that allows for a fine grained control of the device instantiation template. It is the basis also for devicedeclare.device_declare.

All drivers above except INT are adapted to use the devicedeclare.device_declare_multi API.

The interrupt driver uses the devicedeclare.device_declare API. It is a minimal conversion to show the feasibility. For elaborated examples of the devciedeclare.device_declare API see #8561.

Codegen's device declaration is done using a device info template with placeholders that is used for every device instance. The placeholders are replaced by the respective device tree or device instance values:
  - Device tree property placeholder are defined by the property path; either ${[property path]} for properties of the actual device instance or ${[device id]:[property path]} for another device instance property.
  - The device instance placeholders ${device-[xxx]} provide device instance specific info that is autogenerated eg. device name, driver name, name of the data structure ...

```
/**
 * @code{.codegen}
 * codegen.import_module('devicedeclare')
 *
 * device_configs = ['CONFIG_I2C_{}'.format(x) for x in range(0, 5)]
 * driver_names = ['I2C_{}'.format(x) for x in range(0, 5)]
 * device_inits = 'i2c_stm32_init'
 * device_levels = 'POST_KERNEL'
 * device_prios = 'CONFIG_KERNEL_INIT_PRIORITY_DEVICE'
 * device_api = 'api_funcs'
 * device_info = \
 * """"""
 * #if CONFIG_I2C_STM32_INTERRUPT
 * DEVICE_DECLARE(${device-name});
 * static void ${device-config-irq}(struct device *dev)
 * {
 * #ifdef CONFIG_I2C_STM32_COMBINED_INTERRUPT
 *         IRQ_CONNECT(${interrupts/combined/irq}, ${interrupts/combined/priority}, \\
 *                     stm32_i2c_combined_isr, \\
 *                     DEVICE_GET(${device-name}), 0);
 *         irq_enable(${interrupts/combined/irq});
 * #else
 *         IRQ_CONNECT(${interrupts/event/irq}, ${interrupts/event/priority}, \\
 *                     stm32_i2c_event_isr, \\
 *                     DEVICE_GET(${device-name}), 0);
 *         irq_enable(${interrupts/event/irq});
 *         IRQ_CONNECT(${interrupts/error/irq}, ${interrupts/error/priority}, \\
 *                     stm32_i2c_error_isr, \\
 *                     DEVICE_GET(${device-name}), 0);
 *         irq_enable(${interrupts/error/irq});
 * #endif
 * }
 * #endif
 * static const struct i2c_stm32_config ${device-config-info} = {
 *         .i2c = (I2C_TypeDef *)${reg/0/address/0},
 *         .pclken.bus = ${clocks/0/bus},
 *         .pclken.enr = ${clocks/0/bits},
 * #if CONFIG_I2C_STM32_INTERRUPT
 *         .irq_config_func = ${device-config-irq},
 * #endif
 *         .bitrate = ${clock-frequency},
 * #if defined(CONFIG_SOC_SERIES_STM32F3X) || defined(CONFIG_SOC_SERIES_STM32F0X)
 *         .ll_clock_source = LL_${driver-name}_CLOCKSOURCE,
 * #endif
 * };
 * static struct i2c_stm32_data ${device-data};
 * """"""
 *
 * devicedeclare.device_declare_multi( \
 *     device_configs,
 *     driver_names,
 *     device_inits,
 *     device_levels,
 *     device_prios,
 *     device_api,
 *     device_info)
 * @endcode{.codegen}
 */
/** @code{.codeins}@endcode */
```

# Test Strategy

This PR extends the SPI loopback test for the NUCLEO F091RC board. It was tested using this test and some
sample applications.

Signed-off-by: Bobby Noelte <b0661n0e17e@gmail.com>",59771425
1322,2018-10-26T21:53:33Z,2020-03-03T07:09:59Z,,,"# Overview

Extend Zephyr build system by inline code generation ([cogeno](https://cogeno.readthedocs.io/en/latest/)) with Python snippets in source files. As most information for drivers is taken from the device tree an extended device tree database (edts) is added to allow easy retrieval with Python.

The PR is the sucessor to PR #6762. It includes all of #6762 and the relevant commits from #9876.

The PR is completely self contained. Besides the changes to the CMake build system to allow [cogeno](https://cogeno.readthedocs.io/en/latest/) to be used as a script there are no other changes to the current code base.

# Motivation for or Use Case

The prime motivation is to be able to configure drivers on build time by the information from the device tree in a standardized way. Therefor there must be means to easily generate structured  data from device tree information at build time.

The EDTS database directly extracts the device tree information from the compiled DTS data. Inline code generation with Python snippets by cogeno is used to get this information and generate structured data to be compiled.

# Design Details

Python snippets that are inlined in a source file are used as generators. The tool to scan the source file for the Python snippets and process them is [cogeno](https://cogeno.readthedocs.io/en/latest/). [Cogeno](https://cogeno.readthedocs.io/en/latest/) is itself written in Python. [Cogeno](https://cogeno.readthedocs.io/en/latest/) used [Cog](https://nedbatchelder.com/code/cog/index.html) as it's starting point and has extended and rewritten it to provide specific generator functions.

The processing of source files is controlled by two CMake extension functions: zephyr_sources_cogeno(..) and zephyr_sources_cogeno_ifdef(..). During CMake configuration the source files are processed by cogeno and the generated source files are written to the CMake binary directory. The generated source files are added to the Zephyr sources.

The inlined Python snippets can contain any Python code, they are regular Python scripts. All Python snippets in a source file and all Python snippets of included template files are treated as a python script with a common set of global Python variables. Global data created in one snippet can be used in another snippet that is processed later on. This feature is e.g. used to customize included template files.

An inlined Python snippet can always access the [cogeno](https://cogeno.readthedocs.io/en/latest/) module. The [cogeno](https://cogeno.readthedocs.io/en/latest/) module encapsulates and provides all the functions to retrieve information (options, device tree properties, CMake variables, config properties) and to put out the generated code.

# Test Strategy

A working proof of concept for driver instantiation is #10888 (Edit: Has to be updated).

For the EDTS database the sanity check script from #9876 is used with some adaptations.

# PR History

This PR is the sucessor of several PRs:

  - #5799 'extract_dts_includes.py script'
    - This PR is the source of codegen and the extended DTS database. Codegen was added to be able to generate device data structures for pin controllers at build time from DTS data. The EDTS database was added to provide a more consistent access to device tree info. To enable easier review PRs #6762 (codegen) and #6761 (EDTS database/ DTS extraction) were split out. #5799 was also used as a test platform to prove the viability of inline code generation using a very complex driver - the pin controller driver for STM32F0. To have an easy review of the simpler prove of concept drivers also #9163 (Device instantiation) was split out.
  - #6761 '[WIP] scripts: extract_dts_includes.py: enhance'
    - This PR described a way to extract DTS info to the EDTS database using the extract_dts_includes.py script. It was superseded by #9876 which still uses the extract_dts_includes.py script but improved the API of the extended DTS database that holds the DTS info after extraction.
  - #6762 'scripts: add Zephyr inline code generation with Python'
    - This PR contained the inline code generation tool codegen. In the beginning codegen used the DTS info extraction from #6761. Later on it used the sucessor #9876.
  - #9163 'drivers: use codegen for device instantiation'
    - As already descrived in this PR the easy instantiation of drivers using inline code generation was shown. It's pendant that fits to this PR is #10888.
  - #9876 'script/dts: Generate Extended Device Tree database'
    - This PR as the sucessor to #6761 enhanced the EDTS database API and internal structure.
  - #10885 - 2018: ''
    - In this PR the codegen tool (#6762) and the extended DTS database (#9876, #6761) is re-integrated. The additions/ improvements that were done in #9876 are also re-integrated. With the current PR the extraction of DTS info was made independent from the extract_dts_includes.py script to make this PR a self contained change that does not effect the current code base. The EDTS database now includes an internal DTS extraction function that extracts directly from the compiled DTS file.
  - #10885 - NOW: ''
    - Codegen transfered to [cogeno](https://cogeno.readthedocs.io/en/latest/), a standalone tool with it's own repository.  


Signed-off-by: Bobby Noelte <b0661n0e17e@gmail.com>",59771425
1323,2018-09-06T10:54:38Z,2019-10-22T08:59:59Z,,,"This is the first rough proof of concept of adding a LoRa layer.
Sorry for unnecessary files like .gitignore, I'll clean this up as soon as I prepare an actual production PR.

Concept:
- lora_context is the entry point
- keep LoRa and LoRaWAN seperate
- There are a lot of devices based on UART commands, thus, lora_context_uart is meant as their base
- I don't see a reason why there would have to be multiple context instances, well, maybe for a nano gateway but that's out of scope for me
- there are basic events which should be implemented by every application and would go in the lora_context_cb, on the other hand there are callbacks (like I demo'ed for get version) which are rather callbacks then events
- @miyatsu suggested to port LoRaMac-node which I'd love to see - although I can't do it due to a lack of supported devices and need. But basically they could go to a new lora_context_loramacext or so - if required, I've already tried to create a directory tree for this which is not included in this PR to keep things clean

To discuss:
- I suggest abstracting the UART peripherals a bit more, that's why I introduced eg HW_UART0_ENABLED which should be selected from any board-specific UART driver's submenu, if possible
- I feel it is problematic to kind of ""hide"" the UART peripheral's baud rate. I was testing and testing, no response from my RN2483 until I finally remembered to change the baud rate. I think it would be better to be able to configure the baud rate in the Serial driver menu, depending on count of UART peripherals selected

Requests (apart from comments):
- I like @mike-scott 's UART device logic implemented for the modem drivers. Is it possible to move that to a utility class?",59771425
1324,2020-02-11T21:22:49Z,2020-02-11T21:22:49Z,,,"I merge the changes done by @DWiskow in [this repository](https://github.com/DWiskow/grbl1-1g-Servo) with grbl 1.1h version.

DWiskow explains his work in [this post](https://forum.eleksmaker.com/topic/2510/grbl-1-1g-with-servo-for-mana-se) and I replicate it in 1.1h release.

Now you can enable the servo on z axis directly in config.h like the @cprezzi approach.

Thanks for your work.",68751856
1325,2020-02-03T14:16:06Z,2020-02-03T14:16:06Z,,,,68751856
1326,2020-01-21T11:12:26Z,2020-01-21T11:18:12Z,,,"Hey, I would like to send gcode using HC-05 bluetooth module to STM32F103C8T6 and not via usb. It would help me a lot if someone know what to modify in order to make it work. Thanks",68751856
1327,2020-01-07T22:58:54Z,2020-01-07T23:02:26Z,,,"Fixed an issue where grbl's state machine gets corrupted.  For example, if ""$H0abc"" is sent, existing grbl sets sys.state=STATE_HOMING, but then bails out without actually homing.  Subsequent ""$H"" commands are then not executed, because grbl isn't idle (it still thinks it's homing).

Moving sys.state=STATE_HOMING to after the conditional prevents grbl from getting stuck in homing state.",68751856
1328,2019-09-04T22:23:13Z,2019-10-17T20:40:08Z,,,"@chamnit & @bdurbrow
As discussed in #715 this is all that's needed to build `Grbl` as a normal ""sketch"".
Saw no reason to remove `grblUpload` at the moment as it's still valid and none of this breaks being able to use it as a library. However, if this was accepted and you wanted to make it the normal way of using `Grbl` I'd be happy to update the docs to reflect this method.",68751856
1329,2019-08-23T16:48:19Z,2019-08-23T16:48:19Z,,,"Implemention of grbl axis skew compensation.
Axis skew compensation is enabled in config.h. By default only XY skew is enabled.
Axis pair XZ or YZ skew compensation calculations are optional and also configurable on config.h

Compensation is done by computing the current axis position and applying a given factor for each pair of axis. The formula for the compensation factor is explained in the config.h file.
When reporting the current position the inverse transformation is also applied.

The skew factors are saved in EEPROM configuration words $37(XY), $38(XZ) and $39(YZ).",68751856
1330,2019-06-12T02:28:33Z,2019-12-05T08:03:09Z,,,,68751856
1331,2019-06-07T22:18:38Z,2019-06-08T20:24:19Z,,,"In the CNC Shield v4 which is for the Arduino nano, the pins for direction are 2,3 and 4. The same way, the bits for step are 5,6 and 7. Uncommenting the definition for CNC_SHIELD_V4 in grbl/cpu_map.h make these changes",68751856
1332,2019-04-02T04:03:14Z,2019-04-02T04:03:14Z,,,Less radical approach to #623 . Just do not clear G92 and G43.1 on soft-reset. Does not change memory or flash requirements.,68751856
1333,2019-03-18T08:24:51Z,2019-03-25T07:56:23Z,,,"This patch addresses issue #623 . It adds EEPROM persistence to G92 and G43.1 parameters, reduces flash consumption by approximately 150 bytes but increases RAM consumption by 8 bytes.",68751856
1334,2019-02-12T03:52:20Z,2019-02-17T07:01:16Z,,,Attempt to make Grbl respond the way the manual says as per restoring from feed hold.,68751856
1335,2019-01-06T05:22:20Z,2019-01-06T05:22:20Z,,,these are the defaults that shapeoko 3 xxl actually requires with Carbide Motion v4.,68751856
1336,2018-11-10T15:57:11Z,2018-11-11T20:23:51Z,,,"- set OC2A output to low when disabling PWM
- reset timer counter when disabling PWM (synchronize timer)",68751856
1337,2018-05-04T04:52:22Z,2018-05-04T04:52:22Z,,,I'm looking to make these files Python3 compatible but didn't want to do it in one big batch.   Here are some initial patches to clean them up in preparation.  ,68751856
1338,2017-08-11T06:51:30Z,2019-07-25T08:07:20Z,,,"Adds the option to invert the duty cycle of the variable speed spindle output pin.
Tested with VFD Controller (Huanyang Invertor Model: HY01D523B)",68751856
1339,2017-08-07T09:14:42Z,2019-03-11T12:30:58Z,,,"Hi, I've added servo support via the spindle pin (as many others have done it before). My version will look for $33 (and the servo bit flag) as an switch for the servo / non-servo mode. 

I'm using GRBL on a axidraw bot like machine ( https://evilmadscience.s3.dualstack.us-east-1.amazonaws.com/catalog/emskits/axidraw/site/640v3/blogPhotos/1@2x.jpg ) that can either carry a laser (thus requires full range PWM like a spindle) but can also be equipped with an servo-driven pen.

**I admit that this setup might be a bit unique but the requirement for servo support has been raised a couple times and I thought you might consider to integrate it as a run-time switch so people without programming skills can activate this via a simple $33=1** 

it will restrict the pwm to 0.5 - 2.5ms pulse (still uses user configured max_rpm/min_rpm) which is standard servo signal and the same other pull requests have used. I've tested the code on my setup 

Thanks for your work, I hope I can support this great project a little bit.
Kolja",68751856
1340,2017-03-10T15:36:42Z,2020-03-09T10:04:00Z,,,"Hi Sonny

I have implemented support for servo instead of spindle (for EggBot). It's switchable by `#define SPINDLE_IS_SERVO` in config.h. 
This defines a prescaler of 1/1024 (61Hz) and min/max PWM values for a pulse duration between 0.5 and 2.5ms in cpu_map.h.
In spindle_control.c I modified the function spindle_compute_pwm_value: If SPINDLE_IS_SERVO is defined, don't calc spindle override and use min PWM instead of stop_spindle. 

I have tested it with an EggBot and LaserWeb3 and 4.

Hope this is usefull for you.

Regards Claudio",68751856
1341,2019-11-05T20:56:54Z,2019-11-05T20:57:54Z,,,"Backport of IBUS protocol changes already implemented in BF.

The PR created on request of FlySky - they want to have receivers compatible.

New FlySky receivers (AFHDS 3 and latest AFHDS 2a) are using 4 bits free bits in every channel to pass additional data, thus increase total passed channels to 18.
Missing logic has been implemented - it is still compatible with 14 channels receivers.

The fix is critical because if new channels are being send in the frame they are causing invalid value recognition.
Information about change I got from first hand - talked directly to FlySky.",9066347
1342,2019-03-10T08:15:27Z,2019-03-10T08:15:27Z,,,"## Important considerations when opening a pull request:

1. Pull requests will only be accepted if they are opened against the `master` branch. Pull requests opened against other branches without prior consent from the maintainers will be closed;

2. Please follow the coding style guidlines: https://github.com/cleanflight/cleanflight/blob/master/docs/development/CodingStyle.md

3. Keep your pull requests as small and concise as possible. One pull request should only ever add / update one feature. If the change that you are proposing has a wider scope, consider splitting it over multiple pull requests. In particular, pull requests that combine changes to features and one or more new targets are not acceptable.

4. Ideally, a pull request should contain only one commit, with a descriptive message. If your changes use more than one commit, rebase / squash them into one commit before submitting a pull request. If you need to amend your pull request, make sure that the additional commit has a descriptive message, or - even better - use `git commit --amend` to amend your original commit.

5. All pull requests are reviewed. Be ready to receive constructive criticism, and to learn and improve your coding style. Also, be ready to clarify anything that isn't already sufficiently explained in the code and text of the pull request, and to defend your ideas.

6. If your pull request is a fix for one or more issues that are open in GitHub, add a comment to your pull request, and add the issue numbers of the issues that are fixed in the form `Fixes #<issue number>`. This will cause the issues to be closed when the pull request is merged;

7. If you have already had your PR merged in BF then no need to currently create a new PR here.

8. Remove this Text :).
",9066347
1343,2019-02-05T08:25:39Z,2019-02-05T09:20:12Z,,,"## Important considerations when opening a pull request:

1. Pull requests will only be accepted if they are opened against the `master` branch. Pull requests opened against other branches without prior consent from the maintainers will be closed;

2. Please follow the coding style guidlines: https://github.com/cleanflight/cleanflight/blob/master/docs/development/CodingStyle.md

3. Keep your pull requests as small and concise as possible. One pull request should only ever add / update one feature. If the change that you are proposing has a wider scope, consider splitting it over multiple pull requests. In particular, pull requests that combine changes to features and one or more new targets are not acceptable.

4. Ideally, a pull request should contain only one commit, with a descriptive message. If your changes use more than one commit, rebase / squash them into one commit before submitting a pull request. If you need to amend your pull request, make sure that the additional commit has a descriptive message, or - even better - use `git commit --amend` to amend your original commit.

5. All pull requests are reviewed. Be ready to receive constructive criticism, and to learn and improve your coding style. Also, be ready to clarify anything that isn't already sufficiently explained in the code and text of the pull request, and to defend your ideas.

6. If your pull request is a fix for one or more issues that are open in GitHub, add a comment to your pull request, and add the issue numbers of the issues that are fixed in the form `Fixes #<issue number>`. This will cause the issues to be closed when the pull request is merged;

7. If you have already had your PR merged in BF then no need to currently create a new PR here.

8. Remove this Text :).
",9066347
1344,2020-01-14T18:00:18Z,2020-02-04T12:31:31Z,,,"Change ""Rephael"" to ""Raphael"".

As the file had mixed line-endings, this MR also normalizes the line-endings.",30136107
1345,2019-12-31T17:26:04Z,2019-12-31T17:26:04Z,,,,30136107
1346,2019-12-31T14:14:01Z,2019-12-31T14:14:01Z,,,,30136107
1347,2019-11-19T07:50:02Z,2019-11-19T07:50:02Z,,,"placeholder       : ""coding now....""
多了一个  :",30136107
1348,2019-10-13T12:04:43Z,2019-10-13T15:51:02Z,,,add german translated language,30136107
1349,2019-10-11T21:10:13Z,2019-10-11T21:10:13Z,,,"prettify.js has moved from code.google.com to github, this changes the link to the new location.",30136107
1350,2019-07-18T09:31:13Z,2020-01-26T13:44:02Z,,,"marked only accept string type, `new String()` will return an object `[object String]`

https://github.com/markedjs/marked/blob/f35c3e6d9a22980c9a5b61d33c394b4429914803/lib/marked.js#L1549-L1557",30136107
1351,2019-06-21T08:41:32Z,2019-06-21T08:43:04Z,,,"现在如果上传图片没有填写图片描述的话，光标始终会第二行或者第三行，而不是在我原先要输入的地方

不太知道作者原意图是什么？是否要改一下呢？目前我都是注释掉这两行，请看一下，是否改正确，还是有别的我没有想到的地方，感谢。",30136107
1352,2019-05-08T14:31:20Z,2019-05-08T14:31:29Z,,,,30136107
1353,2019-05-08T14:27:45Z,2019-05-09T11:52:04Z,,,,30136107
1354,2018-06-22T20:07:24Z,2018-06-22T20:07:24Z,,,"Fixes Fullscreen problem that happens
when two editormd widgets are loaded
in the same page and one of them enters
fullscreen mode",30136107
1355,2017-08-03T09:32:47Z,2019-01-25T08:30:03Z,,,,30136107
1356,2017-05-12T10:33:22Z,2017-05-12T10:33:22Z,,,"The bug is:
If you paste a line like:
```
#### <i class=""icon-file""></i> Document
```
to the ""Full example"" [page](https://pandao.github.io/editor.md/), the html will be shown like
```
Document"" class=""reference-link""> Document
```
",30136107
1357,2020-02-22T22:01:51Z,2020-02-22T22:01:51Z,,,,46494844
1358,2019-09-25T22:47:46Z,2019-09-25T22:49:33Z,,,"Status: **DO NOT MERGE**

See #247 
See #339 

When we assign our new `(secured-eval)` we've been allowing the `window`
property to bleed through as `this`. Additionally we have been setting
our forbidden symbols as the empty object `{}` which also exposes the
`Object` prototype.

In this patch we're replacing both of those in an attempt to further
limit the extent to which scripts can access global data.

The downside to this approach is that we've lost all prototypes that we
want, such as `Array.prototype.map`. The severity of this limitation is
so high that it's probably unmergable, but I'm hoping there might still
be a way to resolve that.",46494844
1359,2019-01-08T16:14:29Z,2019-01-08T16:14:30Z,,,,46494844
1360,2019-01-03T06:12:45Z,2019-01-03T19:40:00Z,,,,46494844
1361,2018-09-07T05:14:29Z,2019-01-02T15:46:05Z,,,,46494844
1362,2018-07-08T06:13:26Z,2019-01-05T07:08:00Z,,,"Hey @viebel,
I've started working on stopping code execution inside Klipse snippets. Right now, I have a very basic implementation which simply ensure that scripts with infinite loops don't freeze the page (issue #162). 
In the code snippet below, I write an infinite loop in JavaScript but the page remains interactive. 
![klipse](https://user-images.githubusercontent.com/15348827/42417276-09ad09de-823b-11e8-99dd-3f18689f8e12.gif)

My final goal with this PR is to add a simple stop button on the top right corner of the klipse code snippet box that allows the user to stop execution of programs. Let me know if you have any other ideas/design goals you wanted to address with stopify.
",46494844
1363,2017-12-03T21:56:22Z,2018-10-01T17:35:54Z,,,"Closes https://github.com/codefordenver/owlet/issues/314
",46494844
1364,2017-09-17T00:54:04Z,2019-05-30T17:43:38Z,,,I have opened a pull request related to #278 and #279.,46494844
1365,2017-07-02T06:08:38Z,2018-10-01T17:35:53Z,,,This fixes http://dev.clojure.org/jira/browse/ASYNC-159,46494844
1366,2017-05-24T18:20:17Z,2018-10-01T17:35:53Z,,,,46494844
1367,2017-05-23T17:52:48Z,2018-10-01T17:35:53Z,,,"This CLJS release fixes a regression in self-hosted ClojureScript
compiler which rechecked all specs during every macroexpansion.

This CLJS release is also after the clojure.spec -> clojure.spec.alpha
change, so there were some references that needed to change. This also
required an upgrade to viebel/gadjett and will require that library's version to be bumped.",46494844
1368,2017-03-25T19:35:53Z,2018-10-01T17:35:53Z,,,,46494844
1369,2017-03-03T22:45:51Z,2018-10-01T17:35:52Z,,,Replaced the word tag with the word element for precise semantics.,46494844
1370,2017-01-12T10:16:41Z,2018-10-01T17:35:52Z,,,,46494844
1371,2016-11-24T19:54:16Z,2018-10-01T17:35:52Z,,,,46494844
1372,2016-08-19T09:55:19Z,2018-10-01T17:35:52Z,,,,46494844
1373,2020-03-20T16:55:27Z,2020-03-20T23:36:02Z,,,Fixes #1885.,7184072
1374,2020-03-16T02:33:44Z,2020-03-18T13:19:03Z,,,"Resolves #1883
I would encourage reviewers to look at the commit history to see if there is any merit in the an earlier more verbose approach I took.
This is my first time committing lisp code, so any feedback would be kindly received! :)",7184072
1375,2020-03-15T06:45:31Z,2020-03-15T11:48:53Z,,,"* Update argument spec parse logic of parse-args function.
* Update test case of parse-args function.
* Update document of parse-args function.
* Describe the change in NEWS file.
* Add name to AUTHORS file.",7184072
1376,2020-01-18T22:27:10Z,2020-01-19T14:47:53Z,,,"Trivial, yay or nay?",7184072
1377,2019-01-18T21:29:35Z,2019-02-01T12:53:31Z,,,As per https://github.com/hylang/hy/pull/1731.,7184072
1378,2018-09-09T06:18:32Z,2018-09-13T19:11:16Z,,,"With the context manager provided here, `pdb` (`ipdb` and Pdb++) sessions started from the Hy REPL can evaluate Hy code.  For example, the following is possible:
```clojure
=> (pdb.run ""(setv x 1)"")                                                                                                                                                                                           
[1] > <string>(1)<module>()
(Pdb++) p (+ 1 1)                                                                                                                                                                                                   
2L
None
(Pdb++) !(print ""hi"")                                                                                                                                                                                               
hi
(Pdb++) up                                                                                                                                                                                                          
[0] > /home/bwillard/projects/code/python/hy/hy/cmdline.py(150)_hy_bdb_run()
-> exec(cmd, globals, locals)
(Pdb++) (.keys locals)                                                                                                                                                                                              
['__builtins__', 'pdb', 'x', u'hyx_XasteriskX1', '__name__', u'hyx_XasteriskX3', u'hyx_XasteriskX2', '__doc__']
(Pdb++) c                                                                                                                                                                                                           
=> x                                                                                                                                                                                                                
1L
=> (import [hy.contrib.walk [walk postwalk]])                                                                                                                                                                            
=> (pdb.run ""(postwalk identity '(+ x 2))"")                                                                                                                                                                         
[1] > <string>(0)<module>()
(Pdb++) b walk
Breakpoint 1 at /home/bwillard/projects/code/python/hy/hy/contrib/walk.hy:17
(Pdb++) c                                                                                                                                                                                                           
[3] > /home/bwillard/projects/code/python/hy/hy/contrib/walk.hy(17)walk()
-> [(instance? HyExpression form)
(Pdb++) ll                                                                                                                                                                                                          
   1     ;;; Hy AST walker                                                                                                                                                                                          
   2     ;; Copyright 2018 the authors.                                                                                                                                                                             
   3     ;; This file is part of Hy, which is free software licensed under the Expat                                                                                                                                
   4     ;; license. See the LICENSE.                                                                                                                                                                               
   5                                                                                                                                                                                                                
   6     (import [hy [HyExpression HyDict]]                                                                                                                                                                         
   7             [functools [partial]]                                                                                                                                                                              
   8             [collections [OrderedDict]]                                                                                                                                                                        
   9             [hy.macros [macroexpand :as mexpand]]                                                                                                                                                              
  10             [hy.compiler [HyASTCompiler]])                                                                                                                                                                     
  11                                                                                                                                                                                                                
  12     (defn walk [inner outer form]                                                                                                                                                                              
  13       ""Traverses form, an arbitrary data structure. Applies inner to each                                                                                                                                      
  14       element of form, building up a data structure of the same type.                                                                                                                                          
  15       Applies outer to the result.""                                                                                                                                                                            
  16       (cond                                                                                                                                                                                                    
  17  ->    [(instance? HyExpression form)                                                                                                                                                                          
  18         (outer (HyExpression (map inner form)))]                                                                                                                                                               
  19        [(instance? HyDict form)                                                                                                                                                                                
  20         (HyDict (outer (HyExpression (map inner form))))]                                                                                                                                                      
  21        [(instance? list form)                                                                                                                                                                                  
  22         ((type form) (outer (HyExpression (map inner form))))]                                                                                                                                                 
  23        [(coll? form)                                                                                                                                                                                           
  24         (walk inner outer (list form))]                                                                                                                                                                        
  25        [True (outer form)]))                                                                                                                                                                                   
  26                                                                                                                                                                                                                
  27     ...
(Pdb++) 
```
",7184072
1379,2018-05-28T03:07:05Z,2018-07-04T20:57:43Z,,,"Closes #1323

Really trivial to implement as we already properly subclass `code.InteractiveConsole`. Matches `code.interact` API.",7184072
1380,2018-05-21T06:01:04Z,2018-06-03T22:41:03Z,,,"Removes an unnecessary level of indentation, and changes them from using lists to expressions. See for details #1612

Nice work with the pattern matching compiler, its really easy to make the change.",7184072
1381,2018-03-26T21:47:14Z,2019-04-10T13:41:34Z,,,"`hy-repr` is about a year old and it seems to work pretty well. With this PR, `hy-repr` is used to print REPL output by default, and Hy gets a pair of functions `hy-repr` and `hy-eval` analogous to Python's `repr` and `eval`, the latter of which is no longer shadowed by Hy.

The change of default `repl-output-fun` will require a lot of documentation changes, of course, which I haven't yet done, but I will before this PR is merged.",7184072
1382,2018-03-04T22:24:07Z,2018-04-09T06:57:22Z,,,"Fixes a few warning with documentation formatting.

Change code blocks to `hylang`, now that Pygments has support for Hy. The `hy` specifier is used for a different language. This eliminates a lot of lexing errors and should mean more code blocks have syntax highlighting.

We're still not 100% problem free as it seems like repl output doesn't lex nicely:

```
hy/docs/contrib/walk.rst:48: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/contrib/walk.rst:128: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/extra/anaphoric.rst:246: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:124: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:246: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:340: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:469: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:510: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:876: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:903: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:914: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/api.rst:1781: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/core.rst:557: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/core.rst:717: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/language/core.rst:799: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
hy/docs/tutorial.rst:583: WARNING: Could not lex literal_block as ""hylang"". Highlighting skipped.
```",7184072
