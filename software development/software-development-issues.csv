,Title,State,Created_at,Updated_at,Closed_at,Author,Details,Comments,Id
0,Refactor PIO Account using a new Account Management System,open,2020-03-26T12:03:55Z,2020-03-26T12:04:08Z,,MEMBER,"Commands list: https://github.com/platformio/platformio-core/blob/develop/platformio/commands/account.py

- [ ] Login
- [ ] Logout
- [ ] Create a new PIO Account
- [ ] Change password
- [ ] Forgot password
- [ ] View or generate new personal PLATFORMIO_AUTH_TOKEN
- [ ] Show account information (TBD)

# Account Management System

API: https://account.platformio.org/api/v1/

# Overview

1) Move [commands/account.py](https://github.com/platformio/platformio-core/blob/develop/platformio/commands/account.py) to [commands/account/command.py](https://github.com/platformio/platformio-core/blob/develop/platformio/commands/account/command.py)
2) Replace `pioplus_call(sys.argv[1:])` with appropriate implementation using **Account Management System**

# `account` state

We save account data into `app.set_state_item(""account"")` in he next format:
```json
{
  ""auth"": ""Dictionary with authentication tokens, and other info"",
   ""username"": ""..."",
   ""email"": """"
}
```

We can extend this data later with new tasks, for example, roles, groups, etc.

# TODOs

- [ ] Implement `platformio.commands.account.helpers.get_authentication_token`

1) Read current state of authentication via `app.get_state_item(""account"").auth`
2) If `authentication_token` is valid, return it
3) If it is expired but there is `refresh_token`, fetch `authentication_token` and return it
4) If there is [PLATFORMIO_AUTH_TOKEN](https://docs.platformio.org/en/latest/envvars.html#envvar-PLATFORMIO_AUTH_TOKEN) environment variable, fetch `authentication_token` and return it
5) return None

- [ ] Implement `pio accont login` command

1) `get_authentication_token`, if it is not None => `return click.secho(""You are already logged in with %s acccount!"" % app.get_state_item(""account"").email)`
2) Otherwise, login to **Account Management System** and save data into `account` state.

",,19606299
1,Fish shell completions,open,2020-03-22T21:35:46Z,2020-03-24T10:51:03Z,,NONE,"### Configuration

**Operating system**: macOS

**PlatformIO Version** (`platformio --version`): PlatformIO, version 4.0.0

### Description of problem
I would love to have Fish Shell completions!
","Have you tried this https://github.com/click-contrib/click-completion? if it works, we will add to our docs.",19606299
2,Provide more information about failed tests on native platform,open,2020-03-18T13:42:14Z,2020-03-18T13:42:14Z,,MEMBER,"It's a good idea to print more detailed report about the reason of failed tests on native platform if the binary crashes (e.g. segfault) Originally reported here:
https://community.platformio.org/t/getting-output-of-failed-test/10940
",,19606299
3,Implement `pio project import` CLI/API,open,2020-03-18T11:53:37Z,2020-03-18T11:53:37Z,,MEMBER,Allow community to integrate own import tools into PlatformIO. One of example is https://github.com/ussserrr/stm32pio project by @ussserrr ,,19606299
4,Is there a way to install OFFLINE?????,open,2020-03-18T03:52:30Z,2020-03-18T03:58:06Z,,NONE,"My friend have really slow and metered internet, the installation take forever and never complete...
I searched around, there are also people want make it portable have the same issue.
Even copy whole .vscode and .platformio folders won't work.

Cant understand why it is so hard to make it portable and there seems no progress at all on this issue.

I'm trying to get more people play with Arduino without using that shitty IDE, but the online slow download install only really killed everyone's patient...","If there is PATH or other local ENV required, then the script may should just patch that rather than download the whole thing from beginning, at least copy whole .platform folder will work in this way...",19606299
5,Error on serial monitor console over Telnet,open,2020-03-16T19:32:23Z,2020-03-20T11:24:08Z,,NONE,"What kind of issue is this?

- [x] **PlatformIO Core**.

### Configuration

PlatformIO on VSCode

**Operating system**:

MacOS Mojave

**PlatformIO Version** (`platformio --version`):

Home: 3.1.1
Core: 4.2.1 

### Description of problem

While trying to access the serial console on a simulated device via telnet, when I open the serial monitor, I see some garbled characters. After hitting enter some times, I see the console output.

My config:

```
[env:hifive1]
platform = sifive
board = hifive1
framework = zephyr
## ----- Settings below are for Antmicro Renode integration ----- ##
# Monitor port for Renode integration
monitor_port = socket://localhost:1234
monitor_speed = 115200
...
```

The project is: https://github.com/carlosedp/ZephyrConsoleEchoSIM

```
> Executing task: platformio device monitor <

Looking for advanced Serial Monitor with UI? Check http://bit.ly/pio-advanced-monitor
--- Miniterm on socket://localhost:1234  115200,8,N,1 ---
--- Quit: Ctrl+C | Menu: Ctrl+T | Help: Ctrl+T followed by Ctrl+H ---
��␀��␁��␃��""*** Booting Zephyr OS version 2.1.0  ***
Hello! I'm running Zephyr 2.1.0 on hifive1, a riscv32 board.

Enter a line finishing with Enter:
> 
```

#### Steps to Reproduce

1. Build and upload project linked below
2. Open the Serial Monitor
3. See the weird characters, hit enter multiple times to get the correct output.

### Actual Results


### Expected Results

Console to open correectly. I've successfully got the console by using the `telnet 127.0.0.1 1234` command.
","Looks like at least basic telnet session negotiation is required, more info:
https://support.biamp.com/Tesira/Control/Telnet_session_negotiation_in_Tesira
http://mud-dev.wikidot.com/telnet:negotiation",19606299
6,Support for On Semiconductor RSL10 boards,open,2020-03-15T17:07:16Z,2020-03-16T10:02:00Z,,NONE,"There is at the moment unfortunately no support for the RSL10 boards from ON Semiconductor.
The RSL10 chip has an ARM Cortex M3 processor on chip and a Bluetooth stack and is a very low power component.
There exists some dev boards like the RSL10-SENSE-DB-GEVK which has some additional sensors. On Semiconductor provides a CMSIS package.
",,19606299
7,Integrate with Renode Simulation Framework for load and debug,open,2020-03-04T13:02:56Z,2020-03-23T01:13:53Z,,NONE,"What kind of issue is this?

- [x] **Feature Request**.

What is Renode?

[Renode](https://renode.io/) is an open source software development framework with commercial support from Antmicro that lets you develop, debug and test multi-node device systems reliably, scalably and effectively. 

Renode is a fantastic tool to simulate applications on multiple boards. As an example, it supports boards from STMicro and some RISC-V boards like SiFive HiFive1, Kendryte K210 and many more. 

Full board list: https://renode.readthedocs.io/en/latest/introduction/supported-boards.html

This integration would be the best of both worlds where one can develop in PlatformIO and debug/simulate on Renode without requiring hardware. Renode is available for Windows, Mac and Linux just adjusting the execution path.

I've started testing the available options and identified Renode can be started as a Telnet server (over a choosen port) and issued commands to it.

As an example to run the HiFive 1 ZephyrOS Hello World project, I did (on MacOS):

1. Open Renode with Telnet option: `/Applications/Renode.app/Contents/MacOS/macos_run.command -P 1234`
2. Connected to the Renode Telnet server: `telnet 1234`
3. Loaded the HiFive1 board script: `include @scripts/single-node/sifive_fe310.resc`
4. Started Renode remote debugger port: `machine StartGdbServer 3333 True` 
5. Loaded my ""Hello World"" ELF binary built on PlatformIO: `sysbus LoadELF @/Users/cdepaula/Documents/PlatformIO/Projects/200303-171147-zephyr-hello-world/.pio/build/hifive1/firmware.elf`
6. Start simulation with: `start`

<img width=""1399"" alt=""image"" src=""https://user-images.githubusercontent.com/20382/75881513-f8c52480-5dfd-11ea-9d45-07e9c6f76ae7.png"">

To start over, issue the command `Clear` on Renode console.

Another option is loading Renode with command line execute parameters as:

```bash
/Applications/Renode.app/Contents/MacOS/macos_run.command \
    -e ""include @scripts/single-node/sifive_fe310.resc"" \
    -e ""machine StartGdbServer 3333 True"" \
    -e ""sysbus LoadELF @/Users/cdepaula/Documents/PlatformIO/Projects/200303-171147-zephyr-hello-world/.pio/build/hifive1/firmware.elf"" \
    -e ""start""
```

I successfully integrated the PlatformIO debugger to an existing instance of Renode by adding `debug_port = localhost:3333` to `platformio.ini` on my project. Added a test breakpoint and interacted with the debugging on the simulation:

1. Open Renode with Telnet option: `/Applications/Renode.app/Contents/MacOS/macos_run.command -P 1234`
2. Connected to the Renode Telnet server: `telnet 1234`
3. Loaded the HiFive1 board script: `include @scripts/single-node/sifive_fe310.resc`
4. Started Renode remote debugger port: `machine StartGdbServer 3333 True` 

From there, I clicked the debugger ""Play"" and PlatformIO built and loaded my application into Renode.

<img width=""1208"" alt=""image"" src=""https://user-images.githubusercontent.com/20382/75882018-0e871980-5dff-11ea-8cb7-f0465899113a.png"">

Continued the breakpoint:

<img width=""1314"" alt=""image"" src=""https://user-images.githubusercontent.com/20382/75882109-442c0280-5dff-11ea-9413-c29a227fe32f.png"">

I just was not able to ""Reset"" and start over via debugging or software without issuing the `Clear` command on Renode and loading everything from start (it's fast though).

I'm wiling to help writing this support if I can get some tips.","Hey Ivan, thanks for the release! The sifive-platform release required to support this right? Also the integration with Renode is only for Debug and not Upload?

To reduce the amount of logs, just pass `-e logLevel 3` for printing errors only. Check https://renode.readthedocs.io/en/latest/basic/logger.html.

To get the console, I've used:

```
monitor_port = socket://localhost:1234
monitor_speed = 115200
```

But faced the problem from https://github.com/platformio/platformio-core/issues/3421.

I've successfully added integration to the Kendryte K210 using FreeRTOS. One problem tho is that PIO tried to upload `firmware.bin` instead of `firmware.elf`. For this I needed to change the upload argument from `@$SOURCE` to `@$PROJECT_BUILD_DIR/$PIOENV/$PROGNAME"".elf""`. I also had to add `upload_port = /dev/ttyUSB0` otherwise PIO didn't upload to Renode even by overriding by using `upload_command`. 

The complete config became:

```ini
; PlatformIO Project Configuration File
;
;   Build options: build flags, source filter
;   Upload options: custom upload port, speed and extra flags
;   Library options: dependencies, extra library storages
;   Advanced options: extra scripting
;
; Please visit documentation for the other options and examples
; https://docs.platformio.org/page/projectconf.html

[env:sipeed-maix-go]
platform = kendryte210
board = sipeed-maix-go
framework = kendryte-freertos-sdk
## ----- Settings below are for Antmicro Renode integration ----- ##
# Monitor port for Renode integration
monitor_port = socket://localhost:1234
monitor_speed = 115200
# Upload settings for Renode integration
upload_port = /dev/ttyUSB0
upload_command = renode $UPLOAD_FLAGS
upload_flags =
    -e include @scripts/single-node/kendryte_k210.resc
    -e machine StartGdbServer 3333 True
    -e logLevel 3                       ; Loglevel = Errors
    -e emulation CreateServerSocketTerminal 1234 \""externalUART\""
    -e connector Connect uart externalUART
    ; -e sysbus LoadELF @$SOURCE        ; Does not work on K210-FreeRTOS
    -e sysbus LoadELF @$PROJECT_BUILD_DIR/$PIOENV/$PROGNAME"".elf""
    -e start
# Debug settings for Renode integration
debug_tool = custom
debug_port = localhost:3333
debug_server = renode
    --hide-log
    -e include @scripts/single-node/kendryte_k210.resc
    -e machine StartGdbServer 3333 True
    -e logLevel 3           ;Loglevel = Errors
    -e emulation CreateServerSocketTerminal 1234 ""externalUART""
    -e connector Connect uart externalUART
debug_extra_cmds =
    monitor start
```",19606299
8,PIO Home server security model,open,2020-03-01T15:15:15Z,2020-03-13T10:59:16Z,,NONE,"- [x] **PlatformIO Core**

### Configuration

**Operating system**: any

**PlatformIO Version**: any

### Description of problem

Initially described in: https://community.platformio.org/t/pio-home-security-issue/12196

When `platformio home` is run by a user, PIO has unlimited access to the user's home directory.

PIO home on `http://127.0.0.1:8008` exposes the home contents:
- to any other local user
- to any (potentially malicious) website that can connect to localhost (e.g. using javascript and websockets)
- to any (potentially malicious) PIO library

#### Suggested mitigations

On Linux the process can be sandboxed by either:
- Ship a firejail profile and start platformio under firejail
- Run platformio as a system process using systemd sandboxing capabilities
- Implement native sandboxing

The sandboxing is meant to limit which paths the process (and its children) can read and write from.

EDIT: I'm happy to contribute the systemd sandboxing if needed.",What is a multiplatform solution for this issue? Could you provide a PR? Thanks in advance!,19606299
9,Package Manager CLI,open,2020-02-07T17:04:15Z,2020-02-07T17:04:16Z,,MEMBER,"Implement commands for universal package registry:
- `pio package search`
- `pio package install`
- `pio package uninstall`
- `pio package update`
- `pio package list`
",,19606299
10,Build error when parameter is overridden in mbed_app.json (for mbed libraries into project/lib),open,2020-02-05T02:53:24Z,2020-02-10T06:52:24Z,,NONE,"### Configuration

**Operating system**: Ubuntu 16.04.6 LTS

**PlatformIO Version** (`platformio --version`): version 4.1.1b9

### Description of problem

Currently it is possible to build mbed libraries in project/lib directory as PlatformIO can parse mbed_lib.json for each library and add macroses into mbed_config.h. The issue appears when you try to override parameters of those libraries through mbed_app.json. Build fails with error ""mbed build API internal error. Attempt to override undefined parameter"". It looks like currently it is only possible to override parameters of libraries which come with mbed by default.

#### Steps to Reproduce

1. clone https://github.com/edgrin/pio-mbed-lib-target-overrides/tree/a8b580c5deb6e36e74de38f5755cdb611166445f
2. try to build
3. see error Attempt to override undefined parameter 'newlib.param' in 'application[*]'
4. delete line 4 with '""newlib.param"": 2' in mbed_app.json
5. try to build
6. see successful build with newlib in Dependency Graph

### Actual Results

mbed build API internal error

### Expected Results

Successful build","Now script uses board id instead of environment id to separate different overrides. Also the script is simplified and instead of replacing defines with new values, it is just add the content of all found header files to the end of mbed_config.h. All inserted defines come with their #undef first. Maybe this temporary solution would be useful for someone else who also come across this issue.",19606299
11,Extend package manifest validation for platform and framework IDs,open,2020-01-29T12:24:45Z,2020-01-29T12:24:46Z,,MEMBER,https://github.com/platformio/platformio-core/blob/develop/platformio/package/manifest/schema.py#L152,,19606299
12,Use local packages instead of copying,open,2020-01-20T13:51:46Z,2020-02-04T17:34:54Z,,MEMBER,"Use local packages instead of copying for:
- lib_deps
- platform_packages


Install packages only in a case when `pio *** install` command is called",,19606299
13,Platform Monitor: dictionary changed size during iteration,open,2020-01-16T14:46:15Z,2020-03-17T12:10:11Z,,NONE,"BUG:

Platform IO Remote: OSX 10.15.2

When trying to connect to a remote target after upload the following error occurs:

Starting Serial Monitor on mini.local:/dev/cu.usbmodemFA1301
b'dictionary changed size during iteration'

Terminal will be reused by tasks, press any key to close it.

Closing and and trying again will then work.



","Hi @valeros 

ATSAMD21 - Arduino Core

Python 3.8.0


",19606299
14,MBed tests do not print to serial,open,2020-01-15T14:39:46Z,2020-02-06T18:41:11Z,,NONE,"What kind of issue is this?

- [X] **PlatformIO Core**.
      If you’ve found a bug, please provide an information below.

------------------------------------------------------------------

### Configuration

**Operating system**:

PlatformIO, version 4.1.0

### Description of problem

Tests does not output to serial port as expected on mbed os.

#### Steps to Reproduce

Create a embedded test with mbed os using the UNITY framework provided by platformio

### Actual Results

The test compile and runs on the board but does not output anything on serial port

### Expected Results

The test compile and runs on the board and output the results on the serial port

### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini
[env:disco_f407vg]
framework = mbed
platform = ststm32
board = disco_f407vg
build_flags = -DPIO_FRAMEWORK_MBED_RTOS_PRESENT -std=gnu++11
build_unflags = -std=gnu++98
test_transport = custom
```

**Source file to reproduce issue:**
```cpp
#ifdef PIO_FRAMEWORK_MBED_RTOS_PRESENT
#include ""mbed.h""
#endif

#include ""unity.h""

void test_function_calculator_addition(void) {
  TEST_ASSERT_EQUAL(32, 32);
}

void test_function_calculator_subtraction(void) {
  TEST_ASSERT_EQUAL(20, 20);
}

void test_function_calculator_multiplication(void) {
  TEST_ASSERT_EQUAL(50, 50);
}

void test_function_calculator_division(void) {
  TEST_ASSERT_EQUAL(32, 32);
}

int main(int argc, char **argv) {
  #ifdef PIO_FRAMEWORK_MBED_RTOS_PRESENT
  wait(5);     // for ARM mbed framework
  #endif
  UNITY_BEGIN();
  RUN_TEST(test_function_calculator_addition);
  RUN_TEST(test_function_calculator_subtraction);
  RUN_TEST(test_function_calculator_multiplication);
  RUN_TEST(test_function_calculator_division);
  UNITY_END();
}
```

### Additional info

I was able to fix this issue by creating a .mbedignore on the mbed folder for the unity framework (features/framework/unity). 

When I include the unity.h file, the one that is included is from the mbed framework when I do not ignore it, so the modifications done by platformio to the macros variables that allow me to print to the serial port are not used.","@ivankravets Do you have some idea on how you want to proceed to solve this issue? I mean, remove the unity from the mbed framework, or just remove when it is compiling the tests? - Do you think to add an option on the `.json` file?",19606299
15,Windows: package install sometimes fails on shutil.move of temporary directory,open,2020-01-04T22:24:56Z,2020-02-03T17:54:19Z,,CONTRIBUTOR,"### Configuration

**Operating system**:
Windows 10 1909

**PlatformIO Version** (`platformio --version`):
PlatformIO, version 4.1.0 (?) / need confirmation

### Description of problem

Original issue (latest comment with traceback): https://github.com/xoseperez/espurna/issues/2006#issuecomment-570808154

```
CONFIGURATION: https://docs.platformio.org/page/boards/espressif8266/esp01_1m.html
PLATFORM: Espressif 8266 1.5.0 > Espressif Generic ESP8266 ESP-01 1M
HARDWARE: ESP8266 80MHz, 80KB RAM, 1MB Flash
PACKAGES: toolchain-xtensa 1.40802.0 (4.8.2), framework-arduinoespressif8266 1.20300.1 (2.3.0), tool-esptool 1.409.0 (4.9)
Converting espurna.ino
LDF: Library Dependency Finder -> http://bit.ly/configure-pio-ldf
LDF Modes: Finder ~ chain, Compatibility ~ soft
Unicode decode error has occurred, please remove invalid (non-ASCII or non-UTF8) characters from C:\Users\internet\.platformio\packages\framework-arduinoespressif8266@1.20300.1\libraries\ESP8266HTTPUpdateServer\library.properties file
Unicode decode error has occurred, please remove invalid (non-ASCII or non-UTF8) characters from C:\Users\internet\.platformio\packages\framework-arduinoespressif8266@1.20300.1\libraries\ESP8266HTTPUpdateServer\library.properties file
Looking for Embedis library in registry
Found: https://platformio.org/lib/show/408/Embedis
LibraryManager: Installing id=408
Using cache: C:\Users\internet\.platformio\.cache\cc\338ee11d777d75e24f4008826cd592cc
Embedis @ 1.2.0 has been successfully installed!
LibraryManager: Installing espsoftwareserial
git version 2.24.0.windows.2
Cloning into 'D:\mcdev\vscode\espurna\code\.pio\libdeps\generic-esp01s-relay-40-inv\_tmp_installing-16pyir93-package'...
Note: switching to '5378868de76e1a38d34e0fc888d26e3612a5497d'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

PermissionError: [WinError 5] Zugriff verweigert: 'D:\\mcdev\\vscode\\espurna\\code\\.pio\\libdeps\\generic-esp01s-relay-40-inv\\_tmp_installing-16pyir93-package\\.git\\objects\\21\\452c9bf32fc95f03c8adb16ad3382d92f0994e':
  File ""C:\users\internet\.platformio\penv\lib\site-packages\platformio\builder\main.py"", line 151:
    env.SConscript(""$BUILD_SCRIPT"")
  File ""C:\Users\internet\.platformio\packages\tool-scons\script\..\engine\SCons\Script\SConscript.py"", line 605:
    return _SConscript(self.fs, *files, **subst_kw)
  File ""C:\Users\internet\.platformio\packages\tool-scons\script\..\engine\SCons\Script\SConscript.py"", line 286:
    exec(compile(scriptdata, scriptname, 'exec'), call_stack[-1].globals)
  File ""C:\users\internet\.platformio\platforms\espressif8266@1.5.0\builder\main.py"", line 375:
    target_elf = env.BuildProgram()
  File ""C:\Users\internet\.platformio\packages\tool-scons\script\..\engine\SCons\Environment.py"", line 224:
    return self.method(*nargs, **kwargs)
  File ""C:\users\internet\.platformio\penv\lib\site-packages\platformio\builder\tools\platformio.py"", line 140:
    _build_project_deps(env)
  File ""C:\users\internet\.platformio\penv\lib\site-packages\platformio\builder\tools\platformio.py"", line 48:
    project_lib_builder = env.ConfigureProjectLibBuilder()
  File ""C:\Users\internet\.platformio\packages\tool-scons\script\..\engine\SCons\Environment.py"", line 224:
    return self.method(*nargs, **kwargs)
  File ""C:\users\internet\.platformio\penv\lib\site-packages\platformio\builder\tools\piolib.py"", line 1027:
    project.install_dependencies()
  File ""C:\users\internet\.platformio\penv\lib\site-packages\platformio\builder\tools\piolib.py"", line 859:
    lm.install(uri)
  File ""c:\users\internet\.platformio\penv\lib\site-packages\platformio\managers\lib.py"", line 295:
    pkg_dir = BasePkgManager.install(
  File ""c:\users\internet\.platformio\penv\lib\site-packages\platformio\managers\package.py"", line 696:
    pkg_dir = self._install_from_url(name, url, requirements, track=True)
  File ""c:\users\internet\.platformio\penv\lib\site-packages\platformio\managers\package.py"", line 497:
    return self._install_from_tmp_dir(_tmp_dir, requirements)
  File ""c:\users\internet\.platformio\penv\lib\site-packages\platformio\managers\package.py"", line 583:
    shutil.move(tmp_dir, pkg_dir)
  File ""C:\Program Files (x86)\Python38-32\lib\shutil.py"", line 793:
    rmtree(src)
  File ""C:\Program Files (x86)\Python38-32\lib\shutil.py"", line 731:
    return _rmtree_unsafe(path, onerror)
  File ""C:\Program Files (x86)\Python38-32\lib\shutil.py"", line 604:
    _rmtree_unsafe(fullname, onerror)
  File ""C:\Program Files (x86)\Python38-32\lib\shutil.py"", line 604:
    _rmtree_unsafe(fullname, onerror)
  File ""C:\Program Files (x86)\Python38-32\lib\shutil.py"", line 604:
    _rmtree_unsafe(fullname, onerror)
  File ""C:\Program Files (x86)\Python38-32\lib\shutil.py"", line 609:
    onerror(os.unlink, fullname, sys.exc_info())
  File ""C:\Program Files (x86)\Python38-32\lib\shutil.py"", line 607:
    os.unlink(fullname)
====================================================================================================== [FAILED] Took 5.44 seconds ======================================================================================================

```

If platformio.ini has `lib_deps = ...` with git urls, package installation will fail on `shutil.move` after it copies temporary directory into a package dir and tries to remove that temporary directory.

#### Steps to Reproduce

1. Add some git libraries into the `lib_deps = ...`. ESPurna repo is a general example that has a couple of those.
2. Try to build any environment or `pio lib install` (see the referenced issue)
3. It fails right after the first git library installation. Although, package will be there on the next `pio run` call, because data was already copied before the previous directory caused an error and was not removed.

I cannot reproduce, so cc @davebuk @oscarsan1 @knopserl 

### Actual Results

See above.

### Expected Results

shutil.move fails to rename directories for some reason, I would expect that step to succeed:
https://github.com/python/cpython/blob/fa919fdf2583bdfead1df00e842f24f30b2a34bf/Lib/shutil.py#L780

The specific issue is the `rmtree` inability to remove git object files. This was previously fixed for some parts of the platformio code by adding a custom `fs.rmtree` function that `chmod`'s them via onerror hook, but the original Python function is used by the move (and it cannot be overriden)

### If problems with PlatformIO Build System:

See ESPurna's
https://github.com/xoseperez/espurna/blob/dev/code/platformio.ini

### Additional info
\-","@ivankravets I did not give up and did further testing.
Here are my latest findings: 
When I do a Build task without any environment/device selection it takes the wemos-d1mini-relayshield and that build works. But that default devices seem to do no cloning,
When I use any other devices/env. it fails with the access denied error.

Now I tried your previous recommendation and changed to espurna/code directory and executed:
platformio.exe run --environment blitzwolf-bwshpx
Surprisingly, that worked now too.
So it seem to be a VScode + platformio problem.
Any further ideas how to get that further investigated and solved?
I opened also a new issue/bug in the vscode github project. Let's see if they react and accept this as in vscode issue.",19606299
16,Support for SiLabs stk3701 (efm32gg11),open,2019-12-28T01:27:28Z,2020-01-03T20:01:36Z,,NONE,"Would it be possible to add support for the newer giant gecko chips? I have an Efm32gg11 starter kit, part number slstk3701A, and wish to develop for the EFM32GG11B820F2048GQ64-B chip. It seems to be a newer chip revision than what you currently support.

It's for a student project, and I'm finding simplicity studio to be a bit more resource intensive than platformio.

Thanks for all your work :-)

Scott",,19606299
17,pio remote run -t nobuild -t upload not working,open,2019-12-12T21:52:33Z,2020-02-17T08:17:23Z,,NONE,"# -t nobuild not working on a remote run but works fine on a local run

**Operating system**:  Tested on Windows 10, Ubuntu and Gitpod cloud

**PlatformIO Version** (`platformio --version`):

PlatformIO, version 4.1.0

### Description of problem

""pio remote run -t nobuild -t upload""  not working but 
""pio  run -t nobuild -t upload""   works fine





Community post related to the issue at 

[https://community.platformio.org/t/upload-latest-build-without-a-compile-link/9520/9](https://community.platformio.org/t/upload-latest-build-without-a-compile-link/9520/9)

------------------------------------------------------------------

### Configuration

Normal UNO Arduino setup
Serial proof of upload







#### Steps to Reproduce

1. So running VS-Code local on a windows machine with

pio account login
pio remote agent start


2. Then on a ubuntu laptop running VS-Code upload the original sketch

pio account login
pio remote run -t upload


3. Now change your code to ""version 2!"" and save the file. Then try to upload the old compiled verison 1.

pio remote run -t nobuild -t upload



### Actual Results


Version 2!

### Expected Results

Version 1!

### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini

[env:uno]
platform = atmelavr
board = uno
framework = arduino

```

**Source file to reproduce issue:**
```cpp

#include <Arduino.h>

void setup() {
	Serial.begin(9600);
}

void loop() {
	Serial.println(""Version 1! "");
	delay(1000);
}

```

### Additional info

Being able to use ""-t nobuild"" can be very useful when you just want to install a pre-tested working program for that board. I can give my students the pre-tested program and not worry if they have made any environment changes that effect the build.

I found this bug when testing with a cloud method using gitpod.io but the bug seems to happen even when using VS Code on 2 local machines.


Gitpod Cloud docker  github of it [my-gitpod-of-openthread](https://github.com/hpssjellis/my-gitpod-of-openthread) 
[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io#snapshot/fb33bf28-258e-4106-aee1-849e6e0a0934)



","Thanks @ivankravets I tried pio remote run -t nobuild -r? on the cloud server and got this result.
*** [nobuild] Source `.pio/build/nano_33_iot/firmware.bin' not found, needed by target `nobuild'.

The file firmware.bin is definitely in the folder location.
",19606299
18,Support for Logic Green LGT8F328P based boards,open,2019-11-29T09:47:11Z,2020-01-13T05:20:02Z,,NONE,"Hey, I recently came across [these](https://www.aliexpress.com/item/33058909260.html) cool Nano clones that run at 32Mhz and support the arduino core and libraries. They also have a few extra features like 12bit ADC and a DAC. You can program them using the arduino IDE using [this](https://github.com/dbuezas/lgt8fx) super cool resource. 

Since, I moving most of my development to PlatformIO it would be great to know how it can be added. 

",+1,19606299
19,Support for the Tomu board,open,2019-11-27T10:25:37Z,2019-11-28T14:36:32Z,,NONE,"It would be great to see support for the open-hardware [Tomu board](https://tomu.im/tomu.html) which is based on the EFM32. I'm just getting started with PlatformIO, so I don't know how hard that would be or if it is even possible.",,19606299
20,"PIO Remote builds tests and then executes them all, resulting in only the last-built test executing",open,2019-11-12T16:39:12Z,2020-02-14T12:49:53Z,,NONE,"What kind of issue is this?

- [x] **PlatformIO Core**.

### Configuration

**Operating system**: MacOS X

**PlatformIO Version** (`platformio --version`): 4.1.0

### Description of problem
When testing on remote platforms with Teensy, if there are many tests specified for a single environment, the remote agent builds all the tests and then runs them. Unfortunately this only results in a 

See post here: https://community.platformio.org/t/pio-remote-testing-bug/10496

#### Steps to Reproduce

1. Write some unit tests for the Teensy environment and have an environment run all of them
2. Run them on a remote agent: `platformio remote --agent <name> test -e <env>`

### Actual Results
The code for the tests is built in series, but only the test built last is actually uploaded to the device for testing. See
https://travis-ci.org/pathfinder-for-autonomous-navigation/CommonSoftware/jobs/610692665?utm_medium=notification&utm_source=github_status

### Expected Results
The tests are executed one-by-one.

### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini
[env:teensy]
platform = teensy
board = teensy35
framework = arduino
test_build_project_src = true
src_filter = +<*>
test_filter = *
upload_protocol = teensy-cli
```

### Workaround
Use the `--force-remote` option in the remote test command.",,19606299
21,Request for support to pass extra arguments to the target ,open,2019-10-16T19:09:12Z,2019-10-17T10:26:31Z,,NONE,"**Feature Request**.

I would like to be able to pass extra arguments to a binary e.g. when running on a native platform.

Possible usage, when running [Catch2](https://github.com/catchorg/Catch2) tests:

```
platformio test -e native --extra-args=""[testA][testB]""
```
",,19606299
22,Add support for i.MX RT Series MCUs.,open,2019-10-14T08:01:27Z,2019-10-24T16:07:55Z,,NONE,"Hi:
   I have try to support i.MX RT Series MCUs borad on PlatformIO, And Now The Seeeduino Arch MIX(RT1052) was been support, which using the Arduino framework. And  ubsequent support for more boards, and will support the development of native SDK.
  Below is the address of the project.
  - [platform-nxpimxrt](https://github.com/Seeed-Studio/platform-nxpimxrt)
  - [flash tools](https://github.com/Seeed-Studio/BOSSA)

  Arduino project address

 - [Arduino Core](https://github.com/Seeed-Studio/ArduinoCore-imxrt)

I hope to get your support, thank you.","@ivankravets  Wow, this is a great project. I just need it. Can you integrate this platform into the PlatforIO ?",19606299
23,Replace LDF deep with native GCC Preprocessor,open,2019-10-13T10:19:10Z,2019-10-13T10:19:10Z,,MEMBER,Subj.,,19606299
24,Support for Heltec CubeCell series,open,2019-10-02T13:58:05Z,2020-03-07T20:06:42Z,,NONE,"I'm requesting [this board](https://heltec.org/project/htcc-ab01/) to be added into PlatformIO.

This board is relatively new and the MCU is low power. It's based on an ASR6501 and unfortunately this platform doesn't exist yet.

Heltec has already made this board [Arduino compatible](https://github.com/HelTecAutomation/ASR650x-Arduino) 
","@Heltec-Aaron-Lee glad to see you here! Quick guide:

1) Create a new repository `https://github.com/HelTecAutomation/platform-asrmicro` in your organization and invite me (thanks!)
2) See examples of open source dev-platforms => https://github.com/topics/platformio-platform
3) Clone `https://github.com/HelTecAutomation/platform-asrmicro` to `~/.platformio/platforms/asrmicro`. You can work on integration here and commit changes to the repository.

This repository is a good starting point https://github.com/platformio/platform-atmelmegaavr
You just need to correct packages in `platform.json` to use ARM toolchain. Check other dev-platforms where we use this toolchain. For example, https://github.com/platformio/platform-atmelsam

Thanks!",19606299
25,Old dependencies are not removed from .pio folder,open,2019-10-01T12:32:07Z,2019-10-24T16:32:25Z,,NONE,"### Configuration

**Operating system**:
macOS 10.14

**PlatformIO Version** (`platformio --version`):
4.0.3

### Description of problem
Old dependencies that are no longer referenced from `platformio.ini` are not removed from `.pio` folder and are still included in the build.

As a consequence, invalid projects still build as long as they are not shared with other developers via a repository. Furthermore, header files from old dependencies can be included if they have the same name as other files in the project causing hard to find bugs.

#### Steps to Reproduce

1.  Build project - succeeds
2.  Remove `lib_deps` line from `platformio.ini`
3.  Build project again - succeeds even though it should fail

### Actual Results

Project without `lib_deps` still builds even if dependency is removed

### Expected Results

Project without `lib_deps` should fail to build since it's missing a dependency

### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini
[env:uno]
platform = atmelavr
board = uno
framework = arduino

lib_deps = 4
```

**Source file to reproduce issue:**
```cpp
#include <Arduino.h>
#include <IRremote.h>

IRrecv ir(10);
decode_results results;

void setup() {
    Serial.begin(115200);
    ir.enableIRIn();
}

void loop() {
    if (ir.decode(&results)) {
        Serial.println(results.value);
    }
    delay(100);
}
```

### Additional info

The folder `/Users/me/.platformio/lib` is empty.

If the folder `.pio` within the project folder is deleted, the project (without *lib_deps*) no longer compiles as expected.

Also see: https://community.platformio.org/t/what-is-the-proper-way-to-remove-dependency/9580

",,19606299
26,Create qtcreator-generic IDE template,open,2019-09-30T00:13:36Z,2020-02-20T04:25:15Z,,NONE,"Add qtcreator-generic IDE template.  Fixes #3046 

Since Qt Creator can default to running `make` for generic targets, this template also adds a `Makefile` that will allow Qt Creator to automatically build the project without having to manually modify the project settings to launch `platformio`.

This `qtcreator-generic` IDE template diverges from the `qtcreator` template in that it doesn't require a Qt Kit to be setup that contains `qmake`.  It also outputs compiler flags so that detail from custom scripts that alter the compiler flags can be captured by the code model in Qt Creator.  It does, however, lose the `HOMEDIR` isolation of include paths that the `qtcreator` template provides -- this is because I see no good way to do it with the generic project mechanism since it's not parsed by `qmake`.

Run with: `platformio init --ide qtcreator-generic`
","@valeros -- OK, after much experimenting, I think I finally know what's going on.  The `.cflags` and `.cxxflags` are both getting sent to the Clang Code Model.  However, those flags are gcc flags and not clang flags.  As such, it isn't understanding all of them and it ends up mostly disabling the code model.

However, I did find a scenario that seems to work, at least on my projects here with the STM32F103 core libraries.  And that was by doing the following:

1. Make sure you are on the latest Qt Creator (currently 4.11.1)
2. Set up a Bare Metal Kit in Creator manually selecting the `GCC-arm-none-eabi-platformio` with no Qt version and pointing it at the `~/.platformio/packages/toolchain-gccarmnoneeabi` compiler.
3. Create the generic creator project with the IDE template from this pull request.
4. Run `platformio run -t compiledb` to create a `compile_commands.json` file and add it to the list in the `.files` file from this template.  Note, I had to update to PlatformIO 4.2.2a1 via `pio upgrade --dev` as the release 4.2.0 kept exiting with errors when building the `compile_commands.json` target, but 4.2.2a1 built it successfully.
5. Enable the `CompilationDatabaseProjectManager` plugin in Creator and restart Creator to activate it.  Note that that plugin is still somewhat experimental in Creator.
6. Import both the `compile_commands.json` and the `.creator` generic project file from this template.  Go into the `Projects` settings and manually select the Bare Metal Kit that was created as the build target and enter `make all` and `make clean` for the custom build and clean commands, respectively, if it didn't find them on its own (for me, for some reason it found the `make all` step but not the `make clean`).

After doing this, the project is now correctly running the clang code model and completions on all of the code files from the project, and it has all of the library and core include paths and such too, and seems to have the compiler flags figured out.

Getting the kit and compiler setup was key as the clang code model tools call it with the options to dump all of the compiler defines, and without the correct compiler, it was calling the system gcc compiler instead which exited with errors from the arm options, causing it to fail and not run the code model.  But once it started calling the correct compiler, it seems to have things figured out.

So... from what I'm seeing from this experiment, this IDE template needs to somehow call the PlatformIO code to generate the Compilation Database along with the rest of the project and add it to the files list for Qt Creator to use.  But, I'm not totally sure how to automate that step in the PlatformIO IDE generation template.
",19606299
27,Qt Creator integration enhancement request,open,2019-09-25T02:52:17Z,2020-02-07T09:29:24Z,,NONE,"What kind of issue is this?

- [x] **Feature Request**.
      Start by telling us what problem you’re trying to solve. Often a solution
      already exists! Don’t send pull requests to implement new features without first getting our
      support. Sometimes we leave features out on purpose to keep the project small.

- [x] **PlatformIO Core**.
      If you’ve found a bug, please provide an information below.

------------------------------------------------------------------

### Configuration

**Operating system**: All

**PlatformIO Version** (`platformio --version`): 4.0.3

### Additional info

The current integration with Qt Creator works quite well with its ability to output `.pro` files.  However, I would like to see it output it as [Qt Creator generic project](https://doc.qt.io/qtcreator/creator-project-generic.html) files instead, with files like `.config`, `.creator`, `.files`, `.include`, etc.  This will allow it to be used with kit configurations that don't include Qt itself, as `.pro` files are more specific to projects using Qt and requires `qmake` and a full Qt installation.  Plus, `qmake` is a dying application which they are gradually replacing with `cmake`.

All of the content of the `.pro` file that PlatformIO creates fits nicely in these generic project files, which Qt Creator will load together as a project.  Just put the predefined macros (or defines) in the `.config` file.  Put the list of project source files in the `.files` file.  And list the include paths in the `.include` file.  And create a `.creator` file with a single `[General]` line.  And if there are build flags, `.cflags` and `.cxxflags` files can be used.

I think this would be a relatively easy change to PlatformIO, but would be a nice improvement in its export to Qt Creator and will allow people to use it with just Qt Creator installed without installing all of Qt too.


","PR created...

Since Qt Creator can default to running `make` for generic targets, this new template also adds a `Makefile` that will allow Qt Creator to automatically build the project without having to manually modify the project settings to launch `platformio`.

This `qtcreator-generic` IDE template diverges from the `qtcreator` template in that it doesn't require a Qt Kit to be setup that contains `qmake`.  It also outputs compiler flags so that detail from custom scripts that alter the compiler flags can be captured by the code model in Qt Creator.  It does, however, lose the `HOMEDIR` isolation of include paths that the `qtcreator` template provides -- this is because I see no good way to do it with the generic project mechanism since it's not parsed by `qmake`.

Run with: `platformio init --ide qtcreator-generic`
",19606299
28,First build often fails after changing platformio.ini,open,2019-09-05T10:50:28Z,2019-11-01T11:23:44Z,,NONE,"### Configuration

**Operating system**: Windows 10

**PlatformIO Version** (`platformio --version`): 4.0.3

**Platform**: Arduino (ESP8266 to be exact)

**Editor/IDE**: VS-Code

### Description of problem

When changing the platformio.ini file, and save it, a test is run to create a <project>.ino.cpp file.
At the end of this test, the file is deleted.
If you start a build while this test has not yet finished, then the .ino.cpp file is gone by the time the compile run is ready for processing this file.

This is what happens if you don't save the file yet but just hit the 'build' task to run.
It will save all open (unsaved) files and start building.
This save triggers the test run also.

#### Steps to Reproduce

1. Make changes in platformio.ini  Don't save yet
2. Start compile
3. Compile fails, since `setup()` nor `loop()` is found
",I reproduced this issue last time. It's only related when Arduino INO file is used. There is a race condition when PlatformIO Build System and Project Index Builder convert INO to CPP. We will work on good fix for this case. ,19606299
29,Use of #ifdef not processed consistently,open,2019-09-02T11:06:31Z,2019-09-05T11:20:14Z,,NONE,"# Solutions

# 1. [Convert INO files to CPP](http://docs.platformio.org/en/latest/faq.html#convert-arduino-file-to-c-manually)

# 2. Manual prototype declaration

```c++
#ifdef DO_NOT_USE
typedef int32_t delaytype;
void thisShouldNotAppearInTheBinary(delaytype timer); // aded manually
void thisShouldNotAppearInTheBinary(delaytype timer) {
  delay(timer);
}
#endif
```


--------


**PlatformIO Core**.
As discussed here: https://github.com/esp8266/Arduino/issues/6475

### Configuration

**Operating system**:
Windows & Linux

**PlatformIO Version** (`platformio --version`):
PlatformIO, version 4.0.3


### Description of problem

When generating forward declarations of functions in the <project>.ino.cpp, the wrapping #ifdef statements are not taken into account.

#### Steps to Reproduce

Simple steps to reproduce: https://github.com/esp8266/Arduino/issues/6475#issuecomment-527077618

Not really a very simple project at hand here, but I guess this should be enough to have in the project.ino file.

Just use the https://github.com/esp8266/Arduino/blob/74819a763bfb6e9890a57411dcea4aba221a778d/libraries/esp8266/examples/Blink/Blink.ino

and add some function like this in the .ino file:

```c++
#ifdef DO_NOT_USE
void thisShouldNotAppearInTheBinary() {
  delay(1000);
}
#endif
```

As long as you don't have the `DO_NOT_USE` flag set, you should not see it in the generated .ino.cpp file. (it should be wrapped in the #ifdef statements)
Well at least, that's what I expect should happen.

Things will fail to build if you have some object used as parameter which is only defined when a flag is set. For example:

```c++
#ifdef DO_NOT_USE
typedef int32_t delaytype;
void thisShouldNotAppearInTheBinary(delaytype timer) {
  delay(timer);
}
#endif
```
","As a work-around I now do all the forward declarations of the function with the templated class as argument, in the ino file instead of the macro.

It does look like this (in the .ino file)

```c++
bool do_process_c018_delay_queue(int controller_number, const C018_queue_element& element, ControllerSettingsStruct& ControllerSettings);

bool do_process_c018_delay_queue(int controller_number, const C018_queue_element& element, ControllerSettingsStruct& ControllerSettings) {
  bool  success = C018_data.txHexBytes(element.packed, ControllerSettings.Port);
  return success;
}
```

This allows me to have these templated objects all in the #ifdef wrappers.


",19606299
30,"Implement `--no-save` option for ""lib install/uninstall"" commands",open,2019-08-30T08:30:51Z,2019-10-24T16:29:15Z,,MEMBER,"Currently, user should pass `--save` option to save porject dependencies in `platformio.ini`. Default behavior should by `--save` and provide new option `--no-save`.",,19606299
31,Support for RISC-V VegaBoard,open,2019-03-01T11:06:33Z,2019-08-27T11:16:57Z,,MEMBER,- https://open-isa.org/,,19606299
32,Add support for rust,open,2019-08-26T03:17:17Z,2019-08-27T11:05:51Z,,NONE,"Add support for rust and cortex-m-rtfm
https://github.com/japaric/cortex-m-rtfm",,19606299
33,Provide JSON output for PIO Unit Testing,open,2019-07-29T17:38:19Z,2020-03-26T10:27:33Z,,NONE,"I was able to create a set of Unit Tests with PlatformIO and run them as native within a docker container. I also managed to run those tests as port of my build pipeline on Azure DevOps. All looks pretty good. 

### Thank you so much for building this amazing tool!!! ###

Only thing which nags me is that failing unit tests make my build fail with no additional information available before I dig into the log files.
It would be amazing, if I could extract the build results into a test result file in a JUnit format or something alike which I then could use to provide my build system with additional information. 
I'm wondering if something like this is build in right now or if I have to build something on my own.","@jpsfs This is my YAML file for the build. I use a docker container where the build runs in.
Let me know if you have any questions. 

<pre><code># Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

resources:
  containers:
  - container: platformio
    image: infinitecoding/platformio-for-ci:latest   
    options: -u root    

trigger:
- master

jobs:
- job: esp32_platformio
  displayName: ""PlatformIO build""
  container: platformio

  pool:
    vmImage: 'ubuntu-latest'

  steps: 
    - script: dir -a
      displayName: ""Show current directory content""
    - script: cd battleship-embedded/BattleShip
      displayName: ""Open Battleship project directory""
    - script: platformio test -e native -d battleship-embedded/BattleShip >> testresults.txt
      displayName: ""Run Unit Tests""
      continueOnError: true
    - script: python $(Build.SourcesDirectory)/battleship-embedded/BattleShip/_deploy/TestResultsParser.py testresults.txt testresults.xml
      displayName: ""Converting Test Results""
    - task: PublishTestResults@2
      inputs:
        testResultsFormat: 'NUnit'
        testResultsFiles: 'testresults.xml'
        failTaskOnFailedTests: true
    - script: platformio run -e esp32 -d battleship-embedded/BattleShip
      displayName: ""Build for ESP32 platform""
    - task: CopyFiles@2
      inputs:
        SourceFolder: $(Build.SourcesDirectory)/battleship-embedded/BattleShip/.pio/build/esp32/
        Contents: '*.bin'
        TargetFolder: $(Build.ArtifactStagingDirectory)
      displayName: ""Copy build output files to ArtifactsStagingDirectory""
    - task: CopyFiles@2
      inputs:
        SourceFolder: $(Build.SourcesDirectory)/battleship-embedded/BattleShip/_deploy
        Contents: '*.ps1'
        TargetFolder: $(Build.ArtifactStagingDirectory)
      displayName: ""Copy deployment scripts to ArtifactsStagingDirectory""
    - task: PublishBuildArtifacts@1
      inputs:
        ArtifactName: 'Firmware_$(Build.BuildNumber)'
        PathtoPublish: $(Build.ArtifactStagingDirectory)
        publishLocation: Container
        TargetPath: .</code></pre>",19606299
34,ARM mbed: Compilation of project with long file paths not possible,open,2019-08-06T21:13:59Z,2020-02-25T15:05:38Z,,NONE,"What kind of issue is this?

- [X] **PlatformIO Core**.
      If you’ve found a bug, please provide an information below.

------------------------------------------------------------------

### Configuration

**Operating system**: Windows 10 x64

**PlatformIO Version** (`platformio --version`): 4.0.1b3

### Description of problem

When compiling the sample project given below, compilation  fails as soon as the first source file of an external library or the main project is compiled. The occurring error is 

```
arm-none-eabi-g++: error: CreateProcess: No such file or directory
```

Which might hint at file path length problems (see https://github.com/MarlinFirmware/Marlin/issues/7967).

#### Steps to Reproduce

1. Import the sample project given below
2. Before compiling, execute `git config --system core.longpaths true`, otherwise th git clone will fail due to overlong filepaths
3. Compile on Windows 10
4. Observer error message

### Actual Results

```
Processing nucleo_l152re (platform: ststm32; board: nucleo_l152re; framework: mbed)
CONFIGURATION: https://docs.platformio.org/page/boards/ststm32/nucleo_l152re.html
PLATFORM: ST STM32 5.5.0 > ST Nucleo L152RE
HARDWARE: STM32L152RET6 32MHz, 80KB RAM, 512KB Flash
DEBUG: Current (stlink) On-board (stlink) External (blackmagic, jlink)
PACKAGES: toolchain-gccarmnoneeabi 1.70201.0 (7.2.1), framework-mbed 5.51204.190701 (5.12.4)
Collecting mbed sources...
LDF: Library Dependency Finder -> http://bit.ly/configure-pio-ldf
LDF Modes: Finder ~ chain, Compatibility ~ soft
Found 1 compatible libraries
Scanning dependencies...
Dependency Graph
|-- <ArduinoCore-nRF528x-mbedos> #a4b622b [git+https://github.com/arduino/ArduinoCore-nRF528x-mbedos.git] (C:\Users\Maxi\Documents\stackoverflow_testing\.pio\libdeps\nucleo_l152re\ArduinoCore-nRF528x-mbedos)

arm-none-eabi-g++ -o .pio\build\nucleo_l152re\src\main_esp.o -c -std=gnu++98 -fno-rtti [...] @""C:\Users\Maxi\Documents\stackoverflow_testing\.pio\build\nucleo_l152re\longcmd-7828fe635133cd1a11dd36e80ff553da"" src\main_esp.cpp

arm-none-eabi-g++: error: CreateProcess: No such file or directory
```

### Expected Results

Compilation success.

### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini
[env:nucleo_l152re]
platform = ststm32
board = nucleo_l152re
framework = mbed
build_flags = -D PIO_FRAMEWORK_MBED_RTOS_PRESENT
lib_deps = https://github.com/arduino/ArduinoCore-nRF528x-mbedos.git
```

**Source file to reproduce issue:**
```cpp
// Arduino code
#include ""Arduino.h""

void setup() {
    pinMode(LED_BUILTIN, OUTPUT);
    Serial.begin(115200);
    Serial.println(""Welcome to Arduino on Mbed OS"");
}

void loop() {
    digitalWrite(LED_BUILTIN, HIGH);
    Serial.println(""LED is now on!"");
    delay(1000);
    digitalWrite(LED_BUILTIN, LOW);
    Serial.println(""LED is now off!"");
    delay(1000);
}

// Mbed OS code
int main() {
    setup();
    while (1) loop();
}
```

","@valeros Another example of this problem has popped up in https://community.platformio.org/t/avr-g-error-createprocess-no-such-file-or-directory/12046/13?u=maxgerhardt, where compilation of a PlatformIO provided example project fails (https://github.com/platformio/platform-nordicnrf52/tree/master/examples/mbed-ble-thermometer). 

I am able to reproduce that error 

```
arm-none-eabi-g++: error: CreateProcess: No such file or directory
work-mbed@5.51401.200110\components\802.15.4_RF\stm-s2lp-rf-driver\source\NanostackRfPhys2lp.cpp
arm-none-eabi-g++ -o .pio\build\delta_dfbm_nq620\FrameworkMbed\components\802.15.4_RF\stm-s2lp-rf-driver\source\at24mac_s2lp.o -c -std=gnu++14 -fno-rtti -Wvla -c -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -fmessage-length=0 -fno-exceptions -ffunction-sections -fdata-sections -funsigned-char -MMD -fno-delete-null-pointer-checks -fomit-frame-pointer -Os -g -DMBED_TRAP_ERRORS_ENABLED=1 -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=softfp -DMBED_ROM_START=0x0 -DMBED_ROM_SIZE=0x80000 -DMBED_RAM_START=0x20000000 -DMBED_RAM_SIZE=0x10000 -include mbed_config.h -DPLATFORMIO=40202 -DARDUINO_GENERIC -DPIO_FRAMEWORK_MBED_RTOS_PRESENT -DARM_MATH_CM4 -DBOARD_PCA10040 -DCMSIS_VECTAB_VIRTUAL -DCMSIS_VECTAB_VIRTUAL_HEADER_FILE=\""cmsis_nvic.h\"" -DCOMPONENT_NSPE=1 -DCOMPONENT_PSA_SRV_EMUL=1 -DCOMPONENT_PSA_SRV_IMPL=1 -DCONFIG_GPIO_AS_PINRESET -DDEVICE_ANALOGIN=1 -DDEVICE_FLASH=1 -DDEVICE_I2C=1 -DDEVICE_I2C_ASYNCH=1 -DDEVICE_INTERRUPTIN=1 -DDEVICE_LPTICKER=1 -DDEVICE_PORTIN=1 -DDEVICE_PORTINOUT=1 -DDEVICE_PORTOUT=1 -DDEVICE_PWMOUT=1 -DDEVICE_SERIAL=1 -DDEVICE_SERIAL_ASYNCH=1 -DDEVICE_SERIAL_FC=1 -DDEVICE_SLEEP=1 -DDEVICE_SPI=1 -DDEVICE_SPI_ASYNCH=1 -DDEVICE_SYSTICK_CLK_OFF_DURING_SLEEP=1 -DDEVICE_TRNG=1 -DDEVICE_USTICKER=1 -DFEATURE_BLE=1 -DMBED_MPU_CUSTOM -DMBED_TICKLESS -DNRF52 -DNRF52_PAN_12 -DNRF52_PAN_15 -DNRF52_PAN_20 -DNRF52_PAN_30 -DNRF52_PAN_31 -DNRF52_PAN_36 -DNRF52_PAN_51 -DNRF52_PAN_53 -DNRF52_PAN_54 -DNRF52_PAN_55 -DNRF52_PAN_58 -DNRF52_PAN_62 -DNRF52_PAN_63 -DNRF52_PAN_64 -DSWI_DISABLE0 -DTARGET_CORDIO -DTARGET_CORDIO_LL -DTARGET_CORTEX -DTARGET_CORTEX_M -DTARGET_DELTA_DFBM_NQ620 -DTARGET_FF_ARDUINO -DTARGET_LIKE_CORTEX_M4 -DTARGET_LIKE_MBED -DTARGET_M4 -DTARGET_MCU_NRF52832 -DTARGET_NAME=DELTA_DFBM_NQ620 -DTARGET_NORDIC -DTARGET_NORDIC_CORDIO -DTARGET_NRF52 -DTARGET_NRF52832 -DTARGET_NRF5x -DTARGET_RELEASE -DTARGET_RTOS_M4_M7 -DTARGET_SDK_15_0 -DTARGET_SOFTDEVICE_NONE -DTOOLCHAIN_GCC -DTOOLCHAIN_GCC_ARM -D__CMSIS_RTOS -D__CORTEX_M4 -D__FPU_PRESENT=1 -D__MBED_CMSIS_RTOS_CM -D__MBED__=1 @""C:\Users\Maxi\mbed-ble-thermometer\.pio\build\delta_dfbm_nq620\longcmd-4973fc6c3c0d3f729a439ffc951d0e04"" C:\Users\Maxi\.platformio\packages\frameworarm-none-eabi-g++: error: CreateProcess: No such file or directory
```

And again the long command has 32720 bytes 

``` 
ls -l ""C:\Users\Maxi\mbed-ble-thermometer\.pio\build\delta_dfbm_nq620\longcmd-4973fc6c3c0d3f729a439ffc951d0e04""
-rw-rw-rw-  1 Maxi 0 32720 2020-02-25 15:54 C:\Users\Maxi\mbed-ble-thermometer\.pio\build\delta_dfbm_nq620\longcmd-4973fc6c3c0d3f729a439ffc951d0e04
```

However the longcommand is also full of include directories for components not used in the project or thohse who would not appear during a real mbed-os build. It seems the generating code just recursively adds all folder paths to the list, while only excluding some? This code would need a rework if not even PIO's example projects can be compiled..",19606299
35,Use XDG_CONFIG_HOME for .platformio directory,open,2019-08-05T16:02:16Z,2019-10-23T14:23:04Z,,CONTRIBUTOR,"### Configuration

**Operating system**: macOS 10.14

**PlatformIO Version** (`platformio --version`): 4.0.1b3

### Description of problem
The `~/.platformio` directory contains important config data including the user's custom boards. It's currently one of many hidden directories in my home folder. For most Unix-based systems these directories conventionally go in `$XDG_CONFIG_HOME`, which is usually `~/.local/share`. This makes things neater for the user.

On Windows and macOS the variables `XDG_CONFIG_HOME` usually aren't defined, so you can use `C:\Users\x\AppData\Roaming` and `~/.local/share` respectively (i.e., `~/.local/share` does exist on macOS but isn't usually defined as `XDG_CONFIG_HOME`).

#### Steps to Reproduce

1. Run `pio init`
2. Observe new `.platformio` directory in `$HOME`
3.
","I think that allowing the user to override PIO's defaults is besides the point; that's a whole lot of directories which a user is forced to remap. The goal of the [XDG Base Directory Specification](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html) is to free the user from the burden of having to manually manage each piece of software as a unique snowflake directory tree dumped somewhere random in their $HOME directory.

For example, what subdirectories of `~/.platformio` are configuration which needs to be backed up and can be synced between development machines? What directories possibly contain credentials which should never be backed up? Which are runtime data which is necessary to have on hand? Which are cache directories and can safely be discarded if disk space is low? The XDG spec is a way to avoid the user having to figure out the answers to those questions for each piece of software we install. If PIO respected the preferences I've already expressed (and shouldn't have to say differently for every program I install), I'd know that `~/.config/platformio/*` is configuration that I should back up, `~/.cache/platformio` is safe to delete and can be recreated as needed, etc.

Please reconsider opening this issue. Complying with the XDG spec brings a lot of benefits and loses nothing. It's trivial to remain backwards compatible to support existing installations.",19606299
36,Sparkfun Edge Cortex M4 MCU Board Support,open,2019-06-26T05:46:38Z,2019-12-17T15:57:09Z,,NONE,"Requesting the inclusion of support for the Sparkfun Edge board with Cortex M4 MCU.

This board is quite new and the MCU is particularly low power making it ideal for ML applications.

[https://www.sparkfun.com/products/15170](url)

Is there a bounty system for new boards?  Are there open source instructions for creating new board definitions?
 ","We have a helpful individual who has created a PR to try to support PlatformIO in the Apollo3 Arduino core. 
[Issue](https://github.com/sparkfun/Arduino_Apollo3/issues/97)
[Pull Request](https://github.com/sparkfun/Arduino_Apollo3/pull/101)

Since I am unfamiliar with PlatformIO it would take me a while to test out the PR. If anyone who is more familiar could give it a whirl and comment on the PR that would help greatly.",19606299
37,Improve handling library.json dependencies,open,2019-05-28T10:34:49Z,2019-08-30T19:15:46Z,,MEMBER,Currently PlatformIO installs library.json dependencies only if a library was installed via `$ pio lib` CLI or specifically declared via `lib_deps`. It fails with `Error: Could not find `xxx` dependency for `yyy` library.,If I remove the `@version` from the `lib_deps` then it uses the local version. There should probably be a warning about specifying a version when there's a local directory present too.,19606299
38,Support for NuTiny-SDK-NUC505 Boards,open,2019-05-05T03:15:42Z,2019-05-06T15:40:22Z,,NONE,"http://www.nuvoton.com.cn/hq/products/microcontrollers/arm-cortex-m4-mcus/nuc505-series/?__locale=en
http://www.nuvoton.com/resource-files/UM_NuTiny-SDK-NUC505_EN_Rev1.03.pdf",,19606299
39,Board manifest to v2.0,open,2019-04-25T15:53:56Z,2019-06-19T14:33:06Z,,MEMBER,"New board manifest should support 2 types of boards:

1. **Kit** - Classic board, development kit
2. **Device** - generic board based on specific device/mcu. Can be used for custom boards

**Device** should be named as MCU/DEVICE name in upper case.

JSON fields

# version

Should be `2`.

# name

Human readable name

# device

`Type: Object`, fields

- mcu
- cpu
- flash
- ram
- eeprom
- frequency 

# configuration

See Atom configuration

# build

`Type: Object`

# debug

`Type: Object`

# upload

`Type: Object`

# url

`Type: String`

# vendor

`Type: String`",,19606299
40,Import project from Keil µVision IDE,open,2019-04-22T09:32:48Z,2020-03-16T20:57:15Z,,MEMBER,"See https://community.platformio.org/t/port-keil-project-to-platformio/7409

Implement `platformio project import` command.

For example,
```
platformio project import [KEIL_PROJECT_DIR] -d,--destination-dir [WRITABLE_DIR] -t,--type [keil|...]
```",Has anyone found a workaround for this? ,19606299
41,Support for Ai-Thinker A9G Boards,open,2019-04-14T08:26:36Z,2020-02-20T19:31:47Z,,NONE,https://ai-thinker-open.github.io/GPRS_C_SDK_DOC/en/hardware/a9g.html,+1,19606299
42,New project using MCU device,open,2019-03-17T12:05:39Z,2019-03-23T16:03:44Z,,NONE, Please support standalone stm32 mcu selection like keil instead of board selection,,19606299
43,Integration of Pio remote in a Python project,open,2019-03-15T17:20:20Z,2019-08-29T11:41:19Z,,NONE,"- [x] **Feature Request**.
 We hope to integrate Pio Remote in our Python library, is there a way to do that. If we just integrate the PIO's path in the code on a local machine, it won't work in other computers because PIO.exe does dependent on the Python enviorment in the local machine. The best way is to have a API in Python side, does Platformio have a plan of that ?",,19606299
44,Add Catch2 as a unit testing framework,open,2019-03-04T18:51:02Z,2019-07-02T08:20:32Z,,NONE,- https://github.com/catchorg/Catch2,,19606299
45,Pass build flags to the specific scope,open,2019-02-18T22:25:01Z,2019-09-04T13:59:52Z,,MEMBER,"Allow passing build flags to the specific scope. See https://docs.platformio.org/en/latest/projectconf/section_env_build.html#build-flags

Example,

```ini
[env:myenv]
board = ...
build_flags =
    ; Only for C files
    CFLAGS: -Wno-old-style-declaration
    ; Only for CPP files
    CXXFLAGS: -fexceptions
    LINKFLAGS: -u __cxa_guard_dummy -u ld_include_panic_highint_hdl 
```",,19606299
46,К1986ВЕ92VE9x (Milandr) support and settings,open,2019-01-27T09:43:37Z,2019-02-02T19:58:59Z,,NONE,Subj.,"Извините, пожалуйста, Иван, действительно, что такое K1986?
 
как я понимаю, это лицензированная серия клонов ARM Cortex (М0, M3,M4).Доступное здесь - https://www.milandr.ru/products/
либо здесь - https://ic.milandr.ru/products/mikrokontrollery_i_protsessory/32_razryadnye_mikrokontrollery/

Платы отладочные  у них дороги пока, поэтому может лучше просто сориентироваться на некоем generic  k1896. то есть как  у китайцев, покупаем контроллер, припаиваем к универсальной плате  для любых LQFP и начинаем прошивать через UART.  JTAG тоже представлен. Документация  у них, надеюсь, серьёзная и позволит создать конфигурацию для Миландровских контроллеров.

С большой надеждой к вам.",19606299
47,Cypress - FreeSoC / PSoC support,open,2019-01-18T19:19:45Z,2019-01-23T17:21:40Z,,NONE,Subj.,,19606299
48,Set global flags using internal library extra script,open,2018-11-27T12:15:05Z,2020-03-21T09:59:28Z,,MEMBER,"# Temporary solution

A temporary solution is to set build flags per project using https://docs.platformio.org/en/latest/projectconf/section_env_build.html#build-flags

------

- https://community.platformio.org/t/library-json-global-build-flag/3814/4

",,19606299
49,Create JSON schema for library.json,open,2018-10-30T15:16:42Z,2019-04-18T13:26:45Z,,NONE,It would be nice to have a JSON schema to validate library.json files against.,,19606299
50,"update/upgrade breaks things after download stalls, package uninstalled before successful download",open,2018-10-28T03:52:24Z,2019-09-04T13:59:16Z,,NONE,"### Configuration

**Operating system**:
Windows 7

**PlatformIO Version** (`platformio --version`):

3.6.0

### Description of problem

I am using pio command line. Every time the connection stalled during a upgrade/update, ^C wouldn't stop pio, only pskill will do.
Afterwards, you will find some package is missing, and has to be installed again, before pio can be usable again.

#### Steps to Reproduce

1. pio upgrade/update
2. somehow make the connection stall
3. stop the python process since there is no other way around.

### Actual Results

random package got missing, has to be reinstalled ** most of the time, before pio become usable again **
sometimes, pio-home is removed, sometimes other big tool-chain package is gone. 

### Expected Results

pio should be in a usable state even if some package failed to download during update.

most package managers uninstall package  after new versions are downloaded completely. Not sure why pio choose to do it differently.

### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini
Insert here...
```

**Source file to reproduce issue:**
```cpp
Insert here...
```

### Additional info
",,19606299
51,"Declare a custom `pio run -t mytarget` in ""platformio.ini""",open,2018-10-23T16:26:29Z,2020-03-21T10:12:18Z,,MEMBER,"# Temporary solution

A temporary solution is to create custom target usinng extra scripting. See example:
- https://docs.platformio.org/en/latest/projectconf/advanced_scripting.html#custom-target

-------

Would be good to be able to declare a custom target with own command in `platformio.ini`.

- http://docs.platformio.org/en/latest/projectconf/advanced_scripting.html#custom-target


```ini

[env:myenv]
board = ...
targets = buildprog, node
targets_extra = 
  target_name@dependent_target $ shell command
  erase $ st-flash erase
```


```python
def Phony(env = main, deps = [], **kw):
    if not env: env = DefaultEnvironment()
    for target, action in kw.items():
        env.AlwaysBuild(env.Alias(target, deps, action))

Phony(
    cleanall = ""rm -rf build"",
)
```


Related https://github.com/platformio/platformio-core/issues/1122",,19606299
52,Feature Suggestion - Self-hosting the PIO account server,open,2018-10-20T19:38:54Z,2019-08-29T11:42:01Z,,NONE,"I think an open-source project should have most integral parts open-sourced, and that includes account servers too. By having an option to run a self-hosted instance of the client would help both from a privacy and an FOSS standpoint, and that means more users.",,19606299
53,Silicon Labs EFM8 Support,open,2018-09-26T16:32:22Z,2018-11-21T03:14:25Z,,NONE,"- [X ] **Feature Request**.

Hi,
I see there is EFM32 support, so are there any plans to support the 8-bit range of Silabs devices?
The tools supplied by Silabs are ok (Simplicity Studio), but we would like to work in VSCode which is a more familiar environment where we can be more productive and have a workflow common to other device platforms.
Thanks,
Si.      
","there is generic 8051 support now via platform `intel_mcs51`, however no explicit support for efm8, although this can be added by anyone who wants to take this on.
I believe it would be functionally equivalent to supporting c8051 (earlier 8051 silabs series, i think they are probably same/similar cores), as requested in https://github.com/platformio/platform-intel_mcs51/issues/7

adding the basic cpu support would be easy - the challenge may lie in adding product-line specific library/sdk for efm8 and/or c8051, as well as supporting native upload (i.e. via some c2 programmer option)",19606299
54,Library dependency by owner,open,2018-08-31T12:26:31Z,2019-08-29T09:39:39Z,,MEMBER,"Implement an option to declare library dependencies by a specific owner using the next format:
```
@owner/LIBRARY NAME@^1.2.3
```

For example, `platformio.ini`

```
[env:myenv]
board = ...
lib_deps = 
  @owner/lib
```

CLI
```
pio lib -g install ""@owner/lib""
```

P.S: Need to automatically generate library owner depending on Github user name","Sorry for the delay. We will back to this issue soon. We need new data in registry (""owner"" info)",19606299
55,Create a unified driver manager for PlatformIO ecosystem,open,2018-08-28T14:18:12Z,2018-08-31T12:29:22Z,,NONE,"### Problematic
As said here
![image](https://user-images.githubusercontent.com/15887222/44727260-e74cdf00-aad9-11e8-818d-5a2c2decaf63.png)
The heart of platformIO is to answer to this problematic. But it does not answer to the problematic of drivers and the problematic is the same: it complicates the setup and configuration, multiple hardware platforms (MCUs, boards) require different drivers, we don't know which to choose, which to install or not. As you can imagine, I've pulled my hair these last weeks trying to understand which driver to install or not (for 3 different boards), as many documentations or processes are unclear, outdated, bugged, or inconsistent:

Bugged:
https://github.com/ARMmbed/mbed-cli/issues/733 
Outdated tutorial (there is no more firmware STM32 F072BDiscovery_FW_VX.Y.Z in their website):
https://www.st.com/content/ccc/resource/technical/document/user_manual/group0/d0/f7/45/d7/3b/96/47/b3/DM00285842/files/DM00285842.pdf/jcr:content/translations/en.DM00285842.pdf 
Inconcistencies:
https://github.com/platformio/platformio-docs/issues/33
https://github.com/ARMmbed/mbed-os-example-blinky/issues/132
Unclear things:
https://github.com/platformio/platformio-docs/issues/35

### Suggested solution 
So to solve this problem I suggest to create an unified driver manager in PlatformIO ecosystem (inside or beside PlatformIO core). This unified driver manager will install automatically all necessary drivers for the cardboard and the choosen debugger, or (if it is not possible), download them and indicate and call the user to install theses downloaded drivers.

### Additional info
Once this feature is added, the following enhancement suggestion is no more necessary: https://github.com/platformio/platformio-docs/issues/35
At this feature is better than the documentation enhancement suggestion. ",,19606299
56,Include I/O voltage in board information,open,2018-08-11T01:32:46Z,2018-09-14T12:09:16Z,,NONE,"PlatformIO has a great database of development boards and it would be great to be able to use that database for selecting a board in the first place. I'm currently considering switching boards and am looking for certain characteristics in the new development board I go for but I came across two problems: 

1. The online selection tool (at platformio.com/boards) doesn't list the debug tool, just whether debug is supported or not, so I can't differentiate between those that have on-board debug and those that require me to purchase additional hardware.
2. The pio boards command (and online selector) doesn't show I/O voltage for the boards (presumably because that information isn't currently recorded by platformIO?). I would love for that to be available so that I can specifically select 5V as a requirement.","Thanks @ivankravets, that's great! I'm using it already.",19606299
57,dynamically add or replace dependencies by extrascript.py,open,2018-07-16T08:48:16Z,2019-06-01T14:34:35Z,,NONE,"When a library needs two incompatible libraries, there seems to be no way to dynamically create a dependency on one.

An example: a library that supports an I2C library, say either [I2C-Master-Library](https://github.com/DSSCircuits/I2C-Master-Library) or [TinyWireM](https://github.com/adafruit/TinyWireM). Both support `frameworks arduino` and `platforms 
atmelavr`, but `I2C-Master-Library` does not supports `attiny85`. If you list both libs in `library.json`, it causes compilation failure. The solution would be hide either one depending on `cppflags` in `extrascript.py`.

However, the documentation does not say that such trick is possible, probably because it is not.

The question is, is it possible? If not, it would be nice to have a future to add or replace dependencies in `library.json` by `extrascript.py`.

#### Steps to Reproduce

1. Create a library with the two dependencies in `library.json`
2. Build the library

### Actual Results

The build fails while compiling `I2C-Master-Library`.

### Expected Results

`platformio` provides means to add or replace dependency in `extrascript.py`.
",,19606299
58,ZephyrProject integration,open,2018-05-08T11:10:43Z,2020-03-10T10:39:17Z,,NONE,"Hi,

I have been playing with https://www.zephyrproject.org/ recently.
Seems like they are developing really fast.
A lot of SOC supported, especially bluetooth / bluetooth mesh is very promising.
It would be great addition to Platformio.
Please consider adding Zephyr support.

Thanks.
 ","Thanks @ivankravets for sharing the additional details, experience and perspective, really appreciated.

> Can someone explain to me, why do we need YET ANOTHER build system with YET ANOTHER syntax and interpreter?

Because they all suck. From https://mesonbuild.com/Design-rationale.html (and others)

> A software developer's most important tool is the editor. If you talk to coders about the editors they use, you are usually met with massive enthusiasm and praise. [...] The second most important tool, even more important than the compiler, is the build system. **Those are pretty much universally despised.**


But the main issue with build systems is actually... C.

Even though build systems are ""universally despised"", language designers eventually realized their importance and many recent languages provide a build system ""for free"". However it was too late for C. 

The ""translation unit"" is another, old age problem unique to C. It forces every build system that want to support C well to care about weird complexities like precompiled headers or LTO.

Last and main build issue with C: *fragmentation*. Nothing comes close. Partly because of its age again, mainly because it's low-level. Because it's low-level, C generally can't rely on a layer of indirection abstracting portability issues away like most other languages can. In fact C is typically central to that abstraction layer itself.


https://dwheeler.com/autotools/
> Note, however, that the autotools don't just build software, they detect various features to make it much easier to build software that ports to a wide variety of systems. **Sure, you should use standard interfaces, but sometimes there's no standard interface** or the interface has serious bugs/limitations. [...] Some of the autotools issues are fundamental to their goals. Their goal is to make it easy to build a system, using the native tools, and there are variations in the native tools. In the longer term, forcing native tools to get fixed (so that people don’t have to work around their bugs) and getting their functionality updated (so that people don’t have to work around their limitations) would help best in the long term.

From  https://mesonbuild.com/Design-rationale.html again:
> Must not add complexity due to obsolete platforms


 https://youtu.be/7THzO-D0ta4?t=1465  (slides unfortunately missing from https://github.com/CppCon/CppCon2017/tree/master/Presentations )
",19606299
59,the package manager does not respect OS release version,open,2018-03-28T08:10:49Z,2020-01-10T01:21:27Z,,NONE,"### Configuration

N/A

**Operating system**:

FreeBSD (also applies to OpenBSD).

**PlatformIO Version** (`platformio --version`):

```
PlatformIO, version 3.5.1
```

### Description of problem

platform.io does not respect ABIs of OS. FreeBSD keeps ABI compatibility in minor releases. a package for release `N.M` works on release `N.M+1`, but not necessarily for `N+1.0`. it might work sometimes, but not always. the package manager only respects OS name and `${ARCH}` (see https://github.com/platformio/platformio-core/blob/ec9a2b02eac01a41098b6de4cc01d1de17b26c59/platformio/util.py#L176). the `system` attribute in `package.json` should include major release version so that different release version installs packages built for the major release, something like `FreeBSD_11_amd64`.

#### Steps to Reproduce

1. install a platform.io package on a FreeBSD release, preferably CURRENT since most of, if not all, packages were built on a release.
2. see the release version the package was built for, such as `file ~/.platformio/packages/toolchain-xtensa/bin/xtensa-lx106-elf-gcc`. the file come with `toolchain-xtensa` version `1.40802.0`
3. it shows unmatched release version

### Actual Results

`uname -r` on my machine says `12.0-CURRENT`, but `file(1)` says the binary was built for FreeBSD 9.2:

```
ELF 64-bit LSB executable, x86-64, version 1 (FreeBSD), dynamically linked, interpreter /libexec/ld-elf.so.1, for FreeBSD 9.2 (902502), stripped
```

in this case, the binary _happened to run_ fine on my machine, probably on 10.x and 11.x. but when ABI changes, it will break.

this issue affects OpenBSD hard. in OpenBSD, ABI compatibility is not kept even in minor releases, and they are known to be aggressive to bump library versions in the base system. for OpenBSD, minor release version should be included.

### Expected Results

the version in the output should match the major release version of the OS.

an example of expected results:

```
ELF 64-bit LSB executable, x86-64, version 1 (FreeBSD), statically linked, for FreeBSD 12.0 (1200060), FreeBSD-style, stripped
```

### If problems with PlatformIO Build System:

N/A

### Additional info

the expected result above is one from [`toolchain-xtensa32`](https://github.com/trombik/toolchain-xtensa32) that I am currently building for FreeBSD, which is not available in the platform.io package repository. note that package for FreeBSD CURRENT may be missing in the official package repository for obvious reasons. the point is, packages are built for a particular release.","Bump
Also need toolchain-xtensa32 for esp32 on freebsd",19606299
60,New Board: Onion Omega2,open,2018-03-14T12:06:24Z,2019-07-11T15:12:53Z,,NONE,"https://onion.io/omega2/

",Looking forward for Onion Omega2S+ support :),19606299
61,Kdevelop integration Feature Request,open,2018-02-26T21:21:11Z,2018-03-15T21:16:15Z,,NONE,"**Operating system**:  debian sid - KDE

**PlatformIO Version** (`platformio --version`):  version 3.5.2rc1

### Description of problem
KDE is a premier desktop environment with integration between KDE applications and numerous features that aide in programming workflow. When using non KDE applications there is often a feeling quality that something's missing. Kate/Kdevelop are integral to that environment.  Kdevelop's simplicity makes it a powerful tool that doesn't get in the way of your process.

#### Steps to Reproduce

I can run platformio init from within the folder of my project. Then within Kdevelop I can configure a launch to execute ""platformio run -t upload"" and it works to compile and upload but there needs to be a cmake file in order to have my project display external library symbols.

I tried to use the one from using ""pio init --ide clion"" but it compiles with errors and it fails to create the symbols to use within the editor.

","I'm not sure what you need.  I'll help with anything I can understand (unfortunately that's not much, but I'll be happy to do anything you can describe step by step).  I'm attaching here a C++ hello world project made with KDevelop.  I hope that might help.
[helloworld.tar.gz](https://github.com/platformio/platformio-core/files/1817116/helloworld.tar.gz)
 ",19606299
62,Z-Uno (Z-Wave Arduino prototyping board),open,2018-02-01T03:05:39Z,2020-02-07T08:56:41Z,,NONE,"Z-Uno is a Arduino compatible board with built in Z-Wave support, details on the board itself are here:
https://z-uno.z-wave.me/technical/

They currently support the Arduino IDE:
https://z-uno.z-wave.me/install

","This has been open for two years, any updates? ",19606299
63,pio lib update does not follow semver complaint version constraints.,open,2018-01-06T20:46:59Z,2019-09-04T13:38:15Z,,NONE,"
As written in https://github.com/marvinroger/homie-esp8266/issues/470, `platformio lib update` updates locally installed libs even if the latest version does not match the semver compliant version match string.


E.g. if there is a dependency to lib@^1.0.0 a lib from the 1.0.x branch is installed initially, but later is updated to 1.1.x, when `pio lib update` is performed.

--> `pio lib update` shall follow the semver dependencies when looking for new libs.

BTW: I thnik this should not apply for global update (`pio lib -g update`) because pio can't know all locally installed projects and a project can install a older revision of a dependency locally.
",,19606299
64,Library Dependency Graph does not show full version information,open,2018-01-04T12:32:42Z,2019-06-01T14:33:18Z,,NONE,"The Library Dependency Graph does not show the installation method or beta-versions (or git revision) of used libraries.  Also, if different revisions of a library are installed (because it is a ""sub-dependency"" of different dependencies with differing version requirements) they may be shown as same revision.

So I propose some improvements Library Dependency Graph to help tracking down problems that may arise due to complex version dependencies:

* There should be a clear indication about the installed revision and the installation method (repository, git, etc..)
* There should also be a warning message if a dependency is installed in different versions.
* Furthermore, if exactly the same dependency is used several times, the sub-dependencies should not be shown again. (Maybe something like `| |-- ..repeated..` could be shown instead).

**Example 1:** (taken from https://travis-ci.org/euphi/Homie_BareMinimum/builds/324773837)
  - Dependency is https://github.com/marvinroger/homie-esp8266.git#v2.0.0-beta.3 only

  --> The graph should indicate that the library is directly installed from git and with **git-tag** v2.0.0-beta.3.

```
Library Dependency Graph ( http://bit.ly/configure-pio-ldf )
|-- <Homie> v2.0.0
|   |-- <ArduinoJson> v5.12.0
|   |-- <AsyncMqttClient> v0.8.1
|   |   |-- <ESPAsyncTCP> v1.0.1
|   |-- <Bounce2> v2.3
|   |-- <ESP Async WebServer> v1.1.1
|   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <Hash> v1.0
|   |   |-- <ArduinoJson> v5.12.0
|   |-- <DNSServer> v1.1.0
|   |   |-- <ESP8266WiFi> v1.0
|   |-- <Ticker> v1.0
|   |-- <ESPAsyncTCP> v1.0.1
|   |-- <ESP8266mDNS>
|   |   |-- <ESP8266WiFi> v1.0
|   |-- <ESP8266HTTPClient> v1.1
|   |   |-- <ESP8266WiFi> v1.0
|   |-- <ESP8266WiFi> v1.0
|-- <Hash> v1.0
```

**Example 2:** (taken from https://travis-ci.org/euphi/ESP-Touch/jobs/324666146, my by far most complex project)
  - Various dependencies (I know I can simplify the dependency tree by removing redundant dependencies form my own projects, but this shows the dependency tree as it has grown over time)

```
|-- <Homie> v2.0.0                            <------- https://github.com/marvinroger/homie-esp8266.git#v2.0.0-beta.3
|   |-- <ArduinoJson> v5.12.0
|   |-- <AsyncMqttClient> v0.8.1
|   |   |-- <ESPAsyncTCP> v1.0.1
|   |-- <Bounce2> v2.3
|   |-- <ESP Async WebServer> v1.1.1
|   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <Hash> v1.0
|   |   |-- <ArduinoJson> v5.12.0
|   |-- <DNSServer> v1.1.0
|   |   |-- <ESP8266WiFi> v1.0
|   |-- <ESPAsyncTCP> v1.0.1
|   |-- <ESP8266WiFi> v1.0
|   |-- <ESP8266mDNS>
|   |   |-- <ESP8266WiFi> v1.0
|   |-- <ESP8266HTTPClient> v1.1
|   |   |-- <ESP8266WiFi> v1.0
|   |-- <Ticker> v1.0
|-- <HomieNodeCollection> v0.8.1
|   |-- <Homie> v2.0.0                            <------- https://github.com/marvinroger/homie-esp8266.git#v2.0.0-beta.3
|   |   |-- <ArduinoJson> v5.12.0
|   |   |-- <AsyncMqttClient> v0.8.1
|   |   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |-- <Bounce2> v2.3
|   |   |-- <ESP Async WebServer> v1.1.1
|   |   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |   |-- <Hash> v1.0
|   |   |   |-- <ArduinoJson> v5.12.0
|   |   |-- <DNSServer> v1.1.0
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <ESP8266mDNS>
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <ESP8266HTTPClient> v1.1
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <Ticker> v1.0
|   |-- <ESP8266_SSD1306> v3.2.7
|   |   |-- <Wire> v1.0
|   |-- <Wire> v1.0
|   |-- <ESP8266WiFi> v1.0
|   |-- <HomieLoggerNode> v0.9.1
|   |   |-- <Homie> v2.0.0                            <------- https://github.com/marvinroger/homie-esp8266.git#develop
|   |   |   |-- <ArduinoJson> v5.12.0
|   |   |   |-- <AsyncMqttClient> v0.8.1
|   |   |   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |   |-- <Bounce2> v2.3
|   |   |   |-- <ESP Async WebServer> v1.1.1
|   |   |   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |   |   |-- <ESP8266WiFi> v1.0
|   |   |   |   |-- <Hash> v1.0
|   |   |   |   |-- <ArduinoJson> v5.12.0
|   |   |   |-- <DNSServer> v1.1.0
|   |   |   |   |-- <ESP8266WiFi> v1.0
|   |   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |   |-- <ESP8266mDNS>
|   |   |   |   |-- <ESP8266WiFi> v1.0
|   |   |   |-- <ESP8266HTTPClient> v1.1
|   |   |   |   |-- <ESP8266WiFi> v1.0
|   |   |   |-- <Ticker> v1.0
|   |   |-- <Hash> v1.0
|-- <HomieLoggerNode> v0.9.1
|   |-- <Homie> v2.0.0                            <------- repetition (#develop)
|   |   |-- <ArduinoJson> v5.12.0
|   |   |-- <AsyncMqttClient> v0.8.1
|   |   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |-- <Bounce2> v2.3
|   |   |-- <ESP Async WebServer> v1.1.1
|   |   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |   |-- <Hash> v1.0
|   |   |   |-- <ArduinoJson> v5.12.0
|   |   |-- <DNSServer> v1.1.0
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <ESPAsyncTCP> v1.0.1
|   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <ESP8266mDNS>
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <ESP8266HTTPClient> v1.1
|   |   |   |-- <ESP8266WiFi> v1.0
|   |   |-- <Ticker> v1.0
|   |-- <Hash> v1.0
|-- <Automaton> v1.0.2
|-- <Adafruit NeoMatrix> v1.1.2
|   |-- <Adafruit GFX Library> v1.2.2
|   |-- <Adafruit NeoPixel> v1.1.3
|-- <Adafruit GFX Library> v1.2.2
|-- <Adafruit NeoPixel> v1.1.3
|-- <MPR121> v1.0.0
|   |-- <Wire> v1.0
|-- <Hash> v1.0
|-- <ESP8266_SSD1306> v3.2.7
|   |-- <Wire> v1.0
|-- <Wire> v1.0
```
",">> Warning if a library is installed multiple times with different versions

>We can't do that because that is a gold feature of PIO Core where you can have multiple build environments where each of them depends on own library version. As result, different version could be installed in .piolibdeps folder. When LDF starts a work, it will pick up the best version following your requirements in lib_deps for the particular build environment ([env:..])

Ah ok. I didn't think about the build environments. However, it happens that libraries within the same build environment depens on different versions of another libraries. In this case, both versions are installed, but the build process uses only one (the newer one?). In my original post this happend to the Homie-dependency.

>>Warning (or Notice) if a library is required again within the same subtree

>You don't need to bother with that. Linker will optimize all libraries and object. It does not mean that dependent library will be included in final ELF multiple times. We just show the FULL DEPENDENCY GRAPH. There is no link between LDF GRAPH and GCC LINKER.

My idea behind this was to encourage developers to have clean dependencies, to avoid unnecessary complicated trees (that may break due to updates and then conflicting dependencies). Of course there is no need to fix the warning - or better just call it ""notice"".


>>Warning if version from manifest mismatches with the version from origin (e.g git tag)

>This is a very difficult task. VCS does not have ""version"" information. We have COMMIT, BRANCH, and TAG. Version - this is developer's ""thing"". If we start looking in VCS log, list all tags, parse them to version, we will significantly decrease performance.

You only need to do this for libraries that are directly installed from git (or other VCS). For libraries from repository there is no need to do this at runtime, but you could send a warning message to the developer when importing a new version to the repository server.

The idea behind this is again to help library developers to get their versions and dependencies clean.",19606299
65,"Implement ""platform autoremove"" command",open,2017-12-04T17:47:37Z,2019-09-04T13:58:16Z,,MEMBER,Don't remove non-required packages manually. Check them 1 time per 3 days and report user that he can clean unused packages via `pio platform autoremove`.,,19606299
66,Multiple Targets in ini file not executed,open,2017-10-19T21:25:07Z,2019-05-23T17:38:47Z,,NONE,"### Configuration
**Operating system**: Win10
**PlatformIO Version** (`platformio --version`):PlatformIO, version 3.5.0a16

### Description of problem
When I set multiple targets inside platformio.ini, only one is executed

#### Steps to Reproduce

1. set multiple targets
2. ```pio run``` without target parameter

### Actual Results

```

[10/19/17 23:15:45] Processing esp12e (platform: espressif8266; targets: clean, buildprog, buildfs; framework: arduino; board: esp12e)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Removed .pioenvs\esp12e\firmware.bin
[...]
Removed .pioenvs\esp12e\src\main.o
Done cleaning
===================================================================================== [SUCCESS] Took 1.19 seconds =====================================================================================

============================================================================================== [SUMMARY] ==============================================================================================
Environment esp01       [SKIP]
Environment esp01_1m    [SKIP]
Environment esp12e      [SUCCESS]
===================================================================================== [SUCCESS] Took 1.20 seconds =====================================================================================
```
### Expected Results
Alltargets should be executed

### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini
[env:esp12e]
targets = clean, buildprog, buildfs
platform = espressif8266
board = esp12e
framework = arduino
```

### Additional info
Strangely, if I remove ```clean```target only ```buildfs``` is run. ```buildprog``` is skipped.","After reading the code, part of the issue may reside inside [platform-espressif8266](https://github.com/platformio/platform-espressif8266/blob/02032565b05ad72a907c9425957f72c15c0b83d8/builder/main.py#L350-L364)
We cannot build the firmware and the spiffs image on the same build, they seem both exclusive.

And ```clean``` target just replace all targets : https://github.com/platformio/platformio-core/blob/22fb89e56ad4f35aa9af0226f0603f29dad93e4e/platformio/managers/platform.py#L355-L356",19606299
67,NavSpark board support,open,2017-09-09T22:18:56Z,2017-09-09T22:37:32Z,,NONE,"- X Feature Request. 
------------------------------------------------------------------
I've copied this from a forum message. I have same problem and have not found any issue for this platform.

### Configuration

**Operating system**: Linux KDE Neon

**PlatformIO Version** (`platformio --version`): 3.5.0a9

### Description of problem

I have the Navspark mini and would like to use it with Platformio. Navspark has it's own custom settings for the Arduino IDE, but not for Platformio and I cannot figure out how to make this list: http://navspark.mybigcommerce.com/content/package_navspark_index.json compatible with platformio. 

### Additional info
Arduino custom settings file: http://navspark.mybigcommerce.com/content/package_navspark_index.json
User Manual: http://navspark.mybigcommerce.com/content/NavSpark-User-Guide_rev0.9.pdf",,19606299
68,Mongoose OS support,open,2017-09-04T13:54:40Z,2018-12-12T06:02:07Z,,NONE,"Please add support for Mongoose OS as it is very quick to develop with Espressif 32 and others.

Thanks","not anymore it doesn't.
they have some experimental VSCode plugin.
And their awesome webui is now a meh ui since version 2.7.0. no more built-in ide.",19606299
69,Support for Mojo FPGA dev board,open,2017-07-30T18:27:21Z,2017-07-31T18:28:33Z,,NONE,"https://embeddedmicro.com/products/mojo-v3.html

https://embeddedmicro.com/tutorials/mojo/",,19606299
70,Add LinkIt RTOS,open,2017-07-03T19:51:10Z,2019-11-03T14:18:52Z,,NONE,"Please add the official HDK+SDK (http://labs.mediatek.com/en/platform/linkit-rtos), the LinkIt from Mediatek, to support.

Links:
http://labs.mediatek.com/en/platform/linkit-rtos
https://www.seeedstudio.com/LinkIt-7697-p-2818.html
https://docs.labs.mediatek.com/resource/mt7687-mt7697/en/get-started-linkit-7697-hdk/gcc-arm-embedded-linkit-7697
https://docs.labs.mediatek.com/resource/mt7687-mt7697/en/get-started
","I was looking for this integration too since the 7697D supports dual band Wifi. 
I guess after two years of no progress that's a no?",19606299
71,Better Visual Studio support,open,2017-06-25T22:43:05Z,2020-02-08T06:28:24Z,,NONE,"I would like to suggest two improvements to the Visual Studio support in PlatformIO.

---
1) Support **multiple** boards in Visual Studio.

It could be as simple as modifying the CLI like this:
""platformio init --ide visualstudio --board teensy31 --board esp32dev""

Each board would generate a new project. The project files should be named according to the board it supports, **not** just ""platformio.vcxproj / platformio.vcxproj.filters"".
(Note that the ProjectGuid **must be** unique per project. It currently is **not**.)

All projects should then be placed into a single solution. (Currently the solution file is not automatically generated. It should be.) The solution file can be named ""platformio.sln"" - that's fine.

---
2) Provide a way to **update** the project files without completely overwriting them.

Something like:
""platformio refresh --ide visualstudio --board teensy31 --board esp32dev""

When new libraries are installed, they must be added to the projects. This needs to be done without destroying the current project files. A developer may have made many changes unique to each project that need to be preserved. (Folders, files, settings, etc.)","Is this being actively worked on? If not, I'd be interested in working on this feature and submitting a pull request.",19606299
72,Add GDB debugger support for native platform,open,2017-06-09T21:38:20Z,2019-07-02T08:20:43Z,,NONE,Some of my projects include shared components targeting desktop machines as well as microcontrollers.  It would be extremely helpful to have the PIO debugger integrated with GDB to enable local native debugging.,,19606299
73,Support parsing Arduino additional board json files?,open,2017-05-28T23:47:38Z,2017-07-04T16:01:54Z,,NONE,"I recently purchased a [Arducam ESP8266 module](http://www.arducam.com/world-smallest-esp8266-wifi-camera/), and it only has support for the Arduino Text-editor+macro button build system ""IDE"".  It also appears to not exist in the platformio framework (not surprising, it's new and kind of esoteric.

Anyways, I was wondering if it would be possible for platformio to parse either the arduino compatible [""index.json""](http://www.arducam.com/downloads/ESP8266_UNO/package_ArduCAM_index.json), or the various metadata files in the underlying [github repository](https://github.com/ArduCAM/ArduCAM_ESP8266_UNO). It *seems* like it should be possible to infer the required configuration from these files to build a binary for the board, but that could be me being naive.","I'll second that request.
The arduino ide json file is located here:
[http://www.arducam.com/downloads/ESP8266_UNO/package_ArduCAM_index.json](url)

You can get working a nodemcu or the arducam uno board if you select the nodemcu in platform.io and put the arducam library into your lib folder. However, if you do it this way, there is data loss when taking pictures. 
The problem somehow has to do with the standard libraries for the esp8266, see this github link.
[https://github.com/ArduCAM/Arduino/issues/101](url)

If you follow the way described by arducam using the arduino ide the pictures are fine.
So I suppose the makers of arducam somehow modified the esp8266 libraries. But I don't see a possibility to include these modified files when working with platform.io, because always the standard libraries of the framework are compiled. This is way over my level of expertise. Therefore, it would be nice if arducam would be included as one board into platform.io or someone could explain how to force platform.io to take the libraries of the lib folder instead of the framework libraries.

Furthermore, I think it would be huge benefit if there would be some kind of tool to migrate boards by using the json file of the arduino ide and make the necessary migrations to include these boards thereby into platformio. Again way over my level of expertise.",19606299
74,Debugging with Unit Testing,open,2017-04-25T22:35:30Z,2020-02-14T12:24:14Z,,NONE,It is often handy to be able to set a breakpoint while debugging a unit test. This is useful when something is hard to track down - being able to see the whole stack/call chain is very helpful.,"Sorry for the delay on this issue. There are some difficulties to implement it. PlatformIO supports multi-level tests with own `main` functions. You can not debug all of them within the one debugging session. However, we have some interesting solution - adding new option named `debug_test = yes|no` (Bool). Default value is no.

So, you will be able to declare debug environment and configure which test to debug. For example:
```ini
[env:debug]
platform = x
framework = y
board = z
build_type = debug
debug_test = yes
test_filter = sometestname
```

Will it work?",19606299
75,Add support for CMock,open,2017-04-10T23:23:26Z,2019-09-14T17:13:06Z,,NONE,"Since pio test seems to be based on ThrowTheSwitch's [Unity](http://www.throwtheswitch.org/unity), it would be great also being able to use their [CMock](http://www.throwtheswitch.org/cmock) mocking framework, specially when compiling for `platform native` when a bunch of dependencies will fail to compile with native gcc.",This would be really good to have moving forward. It's difficult to have a reliable process when CI can't properly test FW code.,19606299
76,Support Chibitronics Love-to-Code,open,2017-04-01T04:03:04Z,2019-05-24T00:32:23Z,,NONE,"The Chibitronics Love-to-Code board is an ARM Cortex M0-based platform that supports programming via audio.  It has an operating system with about 150 syscalls, enabling small binaries that can be transmitted very quickly.

It also has partial Arduino support.

I have a local Platform available already, and would like to adapt it to meet the Platformio guidelines in order to upstream it.","The MCU is a KL02, which is an NXP Kinetis Cortex M0+",19606299
77,Implement manual package removal,open,2017-03-27T13:17:14Z,2019-09-04T13:46:50Z,,NONE,"I have uninstalled atmelsam platform. However, toolchain-gccarmnoneeabi failed to uninstall automatically. After installing atmelsam platform one more time (throwing errors in process), then uninstalling it again, the package toolchain-gccarmnoneeabi was uninstalled too.

However, it might be beneficial to implement manual package installation/removal. Please consider.",,19606299
78,Arduino Time library: can't build,open,2017-02-27T21:17:11Z,2019-11-22T10:01:39Z,,NONE,"### Configuration

**Operating system**:
Win7_64

**PlatformIO Version** (`platformio --version`):
PlatformIO, version 3.3.0a12

### Description of problem
Can't build a project using both Arduino-Time and  function included in #include <time.h>

see https://github.com/PaulStoffregen/Time/pull/67 as well...


#### Steps to Reproduce

add following lib to platformio.ini
lib_deps  =  
        https://github.com/PaulStoffregen/Time.git#v1.5
        ESPAsyncTCP=https://github.com/me-no-dev/ESPAsyncTCP.git
        ESPAsyncWebServer=https://github.com/me-no-dev/ESPAsyncWebServer.git

try to compile ESPAsyncWebServer example and add to its include #include <TimeLib.h>

### Actual Results
piolibdeps\ESPAsyncWebServer\src\WebHandlers.cpp: In member function 'AsyncStaticWebHandler& AsyncStaticWebHandler::setLastModified(time_t)':
.piolibdeps\ESPAsyncWebServer\src\WebHandlers.cpp:72:60: error: 'gmtime' was not declared in this scope
return setLastModified((struct tm *)gmtime(&last_modified));

### Expected Results
If you build under ArduinoIDE it build correctly


### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**
```ini
Insert here...
```

**Source file to reproduce issue:**
```cpp
Insert here...
```

### Additional info

when ArduinoIde builds library to include into the project (in this case Arduino-time) it produce time.c.o, while platformio produce time.o so it conflicts with gcc internals..

I tried to ask to library developers to rename its time.c and time.h into time_<somethingelse> but he refuse to do so :-( and suggests to ask you for support

Regards
",Hi @ldab ! The problem is related to the header file `Time.h` and since you're using case insensitive OS the only way is to rename this file.,19606299
79,Add support for TI RTOS,open,2017-01-25T16:54:00Z,2019-06-01T14:44:26Z,,NONE,"Add support for [TI RTOS](http://www.ti.com/tool/TI-RTOS).

Should be able to use toolchain-gccarmnoneeabi package.

Ti RTOS is available for a number of processors / boards e.g.

CC13xx
CC26xx
CC3200
MSP432

I'm happy to help on this.",,19606299
80,Support generation of code coverage data,open,2017-01-20T21:08:38Z,2019-10-15T07:11:09Z,,NONE,"Hi Ivan,

I searched for this kind of topic and didn't find anything but let me know if this is a duplicate.

I have my Transition library being tested on Travis using my ArduinoFrameworkFake library which has been working well since you gave me directions on how to import the library.

I'd now like to gather some information regarding coverage so that I can identify areas where I am not testing my code sufficiently. I tried using the build_flags section in platformio.ini to pass ```--coverage``` but was met with a lot of linker errors that I tried (unsuccessfully) to resolve.
Here's a few of the combinations of options I tried using
```-g -O0 --coverage -fPIC -shared -Wl,-fprofile-generate -Wl,-shared -Wl,-fPIC```
```-fprofile-arcs -ftest-coverage -fprofile-generate -Wl,-lgcov --coverage```

I am successfully generating coverage using: https://github.com/r89m/Transition/blob/master/.travis.yml#L56
which is giving me the output I'd like (https://coveralls.io/jobs/22116632) but I'd love to be able to do something along the lines of pio test --coverage or similar and generate the necessary gcno and gcda files.

Any help would be appreciated.

Richard",See https://github.com/pathfinder-for-autonomous-navigation/CommonSoftware/pull/15,19606299
81,Support for DA14580,open,2016-09-19T03:05:54Z,2016-10-26T16:00:34Z,,NONE,"Will boards based on Dialog Semiconductor DA14580 supported soon or is possible to install it manually?

Configuration

Operating system:

WIndows, Linux, OSX

Additional info

More information on Dialog Semiconductor Website: 
http://www.dialog-semiconductor.com/products/connectivity/bluetooth-low-energy/smartbond-da14580
","Could you help us with this issue? 
- http://docs.platformio.org/en/stable/platforms/creating_platform.html
",19606299
82,Add Realtek RTL8710 / RTL8711 / RTL8195,open,2016-09-06T02:38:32Z,2020-02-14T13:00:21Z,,NONE,"Contains ARM Cortex-M3 processor

- http://www.realtek.com/products/productsView.aspx?Langid=1&PNid=33&PFid=45&Level=4&Conn=3","Could someone help us with adding new dev-platform? There are a lot of examples how to do it https://github.com/platformio/platform-espressif32

Thanks in advance!",19606299
83,UltraEdit (UEStudio) as Platformio IDE,open,2016-09-05T11:46:41Z,2019-05-23T17:24:59Z,,NONE,"[x] Feature Request.
We are over 2 mililons of developers working with UltraEdit Professional Editor (www.ultraedit.com) or UEStudio. We are used to using this effective tool for years... It would be nice to implement Platformio IDE also into UltraEdit Editor for smooth adaptation of this ""big family of users"". Hereby Platformio can get greater glory than has today :-).
Many thanks for you excellent Platformio... the life is easier and joyful with this tool!!!
",,19606299
84,Micropython support,open,2016-07-25T22:34:42Z,2019-12-10T00:27:40Z,,NONE,"Add support for Micropython for compatible boards (e.g. esp8266 family)


- Digi Xbee3 Board Support https://github.com/platformio/platformio-core/issues/2863
","I have used some libraries, but few. And to make it more complex is that some libraries are port specific and some are not. I would say that external libraries (non-standard) are pretty use-case specific and most of the time I am writing my own or using the standard libraries. 

I do agree that having a unified library and dependency system would help. Micropython has been working on and improving their ""Machine"" library to abstract more interfaces to help with making code and libraries cross port. But overall this is pretty rare for me. Once I get the library into my source folder (I cannot or do not use upip on my projects) 

Micropython is close enough to python 3.5 some desktop libraries even work without editing. 

For micropython's list of libraries look here as well
https://github.com/micropython/micropython-lib
",19606299
85,Simblee board support,open,2016-07-07T14:24:49Z,2016-10-14T19:09:19Z,,NONE,"I can't seem to find a way to use platformIO alongside Simblee boards. 
Is it possible to add support for Simblee board (RFD77203 RFD77101), or someone could tell me how to configure platformIO to successfully boatload.

Cheers,
","@ivankravets, this is essentially the same RFDuino, but sw library a bit different:
`typedef RFDuino Simblee;`
AFAIK ;)
",19606299
86,Add support for all PIC microcontrollers,open,2016-06-22T18:12:37Z,2019-06-01T14:39:52Z,,NONE,"I want to be able to use platformio for
PIC 12 Family
PIC 16 Family
PIC 18 Family
PIC 24 Family

Also there is a alternative with pic for arduino named pinguino http://www.pinguino.cc
",+1 support for pic micros would be nice,19606299
87,Visual Studio error parsing support and IntelliSense (easy way),open,2016-05-18T16:09:41Z,2018-06-21T15:30:29Z,,NONE,"- [ ] Feature Request.

---
### Configuration

**Operating system**:
Windows 10

**PlatformIO Version** (`platformio --version`):
2.9.1
### Description of problem

Visual Studio displays the error in the build log, but doesn't parse them.
#### Steps to Reproduce
1. Build project in visual with build errors
2. Check Errors tab
### Actual Results

Errors only contains ""exited with code 1""
### Expected Results

Error has a list of all errors and warnings (clickable)
### If problems with PlatformIO Build System:

**The content of `platformio.ini`:**

``` ini
[env:lpc1768]
platform = nxplpc
framework = mbed
board = lpc1768
targets = upload
```

**Source file to reproduce issue:**

``` cpp
int main(){
    -notAReaLCFILEERROR!
}
```
### Additional info

The thing needed for this to work, is something like this: http://www.codeproject.com/Articles/370890/GCCFilter-A-script-for-compiling-with-GCC-in-Visua (But please don't use perl like that, powershell might do, or some python) I'm pretty good with python but no idea where this would need to be added.

Basically a wrapper so the output is transformed so people can click their errors.

From this:

```
src\main.cpp:13:8: error: errormessage
```

to this (replace {errorcode} with the erro code, or don't)

```
C:\path\to\folder\src\main.cpp(13,8): error {errorcode}: errormessage
```

Also add the folders with the framework to the include path of the project. This way the full IntelliSense works. (People can do this manually) This can be done by the init script. It knows the board, it can install the framework folders and add those to the project.
Mine look like this:

```
.\.pioenvs\lpc1768\FrameworkMbedInc-250686161\;.\.pioenvs\lpc1768\FrameworkMbedInc549023428\;.\.pioenvs\lpc1768\FrameworkMbedInc-550770547\;.\.pioenvs\lpc1768\FrameworkMbedInc1648309630\;$(IncludePath)
```
","It does allow you to add the IncludePath and Source Directories. (In the project file)

This gives an almost complete IntelliSense experience. I know it's easy mode, but it works. It's not about the errors, it's about code completion and function prototypes. (Like [this](http://i.imgur.com/0SkO0oS.png) And that does add a lot to the experience. It's auto complete and refactoring is one of the reasons I use the IDE. 

Other options include writing a plugin.
",19606299
88,"How can I list available libraries without being horribly, horribly annoying.",open,2016-02-11T23:16:03Z,2019-06-01T14:33:16Z,,NONE,"I'm looking for a particular library for arduino, so I'm trying to grep through the available libraries. 

However, for some insane reason, `platformio lib search -f arduino` seems dead-set on forcing an extremely annoying ""Show next libraries? [y/N]:"" prompt every 10 items. 

There are 235 arduino libraries.

If I set `platformio settings set enable_prompts no`, it _just_ returns the first 10 items, and then exits.
1. Why on earth are you doing your own pagination. `less` and `more` have existed for that _before I was even born_.
2. Why doesn't `platformio settings set enable_prompts no` cause it to emit all the available libraries. Having it default to exit after just the first 10 is basically useless.

Basically, the built-in pagination breaks any usage of `platformio lib search` in a pipelined context entirely.
","In my case, I remembered that there *was* an arduino library for what I was doing, but didn't remember the name, and the search didn't work for things like the chip name, etc... I wanted to be able to skim the available arduino libraries.


------

Mostly, it's not that there weren't workarounds, it was that I couldn't see any possible good reason for the way it *does* work. ",19606299
89,"Support for ""scripts"" in package manifest",open,2016-01-29T15:01:04Z,2019-09-04T13:41:20Z,,NONE,"It would be nice to have the toolchains have the option to be built locally.  This would make platformio more portable and sustainable in the future.
","Allow assigning different scripts per events from PlatformIO Package Manager via ""scripts"" property. Example, https://docs.npmjs.com/misc/scripts

Having ""postinstall"" action will allow calling a build script where we can build a toolchain/tools from the source code.",19606299
90,Platform IO Bundled Distribution for Windows,open,2016-01-09T17:03:59Z,2018-06-18T16:08:50Z,,NONE,"As some Windows user might not have any console tools installed I would like to see platformio distributed as some self-contained archive/exe file for Windows users. It should contain python distribution and some nice colorful command line + GUI (which is in the works). This should be done side-by-side to existing pip installation or even on top of it.

Please let me know what you think
","All Windows version in recent history have cmd.exe available very easily. Just Shift/Right click on a directory in Windows Explorer and click on Open Command Window Here.
",19606299
91,Templates engine & Examples,open,2016-01-09T16:58:09Z,2018-08-02T21:25:10Z,,NONE,"I would love to see templates in the projects, so when you init a project you could init it with an example, that will have certain information filled out, for example:

`platformio init -b megaatmega2560 --ide clion --template BasicSerial` will init Arduino basic serial project, so you don't have to copy-paste things.

Also, what can be done, is implementing jinja2 templating enging to replace certain values in the actual code (for example serial baud rate:)

``` c++
void setup() {
    Serial.begin({{serial_baudrate}});    
}
```

Where `serial_baudrate` could be a parameter in the PIO global file or local (by the precedence).

Please let me know what do you guys think.
","I think for template feature, it can be split into 2 kinds of template.

## 1. Scaffold Template

This template is a custom template for a very specific case. For example, template project for building Web Server in ESP8266 that will consist of Arduino code and SPA Framework specific code (Angular/Vue/React). However, Scaffold Template is a feature just to facilitate if anyone wants to make their own template project (like in the corporate when they need to integrate their Prototype with their own Service).

### Usage

```cmd
pio init gh:username/platformio-mytemplate
```

This will fetch template from that GitHub repo then generate the files and folder from that.

### Technical Suggestion

Luckily in python, there is a command-line utility that creates projects from project template called [cookiecutters](https://cookiecutter.readthedocs.io/en/latest/case_studies.html). I think it's best if it builds on top of that to reduce the complexity and make the documentation more simple by linking it to cookie-cutter documentation. Also, it can be [called from python](https://cookiecutter.readthedocs.io/en/latest/advanced/calling_from_python.html)

---
## 2. Template from Library Example

This feature is more like *injector* rather than _template_. Some Library (especially many Arduino Library) has Code Example like in [here](https://platformio.org/lib/show/2071/AWS_IOT) that can be treated as a Template then it can be analyzed then injected into the current project file.

### Usage

```bash
pio example <lib_name> --list
```

#### Basic

```bash
pio lib example <lib_name> --print <example_name>                       # print code example to console
pio lib example <lib_name> --print <example_name> --output <filename>   # output code example to file
```

#### Inject

```bash
pio lib example <lib_name> --add
pio lib example <lib_name> --add <example_name>
```

For example, if we want inject/add the implementation of DHT11\_Logger with Library AWS\_IOT into the current project:

```bash
pio lib example AWS_IOT --add DHT11_Logger
```

<details>
<summary>command that's not necessery to implement</summary>

This command is not necessary to implement because better to delete it manually rather than automatically (as long as it's injecting into one file).

```cmd
pio example <lib_name> --remove
pio example <lib_name> --remove <example_name>
```

</details>

### Technical Suggestion

This feature is a little bit complex to implement, especially in inject usage. To implement that, it needs to parse [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree) of the example code then inject it into the main code (some of the javascript project generators usually use this technique). Python lib that I know support parsing AST of C++ source is [pycparse](https://github.com/eliben/pycparser) (although it's not really well documented, there is [code example](https://github.com/eliben/pycparser/tree/master/examples) for the starter). Also, note that the Example code of the Library is Framework and Platform specific. I think the simplest Framework to experiment this feature is Arduino.",19606299
92,Consider adding Particle Platform,open,2016-01-09T12:47:09Z,2019-11-12T23:44:39Z,,NONE,"Enhancement Request: Consider listing the [particle hardware](http://particle.io) as a platform.  It's effectively a web enabled variant of Arduino, and popular, at least in the US.
","> So, platform-particle should be responsible to build the Particle's Arduino/Wiring framework without any javascript files.

They've actually already done all of that. the cli is just a wrapper task/job runner for it all. Their toolchain is nearly identical to the esp8266 toolchains, including the compiler and framework support. 

Only reason I mentioned this approach is that it's the quickest way to get a PoC beta for supporting particle however, is to compress the particle toolchain (including a node binary) into a tar.gz, and drop it in as a framework package in the platform particle. Obviously this isn't the long-term approach, but it gives me what I need in the platform code so i can build out the framework library.

I'm hoping I'll only have this band-aid approach in for about a week or two while I get the other parts of the enablement system wired up.",19606299
93,init --ide eclipse deletes linkedResources,open,2016-01-08T12:19:22Z,2018-06-21T15:29:04Z,,NONE,"If you have linked resources in the Eclipse IDE, running 'platformio init --ide eclipse ...' will update .cproject, but not .project. The <linkedResources> disappear from <projectDescription>.

PlatformIO, version 2.6.3
",,19606299
94,why moderate the registry?,open,2016-01-07T01:55:21Z,2019-09-04T13:42:08Z,,NONE,"Perhaps there's some technical reason why packages must be moderated?
","These were the libraries you put through just this morning (http://platformio.org/lib/show/1971/DataFlash and related). Thank you by the way. As has been discussed thoroughly above, most package systems don't require human intervention, meaning you can publish and consume within seconds. I put ""ages"" in quotes because, while I waited no more than a day or two for the packages to be published, I had to wait at all.",19606299
95,Support UDOO boards,open,2016-01-06T12:54:40Z,2019-06-01T14:40:54Z,,NONE,"Two board classes:
- [Neo](http://www.udoo.org/udoo-neo/) (basic/extended/full variants all using Freescale™ i.MX 6SoloX applications processor with an embedded ARM Cortex-A9 core and a Cortex-M4 Core)
- [Dual/Quad](http://www.udoo.org/udoo-dual-and-quad/), using a separate Atmel® SAM3X8E

The manufacturer provides a patched Arduino IDE based on the board support package linked below. There are two firmware upload paths for the Neo:
1. Run [udooneo-m4uploader](https://github.com/ektor5/udooneo-m4uploader) tool on the local Linux core
2. Run [udooclient](https://github.com/UDOOboard/udoofota) on developer workstation, which uses a TCP connection to a service that runs m4uploader locally

For the Dual/Quad variants, the bossac tool is used (patched, see [repository](https://github.com/UDOOboard/bossac)).

My main interest is in the Neo boards. I'm happy to have a go at writing the support, though I would probably need some help with that.

References
- https://github.com/UDOOboard/arduino-board-package
","I tried to just add new JSON manifest, but I think it's not as simple since it's not really Atmel SAM board but Freescale i.MX 6SoloX with integrated both M9 and M4 chips. I've went through their documentation on http://www.udoo.org/docs-neo/Advanced_Topics/Recompile_MQX_Libraries.html and it seems like we need some MQX libraries (whatever they are..). When I last tried uploading sketch compiled for due in Platformio, i was unable to upload it (whereas the ones compiled with their patched Arduino IDE uploaded without any issues). So, i tried to just copy all their board files from AppData and create new framework out of it, but I don't really think this is the good way
",19606299
96,"Handle Arduino Makefile (mk) project [Teensy, SAM]",open,2015-12-17T20:42:30Z,2016-12-27T14:00:51Z,,MEMBER,"Will be good to handle Arduino Makefile based projects ( https://github.com/sudar/Arduino-Makefile ). It should allow users to build source code for Teensy, Arduino SAM and rest of supported platforms by @PlatformIO.
","@ivankravets I'd very much like this, what would need to be done to add it?",19606299
97,Automatically update IDE settings according to project data,open,2015-12-09T15:07:55Z,2018-02-13T17:12:03Z,,MEMBER,"In the current state PlatformIO initializes project for the specified IDE and board using existing source code. When user modifies project and uses new libraries, then the will not be reflected in IDE settings. The only one solution is to reinitialize IDE settings.

See related isse #362 
",,19606299
98,Improving Linux distribution support,open,2015-11-25T22:03:49Z,2016-01-26T19:23:54Z,,NONE,"While it is perfectly possible to package platformio for Linux (eg. see https://build.opensuse.org/project/show/home:dmacvicar:PlatformIO ) I had trouble submitting it to the main channels for some reasons:
- Some distributions already invest some effort in packaging things like gcc-avr
- Toolchains are compiled ""somewhere"" and published as binaries
# Integration with system-wide packages

I like the approach of downloading on demand to the user $HOME directory. I don't think systems packages are the solution for everything, but I see the point in the trustabilty of binaries.

Some ideas that could help PlatformIO adoption into distributions could be to allow system wide installed packages (coming from distro packages) in addition to the user installed packages.

There is no need to invest on how to install them, that is the job of the distro specific tool. PlatformIO only needs to notice when a toolchain is installed (and the fact that itself can't remove it).

The distro package would have to deal with putting the right metadata in the right places for platformio to notice.
- Allow main manifest to be local, so that the distribution package can include it.
  - Even better, allow to combine a local one with a remote one, with priority for the local one, while still allowing distros to disable the remote one if policy requires to
- Allow toolchains to be installed in the system, and manifests to refer as them
  - The user would install the arduino manifest from his distribution package selector
  - platformio would use it if installed, otherwise download it, otherwise if internet access is not allowed, error
  - for this, it may be useful if the manifest could be read also in in parts eg. `/usr/share/platformio/appstate.d/toolchains/toolchain-atmelavr.json` so if the user installs the distro package platformio-toolchain-atmelavr that file will be installed there and platformio would know immediately that the toolchain is installed (like it does now with appstate.json). May be platformio could read first the directory with parts and merge that to the appstate.json generated from user installed packages.
# Trustability of binaries

In addition to that, some insight on how the current toolchain tarbals are built would be helpful to be able to replicate those packages in build systems like http://build.opensuse.org so that distros can create the packages for the toolchains they are interested in.

This could benefit even the user installable packages from http://dl.platformio.org/packages, as they could be built in a trusted environment like http://build.opensuse.org, which automatically rebuilds and publish, create reproducible builds and does not allow internet access during builds.

PlatformIO could build their toolchains in http://build.opensuse.org either as rpms or ArchLinux PKGBUILDS (Open Build Service is multi-distro), and then unpack those packages to create the tarballs exposed by http://dl.platformio.org/packages (basically, a distro package without external dependencies). Then users would know where those tarballs are built.
",,19606299
99,Ensuring that there is no 'main()' function in user's code when compiling for Arduino,open,2015-06-07T03:21:39Z,2018-06-07T22:08:04Z,,NONE,"Arduino provides its own staff including their own 'main()' function. If user's code happens to have a 'main()' function, too, it can be silently used by a compiler instead of one from Arduino thus producing undesired result. As a potential solution it might be good, in case of Arduino (or, more generally, in case of any framework providing its own code) to check whether user-defined code has a 'main()' function and to report an error.
",,19606299
100,Support popular RTOS projects: ChibiOS/RT & NuttX,open,2015-04-07T00:26:03Z,2020-02-14T12:26:02Z,,NONE,"Is there anything preventing PlatformIO from supporting popular RTOS projects like [ChibiOS/RT](http://chibios.org/), [FreeRTOS](http://www.freertos.org/) & [NuttX](http://nuttx.org/)?\* A quick search on the web UI returned 0 results.

*there are many, many more RTOS projects out there.
","Fair enough. Thanks for all the support thus far.
",19606299
101,"Add new platform ""timsp432"" and support for TI MSP432 LaunchPad",open,2015-03-29T14:06:59Z,2019-10-05T04:40:56Z,,MEMBER,"See: http://energia.nu/releasenotes/

* https://github.com/ivankravets/msp432-core
* https://github.com/energia/msp432r-core

Add example with [Multitasking](http://energia.nu/guide/multitasking/).",Any updates on this? I want to use platformio instead of Energia to program this board,19606299
102,Grammar and punctuation issues in swagger.yml,open,2020-03-26T13:27:20Z,2020-03-26T13:45:48Z,,MEMBER,"### Expected behavior
The description of the Lisk SDK API documentation should be up to date and grammatically correct.

### Actual behavior
The markdown descriptions in the `swagger.yml` file are outdated and have several grammar issues.
",,50873641
103,Add vote weight snapshot - Closes #4938,open,2020-03-26T07:20:29Z,2020-03-26T10:33:52Z,,CONTRIBUTOR,"### What was the problem?

This PR resolves #4938

### How was it solved?

- Update chain to return all the delegates in sorted order
- Create vote weight snapshot
  - If there are not enough standby delegates (less than 2), it chooses top 103
  - If there are more than 2 eligible standby delegate, all standby delegates is added

### How was it tested?
- Add unit test that all scenario ( not enough delegate, including zero vote weight, banned, and more than 2 eligible standby)
- Run the application and see genesis scenario works as expected
",,50873641
104,Add protocol spec for forger selection - Closes #4923,open,2020-03-25T15:49:06Z,2020-03-26T13:22:47Z,,CONTRIBUTOR,"### What was the problem?

This PR resolves #4923

### How was it solved?

Add forger selection protocol specs with the new DPoS system
",,50873641
105,Add safety banning mechanism by productivity to the DPoS system,open,2020-03-25T08:43:00Z,2020-03-25T08:43:04Z,,CONTRIBUTOR,"### Description

Update DPoS system to ban delegate who has very low productivity.
This feature is complex to implement without automatic undo because it needs to track historical changes of lastForgedHeight and consecutiveMissedBlocks.

### Motivation

https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md#delegate-productivity

### Tasks
- Update DPoS library to calculate consecutiveMissedBlocks #4934
- Update DPoS library to calculate and undo last forged height #4935
- Update DPoS library to ban or unban when conditions are met #4942
",,50873641
106,Add network identifier in block signature - Closes #4932,open,2020-03-24T16:38:34Z,2020-03-26T08:49:20Z,,CONTRIBUTOR,"### What was the problem?

This PR resolves #4932

### How was it solved?

- Add network identifier while forging a block
- Add network identifier while validating forged block

### How was it tested?

- Updated tests (we already have signature validation check)
- Run application and see forged block is accepted",,50873641
107,Add hash onion function - Closes #4930,open,2020-03-24T12:00:59Z,2020-03-26T10:38:55Z,,CONTRIBUTOR,"### What was the problem?

This PR resolves #4930 

### How was it solved?

- Add a command to create hash function

### How was it tested?

- add unit test to check if the hash onion can be recalculated
- `./bin/run hash-onion`
- `./bin/run hash-onion --count=100000 --distance=2000 --output=./sample.json`
",,50873641
108,Add unlock transaction - Closes #4926,open,2020-03-24T10:22:02Z,2020-03-26T10:38:40Z,,CONTRIBUTOR,"### What was the problem?

This PR resolves #4926 

### How was it solved?

- Add unlock transaction based on https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md and https://github.com/LiskHQ/lips/blob/master/proposals/lip-0024.md

### How was it tested?

- Added test using protocol specs and unit test templates

### Additional Information
- This should be merged after #5048 
- It currently includes commits from #5048 
",,50873641
109,Add new vote transaction - Closes #4925,open,2020-03-23T20:40:26Z,2020-03-26T10:38:18Z,,CONTRIBUTOR,"### What was the problem?

This PR resolves #4925 

### How was it solved?

- Add new vote transaction based on LIP https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md

### How was it tested?

- All test based on protocol spec and unit test template created at #4918  are added
",,50873641
110,Increase transaction releaseLimit,open,2020-03-13T19:59:13Z,2020-03-13T19:59:13Z,,MEMBER,"### Description
Increate transaction `releaseLimit` when rpc request for `getTransactions` is called.
```
	async handleRPCGetTransactions(data = {}, peerId) {
```
### Motivation
Currently, we only send 25 transactions when we receive rpc request for `getTransactions` and with introduction for LIP https://github.com/LiskHQ/lips/blob/master/proposals/lip-0002.md
https://github.com/LiskHQ/lips/blob/master/proposals/lip-0013.md
https://github.com/LiskHQ/lips/blob/master/proposals/lip-0015.md
we need to ensure the transaction pool has enough transactions to process to ensure the block is full and delegates can benefit from transaction fees.

### Acceptance Criteria
- Increase the `releaseLimit` to meet the above 3 LIP requirement.
",,50873641
111,Create PoM transaction create command,open,2020-03-13T14:53:31Z,2020-03-13T14:53:31Z,,CONTRIBUTOR,"### Description
- Create unlock transaction creation command.
- transaction:create -t 14 or transaction:create:pom should take 2 arguments for block headers
`transaction:create -t 14 fee nonce ""header1"" ""header2""`

### Motivation
With the new BFT violation, PoM transaction command is required to create new transaction

### Acceptance Criteria
- Write description and examples. Example should not include complete header.
- Test both transaction:create -t 14 and transaction:create:pom cases


### Related issues
#4915
",,50873641
112,Remove network identifier from the constructor of transaction,open,2020-03-11T15:29:36Z,2020-03-11T15:29:36Z,,CONTRIBUTOR,"### Description

Please describe what functionality is needed

### Motivation

Network identifier is not part of the instance and it is only required validating signature.
With the #4951, it will be part of the chain state, so it should use that to verify the signature.

### Acceptance Criteria

- Remove the network identifier while instantiating the transaction
- Use the network identifier in the chain state to validate signature
- Remove variable networkIdentifier in the base transaction

",,50873641
113,Typesafe StateStorePrepare,open,2020-03-09T15:25:30Z,2020-03-09T15:25:30Z,,CONTRIBUTOR,"Currently the type definition of the StateStorePrepare is as follow: 

```typescript
export interface StateStoreCache<T> {
	cache(
		filterArray: ReadonlyArray<{ readonly [key: string]: string }>,
	): Promise<ReadonlyArray<T>>;
}
```

Using type literal it is possible to provide an exhaustive list of available filters, allowing slick auto-completion and type safety, in following code : 

```typescript
class SomeTransaction {
	public async prepare(store: StateStorePrepare): Promise<void> {
		await store.account.cache([
			{
				address_in: ['1L', '2L'], // OK
				balance_in: 100, // Error
				balance_gte: 100, // OK
			},
		]);
	}
}
```",,50873641
114,"Update delegate, votes and voters HTTP API endpoints",open,2020-03-09T07:30:48Z,2020-03-11T11:14:38Z,,CONTRIBUTOR,"### Description
- Update HTTP API to show relevant delegate information according to the new DPoS protocol.
- Check “delegates, votes, and voters: endpoint especially.
### Motivation
HTTP API should reflect the latest DPoS changes.
### Acceptance Criteria
- All endpoints responses with valid result
- Updated endpoints are covered with unit test


### Related issues
#4915
",,50873641
115,Update BFT library not to include standby delegates for the calculation,open,2020-03-09T07:30:15Z,2020-03-11T11:14:26Z,,CONTRIBUTOR,"### Description
- Update BFT library not to include the block from standby delegate for pre-votes and pre-commits following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0022.md#bft-consensus-rules-for-standby-delegates
- DPoS should have already implemented isStandby function.
### Motivation
In order to extend the finality time, it should exclude the standby delegate for calculation
### Acceptance Criteria
- Test case where delegate is standby delegate, and the calculation is skipped


### Related issues
#4915
",,50873641
116,Update DPoS library to ban or unban when conditions are met,open,2020-03-09T07:29:38Z,2020-03-12T14:34:39Z,,CONTRIBUTOR,"### Description
- Update DPoS library to ban delegates when condition are met by following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md#delegate-productivity-1
- The consecutiveMissedBlocks and lastForgedHeight should be already calculated in other issues.
- When undoing, if the delegate is banned, it should be unbanned.
- Add the banned list into the consensus state

### Motivation
For the safety mechanism, when the condition is met, delegates should be banned.
### Acceptance Criteria
- Test case when only one condition is met
- Test case when both conditions are met
- Test case when undoing the block which delegate was banned


### Related issues
#4915
",,50873641
117,Update DPoS library to generate forger list from voteWeight list,open,2020-03-09T07:29:05Z,2020-03-23T09:26:50Z,,CONTRIBUTOR,"### Description
- Update delegate selection function in DPoS library following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0022.md#round-computation
- It should use the correct voteWeight with the offset.
- In addition, the created forger list should be stored in the consensus state.
### Motivation
Shuffling of the delegate must be distributed equally.
### Acceptance Criteria
- Test standby delegate selection using protocol spec if the input and output matches the result
- Test if the forger list is properly saved to the state
- Test case where there is no stand by delegates


### Related issues
#4915
",,50873641
118,Update DPoS library to have shuffle function,open,2020-03-09T07:26:17Z,2020-03-23T09:27:13Z,,CONTRIBUTOR,"### Description
Update shuffle function in DPoS library following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0003.md#specification.
### Motivation
Shuffling of the delegate must be distributed equally.
### Acceptance Criteria
- Test using protocol spec if the input and output matches the result


### Related issues
#4915
",,50873641
119,Update DPoS library to calculate random seed,open,2020-03-09T07:25:52Z,2020-03-23T09:28:30Z,,CONTRIBUTOR,"### Description
- Update DPoS library to add function to calculate random seed following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0022.md#random-seeds-computation.
- Using the last 2 rounds of blocks, 2 random seeds should be generated.
### Motivation
In order to add standby delegate, good random seed is required.
### Acceptance Criteria
- Test using protocol spec if the input and output matches the result


### Related issues
#4915
",,50873641
120,Update DPoS library to snapshot totalVotesReceived to voteWeight in consensus state,open,2020-03-09T07:25:21Z,2020-03-26T07:15:59Z,,CONTRIBUTOR,"### Description
Update DPoS library to snapshot totalVotesReceived instead of forgers list at the end of the round.
During the snapshot,
- banned delegate should not be included in the snapshot
- Vote weight of punished delegate should be set to 0
- While undoing, irrelevant snapshots can be removed. (ie: list which will be used more than 2 rounds ahead can be changed, so it can be deleted)
- Save the list with key: round to next round + offset(2)
### Motivation
In order to calculate the correct forger list with the offset, delegate weight needs to be stored.
### Acceptance Criteria
- Test case where there are banned delegates
- Test case where there are punished delegates
- Test case for first 3 rounds, which should be created at the startup
- Test case when undo, future list is removed.


### Related issues
#4915
",,50873641
121,Update DPoS library to validate seedReveal value,open,2020-03-09T07:24:53Z,2020-03-12T14:18:14Z,,CONTRIBUTOR,"### Description
- Update DPoS library to verify seedReveal value following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0022.md#validating-new-block-header-property.
- `isDPoSProtocolComplient(blockHeader: BlockHeader, store: StateStore) => boolean`.
If it’s invalid seed reveal, the reward should be changed to 0 in the block_processor.
### Motivation
In order to encourage inserting correct seed reveal, the value has to be checked
### Acceptance Criteria
- Test case where seed reveal does not match with the previous one
- Test case where seed reveal does match with previous one
- Test case where delegate did not forge for last 2 rounds


### Related issues
#4915

### Additional Information
- `isBFTProtocolComplient` already exists and it should follow similar usage",,50873641
122,Update DPoS library to provide information of an address is standby delegate or not,open,2020-03-09T07:24:30Z,2020-03-12T14:10:07Z,,CONTRIBUTOR,"### Description
Update DPoS library to expose a function to check if a delegate is a standby delegate or not at particular height.
`isStandby(address:string, height: number, stateStore: StateStore) => boolean`.
### Motivation
In the BFT, it should not include the standby delegate for the prevote and pre commit calculation.
### Acceptance Criteria
- Test case when the block is 3 rounds old, which is maximum according to the BFT rule.
- Test case when checking the latest block and forged by standby delegate
- Test case when checking the latest block and forged by active delegate


### Related issues
#4915
",,50873641
123,Update DPoS library to calculate and undo last forged height,open,2020-03-09T07:23:58Z,2020-03-23T09:22:29Z,,CONTRIBUTOR,"### Description
Update lastForgedHeight property of delegate in the DPoS library.
lastForgedHeight must be calculated every block by following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md#delegate-productivity-1

- Update delegate registration to set current height as `account.delegateRegisteredHeight`
- while undoing, search last 3 rounds of blocks first ,and then search block generator in `(deleting block height - 1) ~ (Math.max(deleting block height - 1 - 260000, registeredHeight))`, if it doesn’t exist in this range, lastForgedHeight = delegate registered height
- These property must be removed when removing the `undo`

### Motivation
For the safe fail mechanism for the new DPoS system, consecutiveMissedBlocks must be tracked.
### Acceptance Criteria
- Test case when applying delegate lastForgedHeight increments
- Test case when undoing, lastForgedHeight decrements to the previous value
- Test case when undoing the first block that delegate forged
- Test case where undoing the a block with 260,000 gap from the last block


### Related issues
#4915
",,50873641
124,Update DPoS library to calculate consecutiveMissedBlocks,open,2020-03-09T07:23:29Z,2020-03-25T08:32:28Z,,CONTRIBUTOR,"### Description
- Update missed block calculation in the DPoS library.
- consecutiveMissedBlocks must be calculated every block by following https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md#delegate-productivity-1
- consecutiveMissedBlocks for every delegate between the generator and last block generator should be incremented.

It should take timestamp in consideration. For example,
If D1 forged at 100 timestamp and D2 forged at 2000 timestamp, the delegates in between including D1 and D2 misses blocks more than once.


### Motivation
For the safe fail mechanism for the new DPoS system, consecutiveMissedBlocks must be tracked.
### Acceptance Criteria
- Test case where only one delegate forged
- Test case where all the delegates forges
- Test case where some delegates didn’t forge
- Test case where some delegate misses block more than 2


### Related issues
#4915
",,50873641
125,Update delegate list to be based on address,open,2020-03-09T07:23:04Z,2020-03-11T10:51:18Z,,CONTRIBUTOR,"### Description
Delegate list should be stored as address.
- Update forger list to store address instead of public key as key
- Update forger info to store information with address key
- Delegate slot check should be based on address in forger module
- Generator check should be based on address in processor

### Motivation
In the system, address should be used consistently except where signature validation is required.

### Acceptance Criteria
- Test if forger list is stored with address key
- Test if forger info is stored with address key
- Test if delegate slot is checked against address
- Test if generator is checked against address
- Public key should not be used anywhere except signature validation

### Related issues
#4915
",,50873641
126,Add network identifier in block signature,open,2020-03-09T07:22:23Z,2020-03-24T15:21:48Z,,CONTRIBUTOR,"### Description
Network identifier should be used while signing the block with the same logic as transactions.
However, this information should not be stored anywhere.

### Motivation
In order to prevent replay of block, network identifier need to be added.

### Acceptance Criteria
- Test if signature includes network identifier
- Test if network identifier is not included, signature is invalid


### Related issues
#4915
",,50873641
127,Add seedReveal to the block header,open,2020-03-09T07:21:58Z,2020-03-13T11:20:54Z,,CONTRIBUTOR,"### Description
- Add seed reveal to block header.
- seedReveal should be placed right after the property of previousBlockId in getBytes function.
- hash-onion should be added to the config under each delegate information
- hash-onion should be taken from a config file, and if it does not exist in forger info, it should be saved in the forger info. It should assume multiple delegates can be enabled in a node.
- It should remember which hash is used
- When seed reveal is not provided in config, and it doesn't exist in the forger info, it should exit with proper error message
- used seed reveal should be stored in the forger info, and prune on finality

### Motivation
With the new DPoS system, in order to generate valid random seed in a decentralized way, seedReveal is required.

### Acceptance Criteria
- Test if valid byte array is produced with get bytes
- Test case when seed reveal is not provided in config, and it doesn't exist in the forger info
- Test case where seed reveal is provided and it is not in the forger info
- Test case where seed reveal is used, and the stored seed reveal is the next hash


### Related issues
#4915
",,50873641
128,Create hash onion creation command,open,2020-03-09T07:21:18Z,2020-03-24T11:32:33Z,,CONTRIBUTOR,"### Description
- Create a hash onion creation function.
- `hashonion --output outputFilePath --count=1,000,000 --distance=2000`
- If output is not defined, show in console
- If count or distance are not defined, use above value as default
- Output format should be hash onion, placed in order and the first element should be the one to use at the beginning.
```
{
  count: x,
  distance: y,
  hashes: [],
}
```
Also, hash has to be in sha-256 and 128 most significant bits of the hash result.
### Motivation
With the new DPoS system, tool to output hashonion is required.

### Acceptance Criteria
- Test if correct hash onion is calculable from the hashes
- Test case when output file path is provided


### Related issues
#4915
",,50873641
129,Create an unlocking transaction command,open,2020-03-09T07:20:40Z,2020-03-11T10:57:49Z,,CONTRIBUTOR,"### Description
- Update of unlock transaction creation command is required.
- transaction:create -t 13 or transaction:create:unlock should take
--unlock=”address,amount,unvoteHeight” --unlock=”address,amount,unvoteHeight” format
`transaction:create -t 13 fee nonce  --unlock=”address,amount,unvoteHeight” `
### Motivation
With the new DPoS system, create unlock transaction command needs to be created.

### Acceptance Criteria
- Update description and examples
- Test both transaction:create -t 11 and transaction:create:vote cases
- Test case when vote is not casted


### Related issues
#4915
",,50873641
130,Update create vote transaction command,open,2020-03-09T07:20:09Z,2020-03-11T10:57:34Z,,CONTRIBUTOR,"### Description
- Update of vote transaction creation command is required.
- transaction:create -t 11 or transaction:create:vote should take
--vote=”address,amount” --vote=”address,amount” format
`transaction:create -t 11 fee nonce  --vote=”address,amount” `

### Motivation
With the new DPoS system, create vote transaction command needs to be updated.

### Acceptance Criteria
- Test both transaction:create -t 11 and transaction:create:vote cases
- Test case when vote is not casted


### Related issues
#4915
",,50873641
131,Create a PoM transaction and helper function,open,2020-03-09T07:19:30Z,2020-03-23T09:25:02Z,,CONTRIBUTOR,"### Description
Create proof of misbehavior transaction for supporting BFT protocol.
Follow https://github.com/LiskHQ/lips/blob/master/proposals/lip-0024.md#proof-of-misbehavior--pom

### Motivation
Refer to https://github.com/LiskHQ/lips/blob/master/proposals/lip-0024.md#motivation

### Acceptance Criteria
- Test case where one of the header is older than 260k blocks
- Test case where both of headers are older than 260k blocks
- Test case where the delegate is already banned
- Test case where the delegate is being punished
- Test case where header signature is invalid
- Test case where the delegate receive 5th PoM transaction
- Test case where delegate does not have/have enough balance

### Related issues
#4915
",,50873641
132,Create an unlocking transaction and helper function,open,2020-03-09T07:18:40Z,2020-03-23T09:25:24Z,,CONTRIBUTOR,"### Description
- Create unlock transaction for a new DPoS protocol, and create transaction creation function.
- Follow https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md#new-unlock-transaction
And https://github.com/LiskHQ/lips/blob/master/proposals/lip-0024.md#update-to-validity-of-unlock-transaction
- Also, “unlockBalance” function to create transaction json also needs to be created.

### Motivation
In order to satisfy new DPoS protocol, new unlock transaction has to be created

### Acceptance Criteria
- Test case where sender does not have corresponding unlocking object
- Test case where sender is unlocking self vote, and not waited locking period
- Test case where sender is unlocking non-self vote, and not waited locking period
- Test case where sender is has multiple same unlocking object, but asset unlocking has more (this can happen if 2 or more transaction is included in the same block)
- Test case where unlocking object has more than 20 entries
- Test case where sender is unlocking self vote and currently being punished, and not waited locking period
- Test case where sender is unlocking non-self vote and the delegate is currently being punished, and not waited locking period

### Related issues
#4915
",,50873641
133,Update the current vote transaction and a helper function to the new protocol,open,2020-03-09T07:17:54Z,2020-03-23T09:12:00Z,,CONTRIBUTOR,"### Description
- Update vote transaction for new DPoS protocol, and update creation function.
- Follow https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md#new-vote-transaction-1
- In addition to above specification,
   - Also, “castVote” function also need to be updated.
   - Commander create votes can be removed temporary along with the test, this will be handled in the different issue.
### Motivation
In order to satisfy new DPoS protocol, new vote transaction has to be created

### Acceptance Criteria
- Test case where amount is not multiple of 10 LSK
- Test case where amount is out of range of int64
- Test case where delegate address is not registered delegate
- Test case where sum of upvotes is more than sender balance
- Test case where asset.votes is more than 20
- Test case where asset.votes includes duplicate delegate address
- Test case where asset.votes has invalid sort order
- Test case where unvoting not voted delegate or unvoting more than voted amount
- Test case where unvoting to 0 amount, and account.votes entry is removed
- Test case where unvoting makes account.unlocking more than 20 entries
- Test case where account.votes becomes more than 10 entries
- Test if delegate totalVoteReceived is calculated properly on upvotes and unvotes
 - Test case where delegate goes over/below 1000 LSK totalVotesReceived
 - Test case where delegate already has 1000 LSK totalVotesReceived
- Test case where unvote creates the unlocking object



### Related issues
#4915",,50873641
134,Create protocol spec for selection of delegates,open,2020-03-09T07:15:35Z,2020-03-25T13:58:37Z,,CONTRIBUTOR,"### Description
Create protocol spec for selection of active and standby delegates.

### Motivation
In order to test selection algorithm of delegates, several pattern of the fixtures are required

### Acceptance Criteria
- Valid delegate selection fixtures when there are more than 2 non-active delegates who has more than 1000 LSK voteWeight
- Valid delegate selection fixtures when there are 2 non-active delegates who has more than 1000 LSK voteWeight
- Valid delegate selection fixtures when there are 1 non-active delegates who has more than 1000 LSK voteWeight
- Valid delegate selection fixtures when there are 0 non-active delegates who has more than 1000 LSK voteWeight

### Related issues
#4915
",,50873641
135,Create protocol spec for shuffling of delegate,open,2020-03-08T21:30:41Z,2020-03-23T09:06:14Z,,MEMBER,"### Description
We need to create protocol spec for the introduction of LIP [Uniform ordering of delegates list](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0003.md)

### Motivation
- To validate the implementation of LIP [Uniform ordering of delegates list](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0003.md)
### Acceptance Criteria
- Create protocol-spec for shuffling of standby delegate

### Related issues
#4915

",,50873641
136,Create protocol spec for calculation of random seed,open,2020-03-08T21:28:45Z,2020-03-23T09:06:15Z,,MEMBER,"### Description
We need to create protocol spec for the introduction of LIP [Use Randao-based scheme to include standby delegates and reorder delegate list](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0022.md)

### Motivation
- To validate the implementation of LIP [Use Randao-based scheme to include standby delegates and reorder delegate list](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0022.md)

### Acceptance Criteria
- Create protocol-spec for the calculation of random seed

### Related issues
#4915
",,50873641
137,Create protocol spec for proof of misbehavior transaction,open,2020-03-08T21:26:40Z,2020-03-23T09:06:15Z,,MEMBER,"### Description
We need to create protocol spec for the introduction of LIP [Punish BFT violations]( https://github.com/LiskHQ/lips/blob/master/proposals/lip-0024.md) 

### Motivation
- To validate the implementation of LIP [Punish BFT violations]( https://github.com/LiskHQ/lips/blob/master/proposals/lip-0024.md) 

### Acceptance Criteria
- Create protocol-spec for the proof of misbehavior transaction
- Generate all 3 cases for contradicting headers

### Related issues
#4915

",,50873641
138,Network Consensus - Update DPoS voting system with BFT punishment,open,2020-03-06T16:34:48Z,2020-03-13T14:55:07Z,,CONTRIBUTOR,"### Description
Update DPoS system with 2 new transactions vote and unlock.
Also, implement BFT punishment for the misbehavior.

### Motivation

- Uniform ordering of delegates list
- Use Randao-based scheme to include standby delegates and reorder delegate list
- Introduce vote locking periods and new vote weight definition
- Punish BFT violations

### Acceptance Criteria

To conclude this epic, following LIP must be implemented:

- [Uniform ordering of delegates list](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0003.md)
- [Use Randao-based scheme to include standby delegates and reorder delegate list](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0022.md)
- [Introduce vote locking periods and new vote weight definition](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0023.md)
- [Punish BFT violations](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0024.md)

### Tasks
- Create protocol spec for vote transaction #4918
- Create protocol spec for unlocking transaction #4919
- Create protocol spec for proof of misbehavior transaction #4920
- Create protocol spec for calculation of random seed #4921
- Create protocol spec for shuffling delegate #4922
- Create protocol spec for selection of standby delegates #4923
- Update account class with new properties #4924 
- Update state store interface to support new information #4951 
- Update the current vote transaction and a helper function to the new protocol #4925 
- Create an unlocking transaction and helper function #4926 
- Create a PoM transaction and helper function #4927 
- Update create vote transaction command #4928 
- Create an unlocking transaction command #4929 
- Create PoM transaction create command #4973
- Create hash onion creation command #4930 
- Add seedReveal to the block header #4931 
- Add network identifier in block signature #4932 
- Update delegate list to base on address and validation #4933 
- Update DPoS library to calculate consecutiveMissedBlocks #4934 
- Update DPoS library to calculate and undo last forged height #4935 
- Update DPoS library to provide information of an address is standby delegate or not #4936 
- Update DPoS library to validate seedReveal value #4937 
- Update DPoS library to snapshot totalVotedDelegates to voteWeight in chain state #4938 
- Update DPoS library to calculate random seed #4939 
- Update DPoS library to have shuffle function #4940 
- Update DPoS library to generate forger list from voteWeight list #4941 
- Update DPoS library to ban or unban when conditions are met #4942 
- Update BFT library not to include standby delegates for the calculation #4943 
- Update delegate, votes and voters HTTP API endpoints #4944 ",,50873641
139,Improve code coverage for elements and framework,open,2020-03-06T10:53:33Z,2020-03-06T10:53:33Z,,MEMBER,"### Description
Currently, there are few unit tests missing for elements and framework files which can be improved through code refactoring and test coverage phase.

Most of these files have covered the function level unit test, the majority of missing coverage or related to branching.

### Motivation

To improve the code coverage with unit test

### Acceptance Criteria

- Add missing unit test for empty signature ['mk','mk', '', 'ok', '','ok'] scenario in `utils/verify/verifyMultiSignatureTransaction`
- elements/lisk-cryptography/src/buffer.ts `intToBuffer`
- elements/lisk-cryptography/src/encrypt.ts
- elements/lisk-bft/src/bft.ts
- elements/lisk-chain/src/block_reward.ts
- elements/lisk-chain/src/verify.ts
- elements/lisk-chain/src/chain.ts
- elements/lisk-chain/src/data_access/data_access.ts
- elements/lisk-chain/src/data_access/cache/base.ts
- elements/lisk-chain/src/state_store/state_store.ts
- elements/lisk-chain/src/state_store/chain_state_store.ts
- elements/lisk-chain/src/state_store/transaction_store.ts
- elements/lisk-chain/src/transactions/exceptions_handlers.ts
- elements/lisk-dpos/src/delegates_info.ts
- elements/lisk-validator/src/validation.ts
- framework/src/application/application.js
- framework/src/application/network/network.js
- framework/src/application/configurator/configurator.js
- framework/src/application/node/block_processor_v0.js
- framework/src/application/node/node.js
- framework/src/application/node/rebuilder.js
- framework/src/application/node/forger/forger.js
- framework/src/application/node/forger/sort.js
- framework/src/application/node/processor/pipeline.js
- framework/src/application/node/synchronizer/fast_chain_switching_mechanism.js
- framework/src/application/validator/formats.js
- framework/src/controller/bus.js
- framework/src/controller/controller.js
- framework/src/controller/channels/in_memory_channel.js

### Additional Information

These list was identified by going through the code coverage on sdk development branch from jenkins
https://jenkins.lisk.io/job/lisk-sdk/job/development/86/cobertura/

- Before we start working on this issue, we can have a discussion on which ones to cover and split the issue into multiple accordingly, also eliminate the once which need not required to cover.",,50873641
140,Add command to get fee estimation,open,2020-03-05T19:33:59Z,2020-03-09T09:14:43Z,,CONTRIBUTOR,"### Description

`transaction:estimate` command should be implemented. 
It should call lisk-service endpoint and present the result

### Motivation

- With the new dynamic fee system, command to get fee estimation from the network is required.

### Acceptance Criteria

- It should show all low, medium and high priority estimation

### Related Issues
#4837 ",This  issue is depended on lisk-Service ,50873641
141,Add integration tests for application actions and events,open,2020-03-02T12:24:17Z,2020-03-03T09:50:41Z,,CONTRIBUTOR,"### Description
All the exposed `app` actions and events should have integration tests.
The list doesn't contain the actions that are exposed to the network, as this should be tested in the functional tests

### Motivation

Application actions and events are ultimate endpoints that user can use in the custom modules.
It should have the integration test for these functions.

### Acceptance Criteria
Below actions should be tested
- postTransaction
- getComponentConfig
- getApplicationState
- updateApplicationState
- getConnectedPeers
- getDisconnectedPeers
- calculateSupply
- calculateMilestone
- calculateReward
- getForgerPublicKeysForRound
- updateForgingStatus
- getForgingStatusForAllDelegates
- getTransactionsFromPool
- getSlotNumber
- calcSlotRound
- getNodeStatus
- getAccount
- getAccounts
- getBlockByID
- getBlocksByIDs
- getBlockByHeight
- getBlocksByHeights
- getBlocksByHeightBetween
- getTransactionByID
- getTransactionsByIDs

for Event
- networkEvent with `postBlock`
- networkEvent with `postTransactionsAnnouncement` 
",,50873641
142,Migrate mocha ws functional test,open,2020-03-02T12:15:39Z,2020-03-05T10:02:05Z,,CONTRIBUTOR,"### Description

Transport layer functional test should be moved to the jest.

### Acceptance Criteria
- All tests are separated per each endpoint
- `framework/test/mocha/functional` should be moved to `framework/test/jest/integration/actions`
- Add tests for `app:getLastBlock`
- Add tests for `app:getBlocksFromId`
- Add tests for `app:postTransaction`

",,50873641
143,Dev chain cannot restart after SIGTERM,open,2020-02-26T15:26:06Z,2020-02-26T15:29:14Z,,NONE,"### Expected behavior
I should be able to stop the node with ^c and then restart it.

### Actual beahviour
After stopping a node using `^c` and trying to restart it, the following error is displayed, and the process exit:

```
15:17:29.835Z  INFO lisk-framework: Booting the application with Lisk Framework(0.1.0) (module=lisk-controller)
15:17:29.837Z  INFO lisk-framework: Starting the app - devnet-alpha-sdk (module=lisk-controller)
15:17:29.850Z  INFO lisk-framework: Initializing controller (module=lisk-controller)
15:17:29.857Z  INFO lisk-framework: Loading controller (module=lisk-controller)
15:17:29.927Z  INFO lisk-framework: Previous Lisk PID (module=lisk-controller)
15:17:29.927Z  INFO lisk-framework: Current Lisk PID (module=lisk-controller)
15:17:29.963Z  INFO lisk-framework-chain: Loading in-memory module (module=lisk-controller, version=0.1.0, moduleAlias=chain)
WARNING: Creating a duplicate database object for the same connection.
    at PgpAdapter.connect (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/components/storage/adapters/pgp_adapter.js:89:13)
    at Storage.bootstrap (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/components/storage/storage.js:40:23)
    at module.exports (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/init_steps/bootstrap_storage.js:42:32)
    at Chain.bootstrap (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/chain.js:133:10)
    at async ChainModule.load (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/index.js:139:3)
    at async Controller._loadInMemoryModule (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/controller/controller.js:212:3)
    at async Controller._loadModules (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/controller/controller.js:184:5)
    at async Controller.load (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/controller/controller.js:69:3)

15:17:29.985Z  INFO lisk-framework: Modules ready and launched (module=chain)
15:17:30.012Z FATAL lisk-framework: Failed to initialization chain module (module=chain)
    message: Number of rounds requested is higher than number of existing rounds.
    --
    stack: Error: Number of rounds requested is higher than number of existing rounds.
        at Dpos.getMinActiveHeightsOfDelegates (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/dpos/dpos.js:119:10)
        at async /Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/block_processor_v2.js:172:41
        at async Pipeline.run (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/processor/pipeline.js:55:18)
        at async Processor.init (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/processor/processor.js:73:4)
        at async Chain.bootstrap (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/chain.js:180:4)
        at async ChainModule.load (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/modules/chain/index.js:139:3)
        at async Controller._loadInMemoryModule (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/controller/controller.js:212:3)
        at async Controller._loadModules (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/controller/controller.js:184:5)
        at async Controller.load (/Users/alessandro.ricottone/Desktop/lisk-chess/node_modules/lisk-framework/src/controller/controller.js:69:3)
15:17:30.012Z  INFO lisk-framework: Cleanup controller... (module=lisk-controller)
15:17:30.013Z ERROR lisk-framework: Reason: Error: Number of rounds requested is higher than number of existing rounds. (module=lisk-controller)
15:17:30.014Z  INFO lisk-framework: Unload completed (module=lisk-controller)
15:17:30.014Z  INFO lisk-framework-chain: Loaded in-memory module (module=lisk-controller, version=0.1.0, moduleAlias=chain)
15:17:30.014Z  INFO lisk-framework: Shutting down application (module=lisk-controller, errorCode=0, message={})
15:17:30.014Z  INFO lisk-framework: Cleanup controller... (module=lisk-controller)
```


This error does not happen every time, but seemingly randomly. Dropping the `lisk_dev` database and recreating solves the issue :)

### Steps to reproduce

Launch the dev chain, stop it and then restart it.

### Which version(s) does this affect? (Environment, OS, etc...)
MacOS, using ""lisk-sdk"": ""^3.0.2""",,50873641
144,commander: creation transaction for custom network (betanet) return error,open,2020-02-23T13:30:54Z,2020-02-23T13:30:54Z,,NONE,"With given lisk-commander config (for betanet):
```
{
	""json"": true,
	""api"": {
		""nodes"": [
			""https://betanet.lisk.io""
		],
		""network"": ""7158c297294a540bc9ac6e474529c3da38d03ece056e3fa2d98141e6ec54132d""
	},
	""pretty"": true,
	""default"": {
...
	}
}
``` 
should be possible to create transactions with `lisk transaction:create` (e.g. `lisk transaction:create -t=8 100  3385439950339234343L`)
### Expected behavior

Create transaction.

### Actual behavior
Return error:  `Error: Invalid network identifier`. To create transaction user has to specify the network identifier again with flag --networkIdentifier, which isn't marked as required.
### Steps to reproduce
Config lisk-commander for betanet, try create any type of transaction. 
### Which version(s) does this affect? (Environment, OS, etc...)
lisk-commander/3.0.2 linux-x64 node-v12.14.1",,50873641
145, commander: lisk config:set api.network fails,open,2020-02-22T12:00:13Z,2020-02-23T13:35:05Z,,NONE,"### Expected behavior
Command `lisk config:set api.network beta` should set network to betanet.
### Actual behavior
The command fails with error: 
```
 ›   Error: Value must be a hex string with 64 characters, or one of main or 
 ›   test.
```
### Steps to reproduce
Try to set beta network with lisk commander.
### Which version(s) does this affect? (Environment, OS, etc...)
lisk-commander/3.0.2 linux-x64 node-v12.14.1","If this is correct behavior for the beta argument, then please fix the documentation [here](https://lisk.io/documentation/lisk-sdk/reference/lisk-commander/user-guide.html#_configure_the_network)  (worth to mention in docs that `<NETWORK>` can be the 64 bytes network identifier).",50873641
146,Benchmark default parameters of transaction pool,open,2020-02-18T12:48:43Z,2020-02-27T16:48:57Z,,MEMBER,"### Description

Measure the performance of new transaction pool implementation, this measurement should give us constants which can be defined as default transaction pool processing capability.

### Motivation

With the implementation of a new transaction pool, we need to measure the performance of transaction processing capability to identify the constants for optimal utilization of our transaction pool. 

### Acceptance Criteria

- Pick a constants that allows forger create a 15kb full block with the first 500 ms
- Pick a constants that TxPool can process within the timeframe of the periodic job
- Define and use benchmark environment (CPU, Memory, etc..) to be able to get consistent results
- Derive transaction pool default configs 
```
- maxTransactions: 4056
- maxTransactionsPerAccount: 64
```
### Additional Information
It would be better to conduct this research write after we implement the priority queue so that we identify if there are any bottlenecks to processing transactions.

### Related issues
#4841 ",,50873641
147,Conversion of existing second signature and multi signature accounts,open,2020-02-18T08:03:12Z,2020-02-25T14:00:13Z,,CONTRIBUTOR,"### Description

After implementing #4839, all the testnet and mainnet second signature and multi signature accounts need to be migrated to the new multisignature format.

### Motivation

New multisignature is migratable from the old account schema.

### Acceptance Criteria

- Conversion rule should follow [Make multi-signature accounts more flexible, prevent spamming, and prevent signature mutability](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0017.md)
- Test second signature are migrated properly
- Test multi signature account are migrated properly
- Test multi signature with second signature accounts are migrates properly

### Additional Information
- Add migration to remove the second signature and second publicKey from `mem_accounts`",,50873641
148,Move test app out of framework change to sample app,open,2020-02-17T07:57:09Z,2020-03-19T08:34:24Z,,CONTRIBUTOR,"### Description

Move test app from inside of framework/test to the root level, and change it to the sample app.
Also, it should represents how `application` should be built as PoC.

### Motivation

Test app was created to test the framework when we split the `core` and `sdk`.
However, in order to mimic the behavior of application, it should be outside of `framework`, and use `sdk` instead of `framework`

### Acceptance Criteria

- Remove test app and all the functionality should be moved to this sample-app
- It should be command line tool
",,50873641
149,Add integration test for lisk-chain library,open,2020-02-03T15:52:38Z,2020-02-08T13:35:19Z,,MEMBER,"### Description
Add missing unit and integration test for lisk-blocks module
### Motivation
- Missing unit test for blocks cache module
- Missing integration test for chain module
### Acceptance Criteria
- Add missing unit test for the lisk-blocks module (blocks cache, data access module)
- Add Integration test for lisk-blocks module
### Additional Information
",,50873641
150,TransactionError should encapsulate multiple error and single error,open,2020-02-03T12:31:31Z,2020-02-03T12:31:50Z,,CONTRIBUTOR,"### Description
Update transaction to return `TransactionError`, but contains multiple error in cases there are multiple errors.
Framework, and lisk-blocks should handle them accordingly.

### Motivation

Currently transaction returns `TransactionError[]` as array, and in the framework it throws uses for detecting the exceptions.
However, as a best practice, when throws it should be a single error object

### Acceptance Criteria

- Error should no longer array
- It should still be able to handle exceptions

### Additional Information
",,50873641
151,Allow /transactions to be able to get multiple type,open,2020-01-17T16:01:55Z,2020-02-03T15:42:07Z,,CONTRIBUTOR,"### Description

API endpoint `transactinos` with multiple type `/transactions?type=2,8` should be supported

### Motivation

After migrating to the testnet/mainnet, 2 version of the transaction exist.
ie) type 0 and type 8 is both transfer transaction

### Acceptance Criteria

`/transactions` API should return the multiple version of transactions

### Additional Information
- Once service takes care of handling multiple version of core, we no longer need to handle it in lisk core, then we can close this issue.",,50873641
152,Remove swagger-node-runner dependency from the http-api module,open,2020-01-15T12:11:33Z,2020-02-03T15:43:42Z,,CONTRIBUTOR,"### Description

We need to remove `swagger-node-runner` from `http-api` module and directly use the `sway` package. The runner itself is just a wrapper around sway with few extra usability features. 

### Motivation

We need to reduce the dependencies in the application, specially which are not maintained actively. With that spirit, we need to remove a very less maintained package `swagger-node-runner` from the dependencies. 

### Acceptance Criteria

There should not be any vulnerability after removing swagger-node-runner and directly moving integration to sway package. 
",,50873641
153,Remove tslint and use typescript-eslint,open,2020-01-14T09:24:31Z,2020-01-14T09:24:31Z,,CONTRIBUTOR,"### Description
`tslint` is deprecated in favor of eslint.
Therefore, it should migrate to https://github.com/typescript-eslint/typescript-eslint 

### Actual behavior
It is using tslint
",,50873641
154,"lisk core stops, something about SSL",open,2020-01-02T13:15:48Z,2020-02-03T16:59:37Z,,NONE,"### Expected behavior
Just using lisk commander to send lisk : 
lisk@clovis:~/lisk-test$ lisk transaction:create:transfer 100 11237438676908077440L  --pretty
? Please enter your secret passphrase:  [hidden]
? Please re-enter your secret passphrase:  [hidden]
{
	""id"": ""11945506560372285320"",
	""amount"": ""10000000000"",
	""type"": 0,
	""timestamp"": 113861590,
	""senderPublicKey"": ""ab5146c3d62747f6372f5b35ca68ff85dccba9094526f84cd557133d395a8a7d"",
	""senderId"": ""3897910504949673529L"",
	""recipientId"": ""11237438676908077440L"",
	""fee"": ""10000000"",
	""signature"": ""5e09d5faf7caa6c8c5c6205ce7ad4e21e5fd32cb9bb2471bc6c14504ef0c8b9af49de05e71ce51c423a63df7d5d8b259aea26ad1028d4873b138f51c66143b02"",
	""signatures"": [],
	""asset"": {}
}

lisk@clovis:~/lisk-test$ lisk transaction:get 11945506560372285320
 **›   Error: write EPROTO 139842222430016:error:1408F10B:SSL routines:ssl3_get_record:wrong version number:../deps/openssl/openssl/ssl/record/ssl3_record.c:332:**
 

### Actual behavior
Lisk core stops after few seconds, in logs this msg : 
  ✔ Start Lisk Core instance
lisk@clovis:~/lisk-test$ lisk core:logs lisk-testnet
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12022,""level"":50,""err"":{""message"":""there is no unique constraint matching given keys for referenced table \""trs\"""",""name"":""error"",""stack"":""error: there is no unique constraint matching given keys for referenced table \""trs\""\n    at Connection.parseE (/home/lisk/.lisk/instances/lisk-testnet/node_modules/pg/lib/connection.js:554:11)\n    at Connection.parseMessage (/home/lisk/.lisk/instances/lisk-testnet/node_modules/pg/lib/connection.js:379:19)\n    at Socket.<anonymous> (/home/lisk/.lisk/instances/lisk-testnet/node_modules/pg/lib/connection.js:119:22)\n    at Socket.emit (events.js:198:13)\n    at Socket.EventEmitter.emit (domain.js:448:20)\n    at addChunk (_stream_readable.js:288:12)\n    at readableAddChunk (_stream_readable.js:269:11)\n    at Socket.Readable.push (_stream_readable.js:224:10)\n    at TCP.onStreamRead [as onread] (internal/stream_base_commons.js:94:17)"",""code"":""42830""},""msg"":""there is no unique constraint matching given keys for referenced table \""trs\"""",""time"":""2020-01-02T13:08:20.962Z"",""v"":0}{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12022,""level"":50,""msg"":""App stopped with error there is no unique constraint matching given keys for referenced table \""trs\"""",""time"":""2020-01-02T13:08:20.965Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":30,""msg"":""Booting the application with Lisk Framework(0.1.0)"",""time"":""2020-01-02T13:08:22.523Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":30,""msg"":""Starting the app - lisk-testnet-7004"",""time"":""2020-01-02T13:08:22.524Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":30,""msg"":""Initializing controller"",""time"":""2020-01-02T13:08:22.525Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":30,""msg"":""Loading controller"",""time"":""2020-01-02T13:08:22.536Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":30,""msg"":""Old PID: 12022"",""time"":""2020-01-02T13:08:22.586Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":30,""msg"":""Current PID: 12041"",""time"":""2020-01-02T13:08:22.586Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":50,""err"":{""message"":""there is no unique constraint matching given keys for referenced table \""trs\"""",""name"":""error"",""stack"":""error: there is no unique constraint matching given keys for referenced table \""trs\""\n    at Connection.parseE (/home/lisk/.lisk/instances/lisk-testnet/node_modules/pg/lib/connection.js:554:11)\n    at Connection.parseMessage (/home/lisk/.lisk/instances/lisk-testnet/node_modules/pg/lib/connection.js:379:19)\n    at Socket.<anonymous> (/home/lisk/.lisk/instances/lisk-testnet/node_modules/pg/lib/connection.js:119:22)\n    at Socket.emit (events.js:198:13)\n    at Socket.EventEmitter.emit (domain.js:448:20)\n    at addChunk (_stream_readable.js:288:12)\n    at readableAddChunk (_stream_readable.js:269:11)\n    at Socket.Readable.push (_stream_readable.js:224:10)\n    at TCP.onStreamRead [as onread] (internal/stream_base_commons.js:94:17)"",""code"":""42830""},""msg"":""there is no unique constraint matching given keys for referenced table \""trs\"""",""time"":""2020-01-02T13:08:22.638Z"",""v"":0}
{""name"":""lisk-framework"",""hostname"":""clovis"",""pid"":12041,""level"":50,""msg"":""**App stopped with error there is no unique constraint matching given keys for referenced table \""trs\"""",""time"":""2020-01-02T13:08:22.641Z"",""v"":0}**



### Steps to reproduce
Nothing but installing new testnet node
+ few stuffs : python3, php7, sqlite, and many things that turn around

### Which version(s) does this affect? (Environment, OS, etc...)
Debian 9
lisk-testnet last version
nodejs v12.14.0
npm 6.13.4

","@ManuGowda  I have just reproduced the issue on a new machine (a laptop running Linux Mint 19), 
fresh creation of a lisk user, with nodejs 12.14, ""lisk core:install lisk-mainnet""
and the logs finished like that ... :

> {""name"":""lisk-framework"",""hostname"":""liberspirita"",""pid"":20663,""level"":50,""msg"":""App stopped with error there is no unique constraint matching given keys for referenced table \""trs\"""",""time"":""2020-01-05T17:42:36.341Z"",""v"":0}

",50873641
155,Use chalk package for coloured output in console,open,2019-12-20T15:51:47Z,2019-12-20T15:51:58Z,,CONTRIBUTOR,"### Expected behavior

The usage of coloured output should semantically correct and known to developers. Currently the coloured out put is broken in the system and not known the reason. Even not known which library was used actually for that purpose. 

https://github.com/LiskHQ/lisk-sdk/blob/6b737b961ccf952bd44337b0adbe01d34e3b95e3/framework/test/utils/http/api.js#L61

https://github.com/LiskHQ/lisk-sdk/blob/6b737b961ccf952bd44337b0adbe01d34e3b95e3/framework/test/mocha/functional/ws/transport/transport.js#L249

Check the usage of `string`.grey, its broken right now and showing `undefined; 

### Actual behavior

We should use `chalk` package for such use case as its already in chain for dev dependencies. 

```js
const chalk = require('chalk');

console.log(chalk.grey('String output'));
```

### Steps to reproduce

Run the tests and notice the output. 

### Which version(s) does this affect? (Environment, OS, etc...)

2.0
",,50873641
156,Enable continuous integration for local machine,open,2019-12-13T09:20:04Z,2019-12-13T09:20:18Z,,MEMBER,"### Description
Enable continuous integration for development on the local machine, so that developers can utilize the exact similar functionalities run on Jenkins to detect test issue upfront.
### Motivation
Currently, the sdk uses sample application for testing, which can sometimes lead to false-positive tests, as we are doing the build and link to lisk-core in a different way on Jenkins.
### Acceptance Criteria
To be able to run the exact similar Jenkins pipeline on developers' local machine.
### Additional Information
- Could be a docker container
- Could be a script ",,50873641
157,Replace controller/validator with lisk-validator,open,2019-12-06T11:07:51Z,2020-01-22T06:32:46Z,,CONTRIBUTOR,"### Expected behavior
We should use ""lisk-validator"" library consistently. We should also investigate the tests that are using validator and see if the stubbing or spying were done correctly.
## Actual behavior
During fixing issue #4026 I realized the `framework/test/jest/unit/specs/controller/helpers/validator/validator.spec.js` was giving false-positive results. 

For example, since Ajv class is being mocked and checked the beforeEach hook should like below:
![image](https://user-images.githubusercontent.com/26697004/70318205-cbc59d80-181f-11ea-8988-e0ba333af328.png)

After introducing the change above we realized the tests were not giving meaningful results since ajv itself was mocked.

Also, https://github.com/LiskHQ/lisk-sdk/pull/4603/files#diff-9d26ac4e7d17088447923c52897aa720R150 here the `validator.validate` function was stubbed, therefore try/catch statements were not throwing any error and giving false-positive results.

### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
","env and args should be parsed in the `core` and not directly in the SDK.
We mainly use it in the `components` but components was designed to be difference instance on each module.
However, setting environment variable, does not reflect that idea.",50873641
158,Chain module events miss direction,open,2019-12-04T15:53:55Z,2019-12-05T09:51:20Z,,CONTRIBUTOR,"When I subscribe to the chain module for an event such as `chain:transactions:confirmed:change`, I received the transactions as an argument, but I don't know if those transactions are newly appended or on the contrary have been _poped_.

I suggest we either add a second parameter to the event to state ""appended"" or ""poped"" (I don't like this option but it's a solution), or we add two new events to better describe what happened.

This is required to have a reliable view of blockchain evolution, otherwise we have to store a block height on the listening part, and that's dirty work.

I'm writing a PR for this.","I agree that this is definitely an issue, and it is raised as an issue already https://github.com/LiskHQ/lisk-sdk/issues/3863.
In order to tackle this problem, we want to have a consistent approach throughout the chain module.
Since this would be a big topic, I would suggest posting your idea to issue #3863 

I think the main events that everyone would be interested are
- addition/deletion of block
- update on accounts
- update on chain state (delegate list, finality, etc)
- addition/deletion of transactions from the pool

If we can define the consistent naming for these events, which can be extended for the future use-cases, that would be great",50873641
159,REST API to get unconfirmedBalance,open,2019-12-04T15:13:59Z,2020-02-08T14:58:55Z,,NONE,"### Description

Is there an API to get unconfirmed balance or unconfirmed txs given a wallet address?
","From the Lisk-Core API, we don't currently support to get the unconfirmed balance, but you can get the unconfirmed transactions",50873641
160,Make use of getters across P2P classes ,open,2019-12-04T10:47:09Z,2020-01-20T15:57:36Z,,NONE,"### Expected behavior

Read using getters: `this.id`.

### Actual behavior
Instead of using getters which are more syntactic sugar and prevent data mutations, variables are being read directly `this._id` without using the existing getters or creating them.

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
161,Keep P2P advertiseAddress parameter just in P2PSharedState,open,2019-12-04T10:42:43Z,2020-01-20T15:57:21Z,,NONE,"### Expected behavior

There are no duplicate parameters inside different interfaces.

### Actual behavior

`advertiseAddress` is present in three different interfaces: `P2PSharedState`, `P2PInternalState` & `P2PNodeInfo`.

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
162,Remove unused node info argument from P2P peer selection functions,open,2019-12-04T10:38:01Z,2020-01-20T15:55:10Z,,NONE,"### Expected behavior
 Just the needed data is passed to the P2P peer selection functions.

### Actual behavior
```
export interface P2PPeerSelectionForSendInput {
	readonly peers: ReadonlyArray<P2PPeerInfo>;
	readonly nodeInfo?: P2PNodeInfo;
	readonly peerLimit?: number;
	readonly messagePacket?: P2PMessagePacket;
}
```

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
163,Rename redundant objects inside P2P PeerLists interface,open,2019-12-04T10:33:47Z,2020-01-20T15:55:18Z,,NONE,"### Expected behavior
```
export interface PeerLists {
	readonly blacklisted: ReadonlyArray<P2PPeerInfo>;
	readonly seeds: ReadonlyArray<P2PPeerInfo>;
	readonly fixed: ReadonlyArray<P2PPeerInfo>;
	readonly whitelisted: ReadonlyArray<P2PPeerInfo>;
	readonly previous: ReadonlyArray<P2PPeerInfo>;
}
```

### Actual behavior
```
export interface PeerLists {
	readonly blacklistedPeers: ReadonlyArray<P2PPeerInfo>;
	readonly seedPeers: ReadonlyArray<P2PPeerInfo>;
	readonly fixedPeers: ReadonlyArray<P2PPeerInfo>;
	readonly whitelisted: ReadonlyArray<P2PPeerInfo>;
	readonly previousPeers: ReadonlyArray<P2PPeerInfo>;
}
```

### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
164,Avoid redundant wording related to P2P peers,open,2019-12-04T10:30:00Z,2019-12-04T11:11:08Z,,NONE,"### Expected behavior

`peer.info.id`

### Actual behavior

`peer.peerInfo.peerId`

### Which version(s) does this affect? (Environment, OS, etc...)
`3.0`
",,50873641
165,Move common synchronizer logic from utils to Base Synchronizer,open,2019-11-21T10:38:04Z,2020-01-07T14:00:14Z,,CONTRIBUTOR,"### Description

Functions that are un `synchronizer/utils.js` and use external modules should be moved to Base Synchronizer

### Motivation

It makes no sense to have util functions that accept external modules as arguments while we can have this logic in Base Synchronizer shared to our two custom syncing mechanisms

### Acceptance Criteria

Please describe the conditions which must be met for this issue to close

### Additional Information
",,50873641
166,Hide asset property in the Account entity,open,2019-10-22T10:23:13Z,2019-10-22T10:23:36Z,,CONTRIBUTOR,"### Description
Adapt the Storage account entity interface in order to hide the `asset` field from the user.

### Motivation
Storage account entity exposes the property `asset` as an object that allows users to add any custom property that is required to its use case. This is confusing because users can modify not only the `asset` property but any other property in the account like `balance`, `voteWeight` or `username`.

My suggestion is to abstract the `asset` property hiding it from the user and allowing them to add any property to accounts directly - see example bellow.


**Current way:**
```js
account.asset.myProperty = 42
```

**Proposed way:**
```js
account.myProperty = 42
```

PS: Internally the Storage component would still save the custom property in the `asset` field to avoid the need of migrations.

### Acceptance Criteria
--

### Additional Information
--",,50873641
167,Network reward milestones are not respected,open,2019-10-20T13:47:34Z,2019-10-20T14:14:18Z,,NONE,"### Expected behavior
Network reward milestones should work as it is configurable

### Actual behavior
They are not, in case of rewards=0, after 2160 height, lisk-sdk ignores milestones and
2161 -> 4 reward
2162 -> 3 rewrad
2163 -> 2 rewrad
2164 -> 1 rewrad
and continue with 1.0


### Steps to reproduce
```
""genesisConfig"": {
			""EPOCH_TIME"": ""2019-04-24T17:00:00.000Z"",
			""BLOCK_TIME"": 5,
			""MAX_TRANSACTIONS_PER_BLOCK"": 25,
			""REWARDS"": {
				""MILESTONES"": [
					""0""
				],
				""OFFSET"": 2160,
				""DISTANCE"": 1
			}
		}
```

""OFFSET"": 1000000000
Seems to resolve issue, but this is rather workaround.

### Which version(s) does this affect? (Environment, OS, etc...)
2.3.6",,50873641
168,New node stop syncing at random height,open,2019-10-20T13:42:22Z,2019-11-04T20:55:35Z,,NONE,"### Expected behavior
new nodes should sync correctly

### Actual behavior
After random height, once after genesis, the other time after block 397. Network stops syncing with error
```13:27:54.796Z  INFO lisk-framework: New block added to the chain (id=9532106455191400736, height=392, numberOfTransactions=0)
13:27:54.805Z  INFO lisk-framework: New block added to the chain (id=496901711939001301, height=393, numberOfTransactions=0)
13:27:54.819Z  INFO lisk-framework: New block added to the chain (id=1249316716971551678, height=394, numberOfTransactions=0)
13:27:54.847Z  INFO lisk-framework: New block added to the chain (id=5458066552637902604, height=395, numberOfTransactions=0)
13:27:54.857Z  INFO lisk-framework: New block added to the chain (id=771116527980923729, height=396, numberOfTransactions=0)
13:27:54.866Z  INFO lisk-framework: New block added to the chain (id=8798900519954779906, height=397, numberOfTransactions=0)
13:27:54.942Z  WARN lisk-framework: Failed to load blocks from the network. (error={})
13:27:54.985Z  WARN lisk-framework: Failed to load blocks from the network. (error={})
13:27:55.026Z  WARN lisk-framework: Failed to load blocks from the network. (error={})
13:27:55.071Z  WARN lisk-framework: Failed to load blocks from the network. (error={})
13:27:55.113Z  WARN lisk-framework: Failed to load blocks from the network. (error={})
13:27:55.117Z  INFO lisk-framework: Finished sync
13:27:55.123Z  WARN lisk-framework: Discarded block that does not match with current chain (blockId=15856048681864149412, height=11049, round=2210, slot=3090573)
    generatorPublicKey: 0013bd00bf42a31be2962bc3c3bd3cd2872373ec863bc05ffa6e945da4254b83
13:27:55.257Z  INFO lisk-framework: Peer connect event: Connected to peer 77.55.217.232:5000
13:27:55.261Z  INFO lisk-framework: Peer connect event: Connected to peer 178.19.176.23:5000
13:27:55.943Z  WARN lisk-framework: Discarded block that does not match with current chain (blockId=7142463097950476978, height=11051, round=2211, slot=3090575)
    generatorPublicKey: bb33fc1a19cfbda689f7941fffa34badf16e75348d6dd16833298f774d11f3bf

```

### Steps to reproduce
run ldice app node
https://github.com/thepool-io/ldice
for more info join https://discord.gg/XWMmS8X

### Which version(s) does this affect? (Environment, OS, etc...)
lisk-sdk 2.3.6",Also experiencing this. Seems related to changing asset with a module using the database connector.,50873641
169,Result of computation in the transaction field,open,2019-10-01T17:26:56Z,2020-01-31T09:41:43Z,,NONE,"### Description
Ability to store results in the **asset** field of transaction, without invalidating signature check of base transaction.

### Motivation
There are use-cases where it would be beneficial to store result of computation directly in, let's say **asset_results** field, which would not be part of transaction body verification.

At this moment, anything set to the asset property of transaction will result in verification issue. Workaround for this, is to store, something like **transaction_results** in account asset and allocate objects to **tx_id** key, however I'm not sure that would be efficient with thousands of transactions.",,50873641
170,Rename database table names,open,2019-10-01T12:53:23Z,2020-02-03T15:43:42Z,,CONTRIBUTOR,"### Description
We should rename the tables to have more clear names.

Also, tables should not have prefix `temp`  if the data there is important for the node.

### Motivation

Some of the table names are misleading in the database.

### Acceptance Criteria

- `mem_accounts` to `accounts`
- `trs` to `transactions`
- Find a better name for `temp_block` table.
### Additional Information
",,50873641
171,Update config for test_app fixtures for block version,open,2019-09-23T09:12:57Z,2019-09-23T09:13:15Z,,CONTRIBUTOR,"### Description
Related to #4287, start and end of v1 is defined, but it needs to be changed when we plan to migrate testnet and mainnet.

https://github.com/LiskHQ/lisk-sdk/pull/4287/files#diff-3bad3d13cb08c993be38aa1f548e7399R137
https://github.com/LiskHQ/lisk-sdk/pull/4287/files#diff-f625ab0c83a7174960405b8d052dbdd1R66

Most likely it will be defined in the core first, but we need to back port it for the testing purpose.

### Acceptance Criteria

Match the start and end of the v1 with core.

### Additional Information
First implemented in #4287
",,50873641
172,Advanced test coverage related to active peer management,open,2019-09-19T12:52:26Z,2020-02-03T15:43:42Z,,CONTRIBUTOR,"### Description

More tests are needed to verify that peer management is working under unusual scenarios.
Some things to check (note that this is not an exhaustive list):

- Verify that a peer cannot affect a node's connectivity to other neighbouring peers within the peer pool (e.g. other peers inside _peerMap of a node).
- Verify that the maximum number of peers present in the _peerMap at any given time is always less than or equal to `maxOutboundConnections` + `maxInboundConnections`.
- Verify that a single peer (defined as a unique ipAddress/wsPort combination) can only ever create a single record within a node's _peerMap (no duplicates under any situation).
- Verify that every connected peer is always present in the _peerMap (make sure that peers are always tracked).

Note that this issue is only concerned with active peers inside the PeerPool and not the PeerBook.

Potentially related issue: https://github.com/LiskHQ/lisk-sdk/issues/4279

### Motivation

Active peer management is a complex feature which requires more thorough testing.

### Acceptance Criteria

- The test cases cover advanced or malicious scenarios like the ones described above.
- The goal of this issue is not to add test cases to verify obvious functionality. The tests should aim to uncover flaws. They need to focus on edge cases.
",,50873641
173,Advanced test coverage related to rate limiting and banning,open,2019-09-19T12:39:51Z,2020-02-03T15:43:42Z,,CONTRIBUTOR,"### Description

More tests are needed to verify that banning related to rate limiting is working under unusual scenarios.
Some things to check (note that this is not an exhaustive list):

- Verify that the rate limit is reasonable and has no false positives or false negatives when it comes to disconnecting and banning.
- Verify that ban is lifted after a reasonable amount of time.

### Motivation

Rate-limiting is a complex feature which requires more thorough testing.

### Acceptance Criteria

- The test cases cover advanced or malicious scenarios like the ones described above.
- The goal of this issue is not to add test cases to verify obvious functionality. The tests should aim to uncover flaws. They need to focus on edge cases.
",,50873641
174,Move stub definitions and expectations to a common place for unit & integration tests,open,2019-09-17T08:38:41Z,2020-02-03T15:43:42Z,,CONTRIBUTOR,"### Description

Unit tests should import and use arguments and return values for `whenCalledWith`, `mockReturnValue`, `mockResolveValue` functions from a central folder.

Integration tests should also use the same arguments and expectations to make sure all protocols for I/O connectors were tested.

### Motivation

With the new testing strategy, we are only mocking the I/O connectors. But since unit tests and integration tests are structured separately, It's hard to keep track of what's being mocked and what was integration tested. 

So, by moving expectations into a single folder and by adding that folder to code coverage reports we can keep track of which mocks were integration tested.
### Acceptance Criteria
- unit tests stub definitions must come from a central folder
- integration test expectations must come from that central folder as well.
- central folder must be added to the coverage report for unit & integration test.
- Address these comments: https://github.com/LiskHQ/lisk-sdk/pull/4269#discussion_r326185417, https://github.com/LiskHQ/lisk-sdk/pull/4269#discussion_r326176689
### Additional Information
",,50873641
175,Add unit test coverage for main P2P file,open,2019-09-09T10:30:51Z,2020-02-03T15:43:43Z,,NONE,"### Expected behavior

Every file from `lisk-p2p` library is well covered with unit test. The minimum must be 80% at least to achieve green reports.  

### Actual behavior

`p2p.ts` counts with only  44 %.

### Steps to reproduce

`npm t`

### Which version(s) does this affect? (Environment, OS, etc...)

`+2.3`",,50873641
176,Update unit tests for delegates/api,open,2019-08-30T14:11:10Z,2020-02-03T15:43:43Z,,CONTRIBUTOR,"### Expected behavior
We should follow the new testing guidelines and make sure to test public interfaces instead of privately defined methods. Currently, only private methods are tested which is quite pointless.

File affected: `framework/test/mocha/unit/modules/http_api/controllers/delegates.js`
This file still uses rewire and Mocha, would be nice to avoid rewire and rewrite with Jest.

### Which version(s) does this affect? (Environment, OS, etc...)
`feature/improve-bft` or `development`",,50873641
177,Lisk Client for browser,open,2019-08-27T15:55:12Z,2019-08-27T16:30:06Z,,CONTRIBUTOR,"Currently the Lisk Client export a version for NodeJS and for browsers. This causes a lot of problems while developing into a browser, the main reason being the default version is the NodeJS one, so we have to suffix `/dist-browser`, but even doing this we end up with errors.

One of the error I get :

`The package at ""node_modules/cipher-base/index.js"" attempted to import the Node standard library module ""stream"". It failed because React Native does not include the Node standard library.`

So please make a browser only package so we can import stuff safely.",This issue is related to #3348 ,50873641
178,Move block processor registration to controller,open,2019-08-23T15:55:49Z,2019-08-23T15:55:49Z,,CONTRIBUTOR,"### Description
Currently, processor.register happens on `chain.js` in chain module, but similar to custom transaction, there should be a way to register processor outside of the application.

### Motivation

We want to provide a way for SDK user to change the way of block processing works.

### Acceptance Criteria

- Block version 0 and block version 1 should be registered from outside of SDK",,50873641
179,Lisk Commander create & broadcast,open,2019-08-19T22:20:31Z,2019-08-20T05:38:26Z,,CONTRIBUTOR,"It would be great to have a shortcut to create and directly broadcast the transaction.

```bash
$ lisk transaction:create:transfer --broadcast 100 5051428441069691191L
$ lisk transaction:create:transfer -b 100 5051428441069691191L // Shorthand
```

Piping is just a waste of time 😄",,50873641
180,Lisk Commander aliases,open,2019-08-19T22:16:03Z,2019-08-20T05:38:05Z,,CONTRIBUTOR,"When you want to manually test some scenario during the dev process, it would be great to be able to replace addresses by aliases.

Those aliases would be set in a `.lisk-commander` file for exemple.

```js
{
    account1: { /* account data, copy/paste from the lisk account:create command */},
    account2: { /* another account */ },
   ""@default"": { /* this is the default account, if I press enter without any input */ }
}
```

Then you can use them into more interactive modes :

```bash
$ lisk transaction:create:transfer 100 @account1
```

The prompt will ask for the passphrase, you write `@account2`, select from a list, or simply press enter to use the default account.

You could also make an extra param for `lisk account:create --save myAlias`which would save the account into `.lisk-commander`",,50873641
181,Lisk Commander create custom transaction,open,2019-08-19T22:03:03Z,2019-08-20T05:37:21Z,,CONTRIBUTOR,"Currently the CLI allow us to create core transactions.
It would be great if not mandatory to create custom transactions from CLI, mostly for dev purpose.

It would require an extra method such as :

```js
getCliArguments() {
    return [ ...super.getCliArguments(), 'myOption1', 'myOption2'] // Each argument is then mapped to the transaction asset object
}
```


Then 

`$ lisk transaction:create --type=42 0 myOption1Value myOption2Value 13356260975429434553L`",,50873641
182,Superfluous use of promises,open,2019-08-15T15:22:02Z,2019-08-16T17:11:47Z,,CONTRIBUTOR,"https://github.com/LiskHQ/lisk-sdk/blob/a800c3217e50a94c5e865febd0240ddd834dfb3c/framework/src/modules/chain/blocks/blocks.js#L231

This entire piece:

```js
const { blocksCount, genesisBlock, memRounds } = await new Promise(
    (resolve, reject) => {
        this.storage.entities.Block.begin('loader:checkMemTables', async tx => {
            try {
                const result = await blocksUtils.loadMemTables(this.storage, tx);
                resolve(result);
            } catch (error) {
                reject(error);
            }
        });
    },
);
```

Can be just this:

```js
const { blocksCount, genesisBlock, memRounds } =
    await this.storage.entities.Block.begin('loader:checkMemTables', tx => blocksUtils.loadMemTables(this.storage, tx));
```

And the result will be identical.
","@vitaly-t It is returning the `new Promise` and expecting the value from `resolve` or `reject`. Syntax was it's misleading and not good, but it should be ok.

Also, the reason is consistent return from eslint (where if we use `return` for `reject`, `resolve` should return too`",50873641
183,Commander core commands for remote node(s) ,open,2019-08-11T14:18:41Z,2019-08-11T17:03:31Z,,NONE,"### Description
It would be nice if all the commander core commands (install, status, upgrade, etc...) could not only be used on the local node, but also for remote nodes. It would be even better if multiple nodes could be managed at the same time with one single command (eg lisk core:upgrade node1 node2 node3) 

### Motivation
It would be useful for delegates to manage their nodes, and also for developers who want to set up their own little testbed with multiple nodes. Tjey could install, upgrade and monitor multiple nodes from a single management machine. 

### Acceptance Criteria
### Additional Information
",,50873641
184,Block creation logic extension,open,2019-08-06T15:59:36Z,2019-09-25T20:13:30Z,,NONE,"### Description

Ability to extend block generation logic in similar fashion to custom transactions.

### Motivation

Execute specific code, each X blocks. For example dividend distribution in case of autonomous companies.

### Acceptance Criteria

Ability to extend block creation logic, modifying account balances should be doable from that scope.

### Additional Information
N/A","I'd like to see that functionality too. I think it would allow a lot more use cases. One could be to run some code on every block creation. This would allow to execute automatic code (like a cronjob, executed every 10 sec) and would make the business logic independent from sent transactions (if needed). Such functionality is not present in other chains like for example Ethereum and could be a big advantage for Lisk ",50873641
185,Strongly-typed events,open,2019-08-05T16:45:33Z,2019-08-06T15:41:10Z,,CONTRIBUTOR,"In relation to #3908, #3904, #3827 and #3539, plus general TypeScript makeover...

I was recently struggling with events in my own project, and ended up writing [my own module](https://github.com/vitaly-t/sub-events) to handle events, in case it is of any interest here.

Since you are transforming into TypeScript, strongly-typed events is a must-have.
","[v0.7.0] added very useful [diagnostics], to help counter memory leaks and performance degradation.

[v0.7.0]:https://github.com/vitaly-t/sub-events/releases/tag/0.7.0
[diagnostics]:https://github.com/vitaly-t/sub-events/wiki/Diagnostics
",50873641
186,Enable ESLint rule to require usage of `use strict`,open,2019-07-22T13:47:28Z,2020-02-03T15:43:43Z,,CONTRIBUTOR,"### Expected behavior
`ESLint` should require `use strict` to be written in the top of a file.

To achieve this, this ESLint rule has to be enabled: https://eslint.org/docs/rules/strict?origin_team=T3CBPJ17X

### Actual behavior
We are not checking whether files are making use of the `use strict` statement.
### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
`*`",,50873641
187,Add eslint-plugin-notice,open,2019-07-22T13:30:46Z,2019-07-22T13:30:46Z,,CONTRIBUTOR,"### Expected behavior
Each file should have a copyright notice and we must ensure this with static checks.

See: https://github.com/nickdeis/eslint-plugin-notice 
### Actual behavior
We don't have a eslint rule that ensures this.
### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
188,StorageSandbox is using actual DB connection in Unit tests,open,2019-07-17T08:42:02Z,2020-02-03T15:43:43Z,,CONTRIBUTOR,"### Expected behavior
There shouldn't be db connections in unit tests.
### Actual behavior
StorageSandbox class is trying to connect to the database. and pg instance is not running tests are failing.
### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
189,Improve the blocks and processing tests to have more declarative expectations,open,2019-07-12T11:39:20Z,2019-07-12T11:39:29Z,,CONTRIBUTOR,"### Expected behavior

We introduced new integration test for blocks and transactions processing. `framework/test/mocha/integration/blocks/blocks_and_transactions.js`. 

These tests should be improved to have more declarative expectations.

```js
expect(bat.getTransactionsInLastBlock()).to.deep.equal(
					[valid_trs1, valid_trs2]
				);
```

### Actual behavior

Currently we are have a logic encapsulated in a helper which generates the valid expectations. on runtime. Which is good for given scenario, but if we can refactor and have more declarative expectations that will be great. 

```js
expect(bat.getTransactionsInLastBlock()).to.deep.equal(
					bat.getValidSortedTransactions()
				);
```


### Which version(s) does this affect? (Environment, OS, etc...)
2.x",,50873641
190,Introduce semantic versioning for custom transaction compatibility check,open,2019-07-08T10:54:29Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Expected behavior
There must be a well defined pattern to communicate, document and explain to users about the interface for the custom transaction. And to distinguish between different breaking changes. This should also cover the scenario if user is using `lisk-transactions` package directly to create their transaction and not using `lisk-sdk` or `lis-framework`. 

So the suggestion is to add a static versioning number to the `BaseTransaction` which can be accessed by `BaseTransaction.version`. So once you register a particular transaction with the app through `app.registerTransaction`, framework can identity the version and match agains the version compatible to the framework. This `version` must follow semantic versioning, then it will be easy to identify and communicate the breaking changes. 

We can or not link this version to the package version of `lisk-transactions`, based on the definition of what is exported from the `lisk-transactions`. If there are utility functions then its not possible and we have to introduce different version for BaseTransaction. 

This will also help us to document the custom transaction interface in our docs and also communicate on different developer forums. And when we introduce any breaking change, we can refer back/forth to those documentations. 

### Actual behavior
Currently we are just matching public functions names on the transaction class and there is no way to communicate to users about breaking changes in that interface for future. 

### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)",,50873641
191,Use rimraf instead of rm,open,2019-07-08T06:32:06Z,2019-07-08T07:34:09Z,,CONTRIBUTOR,"### Expected behavior
I know we don't officially support windows but still we can make it a bit easier to developers who have to use windows machines occassionally :D

In `package.json` of lots of subpackages like `lisk-api-client`, `lisk-p2p`, we are using `rm` command. Would be great if we could replace it with `rimraf`.
### Actual behavior
We are using rm commands which is not working on windows and prevents **building** packages.
### Steps to reproduce
Run `npm run build` command on the root directory of the probject on windows machines.
### Which version(s) does this affect? (Environment, OS, etc...)
","Just a side note for windows developers, to be able to setup project properly they'll need to run terminal in administrator mode and make sure `core.symlinks` is set to true. Otherwise run `git config core.symlinks ""true""` before cloning.",50873641
192,Validate each transaction property with its own method,open,2019-07-03T08:27:15Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Expected behavior

Each transaction property has its own validator (this was a suggestion by Lucas/Nazar in #3893)

### Actual behavior

We have a single validate method that uses some methods for some properties

### Steps to reproduce

Check the `validate()` method in baseTransaction.

### Which version(s) does this affect? (Environment, OS, etc...)
2.1","Currently we have the following validations inside `BaseTransaction.validate()`:
```
validateSchema()
validateAsset()
validateSignature()
validateTransactionId()
validateFee()
```
Being able to overwrite a particular one is a nice feature imo",50873641
193,Misleading validation function name,open,2019-07-02T09:35:06Z,2020-01-07T13:48:27Z,,CONTRIBUTOR,"### Expected behavior
Expect the `isValidNumber` function inside `lisk-transactions` to return `true` when `isValidNumber('-1')`

Also expect to have tests for `isValidNumber` function.

### Actual behavior
Currently it returns `true` for `isValidNumber(-1)` but returns `false` for `isValidNumber('-1')`.
This is happening because `isValidNumber` uses `isNumberString` which has a regex allowing only `0-9` numbers.

### Steps to reproduce
```
const { isValidNumber } = require('./validation.ts');

isValidNumber('-1'); //? false
```

### Which version(s) does this affect? (Environment, OS, etc...)
2.*

### Addional Information
- isValidNumber is used to check only the positive number now, so the naming should be isValidPositiveNumber",,50873641
194,Introduce error codes to act and debug easily through out the system,open,2019-07-01T14:45:40Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Actual behavior

Currently we are using different error constructors to identify the right error occurred in the system. That helps to not just identify error but also helps in debugging. 

But with growing system we may end up in huge list of such error constructors, which will decrease on boarding to message. 

https://github.com/LiskHQ/lisk-sdk/blob/fa29121e93e5369cfeaf671480d740e3e78824ef/framework/src/errors.js#L34

https://github.com/LiskHQ/lisk-sdk/blob/fa29121e93e5369cfeaf671480d740e3e78824ef/framework/src/errors.js#L50

https://github.com/LiskHQ/lisk-sdk/blob/fa29121e93e5369cfeaf671480d740e3e78824ef/framework/src/errors.js#L69

https://github.com/LiskHQ/lisk-sdk/blob/fa29121e93e5369cfeaf671480d740e3e78824ef/framework/src/modules/chain/bft/errors.js#L29

https://github.com/LiskHQ/lisk-sdk/blob/fa29121e93e5369cfeaf671480d740e3e78824ef/framework/src/modules/chain/bft/errors.js#L37

### Expected behavior
So we need to reduce the error constructors and have few very generic ones. And also we don't want to handle all cases by long error messages, that usually end up in regular expression matching on error messages if you want to check of couple of cases. 

I suggest to introduce error codes with generic error constructors. That would be easy to know small set of generic error constructors as well extensible to define different error codes to pin point the right error case. 

### Which version(s) does this affect? (Environment, OS, etc...)
3.0.0",,50873641
195,httpPort and wsPort can not change using Lisk Commander 2.2.0,open,2019-06-28T10:06:42Z,2019-06-28T11:54:17Z,,NONE,"### Expected behavior

1. Install [lisk commander 2.2.0]
2. Install Lisk 2.2.0-rc0 on testnet using the following command
```
lisk core:install -n testnet lisk-testnet
```
3. Execute the following command.
httpPort : 7002, wsPort   : 7003
```
lisk core:status lisk-testnet
```
![lisk-commander-port](https://user-images.githubusercontent.com/14948578/60334568-cc3b4c00-99d6-11e9-8b78-8d92b5309677.png)

4. The default value of testnet is
httpPort : 7000, wsPort   : 7001

  **so,I want to change those value to default one.**

5.  lisk config:set command not support [http_api.httpPort] and [network.wsPort]

```
test@lisk99:~/.lisk/instances/lisk-testnet/config/testnet$ lisk config:set --help
USAGE
  $ lisk config:set VARIABLE [VALUES]

OPTIONS
  -j, --[no-]json  Prints output in JSON format. You can change the default behaviour in your config.json file.

  --[no-]pretty    Prints JSON in pretty format rather than condensed. Has no effect if the output is set to table. You can change the default
                   behaviour in your config.json file.

DESCRIPTION
  Sets configuration.
                ...
                Variables available: api.nodes, api.network, json, pretty.

EXAMPLES
  config:set json true
  config:set api.network main
  config:set api.nodes https://127.0.0.1:4000,http://mynode.com:7000

test@lisk99:~/.lisk/instances/lisk-testnet/config/testnet$
```

### Actual behavior

I want to change those value to default one.

---
It seems to need fix for two problems.

 - [lisk config:set] command should be support [http_api.httpPort] and [network.wsPort]
 - Change the default value to [httpPort7000,wsPort7001] when installing lisk core with lisk commander.

### Steps to reproduce

Same the Expected behavior

### Which version(s) does this affect? (Environment, OS, etc...)

Lisk core : Testnet Lisk 2.0.0-RC0 
Lisk commander : 2.2.0
",,50873641
196,Lisk Hub / Lisk Mobile should always connect,open,2019-06-27T19:55:57Z,2019-06-28T07:31:51Z,,NONE,"If you choose ""Mainnet"" or ""Testnet"" in Lisk Hub it should always connect. In the past days several users claimed that nodes were offline. Lisk Hub should always pick only nodes that are online, so users never see ""failed to connect"" again. The current ""lottery""-system is bad.

I was told that this seem to be a problem with Lisk Elements.

",,50873641
197,Refactor the interface for state store for better developer experience,open,2019-06-26T08:54:05Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"Currently we have following interfaces for the state_store. 

1. async cache(filter)
2. createSnapshot()
3. restoreSnapshot()
4. get(primaryValue)
5. getOrDefault(primaryValue)
6. find(fn)
7. set(primaryValue, updatedElement)
8. finalize()

Here is some feedback we can improve; 

1. This store is exposed to transaction with mindset that user will only use `cache `, `get`, `getOrDefault`, `set` and `find`. So we must make all other interfaces private (only by convention) so people know they can't call `finalize` or other. 
2. We should rename `cache` to `getAndStoreToCache` or similar to match its behaviour. Original name `cache` is confusing which refers to get data from cache. 
3. `finalize` meant to return a Promise, it can be declared as `async` to make it clear. 

### Which version(s) does this affect? (Environment, OS, etc...)
2.1.0","The state_store and the issue itself refers to the framework not the elements. If you identity similar problems no matter in framework or element, please create issues for those so we can plan to improve those. ",50873641
198,Allow SDK developers to provide a custom peerSelectionForConnection function,open,2019-06-26T08:07:04Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Expected behavior

The SDK developer should be able to provide a custom `peerSelectionForConnection` function to their node to easily customise peer selection.
The use case is to allows efficient feature-matching between peers. In our case, we would like to offer optional feature-matching based on what modules are available on peers.

### Actual behavior

Right now there is no clean way for SDK developers to provide a custom `peerSelectionForConnection` function to the node (only with a hack).

### Which version(s) does this affect? (Environment, OS, etc...)

2.3
",,50873641
199,Revisit all events and action names in the code base,open,2019-06-26T08:07:01Z,2019-10-07T09:37:49Z,,CONTRIBUTOR,"### Expected behavior
The event names and constants must be very well defined and follow same naming convention. 

### Actual behavior

Currently there is a mix of convention used in the code. 

```js
const EVENT_NEW_BLOCK = 'EVENT_NEW_BLOCK';
const EVENT_DELETE_BLOCK = 'EVENT_DELETE_BLOCK';
const EVENT_BROADCAST_BLOCK = 'EVENT_BROADCAST_BLOCK';
const EVENT_NEW_BROADHASH = 'EVENT_NEW_BROADHASH';

export const EVENT_ADDED_TRANSACTIONS = 'transactionsAdded';
export const EVENT_REMOVED_TRANSACTIONS = 'transactionsRemoved';
export const EVENT_VERIFIED_TRANSACTION_ONCE = 'transactionVerifiedOnce';
export const ACTION_ADD_VERIFIED_REMOVED_TRANSACTIONS = 'addVerifiedRemovedTransactions';
export const ACTION_REMOVE_CONFIRMED_TRANSACTIONS = 'removeConfirmedTransactions';
export const ACTION_ADD_TRANSACTIONS = 'addTransactions';
export const ACTION_EXPIRE_TRANSACTIONS = 'expireTransactions';
export const ACTION_PROCESS_VERIFIED_TRANSACTIONS = 'processVerifiedTransactions';
export const ACTION_VALIDATE_RECEIVED_TRANSACTIONS = 'validateReceivedTransactions';
export const ACTION_VERIFY_VALIDATED_TRANSACTIONS = 'verifyValidatedTransactions';
export const ACTION_ADD_VERIFIED_TRANSACTIONS = 'addVerifiedTransactions';
export const ACTION_ADD_PENDING_TRANSACTIONS = 'addPendingTransactions';
```

I would suggest following pattern `{EVENT|ACTION}_{ENTITY}_{ACTIVITY}`. Where every event/action prefix with `EVENT` or `ACTION` and the entity on which event happens e.g. block, transaction, signature and then actual activity which happens e.g. new, delete. 

### Which version(s) does this affect? (Environment, OS, etc...)
2.1.0","Thanks, @nazarhussain. I think this is a good improvement proposal and will ease further development/improve consistency in the codebase. 
Extending what @michielmulders has commented, it might be also positive to add a third component: `{STATUS}`. Maybe not for the scope of this issue but it can be taken into account.

For example: `blocks:process:succeeded`.

`{STATUS}` could be one of the following: `STARTED|FAILED|SUCCEEDED`.

Note that if we are using the `channel` we don't necessarily need to prefix event names with `event` as there is a known interface for receiving only events, you can't subscribe for actions by mistake. If we decide to keep using EventEmitter then it's a different scenario.

Improving the naming convention for consistency could open the door for use cases like the following, where not only Chain module would benefit but also other modules developed by the community:

![image](https://user-images.githubusercontent.com/7485885/60164137-5334cc80-97fd-11e9-9a96-ccf0d7443896.png)





",50873641
200,Follow common developer approach for error handling in transactions,open,2019-06-26T07:32:45Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"From start we are targeting and speaking about our Lisk SDK, is the first of its kind in JavaScript that will make blockchain accessible to everyone. 

With that said, we should keep in mind that developers with different experience levels and even very beginners will also work with our SDK. So we should keep in mind the common developer approach to write program. 

Or easy to say we should not neglect basic language patterns which every one is familiar of. One of that is `if you have error throw it`. This is very common for developers and they must be familiar and doing this a lot in other projects, which is the user of `throw`. 

Current transaction processing logic does not allow you to throw error, rather we enforce a pattern to collect errors and return as array object from transaction steps `apply` and `undo`. Which could be an additional behaviour for our transaction processing, but we should not neglect the user of `throw` as its very basic language struct. 

We should refactor the processing logic to handle all of below given scenarios; 

```js
apply(store) {
  if(some_condition) {
     throw new Error('Some error in validation.') ;
  }
}
```

```js
apply(store) {
  if(some_condition) {
     return new Error('Some error in validation.') ;
  }
}
```

```js
apply(store) {
  const errors = [];
  if(some_condition) {
     errors.push(new Error('Some error in validation.')); 
  }
  return errors; 
}
```

This also relates to the fact that `enforcing a return value even empty array`, is also against the Javascript paradigm. Yes its an integral concept of functional programming, but our SDK is not here to enforce people to learn functional programming. They should be able to use the Javascript the way they are already doing.  

### Which version(s) does this affect? (Environment, OS, etc...)
2.1.0","@shuse2 I see @nazarhussain 's point that throwing is easier to understand and intuitive for developers of custom transactions. However I feel most custom transaction users will benefit from seeing all the validation errors at once, as opposed to one-by-one. Enforcing returned error array at the end ensures we won't have this bad user experience.",50873641
201,"Rename transaction steps to ""apply"" and ""undo""",open,2019-06-26T07:20:52Z,2019-07-09T07:42:06Z,,CONTRIBUTOR,"The `Transaction` interface is the primary and major interaction for most of the Lisk SDK Developers. So the interfaces presented there must be generic and easy to understand specially without detail explanations. 

Currently we have the transaction steps `prepare`, `applyAsset` and `undoAsset`. These are the three interfaces which everyone have to implement for any custom transaction. The first step `prepare` seems straight forward to understand what it would be. But for next two steps `applyAsset` and `undoAsset` we are mixing up a complete concept **Asset** there, while the steps are not just mutate asset also can change non-asset attributes as well. And with that concept, people can get confused if its the asset of account or asset of transaction. 

So we need to rename those steps to particular verbs, that will make them easy to read and understand the transaction interface, as well to explain.

```js
class MyTransaction extends BaseTransaction {
   prepare(store) {}
   apply(store) {}
   undo(store) {}
}
```

### Which version(s) does this affect? (Environment, OS, etc...)
2.1.x","What about rename it to `applyState`?
Or if one want to be more specific, `applyAccountState`?",50873641
202,Use channel instead of event emitter,open,2019-06-17T07:23:45Z,2019-07-03T16:25:25Z,,CONTRIBUTOR,"### Expected behavior
Within module, it should consistently use channel instead of event emitter.
Event emitter can handle internal events within modules too.

### Actual behavior
Event emitter was used when removing `bus`

### Which version(s) does this affect? (Environment, OS, etc...)
2.2-",Let's remember to have into account potential cases described in https://github.com/LiskHQ/lisk-sdk/issues/3539 ,50873641
203,Cleanup lisk-validator,open,2019-06-14T14:40:25Z,2019-07-29T09:23:53Z,,CONTRIBUTOR,"### Expected behavior

usage of inline vs imported callbacks is consistent 

### Actual behavior

Some formats are defined as functions in ./validation, some as inline functions in this file. We should use a consistent approach.

### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
204,For schemaId use $id instead of id,open,2019-06-14T13:20:34Z,2019-07-29T09:24:36Z,,CONTRIBUTOR,"### Expected behavior

- `$id` is used in schemas
- schemaId in the Ajv configuration uses `$id` instead of `auto`

### Actual behavior

- `id` is used in schemas
- schemaId in the Ajv configuration uses  `auto` instead of `$id`

### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
205,Improve validator in framework to separate default and validation,open,2019-06-12T15:39:31Z,2019-06-12T15:53:45Z,,CONTRIBUTOR,"### Expected behavior
TBD

### Actual behavior

### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
206,Log framework migration process,open,2019-05-23T08:55:54Z,2020-02-03T15:43:43Z,,CONTRIBUTOR,"### Expected behavior
When the Controller loads the migrations in `_loadMigrations` method, it should log the process showing the migration and namespace as it runs.

### Actual behavior
There is no log

### Steps to reproduce
Start the application. Check the logs.

### Which version(s) does this affect? (Environment, OS, etc...)
2.2",REF.: https://github.com/LiskHQ/lisk-sdk/pull/3701#pullrequestreview-240674925,50873641
207,ChildProcessChannel can not subscribe,open,2019-05-20T13:17:51Z,2019-05-20T13:17:51Z,,CONTRIBUTOR,"### Expected behavior
ChildProcessChannel should be able to listen events coming from other childProcessChannels.
### Actual behavior
ChildProcessChannels can not subscribe events that coming from other child process channels.

Blocking #3118 
### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
v.2.2.0",,50873641
208,Missing events for module unloading lifecycle as specified in LIP,open,2019-05-15T13:54:14Z,2019-05-15T13:56:28Z,,CONTRIBUTOR,"### Expected behavior

We specified few events in the LIP under section [Default Events & Actions](https://github.com/LiskHQ/lips/blob/master/proposals/lip-0005.md#default-events--actions) 
For three events that will be published during the unloading life cycle of any module. 

- module:unloading:started
- module:unloading:error
- module:unloading:finished

### Actual behavior

Currently we don't publish any event during the unloading lifecycle of the module. 

### Which version(s) does this affect? (Environment, OS, etc...)
2.0.0",,50873641
209,Unify Endianness of Transactions and Blocks signature,open,2019-05-09T07:52:05Z,2019-05-09T07:52:05Z,,CONTRIBUTOR,"### Expected behavior
There is no reason to use different Endianness (sometimes Little, sometimes Big Endian) while calculating or verifying the signature for transactions and blocks.

Suggestion: Decide on Big Endian and apply consistently. 

The rules for generating transactions signature are nice to have from the perspective of developers creating new transaction types and implementing `getBytes` functions for them.

### Actual behavior


Bytes | Property | Endianness | Note
-- | -- | -- | --
TRANSACTION
1 | type (int) | BE | No difference for 1 byte
4 | timestamp (int) | LE | Buffer.writeIntLE
32 | senderPublicKey | BE | Buffer.from
8 | recipientId | BE | BigNum(’12324’).toBuffer({ 8 endian: 'big' })
8 | amount | LE | BigNum(amount).toBuffer({ size: 8 endian: ‘little’ })
BLOCK
4 | version (int) | LE | byteBuffer.writeInt
4 | timestamp (int) | LE | byteBuffer.writeInt
8 | previousBlockfor loop | BE |  
4 | numOfTransactions (int) | LE | byteBuffer.writeInt
8 | totalAmount (long) | LE | byteBuffer.writeLong
8 | totalFee (long) | LE | byteBuffer.writeLong
8 | reward (long) | LE | byteBuffer.writeLong
4 | payloadngth (int) | LE | byteBuffer.writeInt
32 | payloadHash | BE | for loop
32 | generatorPublicKey | BE | for loop
64 | blockSignature or unused | BE | for loop


There is also `byteBuffer.flip();` at the end of Block's bytes generation.

### Which version(s) does this affect? (Environment, OS, etc...)
`*`",,50873641
210,Improve the use of actions meta information in the network module,open,2019-05-08T14:57:43Z,2020-01-21T09:24:55Z,,CONTRIBUTOR,"### Expected behavior

Currently we can define `actions` as an object. 

```
{
   handler: () => {},
   prop1: true, 
   prop2: 'val'
}
```
Where an action can have different meta information specified along with the handler. We need to provide an alternative way to access all this information in any module. So modules can use this information based on their own business logic. 

### Actual behavior

Currenlty `network` module expect to have `public: true` for actions which are allowed to be executed on network. For such a specific implementation only for network module, we exposed a method in `invokePublic` on all channels, which is unnecessary and not extensible implementation for future use cases.  


### Which version(s) does this affect? (Environment, OS, etc...)
2.0.0",Related to #3358 ,50873641
211,Avoid using helpers from underlying library instead use the adapter ,open,2019-05-08T12:12:12Z,2020-02-03T15:43:43Z,,CONTRIBUTOR,"### Expected behavior

We should avoid using helper or functions from any underlying library in general if we have a wrapper for it. We are wrapping the pgp library with `pgpAdapter` in our storage component, so we should avoid using directly any helper. 

Either the logic should be executed by a specific SQL file or the functionality should be wrapped in the `pgpAdapter`. 

### Actual behavior

There are couple of such usage in the tests. 

https://github.com/LiskHQ/lisk-sdk/blob/eedad04d2e8e6726f337db73a83f38dfcbec1e91/framework/test/mocha/integration/blocks/process/process.js#L93

https://github.com/LiskHQ/lisk-sdk/blob/eedad04d2e8e6726f337db73a83f38dfcbec1e91/framework/test/mocha/integration/blocks/process/process.js#L99

### Which version(s) does this affect? (Environment, OS, etc...)
Not specific",,50873641
212,Avoid Event Missusages,open,2019-05-07T15:25:40Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Expected behavior

We need to make sure events are used for its intended purpose only; currently different modules could be using registered events passing different event.data causing the subscribers to get more than one event and potentially causing unexpected side effects in different modules.
We should also probably document what's the intended use for existing events. 

### Actual behavior

Events can be fired with different data and subscriber can potentially behave erratically

### Steps to reproduce

- Emit a registered event that's in use and send random data or data that's not the expected by the subscribers

### Which version(s) does this affect? (Environment, OS, etc...)
","Example pseudo-stack which might cause failures

Original Stack:

1. FileA.js -> channel.subscribe('event:xyz', cb);
2. FileB.js -> channel.publish('event:xyz', `{ foo: 'bar', value: 42}`);
3. FileA.js -> executes actions expecting `{ foo: 'bar', value: 42}`

All good so far


New Stack due to someone reusing an existing event:

1. FileA.js -> channel.subscribe('event:xyz', cb);
2. FileC.js -> channel.publish('event:zyz', `['radio', 'head', 'pearl', 'jam']`);
3. FileB.js -> channel.publish('event:xyz', `{ foo: 'bar', value: 42}`);
4. FileA.js -> executes actions expecting `{ foo: 'bar', value: 42}` but first gets `['radio', 'head', 'pearl', 'jam']`

As the subscriber is probably expecting an schema the new first publishing to `event:zyz` with different schema will make it fail.",50873641
213,Refine the application config JSON structure ,open,2019-05-06T13:21:53Z,2020-03-19T08:10:44Z,,CONTRIBUTOR,"Creating application with Lisk SDK should be easy and with the shortest possible code. 

To create an application we can pass set of configuration to the constructor. 

```js
const app = new Application(genesisBlock, config); 
```

The current implementation suggest for following structure for the configuration. 

```js
{
   app: {
      label: 'myApp',
      version: '1.0.0',
      genesisConfig: {}
   },
   modules: {},
   components: {},
}
```

This makes it less intuitive for user to relate and pass the configuration of application and the structure logically takes the application with the same levels of modules. So to just change the label of the application. 

```js
const app = new Application(genesisBlock, { app: { label: 'myApp' } }); 
```

We suggest to change the structure of JSON param so that application level configuration get flattered and appear on top level. 

```js
const app = new Application(genesisBlock, { label: 'myApp' }); 
```

After the change the configuration would be look like: 

```js
{
   label: 'myApp',
   version: '1.0.0',
   genesisConfig: {}
   modules: {},
   components: {},
}
```

### Which version(s) does this affect? (Environment, OS, etc...)
2.0.0",,50873641
214,Enable log rotation with bunyan,open,2019-05-06T13:13:29Z,2020-01-31T09:41:43Z,,MEMBER,"### Expected behavior

The built-in log rotation of Bunyan should be enabled by default with reasonable values.

The log rotation should be configurable inside of `config.json` or with `ENV` variables.

### Actual behavior

Log rotation has to be manually and separately set up as post-installation step of Lisk Core.

### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
v1.6.0",,50873641
215,Improve network test to be fast and stable,open,2019-04-17T09:34:12Z,2020-02-03T15:43:43Z,,CONTRIBUTOR,"### Description

Currently network test takes long time to run and randomly fails.
It should be consistently pass and fast to run the test.
",,50873641
216,Add unconfirmed transaction check in the network test for framework,open,2019-04-17T09:30:38Z,2020-02-03T15:43:43Z,,CONTRIBUTOR,"### Description
Addition to existing tests in the network test, it should have unconfirmed transaction test
",,50873641
217,Add test against built files by typescript,open,2018-10-01T08:06:45Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Description
`test:node` should run the test against built files on `dist-node`.
However, after moving to typescript it's disabled.

It cannot be done only by typescript https://github.com/Microsoft/TypeScript/issues/10866.

Therefore, we need to consider benefit of adding this test against increasing the build complexity.",,50873641
218,Add browser field in package.json,open,2018-11-16T11:35:13Z,2020-03-10T16:32:36Z,,CONTRIBUTOR,"### Description
Browser field should be re-introduced in the `package.json`

With the correct setup, `browserify` reads the browser field and it fails, but with `--no-browser-field, --no-bf`, it doesn't replace the node variable correct.

related: https://github.com/browserify/browserify/pull/1826

#### Remarks
- Check in browser
- Check in Lisk-Hub
- Check in Lisk-Mobile","The referred PR in the browserify is not merged yet, so I asked the question there as well.
I tried the latest browserify release but it also doesn't work.

In the mean time, in which environment are you having the problem with? @JesusTheHun ",50873641
219,Passphrase validation should handle error message for invalid length,open,2018-12-11T15:53:45Z,2020-01-31T09:41:54Z,,MEMBER,"### Expected behaviour

When user inputs invalid passphrase with an invalid number of words between 12 and 24 then it should return an error with a proper message.
It should return the error with message `Passphrase must contain either 12, 15, 18, 21 or 24 words.`

### Actual behaviour
It gives ambiguous message. For example,
`Passphrase contains 17 words instead of expected 12. Please check the passphrase.` when use inputs 17 words.

### Steps to reproduce

`getPassphraseValidationErrors(passphrase)`

where a `passphrase` has an invalid number of words i.e, other than 12, 15, 18, 21 or 24 words.

### Which version(s) does this effect? (Environment, OS, etc...)
","the last input of `getPassphraseValidationErrors` is expectedWords.
In the current implementation, we do not allow dynamic word count, so I think the error message is correct.",50873641
220,Create integration tests for transactions module,open,2019-01-16T13:46:47Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Expected behavior

Transactions Module needs integration tests without stubbing.

### Actual behavior

Currently has none.

",,50873641
221,Typescript types should be exported?,open,2019-02-18T17:33:52Z,2020-01-31T09:41:43Z,,NONE,"### Expected behavior

E.g. I'd like to build the transaction object for the `transfer()` and I'd like to assign the types for it. In that case I'd import transfer and TransferInputs as following:

`import {transfer, TransferInputs} from ""@liskhq/lisk-transactions/"";
`

### Actual behavior

Unfortunately TransferInputs is not exported in @liskhq/lisk-transactions/ therefore I'd need to do:

```
import {transfer} from ""@liskhq/lisk-transactions/"";
import { TransferInputs } from '@liskhq/lisk-transactions/dist-node/0_transfer'
```

### Steps to reproduce
See ""Actual behavior"" section

### Which version(s) does this affect? (Environment, OS, etc...)
Latest
","Hello @nerdvibe, 
Thank you for the information.
Instead of doing 
```
 const transaction: TransferInputs = {
    amount,
    recipientId: address,
    passphrase
  };

  if (secondPassphrase) {
    // This doesn't really work since the type of secondPassphrase is readonly, but in theory this was my suggestion.
    transaction.secondPassphrase = secondPassphrase;
  }
```
what you could do is below
```
 const transaction = {
    amount,
    recipientId: address,
    passphrase,
    secondPassphrase,
  };

  return transfer(transaction);
```
or ultimately you can directly insert the input of `createTransaction`.
If you use typescript, it should internally check if the object properties match with `TransferInputs` internally.
Please let me know if it doesn't work!",50873641
222,Request to add 'all' option to 'list' command,open,2017-08-03T18:57:06Z,2020-01-31T09:41:54Z,,NONE,"## Lisky is missing an option to list all delegates, addresses, blocks, etc.

I thought

**`list -a (--all) delegates`**

and @4fryn bring up `-n` option

**`list delegates -n 101`**","Maybe a default limiter to show 20 or 50 entries until the user interacts, like `enter to show more` or something similar.",50873641
223,Add integration tests for lisk-commander,open,2018-09-04T11:55:34Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Description

Currently, all the tests are unit tests with stubs.
We should add integration tests without stubs.
",,50873641
224,Shows MaxListenersExceeded warning in tests when adding event listener on process,open,2018-09-21T15:36:28Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Description

When adding event listener (to handle errors) directly on process or process.stdin/stdout in `/src/base.js`, mocha tests show warning: 

```
MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 
11 error listeners added. 
Use emitter.setMaxListeners() to increase limit 
```

Possibly related to https://github.com/mochajs/mocha/issues/117

**Reproduces how often:**
Always

### Versions

2.0-
",,50873641
225,Node modules are too big after 2.0,open,2018-11-06T08:22:16Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Description

After `2.0`, node_modules size increased significantly to ~200M even with `--production` flag enabled.
It includes `nyc` and `eslint` along with a lot of libraries.

### Steps to Reproduce

```
npm i -g --production lisk-commander@beta
which lisk
```
and check node_modules content

### Versions

2.0-


",,50873641
226,Add validate address command,open,2018-11-19T08:59:52Z,2020-01-31T09:41:54Z,,NONE,As title,,50873641
227,How to judge broadcast is success when use command transaction:broadcast,open,2018-11-21T08:43:10Z,2020-01-31T09:41:54Z,,NONE,"**Expected behavior:** transaction:broadcast  return a flag whether broadcast is success 

**Actual behavior:** It return ```{""message"":""Transaction(s) accepted""}```

","> When `transaction:broadcast` returns `{""message"":""Transaction(s) accepted""}`, it means the transaction is accepted by a node.
> 
> However, it could be rejected later depending on the network decision,
> 
> Having said that, you want to have something like this?
> 
> ```
> {
>   ""success"": true,
>   ""message"":""Transaction(s) accepted""
> }
> ```

yes",50873641
228,Fix piping transaction:create:second-passphrase to transaction:broadcast error,open,2018-12-11T14:05:25Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Description

Since v2.0 `lisk transaction:create:second-passphrase --passphrase=""pass:first pass"" --second-passphrase=""pass:second pass"" | lisk transaction:broadcast` returns inconsitent results (sometimes `No Transaction was provided).  

### Steps to Reproduce

1. npm i lisk-commander@v2.0.0
2. lisk transaction:create:second-passphrase --passphrase=""pass:xxx"" --second-passphrase=""pass:xxx"" | lisk transaction:broadcast


**Expected behavior:** 

It should pipe transaction to broadcast

**Actual behavior:** 

Not piped

**Reproduces how often:**  90%

### Versions
v2.0.0

### Additional Information
","Stop playing and drinking coffee, get rid of dependence, do it your way and fix it eventually",50873641
229,Find a strategy to disable file logger in test environment,open,2019-04-08T15:29:00Z,2019-04-08T15:47:49Z,,CONTRIBUTOR,"### Expected behavior
We don't have to create log files during unit tests.
### Actual behavior
We are creating log files which is unnecessary.
### Steps to reproduce

### Which version(s) does this affect? (Environment, OS, etc...)
",,50873641
230,Remove usage of default and formatting from validation,open,2019-04-06T12:17:56Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Description

Currently, default and formatting are defined in the validation.
However, validation should not concern default or formatting.

Setting default or formatting should be performed prior to the validation.",,50873641
231,Allow some modules to publish any event,open,2019-04-04T13:56:28Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Expected behavior

Sometimes a module may want to publish events which it only knows at runtime.
For example, the Network module should be able to publish any kind of event on the node (depending on messages it receives from the network).

### Actual behavior

Currently, the module needs to specify the complete list of events that it exposes during boot. This can be useful in terms of imposing constraints for some modules but it's too restrictive for modules like the network module. There should be a way for a module to specify that it can publish any event (maybe a wildcard `'*'`?).

In the `feature/create_network_module` branch, the constraint was disabled completely so that any module can publish any event.

","Some possible approaches (this may change):

Subscribing to a remote event (from a remote peer module):

```js
// Subscribe to the postBlock event from a remote chain module
channel.subscribe('network:chain:postBlock', handlerFunction);

// Subscribe to all remote events from all remote modules
channel.subscribe('network', handlerFunction);
```

OR

```js
// Subscribe to the postBlock event from a remote chain module
channel.subscribe('network:receive:chain:postBlock', handlerFunction);

// Subscribe to all remote events from all remote modules
channel.subscribe('network:receive', handlerFunction);
```

OR

```js
// Subscribe to the postBlock event from a remote chain module
channel.subscribe('network:receive::chain:postBlock', handlerFunction);

// Subscribe to all remote events from all remote modules
channel.subscribe('network:receive', handlerFunction);
```

OR

```js
// Subscribe to the postBlock event from a remote chain module
channel.subscribe('network:receive/chain:postBlock', handlerFunction);

// Subscribe to all remote events from all remote modules
channel.subscribe('network:receive', handlerFunction);
```

Publishing remote event to a peer:

```js
channel.invoke('network:publish', {
  event: 'chain:postBlock',
  data: {}
});
```

Also, we should consider whether or not it makes sense to allow a client to subscribe to all remote events from a specific module or we want to force them to specify the exact event.",50873641
232,Correct use of rejects across Jest test suite,open,2019-04-04T11:43:44Z,2019-04-15T08:06:13Z,,NONE,"### Expected behavior

https://github.com/LiskHQ/lisk/pull/3247/commits/ed10f642cd7bb601123859c2dd07272e60a07d6c

### Actual behavior
We don't always write `await` when using `rejects`.
https://github.com/LiskHQ/lisk/blob/390a9e6f9f614ab49d8c4cee055726da6c3cd110/framework/test/jest/specs/unit/controller/bus.spec.js#L63

### Steps to reproduce

We receive false positives after changing the above to
```
	// Act && Assert
	expect(
	     bus.registerChannel(moduleAlias, [], actions)
	).rejects.toBeInstanceOf('###### ---> MYERROR###');
```

### Which version(s) does this affect? (Environment, OS, etc...)
`1.6`
",,50873641
233,Provide ability to extend state with custom properties,open,2019-03-29T14:15:00Z,2019-11-12T12:53:46Z,,NONE,"### Expected behavior

Create a method to extend the application state with custom properties without overwriting the existing ones.

```js
state = { 
 modules: { 
   unicorns: 'xx', 
   zebras: 'yy' ,
  }
}
```

### Actual behavior
> 
> let state = {
... modules: {
..... unicorns: 'xx'
..... }}
> 
> newExtensionForState = {
... modules: {
..... zebras: 'yy'}}
{ modules: { zebras: 'yy' } }
>
> Object.assign(state, newExtensionForState)
{ modules: { zebras: 'yy' } }
> 
> 
> state
{ modules: { zebras: 'yy' } }

### Which version(s) does this affect? (Environment, OS, etc...)
`1.7`
",,50873641
234,PM2 does not show CPU and Memory usage when using `npm start`,open,2019-03-29T11:50:09Z,2019-04-16T07:28:21Z,,CONTRIBUTOR,"### Expected behavior
I expect to be able to start PM2 with `pm2 start npm -- start -- -n testnet` and have CPU and memory usage properly displayed with `pm2 monit`

### Actual behavior
When PM2 starts the application using `npm start` it forks the application and its monitoring tool looks for npm pid instead of application pid.

### Steps to reproduce
`pm2 start npm -- start -- -n testnet`
`pm2 monit`

### Which version(s) does this affect? (Environment, OS, etc...)
1.6",REF.: https://github.com/LiskHQ/lisk/issues/3215,50873641
235,Application don't cleanup when exit running npm start,open,2019-03-28T11:06:23Z,2019-07-03T16:23:25Z,,CONTRIBUTOR,"### Expected behavior
I expect the application to do the cleanup when running with `npm start`

### Actual behavior
When starting the application with `node src/index.js`, it properly does the cleanup when it exits.
But when starting the application with `npm start`, it doesn't.

### Steps to reproduce
Starting the application with `npm start`.
Exit the application with `ctrl + C`

### Which version(s) does this affect? (Environment, OS, etc...)
1.6",,50873641
236,Prevent application from crashing if child process crashes,open,2019-03-21T15:24:57Z,2019-04-15T08:08:46Z,,CONTRIBUTOR,"### Expected behavior
I expect the parent process to keep running if a child process exits.

### Actual behavior
It crashed the parent process

### Steps to reproduce
Run the application and kill httpApi process.

### Which version(s) does this affect? (Environment, OS, etc...)
`feature/child_process_module`",Reopen as per https://github.com/LiskHQ/lisk/issues/3191,50873641
237,Integration test `ChildProcessChannel` class and `InMemoryChannel` class,open,2019-03-20T08:43:01Z,2019-10-25T10:34:32Z,,CONTRIBUTOR,"### Expected behavior
Expect to `ChildProcessChannel` class and `InMemoryChannel` class to be covered by integration tests using Jest framework

### Actual behavior
It doesn't

## Acceptance Criteria
- [x] Add Integration tests for InMemoryChannel #3186 
- [ ] Add Integration tests for ChildProcessChannel #3675 

### Which version(s) does this affect? (Environment, OS, etc...)
`feature/child_process_module`","All work done on #3675 will be kept in https://github.com/LiskHQ/lisk-sdk/tree/3118-integration-test-ChildProcessChannel branch. So when issue #3674 was resolved, maybe we can reuse some of the code here. @lsilvs ",50873641
238,Add a new sorting method to the Transactions endpoint,open,2019-03-16T13:39:50Z,2019-04-16T07:28:40Z,,NONE,"### Add a new sorting method

Sorting by timestamp descending does not always show the latest transactions broadcasted to the blockchain.

For example:
`https://testnet.lisk.io/api/transactions?limit=10&offset=0&sort=timestamp%3Adesc`

should show the latest transactions. But since it's easy to fake a timestamp, for instance by changing the computers clock back a few days and then performing a transaction, this sorting method isn't the most reliable.

I recommend adding sorting by **Height** to the available options, since this might be a more reliable method to discover the latest transactions. 

Adding the following options:

_height:asc
height:desc_
",Related issue: https://github.com/LiskHQ/lisk/issues/1891,50873641
239,Limit log history to a certain amount of days,open,2019-01-27T13:16:49Z,2020-01-31T09:41:43Z,,NONE,"Feature request: Limit log history to a certain amount of days

### Expected behavior

lisk.log ""should"" only store a log of the last n days.

### Actual behavior

By default and left alone, lisk.log grows infinitely. 

### Steps to reproduce

Install and run core, set fileLogLevel to debug and leave the server alone until hard drive is full.

### Reason for request

Several users running core reported that their server logs quickly fill up the hard drive. Which will cause the node to go offline. 

Example:
![image](https://user-images.githubusercontent.com/42899281/51801004-6c2e5700-2238-11e9-8baf-1436af50fd08.png)

There is a solution using logrotate, but the solution to this issue could be greatly simplified for the user by expanding config with the option: logFileHistoryLength.

Example:
![image](https://user-images.githubusercontent.com/42899281/51801210-055e6d00-223b-11e9-8f9b-5dd070793153.png)
",It is indeed a good idea to rotate the log files and we explain how to do so with `logrorate` in the [documentation](https://lisk.io/documentation/lisk-core/setup/binary#logrotate-setup).,50873641
240,Update filters generators to provide more flexible format,open,2019-01-15T08:43:55Z,2019-04-15T08:07:16Z,,CONTRIBUTOR,"Currently the filters generation support the following syntax. 

```
(a = 1 AND b = 2) OR (a = 2 AND b = 3)
```

We need to support following syntax as well: 

```
(a = 1 OR b = 2) AND (a = 2 OR b = 3)
```
or mix of both

```
(a = 1 OR b = 2) AND ( (a = 1 AND b = 2) OR (a = 2 AND b = 3) )
```
","Its a nice to have feature, and should be implemented in following pattern later in some time. 

```
	/**
	 * Parse provided filters and generate valid SQL
	 *
	 * @param {string|Object|Array.<Object>} filters
	 * @param {Object} options
	 * @param {string} options.filterPrefix
	 * @return {string}
	 *
	 * @description
	 *
	 * * Filters can be provided as strings or object or array of objects and strings
	 * * Object type filters will always be combined with *AND* combinator
	 * * Array type filters will always be combined with *OR* combinator
	 * * String values type (AND, OR) can be added as array elements to and used a combinator
	 *
	 * @example
	 * Filters can provided in following format to generate these conditions
	 *
	 * 		{a: 1, b: 2} 						-> (a = 1 AND b = 2)
	 * 		[{a: 1, b: 2}, {c: 3}] 				-> (a = 1 AND b = 2) OR (c = 3)
	 * 		[[{a: 1}, {b: 2}], {c: 3}] 		-> (a = 1 OR b = 2) OR (c = 3)
	 * 		[[{a: 1}, {b: 2}], 'AND', {c: 3}] 		-> (a = 1 OR b = 2) AND (c = 3)
	 */
```",50873641
241,Add an API endpoint to get the balance of an account at a specific unix timestamp,open,2018-11-20T14:17:49Z,2020-01-31T09:41:54Z,,NONE,"### Expected behavior
It would be useful to get the balance of an account at a specific timestamp in the past.
The existing api endpoint `/accounts` could be extended by an additional optional argument `atTimestamp` (or similar)

### Actual behavior
Now it's only possible to get the current balance with `/accounts?address=5726759782318848681L`. To figure out the balance at a time in the past, you have to track all transactions on this account since the beginning and also consider forging rewards and fees if it is a delegate account.

### Steps to reproduce
call `/accounts?address=5726759782318848681L` and try to figure out what it's balance was on 31st of December 2017

### Which version(s) does this affect? (Environment, OS, etc...)
All core versions",,50873641
242,Inconsitency with timestamps in API parameters,open,2018-10-18T19:42:19Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Expected behavior
API parameters containing timestamps should be consistent across all API endpoints.
### Actual behavior
We have inconsistency with those parameters. Swagger definitions describe `fromTimestamp` and `toTimestamp` as Unix timestamps here:
https://github.com/LiskHQ/lisk/blob/01dc88cc34cc20d88658f6ed8fb4ef827658c868/schema/swagger.yml#L1172-L1183
Also `timestamp` parameter for `transactions` endpoint is described as Unix timestamp here:
https://github.com/LiskHQ/lisk/blob/01dc88cc34cc20d88658f6ed8fb4ef827658c868/schema/swagger.yml#L1258-L1263
This is only true for `/delegates/{address}/forging_statistics` endpoint. For other endpoints (`blocks`, `transactions`) those parameters are accepting Lisk Timestamp format and not Unix timestamp, as described here:
https://github.com/LiskHQ/lisk/blob/01dc88cc34cc20d88658f6ed8fb4ef827658c868/schema/swagger.yml#L46-L50

My recommendation is fixing the descriptions and make `fromTimestamp` and `toTimestamp` of `forging_statistics` accept Lisk Timestamp format. We can add `fromUnixTimestamp` and `toUnixTimestamp` for accepting timestamps in Unix format. This will change the API behavior, so fix should go with the major version.
### Steps to reproduce
N/A
### Which version(s) does this affect? (Environment, OS, etc...)
`>= 1.0.0`","As pointed by @4miners, the change would break the public API. Suspended for now.",50873641
243,POST /api/transactions low performance ,open,2018-09-20T07:09:44Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Expected behavior
`POST /api/transactions` should perform efficiently under 1s even under fair amount of stress. 

### Actual behavior
In reference to issue https://github.com/LiskHQ/lisk/issues/1623#issuecomment-420920034 we found that on average it is taking 2.5s time. With following spec of system. 
```
Version: 1.0.2
Network: mainnet
Instance Type: Digital Ocean Droplet
CPU: 1vCPU
RAM: 1GB
```

### Which version(s) does this affect? (Environment, OS, etc...)
1.0.2
",Should be significantly improved after #2209. Suspended for now.,50873641
244,GET api/transactions poor performance under stress test,open,2018-09-10T15:28:24Z,2020-01-31T09:41:54Z,,MEMBER,"### Expected behavior
API performance for GET `/api/transactions` endpoint performance should be under 1 second during stress test

### Actual behavior
API Transactions endpoint is identified to have performance bottleneck, during the testing of `1.1.0-alpha.1` one of the nodes was targeted for a stress test and key metrics was enabled to gather performance stats, here is the link for the key metrics stats https://drive.google.com/open?id=1PxxxlLNGNlGUy_LydGSbPza3GEfWpq6l

Also did benchmark(without stress test) using `ab` and collected the stats for the endpoints.

### Steps to reproduce
https://drive.google.com/open?id=1PxxxlLNGNlGUy_LydGSbPza3GEfWpq6l

### Which version(s) does this affect? (Environment, OS, etc...)
","The new application architecture is described in details here - https://github.com/LiskHQ/lips/blob/master/proposals/lip-0005.md.

We expect it to solve the problem.",50873641
245,/api/node/status delegate count,open,2018-08-29T19:29:05Z,2020-01-31T09:41:43Z,,NONE,Is it possible that current delegate count will be added to this endpoint?,"Thank you, I hope it will be added here.",50873641
246,Auto-configure and/or Keep config. of .db.username in BOTH config.json and snapshot.json on install or upgrade,open,2018-08-11T17:20:50Z,2020-01-31T09:41:43Z,,NONE,"### Expected behavior

./etc/snapshot.json should be processed in the same way config.json is processed on upgrade.

### Actual behavior

./etc/snapshot.json file is only replaced by a vanilla version.

### Extra Infos

Since core version 1 , .db.username needs to be configured as the linux user (instead of lisk) that is running the software. I think there is 2 things that would need to be done. First, modify installLisk.sh to make sure it's configured properly on install. Second, process ./etc/snapshot.json in the same way config.json is processed on upgrade to keep the modified stuff on upgrade. Also, maybe improve documentation so it's easier for newcomers to understand why it doesn't work by default.","Ok, I guess you already have it completly figured it out. I'll keep switching the user with jq in my notes for now on both files and see how snapshot is evolving from known issue to none issue. Thanks for taking time to explain it. Still would like @Nazgolze to confirm second point before closing.",50873641
247,Upgrade Swagger 2.0 to Open API Specification 3.0,open,2018-06-20T13:45:03Z,2020-01-31T09:41:54Z,,CONTRIBUTOR,"### Expected behavior
The latest version of swagger is renamed to `OAS3`. It have plenty of improvements that we can utilized. Specially the multi server definition. 

### Actual behavior
We are using Swagger 2.0 currently. Which is kind of near to obsolete. 

### Steps to Develop 
1. We are using `swagger-node-runner` which does not support OAS3
2. Either we fork and upgrade `swagger-node-runner` to support OAS3
3. Or instead the package `sway` package directory, which is the dependency of `swagger-node-runner` right now. 
4. Upgrade the swagger specification we currently have in `swagger.yml`
5. Update the functional tests (if any change made in endpoints) 

### Which version(s) does this affect? (Environment, OS, etc...)
`1.0.0`",Un-assigning from myself. We will revisit this issue in coming releases and then assign available resource. ,50873641
248,Block is always created with the timestamp value of first second of the slot,open,2018-06-01T08:16:32Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Expected behavior
Block should be created with the actual timestamp value of the machine.
### Actual behavior
Block is created with timestamp value based on slot window, which means that every node will create a block with timestamp value equal to slotWindow * 10. When it should be: slotWindow * 10 + secondsPassedWithinCurrentSlot. This will give us more information about when the block is actually forged and broadcasted to the network, which nodes are forging on time, which nodes are performing too much work and so on and so forth.
### Steps to reproduce
N/A
### Which version(s) does this affect? (Environment, OS, etc...)
*","I agree with @4miners, we should delay this to after 1.0.0.",50873641
249,Add community provided seed nodes,open,2018-05-04T13:22:24Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Expected behavior
Lisk Core config should also contain nodes operated by independent instances to guarantee decentralization and prevent a attack in which seed nodes only supply selected peers to fork the network.

### Actual behavior
Lisk Core config only contains seed nodes operated by LiskHQ.
","@webmaster128 Support for domain names in the peers list (config file) was only added in v1.2; so in the meantime we should stick to IPv4 addresses.

The PR is here: https://github.com/LiskHQ/lisk/pull/2325",50873641
250,Equalise to bytea type all the parameters related to publicKey,open,2018-03-08T09:20:40Z,2020-01-31T09:41:54Z,,NONE,"### Expected behavior

All the references to publicKey presented in the database should be stored as the same data type `bytea`.

### Actual behavior

Some of them are as `bytea` , some others are as `varchar(64)`.

### Which version(s) does this affect? (Environment, OS, etc...)
`1.1.0` ?
",Postponed until https://github.com/LiskHQ/lisk/milestone/35 is implemented.,50873641
251,Proper and consistent behaviour of collection count around different API endpoints,open,2018-01-31T13:08:10Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"Currently there is inconsistency among different endpoints to provided collection count. To do more thinking on this topic I am listing use cases for such counts; 

### Total Collection Count 
Entity |  Current Usage | Probable Use Case  | Implemented 
--- | --- | --- | ---
Transactions | No | No | No
Blocks | No |  No | No
Delegates | Explorer  to show active and on standby delegates |  No | No
Accounts | No |  No | No
Votes | No |  No | No
Voters | No |  No | No

### Filtered Collection Count
Entity |  Current Usage | Probable Use Case | Implemented 
--- | --- | --- | ---
Transaction | Explorer / Nano (to show total incoming and outgoing transactions) | Wallet / Exchanges  / Third-party apps | Yes
Blocks | Explorer | Pagination | No
Delegates | No | Pagination | No
Accounts | No | Pagination | No
Votes | Explorer | Pagination | No
Voters | Explorer | Pagination | No

As per above summary, the most common use case is the pagination. Which can be implemented without total count with Previous<>Next approach. 

We need to think/discuss/brainstorm on this topic further to come up with consistent approach of providing count of collection. 

1. Either we implement it across all collections
2. Or remove it from existing implementations ",I like the idea of having no count by default and using `count=true` to get the count value but in this case (using `count=true`) I reckon it should return the accurate count. If one wants to get an inaccurate count for performance reasons use `inaccurateCount=true` instead.,50873641
252,Consistent and standard error propagation,open,2018-01-29T14:53:27Z,2020-01-31T09:41:43Z,,CONTRIBUTOR,"### Scenario
We have different and multi level hierarchies of modules, helpers, logic etc. And each interface layer e.g. “API”, “Websocket” is consuming those modules individually. 

Considering that some error been propagated from an underlying module and catched by “API” or “Websocket” or even on domain level catched by “process”. So we need to answer to these questions. 

- Categorically what type of error it is? 
- What need to be done with this error? 
- If interfered by HTTP Layer what status code to respond? 
- If interfered by websocket, what response need to send? 
- If logging required, what level of logging is appropriate for this error?

Currently we are dealing with all these questions on adhoc basis with redundant code. That cause instability and increase complexity in code. 

### Case Study
Suppose we this method was called 
```
logic.accounts.getAll 
```
With some parameters and in case of any error it is throwing error
```
setImmediate(cb, 'Account#getAll error');
```
Suppose this error catched on API layer, we are not sure its an SQL related error. All we can do is to add condition if(error === “Account#getAll error”) then decide to respond with 500 error code. But such if such SQL error generated by other module with different message, then we have to extend that condition. 

And if some one change the error message, all error catching logic will break. 

### Proposed Solution
So hereby I propose to introduce custom error constructors introduced and used consistently in every place of the application. Those error constructors can have different embed information on definition level, so our interface layers can catch and process those consistently. 

```js
var SQLError = function(message) {
  Error.captureStackTrace(this, this.constructor);
  this.message = message; 
  
  this.httpStatusCode = 500;
  this.log = true;
  this.logLevel = 'debug';
};
SQLError.prototype = new Error();


var ParamValidationError = function(param, message) {
  Error.captureStackTrace(this, this.constructor);
  this.param = param
  this.message = message; 
  
  this.httpStatusCode = 400;
  this.log = true;
  this.logLevel = 'info';
};
ParamValidationError.prototype = new Error();

var RecordNotFoundError = function(message) {
  Error.captureStackTrace(this, this.constructor);
  this.message = message; 
  
  this.httpStatusCode = 404;
  this.log = false;
};
ParamValidationError.prototype = new Error();

module.exports = {
  SQLError: SQLError,
  ParamValidationError: ParamValidationError,
  RecordNotFoundError: RecordNotFoundError
};
```","Two points to add to this discussion.
- Use of array of errors.
I think this should be avoided although we use intensively in the transaction library.
This makes the error handling more complex and non-standard
- Remove usage of throw in case of expected errors
Our application needs to handle various error in different way, and we want to have consistent way of handling error. Therefore, we should consistently return error instead of throwing in case of handleable error.",50873641
253,Improvements required in delegate search results,open,2017-12-27T11:17:28Z,2020-01-31T09:41:43Z,,MEMBER,"### Actual behaviour
For the `/api/delegates/search` endpoint, the result is an array whose members are alphabetically sorted based on username. for example, if you search for `lisk` with this query:
```
/api/delegates/search?q=lisk
```
you receive an array starting with a delegate object with username `amazinglisk.com` but vividly the closest result is `liska` which starts with the given substring and has the minimum length of suffix.

The above result is retrieved from testnet explorer.

And it's far worst when you search for `zen` which is an already existing delegate (in mainnet) but the first item in result list is `mauroverdekizen`. because alphabetically it's before `zen`.

### The problem
Taking the above behaviour, every client should implement the logic to refine the response to get the intended result.

### Expected behaviour
The result must be sorted based on the degree of similarity of usernames with the given query string. [string-similarity](https://www.npmjs.com/package/string-similarity) is one of the libraries performing such a job.

### Core version
v0.9.x (presently running on testnet and mainnet)",,50873641
254,Future long-term development of Blockchains and Lisk,open,2017-06-18T08:09:45Z,2020-01-31T09:41:43Z,,NONE,"I found an interesting series of blog entries here:
https://bitcoinmagazine.com/articles/op-edwhy-connecting-all-blockchains-final-step-mass-adoption/
https://bitcoinmagazine.com/articles/op-ed-three-technical-requirements-connect-blockchains-without-token/
It's basically about the future of the whole blockchain technology and about that in the future will be to  interconnect all the different blockchains. The author compares this to the early state of the internet, when only small local intranet existed (like our different blockchains BTC, ETH, LSK, etc...) and when the people began to interconnect those intranets to form the internet. Only this interconnection made the internet so important what it is now. The same should/will happen with blockchains.
And I totally agree with him.
He then writes about how this interconnection could be done, using something called HTLCs (Hashed Time-Lock Contracts) which base on the following three main functionalities in a blockchain:

1. Multisignature feature (Multisig);
2. Hashing functionality; and
3. Time-lock functionality

I think he might be right. If I remember correctly, this is the same (or a similar) technology that also the Lightning Network will use to set up fast payment channels on top of the bitcoin network.
https://en.bitcoin.it/wiki/Lightning_Network
""Lightning Network is a proposed implementation of Hashed Timelock Contracts (HTLCs) with bi-directional payment channels which allows payments to be securely routed across multiple peer-to-peer payment channels.[1] This allows the formation of a network where any peer on the network can pay any other peer even if they don't directly have a channel open between each other.""

I think, we from Lisk should also consider to go into this direction. If this connection between blockchain will happen (and I am pretty sure it will in the long term), Lisk should be on board. Every blockchain who doesn't support this concept will be left behind.

TLDR: I think, Lisk should look into HTLC and consider implementing it's functionality, because it might be used in the future to interconnect all different Blockchains.

Maybe we can use this issue/thread to brainstorm and gather some info material
",,50873641
255,Improving network synchronisation - decentralised blockchain snapshots,open,2016-07-10T22:06:39Z,2020-01-31T09:41:43Z,,NONE,"**LIP001 - Lisk Improvement Proposal 1 (Improving network synchronisation - decentralised blockchain snapshots)**

Topic has been raised in issue #232. Currently syncing new node from beginning is totally unstable, even when snapshots are pretty new it still takes lots of time. Process become very slow, syncing one old block sometimes takes even more time than network produce new block which makes node impossible to catchup with network, sometimes syncing suddenly can speed up for a while to import couple blocks per second, anyway currently syncing is bugged but i know team is working on that i have also saw some new commits in regards to that. Currently lisk team occasionally provide blockchain snapshot stored on **lisk.io**. Which is great way to remove some unnecessary load from nodes on cpu-level but it's also centralised and relay on one operator.

I think official snapshots should be removed and replaced with decentralised snapshots. Blockchain snapshots is a great idea to improve syncing efficiency. Optionally node operator could allow distribution of blockchain snapshots. Blockchain splitted to packages of  - for example 256 or 512 or 5000 blocks, or packs of 128mb with N blocks depending on block size. Each pack can be zipped or compressed with any other maybe more efficient method. It should save some unnecessary cpu load and bandwidth and improve syncing new nodes but it will require more space from node operator so it should be as optional feature and possibly as service in upcoming feature ""Standby delegate Market"". Each node which is willing to help network sync at the maximum possible level of speed and stability could simply add one flag in config which allow to create and distribute ""decentralised snapshots"". Each N blocks new package is being created and newly introduced node can simply at efficient speed acquire all packages, uncompress and start rebuilding and verification while another one is downloading from this or another node. But similar solution could be achieved with improvements to network sync. This is proposal to replace official snapshots with decentralised snapshots or possibly improve entire network syncing speed and stability to ""snapshot level"" and logging while local blockchain height is more than 200 blocks behind network could me improved to more readable format like ""Importing blocks 0-256"".
","Hi @karek314 thanks for the proposal this is great!

We have already a few fixes  for the block sync, but far from enough.

So far the implementation is the following:
1. new node is looking at the network for 100 random peers
2. the peer query height on this peer and building an histogram to estimate network height (available at 0.4.0)
3. the peer select a list of peers at the estimated network height using histogram cut (available at 0.4.0)
4. the peer download batch of 1440 blocks for a random peer
5. the random peer is choosen from the list 3. and change every batch of blocks (available in 0.4.0)
- a minor bottleneck is the download time. Being able to zip batches of blocks will surely improve it.
- the major time bottleneck is block processing (above all transactions processing). To give you an idea a block with 25 tx takes 1s in the current implementation.

bottom-line: decentralised block chain should ship the accounts status at some round levels (how many lisks and votes for accounts) to be really efficient imho.
",50873641
256,CSEJavaSDK集成shiro 报错，,open,2020-03-26T12:50:16Z,2020-03-26T12:54:45Z,,NONE,"![image](https://user-images.githubusercontent.com/19624999/77648464-25a2cc80-6fa3-11ea-846b-1f846749f0d9.png)
rg.apache.shiro.UnavailableSecurityManagerException: No SecurityManager accessible to the calling code, either bound to the org.apache.shiro.util.ThreadContext or as a vm static singleton.  This is an invalid application configuration.
但是相同的代码只用springboot是可以的",看了你们给的demo 绕过了ShiroFilterFactoryBean，直接写的HttpServerFilter  有什么方案可以使用ShiroFilterFactoryBean,91674936
257,[SCB-1822]fix problems when using multiple consumer interface for one…,open,2020-03-25T09:30:17Z,2020-03-25T14:06:38Z,,CONTRIBUTOR,"… operation and using CseHttpEntity to set localcontext

Follow this checklist to help us incorporate your contribution quickly and easily:

 - [ ] Make sure there is a [JIRA issue](https://issues.apache.org/jira/browse/SCB) filed for the change (usually before you start working on it).  Trivial changes like typos do not require a JIRA issue.  Your pull request should address just this issue, without pulling in other changes.
 - [ ] Each commit in the pull request should have a meaningful subject line and body.
 - [ ] Format the pull request title like `[SCB-XXX] Fixes bug in ApproximateQuantiles`, where you replace `SCB-XXX` with the appropriate JIRA issue.
 - [ ] Write a pull request description that is detailed enough to understand what the pull request does, how, and why.
 - [ ] Run `mvn clean install -Pit` to make sure basic checks pass. A more thorough check will be performed on your pull request automatically.
 - [ ] If this contribution is large, please file an Apache [Individual Contributor License Agreement](https://www.apache.org/licenses/icla.pdf).

---
","
[![Coverage Status](https://coveralls.io/builds/29607476/badge)](https://coveralls.io/builds/29607476)

Coverage increased (+0.01%) to 84.998% when pulling **478643f1f8ce88ba7edbe76af108d12144d2e678 on liubao68:release** into **6cef5feb94807a246611dc213ba23512def06dc6 on apache:master**.
",91674936
258,mockmvc测试接口异常现象，用例不进入ExceptionToProducerResponseConverter,open,2020-03-25T09:21:54Z,2020-03-26T03:21:53Z,,NONE,"背景：程序使用ExceptionToProducerResponseConverter捕捉ConstraintViolationException参数异常并返回。
![image](https://user-images.githubusercontent.com/30398258/77521015-fd40a280-6ebc-11ea-8391-6f72daed3f85.png)

现象：构造测试用例传递非法入参，用例直接返回4xx错误，不进入ExceptionToProducerResponseConverter。
![image](https://user-images.githubusercontent.com/30398258/77521059-0e89af00-6ebd-11ea-84b0-0d6522b27e70.png)",那请问，java-chassis是否有测试接口的类，类似mockmvc这样的工具。模拟restful请求。,91674936
259,servicecomb启动报空指针异常,open,2020-03-25T08:48:30Z,2020-03-26T01:29:06Z,,NONE,"2020-03-25T11:49:29.948+0800 || http-nio-8080-exec-3 || [.[.[.[ServicecombRestServlet].175  || ERROR || Servlet.service() for servlet [ServicecombRestServlet] in context with path [] threw exception
java.lang.NullPointerException: null
	at org.apache.servicecomb.common.rest.locator.ServicePathManager.getServicePathManager(ServicePathManager.java:59)
	at org.apache.servicecomb.common.rest.AbstractRestInvocation.findRestOperation(AbstractRestInvocation.java:80)
	at org.apache.servicecomb.common.rest.RestProducerInvocation.findRestOperation(RestProducerInvocation.java:57)
	at org.apache.servicecomb.transport.rest.servlet.RestServletProducerInvocation.findRestOperation(RestServletProducerInvocation.java:28)
	at org.apache.servicecomb.common.rest.RestProducerInvocation.invoke(RestProducerInvocation.java:46)
	at org.apache.servicecomb.transport.rest.servlet.ServletRestDispatcher.service(ServletRestDispatcher.java:57)
	at org.apache.servicecomb.transport.rest.servlet.RestServlet.service(RestServlet.java:47)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.huawei.appgallery.quickapp.portal.component.xss.XssFilter.doFilter(XssFilter.java:33)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:109)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:367)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1639)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2020-03-25T11:49:29.953+0800 || http-nio-8080-exec-3 || [.[.[.[ServicecombRestServlet].175  || ERROR || Servlet.service() for servlet [ServicecombRestServlet] threw exception
java.lang.IllegalStateException: Calling [asyncStart()] is not valid for a request with Async state [STARTING]
	at org.apache.coyote.AsyncStateMachine.asyncStart(AsyncStateMachine.java:242)
	at org.apache.coyote.AbstractProcessor.action(AbstractProcessor.java:497)
	at org.apache.coyote.Request.action(Request.java:432)
	at org.apache.catalina.core.AsyncContextImpl.setStarted(AsyncContextImpl.java:323)
	at org.apache.catalina.connector.Request.startAsync(Request.java:1700)
	at org.apache.catalina.connector.Request.startAsync(Request.java:1682)
	at org.apache.catalina.connector.RequestFacade.startAsync(RequestFacade.java:1043)
	at javax.servlet.ServletRequestWrapper.startAsync(ServletRequestWrapper.java:383)
	at org.apache.servicecomb.transport.rest.servlet.ServletRestDispatcher.service(ServletRestDispatcher.java:49)
	at org.apache.servicecomb.transport.rest.servlet.RestServlet.service(RestServlet.java:47)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:712)
	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:461)
	at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:384)
	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:312)
	at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:394)
	at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:253)
	at org.apache.catalina.core.StandardHostValve.throwable(StandardHostValve.java:348)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:173)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:367)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1639)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2020-03-25T11:49:29.954+0800 || http-nio-8080-exec-3 ||        o.a.c.c.C.[.[localhost].175  || ERROR || Exception Processing ErrorPage[errorCode=0, location=/error]
java.lang.IllegalStateException: Calling [asyncStart()] is not valid for a request with Async state [STARTING]
	at org.apache.coyote.AsyncStateMachine.asyncStart(AsyncStateMachine.java:242)
	at org.apache.coyote.AbstractProcessor.action(AbstractProcessor.java:497)
	at org.apache.coyote.Request.action(Request.java:432)
	at org.apache.catalina.core.AsyncContextImpl.setStarted(AsyncContextImpl.java:323)
	at org.apache.catalina.connector.Request.startAsync(Request.java:1700)
	at org.apache.catalina.connector.Request.startAsync(Request.java:1682)
	at org.apache.catalina.connector.RequestFacade.startAsync(RequestFacade.java:1043)
	at javax.servlet.ServletRequestWrapper.startAsync(ServletRequestWrapper.java:383)
	at org.apache.servicecomb.transport.rest.servlet.ServletRestDispatcher.service(ServletRestDispatcher.java:49)
	at org.apache.servicecomb.transport.rest.servlet.RestServlet.service(RestServlet.java:47)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:712)
	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:461)
	at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:384)
	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:312)
	at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:394)
	at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:253)
	at org.apache.catalina.core.StandardHostValve.throwable(StandardHostValve.java:348)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:173)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:367)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1639)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2020-03-25T11:49:29.954+0800 || http-nio-8080-exec-3 ||      o.a.c.h.Http11NioProtocol.175  || ERROR || Error reading request, ignored
java.lang.IllegalStateException: Calling [asyncPostProcess()] is not valid for a request with Async state [MUST_ERROR]
	at org.apache.coyote.AsyncStateMachine.asyncPostProcess(AsyncStateMachine.java:290)
	at org.apache.coyote.AbstractProcessor.asyncPostProcess(AbstractProcessor.java:191)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:81)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1639)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)","你用的哪个版本？ 可以对着代码看看失败代码上下文， 也可以看看更前面的日志，可能是启动过程中其他异常导致的。 
",91674936
260,怎么获取同一APPID Provider的所有实例信息,open,2020-03-25T02:04:16Z,2020-03-25T09:34:32Z,,NONE,"场景：Consumer向Provider发消息，Provider多实例，想向Provider的所有可用节点发起订阅
问题: 
1.若使用负载均衡能力，轮询发消息，怎么获取可用节点个数
2.怎么获取Provider所有的实例信息","这里提供了一个例子，如何实现你的场景：

https://github.com/apache/servicecomb-java-chassis/pull/1664 

1. 通过 DiscoveryTree 获取某个微服务的所有实例；
2. 调用 Provider 接口的时候， 指定具体的实例信息。 

不过这个 PR 没合入，有两个问题需要注意：
1. 如果采用 RestTemplate 调用， 设置 local context 有问题
2. 如果采用 RPC 调用， 需要注意这个接口只能够声明一个 consumer， 携带 InvocationContext 参数

如果你是在某个 REST 接口里面调用其他服务的接口， 则可以直接使用：

```
ContextUtils.getInvocationContext().addLocalContext 设置地址信息，则不会存在上述两个问题。 

```",91674936
261,[SCB-1815] Support sdk register on local SC and discover on SCA,open,2020-03-24T12:26:13Z,2020-03-26T12:34:13Z,,CONTRIBUTOR,"…y and change outlog item name

Follow this checklist to help us incorporate your contribution quickly and easily:

 - [ ] Make sure there is a [JIRA issue](https://issues.apache.org/jira/browse/SCB) filed for the change (usually before you start working on it).  Trivial changes like typos do not require a JIRA issue.  Your pull request should address just this issue, without pulling in other changes.
 - [ ] Each commit in the pull request should have a meaningful subject line and body.
 - [ ] Format the pull request title like `[SCB-XXX] Fixes bug in ApproximateQuantiles`, where you replace `SCB-XXX` with the appropriate JIRA issue.
 - [ ] Write a pull request description that is detailed enough to understand what the pull request does, how, and why.
 - [ ] Run `mvn clean install -Pit` to make sure basic checks pass. A more thorough check will be performed on your pull request automatically.
 - [ ] If this contribution is large, please file an Apache [Individual Contributor License Agreement](https://www.apache.org/licenses/icla.pdf).

---
","**modify as bellow**  :

Support sdk register on local SC and discover on SCA #

we prefer to use  **servicecomb.service.registry.registrator.address** and **servicecomb.service.registry.serviceDiscovery.address**. 

either of them does not exist, we will use 
**servicecomb.service.registry.address** as default

```yaml

# keep same with go chassis
# 
servicecomb:
  service:
    registry:
      address: xxx:30100,xxx:30100
      registrator:
        # registry 
        address: xxx:3100,xxx:30100
      serviceDiscovery:
        # discovery
        address: xxx:3100,xxx:30100
```

There are some restrictions as follows:

1. The target  sc  to be  registered must be in the same cluster as the sca to be discovered.

2. the registry address  and discovery address must be all http or all https



",91674936
262,调用微服务接口报heartbeat fail，Failed to create SSL connection,open,2020-03-24T09:19:54Z,2020-03-24T13:00:47Z,,NONE,"微服务之间调用接口，服务端日志先报了heartbeat fail，message: Failed to create SSL connection，客户端在调用该接口时经常出现handshake timed out错误，现象是接口性能下降了，接口偶尔调用失败，请问可能是什么原因引起的？

**服务端日志：**
[2020/03/16 16:30:16.720][ERROR][PUT /v4/default/registry/microservices/b44f40294f56477d7c961080f821d440c9012694/instances/31132854675811ea9b65482b3c4d5e1f/heartbeat fail, endpoint is 18.35.41.171:30100, message: Failed to create SSL connection][org.apache.servicecomb.serviceregistry.client.http.RestUtils][lambda$null$1,95][registry-vert.x-eventloop-thread-0]PUT /v4/default/registry/microservices/b44f40294f56477d7c961080f821d440c9012694/instances/31132854675811ea9b65482b3c4d5e1f/heartbeat fail, endpoint is 18.35.41.171:30100, message: Failed to create SSL connection
[2020/03/16 16:30:22.303][WARN][invoke service [/v4/default/registry/microservices/b44f40294f56477d7c961080f821d440c9012694/instances/31132854675811ea9b65482b3c4d5e1f/heartbeat] failed, retry.][org.apache.servicecomb.serviceregistry.client.http.ServiceRegistryClientImpl][retry,105][registry-vert.x-eventloop-thread-0]invoke service [/v4/default/registry/microservices/b44f40294f56477d7c961080f821d440c9012694/instances/31132854675811ea9b65482b3c4d5e1f/heartbeat] failed, retry.
[2020/03/16 16:30:26.380][INFO][Change service center address from 18.35.41.171:30100 to 18.35.41.171:30100][org.apache.servicecomb.serviceregistry.client.IpPortManager][getNextAvailableAddress,100][registry-vert.x-eventloop-thread-0]Change service center address from 18.35.41.171:30100 to 18.35.41.171:30100
[2020/03/16 16:30:26.381][ERROR][Unexpected error in server.cause:SSLException,message:handshake timed out][org.apache.servicecomb.transport.rest.vertx.RestServerVerticle][lambda$start$1,112][vert.x-eventloop-thread-24]Unexpected error in server.cause:SSLException,message:handshake timed out
[2020/03/16 16:30:26.389][WARN][sc task taken more than 36505ms to execute][org.apache.servicecomb.serviceregistry.task.ServiceCenterTaskMonitor][endCycle,51][Service Center Task [java.util.concurrent.ThreadPoolExecutor$Worker@4ad1ca85[State = -1, empty queue][95]]]sc task taken more than 36505ms to execute
[2020/03/16 16:36:27.070][INFO][stats of instance dc550f7965a311ea9b65482b3c4d5e1f removed.][org.apache.servicecomb.loadbalance.ServiceCombLoadBalancerStats][onRemoval,145][LoadBalancerStatsTimer]stats of instance dc550f7965a311ea9b65482b3c4d5e1f removed.
[2020/03/16 16:36:27.071][ERROR][Failed to send request, local:18.35.41.171:34328, remote:/18.35.41.171:9086.][org.apache.servicecomb.transport.rest.client.http.RestClientInvocation][lambda$invoke$0,104][vert.x-eventloop-thread-3]Failed to send request, local:18.35.41.171:34328, remote:/18.35.41.171:9086.
io.vertx.core.VertxException: Connection was closed
[2020/03/16 16:36:27.071][ERROR][service CONSUMER rest CISAresService.configNotifications.pollNotification, call error, msg is cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:VertxException,message:Connection was closed, server is rest://18.35.41.171:9086?sslEnabled=true ][org.apache.servicecomb.loadbalance.LoadbalanceHandler][lambda$null$0,370][vert.x-eventloop-thread-3]service CONSUMER rest CISAresService.configNotifications.pollNotification, call error, msg is cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:VertxException,message:Connection was closed, server is rest://18.35.41.171:9086?sslEnabled=true 
[2020/03/16 16:36:27.072][ERROR][Invoke server failed. Operation CONSUMER rest CISAresService.configNotifications.pollNotification; server rest://18.35.41.171:9086?sslEnabled=true; 0-0 msg cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:VertxException,message:Connection was closed][org.apache.servicecomb.loadbalance.LoadbalanceHandler][onExceptionWithServer,295][vert.x-eventloop-thread-3]Invoke server failed. Operation CONSUMER rest CISAresService.configNotifications.pollNotification; server rest://18.35.41.171:9086?sslEnabled=true; 0-0 msg cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:VertxException,message:Connection was closed
[2020/03/16 16:36:27.082][ERROR][Unexpected error in server.cause:SSLException,message:Received close_notify during handshake][org.apache.servicecomb.transport.rest.vertx.RestServerVerticle][lambda$start$1,112][vert.x-eventloop-thread-23]Unexpected error in server.cause:SSLException,message:Received close_notify during handshake
[2020/03/16 16:36:27.091][ERROR][Unexpected error in server.cause:SSLException,message:Received close_notify during handshake][org.apache.servicecomb.transport.rest.vertx.RestServerVerticle][lambda$start$1,112][vert.x-eventloop-thread-19]Unexpected error in server.cause:SSLException,message:Received close_notify during handshake
[2020/03/16 16:36:27.092][ERROR][Unexpected error in server.cause:SSLException,message:Received close_notify during handshake][org.apache.servicecomb.transport.rest.vertx.RestServerVerticle][lambda$start$1,112][vert.x-eventloop-thread-22]Unexpected error in server.cause:SSLException,message:Received close_notify during handshake
[2020/03/16 16:36:27.089][ERROR][Unhandled exception][io.vertx.core.impl.ContextImpl][reportException,342][vert.x-eventloop-thread-21]Unhandled exception
java.lang.IllegalStateException: Response is closed
	at io.vertx.core.http.impl.HttpServerResponseImpl.checkValid(HttpServerResponseImpl.java:575) ~[vertx-core-3.7.0.jar:3.7.0]
	at io.vertx.core.http.impl.HttpServerResponseImpl.end(HttpServerResponseImpl.java:323) ~[vertx-core-3.7.0.jar:3.7.0]
	at org.apache.servicecomb.foundation.vertx.http.VertxServerResponseToHttpServletResponse.internalFlushBuffer(VertxServerResponseToHttpServletResponse.java:122) ~[foundation-vertx-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.foundation.vertx.http.VertxServerResponseToHttpServletResponse.lambda$flushBuffer$0(VertxServerResponseToHttpServletResponse.java:112) ~[foundation-vertx-1.2.1.jar:1.2.1]
	at io.vertx.core.impl.ContextImpl.executeTask(ContextImpl.java:320) ~[vertx-core-3.7.0.jar:3.7.0]
	at io.vertx.core.impl.EventLoopContext.lambda$executeAsync$0(EventLoopContext.java:38) ~[vertx-core-3.7.0.jar:3.7.0]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) [netty-all-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) [netty-all-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [netty-all-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [netty-all-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-all-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-all-4.1.45.Final.jar:4.1.45.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_242]

**客户端日志：**
[2020/03/16 16:30:08.792][ERROR][Failed to send request, local:not connected, remote:/18.35.41.171:9087.][org.apache.servicecomb.transport.rest.client.http.RestClientInvocation][lambda$invoke$0,104][vert.x-eventloop-thread-1]
javax.net.ssl.SSLHandshakeException: Failed to create SSL connection
	at io.vertx.core.net.impl.ChannelProvider$1.userEventTriggered(ChannelProvider.java:111) [vertx-core-3.7.0.jar:3.7.0]
	at io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:344) [netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:330) [netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:322) [netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.handler.ssl.SslUtils.handleHandshakeFailure(SslUtils.java:347) [netty-handler-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.handler.ssl.SslHandler$5.run(SslHandler.java:2004) [netty-handler-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98) [netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:170) [netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164) [netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472) [netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [netty-transport-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) [netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.45.Final.jar:4.1.45.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.45.Final.jar:4.1.45.Final]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_242]
Caused by: javax.net.ssl.SSLException: handshake timed out
	at io.netty.handler.ssl.SslHandler$5.run(SslHandler.java:2001) ~[netty-handler-4.1.45.Final.jar:4.1.45.Final]
	... 9 more","从服务端日志看， 和 service-center, 和 rest://18.35.41.171:9086 的连接都失败了， 很可能是这个节点和其他服务的网络不可达。 也可能这个服务出现了类似挂死的故障，可以观察下这个服务的CPU或者内存是否特别高。 ",91674936
263,在A服务中引入了inspector，在B服务中能够通过cse调用获取到A服务的接口文档,open,2020-03-23T07:18:30Z,2020-03-23T07:55:15Z,,NONE,如题，在A服务中引入了inspector，在B服务中能够通过cse调用获取到A服务的swagger形式的接口文档？,理论上可以的， 参考[inspector说明](https://docs.servicecomb.io/java-chassis/zh_CN/featured-topics/using-inspector/)， 注意 inspector 功能不建议暴露给用户直接使用， 不能够将业务功能建立在依赖这个功能之上，只作为不重要的维护功能。 ,91674936
264,TLS传输明文配置私钥口令,open,2020-03-20T07:00:21Z,2020-03-26T01:30:11Z,,NONE,"microservice.yaml文件中启用TLS通信的配置
ssl.protocols: TLSv1.2
ssl.authPeer: true
ssl.checkCN.host: true

#########certificates config
ssl.trustStore: trust.jks
ssl.trustStoreType: JKS
ssl.trustStoreValue: Changeme_123
ssl.keyStore: server.p12
ssl.keyStoreType: PKCS12
ssl.keyStoreValue: Changeme_123
ssl.crl: revoke.crl
ssl.sslCustomClass: org.apache.servicecomb.demo.DemoSSLCustom

明文配置的私钥口令是Changeme_123,导致私钥泄露风险极大",你可以自定义 `ssl.sslCustomClass` ， 然后提供加密解密措施。 ,91674936
265,edge由于某个后端服务响应慢导致整体故障，影响了其他后端服务的转发,open,2020-03-19T14:05:40Z,2020-03-20T03:19:35Z,,NONE,"现网edge出现大量block，整体故障处于无法服务状态。定位到某个后端服务影响慢，导致edge也转发不了请求给其他的后端服务，这种情况是否说明使用reactive模式存在很大的风险？


2020-03-19 13:34:16.654|SR|WARN |vertx-blocked-thread-checker|{}|io.vertx.core.impl.BlockedThreadChecker$1.run(BlockedThreadChecker.java:55)|Thread Thread[vert.x-eventloop-thread-0,5,main] has been blocked for 228655 ms, time limit is 2000 ms
io.vertx.core.VertxException: Thread blocked
	at io.vertx.core.http.impl.HttpServerResponseImpl.setChunked(HttpServerResponseImpl.java:138) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.http.impl.HttpServerResponseImpl.setChunked(HttpServerResponseImpl.java:55) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at com.huawei.common.util.UrlRedirectUtil.lambda$urlRequest$3(UrlRedirectUtil.java:87) ~[classes!/:?]
	at com.huawei.common.util.UrlRedirectUtil$$Lambda$282/1597685093.handle(Unknown Source) ~[?:?]
	at io.vertx.core.http.impl.HttpClientRequestImpl.doHandleResponse(HttpClientRequestImpl.java:430) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.http.impl.HttpClientRequestBase.doHandleResponse(HttpClientRequestBase.java:175) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.http.impl.HttpClientRequestBase.checkHandleResponse(HttpClientRequestBase.java:162) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.http.impl.HttpClientRequestBase.handleResponse(HttpClientRequestBase.java:146) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.http.impl.Http1xClientConnection.handleResponseBegin(Http1xClientConnection.java:624) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.http.impl.Http1xClientConnection.handleHttpMessage(Http1xClientConnection.java:594) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.http.impl.Http1xClientConnection.handleMessage(Http1xClientConnection.java:560) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.net.impl.ConnectionBase.handleRead(ConnectionBase.java:397) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.net.impl.VertxHandler$$Lambda$71/499332961.handle(Unknown Source) ~[?:?]
	at io.vertx.core.impl.ContextImpl.executeTask(ContextImpl.java:320) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.impl.EventLoopContext.execute(EventLoopContext.java:43) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.impl.ContextImpl.executeFromIO(ContextImpl.java:188) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.vertx.core.net.impl.VertxHandler.channelRead(VertxHandler.java:174) ~[vertx-core-3.6.3.jar!/:3.6.3]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:438) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310) ~[netty-codec-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297) ~[netty-codec-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413) ~[netty-codec-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) ~[netty-codec-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:253) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) ~[netty-handler-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1407) ~[netty-handler-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1177) ~[netty-handler-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1221) ~[netty-handler-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) ~[netty-codec-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428) ~[netty-codec-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) ~[netty-codec-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1434) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:965) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:646) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:581) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460) ~[netty-transport-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884) ~[netty-common-4.1.28.Final.jar!/:4.1.28.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.28.Final.jar!/:4.1.28.Final]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_222]","package com.huawei.common.util;

import com.huawei.common.config.ConfigUtil;
import com.huawei.common.config.KeyConfigUtil;
import com.huawei.common.log.LogUtil;
import com.huawei.servicerouting.filter.HttpEventServletFilter;
import io.vertx.core.Vertx;
import io.vertx.core.http.HttpClient;
import io.vertx.core.http.HttpClientOptions;
import io.vertx.core.http.HttpClientRequest;
import io.vertx.ext.web.RoutingContext;
import org.apache.servicecomb.transport.rest.client.TransportClientConfig;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.net.URI;

import static com.huawei.common.util.SrUtil.CLIENT_RESPONSE;

public class UrlRedirectUtil {

    private static final Logger LOG = LoggerFactory.getLogger(UrlRedirectUtil.class);


    private static Vertx vertx = Vertx.vertx();
    private static HttpClient httpsClient = null;
    private static HttpClient httpClient = null;

    static
    {
        HttpClientOptions options = new HttpClientOptions();
        options.setSsl(true)
        .setTrustAll(true)
        .setVerifyHost(false)
        .setIdleTimeout(TransportClientConfig.getConnectionIdleTimeoutInSeconds())
        .setKeepAlive(TransportClientConfig.getConnectionKeepAlive())
        .setConnectTimeout(KeyConfigUtil.getConnectTimeOut())
        .setMaxPoolSize(TransportClientConfig.getConnectionMaxPoolSize())
        .setMaxHeaderSize(ConfigUtil.getIntConfig(""MaxHeaderSize"", 32000))
        .setMaxInitialLineLength(ConfigUtil.getIntConfig(""MaxInitialLineLength"", HttpClientOptions.DEFAULT_MAX_INITIAL_LINE_LENGTH));
        httpsClient = vertx.createHttpClient(options);

        HttpClientOptions option = new HttpClientOptions();
        //option.setMaxPoolSize() 目前没有限制，设置了会导致新请求拒绝。
        option.setVerifyHost(false)
                .setIdleTimeout(TransportClientConfig.getConnectionIdleTimeoutInSeconds())
                .setKeepAlive(TransportClientConfig.getConnectionKeepAlive())
                .setConnectTimeout(KeyConfigUtil.getConnectTimeOut())
                .setMaxPoolSize(TransportClientConfig.getConnectionMaxPoolSize())
                .setMaxHeaderSize(ConfigUtil.getIntConfig(""MaxHeaderSize"", 32000))
                .setMaxInitialLineLength(ConfigUtil.getIntConfig(""MaxInitialLineLength"", HttpClientOptions.DEFAULT_MAX_INITIAL_LINE_LENGTH));
        httpClient = vertx.createHttpClient(option);
    }

    private static URI getUri(String url) throws Exception
    {
        return new URI(url);
    }

    @SuppressWarnings(""deprecation"")
    public static void urlRequest(RoutingContext context, String url)
    {
        try {
            LOG.info(""Start to deliver by IP={}"", url);

            URI uri = getUri(url);
            HttpClient tempClient = null;
            if (url.startsWith(""https://"")) {
                tempClient = httpsClient;
            }
            else {
                tempClient = httpClient;
            }

            String requestId = LogUtil.getRequestId();

            long startTime = System.currentTimeMillis();
            context.put(HttpEventServletFilter.HTTP_START_TIME, startTime);

            // 使用HttpClient转发请求
            HttpClientRequest clietRequest =
                    tempClient.request(context.request().method(),
                            uri.getPort(),
                            uri.getHost(),
                            context.request().uri(),
                            clientResponse -> {

                                context.request().response().setChunked(true);
                                context.request().response().setStatusCode(clientResponse.statusCode());
                                context.request().response().headers().setAll(clientResponse.headers());
                                context.request().response().headers().set(LogUtil.SRREQUESTID, requestId);

                                clientResponse.handler(data -> {
                                    context.request().response().write(data);
                                    context.put(CLIENT_RESPONSE, data.toString(""UTF-8""));
                                });

                                clientResponse.exceptionHandler(e -> {
                                    LogUtil.putContext(LogUtil.SRREQUESTID, requestId);
                                    SrUtil.handleException(context, e);
                                    LogUtil.clearContext();
                                });

                                clientResponse.endHandler((v) -> {
                                    LogUtil.putContext(LogUtil.SRREQUESTID, requestId);
                                    SrUtil.endResponse(context);
                                    LogUtil.clearContext();
                                });

                            });

            clietRequest.setChunked(true);
            clietRequest.headers().setAll(context.request().headers().remove(""Content-Length"").remove(""Host"").remove(""Connection"").remove(""Cache-Control""));
            clietRequest.setTimeout(KeyConfigUtil.getTotalTimeOut());
            // 吧请求ServiceRoutign的消息体写到clietRequest
            context.request().handler(clietRequest::write);

            clietRequest.exceptionHandler(v->{
                LogUtil.putContext(LogUtil.SRREQUESTID, requestId);
                SrUtil.handleException(context, v);
                LogUtil.clearContext();
            });


            // 异步发送请求
            context.request().endHandler((v) -> clietRequest.end());
        }
        catch (Exception e) {
            SrUtil.handleException(context, e);
        } finally {
            LogUtil.clearContext();
        }
    }
}
",91674936
266,【Feature Request】Support @JsonView,open,2020-03-19T02:12:13Z,2020-03-26T01:31:24Z,,NONE,"In our project we have many dataObjects, they came from kafka (with multiple different format), saved into redis and db and returned  in rest api in more than one flavors. To properly handle them we have a bunch of classes like `PersonEntity/Person/PersonDTO/PersonDTOWithName`, all of them are terribly similiar which smells really bad. We need a more efficent and cleaner way to express the intention to  (de)serialize same json with different property or alias.

Some modification in `org.apache.servicecomb.common.rest.codec.param.BodyProcessorCreator.BodyProcessor#getValue` and `org.apache.servicecomb.common.rest.codec.produce.ProduceJsonProcessor#doEncodeResponse` shall be enough.",,91674936
267,rest.addres:0.0.0.0，有改为自动获取虚机ip的方法,open,2020-03-17T03:23:17Z,2020-03-17T08:13:03Z,,NONE,"由于公司信息安全要求，绑定地址不能为0.0.0.0；
有方法改为listen：
cse:
   listen:eth0:8989

但是我的程序可以启动注册，但是访问不了，不知道这个rest改为listen有没有什么现在，或者其他方法
多谢！",多谢，知道结论了，建议后续可以考虑加上：发布地址都可以，监听地址也支持，达到统一性,91674936
268,ConvertCommon转换微服务接口的返回值时失败，使用ConvertSame无此问题,open,2020-03-16T11:42:09Z,2020-03-18T01:19:40Z,,NONE,"报错信息：
Cannot construct instance of ‘org.spirngframework.http.ResponseEntity’ (no Creators, like default constructor, ... )

CSE版本：2.3.77.B001

接口定义：
    @RequestMapping(value = ""/v2/ping"", method = RequestMethod.POST, produces = ""application/json"")
    @Override
    public ResponseEntity<JSONObject> ping(@RequestHeader(name = HeaderParam.SESSION_ID) String sessionId) {
        transTraceId(0);

        ResponseEntity response =
            new ResponseEntity(new Result(""open call service is running""), buildResponseHead(sessionId), HttpStatus.OK);
        return response;
    }

自定义的swagger：
  /v2/ping:
    post:
      operationId: ""ping""
      produces:
        - ""application/json""
      parameters:
        - name: ""X-Session-Id""
          in: ""header""
          required: true
          type: ""string""
      responses:
        ""200"":
          description: ""response of 200""
          schema:
            type: ""object""
            additionalProperties:
              type: ""object""
另外，不使用自定义swagger文件，使用swagger generator，接口访问OK","这个我在本地试了一把. 启动没问题.. 没复现你的效果, 你手写的契约是不是 **写错了** ...

```java

  @RequestMapping(value = ""/v2/ping"", method = RequestMethod.POST, produces = ""application/json"")
  public ResponseEntity<Person> ping(@RequestHeader(name = ""sess"") String sessionId) {

    ResponseEntity<Person> response =
            new ResponseEntity(new Person(), HttpStatus.OK);
    return response;
  }

```

**swagger 契约**

```
  /v2/ping:
    post:
      operationId: ""ping""
      produces:
      - ""application/json""
      parameters:
      - name: ""sess""
        in: ""header""
        required: true
        type: ""string""
      responses:
        ""200"":
          description: ""response of 200""
          schema:
            $ref: ""#/definitions/Person""

```

java 如下:

```

  @RequestMapping(value = ""/v2/ping"", method = RequestMethod.POST, produces = ""application/json"")
  public ResponseEntity<Object> ping(@RequestHeader(name = ""sess"") String sessionId) {

    ResponseEntity<Object> response =
            new ResponseEntity(new Object(), HttpStatus.OK);
    return response;
  }
```
swagger 契约
```
  /v2/ping:
    post:
      operationId: ""ping""
      produces:
      - ""application/json""
      parameters:
      - name: ""sess""
        in: ""header""
        required: true
        type: ""string""
      responses:
        ""200"":
          description: ""response of 200""
          schema:
            type: ""object""

```
",91674936
269,servicecomb的yaml配置文件，配置项无法通过集成Jasypt方式进行加解密,open,2020-03-13T16:35:04Z,2020-03-26T01:31:39Z,,NONE,项目中jasypt-spring-boot-starter可以对spring的配置项进行加解密处理，有没有办法使用jasypt处理microservices.yaml的配置项，求助,,91674936
270, Cannot deserialize instance of `java.lang.String` out of START_OBJECT token,open,2020-03-13T01:59:31Z,2020-03-13T03:58:58Z,,NONE,"接口测试提示内容
CommonExceptionData [message=Parameters not valid or types not match.]

异常堆栈
java.lang.IllegalArgumentException: Cannot deserialize instance of `java.lang.String` out of START_OBJECT token
 at [Source: UNKNOWN; line: -1, column: -1]
	at com.fasterxml.jackson.databind.ObjectMapper._convert(ObjectMapper.java:3750) ~[jackson-databind-2.9.9.jar:2.9.9]
	at com.fasterxml.jackson.databind.ObjectMapper.convertValue(ObjectMapper.java:3688) ~[jackson-databind-2.9.9.jar:2.9.9]
	at org.apache.servicecomb.swagger.invocation.converter.impl.ConverterCommon.convert(ConverterCommon.java:36) ~[swagger-invocation-core-1.3.0.jar:1.3.0]
","这个一般是body参数的格式不对，你贴的堆栈已经把问题位置打出来了
`org.apache.servicecomb.swagger.invocation.converter.impl.ConverterCommon.convert(ConverterCommon.java:36) ~[swagger-invocation-core-1.3.0.jar:1.3.0]`
建议在这里打断点看看转换的参数原文是什么样的吧？",91674936
271,org.apache.servicecomb.foundation.common.exceptions.ServiceCombException: all transport named rest refused to init.,open,2020-03-12T03:17:52Z,2020-03-16T00:52:19Z,,NONE,"注册服务出现异常，多次更换端口号不起作用，java.lang.IllegalStateException: ServiceComb init failed.
	at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:231) ~[java-chassis-core-1.3.0.jar:1.3.0]
	at org.apache.servicecomb.core.CseApplicationListener.onApplicationEvent(CseApplicationListener.java:81) ~[java-chassis-core-1.3.0.jar:1.3.0]
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:402) ~[spring-context-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:359) ~[spring-context-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.boot.context.event.EventPublishingRunListener.running(EventPublishingRunListener.java:102) ~[spring-boot-2.1.6.RELEASE.jar:2.1.6.RELEASE]
	at org.springframework.boot.SpringApplicationRunListeners.running(SpringApplicationRunListeners.java:77) ~[spring-boot-2.1.6.RELEASE.jar:2.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:326) [spring-boot-2.1.6.RELEASE.jar:2.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1213) [spring-boot-2.1.6.RELEASE.jar:2.1.6.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1202) [spring-boot-2.1.6.RELEASE.jar:2.1.6.RELEASE]
	at org.appstore.mec.MainServer.main(MainServer.java:16) [classes/:na]
Caused by: org.apache.servicecomb.foundation.common.exceptions.ServiceCombException: all transport named rest refused to init.
	at org.apache.servicecomb.core.transport.TransportManager.chooseOneTransport(TransportManager.java:90) ~[java-chassis-core-1.3.0.jar:1.3.0]
	at org.apache.servicecomb.core.transport.TransportManager.buildTransportMap(TransportManager.java:74) ~[java-chassis-core-1.3.0.jar:1.3.0]",可以参考 [transports](https://docs.servicecomb.io/java-chassis/zh_CN/transports/rest-over-servlet/)，  java-chassis支持多种不同的transport， 如果所有的transport初始化失败，则会报告上面的错误。 加了transport-rest-vertx，相当于引入了REST over vert.x,91674936
272,打成jar包形式的servicecomb，启动时找不到ssl认证文件,open,2020-03-09T09:37:17Z,2020-03-16T01:04:32Z,,NONE,"认证文件放在resourecs中，并且一起打包在jar文件中，在启动的时候报错找不到认证文件。
难道不能引用jar内部的认证文件？

[2020-03-09 17:27:25,250][WARN][vert.x-eventloop-thread-15][VertxTLSBuilder.java][]keyStore **[file:/D:/code/github-zhangby/user-mgmt/target/user-mgmt-be.jar!/tls/openmep.p12] file not exist**, please check! org.apache.servicecomb.foundation.vertx.VertxTLSBuilder.buildTCPSSLOptions(VertxTLSBuilder.java:118)
[2020-03-09 17:27:25,271][WARN][vert.x-eventloop-thread-15][VertxTLSBuilder.java][]trustStore **[file:/D:/code/github-zhangby/user-mgmt/target/user-mgmt-be.jar!/tls/openmep.truststore]** file not exist, please check! org.apache.servicecomb.foundation.vertx.VertxTLSBuilder.buildTCPSSLOptions(VertxTLSBuilder.java:138)
[2020-03-09 17:27:25,270][ERROR][vert.x-eventloop-thread-5][RestServerVerticle.java][] org.apache.servicecomb.transport.rest.vertx.RestServerVerticle.start(RestServerVerticle.java:118)
io.vertx.core.VertxException: io.vertx.core.VertxException: Key/certificate is mandatory for SSL
        at io.vertx.core.net.impl.SSLHelper.createContext(SSLHelper.java:299) ~[vertx-core-3.6.3.jar:3.6.3]
        at io.vertx.core.net.impl.SSLHelper.getContext(SSLHelper.java:474) ~[vertx-core-3.6.3.jar:3.6.3]
        at io.vertx.core.net.impl.SSLHelper.validate(SSLHelper.java:499) ~[vertx-core-3.6.3.jar:3.6.3]
        at io.vertx.core.http.impl.HttpServerImpl.listen(HttpServerImpl.java:220) ~[vertx-core-3.6.3.jar:3.6.3]
        at io.vertx.core.http.impl.HttpServerImpl.listen(HttpServerImpl.java:191) ~[vertx-core-3.6.3.jar:3.6.3]
        at org.apache.servicecomb.transport.rest.vertx.RestServerVerticle.startListen(RestServerVerticle.java:216) ~[transport-rest-vertx-1.3.0.jar:1.3.0]
        at org.apache.servicecomb.transport.rest.vertx.RestServerVerticle.start(RestServerVerticle.java:115) ~[transport-rest-vertx-1.3.0.jar:1.3.0]
        at io.vertx.core.impl.DeploymentManager.lambda$doDeploy$8(DeploymentManager.java:494) ~[vertx-core-3.6.3.jar:3.6.3]
        at io.vertx.core.impl.ContextImpl.executeTask(ContextImpl.java:320) ~[vertx-core-3.6.3.jar:3.6.3]
        at io.vertx.core.impl.EventLoopContext.lambda$executeAsync$0(EventLoopContext.java:38) ~[vertx-core-3.6.3.jar:3.6.3]
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.36.Final.jar:4.1.36.Final]
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:405) [netty-common-4.1.36.Final.jar:4.1.36.Final]
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500) [netty-transport-4.1.36.Final.jar:4.1.36.Final]
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906) [netty-common-4.1.36.Final.jar:4.1.36.Final]
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.36.Final.jar:4.1.36.Final]
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.36.Final.jar:4.1.36.Final]
        at java.lang.Thread.run(Unknown Source) [?:1.8.0_241]
Caused by: io.vertx.core.VertxException: Key/certificate is mandatory for SSL
        at io.vertx.core.net.impl.SSLHelper.createContext(SSLHelper.java:259) ~[vertx-core-3.6.3.jar:3.6.3]
        ... 16 more
",证书确实无法打包在jar包内. 建议证书外挂,91674936
273,通过edge访问返回response content-type application/json; charset=utf-8 is not supported,open,2020-03-06T11:07:33Z,2020-03-17T03:22:03Z,,NONE,"通过edge访问一个接口，返回`{
    ""message"": ""method POST, path xxx statusCode 200, reasonPhrase OK, response content-type application/json; charset=utf-8 is not supported""
}`，返回码为400，如果直接访问返回`{
    ""result"": {
        ""code"": 200,
        ""message"": ""xxx""
    }
}`",给一个demo吧. 看的不是很明白. ,91674936
274,跟SpringMVC共用的时候会存在路径冲突,open,2020-03-05T12:34:18Z,2020-03-26T02:54:49Z,,NONE,"```
@RestSchema(schemaId = ""RepeatServiceA"")
@RequestMapping(path = ""/rest/repeat-a"")
public class RepeatService 

@RestController(""RepeatServiceB"")
@RequestMapping(path = ""/rest/repeat-a"")
public class RepeatService {
```
比如下面这两种，因路径冲突SpringMVC会报“Ambiguous mapping”异常。即使CSE和SpringMVC分别声明了独立的根路径。这种问题有什么解决建议吗？
```
spring:
  mvc:
    servlet:
      path: /ui
servicecomb: 
    servlet:
      urlPattern: /cse/*
```",@liubao68 因为CSE和SpringMVC是分别编写的，很难控制命名冲突，比如同样一个用户创建的接口，CSE和SpringMVC可能都叫/user/create，目前的规避措施是SpringMVC全都加上一层前缀，如：/web/user/create，但体验就比较差了。,91674936
275,edge配置是如何设置默认配置的？可以根据服务名自动转发服务,open,2020-03-04T07:42:09Z,2020-03-05T02:40:18Z,,NONE,"后台我有好几个服务，不想每个都配置map映射，想通过default配置实现自动转发，如下配置：
如果我有两个微服务，microserviceName是serverA，提供的url是 /v1/users
另一个微服务microserviceName是serverB，提供url是 server-b/v1/hosts
请教一下，defalut如何配置带服务名自动转发？ js中如何正确构造 url 
```yaml
servicecomb:
  http:
    dispatcher:
      edge:
        default:
          enabled: true
          prefix: rest
          withVersion: true
          prefixSegmentCount: 1
```",不客气 : ),91674936
276,ServiceComb 进行RPC调用时RestClientInvocation可以支持自已实现么？,open,2020-03-04T02:04:58Z,2020-03-05T10:45:02Z,,NONE,ServiceComb 进行RPC调用时会通过RestClientInvocation进行转发，这个类支持自定义扩展么？如果可以该如何配置？,"@yhs0092 已经回了, 可以在 #1611 中讨论",91674936
277,启动TLS后，前台通过cse调用后台接口，返回490错误,open,2020-03-03T14:07:50Z,2020-03-04T03:41:12Z,,NONE,"前后调用后台，启动tls后，cse调用报  490错误
response： {""message"":""Cse Internal Bad Request""}
求助该如何定位解决，配置文件如下

前台配置：
```yaml
# all interconnected microservices must belong to an application wth the same ID
APPLICATION_ID: openMec
service_description:
# name of the declaring microservice
  name: meo-website
  version: 1.0.0
  environment: development
servicecomb:
  service:
    registry:
      address: http://127.0.0.1:30100
  rest:
    address: 0.0.0.0:8081?sslEnabled=true  #Rest通信地址

  tracing:
    enabled: false

  http:
    dispatcher:
      edge:
        default:
          enabled: false
          prefix: api
          withVersion: false
          prefixSegmentCount: 1
        url:
          enabled: true
          mappings:
            user-mgmt-be:
              prefixSegmentCount: 1
              path: ""/user-mgmt-be/.*""
              microserviceName: user-mgmt-be
              versionRule: 0.0.0+
  cors:
    enabled: true
    origin: ""*""
    allowCredentials: false
    allowedMethod: GET,POST,HEAD,OPTIONS,PUT,DELETE
    allowedHeader: x-rest-version,Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,Authorization
    exposedHeader: Location

#########SSL options
ssl.protocols: TLSv1.2
ssl.authPeer: false
ssl.checkCN.host: false

#########certificates config
ssl.trustStore: openmep.truststore
ssl.trustStoreType: JKS
ssl.trustStoreValue: 111111
ssl.keyStore: openmep.p12
ssl.keyStoreType: PKCS12
ssl.keyStoreValue: 111111
#ssl.crl: revoke.crl
ssl.sslCustomClass: org.mec.website.OpenMecSSLCustom
```

后台配置：
```yaml
servicecomb-config-order: 1
APPLICATION_ID: openMec  #应用名
service_description:
  name: user-mgmt-be  #微服务名
  version: 1.0.0   #微服务版本
  environment: development
servicecomb:
  service:
    registry:
      address: http://127.0.0.1:30100  #连接SC(Service Center,注册中心)的地址
 #     address: http://service-center:30100  #连接SC(Service Center,注册中心)的地址
  rest:
    address: 0.0.0.0:8067?sslEnabled=true  #Rest通信地址

  handler:
    chain:
      Provider:
        default: bizkeeper-provider

  cors:
    enabled: true
    origin: ""*""
    allowCredentials: false
    allowedMethod: GET,POST,HEAD,OPTIONS,PUT,DELETE
    allowedHeader: x-rest-version,Content-Type,X-Requested-With,accept,Origin,Access-Control-Request-Method,Access-Control-Request-Headers,Authorization
    exposedHeader: Location

#########SSL options
ssl.protocols: TLSv1.2
ssl.authPeer: false
ssl.checkCN.host: true

#########certificates config
ssl.trustStore: openmep.truststore
ssl.trustStoreType: JKS
ssl.trustStoreValue: 111111
ssl.keyStore: openmep.p12
ssl.keyStoreType: PKCS12
ssl.keyStoreValue: 111111
#ssl.crl: revoke.crl
ssl.sslCustomClass: org.mec.houp.user.tls.OpenMecSSLCustom
```","删除证书重新添加后，又报490错了，帮忙看一下，在我的私有库上
https://github.com/zhangbeiyuan-hw/test-project",91674936
278,将多个query参数聚合为一个POJO类，同时使用POJO和@RequestHeader会导致NullPointerException异常,open,2020-03-03T09:47:41Z,2020-03-04T01:31:31Z,,NONE,"Caused by: java.lang.NullPointerException: null
	at org.apache.servicecomb.swagger.invocation.arguments.producer.ProducerArgumentsMapperFactory.generateDefaultParamMapper(ProducerArgumentsMapperFactory.java:117)
	at org.apache.servicecomb.swagger.invocation.arguments.producer.ProducerArgumentsMapperFactory.generateParamMapperByName(ProducerArgumentsMapperFactory.java:103)
	at org.apache.servicecomb.swagger.invocation.arguments.producer.ProducerArgumentsMapperFactory.collectSwaggerArgumentsMapper(ProducerArgumentsMapperFactory.java:96)
	at org.apache.servicecomb.swagger.invocation.arguments.ArgumentsMapperFactory.collectArgumentsMapper(ArgumentsMapperFactory.java:90)
	at org.apache.servicecomb.swagger.invocation.arguments.producer.ProducerArgumentsMapperFactory.createArgumentsMapper(ProducerArgumentsMapperFactory.java:65)
	at org.apache.servicecomb.swagger.engine.SwaggerEnvironment.createProducer(SwaggerEnvironment.java:187)
	at org.apache.servicecomb.core.definition.schema.ProducerSchemaFactory.getOrCreateProducerSchema(ProducerSchemaFactory.java:78)
	at org.apache.servicecomb.provider.rest.common.RestProducerProvider.init(RestProducerProvider.java:45)
	at org.apache.servicecomb.core.provider.producer.ProducerProviderManager.init(ProducerProviderManager.java:54)
	at org.apache.servicecomb.core.SCBEngine.doInit(SCBEngine.java:246)
	at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:214)
	... 12 common frames omitted

接口定义如下：
@RequestMapping(value = ""/events"", method = RequestMethod.GET)
    public ResponseEntity<?> queryEvents(@PathVariable(value = ""project_id"") String projectId,
        @RequestHeader(value = TOKEN_KEY) String token, @Valid QueryAlarmEventBody body) {
        return null;
    }",当前对value 的实现有问题. 是按照name 实现的,91674936
279,bmi/webapp 这里sample如何启动，webroot是不是需要配置static的绝对路径？,open,2020-03-03T09:10:47Z,2020-03-26T01:40:01Z,,NONE,"配置如下，这里是否要配置绝对路径，能否按照相对路径配置到resuource/static下？windows系统下怎么配置？
# This is web root for windows server, change this path according to where you put your source code
gateway:
  webroot: /code/servicecomb-samples/java-chassis-samples/bmi/webapp/src/main/resources/static


2020-03-03 17:08:41.143 ERROR 9760 --- [ntloop-thread-5] o.a.s.c.rest.locator.OperationLocator    : locate path failed, status:Not Found, http method:GET, path:/index.html/, microserviceName:gateway","[BMI 例子](https://github.com/apache/servicecomb-samples/tree/master/java-chassis-samples/bmi) 里面有配置。 就是你发的：

```
gateway:
    webroot: /code/servicecomb-samples/java-chassis-samples/bmi/webapp/src/main/resources/static
```

这个是windows配置， linux配置的话，只能用相对路径 


你也可以尝试修改代码 [StaticWebpageDispatcher](https://github.com/apache/servicecomb-samples/blob/master/java-chassis-samples/bmi/webapp/src/main/java/org/apache/servicecomb/samples/bmi/StaticWebpageDispatcher.java) 提供更好的配置方法。 ",91674936
280,ServiceComb有access.log访问自身的日志，那有没有调用其他服务的outcall.log?如果有该怎么配置？,open,2020-03-03T08:31:44Z,2020-03-20T06:29:41Z,,NONE,ServiceComb有access.log访问自身的日志，那有没有调用其他服务的outcall.log?如果有该怎么配置？,太感谢了，这个扩展功能做的挺好的。再问下，这个特性会在哪个版本开始支持。,91674936
281,ServiceComb在RPC调用时如果业务请求报错了怎么样才能拿到请求报错的InvocationContext ？,open,2020-03-03T08:20:24Z,2020-03-04T06:47:27Z,,NONE,"在RPC调用时发生了请求异常，此时异常在try-catch中捕获，
如果在当前想要拿到此次RPC请求的异常的InvocationContext ，该怎么取？有办法取吗？",当RPC请求产生异常报错的时候，该报错信息会抛到业务层面上来，如果能在catch位置拿到作为Client时的InvocationContext，就能从里面拿到我设置的变量进行下一步的业务处理。或者这样实现不是很合理。我当前需要做一个记录服务外部调用的功能，想通过ServiceComb框架做一个通用点的实现。不知道有没有更简单的实现？,91674936
282,前后台服务都注册在sc上，使用cse访问，该如何配置tsl,open,2020-03-03T02:55:38Z,2020-03-03T06:42:54Z,,NONE,"当前所有服务都注册在sc上，前台服务也是通过gateway的方式发布的静态页面，vue中通过cse方式调用后台服务；想请教一下，tsl应该配置在每个servicecomb上？还是配置在servicecenter上？或者两个地方都要配置。
servicecomb中没有配置publishAddress地址，我理解客户端不能通过ip直接访问服务，只能通过servicecenter  cse方式访问；","provider 如果开启了 auth.peer. 你consumer 也需要配置. 否则, 不强制. 

服务中心的 只是管理 服务中心本身是 https 发布, 还是 http 发布. 和你的业务没啥关系",91674936
283,servicecomb1.3+spingboo2，启用了ssl，但是实际https请求会报错,open,2020-03-03T02:32:59Z,2020-03-13T16:36:09Z,,NONE,"servicecomb1.2+spingboo1切换成servicecomb1.3+spingboo2之后，启用ssl的配置失效了
`rest:
    address: 0.0.0.0:8090?sslEnabled=true
########SSL options
ssl:
  protocols: TLSv1.2
  authPeer: false
  ciphers: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_GCM_SHA256
  checkCN:
    host: false
  trustStore: D:/tls/icetruststore.jks
  trustStoreType: JKS
  trustStoreValue: 123456
  keyStore: D:/tls/icekeystore.jks
  keyStoreType: JKS
  keyStoreValue: 123456`
报错日志
`2020-03-03 10:31:14.105  INFO 30000 --- [nio-8090-exec-7] o.apache.coyote.http11.Http11Processor   : Error parsing HTTP request header
 Note: further occurrences of HTTP request parsing errors will be logged at DEBUG level.

java.lang.IllegalArgumentException: Invalid character found in method name. HTTP method names must be tokens
	at org.apache.coyote.http11.Http11InputBuffer.parseRequestLine(Http11InputBuffer.java:415) ~[tomcat-embed-core-9.0.29.jar:9.0.29]
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:260) ~[tomcat-embed-core-9.0.29.jar:9.0.29]
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.29.jar:9.0.29]
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:860) [tomcat-embed-core-9.0.29.jar:9.0.29]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1591) [tomcat-embed-core-9.0.29.jar:9.0.29]
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.29.jar:9.0.29]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.29.jar:9.0.29]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]`
这个配置在servicecomb1.2+spingboo1是可以正常启用https","
[demo2.zip](https://github.com/apache/servicecomb-java-chassis/files/4330584/demo2.zip)

通过接口测试https://127.0.0.1:8080/test/hello，报错`java.lang.IllegalArgumentException: Invalid character found in method name. HTTP method names must be tokens`，使用restTemplate.getForEntity(""cse://demo2/test/hello"", String.class)请求则要求create SSL connection，目前我使用springboot2的ssl配置可以正常发布https的rest服务",91674936
284,java的服务（集成java cse的sdk)调用go的服务（集成go cse sdk）通信报错,open,2020-03-03T02:04:16Z,2020-03-04T01:22:45Z,,NONE,"java--> go 报错截图：


go的契约情况：
为空",版本不限,91674936
285,servicecomb可否定制全部的Handler？&servicecomb退出时为何会关闭非守护线程？,open,2020-03-02T07:17:42Z,2020-03-02T07:52:59Z,,NONE,"有两个问题咨询下：
1.SCBEngine在进行初始化时，会进行ProducerProvider的初始化
![image](https://user-images.githubusercontent.com/53045286/75648705-d3180e00-5c8b-11ea-9621-97a4a2868cdb.png)
可以看到框架指定了最后一个Handler——**ProducerOperationHandler，这个Handler作用就是为了进行validator检验的吗？我可否不使用这个Handler？**

2.我在自定义的BootListener监听器中，监听了BEFORE_CLOSE事件：
```
public abstract class AppShutdownBootListener implements BootListener {
    public void onBootEvent(BootEvent bootEvent) {
        switch(bootEvent.getEventType()) {
        case BEFORE_CLOSE:
            this.onBeforeClose();
            break;
        default:
            return;
        }
    }
    private void onBeforeClose() {
        LOGGER.debug(""before close event start"");
        this.thread = new Thread(() -> {
           ......
        }, ""GroupExecutor-monitor-thread"");
        **this.thread.setDaemon(false);**
        this.thread.start();
    }
}
```
在这个事件中，**我开启了一个非守护线程，但是为何随着ServiceComb的JVM钩子线程的结束，进程就退出了**，jvm不是会等待所有的非守护线程结束吗，ServiceComb做了其他操作吗？",,91674936
286,cse本地schema加载,open,2020-03-02T04:13:59Z,2020-03-05T03:30:27Z,,NONE,,你说的“定义第三方接口”是指的[第三方调用](http://1v96us.coding-pages.com/docs/java-chassis/zh_CN/build-consumer/3rd-party-service-invoke/) 的功能吗？第三方调用的接口的契约是根据设置的接口类型自动生成的，不能加载本地手写的契约文件呢,91674936
287,ETCD升级到2.2.3时，使用旧的CA签发证书，server.cer和server.p12文件大小为0,open,2020-02-28T09:32:32Z,2020-02-28T10:10:14Z,,NONE,"ETCD升级到2.2.3时，使用旧的CA签发证书，server.cer和server.p12文件大小为0，但新使用生成的CA就可以成功签发正常文件，keytool版本没有问题，不想更换CA的原因是：业务代码里使用的server.p12和trust.jks，若重新用新的CA签发需要更换掉，会影响现网升级部署，麻烦帮忙看下怎么解决，谢谢！
![image](https://user-images.githubusercontent.com/32881735/75534972-04a49580-5a50-11ea-9a3e-656424ac3b79.png)
",,91674936
288,使用HttpServerFilter拦截请求时无法获取body体内容,open,2020-02-27T02:26:06Z,2020-02-27T10:31:51Z,,NONE,"sdk版本2.5.0。本地使用postman调用服务api，拦截到的httpServletRequestEX中bodyBuffer内容为空。如果放行到正常的代码逻辑里是正常的。其他人使用相同版本和写法就能正常获取
![local](https://user-images.githubusercontent.com/14150277/75406315-1fd9ad00-594b-11ea-88e1-bd512cfd1cf0.jpg)




",可以先看下 httpServletRequestEX 的具体实现类是哪一个， 不同的运行环境这个类的实例不一样， 行为也不一样。 getBodyBuffer 可能为空 。 如果运行于 Servlet 环境， 在实现 HttpServerFilter的时候，注意 'needCacheRequest' 需要返回 true。 ,91674936
289,Is there a plan to support swagger 3.0?,open,2020-02-26T07:47:35Z,2020-02-26T12:44:45Z,,NONE,Is there a plan to support swagger 3.0，our service want to use the swagger file as the API document，but some definitions are not support，like the length of String etc.,"Do you use ""contrast first"" development mode? First write API's , and then use some tool to generate code. 
",91674936
290,微服务RPC调用时在HttpClientFilter 中如何处理请求中产生的异常？,open,2020-02-26T03:19:25Z,2020-02-28T02:58:46Z,,NONE,"在微服务RPC请求时，增加一个HttpClientFilter 做过滤器记录外部请求情况。
如果请求中发生异常，比如超时异常时，在过滤器中会进beforeSendRequest方法但是不会进afterReceiveResponse方法。此时应该如何处理才能满足需求？",实践了一下，这样做不能在Invocation的LocalContext中传递消息，并且handler会在filter之前调用前执行，处理起来比较麻烦，有专门的设置ExceptionHandler处理么？,91674936
291,客户端偶现超时，SlowInvocationLogger无法提供有用信息,open,2020-02-25T02:22:58Z,2020-02-25T06:11:40Z,,NONE,"ServiceComb版本：1.2.0.B006
服务端停机升级后，重新上线，客户端偶现490服务超时，但是从客户端的SlowInvocationLogger看不出问题出在哪个阶段。
通过客户端超时服务traceId追踪，服务端access log中没有该请求。

####客户端日志：
```xml
2020-02-25 00:02:08.159 | ERROR | [vert.x-eventloop-thread-8] | [] | [LoadbalanceHandler] | service CONSUMER rest tts_service_jtest.ttsservice.processTTS, call error, msg is cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/tts/text2audio?null for host 10.31.57.5, server is rest://10.31.57.5:28087?sslEnabled=false&protocol=http2
2020-02-25 00:02:08.159 | ERROR | [vert.x-eventloop-thread-8] | [] | [LoadbalanceHandler] | Invoke server failed. Operation CONSUMER rest tts_service_jtest.ttsservice.processTTS; server rest://10.31.57.5:28087?sslEnabled=false&protocol=http2; 0-0 msg cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/tts/text2audio?null for host 10.31.57.5
2020-02-25 00:02:08.160 | ERROR | [vert.x-eventloop-thread-8] | [] | [LoadbalanceHandler] | Invoke all server failed. Operation CONSUMER rest tts_service_jtest.ttsservice.processTTS, e=cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/tts/text2audio?null for host 10.31.57.5
2020-02-25 00:02:08.160 | WARN  | [gw_worker_20] | [] | [BizkeeperCommand] | bizkeeper command CONSUMER rest tts_service_jtest.ttsservice.processTTS failed due to InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request]
2020-02-25 00:02:08.160 | WARN  | [gw_worker_20] | [] | [BizkeeperHandler] | bizkeeper execution error, info=cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/tts/text2audio?null for host 10.31.57.5
2020-02-25 00:02:08.160 | WARN  | [gw_worker_20] | [] | [BizkeeperHandler] | catch error in bizkeeper:Consumer.tts_service_jtest.ttsservice.processTTS failed and fallback disabled.
2020-02-25 00:02:08.160 | WARN  | [gw_worker_20] | [5e53f37b7b8724b8-2503128] | [SlowInvocationLogger] | slow(5000 ms) invocation, CONSUMER rest tts_service_jtest.ttsservice.processTTS:
  http method: POST
  url        : /v1/tts/text2audio/
  server     : rest://10.31.57.5:28087?sslEnabled=false&protocol=http2
  status code: 490
  total      : 5001.842 ms
    prepare                : 0.3 ms
    handlers request       : 0.147 ms
    client filters request : 0.30 ms
    send request           : 0.0 ms
    get connection         : 0.0 ms
    write to buf           : 0.0 ms
    wait response          : 0.0 ms
    wake consumer          : 0.1 ms
    client filters response: 0.0 ms
    handlers response      : 1.17 ms
2020-02-25 00:02:13.574 | INFO  | [spectator-poller-0] | [] | [DefaultLogPublisher] |
os:
  cpu:
    all usage: 0.77%    all idle: 99.23%    process: 0.77%
  net:
    send(Bps)    recv(Bps)    send(pps)    recv(pps)    interface
    33.197K      14.631K      21           27           eth0
vertx:
  instances:
    name       eventLoopContext-created
    registry   0
    transport  0
    monitor-center 0
  transport:
    client.endpoints:
      remote                connectCount disconnectCount queue         connections send(Bps) receive(Bps)
      10.31.57.5:28087      2            3               165           2           9         5.223K
      10.31.35.137:28087    3            3               0             3           14        6.993K
      (summary)             5            6               165           5           23        12.217K
threadPool:
  coreSize maxThreads poolSize currentBusy rejected queueSize taskCount taskFinished name
  25       100        0        0           NaN      0         0.0       0.0          cse.executor.groupThreadPool-group1
  25       100        0        0           NaN      0         0.0       0.0          cse.executor.groupThreadPool-group0
consumer:
 simple:
  status      tps      latency            operation
  rest.200    0.0      0.000/0.000        asr_service.asrservice.asyncGetAsrResult
              0.0      0.000/0.000        dlg_center_service_prod.SmurfsDialogApplication.answerV2
              0.1      4.738/5.435        tts_service_jtest.ttsservice.processTTS
              0.0      0.000/0.000        gop_service.asrservice.asyncUploadAsrData
              0.0      0.000/0.000        asr_service.asrservice.asyncUploadAsrData
              0.0      0.000/0.000        gop_service.asrservice.asyncGetAsrResult
              0.1      4.738/5.435        (summary)
  rest.490    0.0      0.000/0.000        asr_service.asrservice.asyncGetAsrResult
              0.0      5001.842/5001.842  tts_service_jtest.ttsservice.processTTS
              0.0      0.000/0.000        asr_service.asrservice.asyncUploadAsrData
              0.0      5001.842/5001.842  (summary)

```","是的，我看了源码创建http2连接的时候没有使用自己idleTimeoutInSeconds配置项，这是个bug。
但是理论上，客户端最大连接数应该是这么算的吧？
```xml
 thread-count（32） * maxPoolSize（1） * 服务实例数（2） = 64
```
最大连接数远远大于我们现在的性能要求，但是可能因为HTTP2错误使用了idleTimeoutInSeconds，导致连接不停的重建，我觉得这可能是问题。",91674936
292,请教一下，当前CSE是否支持双通道？,open,2020-02-24T03:22:56Z,2020-02-24T11:54:38Z,,NONE,"当前CSE是否支持双通道；比方说Server-Sent Events；

如果不支持，是否有CSE+双通道解决方案；希望各位大虾帮忙答疑一下",java chassis 目前支持的是 `RPC`， 没有支持事件机制。 可以选择其他消息中间件及其对应的SDK。,91674936
293,foundation-protobuf序列化问题,open,2020-02-20T15:44:29Z,2020-02-21T09:38:06Z,,NONE,"1. 继承，父类的属性 反序列化不出来，是空值
2. 整形类型若值为0， 反序列化出来是 null",你的使用方法比较深入了，不太清楚你的使用场景，不知道是否方便告知。 不过目前这个模块在实现的时候，并没有考虑直接作为API使用，没有进行用户设计， 实际上 java-chassis 调用这些API 的时候，还会对一些情况进行处理，这里的 API 是为其他模块服务的（可以参考 common-protobuf 模块，大部分测试用例实际上在这里）。如果你在寻找一个protobuffer库，建议可以使用protostuff。 ,91674936
294,使用InvokerUtils.syncInvoke调用RPC接口，一直失败，所有RPC接口都报NullPointerException,open,2020-02-19T08:47:50Z,2020-02-20T07:03:59Z,,NONE,"所有RPC调用都报空指针，异常来源于servicecomb
2020-02-18 00:04:18,280Z | ERROR | pool-48-thread-4 | InvokerUtils                     |  | com.huawei.m2m.cig.rpcservice | invoke failed,
java.lang.NullPointerException: null
        at org.apache.servicecomb.core.Invocation.initTraceId(Invocation.java:248) ~[98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at org.apache.servicecomb.core.Invocation.onStart(Invocation.java:280) ~[98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at org.apache.servicecomb.core.Invocation.onStart(Invocation.java:286) ~[98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at org.apache.servicecomb.core.provider.consumer.InvokerUtils.innerSyncInvoke(InvokerUtils.java:68) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at org.apache.servicecomb.core.provider.consumer.InvokerUtils.syncInvoke(InvokerUtils.java:54) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at org.apache.servicecomb.core.provider.consumer.InvokerUtils.syncInvoke(InvokerUtils.java:37) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at com.huawei.m2m.cig.rpcservice.iocm.IocmCmService.queryCertificatesByPage(IocmCmService.java:184) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at com.huawei.m2m.cig.rpcservice.iocm.IocmCmService.queryCertificates(IocmCmService.java:153) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at com.huawei.m2m.cig.rpcservice.cert.DeviceCaCerMgr.loadCaCert(DeviceCaCerMgr.java:81) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at com.huawei.m2m.cig.rpcservice.cert.DeviceCaCerMgr.access$000(DeviceCaCerMgr.java:37) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at com.huawei.m2m.cig.rpcservice.cert.DeviceCaCerMgr$1.run(DeviceCaCerMgr.java:60) [98:com.huawei.m2m.cig.rpcservice:20.2.3]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:?]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:?]
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [?:?]
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [?:?]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:?]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:?]
        at java.lang.Thread.run(Thread.java:748) [?:?]

2020-02-18 00:04:18,280Z | ERROR | pool-42-thread-1 | InvokerUtils                     |  | com.huawei.m2m.cig.rpcservice | invoke failed,
java.lang.NullPointerException: null
        at org.apache.servicecomb.core.Invocation.initTraceId(Invocation.java:248) ~[?:?]
        at org.apache.servicecomb.core.Invocation.onStart(Invocation.java:280) ~[?:?]
        at org.apache.servicecomb.core.Invocation.onStart(Invocation.java:286) ~[?:?]
        at org.apache.servicecomb.core.provider.consumer.InvokerUtils.innerSyncInvoke(InvokerUtils.java:68) ~[?:?]
        at org.apache.servicecomb.core.provider.consumer.InvokerUtils.syncInvoke(InvokerUtils.java:54) ~[?:?]
        at org.apache.servicecomb.core.provider.consumer.InvokerUtils.syncInvoke(InvokerUtils.java:37) ~[?:?]
        at com.huawei.m2m.cig.rpcservice.mongo.IocmDeviceAppService.findOneByDeviceId(IocmDeviceAppService.java:46) ~[?:?]
        at com.huawei.m2m.cig.service.connectionInfo.MqttInfo.addConnectionInfo(MqttInfo.java:31) ~[?:?]
        at com.huawei.m2m.cig.mqtt.server.MqttMessageHandler.onConnect(MqttMessageHandler.java:167) ~[?:?]
        at io.moquette.spi.impl.BrokerInterceptor.lambda$notifyClientConnected$0(BrokerInterceptor.java:99) ~[?:?]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:?]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:?]
        at java.lang.Thread.run(Thread.java:748) [?:?]","我理解你的这个测试程序和OSGI还不一样。 你实现的classloader在加载类的时候，都会搜索父classloader，无论在哪个线程里面， TraceIdGenerator的实现都能够被classloader搜索到。 而OSGI的每个bundle有自己的classloader，每个bundle能够搜索的 jar 路径是不一样的，即某些bundle可能搜索不到TraceIdGenerator的实现。 

对于OSGI的详细原理我也不熟悉，上面的理解仅供参考。 出现这个错误：

```
pool-42-thread-1 | SPIServiceUtils | | com.huawei.m2m.cig.rpcservice | Can not find SPI service for org.apache.servicecomb.core.tracing.TraceIdGenerator
```

并且实现类是存在的，那么肯定是和类加载和classpath搜索有关的问题。 所以寻找问题的方向是没错的。 对OSGI的环境java-chassis确实验证的很少，也没有给所有包提供bundle信息。 OSGI最大的特点是它的类隔离机制，不过在微服务架构下，这个机制显得画蛇添足。
",91674936
295,"使用zuul网关进行http代理对接servicecomb,在http请求中添加header报错",open,2020-02-18T03:53:54Z,2020-02-19T03:06:33Z,,NONE,"使用Zuul网关进行代理，把前台编译出的静态文件放入resources/static目录下，发现带有Authorization header的http请求报错：
`CommonExceptionData [message=Parameter is not valid for operation [user-mgmt-be.user-mgmt-be.getUser]. Parameter is [Authorization]. Processor is [header].]`
不带header的请求调用正常。

zuul网关代码：
`@SpringBootApplication`
`@EnableZuulProxy`
`@EnableServiceComb`
`public class GatewayApplication {`
`public static void main(String[] args) {`
`    SpringApplication.run(GatewayApplication.class, args);`
`  }`
`}`
前台axios调用代码：
`url = '/user-mgmt-be/v1/users/' + res.data.userId`
`            axios({`
`              method: 'GET',`
`              url: url,`
`              headers: {`
`                'Authorization': 'Basic ' + res.data.token,`
`                'Content-Type': 'application/json'`
`              }`
`            })`","> You can first debug `RestCodec` to find the actual resons for the codec error. For security reasons, the exception is not printed by default.
I can't debug  common-rest-1.3.0.jar...
",91674936
296,serviceComb框架如何设置支持跨域？,open,2020-02-17T09:11:07Z,2020-02-18T03:07:56Z,,NONE,"业务需要支持跨域访问，而浏览器会在跨域发生前先发起试探的OPTIONS请求，服务端却响应“Method not Allowed”失败，最终导致请求失败。

OPTIONS前端请求：
![image](https://user-images.githubusercontent.com/9291379/74639080-36903f00-51a8-11ea-82a2-1908fb0ca81c.png)
响应体：
![image](https://user-images.githubusercontent.com/9291379/74639095-3db74d00-51a8-11ea-83ba-fea2494218ec.png)

服务端已通过过滤器设置支持跨域如下：

        responseEx.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, ALLIANCE_DOMAIN);

        responseEx.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_CREDENTIALS, ""true"");

        responseEx.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_HEADERS,
            ""Content-Type,X-Requested-With,Access-Control,Referer,Sec-Fetch-Dest,User-Agent,Accept-Encoding,Cache-Control,Content-Length,Host,Origin"");
        responseEx.setHeader(HttpHeaders.ACCESS_CONTROL_ALLOW_METHODS, ""POST,GET,OPTIONS,DELETE,PUT"");
        responseEx.setHeader(HttpHeaders.ACCESS_CONTROL_MAX_AGE, ""86400"");
","ServiceComb的[跨域配置](https://docs.servicecomb.io/java-chassis/zh_CN/general-development/CORS/)

你的跨域设置代码是在什么地方进行的？ ServiceComb 接口定义是不存在 response 对象的。",91674936
297,CSE目前的熔断是服务级的还是方法级的？,open,2020-02-17T08:00:29Z,2020-02-17T08:24:04Z,,NONE,,Please take a look at [1](http://liubao68.gitee.io/servicecomb-java-chassis-doc/java-chassis/zh_CN/build-provider/configuration/downgrade-strategy/) & [2](http://liubao68.gitee.io/servicecomb-java-chassis-doc/java-chassis/zh_CN/references-handlers/loadbalance/),91674936
298,服务报错InvocationException，信息是message=not support file upload.,open,2020-02-17T01:58:48Z,2020-02-17T02:05:37Z,,NONE,"服务报错InvocationException，这个是什么原因导致
http server failed.org.apache.servicecomb.swagger.invocation.exception.InvocationException: InvocationException: code=590;msg=CommonExceptionData [message=not support file upload.]	at org.apache.servicecomb.swagger.invocation.exception.ExceptionFactory.doCreate(ExceptionFactory.java:74)	at org.apache.servicecomb.swagger.invocation.exception.ExceptionFactory.create(ExceptionFactory.java:61)	at org.apache.servicecomb.swagger.invocation.exception.ExceptionFactory.createProducerException(ExceptionFactory.java:69)","资料在[这里](https://docs.servicecomb.io/java-chassis/zh_CN/general-development/upload-download/) 
参考 `servicecomb.uploads.directory` 配置项的说明",91674936
299,默认线程池没有指定线程名称,open,2020-02-14T06:53:29Z,2020-02-17T08:21:17Z,,NONE,"servicecomb默认使用的线程池
org.apache.servicecomb.core.executor.ThreadPoolExecutorEx#ThreadPoolExecutorEx

在初始化的时候没有指定有意义的线程名称，难以在堆栈中区分线程，不利于问题的调查。

",,91674936
300,query about the thirdParty service rest schema,open,2020-02-11T07:07:46Z,2020-02-11T12:14:49Z,,NONE,"why the thrid party service rest schma in the servicecomb is registered locally but not to the register center, so as for the others service could find the third party service?

@liubao68 ","a service can register itself, not registered by others.",91674936
301,CSE不支持多war包并行启动吗？,open,2020-02-10T12:41:36Z,2020-02-11T06:29:30Z,,NONE,"我们的Tomcat里面有多个war包，设置了并行启动，结果发现服务中心Address的urlPrefix串了。

跟踪了一下CSE的代码发现这个值的上下文是通过System.property传递的，这也太坑爹了吧。。。除了改成串行还有别的办法没？

ServletRestTransport
``` 
  @Override
  public boolean init() {
    String urlPrefix = System.getProperty(Const.URL_PREFIX);
    Map<String, String> queryMap = new HashMap<>();
    if (!StringUtils.isEmpty(urlPrefix)) {
      queryMap.put(Const.URL_PREFIX, urlPrefix);
    }

    String listenAddress = ServletConfig.getLocalServerAddress();
    setListenAddressWithoutSchema(listenAddress, queryMap);

    restClient = RestTransportClientManager.INSTANCE.getRestClient();
    return true;
  }
```",It's not a good practice to host multiple microservices into one JVM.,91674936
302,query about servicecomb rsa  authentication between microservices,open,2020-02-10T05:50:56Z,2020-02-10T08:08:57Z,,NONE,"I want to konw how should i do with my alpha tests if my microservice is configed RSA authentication, how can i  genarate the rsa public key the register center make signature with the private key?

will it be okay with the edge service ?",okay，get it，thanks a lot,91674936
303,swagger method wait not exist in producer,open,2020-01-19T02:22:42Z,2020-01-20T00:49:40Z,,NONE,切换到2.3.77版本的CSE后，服务启动报错：swagger method wait not exist in producer。我的代码中没有名为wait的method,可以看下swagger内容，是否有wait这样一个operation-id。 然后再看看这个怎么来的。比如看看服务端启动日志最新的swagger是否有。 ,91674936
304,开启Https双向认证后如何对接nginx,open,2020-01-17T02:32:59Z,2020-01-17T03:53:54Z,,NONE,"开启https双向认证
![image](https://user-images.githubusercontent.com/12776176/72579596-88794700-3914-11ea-9f24-4b81adadae34.png)


此时nginx接入的请求报错
2020/01/17 09:35:50 [error] 14558#0: *5546524 SSL_do_handshake() failed (SSL: error:14094412:SSL routines:ssl3_read_bytes:sslv3 alert bad certificate:SSL alert number 42) while SSL handshaking to upstream, client: 58.240.77.242, server: lfsmurfsecuritytest.hwcloudtest.cn, request: ""POST /smurf/v1/device/user/its/schedule HTTP/1.1"", upstream: ""https://10.31.53.67:18080/smurf/v1/device/user/its/schedule"", host: ""lfsmurfsecuritytest.hwcloudtest.cn:21443""



请问开启https后 ，nginx如何配置对应的证书？没找到相关资料
","如果你的NGINX是做反向代理的，Java-Chassis这边的微服务开启了双向认证的话，就需要NGINX配置客户端证书，证书能被Java-Chassis微服务信任。
可以在Java微服务启动命令里加上`-Djavax.net.debug=ssl`看看SSL握手具体在哪一步报错。
Nginx证书的配置方式需要查阅Nginx的资料才行。",91674936
305,重写返回值序列化，工程启动报LinkageError,open,2020-01-16T08:29:56Z,2020-01-16T08:54:13Z,,NONE,"业务需要REST返回值支持compactFormat和PrettyPrint两种输出格式，因此重写了ProduceJsonProcessor。但是工程启动却报LinkageError错误。如何解决？
（1）自定义的ProduceProcessor实现类如下：
public class MyProduceProcessor implements ProduceProcessor {

    @Override
    public String getName() {
        return String.valueOf(MediaType.APPLICATION_JSON);
    }

    @Override
    public int getOrder() {
        return -1;
    }

    @Override
    public void doEncodeResponse(OutputStream outputStream, Object o) throws Exception {
        RestObjectMapperFactory.getRestObjectMapper().writerWithDefaultPrettyPrinter().writeValue(outputStream, o);
    }

    @Override
    public Object doDecodeResponse(InputStream inputStream, JavaType javaType) throws Exception {
        return RestObjectMapperFactory.getRestObjectMapper().readValue(inputStream, javaType);
    }
}
（2）自定义的ProduceProcessor实现类如下：
![image](https://user-images.githubusercontent.com/53045286/72506750-78faef00-387d-11ea-969d-d765f1689e18.png)
resources下文件：META-INF/services/org.apache.servicecomb.common.rest.codec.produce.ProduceProcessor，内容com.**.**.utils.MyProduceProcessor（此处隐藏了具体报名）
（3）工程启动报错如下：
Exception in thread ""main"" java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.huawei.nuwa.boot.loader.MainMethodRunner.run(MainMethodRunner.java:31)
	at com.huawei.nuwa.boot.loader.AbstractLauncher.launch(AbstractLauncher.java:65)
	at com.huawei.nuwa.boot.loader.AbstractLauncher.launch(AbstractLauncher.java:58)
	at com.huawei.nuwa.boot.loader.AbstractLauncher.launch(AbstractLauncher.java:42)
	at com.huawei.nuwa.boot.loader.NuwaClassPathLauncher.main(NuwaClassPathLauncher.java:30)
Caused by: com.huawei.nuwa.boot.loader.exception.NuwaBootException: Failed to start nuwa. Cause:
	at com.huawei.nuwa.container.NuwaContainer.main(NuwaContainer.java:59)
	... 9 more
Caused by: com.huawei.nuwa.boot.loader.exception.NuwaBootException: ServiceComb init failed.
	at com.huawei.nuwa.container.model.PluginModel.start(PluginModel.java:382)
	at com.huawei.nuwa.container.service.plugin.PluginDeployServiceImpl.deploy(PluginDeployServiceImpl.java:22)
	at com.huawei.nuwa.container.pipeline.DeployPluginStage.process(DeployPluginStage.java:26)
	at com.huawei.nuwa.container.pipeline.StandardPipeline.process(StandardPipeline.java:39)
	at com.huawei.nuwa.container.NuwaContainer.start(NuwaContainer.java:76)
	at com.huawei.nuwa.container.NuwaContainer.main(NuwaContainer.java:53)
	... 9 more
Caused by: java.lang.IllegalStateException: ServiceComb init failed.
	at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:225)
	at org.apache.servicecomb.core.CseApplicationListener.onApplicationEvent(CseApplicationListener.java:81)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139)
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:402)
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:359)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:896)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:552)
	at com.huawei.nuwa.SpringInitializer.init(SpringInitializer.java:33)
	at com.huawei.nuwa.NuwaBootstrap.start(NuwaBootstrap.java:42)
	at com.huawei.nuwa.container.model.PluginModel.start(PluginModel.java:380)
	... 14 more
Caused by: java.lang.ExceptionInInitializerError
	at org.apache.servicecomb.common.rest.definition.RestOperationMeta.createProduceProcessors(RestOperationMeta.java:199)
	at org.apache.servicecomb.common.rest.definition.RestOperationMeta.init(RestOperationMeta.java:94)
	at org.apache.servicecomb.common.rest.locator.ServicePathManager.addSchema(ServicePathManager.java:86)
	at org.apache.servicecomb.common.rest.RestEngineSchemaListener.onSchemaLoaded(RestEngineSchemaListener.java:54)
	at org.apache.servicecomb.core.definition.loader.SchemaListenerManager.notifySchemaListener(SchemaListenerManager.java:59)
	at org.apache.servicecomb.core.definition.loader.SchemaListenerManager.notifySchemaListener(SchemaListenerManager.java:48)
	at org.apache.servicecomb.core.definition.loader.SchemaListenerManager.notifySchemaListener(SchemaListenerManager.java:54)
	at org.apache.servicecomb.core.SCBEngine.doInit(SCBEngine.java:257)
	at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:214)
	... 25 more
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.huawei.minidemo.utils.MyProduceProcessor] from ClassLoader [com.huawei.nuwa.container.classloader.BizClassLoader@13b6aecc]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:686)
	at org.springframework.util.ReflectionUtils.findMethod(ReflectionUtils.java:207)
	at org.springframework.util.ReflectionUtils.findMethod(ReflectionUtils.java:188)
	at org.apache.servicecomb.foundation.common.utils.SPIServiceUtils.lambda$loadSortedService$0(SPIServiceUtils.java:65)
	at java.lang.Iterable.forEach(Iterable.java:75)
	at org.apache.servicecomb.foundation.common.utils.SPIServiceUtils.loadSortedService(SPIServiceUtils.java:63)
	at org.apache.servicecomb.foundation.common.utils.SPIServiceUtils.getOrLoadSortedService(SPIServiceUtils.java:95)
	at org.apache.servicecomb.foundation.common.utils.SPIServiceUtils.getSortedService(SPIServiceUtils.java:122)
	at org.apache.servicecomb.common.rest.codec.produce.ProduceProcessorManager.<clinit>(ProduceProcessorManager.java:31)
	... 34 more
Caused by: java.lang.LinkageError: loader constraint violation: loader (instance of com/huawei/nuwa/container/classloader/BizClassLoader) previously initiated loading for a different type with name ""com/fasterxml/jackson/databind/JavaType""
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at com.huawei.nuwa.container.classloader.AbstractClasspathClassLoader.resolveLocalClass(AbstractClasspathClassLoader.java:257)
	at com.huawei.nuwa.container.classloader.BizClassLoader.loadClassInternal(BizClassLoader.java:57)
	at com.huawei.nuwa.container.classloader.AbstractClasspathClassLoader.loadClass(AbstractClasspathClassLoader.java:61)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)
	at java.lang.Class.getDeclaredMethods(Class.java:1975)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:668)
	... 42 more","可能自定义的类使用BizClassLoader加载的，这个类依赖的JavaType在另外的class loader加载的，就出现了上面的错误。 
",91674936
306,急急急！cse的微服务配置flowcontrol中operation，配置的这个值是单实例的值，还是汇总的值？,open,2020-01-15T03:27:49Z,2020-01-16T00:55:51Z,,NONE,flowcontrol中存在microservice/schema/operation三个级别的配置 如果配置operation，配置的这个值是单实例的值，还是几台实例的汇总的值？,本实例的。如果是provider，表示别人请求本实例本方法的流量；如果是consumer，表示本实例请求被请求服务的所有实例的方法的流量。 ,91674936
307,rest方式通过edge网关调用微服务的时候使用@Requestbody接受json字符串映射成java对象中文变问号如何解决？,open,2020-01-15T02:39:58Z,2020-01-16T00:53:55Z,,NONE,我都web项目，页面发ajax请求发送json字符串到web项目的后台使用@Requestbody接受并映射成java实体类对象数据接受没有问题，但是在web项目（相当于消费者项目）去通过rest方式调用提供者服务，因为servicecomb不支持复杂类型的参数传递，所以把java对象通过fastjson转换成了json字符串，传递给提供者，提供者使用@Requestbody接受json映射java实体类的时候，参数中的中文全变成了问号，数字没有问题正常显示，请问怎么可以解决这个中文显示问号的问题,这个问题可能需要你先调试下代码，看看问题在哪儿。有几个关键环节： 1. fastjson编码前后；2. java-chassis RestCodec类编码前后。 ,91674936
308,在RPC调用时报下面DuplicateMemberException: duplicate method,open,2020-01-14T14:46:20Z,2020-01-15T01:04:13Z,,NONE,"public interface ICodecService {
  RpcResponse<String> decode(@NotNull DecodeReqDTO decodeInfo) throws Exception;

  RpcResponse<byte[]> encode(@NotNull EncodeReqDTO encodeInfo) throws Exception;
}

public class DecodeReqDTO {
  private String groupId;

  private String deviceId;

  private String bundleId;

  private byte[] binaryData;
}
在RPC接口中定义了一个ICodecService接口，参数是DecodeReqDTO ，在RPC调用时报下面的错误，请问是什么原因啊？
Caused by: javassist.bytecode.DuplicateMemberException: duplicate method: decode in com.****.api.rpc.ICodecService
        at javassist.bytecode.ClassFile.testExistingMethod(ClassFile.java:685) ~[?:?]
        at javassist.bytecode.ClassFile.addMethod(ClassFile.java:660) ~[?:?]
        at javassist.CtClassType.addMethod(CtClassType.java:1485) ~[?:?]","需要确保每个方法有唯一的operation id。 

```
@ApiOperation(value="""", nickname=""decode2"")
RpcResponse decode(@NotNull DecodeReqDTO decodeInfo) throws Exception;

RpcResponse<byte[]> encode(@NotNull EncodeReqDTO encodeInfo) throws Exception;
```",91674936
309,"Failed to send request, local:not connected",open,2020-01-14T02:53:31Z,2020-01-15T01:13:28Z,,NONE,"hello，咨询个服务调用超时的问题，生产环境偶现服务调用超时，java-chassis版本号：1.2.0.B006
客户端配置：
```xml
rest:
    client:
      thread-count: 32
      connection:
        maxPoolSize: 20
        idleTimeoutInSeconds: 10
        keepAlive: true
      http2:
        maxPoolSize: 20
        idleTimeoutInSeconds: 10
  request:
    timeout: 5000
```

服务端配置：
```xml
rest:
    address: 0.0.0.0:18083?sslEnabled=false&protocol=http2
    server:
      thread-count: 32
      connection:
        idleTimeoutInSeconds: 60
```

错误日志：
```xml
2020-01-13 17:56:19.583 | ERROR | [vert.x-eventloop-thread-6] | [RestClientInvocation] | Failed to send request, local:not connected, remote:/10.33.106.89:18083.
io.vertx.core.http.impl.HttpClientRequestBase$1: The timeout period of 5000ms has been exceeded while executing POST /v1/asr/audio/upload/async?null for host 10.33.106.89
2020-01-13 17:56:19.583 | ERROR | [vert.x-eventloop-thread-6] | [LoadbalanceHandler] | service CONSUMER rest asr_service_89.asrservice.asyncUploadAsrData, call error, msg is cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/asr/audio/upload/async?null for host 10.33.106.89, server is rest://10.33.106.89:18083?sslEnabled=false&protocol=http2
2020-01-13 17:56:19.583 | ERROR | [vert.x-eventloop-thread-6] | [LoadbalanceHandler] | Invoke server failed. Operation CONSUMER rest asr_service_89.asrservice.asyncUploadAsrData; server rest://10.33.106.89:18083?sslEnabled=false&protocol=http2; 0-0 msg cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/asr/audio/upload/async?null for host 10.33.106.89
2020-01-13 17:56:19.583 | ERROR | [vert.x-eventloop-thread-6] | [LoadbalanceHandler] | Invoke all server failed. Operation CONSUMER rest asr_service_89.asrservice.asyncUploadAsrData, e=cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/asr/audio/upload/async?null for host 10.33.106.89
2020-01-13 17:56:19.584 | WARN  | [gw_worker_14] | [BizkeeperCommand] | bizkeeper command CONSUMER rest asr_service_89.asrservice.asyncUploadAsrData failed due to InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request]
2020-01-13 17:56:19.584 | WARN  | [gw_worker_14] | [BizkeeperHandler] | bizkeeper execution error, info=cause:InvocationException,message:InvocationException: code=490;msg=CommonExceptionData [message=Cse Internal Bad Request];cause:,message:The timeout period of 5000ms has been exceeded while executing POST /v1/asr/audio/upload/async?null for host 10.33.106.89
2020-01-13 17:56:19.584 | WARN  | [gw_worker_14] | [BizkeeperHandler] | catch error in bizkeeper:Consumer.asr_service_89.asrservice.asyncUploadAsrData failed and fallback disabled.
```

local:not connected是不是代表客户端和服务端的连接没有建立？但是我没看到任何连接异常的日志。

另外，有没有什么办法知道这次请求是阻塞在客户端？还是阻塞在服务端的队列？",这种情况就比较复杂了。 通常可能是性能问题，可以观察下服务端和客户端负载，比如CPU、内存、连接数等。 可以试试打开[metrics](https://docs.servicecomb.io/java-chassis/zh_CN/general-development/metrics.html)，并将统计数据输出到独立文件，能够帮助识别一些问题。 ,91674936
310,接口参数声明使用了子类，服务启动后接口契约识别的参数只有子类的，无父类中定义的属性参数,open,2020-01-13T04:12:22Z,2020-01-14T06:18:33Z,,NONE,"![a](https://user-images.githubusercontent.com/38533501/72232732-eef12300-35fd-11ea-9e5d-677372525ace.png)

![b](https://user-images.githubusercontent.com/38533501/72232736-f284aa00-35fd-11ea-999c-dfd5286d1a9f.png)
","我们分析下这种场景是否支持。不过建议替换一种方式，不要在BeanParam使用复杂的数据结构。即使对于简单类型的BeanParam，也建议越少越好，因为太多的query参数不是一个好主意， 此外还有一些内部RPC逻辑处理上存在的一些潜在问题。 
",91674936
311,除了在controller参数里声明 Invocation 外，能否提供便捷方法获取Invocation,open,2020-01-13T03:41:02Z,2020-01-14T00:54:58Z,,NONE,类似于 org.apache.servicecomb.swagger.invocation.context.ContextUtils#getInvocationContext,"1. Invocation is subclass of InvocationContext, so that you can try .ContextUtils#getInvocationContext
2. You can add a new method:

```
service(args)
service(args, invocation)
```

This is a better solution, or you assume users call service in an determined context, e.g. no thread switch and in a controller context. 
",91674936
312,HTTP切HTTPS报错： signed CRL fields invalid,open,2020-01-13T01:51:25Z,2020-01-13T02:01:08Z,,NONE,"org.apache.servicecomb.foundation.vertx.client.ClientVerticle.start(ClientVerticle.java:38) ->
io.vertx.core.VertxException: java.security.cert.CRLException: signed CRL fields invalid
        at io.vertx.core.net.impl.SSLHelper.getContext(SSLHelper.java:472) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.vertx.core.net.impl.SSLHelper.validate(SSLHelper.java:499) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.vertx.core.http.impl.HttpClientImpl.<init>(HttpClientImpl.java:131) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.vertx.core.impl.VertxImpl.createHttpClient(VertxImpl.java:309) ~[foundation-vertx-1.2.0.B011.jar!/:3.6.3]
        at org.apache.servicecomb.foundation.vertx.client.http.HttpClientPoolFactory.createClientPool(HttpClientPoolFactory.java:36) ~[foundation-vertx-1.2.0.B011.jar!/:1.2.0.B011]
        at org.apache.servicecomb.foundation.vertx.client.http.HttpClientPoolFactory.createClientPool(HttpClientPoolFactory.java:27) ~[foundation-vertx-1.2.0.B011.jar!/:1.2.0.B011]
        at org.apache.servicecomb.foundation.vertx.client.ClientPoolManager.createClientPool(ClientPoolManager.java:60) ~[foundation-vertx-1.2.0.B011.jar!/:1.2.0.B011]
        at org.apache.servicecomb.foundation.vertx.client.ClientVerticle.start(ClientVerticle.java:35) ~[foundation-vertx-1.2.0.B011.jar!/:1.2.0.B011]
        at io.vertx.core.AbstractVerticle.start(AbstractVerticle.java:106) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.vertx.core.impl.DeploymentManager.lambda$doDeploy$8(DeploymentManager.java:494) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.vertx.core.impl.ContextImpl.executeTask(ContextImpl.java:320) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.vertx.core.impl.EventLoopContext.lambda$executeAsync$0(EventLoopContext.java:38) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.28.Final.jar!/:4.1.28.Final]
Caused by: java.security.cert.CRLException: signed CRL fields invalid
        at sun.security.x509.X509CRLImpl.parse(X509CRLImpl.java:1081) ~[?:1.8.0_222]
        at sun.security.x509.X509CRLImpl.<init>(X509CRLImpl.java:146) ~[?:1.8.0_222]
        at sun.security.provider.X509Factory.parseX509orPKCS7CRL(X509Factory.java:523) ~[?:1.8.0_222]
        at sun.security.provider.X509Factory.engineGenerateCRLs(X509Factory.java:420) ~[?:1.8.0_222]
        at java.security.cert.CertificateFactory.generateCRLs(CertificateFactory.java:535) ~[?:1.8.0_222]
        at io.vertx.core.net.impl.SSLHelper.getTrustMgrFactory(SSLHelper.java:342) ~[vertx-core-3.6.3.jar!/:3.6.3]
        at io.vertx.core.net.impl.SSLHelper.getContext(SSLHelper.java:470) ~[vertx-core-3.6.3.jar!/:3.6.3]
",,91674936
313,脚手架生成的项目启动不了,open,2020-01-12T06:27:47Z,2020-01-13T01:58:58Z,,NONE,"如图，用脚手架一键生成的基础项目启动不了，一直报错，请帮忙看看
![image](https://user-images.githubusercontent.com/16242313/72214964-8ba4b980-3547-11ea-92f4-0373363e8ee8.png)
错误日志：
""C:\Program Files\Java\jdk-11.0.2\bin\java.exe"" -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true ""-javaagent:D:\tool\IntelliJ IDEA 2018.3.4\lib\idea_rt.jar=57397:D:\tool\IntelliJ IDEA 2018.3.4\bin"" -Dfile.encoding=UTF-8 -classpath C:\Users\zengqingrong\Downloads\Compressed\demo_3\demo\target\classes;D:\mavenLibs\org\hibernate\hibernate-validator\5.3.6.Final\hibernate-validator-5.3.6.Final.jar;D:\mavenLibs\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;D:\mavenLibs\org\jboss\logging\jboss-logging\3.3.2.Final\jboss-logging-3.3.2.Final.jar;D:\mavenLibs\com\fasterxml\classmate\1.3.4\classmate-1.3.4.jar;D:\mavenLibs\org\springframework\boot\spring-boot-starter\1.5.12.RELEASE\spring-boot-starter-1.5.12.RELEASE.jar;D:\mavenLibs\org\springframework\boot\spring-boot\1.5.12.RELEASE\spring-boot-1.5.12.RELEASE.jar;D:\mavenLibs\org\springframework\spring-context\4.3.20.RELEASE\spring-context-4.3.20.RELEASE.jar;D:\mavenLibs\org\springframework\spring-aop\4.3.20.RELEASE\spring-aop-4.3.20.RELEASE.jar;D:\mavenLibs\org\springframework\spring-beans\4.3.20.RELEASE\spring-beans-4.3.20.RELEASE.jar;D:\mavenLibs\org\springframework\spring-expression\4.3.20.RELEASE\spring-expression-4.3.20.RELEASE.jar;D:\mavenLibs\org\springframework\boot\spring-boot-autoconfigure\1.5.12.RELEASE\spring-boot-autoconfigure-1.5.12.RELEASE.jar;D:\mavenLibs\org\springframework\boot\spring-boot-starter-logging\1.5.12.RELEASE\spring-boot-starter-logging-1.5.12.RELEASE.jar;D:\mavenLibs\ch\qos\logback\logback-classic\1.1.11\logback-classic-1.1.11.jar;D:\mavenLibs\ch\qos\logback\logback-core\1.1.11\logback-core-1.1.11.jar;D:\mavenLibs\org\slf4j\jcl-over-slf4j\1.7.25\jcl-over-slf4j-1.7.25.jar;D:\mavenLibs\org\slf4j\jul-to-slf4j\1.7.25\jul-to-slf4j-1.7.25.jar;D:\mavenLibs\org\slf4j\log4j-over-slf4j\1.7.25\log4j-over-slf4j-1.7.25.jar;D:\mavenLibs\org\springframework\spring-core\4.3.16.RELEASE\spring-core-4.3.16.RELEASE.jar;D:\mavenLibs\org\yaml\snakeyaml\1.17\snakeyaml-1.17.jar;D:\mavenLibs\org\apache\servicecomb\spring-boot-starter-provider\1.2.1\spring-boot-starter-provider-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\spring-boot-starter-servicecomb\1.2.1\spring-boot-starter-servicecomb-1.2.1.jar;D:\mavenLibs\org\apache\tomcat\embed\tomcat-embed-logging-juli\8.5.2\tomcat-embed-logging-juli-8.5.2.jar;D:\mavenLibs\org\apache\servicecomb\provider-springmvc\1.2.1\provider-springmvc-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\provider-rest-common\1.2.1\provider-rest-common-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\swagger-invocation-springmvc\1.2.1\swagger-invocation-springmvc-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\swagger-invocation-core\1.2.1\swagger-invocation-core-1.2.1.jar;D:\mavenLibs\org\springframework\spring-web\4.3.20.RELEASE\spring-web-4.3.20.RELEASE.jar;D:\mavenLibs\com\google\inject\guice\4.2.0\guice-4.2.0.jar;D:\mavenLibs\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\mavenLibs\org\springframework\spring-webmvc\4.3.20.RELEASE\spring-webmvc-4.3.20.RELEASE.jar;D:\mavenLibs\org\apache\servicecomb\swagger-generator-springmvc\1.2.1\swagger-generator-springmvc-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\swagger-generator-core\1.2.1\swagger-generator-core-1.2.1.jar;D:\mavenLibs\io\swagger\swagger-core\1.5.22\swagger-core-1.5.22.jar;D:\mavenLibs\com\fasterxml\jackson\dataformat\jackson-dataformat-yaml\2.9.8\jackson-dataformat-yaml-2.9.8.jar;D:\mavenLibs\io\swagger\swagger-models\1.5.22\swagger-models-1.5.22.jar;D:\mavenLibs\io\swagger\swagger-annotations\1.5.22\swagger-annotations-1.5.22.jar;D:\mavenLibs\org\apache\servicecomb\provider-jaxrs\1.2.1\provider-jaxrs-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\swagger-invocation-jaxrs\1.2.1\swagger-invocation-jaxrs-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\swagger-generator-jaxrs\1.2.1\swagger-generator-jaxrs-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\provider-pojo\1.2.1\provider-pojo-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\java-chassis-core\1.2.1\java-chassis-core-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\service-registry\1.2.1\service-registry-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\deployment\1.2.1\deployment-1.2.1.jar;D:\mavenLibs\io\zipkin\brave\brave\5.6.0\brave-5.6.0.jar;D:\mavenLibs\io\zipkin\zipkin2\zipkin\2.9.3\zipkin-2.9.3.jar;D:\mavenLibs\io\zipkin\reporter2\zipkin-reporter\2.5.0\zipkin-reporter-2.5.0.jar;D:\mavenLibs\org\apache\servicecomb\handler-bizkeeper\1.2.1\handler-bizkeeper-1.2.1.jar;D:\mavenLibs\com\netflix\hystrix\hystrix-core\1.5.12\hystrix-core-1.5.12.jar;D:\mavenLibs\org\hdrhistogram\HdrHistogram\2.1.9\HdrHistogram-2.1.9.jar;D:\mavenLibs\org\apache\servicecomb\foundation-metrics\1.2.1\foundation-metrics-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\foundation-common\1.2.1\foundation-common-1.2.1.jar;D:\mavenLibs\com\fasterxml\jackson\dataformat\jackson-dataformat-xml\2.9.8\jackson-dataformat-xml-2.9.8.jar;D:\mavenLibs\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.8.11\jackson-module-jaxb-annotations-2.8.11.jar;D:\mavenLibs\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\mavenLibs\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\mavenLibs\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\mavenLibs\org\apache\httpcomponents\httpclient\4.5.5\httpclient-4.5.5.jar;D:\mavenLibs\org\apache\httpcomponents\httpcore\4.4.9\httpcore-4.4.9.jar;D:\mavenLibs\commons-codec\commons-codec\1.10\commons-codec-1.10.jar;D:\mavenLibs\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;D:\mavenLibs\commons-io\commons-io\2.6\commons-io-2.6.jar;D:\mavenLibs\com\netflix\spectator\spectator-reg-servo\0.83.0\spectator-reg-servo-0.83.0.jar;D:\mavenLibs\com\netflix\spectator\spectator-api\0.83.0\spectator-api-0.83.0.jar;D:\mavenLibs\org\apache\servicecomb\handler-loadbalance\1.2.1\handler-loadbalance-1.2.1.jar;D:\mavenLibs\com\netflix\ribbon\ribbon\2.2.5\ribbon-2.2.5.jar;D:\mavenLibs\com\netflix\ribbon\ribbon-transport\2.2.5\ribbon-transport-2.2.5.jar;D:\mavenLibs\io\reactivex\rxnetty-contexts\0.4.9\rxnetty-contexts-0.4.9.jar;D:\mavenLibs\io\reactivex\rxnetty-servo\0.4.9\rxnetty-servo-0.4.9.jar;D:\mavenLibs\javax\inject\javax.inject\1\javax.inject-1.jar;D:\mavenLibs\io\reactivex\rxnetty\0.4.9\rxnetty-0.4.9.jar;D:\mavenLibs\commons-configuration\commons-configuration\1.10\commons-configuration-1.10.jar;D:\mavenLibs\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;D:\mavenLibs\com\google\guava\guava\26.0-jre\guava-26.0-jre.jar;D:\mavenLibs\org\checkerframework\checker-qual\2.5.2\checker-qual-2.5.2.jar;D:\mavenLibs\com\google\errorprone\error_prone_annotations\2.1.3\error_prone_annotations-2.1.3.jar;D:\mavenLibs\com\google\j2objc\j2objc-annotations\1.1\j2objc-annotations-1.1.jar;D:\mavenLibs\org\codehaus\mojo\animal-sniffer-annotations\1.14\animal-sniffer-annotations-1.14.jar;D:\mavenLibs\com\netflix\ribbon\ribbon-loadbalancer\2.2.5\ribbon-loadbalancer-2.2.5.jar;D:\mavenLibs\com\netflix\netflix-commons\netflix-statistics\0.1.1\netflix-statistics-0.1.1.jar;D:\mavenLibs\com\netflix\servo\servo-core\0.12.25\servo-core-0.12.25.jar;D:\mavenLibs\com\netflix\netflix-commons\netflix-commons-util\0.1.1\netflix-commons-util-0.1.1.jar;D:\mavenLibs\com\netflix\ribbon\ribbon-core\2.2.5\ribbon-core-2.2.5.jar;D:\mavenLibs\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\mavenLibs\com\netflix\archaius\archaius-core\0.7.3\archaius-core-0.7.3.jar;D:\mavenLibs\com\google\code\findbugs\jsr305\3.0.1\jsr305-3.0.1.jar;D:\mavenLibs\com\fasterxml\jackson\core\jackson-annotations\2.9.8\jackson-annotations-2.9.8.jar;D:\mavenLibs\com\fasterxml\jackson\core\jackson-core\2.9.8\jackson-core-2.9.8.jar;D:\mavenLibs\com\fasterxml\jackson\core\jackson-databind\2.9.8\jackson-databind-2.9.8.jar;D:\mavenLibs\io\reactivex\rxjava\1.1.6\rxjava-1.1.6.jar;D:\mavenLibs\org\apache\commons\commons-lang3\3.7\commons-lang3-3.7.jar;D:\mavenLibs\org\apache\servicecomb\transport-highway\1.2.1\transport-highway-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\foundation-vertx\1.2.1\foundation-vertx-1.2.1.jar;D:\mavenLibs\io\vertx\vertx-core\3.6.3\vertx-core-3.6.3.jar;D:\mavenLibs\io\netty\netty-common\4.1.28.Final\netty-common-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-buffer\4.1.28.Final\netty-buffer-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-transport\4.1.28.Final\netty-transport-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-handler\4.1.28.Final\netty-handler-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-handler-proxy\4.1.28.Final\netty-handler-proxy-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-codec-http\4.1.28.Final\netty-codec-http-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-codec-http2\4.1.28.Final\netty-codec-http2-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-resolver\4.1.28.Final\netty-resolver-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-resolver-dns\4.1.28.Final\netty-resolver-dns-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-codec-dns\4.1.28.Final\netty-codec-dns-4.1.28.Final.jar;D:\mavenLibs\io\vertx\vertx-web\3.6.3\vertx-web-3.6.3.jar;D:\mavenLibs\io\vertx\vertx-web-common\3.6.3\vertx-web-common-3.6.3.jar;D:\mavenLibs\io\vertx\vertx-auth-common\3.6.3\vertx-auth-common-3.6.3.jar;D:\mavenLibs\io\vertx\vertx-bridge-common\3.6.3\vertx-bridge-common-3.6.3.jar;D:\mavenLibs\org\apache\servicecomb\foundation-ssl\1.2.1\foundation-ssl-1.2.1.jar;D:\mavenLibs\io\netty\netty-tcnative-boringssl-static\2.0.14.Final\netty-tcnative-boringssl-static-2.0.14.Final.jar;D:\mavenLibs\org\apache\servicecomb\common-protobuf\1.2.1\common-protobuf-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\common-javassist\1.2.1\common-javassist-1.2.1.jar;D:\mavenLibs\org\javassist\javassist\3.21.0-GA\javassist-3.21.0-GA.jar;D:\mavenLibs\org\apache\servicecomb\foundation-protobuf\1.2.1\foundation-protobuf-1.2.1.jar;D:\mavenLibs\io\protostuff\protostuff-parser\2.2.25\protostuff-parser-2.2.25.jar;D:\mavenLibs\org\antlr\antlr4\4.7\antlr4-4.7.jar;D:\mavenLibs\org\antlr\antlr4-runtime\4.7\antlr4-runtime-4.7.jar;D:\mavenLibs\org\antlr\antlr-runtime\3.5.2\antlr-runtime-3.5.2.jar;D:\mavenLibs\org\antlr\ST4\4.0.8\ST4-4.0.8.jar;D:\mavenLibs\org\abego\treelayout\org.abego.treelayout.core\1.0.3\org.abego.treelayout.core-1.0.3.jar;D:\mavenLibs\org\glassfish\javax.json\1.0.4\javax.json-1.0.4.jar;D:\mavenLibs\com\ibm\icu\icu4j\58.2\icu4j-58.2.jar;D:\mavenLibs\com\google\inject\extensions\guice-multibindings\4.1.0\guice-multibindings-4.1.0.jar;D:\mavenLibs\com\google\inject\extensions\guice-assistedinject\4.1.0\guice-assistedinject-4.1.0.jar;D:\mavenLibs\io\protostuff\protostuff-runtime\1.5.9\protostuff-runtime-1.5.9.jar;D:\mavenLibs\io\protostuff\protostuff-api\1.5.9\protostuff-api-1.5.9.jar;D:\mavenLibs\io\protostuff\protostuff-collectionschema\1.5.9\protostuff-collectionschema-1.5.9.jar;D:\mavenLibs\io\protostuff\protostuff-core\1.5.9\protostuff-core-1.5.9.jar;D:\mavenLibs\com\google\protobuf\protobuf-java\3.6.1\protobuf-java-3.6.1.jar;D:\mavenLibs\org\apache\servicecomb\transport-common\1.2.1\transport-common-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\foundation-config\1.2.1\foundation-config-1.2.1.jar;D:\mavenLibs\io\netty\netty-codec\4.1.28.Final\netty-codec-4.1.28.Final.jar;D:\mavenLibs\io\netty\netty-codec-socks\4.1.28.Final\netty-codec-socks-4.1.28.Final.jar;D:\mavenLibs\org\apache\servicecomb\handler-flowcontrol-qps\1.2.1\handler-flowcontrol-qps-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\transport-rest-vertx\1.2.1\transport-rest-vertx-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\transport-rest-client\1.2.1\transport-rest-client-1.2.1.jar;D:\mavenLibs\org\apache\servicecomb\common-rest\1.2.1\common-rest-1.2.1.jar;D:\mavenLibs\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\mavenLibs\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar com.example.demo.DemoApplication

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::       (v1.5.12.RELEASE)

2020-01-12 14:25:04.309  INFO 7876 --- [           main] com.example.demo.DemoApplication         : Starting DemoApplication on DESKTOP-5R8O0OO with PID 7876 (C:\Users\zengqingrong\Downloads\Compressed\demo_3\demo\target\classes started by zengqingrong in C:\Users\zengqingrong\Downloads\Compressed\demo_3\demo)
2020-01-12 14:25:04.315  INFO 7876 --- [           main] com.example.demo.DemoApplication         : No active profile set, falling back to default profiles: default
2020-01-12 14:25:04.478  INFO 7876 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5f9be66c: startup date [Sun Jan 12 14:25:04 CST 2020]; root of context hierarchy
2020-01-12 14:25:05.216  INFO 7876 --- [           main] o.s.b.f.xml.XmlBeanDefinitionReader      : Loading XML bean definitions from URL [jar:file:/D:/mavenLibs/org/apache/servicecomb/java-chassis-core/1.2.1/java-chassis-core-1.2.1.jar!/META-INF/spring/cse.bean.xml]
2020-01-12 14:25:05.904  INFO 7876 --- [           main] o.s.b.f.xml.XmlBeanDefinitionReader      : Loading XML bean definitions from URL [jar:file:/D:/mavenLibs/org/apache/servicecomb/handler-bizkeeper/1.2.1/handler-bizkeeper-1.2.1.jar!/META-INF/spring/cse.bean.xml]
2020-01-12 14:25:05.923  INFO 7876 --- [           main] o.s.b.f.xml.XmlBeanDefinitionReader      : Loading XML bean definitions from URL [jar:file:/D:/mavenLibs/org/apache/servicecomb/handler-loadbalance/1.2.1/handler-loadbalance-1.2.1.jar!/META-INF/spring/cse.bean.xml]
2020-01-12 14:25:05.941  INFO 7876 --- [           main] o.s.b.f.xml.XmlBeanDefinitionReader      : Loading XML bean definitions from URL [jar:file:/D:/mavenLibs/org/apache/servicecomb/foundation-vertx/1.2.1/foundation-vertx-1.2.1.jar!/META-INF/spring/cse.bean.xml]
2020-01-12 14:25:05.958  INFO 7876 --- [           main] o.s.b.f.xml.XmlBeanDefinitionReader      : Loading XML bean definitions from URL [jar:file:/D:/mavenLibs/org/apache/servicecomb/foundation-config/1.2.1/foundation-config-1.2.1.jar!/META-INF/spring/cse.bean.xml]
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.springframework.cglib.core.ReflectUtils$1 (file:/D:/mavenLibs/org/springframework/spring-core/4.3.16.RELEASE/spring-core-4.3.16.RELEASE.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
WARNING: Please consider reporting this to the maintainers of org.springframework.cglib.core.ReflectUtils$1
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2020-01-12 14:25:06.350  INFO 7876 --- [           main] o.a.s.c.ConfigurationSpringInitializer   : Environment received, will get configurations from [org.springframework.core.env.StandardEnvironment@15288143].
2020-01-12 14:25:06.368  WARN 7876 --- [           main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2020-01-12 14:25:06.368  INFO 7876 --- [           main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2020-01-12 14:25:06.456  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   : create local config:
2020-01-12 14:25:06.456  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   :  jar:file:/D:/mavenLibs/org/apache/servicecomb/java-chassis-core/1.2.1/java-chassis-core-1.2.1.jar!/microservice.yaml.
2020-01-12 14:25:06.456  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   :  file:/C:/Users/zengqingrong/Downloads/Compressed/demo_3/demo/target/classes/microservice.yaml.
2020-01-12 14:25:06.486  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.config.spi.ConfigCenterConfigurationSource, count=0.
2020-01-12 14:25:06.486  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Can not find SPI service for org.apache.servicecomb.config.spi.ConfigCenterConfigurationSource
2020-01-12 14:25:06.486  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   : config center SPI service can not find, skip to load configuration from config center
2020-01-12 14:25:06.503  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Can not find SPI service for org.apache.servicecomb.config.spi.ConfigCenterConfigurationSource
2020-01-12 14:25:06.507  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   : create local config:
2020-01-12 14:25:06.507  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   :  jar:file:/D:/mavenLibs/org/apache/servicecomb/java-chassis-core/1.2.1/java-chassis-core-1.2.1.jar!/microservice.yaml.
2020-01-12 14:25:06.508  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   :  file:/C:/Users/zengqingrong/Downloads/Compressed/demo_3/demo/target/classes/microservice.yaml.
2020-01-12 14:25:06.558  INFO 7876 --- [           main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2020-01-12 14:25:06.740  INFO 7876 --- [           main] o.a.s.s.d.MicroserviceDefinition         : load microservice config, name=HelloServiceComb, paths=[jar:file:/D:/mavenLibs/org/apache/servicecomb/java-chassis-core/1.2.1/java-chassis-core-1.2.1.jar!/microservice.yaml, file:/C:/Users/zengqingrong/Downloads/Compressed/demo_3/demo/target/classes/microservice.yaml]
2020-01-12 14:25:06.805  INFO 7876 --- [           main] o.a.s.s.registry.ServiceRegistryFactory  : It is running in the normal mode, a separated service registry is required
2020-01-12 14:25:06.824  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.serviceregistry.registry.ServiceRegistryTaskInitializer, count=1.
2020-01-12 14:25:06.824  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.serviceregistry.diagnosis.instance.InstanceCacheCheckTask.
2020-01-12 14:25:06.828  INFO 7876 --- [           main] o.a.s.s.r.AbstractServiceRegistry        : microserviceVersionFactory is org.apache.servicecomb.core.definition.PrivateMicroserviceVersionMetaFactory.
2020-01-12 14:25:06.838  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   : create local config:
2020-01-12 14:25:06.838  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   :  jar:file:/D:/mavenLibs/org/apache/servicecomb/java-chassis-core/1.2.1/java-chassis-core-1.2.1.jar!/microservice.yaml.
2020-01-12 14:25:06.839  INFO 7876 --- [           main] o.apache.servicecomb.config.ConfigUtil   :  file:/C:/Users/zengqingrong/Downloads/Compressed/demo_3/demo/target/classes/microservice.yaml.
2020-01-12 14:25:06.842  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.deployment.DeploymentProvider, count=1.
2020-01-12 14:25:06.842  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.deployment.DefaultDeploymentProvider.
2020-01-12 14:25:07.909  INFO 7876 --- [           main] o.a.s.foundation.common.net.NetUtils     : add network interface name:wlan0,host address:192.168.3.4
2020-01-12 14:25:07.950  INFO 7876 --- [           main] o.a.s.foundation.common.net.NetUtils     : add network interface name:eth5,host address:10.0.75.1
2020-01-12 14:25:08.059  INFO 7876 --- [           main] o.a.s.foundation.common.net.NetUtils     : add network interface name:eth14,host address:172.18.16.97
2020-01-12 14:25:08.353  INFO 7876 --- [           main] o.a.s.foundation.common.net.NetUtils     : get localhost address: 10.0.75.1
2020-01-12 14:25:08.353  INFO 7876 --- [           main] o.a.s.foundation.common.net.NetUtils     : add host name from localhost:DESKTOP-5R8O0OO,host address:10.0.75.1
2020-01-12 14:25:08.456  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.swagger.generator.core.CommonParameterTypeProcessor, count=5.
2020-01-12 14:25:08.456  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.swagger.invocation.generator.InvocationContextProcessor.
2020-01-12 14:25:08.456  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   1. org.apache.servicecomb.swagger.generator.springmvc.processor.parameter.MultipartFileTypeProcessor.
2020-01-12 14:25:08.457  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   2. org.apache.servicecomb.swagger.generator.springmvc.processor.parameter.MultipartFileArrayTypeProcessor.
2020-01-12 14:25:08.457  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   3. org.apache.servicecomb.swagger.generator.springmvc.processor.parameter.MultipartFileListTypeProcessor.
2020-01-12 14:25:08.457  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   4. org.apache.servicecomb.swagger.generator.core.processor.parametertype.HttpServletRequestProcessor.
2020-01-12 14:25:08.477  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.swagger.generator.core.ResponseTypeProcessor, count=4.
2020-01-12 14:25:08.477  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.swagger.generator.springmvc.processor.response.ResponseEntityProcessor.
2020-01-12 14:25:08.477  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   1. org.apache.servicecomb.swagger.generator.core.processor.response.CompletableFutureProcessor.
2020-01-12 14:25:08.477  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   2. org.apache.servicecomb.swagger.generator.core.processor.response.OptionalProcessor.
2020-01-12 14:25:08.477  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   3. org.apache.servicecomb.swagger.generator.jaxrs.processor.response.JaxrsResponseProcessor.
2020-01-12 14:25:08.529  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.swagger.generator.core.SwaggerGeneratorContext, count=3.
2020-01-12 14:25:08.530  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.swagger.generator.springmvc.SpringmvcSwaggerGeneratorContext.
2020-01-12 14:25:08.530  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   1. org.apache.servicecomb.swagger.generator.jaxrs.JaxrsSwaggerGeneratorContext.
2020-01-12 14:25:08.530  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   2. org.apache.servicecomb.swagger.generator.pojo.PojoSwaggerGeneratorContext.
2020-01-12 14:25:08.548  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.swagger.invocation.response.producer.ProducerResponseMapperFactory, count=6.
2020-01-12 14:25:08.549  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.swagger.invocation.springmvc.response.SpringmvcProducerResponseMapperFactory.
2020-01-12 14:25:08.549  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   1. org.apache.servicecomb.swagger.invocation.response.producer.CseResponseProducerResponseMapperFactory.
2020-01-12 14:25:08.549  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   2. org.apache.servicecomb.swagger.invocation.response.producer.CompletableFutureProducerResponseMapperFactory.
2020-01-12 14:25:08.549  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   3. org.apache.servicecomb.swagger.invocation.response.producer.OptionalProducerResponseMapperFactory.
2020-01-12 14:25:08.549  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   4. org.apache.servicecomb.swagger.invocation.jaxrs.response.JaxrsProducerResponseMapperFactory.
2020-01-12 14:25:08.550  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   5. org.apache.servicecomb.swagger.invocation.response.producer.DefaultProducerResponseMapperFactory.
2020-01-12 14:25:08.556  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.swagger.invocation.response.consumer.ConsumerResponseMapperFactory, count=6.
2020-01-12 14:25:08.557  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.swagger.invocation.springmvc.response.SpringmvcConsumerResponseMapperFactory.
2020-01-12 14:25:08.558  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   1. org.apache.servicecomb.swagger.invocation.response.consumer.CseResponseConsumerResponseMapperFactory.
2020-01-12 14:25:08.559  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   2. org.apache.servicecomb.swagger.invocation.response.consumer.CompletableFutureConsumerResponseMapperFactory.
2020-01-12 14:25:08.559  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   3. org.apache.servicecomb.swagger.invocation.response.consumer.OptionalConsumerResponseMapperFactory.
2020-01-12 14:25:08.559  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   4. org.apache.servicecomb.swagger.invocation.jaxrs.response.JaxrsConsumerResponseMapperFactory.
2020-01-12 14:25:08.559  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   5. org.apache.servicecomb.swagger.invocation.response.consumer.DefaultConsumerResponseMapperFactory.
2020-01-12 14:25:08.989  INFO 7876 --- [           main] o.a.s.core.executor.GroupExecutor        : thread pool rules:
1.use core threads.
2.if all core threads are busy, then create new thread.
3.if thread count reach the max limitation, then queue the request.
4.if queue is full, and threads count is max, then reject the request.
2020-01-12 14:25:08.990  INFO 7876 --- [           main] o.a.s.core.executor.GroupExecutor        : executor group=2. per group settings, coreThreads=25, maxThreads=100, maxIdleInSecond=60, maxQueueSize=2147483647.
2020-01-12 14:25:09.042  WARN 7876 --- [           main] o.h.v.m.ParameterMessageInterpolator     : HV000184: ParameterMessageInterpolator has been chosen, EL interpolation will not be supported
2020-01-12 14:25:09.328  WARN 7876 --- [           main] o.h.v.m.ParameterMessageInterpolator     : HV000184: ParameterMessageInterpolator has been chosen, EL interpolation will not be supported
2020-01-12 14:25:09.764  INFO 7876 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2020-01-12 14:25:09.799  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.core.BootListener, count=0.
2020-01-12 14:25:10.041  INFO 7876 --- [           main] c.n.config.util.ConfigurationUtils       : Loaded properties file jar:file:/D:/mavenLibs/org/apache/servicecomb/handler-bizkeeper/1.2.1/handler-bizkeeper-1.2.1.jar!/hystrix-plugins.properties
2020-01-12 14:25:10.060  INFO 7876 --- [           main] s.s.g.c.CompositeSwaggerGeneratorContext : select [org.apache.servicecomb.swagger.generator.springmvc.SpringmvcSwaggerGeneratorContext] for [com.example.demo.HelloImpl] to generate schema.
2020-01-12 14:25:10.087  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.swagger.extend.property.creator.PropertyCreator, count=1.
2020-01-12 14:25:10.088  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     :   0. org.apache.servicecomb.swagger.extend.property.creator.springmvc.MultipartFilePropertyCreator.
2020-01-12 14:25:10.203  INFO 7876 --- [           main] o.a.s.c.d.schema.ProducerSchemaFactory   : generate swagger for start.servicecomb.io/HelloServiceComb/hello, swagger: ---
swagger: ""2.0""
info:
  version: ""1.0.0""
  title: ""swagger definition for com.example.demo.HelloImpl""
  x-java-interface: ""cse.gen.start.servicecomb.io.HelloServiceComb.hello.HelloImplIntf""
basePath: ""/""
consumes:
- ""application/json""
produces:
- ""application/json""
paths:
  /hello:
    get:
      operationId: ""hello""
      parameters: []
      responses:
        200:
          description: ""response of 200""
          schema:
            type: ""string""

2020-01-12 14:25:10.203  INFO 7876 --- [           main] o.a.s.c.definition.loader.SchemaLoader   : register schema start.servicecomb.io/HelloServiceComb/hello
2020-01-12 14:25:10.301  INFO 7876 --- [           main] o.a.s.common.javassist.JavassistUtils    : create CtClass cse.gen.start.servicecomb.io.HelloServiceComb.hello.HelloImplIntf in classLoader jdk.internal.loader.ClassLoaders$AppClassLoader@2437c6dc.
2020-01-12 14:25:10.302  INFO 7876 --- [           main] o.a.s.common.javassist.JavassistUtils    : create class cse.gen.start.servicecomb.io.HelloServiceComb.hello.HelloImplIntf in classLoader jdk.internal.loader.ClassLoaders$AppClassLoader@2437c6dc.
2020-01-12 14:25:10.304  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Found SPI service org.apache.servicecomb.swagger.invocation.response.ResponseMetaMapper, count=0.
2020-01-12 14:25:10.304  INFO 7876 --- [           main] o.a.s.f.common.utils.SPIServiceUtils     : Can not find SPI service for org.apache.servicecomb.swagger.invocation.response.ResponseMetaMapper
2020-01-12 14:25:10.314 ERROR 7876 --- [           main] o.a.s.core.definition.SchemaMeta         : Unhandled exception to service HelloServiceComb schema hello
2020-01-12 14:25:10.315  INFO 7876 --- [           main] org.apache.servicecomb.core.SCBEngine    : ServiceComb is closing now...
2020-01-12 14:25:10.315  INFO 7876 --- [           main] org.apache.servicecomb.core.SCBEngine    : BootListener org.apache.servicecomb.core.provider.producer.ProducerProviderManager succeed to process BEFORE_CLOSE.
2020-01-12 14:25:10.315  INFO 7876 --- [           main] org.apache.servicecomb.core.SCBEngine    : BootListener org.apache.servicecomb.common.rest.RestEngineSchemaListener succeed to process BEFORE_CLOSE.
2020-01-12 14:25:10.317  INFO 7876 --- [           main] o.a.s.s.registry.RemoteServiceRegistry   : service center task is shutdown.
2020-01-12 14:25:10.317  INFO 7876 --- [           main] o.a.s.foundation.vertx.VertxUtils        : Closing vertx registry.
2020-01-12 14:25:10.320  INFO 7876 --- [           main] o.a.s.foundation.vertx.VertxUtils        : Vertx registry not exist.
2020-01-12 14:25:10.320  INFO 7876 --- [           main] o.a.s.foundation.vertx.VertxUtils        : Closing vertx config-center.
2020-01-12 14:25:10.320  INFO 7876 --- [           main] o.a.s.foundation.vertx.VertxUtils        : Vertx config-center not exist.
2020-01-12 14:25:10.320  INFO 7876 --- [           main] o.a.s.foundation.vertx.VertxUtils        : Closing vertx transport.
2020-01-12 14:25:10.356  INFO 7876 --- [ntloop-thread-8] o.a.s.foundation.vertx.VertxUtils        : Success to close vertx transport.
2020-01-12 14:25:10.357  INFO 7876 --- [           main] org.apache.servicecomb.core.SCBEngine    : BootListener org.apache.servicecomb.core.provider.producer.ProducerProviderManager succeed to process AFTER_CLOSE.
2020-01-12 14:25:10.357  INFO 7876 --- [           main] org.apache.servicecomb.core.SCBEngine    : BootListener org.apache.servicecomb.common.rest.RestEngineSchemaListener succeed to process AFTER_CLOSE.
2020-01-12 14:25:10.357  INFO 7876 --- [           main] org.apache.servicecomb.core.SCBEngine    : ServiceComb had closed
2020-01-12 14:25:10.362  INFO 7876 --- [           main] utoConfigurationReportLoggingInitializer : 

Error starting ApplicationContext. To display the auto-configuration report re-run your application with 'debug' enabled.
2020-01-12 14:25:10.380 ERROR 7876 --- [           main] o.s.boot.SpringApplication               : Application startup failed

java.lang.IllegalStateException: ServiceComb init failed.
	at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:225) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.CseApplicationListener.onApplicationEvent(CseApplicationListener.java:81) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:172) ~[spring-context-4.3.20.RELEASE.jar:4.3.20.RELEASE]
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:165) ~[spring-context-4.3.20.RELEASE.jar:4.3.20.RELEASE]
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139) ~[spring-context-4.3.20.RELEASE.jar:4.3.20.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393) ~[spring-context-4.3.20.RELEASE.jar:4.3.20.RELEASE]
	at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347) ~[spring-context-4.3.20.RELEASE.jar:4.3.20.RELEASE]
	at org.springframework.boot.context.event.EventPublishingRunListener.finished(EventPublishingRunListener.java:101) ~[spring-boot-1.5.12.RELEASE.jar:1.5.12.RELEASE]
	at org.springframework.boot.SpringApplicationRunListeners.callFinishedListener(SpringApplicationRunListeners.java:79) ~[spring-boot-1.5.12.RELEASE.jar:1.5.12.RELEASE]
	at org.springframework.boot.SpringApplicationRunListeners.finished(SpringApplicationRunListeners.java:72) ~[spring-boot-1.5.12.RELEASE.jar:1.5.12.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:305) ~[spring-boot-1.5.12.RELEASE.jar:1.5.12.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1118) ~[spring-boot-1.5.12.RELEASE.jar:1.5.12.RELEASE]
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1107) ~[spring-boot-1.5.12.RELEASE.jar:1.5.12.RELEASE]
	at com.example.demo.DemoApplication.main(DemoApplication.java:12) ~[classes/:na]
Caused by: java.lang.IllegalStateException: Failed to create lambda from public void org.apache.servicecomb.core.definition.OperationConfig.setSlowInvocationEnabled(boolean)
	at org.apache.servicecomb.foundation.common.utils.LambdaMetafactoryUtils.createLambda(LambdaMetafactoryUtils.java:157) ~[foundation-common-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.config.inject.ConfigObjectFactory.doCreate(ConfigObjectFactory.java:103) ~[foundation-config-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.config.inject.ConfigObjectFactory.create(ConfigObjectFactory.java:68) ~[foundation-config-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.config.priority.PriorityPropertyManager.createConfigObject(PriorityPropertyManager.java:131) ~[foundation-config-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.config.priority.PriorityPropertyManager.createConfigObject(PriorityPropertyManager.java:126) ~[foundation-config-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.OperationMeta.init(OperationMeta.java:83) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.SchemaMeta.initOperations(SchemaMeta.java:129) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.SchemaMeta.<init>(SchemaMeta.java:75) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.loader.SchemaLoader.registerSchema(SchemaLoader.java:86) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.schema.ProducerSchemaFactory.createSchema(ProducerSchemaFactory.java:133) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.schema.ProducerSchemaFactory.createSchema(ProducerSchemaFactory.java:54) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.schema.AbstractSchemaFactory.getOrCreateSchema(AbstractSchemaFactory.java:58) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.definition.schema.ProducerSchemaFactory.getOrCreateProducerSchema(ProducerSchemaFactory.java:76) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.provider.rest.common.RestProducerProvider.init(RestProducerProvider.java:45) ~[provider-rest-common-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.provider.producer.ProducerProviderManager.init(ProducerProviderManager.java:54) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.SCBEngine.doInit(SCBEngine.java:246) ~[java-chassis-core-1.2.1.jar:1.2.1]
	at org.apache.servicecomb.core.SCBEngine.init(SCBEngine.java:214) ~[java-chassis-core-1.2.1.jar:1.2.1]
	... 13 common frames omitted
Caused by: java.lang.invoke.LambdaConversionException: Type mismatch for instantiated parameter 1: boolean is not a subtype of class java.lang.Object
	at java.base/java.lang.invoke.AbstractValidatingLambdaMetafactory.checkDescriptor(AbstractValidatingLambdaMetafactory.java:308) ~[na:na]
	at java.base/java.lang.invoke.AbstractValidatingLambdaMetafactory.validateMetafactoryArgs(AbstractValidatingLambdaMetafactory.java:294) ~[na:na]
	at java.base/java.lang.invoke.LambdaMetafactory.metafactory(LambdaMetafactory.java:328) ~[na:na]
	at org.apache.servicecomb.foundation.common.utils.LambdaMetafactoryUtils.createLambda(LambdaMetafactoryUtils.java:147) ~[foundation-common-1.2.1.jar:1.2.1]
	... 29 common frames omitted

2020-01-12 14:25:10.382  INFO 7876 --- [           main] s.c.a.AnnotationConfigApplicationContext : Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@5f9be66c: startup date [Sun Jan 12 14:25:04 CST 2020]; root of context hierarchy
2020-01-12 14:25:10.385  INFO 7876 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdown

Process finished with exit code 1
项目包：
[demo.zip](https://github.com/apache/servicecomb-java-chassis/files/4050277/demo.zip)

","我自己用脚手架生成了项目，是可以工作的。并且用你的附件demo.zip编译执行，也是可以工作的。 是否和你的编译环境有关，能够检查下JAVA环境，比如版本等信息。 

```
mvn clean install
cd target\bin
java -jar demo-0.0.1-SNAPSHOT-exec.jar
```
",91674936
314,CSE能支持服务端异步吗？,open,2020-01-11T06:19:54Z,2020-01-13T01:40:26Z,,NONE,"类似于SpringMVC的@Async注解，长时间运行的服务，不需要返回值。

AsyncRestTemplate支持客户端异步，实际还是占用Http请求，客户端服务端保持连接。

没找到相关的说明，难道一定要在服务端代码里面自己放到异步队列？
",你说的这种方式目前没提供。可能需要你自己写一些代码将逻辑放到自己的线程池执行，并立即返回一个结果。 ,91674936
315,故障注入功能配置生效问题,open,2020-01-11T03:20:19Z,2020-01-11T07:22:32Z,,NONE,请问，通过修改配置对微服务进行故障注入时，故障注入配置生效的耗时是多少？ 需要重启应用吗？,"> java-chassis的故障注入都是通过[Hanlders](https://github.com/apache/servicecomb-java-chassis/tree/master/handlers/handler-fault-injection)实现的， 内部配置生效依赖于动态配置下发生效。 这个取决于连接[配置中心的机制](https://docs.servicecomb.io/java-chassis/zh_CN/config/general-config.html)，如果是pull模式（默认），时效性一般在1~2个pull周期，默认是30s一个周期。 如果是push模式，时效性更好。 但是pull模式的可靠性会好很多。

理解了，非常感谢。",91674936
316,接口返回值定义的是ResponseEntity，为什么返回值的Body为空？,open,2020-01-11T03:07:38Z,2020-01-17T01:48:04Z,,NONE,返回代码参考：return ResponseEntity.status(status).body(message)；,"下面有个例子可以参考下：

```
  @ResponseHeaders({@ResponseHeader(name = ""h1"", response = String.class),
      @ResponseHeader(name = ""h2"", response = String.class)})
  @RequestMapping(path = ""/responseEntity"", method = RequestMethod.POST)
  public ResponseEntity<Date> responseEntity(InvocationContext c1, @RequestAttribute(""date"") Date date) {
    HttpHeaders headers = new HttpHeaders();
    headers.add(""h1"", ""h1v "" + c1.getContext().get(Const.SRC_MICROSERVICE));

    InvocationContext c2 = ContextUtils.getInvocationContext();
    headers.add(""h2"", ""h2v "" + c2.getContext().get(Const.SRC_MICROSERVICE));

    return new ResponseEntity<>(date, headers, HttpStatus.ACCEPTED);
  }
```

注意：
1. 需要显示声明ResponseEntity的模板类型；
2. 如果还需要返回额外的headers，需要通过ResponseHeaders显示的声明返回的header。 

这个是java-chassis和Spring MVC不同的地方， 接口定义需要是明确的，能够通过契约描述出来实际的类型和header。 


",91674936
317,Unhandled exception to service ConfigQueryService schema application,open,2020-01-10T02:04:34Z,2020-01-11T00:54:47Z,,NONE,ARM环境下，当业务在启动CSE，加载Schema时候，报了Unhandled exception to service ConfigQueryService schema application这个错误，随后就关闭了Servicecomb，求助是什么原因，代码没有问题，在其他环境运行正常。,"Sorry, github will not load images sometimes, I cannot see your logs. Maybe you need to check the related code or debug it to find the exception message",91674936
318,【求助】CSE框架edge直接返回如何记录traceId到cse接口日志,open,2020-01-09T06:46:47Z,2020-01-10T01:21:14Z,,NONE,"
![image](https://user-images.githubusercontent.com/52325473/72044486-d4ae0100-32ee-11ea-8946-c5052956978e.png)



打印方式为yaml中如下方式：

pattern: ""%SCB-traceId|%{yyyy-MM-dd HH:mm:ss.SSS}t|%h|%r|%s|%D""


traceId加入上下文方式（非edge直接返回场景可以正常打印）：

ContextUtils.getInvocationContext().addContext(Const.TRACE_ID_NAME, traceId)

使用 routingContext.response() 返回的","I do not quite understand your question. Maybe you can investigate [RestServerVerticle](https://github.com/apache/servicecomb-java-chassis/blob/master/transports/transport-rest/transport-rest-vertx/src/main/java/org/apache/servicecomb/transport/rest/vertx/RestServerVerticle.java) , the access log module is bounded as a Handler to mainRoot. 
",91674936
319,使用servlet将工程打成war包，无法生成契约,open,2020-01-09T02:31:05Z,2020-01-10T01:10:55Z,,NONE,"![image](https://user-images.githubusercontent.com/40970933/72032630-e54c8000-32ca-11ea-90e9-8ee3129e0e6f.png)

使用上述方法将项目打成war包放在tomcat下启动，成功注册到service center了，但是没有生成契约文件，不知道是什么原因，Controller类上面添加了@RestSchema的注解，本地启动是没有问题的，但是打包后就出了问题","May be you can add this to your web.xml

```
  <context-param>
    <param-name>contextConfigLocation</param-name>
    <param-value>
      classpath*:META-INF/spring/*.bean.xml
    </param-value>
  </context-param>
```

see this [demo](https://github.com/apache/servicecomb-java-chassis/blob/master/demo/demo-server-servlet/src/main/webapp/WEB-INF/web.xml)",91674936
320,CSE的服务端会话缓存是否开启和缓存周期这个是在哪块配置的？,open,2020-01-08T01:59:45Z,2020-01-08T10:16:26Z,,NONE,"### 为了加快建立握手的速度，减少协议带来的性能降低和资源消耗(具体分析在后文)，TLS 协议有两类会话缓存机制：会话标识 session ID 与会话记录 session ticket。
### session ID 由服务器端支持，协议中的标准字段，因此基本所有服务器都支持，服务器端保存会话ID以及协商的通信信息，Nginx 中1M 内存约可以保存4000个 session ID 机器相关信息，占用服务器资源较多;
=====================
### 就是这个TLS协议下的sessionID缓存机制",嗯，没有用session ticket。只是用了session ID缓存，这个是TLS标准协议支持的。在CSE上通过sslEnabled开启后已经验证过了，想确认下这个sessionID缓存在CSE上怎么配置 是否开启 和 缓存时间。,91674936
321,为什么在过滤器中，无法向HTTP请求头添加参数？,open,2020-01-03T07:02:55Z,2020-01-04T08:19:21Z,,NONE,"如下图，自定义了一个过滤器，在过滤器中向请求头添加参数，在Controller中无法拿到该参数；
但是添加的Parameter参数，在Controller中可以获取到。这是为什么？


![image](https://user-images.githubusercontent.com/9291379/71711033-f82e0300-2e39-11ea-9d80-db27c97eec50.png)
","可以使用invocation这个参数进行传递.
在过滤器的afterReceiveRequest()方法中,将你要传递的header参数使用
invocation.addContext(Constants.DEVELOPER_UID, “123456”);
的方式进行包装，然后在Controller中使用
public Response logout(InvocationContext context) {
        String value = context.getContext(Constants.DEVELOPER_UID);
        return null;
    }
即可获取到值。",91674936
322,通过RestClient/PostMan等工具发送的HTTP 请求中的Cookie缺失了部分信息,open,2020-01-02T12:47:34Z,2020-01-03T06:19:01Z,,NONE,"以下是在工具中配置的Cookie内容，为何在服务端从request中取出来的cookie少了authInfo？

X-HD-SESSION=12456c12-2*****************37ee545d5; authInfo=""{\""expiretime\"":\""20200102T102330Z\"",\""rtCiphertext\"":\""7qfADfdUA*******************************************SQ2/XhB6wV6siN6P9UyFvLzivo/cLOYTrom8JV0vOAEy/SCYXCts7iutg+Nv5+FhvovWBsCPS/fPnxBaCjWiLJWzlI2nw\"",\""createtime\"":\""20200102T092330Z\"",\""accesstoken\"":\""CV4NxKKd/E*******************cIpjY9uoZs8uGD/Hv6rw01AD*****************LDelXxDg==\"",\""siteID\"":\""11\"",\""x-uid\"":\""900086*****001817\""}""; csrfToken=24B4805793964D1D7D558649451764E1CD0D602E18E9542C97; x-hd-grey=1; x-country=CN; x-userType=2; ID_CAS_ISCASLOGIN=true; CASLOGINSITE=1; LOGINACCSITE=1; x-uid=90008*****000375; x-teamId=90008*****000375; x-country=CN; x-userType=2; x-uid=90008*****000375; developer_userinfo=%7B%22siteid%22%3A***********************************amid%22%3A%22900086000000000375%22%7D",试过将Cookie内容进行URL编码，编码之后可以获取到了。,91674936
323,能否允许业务对流式数据进行处理，比如上行流可以让业务自己来读取,open,2020-01-02T06:13:44Z,2020-01-03T00:57:32Z,,NONE,现在业务需要流式读取数据，但是貌似框架会把数据从socket里面读取完毕，然后一把给到下面业务处理，这块有没有比较好的方法来完成，多谢！,可以参考这个[示例](https://github.com/apache/servicecomb-java-chassis/blob/master/demo/demo-signature/src/main/java/org/apache/servicecomb/demo/signature/ClientSignature.java),91674936
324,怎么自定义Jackson的ObjectMapper？,open,2019-12-30T16:31:15Z,2019-12-31T01:45:16Z,,NONE,"我想做两件事：
1、支持org.json的转换
2、把所有Rest接口默认使用下划线方式

没找到相关文档，扒代码找到如下方式设置：
```
JsonUtils.OBJ_MAPPER.registerModule(new JsonOrgModule());
JsonUtils.OBJ_MAPPER.setPropertyNamingStrategy(PropertyNamingStrategy.SNAKE_CASE);
        
RestObjectMapperFactory.getRestObjectMapper().registerModule(new JsonOrgModule()); 
RestObjectMapperFactory.getRestObjectMapper().setPropertyNamingStrategy(PropertyNamingStrategy.SNAKE_CASE);
```

我试了下org.json支持没问题，但是SNAKE_CASE会导致ServiceComb无法启动，提示微服务命名格式不对。

我这是标准的扩展ObjectMapper的方式吗？扩展的时候到底有什么限制？","1、有没有文档定义哪些行为能改，判断原则有吗？比如我现在改了，目测能运行，但是不知道有没有什么坑。
2、setConsumerWriterMapper是什么场景用的，调试时没看到有地方使用。",91674936
325,业务如果想在发生熔断的时候，在业务日志打个error日志，这个怎么做呢？,open,2019-12-27T02:34:04Z,2019-12-28T03:27:25Z,,NONE,现在业务貌似获取不到熔断这个事件，只有cse知道,"是不是没有触发熔断啊。
我基于[微服务21天培训课程](https://education.huaweicloud.com:8443/courses/course-v1:HuaweiX+CBUCNXP012+Self-paced/courseware/9d1e7d073ba04f6ebc11d984dbc72eb5/4e114502a206474482dd72fa98409caa/)里面第九天的demo，加了一个listener监听事件
```java
package microservice.demo.training21days.edge.listener;

import org.apache.servicecomb.bizkeeper.event.CircutBreakerEvent;
import org.apache.servicecomb.common.rest.codec.RestObjectMapperFactory;
import org.apache.servicecomb.foundation.common.event.EventManager;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.stereotype.Component;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.google.common.eventbus.Subscribe;

@Component
public class CircuitBreakListener implements InitializingBean {

  private static final Logger LOGGER = LoggerFactory.getLogger(CircuitBreakListener.class);

  @Subscribe
  public void onCircuitBreakEventHappen(CircutBreakerEvent event) {
    try {
      LOGGER.info(""event happen! {}"", RestObjectMapperFactory.getRestObjectMapper().writeValueAsString(event));
    } catch (JsonProcessingException e) {
      LOGGER.info(""failed to write "", e);
    }
  }

  @Override
  public void afterPropertiesSet() throws Exception {
    EventManager.register(this);
    LOGGER.info(""registered!"");
  }
}
```

发现是可以生效的。会打印像这样的日志
熔断触发：
```
2019-12-28 11:18:57,155 [INFO] event happen! {""type"":""OPEN"",""role"":""CONSUMER"",""microservice"":""consumer"",""schema"":""helloConsumer"",""operation"":""sayHello"",""currentTotalRequest"":3,""currentErrorCount"":100,""currentErrorPercentage"":3,""requestVolumeThreshold"":3,""sleepWindowInMilliseconds"":30000,""errorThresholdPercentage"":50} microservice.demo.training21days.edge.listener.CircuitBreakListener.onCircuitBreakEventHappen(CircuitBreakListener.java:22)
```
熔断恢复：
```
2019-12-28 11:25:53,837 [INFO] event happen! {""type"":""CLOSE"",""role"":""CONSUMER"",""microservice"":""consumer"",""schema"":""helloConsumer"",""operation"":""sayHello"",""currentTotalRequest"":0,""currentErrorCount"":0,""currentErrorPercentage"":0,""requestVolumeThreshold"":3,""sleepWindowInMilliseconds"":30000,""errorThresholdPercentage"":50} microservice.demo.training21days.edge.listener.CircuitBreakListener.onCircuitBreakEventHappen(CircuitBreakListener.java:22)
```

如果你那边触发不了的话，建议去`CircutBreakerEventNotifier`里面打个断点检查一下",91674936
326,edge契约更新不动,open,2019-12-25T09:27:56Z,2019-12-27T03:44:06Z,,NONE,"感觉上了环境有些问题的。edge感知不到后面微服务最新接口字段的变化，重启和升级版本都试过了，edge还是感知不到新增的字段。

直接请求微服务节点是能够获取最新的接口数据，通过edge转发请求的话，就更新的接口字段展示不出来。","不客气 : )
对于强类型内核的Java-Chassis版本（1.x版本），框架会把契约中的`x-java-class`属性所记录的Java类型作为参数的实际类型。consumer端加载provider契约后会根据`x-java-class`字段去classpath中搜索是否存在这个类，如果存在就直接拿来用。如果不存在会根据契约动态生成这个Java类型。
一般edge不引入后端服务的jar包的话，每次加载新版本服务契约都会动态生成Java参数类型的（一个微服务版本对应一个ClassLoader），所以碰不到你这种问题。
不过你们这种场景下就会一直沿用依赖jar包里面的旧的参数类型了。",91674936
327,[Suggestion]Check whether current thread is eventLoopThread before calling other microservice synchronously,open,2019-12-25T01:50:02Z,2019-12-26T01:34:18Z,,NONE,"In our microservice there were a chance that after calling a microservice, no packet was sent but `
vertx-blocked-thread-checker`  continuously print following logs:
```
2019-12-24 13:36:56.097|[]|vertx-blocked-thread-checker|WARN |BlockedThreadChecker.java:55|Thread Thread[vert.x-eventloop-thread-1,5,main] has been blocked for 5389 ms, time limit is 2000 ms
io.vertx.core.VertxException: Thread blocked
	at sun.misc.Unsafe.park(Native Method) ~[?:1.8.0_222]
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) ~[?:1.8.0_222]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:838) ~[?:1.8.0_222]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:999) ~[?:1.8.0_222]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1306) ~[?:1.8.0_222]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231) ~[?:1.8.0_222]
	at org.apache.servicecomb.core.provider.consumer.SyncResponseExecutor.waitResponse(SyncResponseExecutor.java:53) ~[java-chassis-core-1.3.0.jar!/:1.3.0]
	at org.apache.servicecomb.core.provider.consumer.InvokerUtils.innerSyncInvoke(InvokerUtils.java:75) ~[java-chassis-core-1.3.0.jar!/:1.3.0]
	at org.apache.servicecomb.provider.pojo.Invoker.syncInvoke(Invoker.java:174) ~[provider-pojo-1.3.0.jar!/:1.3.0]
	at org.apache.servicecomb.provider.pojo.Invoker.invoke(Invoker.java:161) ~[provider-pojo-1.3.0.jar!/:1.3.0]
```

We finally found out its due to we are running our bussiniess logic in a async callback to other service which runs in eventLoopThread. If vertx happens to pick the same eventLoopThread for connecting when it calls another microservice synchronously then there is deadlock. 

Maybe checking whether current thread is eventLoopThread before calling other microservice synchronously and print some warning log for troubleshooting such like problem is helpful.",And other blocking case is only slowing down the application. But calling other microservice is causing deadlock.,91674936
328,query about context delivery mechanism of servicecomb,open,2019-12-24T02:11:22Z,2019-12-24T06:19:22Z,,NONE,"In my case,  when request arrived at edge service, some properties will be added to the invocation context, so the invocation instance will get the context setted by edge service.

but in the invocation instance, I depend on the other service instance, so how clould I diliver this context by a remote rpc request to a new service instance ?","Do you mean 
```
  @ApiResponse(code = 200, response = User.class, message = """")
  @ResponseHeaders({@ResponseHeader(name = ""h1"", response = String.class),
      @ResponseHeader(name = ""h2"", response = String.class)})
  @Path(""/cseResponse"")
  @GET
public Response cseResponse(InvocationContext c1) {
    Response response = Response.createSuccess(Status.ACCEPTED, new User());
    Headers headers = response.getHeaders();
    headers.addHeader(""h1"", ""h1v "" + c1.getContext().get(Const.SRC_MICROSERVICE).toString());

    InvocationContext c2 = ContextUtils.getInvocationContext();
    headers.addHeader(""h2"", ""h2v "" + c2.getContext().get(Const.SRC_MICROSERVICE).toString());

    return response;
  }
```

or

```
void testTraceIdOnContextContainsTraceId() {
    InvocationContext context = new InvocationContext();
    context.addContext(Const.TRACE_ID_NAME, String.valueOf(Long.MIN_VALUE));
    ContextUtils.setInvocationContext(context);
    String traceId = test.testTraceId();
    TestMgr.check(String.valueOf(Long.MIN_VALUE), traceId);
    ContextUtils.removeInvocationContext();
  }
```",91674936
329,"consolewebsite配置了SSO登录后报错,报错信息如下",open,2019-12-23T08:56:17Z,2019-12-23T08:56:17Z,,NONE,"23-Dec-2019 12:42:52.715 SEVERE [http-nio-30106-exec-2] org.apache.catalina.core.StandardWrapperValve.invoke Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [org.jasig.cas.client.validation.TicketValidationException: Ticket 'ST-1963-5gkarWAeLJAacRHbBZyYXeZcJ6Csij-cas01.example.org' not recognized] with root cause
 org.jasig.cas.client.validation.TicketValidationException: Ticket 'ST-1963-5gkarWAeLJAacRHbBZyYXeZcJ6Csij-cas01.example.org' not recognized
        at org.jasig.cas.client.validation.Cas20ServiceTicketValidator.parseResponseFromServer(Cas20ServiceTicketValidator.java:92)
        at org.jasig.cas.client.validation.AbstractUrlBasedTicketValidator.validate(AbstractUrlBasedTicketValidator.java:198)
        at org.jasig.cas.client.validation.AbstractTicketValidationFilter.doFilter(AbstractTicketValidationFilter.java:204)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.jasig.cas.client.authentication.AuthenticationFilter.doFilter(AuthenticationFilter.java:177)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101)
        at org.springframework.boot.web.support.ErrorPageFilter.doFilter(ErrorPageFilter.java:123)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
        at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:719)
        at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:465)
        at org.apache.catalina.core.ApplicationDispatcher.doForward(ApplicationDispatcher.java:390)
        at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:317)
        at org.springframework.boot.web.support.ErrorPageFilter.forwardToErrorPage(ErrorPageFilter.java:197)
        at org.springframework.boot.web.support.ErrorPageFilter.handleException(ErrorPageFilter.java:180)
",,91674936
330,微服务安全有了TLS，是不是不需要RSA鉴权呢，RSA是不是多此一举呢,open,2019-12-20T05:50:33Z,2019-12-23T03:12:42Z,,NONE,,They are different ways to provide application security. Choose the one best fit for your. ,91674936
331,cse service node stop but the edge still forward the request to the stopped node,open,2019-12-19T08:53:26Z,2019-12-19T09:22:26Z,,NONE,"In the production environment, I found when I rolling upgrade my service node, the edeg service will forword the request to the stopped node, so in this case the request failed.

or on the begin，the new started service node registed service center, when the edeg forward request to it, the request failed too.

what should I do to avoid this in my upgrade process？","When an instance is stopped, EdgeService may forward requests to this instance in a short period because the consumer side cannot get it's cached provider instance list refreshed without any latency. This is determined by the current service discovery mechanism. There are some approaches to shorten the latency. As for those requests forwarded to the down instances, some network related exceptions may occur and the instance isolation and retry mechanism in the [LB module](https://docs.servicecomb.io/java-chassis/zh_CN/references-handlers/loadbalance.html) may cover them and make the business invoke still success outside of the consumer side. Be careful the retry mechanism is limited and they cannot ensure the business invocation success in all of the cases. You can get some references in #1238.

As for the instance start up cases, in terms of the Java-Chassis, when the instances get registered onto the service center, they are ready to process the requests. Maybe the failures occur because some of your business related modules are not ready at this time. I guess you can implement the `org.apache.servicecomb.core.BootListener` and get you modules initiated in the proper stage. The enum `org.apache.servicecomb.core.BootListener.EventType` lists the stages in the microservice instance lifecycle, you can find their meaning in Java -Chassis source code.",91674936
332,"开发环境微服务多次发布后网关服务发生GC, MircroserviceMeta占用内存过大",open,2019-12-19T07:54:11Z,2019-12-20T01:02:55Z,,NONE,"每次服务升级版本，MircroserviceMeta 实例都保留旧的版本，不知道什么原因实例占用内存越来越大

![dump](https://user-images.githubusercontent.com/7219324/71154877-83729a80-2277-11ea-8071-e182d2d63f7a.png)
","This is a major problem working on 2.0.0(not released, but for REST transports the version is ready, and we still have a lot of work to do with HIGHWAY transports). Using versions before 2.0.0 should avoid change versions frequently or restart edge service is needed or the the memory will grow when a new version comes.  
",91674936
333,服务器性能余量充足，但是请求排队超时，报错InvocationException: code=500,open,2019-12-19T04:01:01Z,2019-12-20T01:21:30Z,,NONE,"报错rest server onRequest error org.apache.servicecomb.swagger.invocation.exception.InvocationException: InvocationException: code=500;msg=CommonExceptionData [message=Timeout when processing the request.] 以及Unhandled exceptionjava.lang.IllegalStateException: Response is closed以及CSE心跳丢失
服务器平时cpu使用率2%，内存20%，性能余量充足，发生问题时请求超时，同时伴随的cpu使用率飙升到60%，持续3秒，导致现网少量请求失败，这种情况根因是什么，有什么解决办法 ","可能你服务端并发调用出现死锁。 业务应该尽可能避免循环调用，比如 A -> B -> A，或者A->A。 当线程池足够或者并发数很小的时候，可能没问题。 并发数大了就会死锁。 

服务内部调用，建议直接调用service暴露出来的API。 
",91674936
334,文件下载接口，客户端Response body为空，导致客户端JS收不到文件流,open,2019-12-19T03:06:47Z,2019-12-19T07:01:37Z,,NONE,"参考如下文档写了一个文件下载接口，但是客户端收到的Response body为空，导致前端JS处理时获取不到文件流。

代码截图：
![image](https://user-images.githubusercontent.com/9291379/71141526-5ad6aa80-224f-11ea-846e-4cdcc6bfdb49.png)

客户端问题：
![image](https://user-images.githubusercontent.com/9291379/71141553-75a91f00-224f-11ea-8187-68ff945262b6.png)

服务端有过滤器，过滤器解析body的时候，body也是null，导致报了空指针异常：
![image](https://user-images.githubusercontent.com/9291379/71141578-8fe2fd00-224f-11ea-831e-84106273aec0.png)

参考文档：https://docs.servicecomb.io/java-chassis/zh_CN/general-development/file-download.html

https://github.com/apache/servicecomb-java-chassis/blob/master/integration-tests/it-producer/src/main/java/org/apache/servicecomb/it/schema/DownloadSchema.java


",代码和返回的消息头看上去都挺正常的，不过貌似你不是在本地做开发调试的对吧？建议先在本地跑一下看看，排查一下中间的代理或者网关造成问题的可能性。,91674936
335,RestTemplateBuilder 缺少setConnectionTimeout和setReadTimeout方法,open,2019-12-19T03:05:59Z,2019-12-19T07:09:55Z,,NONE,但是org.springframework.boot.web.client.RestTemplateBuilder#setConnectTimeout 支持,"```
servicecomb.request.${service}.${schema}.${operation}.timeout
```
request timeout can be set to each operation. ",91674936
336,建议提供更灵活的线程池扩展,open,2019-12-13T01:50:28Z,2019-12-17T09:28:07Z,,NONE,"servicecomb支持为每个接口提供执行线程池，前提是需要在spring里定义对应的线程池bean，同时在microservice.yaml里进行对应的配置。

一些业务场景，需要临时动态的调整线程池的安排，通过spring+microservice.yaml的调整加重启的方式显得笨拙了一些。

期待提供一种更灵活的线程池扩展形式，
1、可以仅通过修改配置文件就可以定义出一个线程池
2、可以在代码级别扩展线程池自定义线程池选择策略
3、支持在请求处理前一刻选择线程池。","Thread pools [reference ](https://docs.servicecomb.io/java-chassis/zh_CN/build-provider/thread-pool.html), 

It seems like you want to support creating THREAD POOLS according to the configuration, and maybe destroy and create dynamically. This is not a good idea and seams too complicated. ",91674936
337,使用SpringBoot2+外置Tomcat容器RestServletInitializer报空指针错误,open,2019-12-06T07:39:24Z,2020-03-25T02:13:44Z,,NONE,"错误位置如下：
![image](https://user-images.githubusercontent.com/4591255/70304464-f2de9800-183c-11ea-83d4-8e7ffffc1beb.png)

使用内嵌Tomcat没有问题，根据调测发现是外置Tomcat场景onStartup方法执行早于customize，导致factory对象还未初始化。
","> 提供两个思路
> 1、切面重写RestServletInitializer.startip方法；
> 2、不去引用spring-boot2-starter-servlet，而是将其中依赖copy，重新实现RestServletInitializer

我之前就是这么规避的，新版本已经修复了，不用折腾了",91674936
338,expected: .TooLongFrameException but was :io.vertx.core.VertxException,open,2019-11-28T12:20:44Z,2019-12-04T01:13:44Z,,NONE,"![image](https://user-images.githubusercontent.com/7249331/69805579-eabea100-121b-11ea-9c8a-44ba76293a56.png)

![image](https://user-images.githubusercontent.com/7249331/69805608-f5793600-121b-11ea-96a1-ddcb081a6564.png)

![image](https://user-images.githubusercontent.com/7249331/69805616-fb6f1700-121b-11ea-8dd3-8a135a2460e7.png)

![image](https://user-images.githubusercontent.com/7249331/69805649-0a55c980-121c-11ea-9d50-aa5df3f53b8d.png)

这里我跑it-consumer过不了，我发现在类  /transports/transport-rest/transport-rest-client/src/main/java/org/apache/servicecomb/transport/rest/client/http/RestClientInvocation.java处理后
本来是class io.netty.handler.codec.TooLongFrameException错误，经过处理后连接断开，变成了class io.vertx.core.VertxException错误，最后断言判断错误不匹配，不知道我的理解对不对？
","我在arm64上构建，有什么需要特别注意的设置吗？ 执行命令 ：
mvn clean install -B -Pdocker -Pjacoco -Pit",91674936
339,对接 Nacos  配置中心,open,2019-10-17T01:55:30Z,2019-12-02T02:20:31Z,,NONE,"nacos的动态配置服务让您能够以中心化、外部化和动态化的方式管理所有环境的配置。动态配置消除了配置变更时重新部署应用和服务的需要。配置中心化管理让实现无状态服务更简单，也让按需弹性扩展服务更容易。
能否提供java-chassis对接Nacos的配置中心的demo?","> Sorry，I add some new file in config-nacos model，the new pr is :#1405

Thanks. You can add more commits to the PR if you find something wrong and github will help to integrate new commits to the same PR :-)",91674936
340,Can not close file when upload file body without the end delimiter,open,2019-10-15T02:43:30Z,2019-11-26T04:00:01Z,,NONE,"**Step:**
1. use edge service to route REST url request, use class org.apache.servicecomb.transport.rest.vertx.RestBodyHandler to parse request body,including files.
2. server has a REST interface, like Content-Type: multipart/form-data, accept file(s).
3. send a post request to the file upload REST, and use proxy tool to modify the request raw.
use the latest version.

**For example:**
[Normal]
> POST /url/ HTTP/1.x
xxxxxx
Content-Type: multipart/form-data; boundary=--------1122334455
xxxxxx
--------1122334455
...file...
--------1122334455
...file...
--------1122334455--

[Abnormal]
> POST /url/ HTTP/1.x
xxxxxx
Content-Type: multipart/form-data; boundary=--------1122334455
xxxxxx
--------1122334455
...file...
--------1122334455
...file...

Use abnormal body to request, it will be wating to timeout.
I find the NettyFileUpload#addContent param-last is false, it will not into if branch to execute end() method, so the file will not close in endHandler after open by HttpServerFileUploadImpl#streamToFileSystem.
Is there an elegant way to solve this problem?",We have update netty(4.1.43.RELEASE) and vert.x(3.8.3) to the lasted version. But I am not sure if they solved this problem. Would you mind make your test with the lastest version?,91674936
341,controller 层无法使用@Validated注解，而只能使用@Valid注解，导致无法进行group分类，请问怎么解决？,open,2019-09-06T10:07:23Z,2019-10-08T01:28:08Z,,NONE,"public ApplicationResp update(@NotBlank @PathVariable(""project_id"") String projectId, @PathVariable long id,**@Validated** @RequestBody ApplicationReq appReq)",,91674936
342,缺少默认的xml返回值的ProduceProcessor,open,2019-08-19T08:41:25Z,2019-10-31T08:43:21Z,,NONE,"能否默认支持xml的返回值？
当前的ProduceProcessor只有ProduceJsonProcessor、ProduceTextPlainProcessor。",,91674936
343,trust-sample在指定场景出现java.lang.NullPointerException: null,open,2019-07-04T02:21:47Z,2019-07-22T02:06:22Z,,NONE,我在尝试运行trust-sample成功后，关停sc（本地），短时间内进行consumer端调用store成功，但是在经过12小时后进行调用会报错，java.lang.NullPointerException: null，message会报Internal Server Error,问题定位在AccessController.java:99，怀疑是在进行isAllowed判断时没有验证microservice是否为空产生的报错，但问题关键在于此类场景怎么保证服务可以正常调用。,91674936
344,About RuleNameExtentionsFactory spell error,open,2019-05-29T06:24:39Z,2019-07-01T03:02:54Z,,NONE,"Different spells:

org.apache.servicecomb.loadbalance.ExtensionsFactory
org.apache.servicecomb.loadbalance.RuleNameExtentionsFactory
org.apache.servicecomb.loadbalance.DefaultRetryExtensionsFactory

wrong:
public class RuleNameExtentionsFactory implements ExtensionsFactory

I think “Extensions” is better than “Extentions”

RuleNameExtentionsFactory =\> RuleNameExtensionsFactory ",,91674936
345,ServerRestArgsFilter可能提前返回响应，导致后面的Filter无效,open,2019-05-08T02:51:20Z,2020-02-25T02:55:08Z,,NONE,"问题描述：

org.apache.servicecomb.common.rest.filter.inner.ServerRestArgsFilter#beforeSendResponseAsync

当Object body = response.getResult();是Part类型的时候，导致响应提前返回，

从而后面的Filter滞后执行，而导致可能的错误。（比如增加Header的逻辑，就没有用了）

```
if (Part.class.isInstance(body)) {
            return responseEx.sendPart((Part)body);
        }
```



",写流的操作 应该放在filter全部执行完之后吧。,91674936
346,IllegalArgumentException at ConfigurationSpringInitializer#getProperties ,open,2019-03-19T01:39:15Z,2019-03-21T06:26:03Z,,NONE,"Method of ConfigurationSpringInitializer#getProperties with environment.getProperty(propertyName) throw an IllegalArgumentException

Suggest to modify setEnvironment around this.getAllProperties(environment) , setIgnoreUnresolvableNestedPlaceholders as true！


Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'ip' in value ""jdbc:postgresql://${ip}:${port}/pt""
	at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:174) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:126) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:236) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:210) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.springframework.core.env.AbstractPropertyResolver.resolveNestedPlaceholders(AbstractPropertyResolver.java:227) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.springframework.core.env.PropertySourcesPropertyResolver.getProperty(PropertySourcesPropertyResolver.java:84) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.springframework.core.env.PropertySourcesPropertyResolver.getProperty(PropertySourcesPropertyResolver.java:61) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.springframework.core.env.AbstractEnvironment.getProperty(AbstractEnvironment.java:531) ~[spring-core-4.3.22.RELEASE.jar:4.3.22.RELEASE]
	at org.apache.servicecomb.config.ConfigurationSpringInitializer.getProperties(ConfigurationSpringInitializer.java:141) ~[foundation-config-1.1.0.jar:1.1.0]
","explanation above issue：
 There are some placeholders that cannot be replaced during the startup phase.（eg：`jdbc:postgresql://${ip}:${port}/pt`, database  endpoint can only be obtained from the service center after service registration）  

`ConfigurationSpringInitializer#setEnvironment(Environment)` will be invoked automatic (for `implements EnvironmentAware`) after bean created&Initialized，then call stack is as follows：
```java
ConfigurationSpringInitializer#setEnvironment(...)
ConfigurationSpringInitializer#getAllProperties(...)
ConfigurationSpringInitializer#getProperties(...)
AbstractEnvironment#getProperty(...)
......
```
at `AbstractPropertyResolver#resolveNestedPlaceholders`  used `AbstractEnvironment#propertyResolver`(**not** ConfigurationSpringInitializer ) to  resolve placeholder; although `ConfigurationSpringInitializer   extends PropertyPlaceholderConfigurer` & `ignoreUnresolvablePlaceholders=true` and can be used to replace placeholders and not throw exceptions",91674936
347,What about to support zipkin tracing in spring-cloud-gateway in java-chassis?,open,2019-03-04T06:43:49Z,2019-03-14T04:27:42Z,,CONTRIBUTOR,"As we known, when users using spring-cloud-gateway in java-chassis, they cannot tracing the gateway service.
And I have find that tracing zuul in java-chassis has been supported, so I am going to support tracing spring-cloud-gateway in java-chassis.

Any other thoughts?","as we discussed before, gateway(zuul/springcloud gateway) no need to add servicecomb logic, just use zipkin modules for them directly

after that, zuul/springcloud gateway will forward request to internal microservice with zipkin http headers, internal microservice enable handler-tracing-zipkin to inherit zipkin data from header to CseContext.
maybe this can work.",91674936
348,Suggestion : API for kotlin coroutines,open,2018-10-01T16:50:42Z,2019-01-11T06:22:40Z,,NONE,"Some new project using kotlin as a better Java. kotlin coroutines make none-blocking programing easier.

Vert.x provide coroutines API : https://vertx.io/docs/vertx-lang-kotlin-coroutines/kotlin/

kotlin also provide kotlinx-coroutines-reactive and  kotlinx-coroutines-reactor to integrate with Spring Reactor.

I think Kotlin have great potential in server programming, so you guys may think about provide kotlin coroutine integration in your roadmap. :)
",,91674936
349,Suggestion: Ringpop like loadbalance,open,2018-10-01T16:42:19Z,2019-02-18T08:09:15Z,,NONE,"For most scenarios, round-robin load-balance is good enough.

But in our project, sometimes round-robin is not the best choice.

1. every instance of micro-service maintains a data zone by keys. especially using in-memory cache. Using round-robin, every instance may maintains all data.

2. every micro-service may have many instances. Using round-robin, may case m * n connection network.

These scenarios can reference to Uber's Ringpop micro-service model.  

1. Instances of a micro-service construct a consistence hash ring 
2. Each instance maintains a piece of data by specified key.
3. Random select three instance deal with the request from client, so no m * n connections.

  ",,91674936
350,Suggestion: provide mechanism to deal with chunked mode and multipart request,open,2018-10-01T15:43:42Z,2019-01-11T06:23:29Z,,NONE,"Now service comb only provide rest api for deal with the whole http request body.

But in some scenarios, save whole body in memory is not an effective way. 

Servicecomb only support using multipart request to upload files but can not process other scenarios.

I hope servicecomb can provide call-back mechanism to deal with chunked message and multipart requests.

for example, see the Amazon Alexa AVS API.

https://developer.amazon.com/zh/docs/alexa-voice-service/structure-http2-request.html ","Additional info, we hope servicecomb can also support chunked response and http/2 frames. In some scenarios, we can't construct a whole response before we send back. For example  : http/2 half-closed down channel stream as link above about alexa AVS API.",91674936
351,Suggestion : provide executeBlocking mechanism,open,2018-10-01T15:34:57Z,2019-01-11T06:24:21Z,,NONE,"In our project, we using reactive mode to gain high performance in high concurrency scenarios.  But sometimes we had using a few legacy Blocking API. 

So we need to using executor's executeBlocking to running these blocking code. but with this raw vert.x API, blocking code lost the InvocationContext. we need to using ugly wrapper to passing InvocationContext, traceId, etc , just like following : 

public class TraceUtils <T> {
	public static <T> Handler<T> traceable (Handler<T> fromHandler) {
		String traceId = MDC.get(MDC.TRACE_ID_KEY);
		return T -> {
			MDC.put (MDC.TRACE_ID_KEY, traceId);
			fromHandler.handle(T);
		};
	}
}  

If servicecomb provide similar executingBlocking API, and passing the InvocationContext. it would be helpful. we can using InvocationContext the pass the context variable like traceId.

",,91674936
352,Suggestion : multiple rest service endpoint.,open,2018-10-01T15:16:08Z,2019-01-11T06:25:08Z,,NONE,"I think servicecomb need to provide multiple service endpoint for different port.

for example,  I need provide a service for dealing with the requests from internet. In the same time, I also need to provide a service for dealing with the requests from other micro-services in intranet.

For security, authentication and other reason, we had to listen different port to provide two or more services.

We now implement micro-service for internal micro-services, and implement   service for internal using raw vert.x API. we implement a home-made transport.  in the init function, we using vertx instance created by servicecomb to do our own initializations.

",,91674936
353,servicecomb的动态配置模块不支持apollo配置中心的多namespace配置,open,2018-08-07T09:12:02Z,2019-01-11T06:30:28Z,,NONE,如题，servicecomb的动态配置模块不支持apollo配置中心的多namespace配置，建议支持,,91674936
354,关于servicecomb 的一些建议,open,2018-07-31T08:49:50Z,2019-01-11T06:31:23Z,,NONE,"servicecomb其他方面都挺好.就配置中心不能理解,既然选择了apollo为什么还要在搞个模块在项目里面呢.而且目前的实现还有问题.
apollo本身对spring的兼容性非常好,而且社区也很活跃,为什么不让用户自己选择集成apollo.

实际上,当我引入了apollo官方自己的client去掉了servicecomb-config的依赖后,一切问题都解决了.
包括:
     不支持多namespace
     和sb的一些注解不兼容,导致 初始化无法读取配置信息","1 核心依赖版本低
2不兼容sb2.0,我尝试过升级，启动报错。因为sb2.0的spring是5.x而servicecomb底层依赖spring4.x，5.x有个类删除了，启动报错。
3如果不用servicecomb config单纯用apollo client会不会存在一些问题？",91674936
355,PHP 7.4 tests failed because of goaop/parser-reflection,open,2020-03-08T12:16:03Z,2020-03-08T12:16:03Z,,NONE,"I'm really new to AOP and this framework. And just tried. The tests failed with the following:
```
Go\Core\AdviceMatcherTest::testGetSinglePropertyAdviceForClassFromAdvisor
Declaration of Go\ParserReflection\Traits\InitializationTrait::isInitialized() should be compatible with ReflectionProperty::isInitialized($object = NULL)
```
Would these [changes](https://github.com/yaroslavche/parser-reflection/commit/b072e4072d47431bfa025fa36b3e8ea86440c2cc) break other things?

Also in `tests/Go/Proxy/Part/FunctionCallArgumentListGeneratorTest.php:45`
expects
```
['pack', '[$format], $args']
```
but seems it should be
```
['pack', '\array_slice([$format], 0, \func_num_args()), $args']
```
When this changed, tests passed with PHP 7.4. But I can’t check other versions, for unknown reasons I can’t run the travis build in my fork",,1416156
356,Function ReflectionType::__toString() is deprecated,open,2020-01-09T09:33:25Z,2020-02-04T07:59:56Z,,NONE,"Running on PHP 7.4, this line throws exception:
https://github.com/goaop/framework/blob/b39293743d69722d9bb557804d29bf1315d73e79/src/Proxy/ClassProxyGenerator.php#L233
We should replace the string casting with the getName() method on ReflectionType, or make sure we use the overloaded ReflectionType from goaop/parser-reflection library","Yes, it would be nice to move to new method to prevent deprecation errors.",1416156
357,New release with the latest goodies,open,2019-11-25T16:52:17Z,2019-12-05T09:28:07Z,,NONE,I'm especially interested in https://github.com/goaop/framework/pull/412,"I use it in a phpunit extension which i haven't open sourced (yet).

I'd have many more use cases for this project if phpunit used autoloading to load test cases ;)",1416156
358,SelfValueVisitor throws exception on parsing class without namespace,open,2019-05-31T10:12:17Z,2019-05-31T11:53:56Z,,NONE,"Error message:

> Call to a member function toString() on null in vendor/goaop/framework/src/Instrument/Transformer/SelfValueVisitor.php:72

```
    public function enterNode(Node $node)
    {
        if ($node instanceof Stmt\Namespace_) {
            $this->namespace = $node->name->toString();
```

`$node->name` is null in a class without namespace.","Yeah, the goaop/framework version is 2.3.1 and the PHP version is 7.1.23.

More details about the exception stack trace:
```
Stack trace:
#0 vendor/nikic/php-parser/lib/PhpParser/NodeTraverser.php(200): Go\Instrument\Transformer\SelfValueVisitor->enterNode(Object(PhpParser\Node\Stmt\Namespace_))
#1 vendor/nikic/php-parser/lib/PhpParser/NodeTraverser.php(91): PhpParser\NodeTraverser->traverseArray(Array)
#2 vendor/goaop/framework/src/Instrument/Transformer/SelfValueTransformer.php(32): PhpParser\NodeTraverser->traverse(Array)
#3 vendor/goaop/framework/src/Instrument/Transformer/CachingTransformer.php(121): Go\Instrument\Transformer\SelfValueTransformer->transform(Object(Go\Instrument\Transformer\StreamMetaData))
```

I simplify my project as below:

annotation/test.php
```
<?php
namespace AopTest;
use Doctrine\Common\Annotations\Annotation;
/**
 * Pointcut annotation.
 * @Annotation
 * @Target(""METHOD"")
 */
class Test extends Annotation {
}
```

aspect/test.php
```
<?php
use Go\Aop\Intercept\MethodInvocation;
use Go\Lang\Annotation\Around;

/**
 * Test Aspect
 */
class AspectTest implements \Go\Aop\Aspect {
    /**
     * @Around(""@execution(AopTest\Test)"")
     */
    public function aroundTest(MethodInvocation $invocation) {
        echo ""Before around<br/>"";
        $res = $invocation->proceed();
        echo ""After around<br/>"";
        return $res;
    }
}
```
service/profit/test.php
```
<?php
use AopTest\Test;
/**
 * Example class to test aspects
 */
class ServiceProfitTest {
    /**
     * @Test
     */
    public function test()
    {
        echo ""Test Result<br/>"";
    }
}
```
aop_kernel.php
```
<?php
require_once (DIR_APPLICATION.""aspect/test.php"");
use Go\Core\AspectKernel;
use Go\Core\AspectContainer;

/**
 * Application Aspect Kernel
 */
class AopKernel extends AspectKernel {
    protected function configureAop(AspectContainer $container) {
        $container->registerAspect(new AspectTest());
    }
}
```
index.php
```
// codes about initing the aspect kernel
$aop_kernel = AopKernel::getInstance();
$aop_kernel->init(array(
    'debug' => true,
    // Cache directory
    'cacheDir' => DIR_CACHE,
    'includePaths' => array(
        DIR_APPLICATION . 'service/'
    ),
    'excludePaths' => array(
        DIR_ROOT . 'vendor/',
        DIR_APPLICATION . 'aspect/',
    ),
));
```
And then I load and invoke the `ServiceProfitTest::test` method in a controller method.
```
    public function someControllerMethod() { 
        $this->load->service(""profit/test"");
        $this->service_profit_test->test();
    }
```
The `$this->load->service` above is the loader in my project which maintains the mapping of file name and class name. More detail is as below:
 ```
public function service($service, $data = array()) {
        $file = DIR_APPLICATION . 'service/' . $service . '.php';
        $class = 'Service' . preg_replace('/[^a-zA-Z0-9]/', '', $service);

        if (file_exists($file)) {
            // $this->classloader is the Composer\Autoload\ClassLoader instance
            if(empty($this->classloader)) {
                // regular route
                include_once($file);
            } else {
                // hack to make goaop work
                $this->classloader->addClassMap(array(
                    $class => $file,
                ));
            }
            $this->registry->set('service_' . str_replace('/', '_', $service), new $class($this->registry));
        } else {
            trigger_error('Error: Could not load service ' . $file . '!');
            exit();
        }
    }
```

It would throws an exception if the class `ServiceProfitTest` dose not has a namespace. And it would be OK if I add a namespace for the `ServiceProfitTest`.

It is OK if I do some check in the SelfValueVisitor::enterNode method as below:
```
public function enterNode(Node $node)
    {
        if ($node instanceof Stmt\Namespace_) {
            $this->namespace = $node->name->toString();
            if(!empty($node->name)) {
                $this->namespace = $node->name->toString();
            }
```",1416156
359,[Known-issue] No access to annotations from a parent method in children classes,open,2017-12-19T13:57:53Z,2019-05-13T08:46:02Z,,CONTRIBUTOR,"Consider example:

---------- file A.php ------------

    use Some\Annotation as Annotation;

    abstract class A {
        /**
         * @Annotation\Cacheable()
         */
        public foo () {}
    }

---------- file B.php ------------

    abstract class B extends A {}

We define our pointcut to target every public method annotated with annotation `\Some\Annotation\Cacheable`

Class A will get weaved, class B will get weaved as well. Exception will occur on class B since:
1. method `foo()` will be defined and weaved in class B as well because of A and pointcut
2. method `foo()` in weaved B will get docblock comment from `foo()` from A (`@Annotation\Cacheable()`)

Exception will be thrown because `@Annotation\Cacheable()` is not imported into weaved B.

This is easy to reproduce.

Fix is easy - instead of using class aliases for docblock annotations, in process of compiling classes and creating proxies, for all annotations FQCN should be used, eg, instead of `@Annotation\Cacheable()` -> write `@Some\Annotation\Cacheable()`


",Mark this as `known-issue` for now. It's unlikely that it used by developers very often.,1416156
360,[Known-issue] Doctrine entities could not be woven ,open,2017-07-07T21:33:35Z,2019-05-13T08:35:39Z,,CONTRIBUTOR,"Doctrine entities can not be weaved - class metadata gets all messed up.

Engine generates `Entity__AopProxied`, which is copy of original class, and then generates class `Entity` that extends `Entity__AopProxied` and contains weaved methods/properties.

Issue is that `Entity__AopProxied` contains doctrine metadata, so Doctrine actually generates such metadata that `Entity__AopProxied` is main class and every relation is bound to that class, not `Entity`.

Side effects are that, per example, table name gets suffix ""__aop_proixed"", while relations gets all screwed up, so any join is broken because different aliases are generated with SQL walker. Lazy loading does not work as well.

Possible solution would be (in order to preserve BC compatibility) to provide possibility to specify different method of weaving for certain classes. Per example, in this case, in order to work as it should, `Entity__AopProxied` should not be generated and inherited, it should be generated only `Entity` class.

Yes, maybe we will loose nice debugging and breakpoints, however, for now, we can sacrifice that for working code.

 

","Thanks @lisachenko !

It works fine this way :) And I can live with the fact of not having execution traces on the entities methods :)",1416156
361,Uncaught Error: Class 'Doctrine\Common\Annotations\AnnotationReader' not found,open,2016-06-16T18:58:34Z,2017-07-06T14:27:26Z,,NONE,"Hello, I'm trying to use Go in a project, but it's crashing out of the box. It seems strange to me because I would think a crash this basic would affect more people. Perhaps it's my environment. I added some print debugging to the composer ClassLoader and the AopComposerLoader. As you can see it successfully locates the files on disk and includes them, but in the case of the doctrine AnnotationReader it tries to apply the go.source.transforming.loader filter and crashes the program.

`Searching for class Symfony\Component\Console\Application with extension .php
        File path before rewrite:
                /root/git/project/vendor/composer/../symfony/console/Application.php
        File path after rewrite:
                php://filter/read=go.source.transforming.loader/resource=/root/git/project/vendor/composer/../symfony/console/Application.php
Searching for class Go\Instrument\Transformer\StreamMetaData with extension .php
        File path before rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Instrument/Transformer/StreamMetaData.php
        File path after rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Instrument/Transformer/StreamMetaData.php
        Including /root/git/project/vendor/composer/../goaop/framework/src/Instrument/Transformer/StreamMetaData.php
Searching for class Go\Instrument\Transformer\WeavingTransformer with extension .php
        File path before rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Instrument/Transformer/WeavingTransformer.php
        File path after rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Instrument/Transformer/WeavingTransformer.php
        Including /root/git/project/vendor/composer/../goaop/framework/src/Instrument/Transformer/WeavingTransformer.php
Searching for class Go\Core\AdviceMatcher with extension .php
        File path before rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Core/AdviceMatcher.php
        File path after rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Core/AdviceMatcher.php
        Including /root/git/project/vendor/composer/../goaop/framework/src/Core/AdviceMatcher.php
Searching for class Go\Core\AspectLoader with extension .php
        File path before rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Core/AspectLoader.php
        File path after rewrite:
                /root/git/project/vendor/composer/../goaop/framework/src/Core/AspectLoader.php
        Including /root/git/project/vendor/composer/../goaop/framework/src/Core/AspectLoader.php
Searching for class Doctrine\Common\Annotations\AnnotationReader with extension .php
        File path before rewrite:
                /root/git/project/vendor/composer/../doctrine/annotations/lib/Doctrine/Common/Annotations/AnnotationReader.php
        File path after rewrite:
                php://filter/read=go.source.transforming.loader/resource=/root/git/project/vendor/composer/../doctrine/annotations/lib/Doctrine/Common/Annotations/AnnotationReader.php
PHP Fatal error:  Uncaught Error: Class 'Doctrine\Common\Annotations\AnnotationReader' not found in /root/git/project/vendor/goaop/framework/src/Core/GoAspectContainer.php:88
Stack trace:
#0 /root/git/project/vendor/goaop/framework/src/Core/Container.php(65): Go\Core\GoAspectContainer->Go\Core{closure}(Object(Go\Core\GoAspectContainer))
#1 /root/git/project/vendor/goaop/framework/src/Core/Container.php(87): Go\Core\Container->Go\Core{closure}(Object(Go\Core\GoAspectContainer))
#2 /root/git/project/vendor/goaop/framework/src/Core/GoAspectContainer.php(50): Go\Core\Container->get('aspect.annotati...')
#3 /root/git/project/vendor/goaop/framework/src/Core/Container.php(65): Go\Core\GoAspectContainer->Go\Core{closure}(Object(Go\Core\GoAspectContainer))
#4 /root/git/project/vendor/goaop/framework/src/Core/Container.php(87): Go\Core\Container->Go\Core{closure}(Object(Go\Core\GoAspectContainer))
#5 /root/git/project/vendor/goaop/framework/src/Core/GoAspectContai in /root/git/project/vendor/goaop/framework/src/Core/GoAspectContainer.php on line 88`
","@lisachenko 
Might be small question am not finding that how you are relating annotations with aspect.. am trying to create custom annotation with aspect. I just followed following article 
http://go.aopphp.com/blog/2013/07/21/implementing-logging-aspect-with-doctrine-annotations/

Am using yii2",1416156
362,[Feature][Long-Term] Interception of methods in the internal PHP classes,open,2014-12-02T11:10:00Z,2020-02-04T08:56:55Z,,MEMBER,"Interception of methods in the internal PHP classes is the most complex one, however, it is required for special cases, for example, to intercept `mysql->query()` invocation:

``` php
class MysqliQueryOperationCollectionAspect implements Aspect {

    /**
     * @param MethodInvocation $invocation Invocation
     * @Around(execution(public mysqli->query(*))
     * @return mixed
     */
    public function aroundQueryMethod(MethodInvocation $invocation) {
        $method = $invocation->getMethod();
        $args = $invocation->getArguments();
        $query = $args[1];
        if ($this->logger->isTraceEnabled()) {
            $this->logger->trace($method->getName().'('.$query.')');
        }

        try {
            $result = $invocation->proceed();
            return $result;
        } catch(Exception $e) {
            if ($this->logger->isTraceEnabled()) {
                $this->logger->trace($method->getName().'('.$query.') '.get_class($e).':' .$e->getMessage());
            }
            throw $e;
        }
    }
}
```
",@lisachenko Thank you so much for the quick response. I hope version  4 will be available soon ,1416156
363,Thoughts and feedback about AOP,open,2014-07-08T11:50:06Z,2020-02-12T20:03:00Z,,MEMBER,"If you are using an AOP or have a plan to use it, please add a small comment here or just put a +1 ) I will be happy to see that this technique can be useful for you ) 
You can also provide an additional information about the usage (how you use it and where). I can put this information later on my site with hyper-link to your solution.
","@Ocramius :+1:
",1416156
364,[Known-issue]Conflict with JMSExtraSecurity bundle,open,2012-12-18T06:09:36Z,2019-05-13T08:36:23Z,,MEMBER,"JMSExtraSecurity bundle verifies that secure annotation is copied to overridden method from the parent method annotation and @SatisfiesParentSecurityPolicy annotation is added to the child class.
",,1416156
365,[feature request] - check DNS record before requesting/refreshing LE certificate,open,2020-03-09T09:53:52Z,2020-03-09T20:28:19Z,,NONE,"# Summary
LE refresh is not checking if domain is on the server anymore. In my case a customer enables LE for an domain which he changed to another IP-address a few months later via DSN-editor - so LE can't find the acme-challenge in FROXLORs host because damian was already redirectet to  another machine via DNS.
As result my whole server was blocket from LE because of a lot of faulty requests.


# System information
* Froxlor version: 0.10.15
* Web server: apache2
* DNS server: Bind
* OS/Version: Debian 10


# Steps to reproduce
1. enable LE for an (sub-)domain (e.g. www.example.com)
2. change A-record of these (sub-)domain (e.g. www.example.com) to another server
3. wait for or try to refresh the LE certificate for this (sub-)domain


# Expected behavior
Don't run LE refresehs (and also requests?) for domains where DNS points to another IP-address.


# Actual behavior
LE refresehs (and also requests?) were startet every cron run.
","If DNS is correct and froxlor is setup correctly then the DNS check will be sufficient because the rest surely works. Of course we can also create a random file to the acme-challenge directory, effect is the same imho ",3639119
366,acme.sh Please specify at least one validation method.,open,2020-03-08T19:18:29Z,2020-03-09T11:04:27Z,,CONTRIBUTOR,"# Summary

SSL certs do not update since one of the last updates.

# System information
* Froxlor version: 0.10.15 (DB: 202002290), but also on 0.10.12.
* Web server: apache2:amd64/stable 2.4.38-3+deb10u3
* DNS server: bind9:amd64/stable 1:9.11.5.P4+dfsg-5.1
* POP/IMAP server: not on this server
* SMTP server: not on this server
* FTP server: ---
* OS/Version: Debian GNU/Linux 10 (buster)

# Steps to reproduce

1. Enable SSL.

# Expected behavior

1. Certificate updates

# Actual behavior

1. Certificate does not update

# Log files/log entries
<pre>
[information] Requesting/renewing Let's Encrypt certificates
[information] Updating certificate for domain.tld
[information] Adding SAN entry: domain.tld
[information] Adding SAN entry: www.domain.tld
[information] Checking for LetsEncrypt client upgrades before renewing certificates:
[Sun 08 Mar 2020 07:55:10 PM CET] Already uptodate!
[Sun 08 Mar 2020 07:55:10 PM CET] Upgrade success!
[Sun 08 Mar 2020 07:55:10 PM CET] Removing cron job
[Sun 08 Mar 2020 07:55:10 PM CET] Lets find script dir.
[Sun 08 Mar 2020 07:55:10 PM CET] _SCRIPT_='/root/.acme.sh/acme.sh'
[Sun 08 Mar 2020 07:55:10 PM CET] _script='/root/.acme.sh/acme.sh'
[Sun 08 Mar 2020 07:55:10 PM CET] _script_home='/root/.acme.sh'
[Sun 08 Mar 2020 07:55:10 PM CET] Using config home:/root/.acme.sh
[Sun 08 Mar 2020 07:55:10 PM CET] Using server: https://acme-v02.api.letsencrypt.org/directory
[Sun 08 Mar 2020 07:55:10 PM CET] Running cmd: renew
[Sun 08 Mar 2020 07:55:10 PM CET] Using config home:/root/.acme.sh
[Sun 08 Mar 2020 07:55:10 PM CET] ACME_DIRECTORY='https://acme-v02.api.letsencrypt.org/directory'
[Sun 08 Mar 2020 07:55:10 PM CET] DOMAIN_PATH='/root/.acme.sh/domain.tld'
[Sun 08 Mar 2020 07:55:10 PM CET] Le_API
Please specify at least one validation method: '--webroot', '--standalone', '--apache', '--nginx' or '--dns' etc.
[debug] https://github.com/acmesh-official/acme.sh
v2.8.6
[Sun 08 Mar 2020 07:55:10 PM CET] Renew: 'domain.tld'
[information] Updated Let's Encrypt certificate for domain.tld
[information] Updating certificate for domain.tld
[information] Adding SAN entry: domain.tld
[information] Adding SAN entry: www.domain.tld
[Sun 08 Mar 2020 07:55:10 PM CET] Lets find script dir.
[Sun 08 Mar 2020 07:55:10 PM CET] _SCRIPT_='/root/.acme.sh/acme.sh'
[Sun 08 Mar 2020 07:55:10 PM CET] _script='/root/.acme.sh/acme.sh'
[Sun 08 Mar 2020 07:55:10 PM CET] _script_home='/root/.acme.sh'
[Sun 08 Mar 2020 07:55:10 PM CET] Using config home:/root/.acme.sh
[Sun 08 Mar 2020 07:55:10 PM CET] Using server: https://acme-v02.api.letsencrypt.org/directory
[Sun 08 Mar 2020 07:55:10 PM CET] Running cmd: renew
[Sun 08 Mar 2020 07:55:10 PM CET] Using config home:/root/.acme.sh
[Sun 08 Mar 2020 07:55:10 PM CET] ACME_DIRECTORY='https://acme-v02.api.letsencrypt.org/directory'
[Sun 08 Mar 2020 07:55:10 PM CET] DOMAIN_PATH='/root/.acme.sh/domain.tld'
[Sun 08 Mar 2020 07:55:10 PM CET] Le_API
Please specify at least one validation method: '--webroot', '--standalone', '--apache', '--nginx' or '--dns' etc.
[debug] https://github.com/acmesh-official/acme.sh
v2.8.6
[Sun 08 Mar 2020 07:55:10 PM CET] Renew: 'domain.tld'
[information] Updated Let's Encrypt certificate for domain.tld
</pre>
","> > No, I checked that already. I might have in the past for this specific domain, but this is long undone and set to none/0 in the db.
> 
> Manual edits in the database are not intended. That way froxlor does not know about these changes and does not trigger these changes.

Yes, I know about that too, but these changes must have been done via the UI, because my clients do not have access to the database.

> > I only said it also did not work in 0.10.12. This is a fact.
> 
> Did for me. Fact.

That is great for you, and as I said the majority of my domains works just fine too. I just want to remark again, that this problem which for some reason prevented the certificate update already existed in 0.10.12 and because lack of time to investigate, I had to generate the certificate externally, and use the custom certificate option in Froxlor to supply the generated certificate. I thought an update would fix it, but even the latest 0.10.15 that I installed yesterday did not solve this.

> 0.9.x used a totally different lets encrypt implementation, you are right. Again, without more details about domain settings, dns settings for that domain, possible existing files, etc. I can only say: this works for me on more than two servers

Well, I'm still trying to figure out what is different about those domains that do not work. I yet have no clue at all, because I can not find any differences to domains that work, which leads me to believe, that even those domains do not work due to some prior settings that have been changed since then.",3639119
367,Improvements,open,2020-03-06T20:48:23Z,2020-03-08T06:36:33Z,,NONE,"# Description

Please include a summary of the change and which issue is fixed if any. Please also include relevant motivation and context. List any dependencies that are required for this change.

Fixes # (issue)

## Type of change

Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Please describe the tests that you ran to verify your changes. Provide instructions so we can reproduce. Please also list any relevant details for your test configuration

- [ ] Test A
- [ ] Test B

**Test Configuration**:

* Distribution:
* Webserver:
* PHP:
* etc.etc.:

# Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes

","# [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/814?src=pr&el=h1) Report
> Merging [#814](https://codecov.io/gh/Froxlor/Froxlor/pull/814?src=pr&el=desc) into [master](https://codecov.io/gh/Froxlor/Froxlor/commit/62ce21c9ec393f9962515c88f0c489ace42bf656&el=desc) will **increase** coverage by `0.00%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/Froxlor/Froxlor/pull/814/graphs/tree.svg?width=650&height=150&src=pr&token=hB0x5LKvE9)](https://codecov.io/gh/Froxlor/Froxlor/pull/814?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master     #814   +/-   ##
=========================================
  Coverage     33.03%   33.03%           
  Complexity     5654     5654           
=========================================
  Files           107      107           
  Lines         15597    15598    +1     
=========================================
+ Hits           5152     5153    +1     
  Misses        10445    10445           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/814?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/814?src=pr&el=footer). Last update [62ce21c...97175c8](https://codecov.io/gh/Froxlor/Froxlor/pull/814?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",3639119
368,Storage engine MEMORY is disabled (Table creation is disallowed).,open,2020-03-05T16:48:54Z,2020-03-08T06:36:33Z,,NONE,"
# Summary

Please provide a concise summary of the problem you're experiencing...
While installing Froxlor using Mysql 8.0 with Digital Ocean Managed Database, get the following error.
![2020-03-05 12_43_35-Froxlor Server Management Panel - Installation](https://user-images.githubusercontent.com/8250019/76003881-13bb9580-5edf-11ea-82d0-ad9779d02a66.png)


From what I've read most cloud managed database providers don't allow ENGINE_MEMORY.

https://magento.stackexchange.com/questions/236316/install-fails-storage-engine-memory-is-disabled-table-creation-is-disallowed

# System information
* Froxlor version: latest
* Web server: nginx
*Mysql: 8.0.18 (Managed Digital Ocean)",[mysql] logs...?,3639119
369,Ubuntu 19.10 install is not supported,open,2020-03-04T16:20:34Z,2020-03-08T06:36:33Z,,NONE,"# Summary

Ubuntu 19.10 is not supported.

![image](https://user-images.githubusercontent.com/16578570/75899825-54160780-5e3c-11ea-9f6a-e3bec74731e4.png)


# System information

* OS/Version: ubuntu server 19.10

",we never supported non-lts tho,3639119
370,Gesamtspeicherplatz or Webspace,open,2020-03-03T12:18:38Z,2020-03-04T08:00:33Z,,NONE,"# Bug report

# Summary

First of call I'm using Froxlor with german language. So not sure if this applies to all languages.

I'm a bit confused by the storage consumption setup and I think there is at least a naming issue somewhere.
I have set for a customer/user:
Webspace (MiB): 10000
E-Mail-Kontingent (MiB) *: 25000

The customer dashboard now looks like this:
![image](https://user-images.githubusercontent.com/1312102/75774665-b691d980-5d50-11ea-8ae6-f1d184ff3b51.png)

The dashboard looks ok because it says ""Gesamtspeicherplatz"" vs ""Webspace"" but in the admin settings for that user it's called Webspace.
So I see two possibilities:
1. ""Gesamtspeicherplatz"" is set nowhere and should be calculated by Webspace+Mailquota
2. Webspace actually means ""Gesamtspeicherplatz"" and there is no dedicated setting for Webspace. Then the configuration should be renamed to Gesamtspeicherplatz instead of Webspace.

Could have been introduced by Issue #733 ?



# System information
* Froxlor version: 0.10.13
* Web server: apache2
* DNS server: PowerDNS
* POP/IMAP server: Dovecot
* SMTP server: postfix
* FTP server: proftpd

","Aah, the neverending story about webspace,mailspace,total space etc :)

Total = Web + Mail + MySQL

Mail-quota is not part of that. This only restricts the usage to a certain amount of diskspace. Relevant is what's used. So in your case,  webspace `112,613 MiB` + email accounts `10132,098 MiB` equals the `10244,711` of total disk usage (you don't seem to use mysql databases here, the would also be added to the total usage). Hence >100% usage. 

I see what might cause the confusing is that you can assign more mail-quota disk-space that you acutally have in webspace. That's due to the quota being ""virtual"". Like, you have 25000 MiB available to assign to accounts in total, the actually used diskspace is in ""email accounts""

The ""naming"" originated from earlier days. Customers mostly want to know: what diskspace can I use for my websites/applications/etc.; on the admins side, of course the customer also uses diskspace for his email-accounts and mysql-databases, that's why this is added to the usage of the customer. Maybe we can find a good explanation to add to the corresponding settings to avoid such confusion",3639119
371,feature request - duplicate domain,open,2020-02-20T14:25:06Z,2020-02-20T18:15:40Z,,NONE,"# Summary

would be nice to be able to duplicate domains so that the configurations could be copied.
","Basically, that could make sense for various entities ;) let's see what we can do",3639119
372,Verschiedene Mountpoints für Quota,open,2020-02-16T15:13:30Z,2020-02-16T15:20:17Z,,NONE,"Es wäre schön, wenn die Kundendaten nicht alle im selben Mountpoint liegen müssen.
Wünschenswert wären verschiedene Mountpoints für Web, Mail und Datenbank in den Einstellungen von Quota.",,3639119
373,Logging --force parameter,open,2020-02-04T17:46:42Z,2020-02-05T08:01:57Z,,CONTRIBUTOR,Logging --force parameter,"# [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/800?src=pr&el=h1) Report
> Merging [#800](https://codecov.io/gh/Froxlor/Froxlor/pull/800?src=pr&el=desc) into [master](https://codecov.io/gh/Froxlor/Froxlor/commit/734c02e33f9a0546a183b84636412d09f1bf2698?src=pr&el=desc) will **decrease** coverage by `<.01%`.
> The diff coverage is `0%`.

[![Impacted file tree graph](https://codecov.io/gh/Froxlor/Froxlor/pull/800/graphs/tree.svg?width=650&token=hB0x5LKvE9&height=150&src=pr)](https://codecov.io/gh/Froxlor/Froxlor/pull/800?src=pr&el=tree)

```diff
@@             Coverage Diff              @@
##             master     #800      +/-   ##
============================================
- Coverage     33.08%   33.08%   -0.01%     
  Complexity     5650     5650              
============================================
  Files           107      107              
  Lines         15565    15566       +1     
============================================
  Hits           5150     5150              
- Misses        10415    10416       +1
```


| [Impacted Files](https://codecov.io/gh/Froxlor/Froxlor/pull/800?src=pr&el=tree) | Coverage Δ | Complexity Δ | |
|---|---|---|---|
| [lib/Froxlor/Cron/MasterCron.php](https://codecov.io/gh/Froxlor/Froxlor/pull/800/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvQ3Jvbi9NYXN0ZXJDcm9uLnBocA==) | `0% <0%> (ø)` | `64 <0> (ø)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/800?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/800?src=pr&el=footer). Last update [734c02e...ae47995](https://codecov.io/gh/Froxlor/Froxlor/pull/800?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",3639119
374,FR: ECDSA AND RSA support,open,2020-02-01T20:24:43Z,2020-02-01T20:24:43Z,,CONTRIBUTOR,"This is a new GitHub issue referring to #651. While ECDSA is gaining more attraction and use in the web over time, it's still not supported everywhere. Therefore I'm honestly not that big fan of either RSA or ECDSA.

Most server services, including nginx and apache2, includes support for using RSA and ECDSA, depending on the support of the client. ECDSA is preferred, RSA used as an fallback.

Relevant parts:
- **nginx**: In case of nginx you can simply provide multiple `ssl_certificate` config settings, one to the RSA c ertificate and one to ECDSA certificate. Same for the private key. nginx takes care about the rest. (Apache2 handles it most likely the same)
- **Froxlor**: That might be the more interesting part. Most likely there should be a separated column called ""type"" or so, so either RSA or ECDSA in the end.

I'd really like having this support in Froxlor in the future :) Thanks for the amazing work!",,3639119
375,Acme.sh cronjob removal,open,2020-01-17T09:54:49Z,2020-03-08T06:36:33Z,,CONTRIBUTOR,"I was using acme.sh on my server even before Froxlor started using it but now Froxlor is breaking it by always removing the cronjob

https://github.com/Froxlor/Froxlor/blob/master/lib/Froxlor/Cron/Http/LetsEncrypt/AcmeSh.php#L429

This is really bad. Maybe Froxlor should keep its own copy of acme.sh and not mess with the installed one?","The whole process of either issue or renew has to be restructured. The current plan is to just mirror the generated certificate files in froxlors database (so the cronjob that generates vhosts and includes the certificates etc. does not need to be touched, same goes for the front-end page of certificates) and a ""renew"" is more like a ""check database content against file system content"" so that acme.sh can do what it is supposed to do",3639119
376,[Feature request] Ability to add columns in overview,open,2020-01-03T13:23:59Z,2020-01-03T14:19:22Z,,NONE,"# Feature Request

# Summary

* It would be great, if we manually can add/remove columns in the Customers/Domains overview.

For example:
* Customers overview: add the applyed hosting plan, Email and other fields.
* Domains overview: add the document root, separate logfile enabled, Emaildomain enabled, Only email? enabled and other fields.




# System information
* Froxlor version: 10.10




# Steps to reproduce

1. Open Froxlor and navigate to ""Ressources -> Customers"" or ""Ressources -> Domains""


# Expected behavior

1. Able to add/remove columns in the overview.




# Actual behavior

1. Not able to add/remove columns in the overview.


",Good idea for 0.11.x (new interface / template engine),3639119
377,"[Feature] Refacoring traffic and diskspace calculation to group stats per period, for example day",open,2019-12-08T09:52:55Z,2019-12-08T13:22:22Z,,NONE,"# Bug report vs. support request
If you're unsure of whether your problem is a bug or a configuration error
* contact us via IRC in #froxlor on freenode
* or post a thread in our forum at https://forum.froxlor.org

As a rule of thumb: before reporting an issue
* see if it hasn't been [reported](https://github.com/Froxlor/froxlor/issues) (and possibly already been [fixed](https://github.com/Froxlor/froxlor/issues?utf8=✓&q=is:issue%20is:closed)) first
* try with the git master





# Summary

If changing period to collect traffic and disk usage more than once a day, stats should be merged for example a day, or after a month to avoid huge amounts of usage records.



# System information
* Froxlor version: 0.10.9
* Web server: apache2
* DNS server: none
* POP/IMAP server: Dovecot
* SMTP server: postfix
* FTP server: proftpd
* OS/Version: Debian Buster, MySql 8.x




# Steps to reproduce

1. Set Consettings of traffic and disk usage for example to 5 Minutes
2. After a while 12 Months there many records in the tables
3. Open Customers, this will take long time




# Expected behavior

1. If setting cronsettings traffic and diskusage  to smaller values, ui is also fast as collecting much less traffic and disk usage stats
2. Traffic and customer are available within less than 1 second

# Actual behavior

1. Too many records in panel_traffic, panel_traffic_admins, panel_diskspace and disk_space_admins, made UI tab customers and traffic very slow (1-5 minutes)

",,3639119
378,[Feature Request] Add config instructions for DNS on CentOS/RHEL,open,2019-12-07T07:35:59Z,2019-12-10T09:28:34Z,,NONE,"# Feature Request

# Summary

* Would be nice to have DNS configuration instructions for CentOS/RHEL systems. 
* Debian/Ubuntu instructions can (mostly) be followed, if the correct paths for CentOS/RHEL are substituted/symlinked

# System information
* Froxlor version: 0.10.8
* Web server: apache2
* DNS server: Bind9
* POP/IMAP server: Dovecot
* SMTP server: postfix
* FTP server: proftpd
* OS/Version: CentOS Linux release 7.7.1908 (Core)

# Steps to reproduce

1. Install froxlor
2. Go to configuration->Cent/RHEL 7


# Expected behavior

1. Service config instructions for DNS

# Actual behavior

1. No service for Nameserver listed under Cent/RHEL 7

# Comment
* Intentionally have not updated to 0.10.9 as the system running 0.10.8 is being made production ready and cannot take an update right now (ensuring update will not negatively impact production; no separate test system available - yet)","Pull requests are welcomed, I don't know anyone using centos, the config templates for that are all community contributed",3639119
379,Add validation for special IP 0.0.0.0 and 0.0.0.0/0.0.0.0 + test,open,2019-11-26T14:49:18Z,2019-11-26T15:08:47Z,,CONTRIBUTOR,"# Description

IP validation sorts out any ""reserved"" IP. That's a good thing because we do not want e.g. to DHCP bind to broadcasts IPs. But there are some special cases that are filtered out by FILTER_FLAG_NO_RES_RANGE:

* Using 0.0.0.0 in ""Ports and IPs"" to create a Port listening on any IP
* Using 0.0.0.0/0.0.0.0 e.g. for MySQL to allow access to any IP

(Personally, I have only use case 1 but since It's quite similar, I added the other too).

## Type of change

Please delete options that are not relevant.

- [ ] Bug fix (non-breaking change which fixes an issue)
- [X] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

I have manually tested that creating a port with IP 0.0.0.0 works as expected. I have added Tests into ValidationTests for both use cases.

# Checklist:

- [x] I have performed a self-review of my own code
- [x] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
-> No idea where to document it exactly, it's just a minor fix/enhancement
- [?] My changes generate no new warnings
-> How to test?
- [x] I have added tests that prove my fix is effective or that my feature works
- [X] New and existing unit tests pass locally with my changes
",Allowing 0.0.0.0 as ip for domains will surely break DNS... ,3639119
380,[Feature Request] dns and web-based autodiscovery for mail and other services,open,2019-10-12T16:27:16Z,2019-10-12T16:52:32Z,,NONE,"# Summary

There are a few dns records that help clients to do auto discovery,eg, for mail, caldav, and carddav. It would be great if Froxlor would make sure that they are in the DNS zones.

For domains with email support:
* adding [rfc6186](https://tools.ietf.org/html/rfc6186) compatible records (This is related to #719 .)
* https://developer.mozilla.org/en-US/docs/Mozilla/Thunderbird/Autoconfiguration defines autoconfig.domain
* https://support.microsoft.com/en-us/help/3211279/outlook-2016-implementation-of-autodiscover defines _autodiscover._tcp.domain in step 10.
* The iOS feature would also be nice to have, see https://github.com/mailcow/mailcow-dockerized/blob/master/data/web/mobileconfig.php for an example.

Adding custom records to multiple domains managed by Froxlor would help too, eg, caldav, carddav see [rfc6764](https://tools.ietf.org/html/rfc6764)

Thanks",Customer can overwrite any entry via the dns editor if enabled already,3639119
381,[Feature Request] Allow customer to add/configure/remove domains,open,2019-10-12T15:52:12Z,2019-10-12T16:51:06Z,,NONE,"# Summary
Allow customers in Froxlor to add/configure/remove domains. (Not just subdomains as today.)

Pre-populate the zone configuration with sensible defaults for zone hosting, email, web and any combiation of them. 

Optional: Allow an easy integration with a domain registrar.

Thanks","> Sure: I meant sensible defaults for all values required to bridge the gap between admin-domain-add and customer-domain-add. - These of course need to be defined by the admin.

This means a lot of changes and additional settings, maybe in later versions",3639119
382,[Feature request]: SRV entry description in web interface,open,2019-10-01T09:45:06Z,2019-10-13T08:30:43Z,,NONE,"Hi all,

the SRV entry in the dns settings is a bit special.
Often a dns editor has special fields for this entry in the editor: port, weight, protocol, service
https://blog.contabo.de/tutorials/srv-records-wie-nutze-ich-sie-richtig/

Can you add this special fields in the editor. If it is not possible, can you add the description how to make a SRV entry not in the error message but as a message directly in the editor or when the entry type SRV is choosen?
An example for a right SRV entry would be great, too.",Setting milestone to 0.11.0 as it will introduce the new frontend and things like that will be way easier to implement,3639119
383,implementation DKIM using Amavis or OpenDKIM,open,2019-08-05T14:11:13Z,2020-02-01T08:58:28Z,,NONE,"...fully working now

working:
- creating DKIM keys 1024 / **2048** / 4096 and pusing to db
- creating config files for amavis or opendkim and writing to a user defined location
- writing all DKIM keys to a user defined location
- showing neccessary zonefile addidtions for external nameserver in admin-domain-edit
- creating zonefile for internal nameserver
- restarting services at changes
- translations german and english

not ready / 2do:
- creatind instructions how to configure amavis or DKIM for different distributions","# [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/708?src=pr&el=h1) Report
> Merging [#708](https://codecov.io/gh/Froxlor/Froxlor/pull/708?src=pr&el=desc) into [master](https://codecov.io/gh/Froxlor/Froxlor/commit/ad240166d993eb8eea5b63456ddded7a31e4eba9?src=pr&el=desc) will **increase** coverage by `0.32%`.
> The diff coverage is `49.31%`.

[![Impacted file tree graph](https://codecov.io/gh/Froxlor/Froxlor/pull/708/graphs/tree.svg?width=650&token=hB0x5LKvE9&height=150&src=pr)](https://codecov.io/gh/Froxlor/Froxlor/pull/708?src=pr&el=tree)

```diff
@@             Coverage Diff              @@
##             master     #708      +/-   ##
============================================
+ Coverage     32.78%   33.11%   +0.32%     
- Complexity     5643     5660      +17     
============================================
  Files           107      107              
  Lines         15568    15599      +31     
============================================
+ Hits           5104     5165      +61     
+ Misses        10464    10434      -30
```


| [Impacted Files](https://codecov.io/gh/Froxlor/Froxlor/pull/708?src=pr&el=tree) | Coverage Δ | Complexity Δ | |
|---|---|---|---|
| [lib/Froxlor/PhpHelper.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvUGhwSGVscGVyLnBocA==) | `0% <ø> (ø)` | `69 <0> (ø)` | :arrow_down: |
| [lib/Froxlor/Froxlor.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvRnJveGxvci5waHA=) | `21.42% <ø> (ø)` | `41 <0> (ø)` | :arrow_down: |
| [lib/Froxlor/Settings/FroxlorVhostSettings.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvU2V0dGluZ3MvRnJveGxvclZob3N0U2V0dGluZ3MucGhw) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |
| [lib/Froxlor/User.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvVXNlci5waHA=) | `0% <0%> (ø)` | `43 <0> (ø)` | :arrow_down: |
| [lib/Froxlor/FroxlorLogger.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvRnJveGxvckxvZ2dlci5waHA=) | `30.35% <0%> (-0.56%)` | `51 <0> (ø)` | |
| [lib/Froxlor/Dns/Dns.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvRG5zL0Rucy5waHA=) | `0% <0%> (ø)` | `107 <0> (+1)` | :arrow_up: |
| [lib/Froxlor/Cron/Http/Nginx.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvQ3Jvbi9IdHRwL05naW54LnBocA==) | `0% <0%> (ø)` | `267 <0> (ø)` | :arrow_down: |
| [lib/Froxlor/Cron/Http/Apache.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvQ3Jvbi9IdHRwL0FwYWNoZS5waHA=) | `0% <0%> (ø)` | `286 <0> (ø)` | :arrow_down: |
| [lib/Froxlor/Cron/Http/Php/Fpm.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvQ3Jvbi9IdHRwL1BocC9GcG0ucGhw) | `0% <0%> (ø)` | `51 <0> (+1)` | :arrow_up: |
| [lib/Froxlor/Http/Statistics.php](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvSHR0cC9TdGF0aXN0aWNzLnBocA==) | `0% <0%> (ø)` | `16 <0> (+1)` | :arrow_up: |
| ... and [17 more](https://codecov.io/gh/Froxlor/Froxlor/pull/708/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/708?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/708?src=pr&el=footer). Last update [ad24016...708acbd](https://codecov.io/gh/Froxlor/Froxlor/pull/708?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",3639119
384,[Feature request] Internal / Intranet Domains through VPN,open,2019-06-13T12:52:16Z,2019-06-13T13:13:47Z,,NONE,"Currently it is not possible to add VPN server IPs within froxlor to setup VPN / Intranet pages.
I understood, that this has been configured like that on purpose. Is there any specific reason to do so ? And is it planned to be supported in a new release?

Thanks in advance!","Yes - did so already - was just wondering of a specific reason - i can also notice some dns related issues which i am not really able to solve until know - but will have a deeper look to understand what is going on

Von meinem iPhone gesendet

> Am 13.06.2019 um 15:05 schrieb Michael Kaufmann <notifications@github.com>:
> 
> might break some parts of functionality, mostly dns related I'd say. There is nothing really planned as only few people use froxlor in such an environment. You COULD try forking the repository, enable private-network in the corresponding validations (see https://github.com/Froxlor/Froxlor/blob/master/lib/Froxlor/Validate/Validate.php#L84 which is the function to use for validation ips) and see if it breaks anything :)
> 
> Or simpler: just change the IP values directly in the table panel_ipsandports :P
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",3639119
385,* Make ftp quota related to used traffic instead of used disk space,open,2019-05-17T09:28:04Z,2019-05-18T06:19:05Z,,NONE,"# Description

Currently Froxlor calculates FTP quota based on disk space usage which is wrong. If we setup traffic (bandwidth) limit lower than disk space in current state then this prevents user from FTP usage. 

Fixes # (issue)

## Type of change

Please delete options that are not relevant.

- [x] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] This change requires a documentation update

# How Has This Been Tested?

Checking working instance after few days and current system calculation manually.

- [ ] Test A
- [ ] Test B

**Test Configuration**:

* Distribution:
* Webserver:
* PHP:
* etc.etc.:

# Checklist:

- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes

",I can only repeat myself....FTP quota (the .ftpquota file) shows the _disk usage_ and **NOT** the _traffic usage_,3639119
386,Feature-request #672 - database name prefixes + custom name,open,2019-05-10T01:06:14Z,2019-10-28T15:02:52Z,,CONTRIBUTOR,"Add mysql prefix option to use customername + database description field as final databasename

Fixes #672 

## Type of change

- [ ] Bug fix (non-breaking change which fixes an issue)
- [x] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [x] This change requires a documentation update

# How Has This Been Tested?

Locally. If the newely option value ""DBNAME"" is used, new functionality is triggered and executed.

# Checklist:

- [x] I have performed a self-review of my own code
- [x] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [x] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes

I've only added english and german localization, as I do not speak the other languages.","# [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/680?src=pr&el=h1) Report
> Merging [#680](https://codecov.io/gh/Froxlor/Froxlor/pull/680?src=pr&el=desc) into [master](https://codecov.io/gh/Froxlor/Froxlor/commit/822bb2bd4d761681101fe32c1a1250382d82b994?src=pr&el=desc) will **increase** coverage by `<.01%`.
> The diff coverage is `43.75%`.

[![Impacted file tree graph](https://codecov.io/gh/Froxlor/Froxlor/pull/680/graphs/tree.svg?width=650&token=hB0x5LKvE9&height=150&src=pr)](https://codecov.io/gh/Froxlor/Froxlor/pull/680?src=pr&el=tree)

```diff
@@             Coverage Diff              @@
##             master     #680      +/-   ##
============================================
+ Coverage     31.17%   31.18%   +<.01%     
- Complexity     5380     5386       +6     
============================================
  Files           105      105              
  Lines         14854    14862       +8     
============================================
+ Hits           4631     4634       +3     
- Misses        10223    10228       +5
```


| [Impacted Files](https://codecov.io/gh/Froxlor/Froxlor/pull/680?src=pr&el=tree) | Coverage Δ | Complexity Δ | |
|---|---|---|---|
| [lib/Froxlor/Database/DbManager.php](https://codecov.io/gh/Froxlor/Froxlor/pull/680/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvRGF0YWJhc2UvRGJNYW5hZ2VyLnBocA==) | `0% <0%> (ø)` | `21 <0> (+1)` | :arrow_up: |
| [lib/Froxlor/Api/Commands/Mysqls.php](https://codecov.io/gh/Froxlor/Froxlor/pull/680/diff?src=pr&el=tree#diff-bGliL0Zyb3hsb3IvQXBpL0NvbW1hbmRzL015c3Fscy5waHA=) | `79.46% <70%> (-0.82%)` | `62 <0> (+5)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/680?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/Froxlor/Froxlor/pull/680?src=pr&el=footer). Last update [822bb2b...865fc6b](https://codecov.io/gh/Froxlor/Froxlor/pull/680?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",3639119
387,[feature request] database name prefixes + custom name,open,2019-04-19T18:27:24Z,2019-10-12T06:33:08Z,,NONE,"I would like to choose the names for my databases.

I have now 7 databases called mostly like

user1
user2
...
user7

Is difficult to know which one is doing what
thx.","yes, the customer name as prefix and the database name attached to it should work, like:

customername_dbname",3639119
388,Future: implement dovecot 2.3 submission proxs,open,2019-03-21T13:36:19Z,2019-04-25T16:54:20Z,,CONTRIBUTOR,"wäre was für die zukunft. debian bietet nur 2.2 an. wäre also was für debian 10. 
Aktuell teste ich gerade bisschen rum. Ich würde hier, wenn es läuft, mein ergebnis bereit stellen.

Bisher bekomme ich es jedoch nicht zum laufen. -> "" unknown user"" :/


`protocols = imap sieve submission

protocol submission {

}

service submission-login {
  inet_listener submission {
    port = 587
  }
}
service submission {
}`","dazu ein klares: jein.

in einer konfiguration ohne smtp rejections (die ja ansich nicht zutrifft weil wir den postfix ja checken lassen ob die from adresse vom loginuser stammt (glaube ich zumindest?!)) ist es sinnvoll da wir uns einen db lookup sparen - dovecot/auth hat den kram ja schon da.

als das ding in 2.3 dazukam wollt ich mir das auch mal genauer ansehen, kam aber bisher nicht dazu.
ich meine naemlich dass ein outbound content filter dann eher nicht funktioniert aber den haben wir ja eh nicht in der standardconfig - wie gesagt, muss ich mal schauen",3639119
389,Implement DMARC,open,2019-02-26T17:27:30Z,2019-11-21T09:36:24Z,,NONE,"Hey guys,

Any plans to add support for DMARC? I think this is a simple one that can be added fairly simply.","I recommend to setup [rspamd](https://rspamd.com/). It includes DKIM signing and checking, SPF checking and DMARC. And a really good spamfilter, better than amavisd/spamassasin.
Sure you have to generate keys and configure them in DNS yourself.
With the new Froxlor API, no problem to do so automatically for all domains configured in Froxlor.",3639119
390,Feature Request: Behind-a-reverse-proxy-support (e.g. Cloudflare),open,2019-02-12T23:38:48Z,2019-02-12T23:38:48Z,,CONTRIBUTOR,"**Problem**

Reverse proxy are getting more usual, and Cloudflare is a very common one offering a lot of benefits. However there are also changes required on the server-side to get the real IP of the visitor, and not the Cloudflare Edge IP address which is contacting the origin server, like Froxlor in this case.

**Idea**

Having new configuration options when editing a (sub)domain:
- ""Is behind a reverse proxy?"": boolean. Set if domain is behind a reverse proxy or not.
- ""Trusted IP addresses"": string. A set range of IP addresses from the reverse proxy, which determines if the real IP should be read from the `X-Forwarded-For` header instead.
- ""real_ip_recursive"": boolean. I'm not sure if this is needed. Might be nginx-specific.

**Ressources**

- http://nginx.org/en/docs/http/ngx_http_realip_module.html",,3639119
391,Feature Request: Multi-line for log format,open,2019-02-12T11:14:48Z,2019-05-04T13:43:44Z,,CONTRIBUTOR,"I'd like to see the setting `Settings - Webserver Settings - Access-log format` as a multi-line input for more extended log formats. Having the whole format in a single line is really hard to read - and it might happen to just have longer log formats.

As an example see the [nginx amplify recommended log format](https://github.com/nginxinc/nginx-amplify-doc/blob/master/amplify-guide.md#additional-nginx-metrics):
```
log_format  main_ext  '$remote_addr - $remote_user [$time_local] ""$request"" '
                        '$status $body_bytes_sent ""$http_referer"" '
                        '""$http_user_agent"" ""$http_x_forwarded_for"" '
                        '""$host"" sn=""$server_name"" '
                        'rt=$request_time '
                        'ua=""$upstream_addr"" us=""$upstream_status"" '
                        'ut=""$upstream_response_time"" ul=""$upstream_response_length"" '
                        'cs=$upstream_cache_status' ;
```

Just to point that out: I'm unsure if this might conflict with apache2 in terms of support of multi-line log formats.","possible yes, but not very high priority",3639119
392,Implement Openkdim,open,2018-12-27T15:58:57Z,2019-07-30T08:19:08Z,,NONE,"Since dkim-filter is deprecated it would be great to implement its replacement Openkdim.

I set up dmarc reports on my server and neither Yahoo and auth-results@verifier.port25.com don't like the current dkim-filter implementation. On auth-results@verifier.port25.com complains about the dkim selector having an underscore. Fortunately Google doesn't complain and passes de dmarc test. 

```
----------------------------------------------------------
DKIM check details:
----------------------------------------------------------
Result:         permerror (syntax error in s= tag: Error in ""dkim_1"": invalid character U+005F ('_') in domain label)
ID(s) verified: 

DNS record(s):

NOTE: DKIM checking has been performed based on the latest DKIM specs
(RFC 4871 or draft-ietf-dkim-base-10) and verification may fail for
older versions.  If you are using Port25's PowerMTA, you need to use
version 3.2r11 or later to get a compatible version of DKIM.
```


","Config templates are so damn easy. Near stock actually. OpenDKIM is much easier to implement compared to dkim-milter, as it already supports SQL OOTB.

Will do.",3639119
393,Feature Request: Support PGP encryption for backups,open,2018-11-20T09:31:21Z,2019-11-09T10:43:51Z,,NONE,"Froxlor should support PGP encryption of backups to increase security. That could be realized by adding a field pgp_public_key to the users basic data or within the backup dialog. After the backup archive was created successfully, and a pgp key is available, the archive should be encrypted, so only the owner of the according private key is able to read that backup.

That would be especially useful if it takes a long time to create the backup (e.g. overnight) and you do not want to have your plaintext backup stored that long.

What do you think about that?

Best regards
Matthias","Not yet, didn't recognize that 0.10.x is released. When I find the time, I will start with implementing that.",3639119
394,HTML Mails broken,open,2018-08-16T20:47:26Z,2019-10-13T08:27:43Z,,NONE,"When setting up a HTML email template (i.e. new new_database_by_customer) the mail being send is broken.



# System information
* Froxlor version: 0.9.39.5
* Web server: apache2
* SMTP server: postfix
* OS/Version: Ubuntu 18.04


# Steps to reproduce

1. fill in HTML code on the admin_templates.php page
2. let froxlor send mail
3. view raw mail in MUA
4. see that all newlines have been converted to `'<br/>'` which breaks the design of the mails


# Expected behavior

1. no conversion to `<br/>` of newlines so that HMTL mails get displayed correctly


# Actual behavior

1. line 257 of customer_mysql.php does the str_replace.
   `$mail->MsgHTML(str_replace(""\n"", ""<br />"", $mail_body));`


I would love to be able so send out html mails!
Thanks!",@torcolato Workaround: Remove all newlines from your HTML email template. Works fine for me.,3639119
395,Feature request: apache mod_chroot,open,2018-04-18T19:28:59Z,2018-04-25T15:03:03Z,,NONE,"# System information
* Froxlor version: 0.9.39.5 (DB: 201802130)
* Web server: apache2
* OS/Version: Debian 9
## Implement apache mod_chroot usage.

Current problem, when using mpm_itk is that, although every apache process will run as its owner when virtualhost config states:
`  <IfModule mpm_itk_module>
    AssignUserID $USER $GROUP
  </IfModule>
`
users are not isolated from each other and all users are able to view system files and other user files  when they upload some sort of php file manager.

mod_chroot itself resolves problem that user is able to view system files by jailing apache master process.
It will require to state global chroot folder, in froxlor case it will probably be /var/customer/webs, also some libraries must be preloaded, for php name resolving, and timezone files, resolv.conf, and some other config files must be present in chroot jail.
Since server reconfiguration is done by cron (and run by root using cli php), this will not affected by apache module.

Also, user folders must be created as 750, currently they are created as 755

This setup will result that users are able to view all folders in /var/customer/webs, but they cannot look into folders, and folder /var/customer/webs looks to them as root folder (/)
Apache virtual host DocumentRoot in this case will be /$USER","Yes, i do, and i see what you are saying.

File manager i used:
[https://github.com/Rugoals/phpFileManager](https://github.com/Rugoals/phpFileManagerl)

Indeed, when i try to access upper folder, php file manager gives me:
```
I/O Error./var/customers/webs/
--
```
But, if i use ""shell"" in that particular file manager, i can do:
```
# pwd
/var/customers/webs/testuser/fm
# ls ../../../../../
bin
boot
dev
etc
home
initrd.img
initrd.img.old
lib
lib64
media
mnt
opt
proc
root
run
sbin
srv
sys
tmp
usr
var
vmlinuz
vmlinuz.old
```
I have another web server instance which uses mpm_itk with mod_chroot (no froxlor), and there, same file manager is unable to ""see"" folder listings (in froxlor case this would be folders with usernames), but it cannot go up because of mod_chroot.
And manager cannot look into other users folders because of folder permissions (700) and every user apache vhost is running as that particular user, so no access to other user folders.",3639119
396,Add Option to set OpenBaseDir manually for domain/subdomain,open,2018-02-13T13:09:45Z,2019-10-16T16:21:26Z,,NONE,"The OpenBaseDir can only be set to the ""Home Directory"" or the ""Document Root"". It would be nice to have a third option to set it manually. For example: 
Magento needs only it's pub directory to be accessible via Apache (DocumentRoot), but PHP needs access to all files in the ""Mangento Root"" (OpenBaseDir). Currently I must give it access to all files under the home directory of the user.","I understand fully, and I can relate why this improvement is needed. Still, like said in https://github.com/Froxlor/Froxlor/issues/515#issuecomment-365264373 I try to avoid entering custom paths by customers as extensivly as possible",3639119
397,add a third option to temp. disable local mail delivery (for domain transfer purposes),open,2017-12-07T10:19:44Z,2018-04-06T14:09:45Z,,NONE,"There should be the posibillity to setup mail configuration for a domain without routing mails to local mailboxes.
This may be needed e.g. for situations of domaintransfer from any hoster to a froxlor using hoster.
If the *NIC knows the domain and froxlor knows the domain also, your (froxlor admins) customers will send mail to the new unknown mailboxes while rest of the world sends mail to the ""old""/public mailboxes. REachability of this transfering customer is broken until setup, domain transfer and dns caches are ready - this takes usualy about 2 days (if you'r not able to route mail from your past provider to froxlor).

At the moment froxlor knows two states : domain is emailenabled or not. With disabling all alises, forwardings and mailboxes will be deleted. I'ld like to see a third state, which enables a parallel mail infrastructure : domain allows mailsettings (aliases, forwards, mailboxes up to fully functional smtp-auth and imap/pop3) but does not deliver local. Instead it should relay mail to offical MX.

At the moment I set inside SQL isemaildomain='2' and add official MX to postfix' relay_domains map. So I'm able to build the whole mail infrastructure, copy content and test access without loosing ability to contact the customer by official mail routing.
",Its not necessary for MTA but for FROXLOR. You are not able to manage mail settings als forwardings an mailboxes in FROXLOR without enabling e-mail. Because this is going hand in hand with dns (MX) and MTAs transport configuration through FROXLOR there is at the moment no posibility to set e-mail settings without being local mail destination.,3639119
398,Wrong Unit in traffic graphs mouseover,open,2017-04-13T08:46:57Z,2019-12-10T09:32:40Z,,NONE,"Hi,

when looking at the traffic graphs the mouseover box for the single points always show one unit higher than it should. E.g. when the value is MB the mouseover shows GB. The unit in the header of the graphs is correct, wherefore I assume it's just a rendering bug in the frontend.

![froxlor_graph_bug](https://cloud.githubusercontent.com/assets/2489598/24997232/2996a77c-2036-11e7-906e-b04e79019e41.png)

**Setup**:
Froxlor 0.9.38.7 
Nginx 1.10.3
PHP 7.0.17
Debian Jessie",This will change in 0.11. with new Frontend and new Chart library,3639119
399,"allow external customer database, fixes #1438",open,2015-04-29T12:21:36Z,2015-08-17T18:37:08Z,,CONTRIBUTOR,"Patch based on PR #197, adapted to master, with some additions.
## Description

This patch allows to have a separate customer database (or even multiple customer databases). To enable it, just add a second database to `$sql_root` in `userdata.inc.php`:

```
$sql_root[0]['caption']='Default';
$sql_root[0]['host']='127.0.0.1';
$sql_root[0]['user']='root';
$sql_root[0]['password']='xyz';
$sql_root[0]['hidden']=true;

$sql_root[1]['caption']='Customer';
$sql_root[1]['host']='10.0.10.18';
$sql_root[1]['user']='root';
$sql_root[1]['password']='abc';
```

Now, when the customer wants to create a new database, he will be able to select the server from a dropdown. If you don't want to allow customer databases on the Froxlor db host itself, you can set the main database to `hidden` (see above) - then it will not be available in the customer panel.

The patch also enables using wildcards in `system.mysql_access_host`, which was not possible before (but is useful, if you want to limit access to a network or number of hosts).
#### Implementation notes
- the host for a given customer db is stored in `panel_databases`.`dbserver`, which is an index to `$sql_root`. This field was already there, and is now used again.
- to operate on a specific database, call `Database::needRoot()` with the server's index as the second parameter
- If set, `$linkWithoutDatabase` removes the database name from the PDO DSN, which is required if `$dbserver` is not `0` (this can probably be removed completely, but it was in the original patch, so I left it in)
- `correctMysqlUsers()` has been rewritten completely, as the old version was a total mess and would delete non-froxlor database users under some circumstances. 
","I have seen it. Github sends notifications. No time yet.
",3639119
400,Add possibility to have external database server for customers database,open,2014-07-09T16:25:58Z,2015-02-27T09:20:27Z,,NONE,"Fixes Bug #1438: Second External database server for customers database
not anymore possible
","The rights issue is related to the root user missing the grant_priv.

This can be seen by issuing :
SELECT host,user,password,Grant_priv,Super_priv FROM mysql.user;

This can be fixed by issuing :
 UPDATE mysql.user SET Grant_priv='Y', Super_priv='Y' WHERE User='root';

All CRUD operations work as expected and the database is seen correctly in froxlor.
",3639119
401,Vitis Creating the awsxlcbin file failed ,open,2020-03-17T10:50:55Z,2020-03-18T02:50:04Z,,NONE,"By calling $VITIS_DIR/tools/create_vitis_afi.sh to generate AFI/AFGI and the awsxclbin, I got some error report:
`XRT Build Version: 2.5.309 (2019.2_PU2)
       Build Date: 2020-02-23 18:52:05
          Hash ID: 9a03790c11f066a5597b133db737cf4683ad84c8
Reading xclbin file into memory.  File: /home/ubuntu/prj/Triden/sha256/Hardware/binary_container_1.xclbin
ERROR: Section 'PARTITION_METADATA' is not part of the xclbin archive.`

Check the detail of the script, it looks if I remove the ""--remove-section PARTITION_METADATA"" from the last line of script code, I can get the final file output:

https://github.com/aws/aws-fpga/blob/0b840c6b41e855e4bf8825914674356cc3167762/Vitis/tools/create_vitis_afi.sh#L286",,72888735
402,Symlink for Windows HLx Builds not work - please add copy to TCL,open,2020-01-18T09:53:49Z,2020-01-18T10:05:36Z,,NONE,When build f1_inst vivado cannot copy  file from $AWSINSTALL/hdk/common/shell_v04261818/hlx/design/ip/aws_v1_0/hdl/synth/ because on windows this sym-link does not work - please add creation of NTFS-links or copy this folders(sym & synth) when hlx_setup.tcl,Another but similar for lib_pipe.sv - not work on windows,72888735
403,Missing <linux/version.h> in mgmt-core.h cause failure to compile DKMS on kernel 3.10.0-1062.1.2,open,2019-10-18T07:48:12Z,2019-10-24T23:10:43Z,,NONE,"After updating the kernel to 3.10.0-1062.1.2 and installing the respective kernel-headers and kernel-devel packages, dkms autoinstall will fail to compile the awsmgmt and xocl modules.

### Errors

`# dkms autoinstall`
``
`Kernel preparation unnecessary for this kernel.  Skipping...`
``
...
`Error!  Build of awsmgmt.ko failed for: 3.10.0-1062.1.2.el7.x86_64 (x86_64)`
`Consult the make.log in the build directory`
...
`# cat /var/lib/dkms/xrt-aws/2.2.0/build//make.log`
`In file included from /var/lib/dkms/xrt-aws/2.2.0/build/driver/aws/kernel/mgmt/mgmt-core.c:25:0:`
`/var/lib/dkms/xrt-aws/2.2.0/build/driver/aws/kernel/mgmt/mgmt-core.h:28:5: warning: ""LINUX_VERSION_CODE"" is not defined [-Wundef]`
`...`
`/var/lib/dkms/xrt-aws/2.2.0/build/driver/aws/kernel/mgmt/mgmt-core.h:28:27: warning: ""KERNEL_VERSION"" is not defined [-Wundef]`
`...`
`/var/lib/dkms/xrt-aws/2.2.0/build/driver/aws/kernel/mgmt/mgmt-core.h:28:41: error: missing binary operator before token ""(""`
`...`
`make[2]: *** [/var/lib/dkms/xrt-aws/2.2.0/build/driver/aws/kernel/mgmt/mgmt-core.o] Error 1`
`make[1]: *** [_module_/var/lib/dkms/xrt-aws/2.2.0/build/driver/aws/kernel/mgmt] Error 2`
`make[1]: Leaving directory '/usr/src/kernels/3.10.0-1062.1.2.el7.x86_64'`
`make: *** [all] Error 2`



### Workaround (fix?)
I have managed to compile the module by adding the include line to the mgmt-core.h file:

`# pwd`
`/usr/src/xrt-aws-2.2.0/driver/aws/kernel/mgmt`
`# diff -c mgmt-core.h mgmt-core.h.bkp`
`*** mgmt-core.h	2019-10-18 07:31:14.254081701 +0000`
`--- mgmt-core.h.bkp	2019-09-06 19:46:17.000000000 +0000`
`***************`
`*** 15,21 ****`
`  #define _AWS_MGT_PF_H_`
``
`  #include <linux/cdev.h>`
`- #include <linux/version.h>`
`  #include <asm/io.h>`
``  
`  #define DRV_NAME ""awsmgmt""`
`--- 15,20 ----`

","Hi @deeppat,

I have used the FPGA Developer AMI v1.7.0 from Marketplace. XRT 2.2.0. That AMI comes with an older kernel version. Running ""yum -y groupinstall ""GNOME Desktop"""" will resolve some dependencies and install a VDO package that requires kernel > 3.10.0-1025, and trigger the kernel update.

Immediately after the update, I rebooted the instance and the xocl driver was no longer available. 

During the yum command there are error messages stating that the kernel-headers and kernel-devel packages were not available in the correct version (because the Gnome installation did not trigger those), but once I updated those packages and ran ""dkms autoinstall"", the compilation failed with the messages I provided initially.

Double checking, I noticed that the output of diff is garbled. I just had to add the #include for linux/version.h and run ""dkms autoinstall"".

The file I changed was from the aws-fpga package, hence I reported the issue here.",72888735
404,"The ""cl_dram_dma"" pre-gen AFI can not be load while ""cl_hello_world"" AFI can be load.",open,2019-10-11T11:27:39Z,2019-10-15T07:01:25Z,,NONE,"Hello, I am doing some quick test by using the pre-generated AFI, so I don't need rebuild it.

I can find ""cl_hello_word"" AFI: agfi-0fcf87119b8e97bf3 (https://github.com/aws/aws-fpga/blob/master/hdk/cl/examples/cl_hello_world/README.md#metadata).
This AFI can be loaded correctly.

I can find ""cl_dram_dma"" AFI: agfi-02f141212beac0cfb (https://github.com/aws/aws-fpga/tree/master/hdk/cl/examples/cl_dram_dma).
However this AFI can not be loaded:

Can someone have a check on that?
`ubuntu@ip-:/aws-fpga$ sudo fpga-load-local-image -S 0 -I agfi-0fcf87119b8e97bf3
AFI          0       agfi-0fcf87119b8e97bf3  loaded            0        ok               0       0x04261818
AFIDEVICE    0       0x1d0f      0xf000      0000:00:1d.0

ubuntu@ip-: /aws-fpga$ sudo fpga-clear-local-image -S 0 
AFI          0       none                    cleared           1        ok               0       0x04261818
AFIDEVICE    0       0x1d0f      0x1042      0000:00:1d.0

ubuntu@ip-: /aws-fpga$ sudo fpga-load-local-image -S 0 -I agfi-02f141212beac0cfb
Error: (5) invalid-afi-id
The agfi id passed is invalid or you do not have permission to load
the AFI. `","@deeppat Thanks for help. I assume few copy command can make this available in China region--but this can really help people saving a lot of resource if they don't want to rebuild the code (I had done the cl_helloworld build, take more than 5 hrs--really make no sense to rebuild that example project if one already did practice..",72888735
405,Issue with examples/3rd_party/fft1d,open,2019-07-28T17:37:46Z,2019-07-30T15:46:05Z,,NONE,"Is it possible to provide full implementation instead of diff delta?
I tried to compile and run it on hardware but it hangs. Wonder if you have tried it in actual hardware?","Hi @yyang29,

The main purpose of providing these 3rd party examples is to show how to migrate such examples to the AWS platform. Depending on the type of licensing of the examples, we might not be able to distribute and provide a full implementation. 

Could you give us some data on which Vivado tool version you are targeting the build for? 

-Deep
",72888735
406,Runtime packages,open,2019-06-04T09:37:45Z,2019-06-11T13:50:24Z,,NONE,"Please, consider creating .deb/.rpm packages for runtime libraries and utilities (Ex `aws-fpga-mgmt`) for most common OS (Ubuntu/CentOS).

Cloning the git and sourcing the script is OK for development environments, but much less for a runtime environment. Using packages may help to:
- Reduce downloading from full source (~275MB) to only required compiled files (~0.3MB).
- Remove the need to install build requirements (GCC, Git, ...).
- Reduce the whole install duration.
- Handle install and updates using the package manager.
- Allow signature verification.

The package may contain:

Management utilities (Maybe not all if some are not relevant in runtime environment):
- `/usr/bin/fpga-clear-local-image`
- `/usr/bin/fpga-describe-local-image`
- `/usr/bin/fpga-describe-local-image-slots`
- `/usr/bin/fpga-get-virtual-dip-switch`
- `/usr/bin/fpga-get-virtual-led`
- `/usr/bin/fpga-load-local-image`
- `/usr/bin/fpga-local-cmd`
- `/usr/bin/fpga-set-virtual-dip-switch`
- `/usr/bin/fpga-start-virtual-jtag`

Libraries:
- `/usr/lib64/libfpga_mgmt.so`
- `/usr/lib64/libfpga_mgmt.so.1`
- `/usr/lib64/libfpga_mgmt.so.1.0.0`

Udev rule:
- The script to generate udev rule, `sdk/userspace/add_udev_rules.sh` (By example as `/usr/bin/fpga-add-udev-rule`)
- `/opt/aws/bin/change-fpga-perm.sh` (Maybe moved to `/usr/bin/fpga-change-perm`)

Python libraries (Eventually as extra package like  `python3-aws-fpga-mgmt`, can also be uploaded as PIP package):
- `<OS dependant path>/fpga_dma.py`
- `<OS dependant path>/fpga_mgmt.py`
- `<OS dependant path>/fpga_pci.py`

Eventually, a development package (Example: `aws-fpga-mgmt-dev` deb package  / `aws-fpga-mgmt-devel` rpm package) may also be created to install include files (from `/sdk/userspace/include`) to allow build software without the whole SDK.
","Hi @xlz-jgoutin, this is excellent feedback for us to take back to our development team. 

This adds a lot of value and ease of use for a runtime environment. I will discuss it with the development team and discuss where we can place it within our development efforts. I'll update here once I have something for you. 

-Deep",72888735
407,Python bindings error in default AMI (undefined symbol: fpga_pci_readdir_mutex),open,2019-04-15T23:18:46Z,2019-05-16T19:35:38Z,,NONE,"Thank you for adding a Python bindings API! I was excited to try it, but ran into an issue in `fpga_pci.py` when testing with AMI 1.6.0. Specifically, this is the traceback:

```
 import fpga_pci
  File ""/usr/lib64/python2.7/site-packages/fpga_pci.py"", line 196, in <module>
    fpga_pci_readdir_mutex = (union_c__UA_pthread_mutex_t).in_dll(_libraries['/usr/local/lib64/libfpga_mgmt.so'], 'fpga_pci_readdir_mutex')
ValueError: /usr/local/lib64/libfpga_mgmt.so: undefined symbol: fpga_pci_readdir_mutex
```

The issue stems from a conditional compilation in [fpga_pci.h](https://github.com/aws/aws-fpga/blob/0f678055fa9f1378610389e46750f8607a0d4c23/sdk/userspace/include/fpga_pci.h#L246), which affects the existence of `fpga_pci_readdir_mutex` in [fpga_pci.py](https://github.com/aws/aws-fpga/blob/6c707ab4a26c2766b916dad9d40727266fa0e4ef/sdk/userspace/python_bindings/fpga_pci.py#L196). 

As a side-note, the AMI ships with a `libc` version of 2.17, so `readdir_r ` is available:
```
ldd --version
ldd (GNU libc) 2.17
```

Commenting line 196 in `fpga_pci.py` allows me to run code as needed, so asolution would be to conditionally include or remove `fpga_pci_readdir_mutex` in Python (and the `__all__` variable in the same file). ","Hi @giech Thanks for pointing that out as well. 

On a side note, our team is still working on a fix and while we could not get it released in time for 1.4.9, I'm targeting it for the next rev. I'll update you here once we have the fixes out! 

Thanks again,

Deep
",72888735
408,"It's better to change “data transferred / execution time” to ""execution time /  data transferred"" in SDAccel_Guide_AWS_F1.md.",open,2018-01-05T07:36:51Z,2018-01-05T07:38:15Z,,NONE,"It's better to change “data transferred / execution time” to ""execution time /  data transferred"" from the context in SDAccel_Guide_AWS_F1.md.
  ",,72888735
409,[Feature Request] Add -std=c++11 to Makefiles,open,2020-03-24T16:16:07Z,2020-03-24T23:19:50Z,,CONTRIBUTOR,"**Summary**

Can we add `-std=c++11` to the Makefiles, e.g. `Makefile.mpi` and others, now that LAMMPS requires it?","@stanmoore1 I would recommend against adding it to Makefile.mpi since this makefile is supposed to work on the largest variety of machines without modifications and `-std=c++11` is specific to GNU gcc and compilers that try to be command line compatible with it. Most compilers on most systems are C++11 compatible by default. It is mostly RHEL/CentOS 7.x that is not.

Beyond that, for people that have trouble handling this situation, we should recommend building with CMake, as this will attempt to automatically discover most settings, will automatically enable C++11 compatibility with the compiler specific flag, and - as of recent - also will try to set some additional compiler dependent optimization flags (where known). With the latest changes, people on most machines should be able to get a well working LAMMPS executable with many commonly used features included through:
```
cd path/to/lammps
mkdir build
cd build
cmake3 -C ../cmake/presets/most.preset ../cmake
cmake3 --build .
```
Or if they want a more minimal but still widely applicable configuration (MANYBODY, MOLECULE, KSPACE, RIGID) use the `minimal.cmake` preset (which is similar to the packages installed by default in older LAMMPS tarballs).",12007030
410,[BUG] Erronious equation in documentation of the force 2-norm in min_modify,open,2020-03-24T04:48:55Z,2020-03-25T00:45:58Z,,COLLABORATOR,"**Summary**

The equation for the 2-norm of the global force vector is shown as the length of the sum of per-particle force vectors, when it should be the square-root of the sum of the squared 2-norms of each per-particle vector.

**LAMMPS Version and Platform**

19 Mar 2020

**Expected Behavior**

||F|| = sqrt( ||F_1||^2 + ||F_2||^2 + ||F_3||^2 + ...  )

**Actual Behavior**

||F|| = sqrt( F_1 + F_2 + F_3 + ...  )

**Link**

https://lammps.sandia.gov/doc/min_modify.html","Sounds good, I'll do that. Thanks a lot Axel!",12007030
411,Restrain lbound,open,2020-03-23T17:10:48Z,2020-03-25T01:11:49Z,,NONE,"**Summary**

Extension of the ""fix restrain bond"" adding the possibility of having a start and end equilibrium distance.

Definitionof a new fix restrain for lower bound harmonic. It is an harmonic restraint to keep atoms far apart from each other and vanishes above the equilibrium bond distance.

These harmonics are useful to implement restraint-based modelling approaches for the structural determination of biological molecules using molecular dynamics.

**Related Issues**

_If this addresses an open GitHub issue for this project, please mention the issue number here, and describe the relation. Use the phrases `fixes #221` or `closes #135`, when you want an issue to be automatically closed when the pull request is merged_

**Author(s)**

David Castillo, Structural Genomics Group, CNAG-CRG
Marco Di Stefano, Structural Genomics Group, CNAG-CRG

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

There is no backward compatibility issue.

**Implementation Notes**

_Provide any relevant details about how the changes are implemented, how correctness was verified, how other features - if any - in LAMMPS are affected_

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [x] The feature or features in this pull request is complete
- [x] Licensing information is complete
- [x] Corresponding author information is complete
- [x] The source code follows the LAMMPS formatting guidelines
- [x] Suitable new documentation files and/or updates to the existing docs are included
- [x] The added/updated documentation is integrated and tested with the documentation build system
- [x] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


",,12007030
412,cmake: major clean-up,open,2020-03-22T20:43:58Z,2020-03-26T13:26:32Z,,MEMBER,"Use more modern cmake paradigms. 

- [x] Remote old style `include_directories()` calls
- [x] Remove old style `add_definitions()` calls
- [x] Create imported target for
  - [x] NetCDF
  - [x] QUIP
- [x] turn `linalg`, `mpi_stubs` in `${PKG_LIB}` in object libraries - Nope, CMake-3.10 doesn't have full support for `OBJECT` libs yet
- [x] Create exported target for lammps library
- [x] Drop pkg-config files? - Nope
- [x] Update old style (without `PRIVATE`/ `PUBLIC` keyword) `target_link_libraries()` calls","Configuring with: `cmake  ../cmake/  -DBUILD_LIB=on -DBUILD_MPI=off`

leads to:
```
[ 99%] Built target lammps
Scanning dependencies of target lmp
[100%] Building CXX object CMakeFiles/lmp.dir/home/akohlmey/compile/lammps/src/main.cpp.o
In file included from /home/akohlmey/compile/lammps/src/main.cpp:14:
/home/akohlmey/compile/lammps/src/lammps.h:17:10: fatal error: mpi.h: No such file or directory
   17 | #include <mpi.h>
      |          ^~~~~~~
compilation terminated.
```",12007030
413,Fixing and Updating HowTo Discussion: 8.1.3. Using LAMMPS with Bash on Windows ,open,2020-03-20T17:50:20Z,2020-03-24T22:59:36Z,,NONE,"**Summary**

 [HowTo Discussion 8.1.3. Using LAMMPS with Bash on Windows](https://lammps.sandia.gov/doc/Howto_bash.html)  needs updating 

Now that it's easier to use linux on windows, this section should be updated.

**Detailed Description**

1.  Should probably include this link at the beginning: 
[https://docs.microsoft.com/en-us/windows/wsl/install-win10](https://docs.microsoft.com/en-us/windows/wsl/install-win10)

2.  In the section ""Installing Prerequisite Packages"", the second step needs to be fixed. 
In 
`sudo apt install -y build-essential ccache gfortran openmpi-bin libopenmpi-dev libfftw3-dev libjpeg-dev libpng12-dev python-dev python-virtualenv libblas-dev liblapack-dev libhdf5-serial-dev hdf5-tools
`
the `libpng12-dev` is no longer supported and should be changed to `libpng-dev` according to: [https://askubuntu.com/questions/991706/e-package-libpng12-dev-has-no-installation-candidate](https://askubuntu.com/questions/991706/e-package-libpng12-dev-has-no-installation-candidate)


I'm just starting to use LAMMPS so thought I could add some feedback before I forget. ","Thanks for reporting! I've fixed the two issues you mentioned in PR  #1962. WSL is a moving target and we'll update the docs. Right now I'm waiting for the general availability of WSL 2.0, which will require a larger rewrite.",12007030
414,Kim property,open,2020-03-17T21:12:09Z,2020-03-18T22:10:44Z,,CONTRIBUTOR,"**Summary**

A new kim_commands feature.

- New capability within LAMMPS for writing material properties computed in LAMMPS to standard KIM property instance format.
- Updating the kim_coammands document
- Updating the KIM package documents
- Addition of a KIM reference to the pair potentials document (pair_adp, and  pair_eam).

**Author(s)**

Yaser Afshar (U Minnesota)
Ellad Tadmor (U Minnesota)
Daniel S. Karls (U Minnesota)
Ryan Elliott (U Minnesota)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

There is no backward compatibility issue.

**Implementation Notes**

The new command requires that LAMMPS is built with the Python 3.6 or later package installed. It uses Python/C interface, and in case LAMMPS is not made with Python 3, calling this command will fail with a message indicating the problem.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [x] The feature or features in this pull request is complete
- [x] Licensing information is complete
- [x] Corresponding author information is complete
- [x] The source code follows the LAMMPS formatting guidelines
- [x] Suitable new documentation files and/or updates to the existing docs are included
- [x] The added/updated documentation is integrated and tested with the documentation build system
- [x] The feature has been verified to work with the conventional build system
- [x] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


","> @yafshar I think that we should aim to align the way how python is used in this command better with how it is used in the PYTHON package. For starters, you should initialize the python interpreter instance inside the LAMMPS class with `python->init()` like it is done with the styles in the PYTHON package. Then we should add a `load_module()` method to the `PythonInterface` adapter class (and its implementation) to have a consistent and generalized way of importing a python module into that global python interpreter instance. I have some more ideas of what could be generalized and abstracted, but I would prefer to discuss them first with @giacomofiorin and @rbberger who have figured out a lot of the details of how python is currently embedded into LAMMPS.

@akohlmey I fixed the first thing you mentioned by adding `python->init()`. I have also written a wrapper in my other repo for importing the python module and functions in c++. If I understand you correctly, you aim something general in LAMMPS, maybe a bit similar to what I have done here [PyGetAttribute](https://github.com/yafshar/UMUQ/blob/fd3e0e4b4b910d741e766e5ebf24199ccb141804/src/interface/python.hpp#L523), [PyCallFunctionObject](https://github.com/yafshar/UMUQ/blob/fd3e0e4b4b910d741e766e5ebf24199ccb141804/src/interface/python.hpp#L568), and [PyCallFunctionName](https://github.com/yafshar/UMUQ/blob/fd3e0e4b4b910d741e766e5ebf24199ccb141804/src/interface/python.hpp#L672) If this is what you have in mind I can help to implement it in LAMMPS.",12007030
415,[Feature Request] Let's boost users' contributions in extending lammps,open,2020-03-16T20:19:34Z,2020-03-17T14:26:23Z,,NONE,"**Summary**

Dear LAMMPS developers,
 Without any doubt, a remarkable percentage of LAMMPS users who have enjoyed working with its highly versatile and broad capabilities and have some programing experiences in c++, would be so ambitious to contribute in extending and developing LAMMPS, either to add new features related to their specific projects which might be useful for others or improving some previous algorithms and  features. Nevertheless, considering the high level of the programing applied in developing LAMMPS by developers who are typically experienced programmers and the versatile structure of the code, it might be a big challenge for new arrivals and specially not highly experienced c++ programmers to getting started and having themselves involved, resulting in being disappointed and surrender right at the beginning.
I am writing to ask/share with you a suggestion which can be very much helpful for such persons and that is, for few number of highly important .cpp files of LAMMPS, provide line by line elaborately explained comments and share it as some c++ or LAMMPS code tutorials. I would suppose, for majority of LAMMPS developers who know the structure of the code by heart, it won't take more than few minutes but it can save days/weeks of novices and will definitely have a very remarkable influences. 
I already surveyed a lot the web for something similar but couldn't find anything useful.
Bests,
Amin

","> Please let me to declare that I am not suggesting it only on behalf of myself. I can apply new things I need to try by modifying some in house codes written in fortran90. For LAMMPS modifying, I already have done this once without needing to understand the whole code and only via changing some similar codes. The reason I suggested it is that I learned that this is exactly something many colleagues and students wish to and makes getting started ways easier. At least for most of .cpp codes of lammps I can say they are minimally commented (see e.g. fix_temp_rescale.cpp).

You are *still* missing my point. There is no way to bypass having to go through the process of learning the way how I have already outlined it. You can call it ""the hard way"", see the website and book ""Learn Python the Hard Way"" for and example and good arguments, why this is the better way to approach writing code). Fix `temp/rescale` is a good example for a file that has **exactly** the right amount of comments in the right places.  The remaining information is already in the manual and in the Developer.pdf document that describes the overall flow of control.  Asking for more is ignoring the realities of how much time LAMMPS (core) developers have to spend on working on LAMMPS and how few of them there are that can do this kind of work. While what you are proposing may get more people started, it will give them a wrong sense of their own skills and that is very dangerous. If you the search the web for the essay ""How Developers Stop Learning: Rise of the Expert Beginner"" and some more related texts on ""expert beginners"", you find more examples and better arguments than I have the time to present here, why it is sometimes in the grand scheme of things better to make things not too easy. I think this very much applies here.


> 
> Sounds great. And to make it easier, even if it is not line by line extensively commented (which I guess I kind of overstated what I meant), even few comments for each part of the code to declare what it is supposed to and how it connects to other classes for few important parts (update.cpp, fix_npt.cpp, ..) would be a great help and probably more helpful to understand the structure of the code compared to developer manuals. 

The overall flow of control and how everything is connected together *is* outlined in Developer.pdf. There is not much to explain about fix npt.cpp its relation to fix_nh.cpp requires just basic C++ knowledge and the integration of a fix into the flow of control is - again - outlined in Developer.pdf and the purpose of the individual required functions of a fix in the manual.  That aside, the nose-hoover fixes are a rather unusual part of LAMMPS and to understand the functioning of the time stepping, it is sufficient to study fix nve instead. The rest is specific to nose-hoover thermostat and barostat algorithms and thus very specific and therefore not something for a beginner to start with.

Don't hold you breath on more doxygen decorations in the manual. As I already outlined, this is a low priority item and will take a very long time to get anywhere to become useful. 

We are starting to argue in circles. I do understand the frustrations of some people (I have been there myself), but I have to re-state that this something that primarily needs to be addressed by a change of the approach and adjustment of expectations of what can be done with a given level of experience.  If anybody is in a position to assist with that, those would be the individual PIs and supervisors that need to assert suitable advice and guidance on their coworkers and students. We are seeing time and again, that those rather than providing that kind of guidance (like I have experienced it from my adviser and by whom I was given the time to learn things ""the hard way(tm)""), and from collaborators on various software packages) revolve to abandoning their students/posdocs/coworkers for fear of exposing their own lack of experience and creating pressure to produce results.

To summarize. The LAMMPS developers are aware of how daunting it is to start working on as large a software package as LAMMPS.  We are committed to keep at least the current status (even though it is a challenge already) and have raised our requirements and automated tests for code quality (to existing and new code) over time already.  Time permitting, we will work on improving the situation. However, there is plenty of guidance already available and the vast majority of problems people are having originate from impatience or lack of experience, neither of which can be addressed by the LAMMPS developers through expanding documentation and comments in the source code.
",12007030
416,fix adapt: implement scale keyword for diameter/charge and 2d compatibility,open,2020-03-13T19:35:17Z,2020-03-18T10:05:16Z,,COLLABORATOR,"**Summary**

This PR implements 2 main changes to the `fix adapt` command:
- the `scale` keyword can apply to the parameters `diameter` and `charge`
- a `diameter/disc` parameter is defined so that mass changes associated with diameter changes can be consistent for 2d simulations

Bugs fixes and corresponding edits to the documentation are also performed.

**Related Issues**

This closes #1508 , enhancement I created to allow `fix adapt` to change the diameter of polydisperse granular assemblies. This is realized by implementing the `scale` capability for the `diameter` parameter. It is not as general as implementing atom-style variables as I initially suggested in issue #1508 but was much easier implementation and fits many polydisperse applications.

**Author(s)**

Jibril B. Coulibaly, Northwestern University, jibril.coulibaly@northwestern.edu

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

yes

**Implementation Notes**

To implement the `scale` keyword for `diameter` and `charge` parameters, the `FixAdapt::post_constructor()` function is modified so that the internal `Fix Store` are created even when the `reset no` option is used. This allows storing the initial diameter/charge and scaling them in the `FixAdapt::change_settings()` function, the same way `pair` and `bond` parameters are presently scaled.

The implementation of the `diameter/disc` parameter uses a `discflag` to determine the way particles mass should be modified and uses the disc area to define the mass in the `FixAdapt::change_settings()` and `FixAdapt::restore_settings()` functions.

Some non-compliant comments are currently left in the source files to facilitate the review of this PR.

[Documented input files](https://github.com/lammps/lammps/files/4331328/MWE_fix_adapt_PR.zip) showing the effects of the modifications proposed in this PR are enclosed:
 - `in.bug_post_constructor_reset_radius_charge_flag`: shows current bug in `FixAdapt::post_constructor()`
- `in.scale_diameter_charge`: demonstrates implementation of the `scale` keyword for `diameter` and `charge` parameters
- `in.diameter_disc`: demonstrates implementation of the 2d compatibility using `diameter/disc` parameter


**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

","thanks for your contribution. this apparently will need some careful review and i already noticed that there are some issues with included changes and some discussion points. I am writing this comment to acknowledge your submission but also to notify you that it will take some time until we will look into it, as other pending pull requests currently have a higher priority.",12007030
417,[BUG] _pair_lubricate_poly.cpp_issues,open,2020-03-13T15:02:35Z,2020-03-25T01:09:34Z,,NONE,"**Summary**

pair_lubricate_poly.cpp has bugs related to force calculation using a_sq, a_sh, etc. as Ranga from Edinburgh university pointed out. 
The forces are not pairwise symmetric (i.e.lubrication force between a pair of particle i and particle j must be equal and opposite, here it is not so).

secondly the 
if(shearing) branch has a bug in line 127 Ef[1][2] = Ef[2][1] = 0.5 * h_rate[3]/domain->zprd;
It is supposed to be 
Ef[1][2] = Ef[2][1] = 0.5 * h_rate[3]/domain->xprd;


**LAMMPS Version and Platform**

22Aug2018 stable release, Ubuntu 19.0 



**Expected Behavior**

The terms need to be corrected to maintain physics.

**Actual Behavior**

Incorrect force on particles.

**Steps to Reproduce**

open the file and see it. run a lammps script with (lubrication force for polydisperse samples)poly_luburicate. 

**Further Information, Files, and Links**
",@arneshpalanisamy do you have any updates/answers on this issue?,12007030
418,Add method to copy Kokkos neighbor list to CPU list,open,2020-02-26T21:29:37Z,2020-02-27T07:56:23Z,,CONTRIBUTOR,"**Summary**

Add method to copy Kokkos neighbor list to CPU list. Gives speedup when running on GPUs and non-Kokkosized diagnostics request lists.

**Related Issues**

None.

**Author(s)**

Stan Moore (SNL)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No issues.",,12007030
419,Add Kokkos version of compute coord/atom,open,2020-02-25T19:52:04Z,2020-02-26T16:53:40Z,,CONTRIBUTOR,"**Summary**

Add Kokkos version of compute coord/atom.

**Related Issues**

Includes changes in #1895, should be merged after #1895.

**Author(s)**

Stan Moore (SNL)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No issues.",,12007030
420,Add Kokkos version of compute orientorder/atom,open,2020-02-24T20:30:05Z,2020-03-04T20:09:34Z,,CONTRIBUTOR,"**Summary**

Add Kokkos version of compute orientorder/atom

**Related Issues**

None.

**Author(s)**

Stan Moore (SNL)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No issues.",,12007030
421,delay change_box error check on per-atom restart data existing,open,2020-02-20T19:50:56Z,2020-02-25T14:40:15Z,,CONTRIBUTOR,"**Summary**

Allow the change box ortho/triclinic command to be used even if restarting from a restart file that contained per-atom fix info.  Do this by delaying the error check until after all the keywords are scanned.

**Related Issues**

N/A

**Author(s)**

Steve

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

It should simply not throw an error for cases that the error check was too stringent before.

**Implementation Notes**

_Provide any relevant details about how the changes are implemented, how correctness was verified, how other features - if any - in LAMMPS are affected_

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


",@sjplimp will look into it after the stable release.,12007030
422,[Feature Request] Add a portability namespace with functions that perform operations that are non-portable or becoming obsolete,open,2020-02-17T12:53:22Z,2020-02-17T12:53:22Z,,MEMBER,"**Summary**

We can improve the portability and maintainability of the LAMMPS (core) code base by writing generic functions that provide an abstraction of non-portable functionality (e.g. Windows vs. POSIX) or handling of obsolescent APIs (e.g. newer POSIX standards declare APIs obsolete and thus they may go away in the future).

**Detailed Description**

Several parts of LAMMPS use ""ad hoc"" solutions for features that are not available in the standard C/C++ API and require platform specific code. Examples are dynamic loading of shared objects, access to OS version/revision, precise timers (to measure time or to suspend execution for a time shorter than 1 second), file system traversal and similar. Also, several commonly used POSIX compatible functions like `gettimeofday()` or `usleep()` are declared obsolete in more recent standards, so it is to be expected, that those may go away at some time and they would need to be replaced by equivalent replacements, which will usually not have the same API. The largest challenge is to maintain (full) portability to native Windows compilers, but even on Linux systems, some issues are to be expected.

So it would be a good idea to define some wrapper functions in a suitable namespace, that would provide an abstraction to those platform specific solutions, which would then confine the platform specific code to these functions and keep the rest of LAMMPS (more) portable. It would also be worth exploring if any of this abstracted functionality is provided by the C++11 runtime library.
For a transition period, we should include wrappers using the obsoleted API calls so that we can ask users to switch to backward compatible mode, in case compilation with the replacement APIs fails. With CMake, this could possibly also be automated and it could detect which APIs are available and which not.

**Further Information, Files, and Links**

Known issues:
- `usleep()` has been declared obsolete and it is suggested to use `nanosleep()` instead
- `gettimeofday()` is declared obsolete and it is suggested to use `clock_gettime()` instead
- Windows does not provide the `unistd.h` header and most of the functionality is missing
- Windows has multiple functions that differ from their POSIX counterparts, but the POSIX compatible version is available as `function_()` instead of `function()`
- Directory traversal in Windows is different than on Unix/POSIX

Platform specific code for Windows can be identified from preprocessor directives testing for either `__WIN32` or `_MSC_VER`.",,12007030
423,[BUG] no usleep while compiling using gcc-9.1 or Intel Compiler,open,2020-02-14T07:30:36Z,2020-03-25T01:08:55Z,,NONE,"**Summary**

After `git clone -b stable https://github.com/lammps/lammps.git` I do: `cd src; make yes-manybody; make gpu`. Then I get this error:
```
../variable.cpp: In member function ‘int LAMMPS_NS::Variable::next(int, char**)’:
../variable.cpp:677:7: error: ‘usleep’ was not declared in this scope; did you mean ‘sleep’?
```
I use CUDA-10.1, GCC-9.1, openmpi/4.0.1. If I try to use Intel Compiler (15, 2017 or 2019), I get the same error (other words, but the same meaning).

**LAMMPS Version and Platform**

LAMMPS from git, branch `stable` (14.02.2020). Intel Xeon E5-2697 v3, Linux Centos 7.5.

**Expected Behavior**

Succesfull compilation.

**Actual Behavior**

Compiler error - no usleep function.

**Steps to Reproduce**

`git clone -b stable https://github.com/lammps/lammps.git && cd lammps/src; make yes-manybody; make gpu`

**Further Information, Files, and Links**
",@zhum any updates?,12007030
424,Refactor handling of box change information from fixes,open,2020-02-08T20:19:15Z,2020-03-19T21:36:53Z,,MEMBER,"
**Summary**

The changes in this PR allow a more specific tracking of whether multiple fixes are
modifying the same box parameter and error out in that case instead of letting LAMMPS continue and produce bogus simulation results.

**Author(s)**

Axel Kohlmeyer (Temple U)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

Compatibility on the command line is preserved, but (external) source code needs to be adapted, if it was using any of the removed class member variables of the fix class.

**Implementation Notes**

By using a (single) bitmask instead multiple per-category variables, we can now check more specifically which box parameters are manipulated by a fix. During Domain::init() this information is then used to determine if the box is changed per category (like before), but also a new check is added to ensure that no two fixes are modifying the same box parameter. In that case the code will error out.

**Post Submission Checklist**

- [x] The feature or features in this pull request is complete
- [x] Licensing information is complete
- [x] Corresponding author information is complete
- [x] The source code follows the LAMMPS formatting guidelines
- [x] Suitable new documentation files and/or updates to the existing docs are included
- [x] The added/updated documentation is integrated and tested with the documentation build system
- [x] The feature has been verified to work with the conventional build system
- [x] The feature has been verified to work with the CMake based build system

","@sjplimp here is a proposed change to detect cases of multiple fixes modifying the same box parameter and error out. This should also make some existing checks obsolete, e.g. for fix deform from within `fix_nh.cpp` and similar. And we can probably also move the checks for compatibility with shrinkwrap boundaries also into the same test in `Domain::init()` and thus have a more consistent and complete testing. To try it out, you can replace in the melt example the `fix nve` line with:
```
fix		1 all npt temp 1.5 1.5 10.0 iso 0.0 0.0 1000.0
fix		2 all deform 1 x final -1 11 units lattice
```
and it should now error out with:
```
ERROR: Must not have multiple fixes change box parameter x (src/domain.cpp:162)
```

I am leaving the pull request ""open"", so you can push additional changes into it, if you desire. Given the somewhat disruptive nature of the change, it will have to wait until after the stable release before I would want to merge it.
```",12007030
425,Tubular potential force field package for carbon nanotubes,open,2020-02-07T00:41:53Z,2020-03-26T02:54:05Z,,NONE,"**Summary**

This pull request incorporates the tubular potential model (TPM) force field into LAMMPS. This force field is designed for mesoscopic simulations of interacting flexible carbon nanotubes (CNTs) and is based on representation of nanotubes as chains of stretchable cylindrical segments. Further details about this force field can be found in the references listed below and in doc files submitted with this pull request.

This pull request includes the following:

1. TPM nanotube Fortran library (mesont) developed by Alexey N. Volkov, the author of TMP force field, and used to produce results listed in the references below. This library implements basic level functions describing stretching, bending, and intertube components of the force field. Harmonic bending [1] and anharmonic bending-buckling [2] potentials, as well as segment-segment and segment-chain intertube interaction approximations [3,4] are included.

2. USER-MESONT LAMMPS package incorporating mesont Fortran library into the LAMMPS framework:

- mesont/tpm pair style implementing TPM mesoscopic force field. It includes generation of bonds, rearrangement of nanotube nodes into contiguous chains, generation of a list of neighboring chains (to support both segment-chain and segment-segment approximations of intertube interaction), and calls of corresponding mesont Fortran library functions.

- mesont atomic style designed to work with tubular representation of CNTs and use it together with TPM force field.

- mesont/Es, mesont/Eb, mesont/Et, mesont/B, mesont/Es_tot, mesont/Eb_tot, mesont/Et_tot computes to evaluate different components (stretching, bending, intertube) of the potential energy and buckling state. 

3. Potential tables parameterized for single wall CNTs with (10,10) chirality.

4. Two examples of input for simulation of a single CNT bundle and relaxation of a thin CNT film.

5. Tools:

-  TMDPotGen, the code for generation of TMP potential tables for single-walled CNTs with a given chirality (m,n).

- TMDGen, the code designed to generate initial samples composed of straight and dispersed nanotubes of given chirality and length at a given material density. The files are saved in the format compatible with mesont atomic style provided with this pull request.

- dump2vtk, the code for conversion of output from NT simulations written in *.dump format into VTK that can be visualized as a set of tubes (rather than a set of NT nodes) in Paraview or other packages (see images below).

6. Documentation describing the features provided with the pull request.


**Author(s)**

Maxim V. Shugaev, University of Virginia, mvs9t@virginia.edu
Alexey N. Volkov, University of Alabama, avolkov1@ua.edu
Leonid V. Zhigilei, University of Virginia, lz2n@virginia.edu

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No known issues

**Implementation Notes**

A brief description of the implementation details is provided above, in the summary section, and a paper with additional implementation and verification details will be published soon. The correctness of the implementation is verified in the following tests. (1) Energy conservation in NVE simulation of CNT film relaxation performed for segment-segment and segment-chain approximations with harmonic bending potential. (2) Direct comparison of the energy evolution (with separate consideration of bending, buckling, and intertube interaction) and structures predicted by the current LAMMPS implementation and the original Fortran code developed by Alexey N. Volkov and used for the work reported in the references listed below. The simulations are performed for both harmonic bending and anharmonic bending-buckling potentials under NVE and NVT conditions. Both serial and parallel codes were verified in these sets of simulations. (3) Large parallel simulation of film relaxation (see the movie below).

The code is developed in a way to minimize its impact on other components of LAMMPS. In particular, this pull request only requires including several variables to atom.h and the corresponding code for their initiation in atom.cpp. Other additions are localized within the developed package, and no other components of LAMMPS are affected.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

[1] L. V. Zhigilei, C. Wei, and D. Srivastava, Mesoscopic model for dynamic simulations of carbon nanotubes, Phys. Rev. B 71, 165417, 2005.
[2] A. N. Volkov and L. V. Zhigilei, Structural stability of carbon nanotube films: The role of bending buckling, ACS Nano 4, 6187-6195, 2010.
[3] A. N. Volkov, K. R. Simov, and L. V. Zhigilei, Mesoscopic model for simulation of CNT-based materials, Proceedings of the ASME International Mechanical Engineering Congress and Exposition (IMECE2008), ASME paper IMECE2008-68021, 2008.
[4] A. N. Volkov and L. V. Zhigilei, Mesoscopic interaction potential for carbon nanotubes of arbitrary length and orientation, J. Phys. Chem. C 114, 5513-5531, 2010.
[5] B. K. Wittmaack, A. H. Banna, A. N. Volkov, L. V. Zhigilei, Mesoscopic modeling of structural self-organization of carbon nanotubes into vertically aligned networks of nanotube bundles, Carbon 130, 69-86, 2018.
[6] B. K. Wittmaack, A. N. Volkov, L. V. Zhigilei, Mesoscopic modeling of the uniaxial compression and recovery of vertically aligned carbon nanotube forests, Compos. Sci. Technol. 166, 66-85, 2018.
[7] B. K. Wittmaack, A. N. Volkov, L. V. Zhigilei, Phase transformation as the mechanism of mechanical deformation of vertically aligned carbon nanotube arrays: Insights from mesoscopic modeling, Carbon 143, 587-597, 2019.
[8] A. N. Volkov and L. V. Zhigilei, Scaling laws and mesoscopic modeling of thermal conductivity in carbon nanotube materials, Phys. Rev. Lett. 104, 215902, 2010.
[9] A. N. Volkov, T. Shiga, D. Nicholson, J. Shiomi, and L. V. Zhigilei, Effect of bending buckling of carbon nanotubes on thermal conductivity of carbon nanotube materials, J. Appl. Phys. 111, 053501, 2012.
[10] A. N. Volkov and L. V. Zhigilei, Heat conduction in carbon nanotube materials: Strong effect of intrinsic thermal conductivity of carbon nanotubes, Appl. Phys. Lett. 101, 043113, 2012.
[11] W. M. Jacobs, D. A. Nicholson, H. Zemer, A. N. Volkov, and L. V. Zhigilei, Acoustic energy dissipation and thermalization in carbon nanotubes: Atomistic modeling and mesoscopic description, Phys. Rev. B 86, 165414, 2012.
[12] A. N. Volkov and A. H. Banna, Mesoscopic computational model of covalent cross-links and mechanisms of load transfer in cross-linked carbon nanotube films with continuous networks of bundles, Comp. Mater. Sci. 176, 109410, 2020.

A representative image of a thin CNT film after relaxation colored based on the potential energy. The plot illustrates tube buckling (dark red regions) and formation of bundles (blue regions).
![TB 0200](https://user-images.githubusercontent.com/49990208/73982817-fe187780-4902-11ea-95b9-a973d91d36d6.png)

Relaxation of a thick CNT film composed of 8000 200 nm tubes, which corresponds to 1.6M CNT segments in total.
![plot1](https://user-images.githubusercontent.com/49990208/73983392-5ac86200-4904-11ea-9722-fcf96f652995.gif)

Schematic illustration of implementation details:
![CNT](https://user-images.githubusercontent.com/49990208/74197968-75654880-4c2e-11ea-8d8f-5063580a8ce0.jpg)


","We are still working on the stable release. Will get back to you in a few
days.

--
Dr. Axel Kohlmeyer akohlmey@gmail.com http://goo.gl/1wk0
College of Science & Technology, Temple University, Philadelphia PA, USA
International Centre for Theoretical Physics, Trieste, Italy

On Mon, Mar 2, 2020, 15:43 iafoss <notifications@github.com> wrote:

> @akohlmey <https://github.com/akohlmey> , Do you have any updates on this
> request?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/lammps/lammps/pull/1873?email_source=notifications&email_token=AACGTY7KTVORTZDEW6QH5MTRFQLAXA5CNFSM4KRGOZGKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOENQ42GI#issuecomment-593612057>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AACGTY5LZBT6TP6WCHL6N7TRFQLAXANCNFSM4KRGOZGA>
> .
>
",12007030
426,Update Kokkos library to v3.0,open,2020-02-05T15:13:05Z,2020-03-26T01:13:36Z,,CONTRIBUTOR,"**Summary**

Update Kokkos library to v3.0 and remove deprecated code.

**Author(s)**

Stan Moore (SNL)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No issues.","@stanmoore1: I think I got the wrong patch, can you have a look?",12007030
427,Bond style special,open,2020-01-31T21:19:13Z,2020-02-01T03:00:51Z,,COLLABORATOR,"**Summary**

This bond style provides an alternative mechanism to create special bonds by creating an actual bond that calls force->pair->single(). It can be used to create 1-5 (, 1-6, ..) interactions.

**Related Issues**

There have been a few discussions on 1-5 interactions over the years on the mailing list (e.g. 
https://lammps.sandia.gov/threads/msg78113.html)

**Author(s)**

David Nicholson
MIT
davidanich@gmail.com

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No issues.

**Implementation Notes**

There are requirements on the special_bonds command, since this command will create new 1-2, 1-3 and 1-4 interactions. These are detailed in the documentation and error handling.

In this example, I add 1-5 interactions to a united atom C8 molecule. These 1-5 interactions are the weighted by 1, and thus should be equivalent to pairwise ones. The script using bond_style special (in.c8-special) yields the same total energy as the one using the pair potential (in.c8).

[bond_special_example.zip](https://github.com/lammps/lammps/files/4141445/bond_special_example.zip)

**Post Submission Checklist**

- [x] The feature or features in this pull request is complete
- [x] Licensing information is complete
- [x] Corresponding author information is complete
- [x] The source code follows the LAMMPS formatting guidelines
- [x] Suitable new documentation files and/or updates to the existing docs are included
- [x] The added/updated documentation is integrated and tested with the documentation build system
- [x] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [x] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

n/a

","@sjplimp In principle, I think this style is more flexible since it can be used ennumerate any set of special bonds and assign their weights. With that said, I think the functionality that people are looking for (myself included) is 1-5 interactions. 

I can think of one potential use case for this style that may not be easily handled by extending special bonds to 1-5 or 1-6. If you have a large molecule and want to include only bonded interactions and short-range steric hindrances (e.g. the pentane effect  in polyethylene), you could use this style for the short-range pairwise interactions and turn off the actual pair interactions. This could potentially be useful in creating equilibrated melts for polymer models that have dihedrals (as discussed in your article on equilibration: Auhl et al., JCP, 119, 24, 2003). This is not something I have worked on. Just a thought.",12007030
428,HIP back end to GPU package to support AMD GPUs via the ROCm toolkit,open,2020-01-31T20:17:12Z,2020-03-11T15:44:10Z,,CONTRIBUTOR,"**Summary**
This PR is an update for the changes proposed in #1590. It has been merged with the current 'master' and now includes the changes from #1752, #1776, etc. Also, the building instructions in lib/gpu/README has been extended accordingly.

The PR enhances LAMMPS with the capability for using the new HIP backend for GPU-offloading of MD calculations as implemented in the GPU package. The GPU package has been developed originally with the support of CUDA and OpenCL backends using the  geryon library as the unification layer. This PR adds AMD HIP as a third backend to the geryon library. 
The AMD ROCm open source GPU framework provides the driver and the programming tools for new high performance AMD GPUs (including the new Vega20 architecture). ROCm supports OpenCL 2.0 standard and OpenCL 1.2 compatibility mode. However the existing OpenCL back-end of LAMMPS is not compatible with ROCm due to some deviations from the standard (#1368). Some small changes in all *.cu files are required. That is why the current version of GPU package can not be used with ROCm at all. This PR removes this restriction. Besides, the HIP backend is more than 30% faster than the OpenCL backend.
HIP is a part of the AMD ROCm framework. This new HIP-backend can be used either with the hcc compiler for AMD GPUs, or with the nvcc compiler for Nvidia GPUs. In the latter case, the HIP acts as a thin layer between the library and CUDA.

**Related Issues**
This PR is related to issue #1368 and opens a new way of running LAMMPS on AMD GPUs that support ROCm without fixing the current version of the GPU package OpenCL-backend that is not fully compatible with the OpenCL standard required for ROCm. The issue #1368 could be probably closed after merging.

**Author(s)**
Evgeny Kuznetsov (@eokuznetsov), Vladimir Stegailov (v.stegailov@hse.ru, stegailov@gmail.com, @vvsteg), Vsevolod Nikolskiy (thevsevak@gmail.com, @Vsevak)
International Laboratory for Supercomputer Atomistic Modelling and Multi-scale Analysis, National Research University Higher School of Economics, Russia

**Licensing**
By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**
This PR should not break backward compatibility. The solution is implemented as the third backend in addition to existing CUDA and OpenCL. The decision between CUDA, OpenCL, and HIP is a compile-time decision for compiling the library in lib/gpu.

**Implementation Notes**
See #1590.
This PR has been tested using ROCm 2.2-3.0 and different standard LAMMPS input examples on Radeon VII (gfx906), Radeon RX 480 (gfx803), Radeon RX Vega (gfx900),  and Titan V (sm_70) with OpenMPI and MPICH.
The new HIP backend has not been integrated into CMake yet.

**Post Submission Checklist**
- [x] The feature or features in this pull request is complete
- [x] Licensing information is complete
- [x] Corresponding author information is complete
- [x] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [x] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [x] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**


","Now that the stable release is out, this PR is under consideration to be merged. However, it looks we still need support for it in the CMake scripts and also it needs added documentation in the manual.",12007030
429,[Feature Request] KOKKOS - fix rattle / shake,open,2020-01-21T11:01:18Z,2020-01-23T14:21:15Z,,NONE,"**Summary**

Porting fix rattle / shake to kokkos package

**Detailed Description**

As we perform calculations of big systems with a lot of water on a GPU cluster using the Kokkos package we would ask to port the fix shake and/or rattle to the Kokkos package. Is it planned in the future? Thank you in advance!
","@akohlmey Thank you for your advice. We've used the GPU packaged in the past but not in a combination with USER-OMP. I will give it a try and will do some benchmarks in the next days.

@stanmoore1 I am glad to hear that and will be patient.

Thank you both for your fast answer.
",12007030
430,[Feature Request] Improve thread safety,open,2020-01-15T17:36:34Z,2020-01-15T17:36:46Z,,MEMBER,"**Summary**

To satisfy increasing demand from users to run multiple LAMMPS instances concurrently from threads of the same process, we should take some measures to make LAMMPS work correctly under these circumstances.

**Detailed Description**

While it is going to be difficult and a lot of effort to make all of LAMMPS completely thread safe, there are a few steps that can improve the situation.
- Switch from using `MPI_Init()` to `MPI_Init_threads()`
- Document possible problems for using threads with MPI and suggest workarounds
- add a define `-DLMP_THREADSAFE` to include conditional code that can improve thread safety.
- use C++11 mutexes to implement a `utils::lock` and `utils::unlock` function that can be used to protect parts of the LAMMPS code that is not thread safe. If those functions are inline functions and NOPs without `-DLMP_THREADSAFE`, then there would be no speed impact on normal use of LAMMPS.

**Further Information, Files, and Links**

Some more discussion on this subject is in PR #1799
",,12007030
431,tarball is getting pretty big,open,2020-01-14T21:10:32Z,2020-03-25T03:44:04Z,,MEMBER,"```
$ ll -S lammps-*20??.tar.gz
-rw-rw-r--. 1 junghans junghans 110M Dec 11  2018 lammps-stable_12Dec2018.tar.gz
-rw-rw-r--. 1 junghans junghans 104M Aug 22  2018 lammps-stable_22Aug2018.tar.gz
-rw-rw-r--. 1 junghans junghans 104M Jan 14 11:16 lammps-patch_9Jan2020.tar.gz
-rw-rw-r--. 1 junghans junghans 102M Jun  4  2019 lammps-stable_5Jun2019.tar.gz
-rw-rw-r--. 1 junghans junghans 101M Aug 14 14:13 lammps-stable_7Aug2019.tar.gz
-rw-rw-r--. 1 junghans junghans  88M Jun 29  2018 lammps-stable_16Mar2018.tar.gz
-rw-r--r--. 1 junghans junghans  88M Mar  8  2018 lammps-patch_8Mar2018.tar.gz
-rw-rw-r--. 1 junghans junghans  88M Mar  5  2018 lammps-patch_22Feb2018.tar.gz
-rw-rw-r--. 1 junghans junghans  88M Jan 26  2018 lammps-patch_17Jan2018.tar.gz
-rw-rw-r--. 1 junghans junghans  86M Nov  3  2017 lammps-patch_23Oct2017.tar.gz
-rw-rw-r--. 1 junghans junghans  85M Sep 10  2017 lammps-patch_1Sep2017.tar.gz
```
It creeped up slowly, but it is getting pretty big.

Inside the latest tarball:
```
$ du --max-depth=1 -h | sort -h
88K	./.github
396K	./cmake
924K	./python
18M	./tools
29M	./lib
37M	./bench
38M	./src
39M	./potentials
40M	./doc
150M	./examples
349M	.
```
Around 40% are the examples.","I've tried and set up LAMMPS for obtaining a DOI for the latest stable release. This specific release is registered as: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3726417.svg)](https://doi.org/10.5281/zenodo.3726417)

There also is a DOI for **all** LAMMPS releases [https://doi.org/10.5281/zenodo.3726416](https://doi.org/10.5281/zenodo.3726416)
",12007030
432,[Feature Request] KOKKOS NVE integrator for aspherical particles,open,2019-12-19T14:46:43Z,2020-01-03T16:30:26Z,,COLLABORATOR,"**Summary**

KOKKOS NVE integrator for ellipsoidal particles

**Detailed Description**

It seems Langevin dynamics is not supported with the KOKKOS package and aspherical particles. This requires the fix_langevin, which appears to be KOKKOS-enabled, but also the fix_nve_asphere, which is missing.
",,12007030
433,Convert strtok calls to strtok_r for thread safety,open,2019-12-03T21:35:58Z,2020-03-11T14:41:51Z,,NONE,"**Summary**

The C standard library function `strtok` uses internal static data to manage its state, which unfortunately is not thread-safe. In most cases, LAMMPS is unaffected by this. However, the Adaptive MPI runtime virtualizes MPI ranks as user-level threads, which may execute concurrently across kernel threads in the same process. Virtualizing ranks in this way requires thread safety issues to be addressed.

This PR changes all calls to `strtok` in the `src/` folder of the LAMMPS repository to use the thread-safe POSIX standard `strtok_r` function instead. Microsoft Visual Studio does not provide this function, but it handles `strtok` in a thread-safe manner, so a shim is provided in `lmpwindows.h`.

This change aligns well with the modularity concerns behind the LAMMPS project's directive against use of global variables.

**Related Issues**

N/A

**Author(s)**

Aayush Raj (Charmworks, Inc.)
Evan Ramos (Charmworks, Inc.)

**Licensing**

By submitting this pull request, I agree, that our contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No changes.

**Implementation Notes**

This PR consists almost entirely of mechanical changes to the LAMMPS source code.

**Post Submission Checklist**

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system

**Further Information, Files, and Links**

- Adaptive MPI manual: https://charm.readthedocs.io/en/latest/ampi/manual.html
- `strtok_r` documentation: https://linux.die.net/man/3/strtok_r
- thread safety of MSVC's `strtok`: https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/strtok-strtok-l-wcstok-wcstok-l-mbstok-mbstok-l","@evan-charmworks @akohlmey What I suggest for doc
is to add a Howto bullet (one *rst file) to this page:
http://lammps.sandia.gov/doc/Howto.html, under the
General category to complement what is already there.
E.g. Howto_adpative_mpi.rst  Doesn't have to be long,
you can point interested users to other resources.
Take a quick cut at it, and we can give you feedback
from a LAMMPS user perspective.  Also maybe add a
paragraph on thread-safety to Howto_library and/or 12.1.

A bonus would be an example under the examples/COUPLE
dir.  But that can wait for another PR if it is more complicated.

Steve",12007030
434,initial refactoring on AtomVec class,open,2019-11-26T20:46:39Z,2020-03-18T22:51:06Z,,CONTRIBUTOR,"**Summary**

Possible refactorization of atom styles with goal of making it as simple as possible for a  developer
to add a new atom style.

**Related Issues**

N/A

**Author(s)**

Steve

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

Styles that have been refactored should work identically as before.

**Implementation Notes**

The basic idea is that the AtomVec child classes (atom style classes) only specify
lists of peratom variables that need to be communicated in various categories.
The parent AtomVec class now loops over those lists and packs/unpacks them
into communication buffers in a more generic manner than previously.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


","@akohlmey To resolve these conflicts should I do a local merge of current master into
this PR branch?  Then push the result back to GHub?
This push was the new doc pages.  So reading them would be a good start
for you to see what the changes are.  I think it is dramatically simpler now
for someone to write a new atom style.

These are the only undone tasks I think are left on this PR.  For some
of them I likely need to be back in the office:

a) check that this works with fix property/atom q or mol (custom is OK)
b) spin style: needed to rearrange the atom lines in the data file, so that
     all 4 values stored in sp[4] are consecutive.  Julian T may have to change
     his data files
c) Noticed the AWPMD Install.py file is not creating a Makefile.lammps.
    @akohlmey can you check this - not sure if this is also an issue with CMake
d) 2 changes I want to do to the src code in USER-SPH
     change variable ""e"" (too generic) to ""e_sph"", and rename atom_style mess
     (also too generic) to atom_style sph
e) when running tests on every atom style, I needed to make a few changes
     to scripts in the example dirs - I need to include that in the PR
",12007030
435,[Feature Request]  Adding GPU support to pair style meam/c potential,open,2019-11-16T02:04:01Z,2019-11-16T02:34:00Z,,NONE,"Summary:

Request for adding GPU support to pair style meam/c potential.

Detailed Description:

The package gpu command currently doesn’t have support for switching on Newton’s 3rd law. My understanding is that, due to the unavailability of newton on, the pair styles which require newton pair on (like pair style meam/c) do not have GPU support. I want to accelerate some large scale simulations which I am running using MEAM potential. This enhancement will help in decreasing the time required for very large simulations and in increasing the usage of hardware available at HPCs. Is the implementation of “newton pair on” in the package gpu and eventually GPU support for pair style meam planned for the future? 

Thank you,

","Thanks for the clarification.
I read in the documentation that the GPU package does not support ""newton pair on"" because ""more computation is done, but less communication"" but I was not sure about the reason for not having GPU support for pair style meam/c. I hope someone who knows GPU programming finds this enough interesting to work upon it.",12007030
436,added internal fix dummy command to enable more control of fix ordering,open,2019-11-05T20:01:13Z,2020-02-03T22:29:23Z,,CONTRIBUTOR,"**Summary**

Add a fix dummy command which other styles can use to create a placeholder fix (early in the input script) which is replaced later with the desired fix.  This enables the ordering of fixes to correspond to the listing of commands in the input script.  This addresses a bug reported where granular history was not preserved correctly with fix deform or fix balance when they migrated atoms w/out FixNeighHistory having been invoked soon enough to assign history to atoms.

**Related Issues**

N/A

**Author(s)**

Steve

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

Should not, but regression testing should be done.

**Implementation Notes**

_Provide any relevant details about how the changes are implemented, how correctness was verified, how other features - if any - in LAMMPS are affected_

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


","Joel Clemmer has done his granular testing.  So this is now good to merge,
once @stanmoore1 has checked if there are Kokkos changes needed.",12007030
437,Semi Infinite Crack Introduction and Expansion Fix,open,2019-11-05T02:42:43Z,2019-11-06T16:40:02Z,,COLLABORATOR,"**Summary**

This ""fix"" allows users to introduce and propagate a crack of desired mode, or combination of modes (I, II, or III) in a sample of atoms 

**Author(s)**

Nathan Beets, Dr. Diana Farkas

**Licensing**

N/A

**Backward Compatibility**

This code is backwards-compatible

**Implementation Notes**

All source code and input scripts were tested with a variety of stress intensities and Mode combinations.  the .cpp and .h files are located in the /src/ folder of this pull request, and so building the serial or mpi version of LAMMPS after typing ""make-yes-all"" should automatically create an executable with this fix included as a functional command. 

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


",,12007030
438,[Feature Request] Implement Widom insertion method,open,2019-11-03T16:28:05Z,2020-01-17T05:27:37Z,,COLLABORATOR,"**Summary**

Implement in a ""fix"" or ""compute"" the Widom insertion method to compute chemical potentials 

**Detailed Description**

Implementing Widom insertion would enable users to carry out tasks such as:
- parametrization of DPD models based on experimental solubility values following the approach in J Chem Phys. 2017, 147, 094503. doi: 10.1063/1.4992111. 
- direct chemical potential calculations in non-homogeneous liquids following the approach in J Chem Phys. 2018, 149, 072305. doi: 10.1063/1.5024631. The implementation of this approach requires also the coupling of LAMMPS with PLUMED which already exists.
- to speed-up calculations when using soft potentials and performing thermodynamic integration or free energy perturbation (doi 10.1021/ma970383u). For small \lambda values up to 0.15 the free energy can be computed directly by the Widom insertion method.

Most of the code for the geometric insertion & the energy evaluation could be inherited from fix gcmc. Nevertheless, IMHO the code in gcmc needs to be restructured. For instance, the function attempt_atomic_insertion() could be split into separate functions (I) for the insertion, (ii) the energy evaluation & (iii) the acceptance criterion and (iv) the update of all relevant quantities if the insertion is accepted. In this case, there is an additional benefit for GCMC: it will make easier to implement biased schemes for a more efficient grand canonical simulations (for instance see doi 10.1080/00268978000101971 ) as changes in only one place would need to be made.
  
I would like to participate in the implementation.

**Further Information, Files, and Links**

A naive implementation heavily based on the fix gcmc can be found in the attached files.  
[fix_widom.cpp.txt](https://github.com/lammps/lammps/files/3916667/fix_widom.cpp.txt)
[fix_widom.h.txt](https://github.com/lammps/lammps/files/3801726/fix_widom.h.txt)

","Hi, I'm just wondering whether this fix_widom command can be used on multi-processors for full-energy molecules. I remembered that  fix_gcmc was fixed to only one processor because people were reporting error when employing GCMC to full-energy molecule translation and rotation on multi-nodes. However, for widom test particle insertion, we didn't do any translation and rotation (e.g for water). So I'm wondering whether i can delete the error message for full-energy molecules on muti-nodes. Please correct me if I get something wrong.",12007030
439,[Feature Request]  Improve OOM error message,open,2019-10-09T17:56:35Z,2019-10-09T22:17:17Z,,CONTRIBUTOR,"**Summary**

The following type of error can be confusing for users because it doesn't specifically mention ""out of memory"" and the number of bytes is negative.

`
ERROR on proc 4: Failed to reallocate -12624743936 bytes for array bond/react:constraints (../memory.cpp:99)
`

**Detailed Description**

Can we make this more verbose and remove the negative number, something like:

`ERROR on proc 4: Out of memory: Tried to reallocate too many bytes for array bond/react:constraints (../memory.cpp:99)`
","I am not sure that this kind of change is really helping that much. I suspect in many cases, the cause of the wraparound is not that actually that much memory is requested, but either the number is computed from an uninitialized variable (which on Linux boxes often, but not always, will contain 0 due to the way malloc() is implemented, and thus it will not always show), or from doing 32-bit integer operations where 64-bit would be required (typically for large systems). In both cases, it would be sufficient to stop with an even more generic ""memory allocation failure"" message, but then it should print the line of the source, where this allocation actually is being called from. rather then applying the FLERR macro in place and pointing to the line in memory.cpp. the string for the array that is passed along is not that helpful. This is another case of LAMMPS showing its age by using what was considered best practice at times when when serious programs would be written in fortran. I've seen the same kind of thing in several fortran based MD codes (for classical and ab initio MD).",12007030
440,[Feature Request] Create neighbor list exclusions based on custom per-atom properties,open,2019-10-09T14:29:18Z,2019-10-09T14:29:18Z,,MEMBER,"**Summary**

Allow definition of neighbor list exclusion based on custom properties, e.g. via fix property/atom integers or per-atom variables. Similar to `neigh_modify` with options `molecule/intra` and `molecule/inter`.
This is the remainder of the feature set from PR #658 and needs to be re-implemented.",,12007030
441,[Feature Request] Allow different options to handle PBC for computing per-chunk properties,open,2019-10-09T13:40:47Z,2019-10-09T13:40:47Z,,MEMBER,"**Summary**

Computing per-chunk properties for chunks that straddle periodic boundaries can give unexpected results. Some cases need unwrapping of coordinates, some don't, some may require to follow specific protocols to give consistent results. This needs to be implemented somehow. PR #575 contains some suggestions and a discussion, but it doesn't handle the problem in a sufficiently general and consistent way.
",,12007030
442,Optimize PPPM/FFT setup for very large MPI task counts,open,2019-10-08T20:06:24Z,2019-10-08T20:06:24Z,,CONTRIBUTOR,"**Summary**

Implement ideas from PR #713, implemented by Chris Knight (ANL), to speed the setup of FFTs for large MPI rank counts.  The other portions of the original PR #713 have already been added to LAMMPS, some by alternate methods, in other PRs. 

**Detailed Description**

The setup of general communication patterns for FFTs can scale badly for very large MPI rank counts.  Chris has implemented some ideas to minimize this setup time.

**Further Information, Files, and Links**

See PR #713 for coding ideas.
",,12007030
443,[Feature Request] external callback fix supporting other arrays,open,2019-09-27T06:06:14Z,2019-09-30T20:06:16Z,,NONE,"## Summary

I propose to add support for the `external pf/callback` fix type to be able to read and influence arrays other than `x` and `f`.

## Detailed Description

I am writing a coupling of a CFD code ([TCLB](https://github.com/CFD-GO/TCLB.git)) with LAMMPS. The general structure of the LAMMPS code (as shared library) and `pf/callback` fix is perfect for my purposes. But the callback exposes only *positions* and allows only the *forces* to be modified. I would need *radius*, *velocity* and *angular velocity* exposed, and would need to write in external *moment of force*. But maybe it is a good opportunity to add support for something more general.

## Development
**I am happy to modify the code myself**, make all appropriate checks, keep it backwards compatible, and make a Pull Request. I would like to know what you (the authors) think is the best lane to pursue this idea, so my development will be in accordance with the general design of the code.

### Proposed solution
The way I see it now, is that I would add a new function `set_callback_atom`. Which would add a different type of callbacks, and select the size of the persistent storage space (currently `fexternal`). There would be two callbacks, one for *force calculation* and the other for *force application*. One would be called on every `Ncall` iteration, and another on every `Napply` iteration. Both of them would be supplied with the `atom` structure, and the persistent storage array (that is `fexternal` in case of the normal callbacks).

This would not change the existing interface, but would allow for a more general couplings. It would also open the road for the couplings to influence the particles in different ways. Not only apply *moment of force*, but for example modify mass and radius (eg. melting), or other things.

### Notes
Or maybe there is another way for such coupling that is preferred.
",,12007030
444,Fix rigid kokkos,open,2019-09-16T17:04:40Z,2020-01-25T02:37:31Z,,COLLABORATOR,"**Summary**

This is a ""work in progress"" PR for a port of fix rigid to Kokkos.

**Author(s)**

Stefan Paquay @ Brandeis University (stefanpaquay@gmail.com)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

Only adds new features so is backward compatible.

**Implementation Notes**

Ported stuff to Kokkos using Stan's advice. Wrote some notes about the process. To verify I check the examples in examples/rigid.

**Post Submission Checklist**

- [ ] The feature or features in this pull request is complete
- [x] Licensing information is complete
- [x] Corresponding author information is complete
- [x] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


","> For some reason OpenMP is no longer giving the right results. I must have changed something but I don't know what, trying to find it now.
> […](#)
> On Wed, Oct 16, 2019 at 12:51 PM Stan Moore ***@***.***> wrote: Once the OpenMP version is working, I've found the only issues that normally remain with CUDA are missing sync/modify and thread-safety issues that only show up with a large number of threads. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <#1680?email_source=notifications&email_token=AEFLJ7APZIZEZPIPDTT7UNLQO5A7NA5CNFSM4IXE6W72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBNF5CI#issuecomment-542793353>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AEFLJ7BYXOSW56ELRUOWGW3QO5A7NANCNFSM4IXE6W7Q> .

I bet these differences are DOF-related, but I don't remember modifying anything about that at all. Explicitly inheriting dof() and synching before calling the base class' dof does not fix the issue, but just know I've noticed a warning that pops up (from within dof()) with the Kokkos version that does not pop up with the normal version, which should help narrow it down significantly.",12007030
445,[BUG] No rigid body rotation for rigid/nve styles,open,2019-09-03T21:17:06Z,2019-09-27T18:42:21Z,,COLLABORATOR,"**Summary**

The `fix rigid/nve` styles do not perform rotation of granular rigid bodies

**LAMMPS Version and Platform**

07 Aug 2019, Windows

**Expected Behavior**

The orientation of the non-spherical rigid bodies should be altered when getting in contact with one other

**Actual Behavior**

The rigid bodies only undergo translations when using `fix rigid/nve` styles. Rotations are obtained when using `fix rigid` style.

**Steps to Reproduce**

- run input file `in.norot_issue` and visualize dump : no rotation observed using `fix rigid/nve`
- the same simulation with different dimensions of the system/rigid bodies (`in.rot_noissue`) has the expected behavior with rotations for all `fix rigid` commands


**Further Information, Files, and Links**

[in.norot_issue.txt](https://github.com/lammps/lammps/files/3571657/in.norot_issue.txt)
[in.rot_noissue.txt](https://github.com/lammps/lammps/files/3571658/in.rot_noissue.txt)
[clump.mol.txt](https://github.com/lammps/lammps/files/3571680/clump.mol.txt)
","> Thank you very much for closely inspecting the code for `fix rigid` and `fix rigid/nve`.
> 
> Regarding the inertia, I do not think this should occur since the ""issue"" input scales down the molecule size: `molecule mol_poly_clump clump.mol scale 0.0004` which should scale down the inertia as well.
> 
> Do you also obtain identical trajectories when running the ""issue"" input using `fix rigid` instead of `rigid/nve` ?

just re-checked with clean inputs. the trajectories start out identical and then gradually diverge for using fix rigid, rigid/small, rigid/nve, rigid/nve/small

i've modified the inputs to print out some more thermo info. too. 
the difference between the rot and norot variants has to be due to some units related setting. there is probably more that needs to be adjusted than the scaling factor for the molecule files.

i am tempted to close this issue, since i cannot see a convincing argument that something is amiss here.




[comparing-inputs.zip](https://github.com/lammps/lammps/files/3664113/comparing-inputs.zip)
",12007030
446,[BUG] _Fix_ehex_singularity,open,2019-08-30T20:02:10Z,2019-09-03T22:25:58Z,,COLLABORATOR,"**Summary**

The coordinate correction in the rescale function of fix ehex can alter atoms by massive displacements (e30 etc.) when the computed rotational kinetic energy is near zero for the reservoir group. 

**LAMMPS Version and Platform**

August 7 2019 version running on the UFRC supercomputer with intel/2018 and openmpi/3.1.0.

**Expected Behavior**

atoms not exploding into infinity

**Actual Behavior**

large atom deformations; first noticed by debugging a deadlock in a remap function that was the result of a while loop slaving away for potentially e26 iterations.

**Steps to Reproduce**

run the attached input script with the attached model using virtually any number of tasks (works with 1).

**Further Information, Files, and Links**

[Cu_heat_model.txt](https://github.com/lammps/lammps/files/3561299/Cu_heat_model.txt)

[in_ehex.txt](https://github.com/lammps/lammps/files/3561298/in_ehex.txt)
","> @Adrian-Diaz have you tried contacting the author of fix ehex?

I have not.",12007030
447,[BUG]  Segfaults with balance command and KOKKOS,open,2019-08-29T21:45:44Z,2019-08-29T21:45:44Z,,MEMBER,"**Summary**

Running balance examples causes segfaults when running with KOKKOS and CUDA.

**LAMMPS Version and Platform**

master

**Expected Behavior**

An error message due to some neighbor list requirement or a successfully completed simulation.

**Actual Behavior**

Segmentation faults, e.g. in `imbalance_neigh.cpp:80` due to garbage in the neighbor list

**Steps to Reproduce**
```
mkdir build
cd build
cmake -D CMAKE_BUILD_TYPE=Debug -D CMAKE_CXX_COMPILER=$PWD/../lib/kokkos/bin/nvcc_wrapper  -D PKG_KOKKOS=on -DKOKKOS_ENABLE_CUDA=on -DKOKKOS_ARCH=Volta70 ../cmake
make

cd ../examples/balance/
# serial ok
../../build/lmp -in in.balance.clock.static 
# kokkos crashes
../../build/lmp -in in.balance.neigh.static -k on g 1 -sf kk -pk kokkos newton on neigh half
```

**Further Information, Files, and Links**

CI reports:  https://ci.lammps.org/job/lammps/job/master/job/cmake/job/cmake-testing-kokkos-cuda/113/testReport/
",,12007030
448,Omp4 compat,open,2019-08-28T16:09:03Z,2020-03-20T20:12:54Z,,NONE,"**Summary**

- Use macros to support OpenMP in GCC 9.x.
- Reenable OpenMP by default for GCC 9.x in cmake builds.

This replaces the script `hack_openmp_for_pgi_gcc9.sh`, which required manual intervention and modifies the source tree.

**Author(s)**

Michael Lamparski, diagonaldevice@gmail.com

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

This change is backwards compatible.

**Implementation Notes**

A python script was used to perform commit dbb4d0413283.  This will be posted in a following comment.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated

**Further Information, Files, and Links**

See https://github.com/lammps/lammps/issues/1482","Since the automated changes in the second commit are almost certainly out of date by now, I'll rebase this on top of master and regenerate them.",12007030
449,[Feature Request] KOKKOS fix rigid,open,2019-08-06T21:40:03Z,2019-10-01T18:42:07Z,,NONE,"**Summary**
 
Porting fix rigid to KOKKOS

**Detailed Description**

In the past I've benefited significantly from using LAMMPS accelerated with KOKKOS. I am trying to run large scale simulations in GPUs with rigid bodies. Is porting fix rigid planned for the future?
","@Pakketeretet2 

>In FixRigid::FixRigid(), some arrays (let's take the body array as example, because that one has me stumped) are allocated and filled with data, on the host. I want to preserve these values but move them to the Kokkos array because I need them inside device kernels. However, because the host array is filled in the base constructor, the data is already in the host array by the time I would call memoryKK->create().

Ah yes, this is tricky. Normally I would just override the `grow_arrays` method but it is not possible to call a virtual method in the base constructor. I think this is poor design in FixRigid so I would suggest moving this memory allocation in the constructor to an `init` function, then you can override the `grow_arrays` method like normal.

",12007030
450,[BUG]  dump NetCDF  fails when process has no atoms. ,open,2019-06-28T08:22:12Z,2019-06-28T18:04:15Z,,NONE,"**Summary**
When dumping data while using multiple processors, error is raised if one processor does not contain any atoms. 

**LAMMPS Version and Platform**

Tested on versions 30 Apr 2019 and 9 Nov 2018. 

**Actual Behavior**
I created a test file with a large box and create a single atom on one end. If I run it on one core there is no problem. On two cores the error is raised when the dump command is reached. This error is not raised if I create a second atom on the other side of the box. 

ERROR on proc 0: NetCDF failed with error 'NetCDF: Index exceeds dimension bound' in line 917 of ../dump_netcdf.cpp. (../dump_netcdf.cpp:1029)

I will attach a minimal working example that reproduces the error. 

[test.in.zip](https://github.com/lammps/lammps/files/3338222/test.in.zip)
",,12007030
451,Contribute USER-CAC package for multi-scale modeling,open,2019-06-15T22:58:40Z,2020-03-26T02:39:23Z,,COLLABORATOR,"**Summary**

Provides an implementation of the CAC method as presented in:
Chen, Y. Reformulation of microscopic balance equations for multiscale materials modeling. 
The Journal of Chemical Physics 130, 134706, (2009).

The implementation is designed for scalability with both uniform and multi-resolution models.


**Author(s)**

Adrian Diaz (University of Florida) 
Email: adriandiaz@ufl.edu

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

Clear of Conflict (at least without accounting for unforeseen bugs)

**Implementation Notes**

Several styles are implemented to carry forth the calculations required for the CAC method to be solved in parallel; this includes atom, comm, fix, dump, min, and compute styles. In addition several parent interfaces are added to for operation such as neighbor.cpp.

Correctness was verified with several example CAC and pure MD simulations (to make sure changes didn't break the original LAMMPS code execution). A couple of these examples can be found in the examples folder for USER-CAC.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**




","> I think this should work but using const char arrays as members is a grey area for me honestly. Makes me a bit nervous; did it test out simple cases like comm brick and tiled being called? I can try it on my local build otherwise.
> 
> there is nothing to be nervous about. these are just pointers, the strings constants are placed in the data segment, and nothing is ever copied around or needs to be allocated or deallocated. constructors of derived classes are run in the correct order to reset the pointers accordingly. This all works (and is different from cases like pair styles), since the comm_style string is stored inside the Comm class and its derived classes. In the other cases, the style name string is maintained by the class that is storing the instance of the class, e.g Force for Pair, Bond, etc. Again, a lot of that goes back to when LAMMPS was written in Fortran 95 and then re-written in C++ but with the intent of keeping the code structure similar to what it was before to keep the learning curve for the developers manageable.

Alright, Thanks for all the help Axel. ",12007030
452,[Feature Request] implement atom-style variables for fix adapt diameter,open,2019-06-13T03:24:27Z,2020-03-06T17:21:20Z,,COLLABORATOR,"Dear developers,

Would it be possible to enable the use atom-style variables for the 'diameter' attribute of the 'fix adapt' command ? The same way 'fix setforce' accepts atom-style variable for example ? The present 'fix adapt' command only supports equal-style variables: all particles have the same diameter and it is not possible to adapt diameter for polydisperse granular systems.

This would be a very helpful feature as the only way to modify the diameter of polydisperse particles is currently to use 'set diameter' periodically in a loop or in a 'run xx every yy' which can become hefty when a smooth evolution of diameter is needed.

Thank you very much for your consideration.",I will start working on this enhancement,12007030
453,npt/asphere doesn't run on specific groups,open,2019-06-11T02:59:49Z,2019-06-12T14:39:28Z,,NONE,"Hi,

I am trying to simulate a molecule made of one ellipsoid particle and one point particle. I assign these particles groups anisotropic and isotropic and run NPT simulation using 'fix npt/asphere' and 'fix npt' respectively. But I get the following error:
Compute temp/asphere requires extended particles (../compute_temp_asphere.cpp:112)

If I run the same simulation in NVT ensemble with 'fix nvt/asphere' and 'fix nvt', it runs perfectly.
I have attached the files. I appreciate your help!
Thank you!
[npt_asphere_issue.zip](https://github.com/lammps/lammps/files/3274588/npt_asphere_issue.zip)","yes, if all particles are ellipsoids, then there will be no error.
i cannot comment on the second part. i have no experience with gay-berne potentials.",12007030
454,USER-PAFI,open,2019-05-22T12:05:29Z,2020-01-15T17:27:01Z,,COLLABORATOR,"**Summary**

_Briefly describe the new feature(s), enhancement(s), or bugfix(es) included in this pull request._

**Related Issues**

_If this addresses an open GitHub issue for this project, please mention the issue number here, and describe the relation. Use the phrases `fixes #221` or `closes #135`, when you want an issue to be automatically closed when the pull request is merged_

**Author(s)**

Thomas D Swinburne (Corresponding)
CNRS / CINaM Marseille 
swinburne@cinam.univ-mrs.fr

Mihai-Cosmin Marinica
SRMP, CEA, Saclay, France

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**
None

**Implementation Notes**
Only change outside of USER-PAFI directory
Addition of new atom styles pafi and pafipath- minor changes (fully compatible) to atom.h, atom.cpp

gather_peratom_fix library function- minor changes (fully compatible) to library.h library.cpp

USER-PAFI package:
Addition of hp and ave/deviation fixes
Addition of pafi and pafipath atomvecs

Successful compilation in serial / parallel, tested on multiple architectures.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

_Put any additional information here, attach relevant text or image files, and URLs to external sites (e.g. DOIs or webpages)_


","@tomswinburne @axel Hi Tom - I just looked over this PR and your new files.  Sorry for the delay. The free energy method seems like a nice addition to LAMMPS, thanks for contributing it.  Here are a few hi-level comments about the structure of the code:

(a) It's not clear to me why you need new atom styles.  The 3 (N,3) arrays (path, norm, dnorm) seem like they could be defined via the fix property/atom command and given names which fix hp could use to initialize and update them.  That fix would handle all the things that the new atom style is doing, including ghost atom comm in borders().  You could also access the 3 arrays elsewhere in the code, e.g. to dump them as a per-atom value.

(b) Fix ave/deviation looks like a stripped down version of fix ave/atom to operate on one of the 3 vectors.  I'm wondering if you could define a atom-style variable(s) to compute the deviation equation, and then use that as input to fix ave/atom.  I.e. no need for fix ave/deviation.

(c) Maybe there are other features here I missed with regards these 3 quantities.  Do they
all need to persist with the atoms across timesteps.  Or how you initialize them from a data file or restart file.

If you prefer to discuss this off-line, just email me.  We can help reformulate this new feature so it is more LAMMPS-compatible.

Steve ",12007030
455,[BUG] CMake is not propagating all settings to the subordinate builds,open,2019-05-21T16:57:27Z,2019-05-22T16:26:03Z,,NONE,"**Summary**

Using the CMake build with Intel 2019 update 3 and mvapich2 2.3.1 and cmake 3.14.0.  It seems that the configurations for the subordinate packages within lammps are not correctly receiving all of the configuration options that were set when running cmake to configure LAMMPS, causing the build to fail. In addition, the `-xHost` flag is getting added implicitly and inappropriately to the CFLAGS/CXXFLAGS/FFLAGS, which then overrides any previous settings of the `-x` flag, such as my case where I need `-xSSE4.2` because I am building this for a heterogeneous cluster.  That should either be made explicit, removed, or PREpended to the flags rather than appended, as intel always uses the most recently read flag in the case of repeats.  at least one build seems to use `CC=gcc`, which then fails because the CFLAGS contains intel-specific flags that it does not recognize.  another is using `LD=ld` when `LD=xild` was explicitly set in CMake as well as exported to the environment, which then causes failures when running with `-ipo` optimization and it seems to be unable to find intel libraries.

**LAMMPS Version and Platform**

patch release 30Apr2019 on CentOS 7.4 x86_64

**Expected Behavior**

Configurations set in the top level CMake configuration should be applied to all subordinate packages and no package should be implicitly/transparently setting potentially breaking (architecture selection, for instance) compiler flags by default.
**Actual Behavior**

Certain packages within LAMMPS do not seem to be receiving all of the configuration options set when CMake was run, causing builds to fail. Compiler flags such as `-xHost` are being set implicitly and transparently, which causes incorrect binaries to be produced when the user had set their own architecture flags, which they expected to be applied.

**Steps to Reproduce**

Try to configure and build LAMMPS with most of the optional packages enabled, using the Intel compiler with custom compiler optimization flags set and the linkers set to `xiar` for 'ar' and `xild` for 'ld'. See attached CMakeCache.txt below.

**Further Information, Files, and Links**

[CMakeCache.txt](https://github.com/lammps/lammps/files/3203622/CMakeCache.txt)
[CMakeOutput.log](https://github.com/lammps/lammps/files/3203623/CMakeOutput.log)

","> We are trying to improve, but specifically for the automated downloads, you should consider installing the underlying packages separately and then point the LAMMPS CMake to those installations. This is the recommended procedure. The automated download is primarily meant for in-place testing and development.

Maybe that practice should be mentioned in the documentation

> Hmm, I am not sure we can accommodate all these wishes for such specialized builds installing lammps through a real package manager like spack might be the better option. However, we can certainly add an option to not overwrite user specified C/CXX flags.

Isn't the point of using CMake to do this though? especially since at least one of the packages that is messing up seems to also be configured with CMake, and CMake does definitely have support for handling embedded dependencies at the top level.  Thus far, it only seems to be a small number of packages having the issue and most of this should be trivial, such as making sure that the variables set up top are being used in the configuration process for the subpackages.  For sub projects with CMake, it's as simple as passing the same CMake options used up top (with exceptions where necessary) and for things using Automake/autoconf just making sure that flags like CC, CXX, CFLAGS, CXXFLAGS, LD, AR, and so on are used when running those configuration scripts.  I am not too familiar with actually writing CMake files, but I can look into trying to implement some of this as time permits",12007030
456,extends automated neighbor rebuild diagnostics ,open,2019-05-20T18:46:43Z,2020-01-31T17:43:12Z,,COLLABORATOR,"
**Summary**

Adds functionality in the form of a check_distance function and a set_hold_properties function to atom_vec. These serve the role of enabling developers to program their own neighbor rebuild diagnostics for automated neighbor rebuilds. The interface to call these functions is also placed in neighbor.cpp

**Related Issues**


**Author(s)**

Adrian Diaz (University of Florida)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

Clear of Conflict

**Implementation Notes**

The only additional computation for a standard run is three if checks in neighbor.cpp. The implementation was tested with a custom atom vec style that invokes extended objects. Correctness was verified by comparing the outputs of ""check every n"" with the automated rebuild strategy for dynamic simulations.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_


**Further Information, Files, and Links**




",By the way these changes are duplicated in the USER-CAC PR.,12007030
457,comm_tiled_sendself_fix,open,2019-04-11T19:02:21Z,2020-01-31T17:43:19Z,,COLLABORATOR,"**Summary**

Fixes a memory error that would occur when both sendself and recvother in the borders routine were flagged to allocate ghosts in avec->unpack_border. The use of max== as a criterion to grow the array introduces a segfault since the index fed to unpack for the sendself routine assumes array allocation has already taken place for the ghosts received as part of recvother; the role played by the firstrecv array.

**Related Issues**

N/A

**Author(s)**

Adrian Diaz (University of Florida)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

Clear of Conflict

**Implementation Notes**

Segfaulting case with a long cutoff radius was resolved.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_


**Further Information, Files, and Links**




",,12007030
458,[Feature Request] Allow delete_atoms to work on specific species or group,open,2019-04-11T09:22:29Z,2019-10-23T22:50:15Z,,NONE,"**Summary**
The delete atoms command currently is indiscriminate towards the group or species of an atom, and simply works on a given geometric region. It would be useful to have the option to discriminate between types of atoms.

**Use case**
As an example use case, when calculating Li diffusion coefficients through a cathode, it is necessary to remove a small fraction of Li atoms from the pristine system. The porosity command seems perfect for this, but currently deletes atoms indiscriminately. It would be useful to be able to delete a given fraction of atoms of a given type, making what is normally a manual operation on the input file something that can be done in one line and seeded for provenance. 
","Yeah, I agree with mkanski. ",12007030
459,[Feature Request] Implement per-atom stress in pair style reax/c/omp,open,2019-04-06T15:46:13Z,2020-01-31T14:47:28Z,,MEMBER,"**Summary**

Per-atom stress is not properly tallied in pair style reax/c/omp. This should be corrected.

**Detailed Description**

When requesting per-atom stress when running pair style reax/c/omp the results are either missing or double counting some contributions. for more details and test inputs, please see issue #1411 
",,12007030
460,Kokkos exchange comm for fixes ,open,2019-03-28T21:22:58Z,2020-01-25T02:36:00Z,,COLLABORATOR,"**Summary**

This pull request implements exchange communication for fixes on Kokkos. This is a particular issue when using FixNeighHistory, which would fallback to classic communication. We expect to improve performance when using cuda-aware MPI implementations due to reduced number of copies to host memory.

**Related Issues**

No issue related to this pull request.

**Author(s)**

Denis Taniguchi (denis.taniguchi@gmail.com) - Newcastle University

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

No backward compatibility issues.

**Implementation Notes**

Major changes can be seen in CommKokkos::exchange_device. After all AtomVec exchanges are performed we loop over the fixes flagged as extra_grow. We call pack_exchange_kokkos/unpack_exchange_kokkos in each of them. Each fix has a separate call to MPI_Irecv/MPI_Send/MPI_Wait. Since there is no guarantee that the unpack in fixes will happen in the same order as in AtomVec (remember that we rely on atomic operations to define the index of the new incoming atom in AtomVec) we need a new interface that returns the indices assigned to each unpacked atom. That was included in AtomVecKokkos with empty default implementation (returning 0). Those indices are used while unpacking data for fixes ensuring that we correctly match the info in AtomVec with info in fixes.
This pull request include implementations for AtomVecSphereKokkos, FixNeighHistoryKokkos, and FixWallGranKokkos already compatible with the new feature in CommKokkos.
If you use AtomVecs not compatible with exchange comm for fixes we fallback to classic comm. This is verified using a new unpack_exchange_indices_flag member variable in AtomVecKokkos. If you wish to make your AtomVec* compatible with fixes exchange, set unpack_exchange_indices_flag to 1 and implement:
```
int unpack_exchange_kokkos(
  DAT::tdual_xfloat_2d &k_buf,
  DAT::tdual_int_1d &indices,
  int nrecv, int nlocal, int dim,
  X_FLOAT lo, X_FLOAT hi,
  ExecutionSpace `space);
```
Fixes must provide:
```
virtual int pack_exchange_kokkos(const int &nsend,DAT::tdual_xfloat_2d &buf,
                                 DAT::tdual_int_1d k_sendlist,
                                 DAT::tdual_int_1d k_copylist,
                                 ExecutionSpace space, int dim,
                                 X_FLOAT lo, X_FLOAT hi);
virtual void unpack_exchange_kokkos(DAT::tdual_xfloat_2d &k_buf,
                                    DAT::tdual_int_1d &indices,int nrecv,
                                    int nlocal,int dim,X_FLOAT lo,X_FLOAT hi,
                                    ExecutionSpace space);
```
Implementation was validated using the attached case, which is a variation of the chute case.
An example of command to run the case is given bellow:
`mpirun -np 3 lmp_kokkos_cuda_mpi -k on g 3 -sf kk -pk kokkos neigh half -in in.gran`

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted. Delete lines that don't apply_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

[in.gran.txt](https://github.com/lammps/lammps/files/3020186/in.gran.txt)
[data.chute.txt](https://github.com/lammps/lammps/files/3020188/data.chute.txt)

","Yes, sorry for the delay, this is on my to-do list.",12007030
461,[BUG] _Possible errors in unit conversion factors and/or units documentation_,open,2019-03-24T12:48:14Z,2020-01-31T14:46:41Z,,CONTRIBUTOR,"**Summary**

As part of the extension of the OpenKIM testing framework to support LAMMPS simulator models, I have written a program to convert units between the LAMMPS unit systems.  To conform to LAMMPS, I have used physical constants from NIST (https://physics.nist.gov/cuu/Constants/Table/allascii.txt).  To test my code, I verified that I could reproduce the conversion factors given in update.cpp in the LAMMPS code.  I get agreement for almost all factors, but there are several discrepancies that I would like to bring to your attention.  These may be due to documentation errors on the LAMMPS units page site or bugs in update.cpp.

Here is a summary of the discrepancies I see:

1. Electron system (mvv2e factor). According to the LAMMPS documentation, the velocity units in electron are ""Bohr/atomic time units [1.03275e-15 seconds]"" (note this is not the standard atomic time units). See:

https://sourceforge.net/p/lammps/mailman/lammps-users/thread/BCA2BDB2-BA03-4280-896F-1E6120EF47B2@caltech.edu/

With this definition, I get a value of mvv2e = 1.0. However, the value in update.cpp is mvv2e = 1.06657236. This value is obtained if the velocity is in Bohr/femtosecond not Bohr/atu_electron. So it appears that either the documentation is wrong or the value in update.ccp is wrong.

2. Electron system (ftm2v factor). Same issue as in item 1. With the velocity in ""Bohr/atomic time units 1.03275e-15 seconds]"", I obtain ftm2v = 0.968288666437. Whereas the value in update.cpp is ftm2v = 0.937582899. As in 1, the value in update.cpp is obtained if the velocity is taken to be bohr/fs.

3. Electron system (vxmu2f). The units documentation does not provide dynamic viscosity units for the electron system. If I guess that the units are Pascal*second, then I get vxmu2f = 32.9114634037. The value in update.cpp is vxmu2f = 3.39893149e1. As in item 1, this discrepancy is corrected if the velocity is taken to be bohr/fs. (Note in addition to dynamic viscosity, the LAMMPS documentation page also does not provide units for the electron system for torque (I guessed hartree), and density (I guessed amu/bohr^3), and should be provided.)

4. Micro system (qe2f). Based on the units reported in the LAMMPS documentation, I get a value of qe2f = 1000.0. The value in update.cpp is qe2f = 1.0.  The factor of 1000 probably comes from the force unit which is picogram-micrometer/microsecond^2 for this system. A possible error in update.cpp is that picogram is 10^-12 relative to a gram, but 10^-15 relative to kg (which is the base SI unit). In any case, I don't see an error on my end.

5. Nano system (qe2f). Based on the units reported in the LAMMPS documentation, I get a value of qe2f = 160.21766208. The value in update.cpp is qe2f = 1.0.  The difference is 100*1.6021766208. The 100 probably comes from a similar issue as in item 4, and the 1.6021766208 term comes from the electron charge. According to the LAMMPS documentation, charge for the nano system is in ""multiple of electron charge (1.0 is a proton)"", so to obtain a force in ""attogram-nanometer/nanosecond^2"" it is necessary to multiply by the electron charge. This appears to be missing in the update.cpp expression.

**LAMMPS Version and Platform**

The LAMMPS code was not run, only comparisons were made to values in update.cpp. The version is 28 Feb 2019.
",@sjplimp this should be added to your TODO list,12007030
462,[BUG] gpu_package seems not to follow OpenCL 2.0 and does not compile with ROCm 2.2,open,2019-03-17T04:22:18Z,2019-06-26T21:32:30Z,,COLLABORATOR,"The current version of LAMMPS is compiled with the opencl variant of the gpu_package under Ubuntu 18.04 (14.15 kernel) with ROCm 2.2. There is one Radeon VII GPU in the system.

The standard ```example/melt``` benchmark provides the following errors messages during execution
```
../../src/lmp_mpi -sf gpu -pk gpu 1 -in in.melt 
LAMMPS (28 Feb 2019)
Lattice spacing in x,y,z = 1.6796 1.6796 1.6796
Created orthogonal box = (0 0 0) to (67.1838 67.1838 67.1838)
  1 by 1 by 1 MPI processor grid
Created 256000 atoms
  Time spent = 0.0260232 secs

--------------------------------------------------------------------------
- Using acceleration for lj/cut:
-  with 1 proc(s) per device.
-  with OpenCL Parameters for: GENERIC
--------------------------------------------------------------------------
Device 0: gfx906, 60 CUs, 16 GB, 1.8 GHZ (Mixed Precision)
--------------------------------------------------------------------------

Initializing Device and compiling on process 0.../tmp/AMD_3903_69/t_3903_71.cl:582:17: error: variables in the local address space can only be declared in the outermost scope of a kernel function
    __local int n_stride;
                ^
/tmp/AMD_3903_69/t_3903_71.cl:621:5: error: variables in the local address space can only be declared in the outermost scope of a kernel function
    store_answers(f,energy,virial,ii,inum,tid,t_per_atom,offset,eflag,vflag,
    ^
/tmp/AMD_3903_69/t_3903_71.cl:395:20: note: expanded from macro 'store_answers'
    __local acctyp red_acc[6][BLOCK_PAIR];                                  \
                   ^
/tmp/AMD_3903_69/t_3903_71.cl:656:17: error: variables in the local address space can only be declared in the outermost scope of a kernel function
    __local int n_stride;
                ^
/tmp/AMD_3903_69/t_3903_71.cl:694:5: error: variables in the local address space can only be declared in the outermost scope of a kernel function
    store_answers(f,energy,virial,ii,inum,tid,t_per_atom,offset,eflag,vflag,
    ^
/tmp/AMD_3903_69/t_3903_71.cl:395:20: note: expanded from macro 'store_answers'
    __local acctyp red_acc[6][BLOCK_PAIR];                                  \
                   ^
4 errors generated.
Done.
Initializing Device 0 on core 0...Done.

Setting up Verlet run ...
  Unit style    : lj
  Current step  : 0
  Time step     : 0.005
OpenCL error in file 'geryon/ocl_kernel.h' in line 219 : -48.
```
If I am not mistaken the reason of these error messages is that the gpu_package does not follow the OpenCL C specifications required by OpenCL 2.0. 

See a similar problem discussed here [https://github.com/RadeonOpenCompute/ROCm/issues/674](url)",What is the current way to get the HIP version to build and run?.,12007030
463,Optimized fix/pour,open,2019-03-06T18:16:54Z,2019-06-27T04:20:52Z,,MEMBER,"**Summary**

Adds an optimized fix `pour` implementation accessible as `pour/opt` to reduce time needed for insertions. I need to work on this, do some more testing myself, which is why I'm creating only a draft PR.

**Author(s)**

@rbberger  (Temple U)

**Licensing**

By submitting this pull request, I agree, that my contribution will be included in LAMMPS and redistributed under either the GNU General Public License version 2 (GPL v2) or the GNU Lesser General Public License version 2.1 (LGPL v2.1).

**Backward Compatibility**

needs testing, some folks from SNL have been testing it

**Implementation Notes**

Adds a generic cell list implementation to the Granular package which is the data structure used to reduce the number atoms checked during insertion.

**Post Submission Checklist**

_Please check the fields below as they are completed **after** the pull request has been submitted_

- [ ] The feature or features in this pull request is complete
- [ ] Licensing information is complete
- [ ] Corresponding author information is complete
- [ ] The source code follows the LAMMPS formatting guidelines
- [ ] Suitable new documentation files and/or updates to the existing docs are included
- [ ] The added/updated documentation is integrated and tested with the documentation build system
- [ ] The feature has been verified to work with the conventional build system
- [ ] The feature has been verified to work with the CMake based build system
- [ ] A package specific README file has been included or updated
- [ ] One or more example input decks are included

**Further Information, Files, and Links**

Motivated by my previoius work I did in my PhD thesis a long, long time ago.

",,12007030
464,[Proposal] Use RST and convert images generated from LaTeX to use MathJax,open,2019-02-14T09:49:43Z,2020-01-31T16:25:24Z,,MEMBER,"**Summary**

In case we adopt the changes from #1320, the biggest hurdle for switching to using the RST file format as source for the documentation has been removed. This would be further simplified and more consistent, if we take all equations in latex format and integrate them as MathJax. This would also allow us to use LaTeX typesetting to refer to parameters from those equations in the text.

**Detailed Description**

The markup used by txt2html is simple and has served well as a tool to have a single source for web-based and printable PDF documentation. However, the switch to RST based html generation via Sphinx has significantly improved the visual appeal and accessibility of the online documentation. But since we are still using the .txt files and convert them to RST with a script, we cannot take full advantage of RST and are limited by some of the ""hacks"" that were used to get desirable typesetting through txt2html, which would be done differently in plain RST. With the added complexity in the documentation, creating a reasonably well looking and typeset PDF file of the documentation has become increasingly difficult.

Thus one possible path to move forward is the following:
- abandon the txt2html processing and using .txt markup for the documentation
- instead do one complete conversion and instead import the resulting .rst files and use those as source for the future documentation.
- incrementally replace all generated images of equations typeset with LaTeX with inline MathJax. once completed, that should simplify maintenance of the documentation and generation of html and pdf manual
- incrementally review the RST markup and replace constructs resulting from txt2html hacks with cleaner RST based formatting
- provide an archive of the latest updated .txt files with the corresponding .html files and generated .pdf files as ""Legacy Documentation"".

_This most certainly will need to be discussed in person, but we can use this issue as the document where we review and rewrite the proposed steps and ultimately chosen approach. So both, comments below as well as edits to this text are welcome_

","@rbberger  I tried to make it easy to review the conversion and, eventually, correct problem equations. But there are a lot of files and it probably needs to be done file by file. If you look at my pull request or if you go to my repo on github and look at branch iss1334proofOfConcept, you will find the two folders described below. A directory list will give you a list of files. A diff will allow you to see what changes were made:

From my pull request:
_src/modifiedRst/*.rst files: I wrote new script (doc/utils/converters/lammpsdoc/eqImg2mathjaxInline.py) to find image links in the rst files for images from the Eqs folder and substitute math markup straight out of the .tex file for each .jpg. Rather than slap the new versions down into the src folder wholesale, I thought it would be easier to review this conversion if each reviewer picked a few of the modified files for documentation for which they are familiar, moved those into src, rebuilt, and then could review only those selected pages in the output._

_src/safeRst/*.rst: The script above makes a copy of the original rst file in this folder. This is a bit redundant but makes it simple to diff the two versions._

The above approach assumes everyone owns a diff tool that makes reviewing 188 diffs relatively easy. If you don't, I believe I can produce text output (like a patch file) from mine that I can attach here if needed.

I did not have any idea how to make fixes to the tex markup or even how to reliably spot problems on my own so I didn't start on that.",12007030
465,[BUG] Incorrect handling of atom_style ellipsoid data with read_data and write_data,open,2019-02-13T08:17:43Z,2020-02-01T02:10:23Z,,MEMBER,"**Summary**

Using `read_data` and `write_data` does not enforce or create correct data files

**LAMMPS Version and Platform**

LAMMPS 4 Jan 2019 and 8 Feb 2018, Linux x86_64 fedora 29 and ubuntu
 
**Expected Behavior**

`read_data` should enforce consistent settings in the data file, and `write_data` should write out correct and consistent data files.

**Actual Behavior**

`read_data` accepts lines in the `Atoms` section that set the ellipsoid flag, even though there are no ellipsoids defined in the header and thus no bonus storage allocated. Consequently, also the necessary `Ellipsoids` section is not required. `write_data` does not write out this information, thus the data file can be read in, but will cause segfaults due to the missing bonus data.
_Describe the actual behavior, how it differs from the expected behavior, and how this can be observed.  Try to be specific and do **not** use vague terms like ""doesn't work"" or ""wrong result"".  Do not assume that the person reading this has any experience with or knowledge of your specific area of research._

**Steps to Reproduce**

running `lmp -in in.ellipse.txt` will cause segfaults when trying to change the ellipse parameters or starting a run. The data file is inconsistent and `read_data` does not catch it.

Adding a `write_data` command to the gay-berne ellipsoid example produces an incorrect data file.

**Further Information, Files, and Links**

reported on [lammps-users](https://sourceforge.net/p/lammps/mailman/message/36585849/)

[data.txt](https://github.com/lammps/lammps/files/2859408/data.txt)
[in.ellipse.txt](https://github.com/lammps/lammps/files/2859409/in.ellipse.txt)

",,12007030
466,updated comm tiled to have multi style ghost communication,open,2019-01-21T19:37:35Z,2020-02-05T18:54:57Z,,COLLABORATOR,"## Purpose

Enables comm style tiled to use multiple cutoff lengths to communicate ghosts in the borders function.

## Author(s)

Adrian Diaz (University of Florida)

## Backward Compatibility

Clear of Conflict

## Implementation Notes

Additional sendbox arrays are defined, allocated, and then defined using the multiple cutoffs available in cuttype from the Neighbor class. The changes were tested with a lead tellurium/ lead selenium interface model using both single and multi settings.


",@Adrian-Diaz I've merged in the current master which had changes to `comm_tiled.cpp`. I've tried to resolve the merge conflicts. Please review the current state and verify that it still works.,12007030
467,Plug memory leaks in fix bocs,open,2018-09-06T14:32:46Z,2019-11-04T16:25:22Z,,MEMBER,"## Summary

Fix bocs does malloc()/calloc() small chunks of memory all over the place but doesn't seem to free() them.

## Type of Issue

Bug report

## Detailed Description (Enhancement Suggestion)

The code should use either stack allocations or call free() on 

## LAMMPS Version (Bug Report)

Observed with version 5 Sep 2018, but has been in the code since the package was added.

## Expected Behavior (Bug Report)

No memory leak.
","@mdelyser As you can see from radio silence, once my teaching semester began, I lost all time to work on this defect. But we were on the right track and making progress. I'm hoping that once my fall semester is over, mid-December or so, I can use some of my free weeks till mid-January to work on and perhaps even complete this small project. I'll be in touch with you in December to see if you are still up for working together on this.
",12007030
468,Problem with critical strain s0 in pair_style peri/pmb,open,2018-06-30T15:02:04Z,2018-06-30T15:02:04Z,,NONE,"## Summary

In the pair_peri_pmb.cpp source the implementation of equation 9 of www.sandia.gov/~mlparks/papers/pd-lammps-cpc.pdf is slightly different from what stated by the theory; the present implementation happens to work when all the alpha's and the s00's are the same, but fails to make the crack easier when we have a smaller s00 at the interface. 

## Type of Issue

Bug Report

## LAMMPS Version (Bug Report)

LAMMPS 30March2018 version

## Expected Behavior (Bug Report)

From our understanding of the theory as presented in www.sandia.gov/~mlparks/papers/pd-lammps-cpc.pdf (equation 9 in particular), the parameters s00 and alpha need not be the same for all the pair interactions (at least in principle). Our idea was to use a smaller s00 for the interactions between the two blocks initially at contact, so to determine an area where a crack is more likely to initiate. We would prefer this solution as opposed to the one we found suggested in the mailing list, i.e. to weaken the 'effective spring constant' of the Peridynamic bond, as this choice would affect also the short-range repulsion (eq.10a of the same article).

## Actual Behavior (Bug Report)

This fails to work in the present implementation. Specifically, in the pair_peri_pmb.cpp source we find the line: (L266)

MAX(s0_new[i],s00[itype][jtype] - (alpha[itype][jtype] * stretch))    

not to implement equation 9 mentioned above: instead of really minimizing the stretch within the horizon of particle i, in the code the total quantity s0 is maximized. 
This implementation happens to work when all the alpha's and the s00's are the same, but fails to make the crack easier when we have a smaller s00 at the interface (because the MAX will not select that smaller value). If different alpha's and s00's (depending on the particles type) appear within the horizon of the i particle, the MAX over the total quantity s0 is in general different from a combination of the appropriate s00 for that bond with the MIN over the stretch for that particle.

We tried to modify pair_peri_pmb.cpp (see attachments), but our version currently works only in the special case alpha=0.

## Steps to Reproduce (Bug Report)

This is a simple&quick input file (also attached) which illustrates the problem we are referring to:

#--------------------------------------------------------------------------
# INITIALIZATION
#--------------------------------------------------------------------------

units           si
boundary        p p p
atom_style      peri
atom_modify     map array
neighbor        0.0001 bin

#--------------------------------------------------------------------------
# SETUP
#--------------------------------------------------------------------------

# TRIALBOX
lattice         sc 0.00025
region          trialbox block 0 0.006 0 0.006 0 0.006 units box
create_box      2 trialbox

############################################

region          constraintA block 0.00275 0.00326 0.00275 0.00326 INF 0.00025 units box
region          fixedA block 0.00275 0.00326 0.00275 0.00326 0.0002501 0.00075 units box
region          movingA block 0.00275 0.00326 0.00275 0.00326 0.0007501 0.00125 units box

############################################

# CREATE ATOMS (bottom to top)
create_atoms    1 region constraintA
create_atoms    1 region fixedA
create_atoms    2 region movingA

############################################

# GROUPS (bottom to top)
group           constraint region constraintA
group           fixed region fixedA
group           moving region movingA
group           lower union constraint fixed

#--------------------------------------------------------------------------
# POTENTIAL
#--------------------------------------------------------------------------

pair_style      peri/pmb

# PMMA --> parameters from 10.1016/j.prostr.2016.06.022
pair_coeff      *   *   7.0247e+22   0.000751      0.013      0.0

#pair_coeff      1   2   7.0247e+22   0.000751      0.0065      0.0

#--------------------------------------------------------------------------
# PROPERTIES SETUP
#--------------------------------------------------------------------------

set             group all density 1180
set             group all volume 1.5625e-11
velocity        all set 0.0 0.0 0.0 sum no units box

#--------------------------------------------------------------------------
# FIXES
#--------------------------------------------------------------------------

fix             F1 lower nve
fix             F2 moving move linear NULL NULL 1.0 units box
fix             F3 constraint setforce 0.0 0.0 0.0

compute         Cdam all damage/atom

#--------------------------------------------------------------------------
# RUN
#--------------------------------------------------------------------------

timestep        5e-08
thermo_style    custom step time #...
thermo          20
dump            D1 all custom 20 dump.peri id type x y z c_Cdam

run             20000

#--------------------------------------------------------------------------

The results obtained with both LAMMPS compiled with the original pair_peri_pmb.cpp and the one compiled with our fixed version are identical because here all s00's are the same.
However, if line number 50

#pair_coeff      1   2   7.0247e+22   0.000751    0.0065   0.0

is uncommented, the difference is clear. The fixed version produces a crack at the interface between particles of type 1 and particles of type 2 as their s00 is just half of that acting between 1-1 and 2-2
interactions. The uncorrected LAMMPS instead produces exactly the same trajectory as with the commented line (all equal s00's).

However, note that this example has alpha=0. Our version would fail with any alpha != 0, e.g. the usual alpha=0.25 choice.
The reason for this failure is the need to break the bonds symmetrically as prescribed by the min in the first line of equation 9. We tried to implement this symmetrization of the bond breakage in the commented lines from L283 to L295, but the results are quite bad.

## Further Information, Files, and Links

[pair_peri_pmb.cpp.gz](https://github.com/lammps/lammps/files/2151822/pair_peri_pmb.cpp.gz)
[in.pmb.peri.gz](https://github.com/lammps/lammps/files/2151823/in.pmb.peri.gz)
www.sandia.gov/~mlparks/papers/pd-lammps-cpc.pdf",,12007030
469,[Feature Request] Implement bond style python,open,2018-04-03T14:32:29Z,2018-05-11T15:23:18Z,,MEMBER,"## Summary

It would be nice to have a bond style python similar to pair style python to conveniently test custom bonded interactions.

## Type of Issue

Feature request

",,12007030
470,Fallback to bin/nsq method when corresponding halffull method does not exist,open,2018-01-18T04:49:32Z,2018-08-04T09:13:44Z,,NONE,"## Summary

_Fallback to bin/nsq method when corresponding halffull method does not exist_

## Type of Issue

_'Suggestion for an Enhancement'_

## Detailed Description (Enhancement Suggestion)

_Since not all kind of half lists have its corresponding ""halffull"" method, but the ""morph_halffull()"" function set the request to ""halffull"" when there is a corresponding full list request, then the halffull request cannot be fulfilled. I suggest to fallback to the ""bin"" or ""nsq"" method in that case._
e.g.
```
  irequest = neighbor->request(this,instance_me);
  neighbor->requests[irequest]->newton = 2;
  neighbor->requests[irequest]->ghost = 1;
  neighbor->requests[irequest]->id = 0;
  irequest = neighbor->request(this, instance_me);
  neighbor->requests[irequest]->newton = 2;
  neighbor->requests[irequest]->ghost = 1;
  neighbor->requests[irequest]->id = 1;
  neighbor->requests[irequest]->half = 0;
  neighbor->requests[irequest]->full = 1;
```

_The list with id=0 is a half list of list with id=1, so the morph_halffull make the first request halffull, but there is not a npair_halffull_ghost method, making the program exits with an ""unknown pair style""._
_I suggest fallback to bin method in such case, based on the 11Aug17 version, I have the following modification making this work:_
```
729,740d728
<     flag = choose_pair(requests[i]);
<     if (flag < 0) {
<       if (requests[i]->halffull){
<       requests[i]->halffull = 0;
<       flag = choose_pair(requests[i]);
<       }
<     }
<     lists[i]->pair_method = flag;
<     if (flag < 0) {
<       error->all(FLERR,""Requested neighbor pair method does not exist"");
<     }
<
749a738,742
>
>     flag = choose_pair(requests[i]);
>     lists[i]->pair_method = flag;
>     if (flag < 0)
>       error->all(FLERR,""Requested neighbor pair method does not exist"");
```
_and make the loop like this:_
```
  for (i = 0; i < nrequest; i++) {
    flag = choose_pair(requests[i]);
    if (flag < 0) {
      if (requests[i]->halffull){
        requests[i]->halffull = 0;
        flag = choose_pair(requests[i]);
      }
    }
    lists[i]->pair_method = flag;
    if (flag < 0) {
      error->all(FLERR,""Requested neighbor pair method does not exist"");
    }

    flag = choose_bin(requests[i]);
    lists[i]->bin_method = flag;
    if (flag < 0)
      error->all(FLERR,""Requested neighbor bin option does not exist"");

    flag = choose_stencil(requests[i]);
    lists[i]->stencil_method = flag;
    if (flag < 0)
      error->all(FLERR,""Requested neighbor stencil method does not exist"");
  }
```
So if there is not a halffull method, the request will be handled by bin/nsq method.
## LAMMPS Version
_11Aug17_

",@dxhisboy this has been idle for many months now. Obviously people are waiting for your input...,12007030
471,[Feature Request] Symmetrical boundary conditions,open,2017-09-13T03:58:58Z,2018-05-09T01:35:44Z,,CONTRIBUTOR,"Thanks to the user package SMD (Smoothed Mach Dynamics) SPH can be used to simulate solid materials. Often the problems simulated possess symmetries. However, due to the lack of symmetrical boundary conditions in LAMMPS, such symmetries cannot be exploited in order to reduce the size of the domain to compute.

It would be nice to implement symmetrical boundary conditions in LAMMPS to be able to reduce the size of certain simulations of solid materials. Apparently it would not be very easy to do. But is it something that the developers have thought about? ","@abbatux there have been discussions about this a very long time ago. You might find them in the mailing list archives. If I remember correctly, it was determined, that for example a wedge shaped cell would cause lots of difficulties to implement in the face of LAMMPS' domain decomposition based parallelization. There are also ambiguities in what has to happen with atoms at the tip of the wedge.
So before even thinking about the technical implementation, one would have to come up with unambiguous ways to implement such symmetric cells in a general fashion.",12007030
472,[Feature Request] Implement Double-band EAM Potential Style,open,2017-09-11T16:08:04Z,2018-05-09T01:36:17Z,,NONE,"## Summary
Introduce in LAMMPS the posibility to use the double-band EAM potentials, where the contributions from s-band and d-electrons are treated separately. An example of such a system is FeCr, which is widely used as a model alloy for many construction materials in civil and nuclear/fusion energetics.

## Type of Issue

Suggestion for an Enhancement

## Detailed Description (Enhancement Suggestion)

The EAM potentials with double-band support should be integrated  in LAMMPS from the box. 

## Further Information, Files, and Links

The description of the double-band EAM potential formalism can be taken from:

- P. Olsson et al.. Two-band modeling of alpha-prime phase formation in Fe-Cr. PHYSICAL REVIEW B 72, (2005) 214119 [Link to the article](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.72.214119)
- G. Bonny et al. Iron chromium potential to model high-chromium ferritic alloys. Philosophical Magazine Vol. 91, No. 12, 21 April 2011, 1724–1746  [Link to the article](http://www.tandfonline.com/doi/abs/10.1080/14786435.2010.545780)
","There is a feasible method to implement  Double-band EAM Potential Style in lammps just with input script like this:
`pair_style     hybrid/overlay eam/fs eam/fs`

Another way, I have modified the eam/fs pair.cpp(spline) to double band style, but it is not universal. The cpp file needs to be modified appropriately if anyone else wants to use it.
",12007030
473,Add MSVC support and add __declspec to library interface,open,2017-08-27T19:22:20Z,2017-09-26T22:43:30Z,,COLLABORATOR,"## Summary

To be able to use LAMMPS as a dll-library on windows, additional keywords like `__declspec(export)` and `__declspec(import)` to have these functions available. A few compilation issues with MSVC also need to be taken care of. 

## Type of Issue

Suggestion for an Enhancement

## Detailed Description (Enhancement Suggestion)

I discussed this with @rbberger during the LAMMPS workshop. I want to create a Windows build of Atomify where LAMMPS is being used as a library. A typical way to create libraries on Windows is 
```
#if COMPILING_DLL
    #define DLLEXPORT __declspec(dllexport)
#else
    #define DLLEXPORT __declspec(dllimport)
#endif
```
and use DLLEXPORT in front of the exported library functions. -DCOMPILING_DLL is used during compilation of the library. This part I could do myself, but there are other issues when compiling LAMMPS with MSVC compilers since

1. MSVS does not support [variable-length arrays](https://stackoverflow.com/questions/5246900/enabling-vlasvariable-length-arrays-in-ms-visual-c), and 
2. there were some other compilation issues @rbberger mentioned that he needed to discuss with @sjplimp to pick a good way to solve them.

@rbberger can add more details on this.","just for reference, I already have a branch (https://github.com/rbberger/lammps/commit/f6def26d16863ec004d0b27a79a6fc5c10660e84) with some quick hacks to make it ""work"". But I need to go over them and solve those issues properly / discuss with Steve or Axel.",12007030
474,Possible memory leak in USER-MGPT package,open,2017-07-14T18:16:45Z,2020-01-31T14:25:16Z,,MEMBER,"## Summary

There seems to be a memory leak in the USER-MGPT package

## Type of Issue

Bug report

## Detailed Description (Enhancement Suggestion)

When running the example inputs for pair style mgpt with an executable compiled with GCC using the -fsanitize=address flag, the following report of a memory leak is produced.

```
=================================================================
==6292==ERROR: LeakSanitizer: detected memory leaks

Direct leak of 88392 byte(s) in 1 object(s) allocated from:
    #0 0x7ff24023d040 in operator new[](unsigned long) (/lib64/libasan.so.3+0xc8040)
    #1 0x26fe20f in potdata::readpot(char const*, char const*, double) ../mgpt_readpot.cpp:351
    #2 0x61c00000fe27  (<unknown module>)

Direct leak of 12160 byte(s) in 1 object(s) allocated from:
    #0 0x7ff24023d040 in operator new[](unsigned long) (/lib64/libasan.so.3+0xc8040)
    #1 0x26fd826 in potdata::readpot(char const*, char const*, double) ../mgpt_readpot.cpp:517
    #2 0x61c00000fe27  (<unknown module>)

Direct leak of 12160 byte(s) in 1 object(s) allocated from:
    #0 0x7ff24023d040 in operator new[](unsigned long) (/lib64/libasan.so.3+0xc8040)
    #1 0x26fd88c in potdata::readpot(char const*, char const*, double) ../mgpt_readpot.cpp:518
    #2 0x61c00000fe27  (<unknown module>)

Direct leak of 116 byte(s) in 1 object(s) allocated from:
    #0 0x7ff24023d040 in operator new[](unsigned long) (/lib64/libasan.so.3+0xc8040)
    #1 0x26fc138 in potdata::readpot(char const*, char const*, double) ../mgpt_readpot.cpp:239
    #2 0x61c00000fe27  (<unknown module>)

SUMMARY: AddressSanitizer: 112828 byte(s) leaked in 4 allocation(s).
```
This looks like potential parameter data is not freed when the pair style is deleted. This is not a big issue for normal inputs with a single, but may become a problem for people running many short computations with different settings via loops or the library interface.

## LAMMPS Version (Bug Report)

6 July 2017

## Expected Behavior (Bug Report)

All memory allocated by LAMMPS classes should be freed

## Actual Behavior (Bug Report)

The instrumented executable reports that over 100kB are leaked each for the example inputs

## Steps to Reproduce (Bug Report)

Compile LAMMPS using a recent GCC g++ compiler (tested with version 6.x) and add -fsanitize=address to the compiler and linker flags. Then run the input decks in `examples/USER/mgpt`

## Further Information, Files, and Links

n/a
","@sjplimp can you please verify, if the authors of this code are still maintaining their contribution to LAMMPS? This code has not seen *any* updates by the authors since it original integration 5 years ago. An this issue is now open for 2 1/2 years. All changes since have been to keep it consistent with the rest of LAMMPS. ",12007030
475,[Feature Request] hybrid monte carlo,open,2017-07-07T14:31:56Z,2018-05-10T06:12:45Z,,COLLABORATOR,"I'd like to submit a feature request for Hybrid Monte Carlo (HMC) simulations. At present, one can do mixed MD/MC using a combination of 'fix gcmc' and a time integration fix. However, there's no way to accept/reject the MD moves that take place between the steps when 'fix gcmc' is invoked. I believe that such accept/reject rules are formally necessary to provide detailed balance for proper sampling. (Velocity re-randomization is also necessary, but this can be currently implemented by the user looping between 'velocity create' and 'run' commands.)

I'm not sure of the best implementation for this feature. I think it'd probably be best to add a keyword to 'fix gcmc' to do this, and then LAMMPS would save the state at the end of the Monte Carlo moves and compare it to the energy of the state when the Monte Carlo moves next begin.

I might be able to implement this myself, but I wanted to check first to see if this feature is already being developed and to see what else the developers or other users thought about this.","@akohlmey right now I'm finishing my thesis, but I will be able to resume on this project in a few weeks. Thank you.",12007030
476,[Feature Request] Add support for Extended-Lagrangian scheme for fix qeq,open,2017-05-30T17:47:56Z,2018-05-11T14:40:44Z,,COLLABORATOR,"I'm working at Vashishta's group and I showed them some benchmarks of `user-reaxc` on KOKKOS CUDA. On a 6 million atom system, `fix qeq` is ~75% of computation time (performed every step). One of the students here mentioned a rather new paper from Ken-ichi Nomura (Vashishta's group): [https://pdfs.semanticscholar.org/dc21/afb1d69b186fb2a65ac97fda7be7f2ad989f.pdf](https://pdfs.semanticscholar.org/dc21/afb1d69b186fb2a65ac97fda7be7f2ad989f.pdf) (_An extended-Lagrangian scheme for charge equilibration in reactive
molecular dynamics simulations_, Ken-ichi Nomura, Patrick E. Small, Rajiv K. Kalia, Aiichiro Nakano
, Priya Vashishta).

In this work, the regular `qeq` is performed once (or possibly regularly), and after this, every `qeq` step lets the charges follow the trajectory defined by a Lagrangian which is almost computationally free, but still very accurate. 

This should of course not replace regularer `qeq`, but would be a nice addition which in my case would speed up my simulation by a factor 4.

I might give it a try myself, but I don't know the details of `qeq` that well.","FWIW, a more conservative approach would be to use some extrapolation scheme to improve the initial guess and thus reduce the time to convergence (or in the most extreme case, just use a fixed number of iterations). i've seen this used successfully, e.g. in the form of the ASPC scheme in Kolafa, J. Comp. Chem., 25(3), 335 (2003) applied to the CPMD and CP2k codes for improving the BOMD performance while also removing the systemic loss of energy when using the previous electronic ground state as initial guess. Quite funny how BOMD-like and CPMD-like methods seem to be leapfrogging each other. ;-)",12007030
477,[Feature Request] Add '*' option for fix reax/c/bonds to output one file per timestep ,open,2017-05-12T18:51:39Z,2018-03-20T20:28:27Z,,CONTRIBUTOR,From mail list: It would be really handy if the fix reax/c/bonds command had the '*' option to output one file per timestep ,,12007030
478,Pair style meam/spline has inconsistent trajectories for different number of processors,open,2017-05-09T22:25:20Z,2017-05-10T02:24:28Z,,MEMBER,"As noted in the comments for PR #466, the basic meam/spline pair style implementation has an inconsistency (most likely in the forces) when using different number of processors. the following input:
```
units		metal
lattice		fcc 4.147
region		box block 0 5 0 5 0 5
create_box		1 box
create_atoms	1 box
pair_style      meam/spline
pair_coeff      * * Si_1.meam.spline Si
mass            * 28.085
velocity        all create 300 112233
fix             1 all nve
thermo          10
run 100
```
produces the following energies for 1 MPI rank:
```
Step Temp E_pair E_mol TotEng Press 
       0          300   -1821.1127            0   -1801.7624   -237937.88 
      10    296.65632   -1820.8969            0   -1801.7623   -237036.31 
      20    291.14195   -1820.5401            0   -1801.7612   -233933.15 
      30    306.76662   -1821.5462            0   -1801.7595   -223659.07 
      40    376.20999   -1826.0258            0     -1801.76   -207049.56 
      50     500.8805   -1834.0683            0   -1801.7611   -187888.89 
      60      669.457   -1844.9434            0   -1801.7629   -176424.02 
      70    870.48021   -1857.9107            0    -1801.764   -162538.37 
      80    1101.3965   -1872.8053            0   -1801.7644   -151658.19 
      90     1350.669   -1888.8883            0   -1801.7691   -139529.15 
     100    1565.0428   -1902.7144            0   -1801.7679   -121260.66 
```
and for 2 MPI ranks:
```
Step Temp E_pair E_mol TotEng Press 
       0          300   -1821.1127            0   -1801.7624   -237937.88 
      10    297.30117   -1820.9385            0   -1801.7623   -236872.43 
      20    293.16807   -1820.6709            0   -1801.7613   -233082.91 
      30    310.51297   -1821.7879            0   -1801.7596   -222363.54 
      40      381.149   -1826.3447            0   -1801.7603   -205392.25 
      50    503.58087   -1834.2435            0   -1801.7621   -188351.04 
      60    661.22248   -1844.4123            0   -1801.7629   -174562.04 
      70    857.73128   -1857.0883            0    -1801.764   -161851.76 
      80    1101.0317   -1872.7837            0   -1801.7663   -151178.09 
      90    1359.7113   -1889.4731            0   -1801.7706   -137839.29 
     100    1579.2071   -1903.6327            0   -1801.7725   -119203.22 
```
and for 4 MPI ranks:
```
Step Temp E_pair E_mol TotEng Press 
       0          300   -1821.1127            0   -1801.7624   -237937.88 
      10    297.28158   -1820.9373            0   -1801.7624   -236805.11 
      20    293.13847    -1820.669            0   -1801.7613    -232639.7 
      30    309.97086    -1821.753            0   -1801.7597   -221303.58 
      40    379.08226   -1826.2111            0     -1801.76   -206311.05 
      50    503.63517   -1834.2463            0   -1801.7615    -189600.6 
      60    668.81808   -1844.9015            0   -1801.7621   -168134.87 
      70    875.68455   -1858.2465            0   -1801.7641   -160117.03 
      80    1110.2925   -1873.3794            0   -1801.7646    -152731.4 
      90    1364.9951   -1889.8104            0   -1801.7671   -136621.17 
     100    1616.6913   -1906.0509            0    -1801.773   -120935.96 
```",,12007030
479,attempt_molecule_deletion_full in fix gcmc gives wrong energy with reaxff,open,2017-04-16T21:42:17Z,2019-07-09T15:55:31Z,,COLLABORATOR,"I'm working on water loading inside zeolites with ReaxFF and fix_gcmc using the KOKKOS package (`kokkos_omp`, 1 MPI process, 32 threads) with LAMMPS (11 Apr 2017). I've used the `intra_energy` flag to remove the internal energy of the water molecule in the potential (this may be wrong?). The gcmc command I've used is

`fix gcmc newAtoms gcmc 200 2000 ${nwater} 0 $(1234+v_i) 723 0.0 1.0 mol water pressure 1.0 fugacity_coeff 1.00100907349 overlap_cutoff 0.4 intra_energy -245.49798`

The results I'm getting seems to be wrong (explained below). I'm printing debug information to track what's going on and one of the things I've seen is the following (my debug output):

```
Inserted atom 2944 in molecule 28 of type 3 at 3.66323, 11.1574, 5.71532
Inserted atom 2945 in molecule 28 of type 4 at 3.40518, 11.1564, 6.68145
Inserted atom 2946 in molecule 28 of type 4 at 3.85346, 12.0943, 5.4221
Trying to insert with ngas=0, beta=0.696015, natoms_per_molecule=3, zz=1.01609e-05, volume=65163.2
energy_before=-434197, energy_after=-434444, energy_intra=-245.498, delta_energy=-1.1066
   GCMC insertion ACCEPTED with deltaphi=1.43031 (deltaE = -1.1066)
```

which seems fine. But a couple of MC tries later (without any dynamics in between), the same molecule is tried to be deleted:

```
picked molecule 28 for deletion
Found 3 atoms in deleted molecule
Trying to delete with ngas=3, beta=0.
696015, natoms_per_molecule=3, zz=1.01609e-05, volume=65163.2
energy_before=-434444, energy_after=-434410, energy_intra=-245.498, delta_energy=279.725
   GCMC deletion ACCEPTED with deltaphi=1.09917e+64 (deltaE = 279.725)
```

Note that the `energy_before` in the insert step is not identical to the `energy_after` after deletion. For me it would make sense that once that molecule is removed, we would get the exact same energy as before we inserted it. The energies should be symmetric due to identical states. 

What could be different? 

Attached is the modified fix_gcmc.cpp that prints the debug output to gcmc.log.txt and a system reproducing the behaviour above. Just run `./run.sh` assuming `lmp_kokkos_omp` exists in PATH.
[reax_gcmc_bug.zip](https://github.com/lammps/lammps/files/924594/reax_gcmc_bug.zip)
","Thanks! I understand the problem better now.  With full_energy molecule deletions, the bonded contributions to the intramolecular energy are turned off term-by-term in toggle_intramolecular(). However, there are also nonbonded intramolecular terms, such a per-atom energy (ReaxFF) or LJ in your example.  Maybe we can also turn these off in toggle_intramolecular() or account for them in some other way.  I need to think about it. ",12007030
480,[Feature Request] implement kspace slab correction for triclinic boxes,open,2017-03-10T21:49:34Z,2018-05-11T14:36:30Z,,COLLABORATOR,"According to the docs, http://lammps.sandia.gov/doc/kspace_modify.html
>  The slab keyword is not currently supported by Ewald or PPPM when using a triclinic simulation cell.

... which is supported by the checks at ewald.cpp:109 ""Cannot (yet) use Ewald with triclinic box and slab correction""
and pppm.cpp:192 ""Cannot (yet) use PPPM with triclinic box and slab correction""

From my reading of Yeh and Berkowitz, subtracting the z-dipole should not be fundamentally more difficult in non-orthogonal box shapes, and is indeed implemented straightforwardly already on pppm.cpp:2944.  The only issue I noticed when trying it out was that the coordinates, x[i][2], refer to scaled versions and need to be transformed back into Cartesian when the dipole is summed on line 2954.

Rather than do that, the simple formula in Ballenger, JCP 140, 161102 makes it really tempting to implement corrections for arbitrary box shapes by accepting a tensor, 'J' and computing the whole dipole.
","my previous remarks about the tilt factors are a red herring. due to the way how LAMMPS defines a tilted box, the z-direction spacing is not affected. however, the changes required to support this are quite invasive, since the effect of `slab_volfactor` has to be taken into account for the regular kspace calculation.
the suggested change of transferring the coordinates from lamda to cartesian coordinates works fine, but the rest of the computation, needs to take the change in volume into account.",12007030
481,USER-DPD fix_rx segfaults when input file is invalid,open,2017-01-20T00:25:24Z,2017-04-05T15:07:46Z,,CONTRIBUTOR,"USER-DPD fix_rx segfaults when its input file (such as kinetics.dpdrx) is invalid (for example, if there is a stray line). Ideally it should error out gracefully and notify the user the file is invalid without seg-faulting.

<pre>
==129793== Invalid read of size 1
==129793==    at 0x4088098: strlen (vg_replace_strmem.c:454)
==129793==    by 0x1017C00B: LAMMPS_NS::FixRX::post_constructor() (fix_rx.cpp:319)
==129793==    by 0x10449587: LAMMPS_NS::Modify::add_fix(int, char**, int) (modify.cpp:900)
==129793==    by 0x10153083: fix (input.cpp:1559)
==129793==    by 0x10153083: LAMMPS_NS::Input::execute_command() (input.cpp:797)
==129793==    by 0x1015373B: LAMMPS_NS::Input::file() (input.cpp:244)
==129793==    by 0x100233B3: main (main.cpp:47)
==129793==  Address 0x0 is not stack'd, malloc'd or (recently) free'd
<pre>
","AFAIK, this is still an open issue, but we can't work on it until after April 15th.",12007030
482,Move replicated constants and enumerators to header files,open,2017-01-05T22:58:44Z,2017-01-06T03:50:29Z,,MEMBER,"LAMMPS has several constants that need to be kept in sync across multiple files. They are usually not included in headers because of their generic names. However, in the interest of code maintainability, the current practice should be abandoned in favor of adding those constants to suitable header files and either to base class definitions (example `Timer`) or to separate namespaces (example `FixConst`).","I think this is a good change. However, there are a LOT of enums in LAMMPS, and I think any change here should be done as a whole, and not incrementally, to avoid collisions, which could be a significant amount of work.",12007030
483,[Feature Request] fix ave/atom etc should produce standard deviation,open,2016-11-03T19:57:36Z,2018-10-07T17:09:12Z,,COLLABORATOR,"When using the ave/atom (and similar averaging commands) it makes sense to be able to produce the standard deviation for the quantity. 

For instance `stddev yes` will add N extra columns with the standard deviations for each N values.

What is your view on this?","This comes with some caveats. While its easy to calculate some number < (x-<x>)^2> for some series of data, this is only the variance, IFF the sampled x'es are statistically independent, which depends on details of the observable and the system.

To estimate the variance, data should be blocked and the convergence after subsequent blocking transformations should be studied. See e.g. the algorithm in Flyvbjerg Pedersen J.Chem.Phys. 1, 461 (1989).  http://dx.doi.org/10.1063/1.457480  Not that trivial...",12007030
484,Slowdown for fix gcmc with regions and molecule files,open,2016-10-18T21:43:09Z,2018-05-09T18:59:42Z,,MEMBER,"Reported on lammps-users by Evan Lowry and confirmed by Aidan Thompson as follows:

```
The loss of performance occurs when combining the region and mol keywords.
After every MC move, the entire list of active GCMC atoms/molecules is
regenerated from scratch. With region and molecule, this requires calculating
the the center-of-mass of every molecule. This turns out to be a very expensive
operation.  The best solution would be replace the full list generation with a
list update operation.
```

Example input files and output are available at the links below.

[log_gcmc_region.txt](https://github.com/lammps/lammps/files/537413/log_gcmc_region.txt)
[log_gcmc.txt](https://github.com/lammps/lammps/files/537416/log_gcmc.txt)
[in_gcmc.txt](https://github.com/lammps/lammps/files/537417/in_gcmc.txt)
[in_gcmc_region.txt](https://github.com/lammps/lammps/files/537414/in_gcmc_region.txt)
[system.txt](https://github.com/lammps/lammps/files/537418/system.txt)
[mtn.txt](https://github.com/lammps/lammps/files/537415/mtn.txt)
",,12007030
485,"some compute_*_chunk.cpp files missing a ""setup()"" causes errors",open,2016-08-29T13:07:50Z,2018-03-20T20:29:05Z,,MEMBER,"Reported by Efrem Braun on lammps-users:

Hello,

I believe I found a bug I'd like to report, running LAMMPS with the latest stable release from July 30, 2016. When I run the following, I get no errors:

```
#settings
units                real
atom_style      bond
timestep          1.0
#atom and FF definitions
read_data        ""system.data""
pair_style         lj/cut 14.0
pair_coeff         1 1 0.195 3.75
bond_style       harmonic
bond_coeff       1 240 1.54
#compute
compute           cc2 all chunk/atom molecule
compute           moleculeAngMom all angmom/chunk cc2
fix                     1 all ave/time 1 1 1 c_moleculeAngMom[1] file tmp.out mode vector
#run
velocity             all create 300 49254
fix                      2 all nve
run                    100
```

If I replace the first fix with:

```
variable             AngMomVar vector c_moleculeAngMom[1]
fix                      1 all ave/time 1 1 1 v_AngMomVar file tmp.out mode vector
```

I then obtain the error:
`ERROR: Variable formula compute array is zero length (../variable.cpp:1407)`

So even though all I'm doing is putting the compute moleculeAngMom into a variable before I try to output it, I get this error. If I use ""compute vcm/chunk"" instead of ""compute angmom/chunk,"" I get no error.

I believe this is because compute_angmom_chunk.cpp does not run ""compute_array()"" before the empty-array error-checking in variable.cpp. This is because compute_angmom_chunk.cpp does not contain a ""setup"" function like compute_vcm.chunk.cpp. When I add in the following to compute_angmom_chunk.cpp:

```
void ComputeAngmomChunk::setup()
{
  compute_array();
}
```

And I put this function's declaration into compute_angmom.chunk.h, then everything runs smoothly. There are probably more elegant ways to fix the problem than the one I used, but I'm not too familiar with the source code.

Similar things apply to other compute_*_chunk.cpp files, where \* includes omega, inertia, gyration, torque, dipole, and perhaps others I missed.

Efrem Braun
","well, at the very least, this behavior needs to be documented and a suitable warning and explanation added. i'll take a look and see if there is a practical way to sort this out properly.
",12007030
486,PyLammps: Add access to thermo output and dump information,open,2016-08-19T07:45:02Z,2017-05-11T22:03:51Z,,MEMBER,"This is a feature request from multiple participants of the [LAMMPS Tutorial at Temple University in August 2016](https://sites.google.com/site/templesummermd/):

> It would be great if there is an easy way to access the thermo output and data generated by dumps. E.g. by fix ave/chunk.
## Current state:
- [x] Access to thermo output data
- [x] Access to dump data (e.g., ave/chunk)
- [ ] Add documentation about these features
",please don't close issues until the PR is merged.,12007030
487,Initialize pointers to zero before any errors can be thrown,open,2016-08-19T03:22:51Z,2018-11-29T04:48:24Z,,COLLABORATOR,"When LAMMPS is used as a library, it could make sense to have the process still running after a LAMMPS crash (i.e. invalid command). As of now, several of the classes with arrays have pointers that aren't set to NULL before the first possible error. 

One example is fix_ave_chunk.cpp which can throw an error in the first line in the constructor:
if (narg < 7) error->all(FLERR,""Illegal fix ave/chunk command"");

where the pointer count_list isn't set to NULL until the end of constructor.

What can happen is that an error is thrown (before pointers were NULLed) so that if the LAMMPS destructor is called, it tries to destroy memory that never was allocated, but pointer value is non-zero.
## What to do

In all classes, NULL all pointers before any error can be thrown.
## List over remaining directories:
- [x] src
- [x] src/ASPHERE
- [x] src/BODY
- [x] src/CLASS2
- [x] src/COLLOID
- [x] src/COMPRESS
- [x] src/CORESHELL
- [x] src/DIPOLE
- [x] src/GPU
- [x] src/GRANULAR
- [x] src/KIM
- [x] src/KOKKOS
- [x] src/KSPACE
- [x] src/MANYBODY
- [x] src/MC
- [x] src/MEAM
- [x] src/MISC
- [x] src/MOLECULE
- [x] src/MPIIO
- [x] src/OPT
- [x] src/PERI
- [x] src/POEMS
- [x] src/PYTHON
- [x] src/QEQ
- [x] src/REPLICA
- [x] src/RIGID
- [x] src/SHOCK
- [x] src/SNAP
- [x] src/SRD
- [x] src/VORONOI
- [ ] src/USER-ATC
- [x] src/USER-AWPMD
- [ ] src/USER-CG
- [ ] src/USER-COLVARS
- [x] src/USER-DIFFRACTION
- [ ] src/USER-DPD
- [ ] src/USER-DRUDE
- [ ] src/USER-EFF
- [ ] src/USER-FEP
- [ ] src/USER-H5MD
- [ ] src/USER-HADRESS
- [ ] src/USER-INTEL
- [ ] src/USER-LB
- [ ] src/USER-MANIFOLD
- [ ] src/USER-MGPT
- [ ] src/USER-MISC
- [ ] src/USER-MOLFILE
- [x] src/USER-OMP
- [ ] src/USER-PHONON
- [ ] src/USER-QMMM
- [ ] src/USER-QTB
- [ ] src/USER-QUIP
- [ ] src/USER-REAXC
- [ ] src/USER-SMD
- [ ] src/USER-SMTBQ
- [ ] src/USER-SPH
- [ ] src/USER-TALLY
- [ ] src/USER-VTK
","Yeah I see that I don't get to do it for some time. You can unassign me and when I get to do it, I can tell you :) ",12007030
488,USER-DPD rx should not hardcode indices into atom->dname and atom->dvector arrays,open,2016-08-06T15:20:50Z,2016-08-08T15:44:29Z,,MEMBER,"The various ""rx"" components in USER-DPD has an arbitrary requirement, that no other feature in LAMMPS may use fix property/atom. This is against the modular design of LAMMPS and not really needed. For the same reason, there is no need to define two fix property/atom instances; one should be enough. all that would be needed to achieve the same features, would be generating a table (or map) that identifies which specific index in the atom->dname[] array matches with the desired property and then access them accordingly. 
","yeah, i was looking into this while working on the weighted load balancing, where i initially thought, that using fix property/atom would be the right way to store the per-atom weight parameter and was looking at other uses of it. but since property/atom by construction has a global namespace, things are a bit complicated and i got stuck trying to resolve access conflicts between fix balance and the balance command. in the end, i went for a simpler solution and used fix store (which is only internal and does not support communicating properties to ghost atoms) instead, which is sufficient in my case. fix property/atom is beneficial, if you have properties that you want to read in from a data file and restart as well. you just need to give them uniquely identifiable names, e.g. DPD_RX_spec_1  for species/type 1 and so on and then look them up via atom->find_custom(). to speed up the process, you could simply store those indices in an atom->ntypes size array. if fix store is sufficient, you simple need to give it a suitable fix-ID and then look up the fix and then refer to the stored data.

HTH,
      axel.
",12007030
489,"implement generic logger class to replace ""logfile"" and ""screen""",open,2016-07-20T20:14:57Z,2018-09-08T15:07:07Z,,MEMBER,"we should have a logger class with semantics similar to C++ iostreams, which would make logging simpler and less programming effort, as all choices whether output should be sent to ""screen"" or ""logfile"" would be delegated to the logger. using iostream semantics would allow to get rid of temporary fixed size buffers. VMD uses something similar. it would be nice to also have an option to choose verbosity, i.e. assign ""urgency"" levels, so that output would be either very terse or more verbose.
the error class already serves some of the same purposes, but primarily suffers from requiring a char \* argument. perhaps those can be combined. using a little preprocessor trickery, it may be possible to also hide the FLERR macro.
","My lousy 2 cents:

I'm not sure precisely what kind of design you have in mind, but I hope it is not the iostream API itself! This is one of the most awkwardly designed parts of C++, and I think it would bring a great loss of clarity to the code base to see it replace the existing C formatting routines.

And I'm not just talking about the verbose and ugly syntax. Treating formatting flags as printable values was a terrible idea, and the iostream API has many gotchas:

* Some flags like `setprecision` are sticky, which can lead to unintended side-effects.
* Some other flags like `setw` are automatically reset under a seemingly arbitrary selection of cases.
* Just weird inconsistencies everywhere.  E.g. you can't print 8-bit integers because `unsigned char` and `signed char` are for some reason formatted like `char` (despite all three being recognized as independent types in the language)

Having something closer to the C API would not only make migration easier, but I honestly believe it would lead to less bugs in the end.  The main troubles with this approach though are:

* I doubt that a function with a signature like `template<class... Args> void function(const char *format, Args... args)` could be type-checked or linted with a static analyzer in the same manner that `printf` and friends are. (a macro might work, but... ick)
* Be it a macro or template, it will be tricky to avoid code bloat.",12007030
490,adjust fix poems to detect other cell changing fixes,open,2016-06-16T14:08:42Z,2018-05-09T22:42:37Z,,MEMBER,"fix poems explicitly looks for fix npt and nph and requires to be run after them. this probably needs to be investigated and extended to apply to all cell shape changing fixes?
explore if Fix::box_change_size is correctly used across all fixes.
","@sjplimp the test seems to be used consistently, but it explicitly only checks for `fix npt` and `fix nph`. Many more fixes can change the box. So a test for `Fix::box_change_size` or `Fix::box_change_shape` being non-zero may be a more reliable test.",12007030
491,Convert analytical approximation for erfc() to use double precision version,open,2016-06-14T19:45:47Z,2019-10-09T13:18:17Z,,MEMBER,"Apply the following change to all coul/long pair styles, this will improve the accuracy and precision of computing the analytical coulomb potential for use with long-range solvers significantly.

``` diff
diff --git a/src/KSPACE/pair_lj_charmm_coul_long.cpp b/src/KSPACE/pair_lj_charmm_coul_long.cpp
index 2c709a3..f4695d9 100644
--- a/src/KSPACE/pair_lj_charmm_coul_long.cpp
+++ b/src/KSPACE/pair_lj_charmm_coul_long.cpp
@@ -30,18 +30,14 @@
 #include ""neighbor.h""
 #include ""neigh_list.h""
 #include ""neigh_request.h""
+#include ""math_special.h""
+#include ""math_const.h""
 #include ""memory.h""
 #include ""error.h""

 using namespace LAMMPS_NS;
-
-#define EWALD_F   1.12837917
-#define EWALD_P   0.3275911
-#define A1        0.254829592
-#define A2       -0.284496736
-#define A3        1.421413741
-#define A4       -1.453152027
-#define A5        1.061405429
+using namespace MathSpecial;
+using namespace MathConst;

 /* ---------------------------------------------------------------------- */

@@ -144,11 +140,10 @@ void PairLJCharmmCoulLong::compute(int eflag, int vflag)
           if (!ncoultablebits || rsq <= tabinnersq) {
             r = sqrt(rsq);
             grij = g_ewald * r;
-            expm2 = exp(-grij*grij);
-            t = 1.0 / (1.0 + EWALD_P*grij);
-            erfc = t * (A1+t*(A2+t*(A3+t*(A4+t*A5)))) * expm2;
+            expm2 = expmsq(grij);
+            erfc = my_erfcx(grij) * expm2;
             prefactor = qqrd2e * qtmp*q[j]/r;
-            forcecoul = prefactor * (erfc + EWALD_F*grij*expm2);
+            forcecoul = prefactor * (erfc + MY_ISPI4*grij*expm2);
             if (factor_coul < 1.0) forcecoul -= (1.0-factor_coul)*prefactor;
           } else {
             union_int_float_t rsq_lookup;
@@ -479,11 +474,10 @@ void PairLJCharmmCoulLong::compute_outer(int eflag, int vflag)
           if (!ncoultablebits || rsq <= tabinnersq) {
             r = sqrt(rsq);
             grij = g_ewald * r;
-            expm2 = exp(-grij*grij);
-            t = 1.0 / (1.0 + EWALD_P*grij);
-            erfc = t * (A1+t*(A2+t*(A3+t*(A4+t*A5)))) * expm2;
+            expm2 = expmsq(grij);
+            erfc = my_erfcx(grij) * expm2;
             prefactor = qqrd2e * qtmp*q[j]/r;
-            forcecoul = prefactor * (erfc + EWALD_F*grij*expm2 - 1.0);
+            forcecoul = prefactor * (erfc + MY_ISPI4*grij*expm2 - 1.0);
             if (rsq > cut_in_off_sq) {
               if (rsq < cut_in_on_sq) {
                 rsw = (r - cut_in_off)/cut_in_diff;
@@ -572,7 +566,7 @@ void PairLJCharmmCoulLong::compute_outer(int eflag, int vflag)
         if (vflag) {
           if (rsq < cut_coulsq) {
             if (!ncoultablebits || rsq <= tabinnersq) {
-              forcecoul = prefactor * (erfc + EWALD_F*grij*expm2);
+              forcecoul = prefactor * (erfc + MY_ISPI4*grij*expm2);
               if (factor_coul < 1.0) forcecoul -= (1.0-factor_coul)*prefactor;
             } else {
               table = vtable[itable] + fraction*dvtable[itable];
@@ -966,11 +960,10 @@ double PairLJCharmmCoulLong::single(int i, int j, int itype, int jtype,
     if (!ncoultablebits || rsq <= tabinnersq) {
       r = sqrt(rsq);
       grij = g_ewald * r;
-      expm2 = exp(-grij*grij);
-      t = 1.0 / (1.0 + EWALD_P*grij);
-      erfc = t * (A1+t*(A2+t*(A3+t*(A4+t*A5)))) * expm2;
+      expm2 = expmsq(grij);
+      erfc = my_erfcx(grij) * expm2;
       prefactor = force->qqrd2e * atom->q[i]*atom->q[j]/r;
-      forcecoul = prefactor * (erfc + EWALD_F*grij*expm2);
+      forcecoul = prefactor * (erfc + MY_ISPI4*grij*expm2);
       if (factor_coul < 1.0) forcecoul -= (1.0-factor_coul)*prefactor;
     } else {
       union_int_float_t rsq_lookup;
```

Similar for pppm styles:

``` diff
diff --git a/src/KSPACE/pppm.cpp b/src/KSPACE/pppm.cpp
index 9b18ad8..4ff1bd8 100644
--- a/src/KSPACE/pppm.cpp
+++ b/src/KSPACE/pppm.cpp
@@ -1200,23 +1200,24 @@ double PPPM::compute_qopt()
           sum2 = 0.0;
           sum3 = 0.0;
           sum4 = 0.0;
+          const double inv_gew = 1.0/g_ewald;
           for (nx = -2; nx <= 2; nx++) {
             qx = unitkx*(kper+nx_pppm*nx);
-            sx = exp(-0.25*square(qx/g_ewald));
+            sx = expmsq(0.5*qx*inv_gew);
             argx = 0.5*qx*xprd/nx_pppm;
             wx = powsinxx(argx,twoorder);
             qx *= qx;

             for (ny = -2; ny <= 2; ny++) {
               qy = unitky*(lper+ny_pppm*ny);
-              sy = exp(-0.25*square(qy/g_ewald));
+              sy = expmsq(0.5*qy*inv_gew);
               argy = 0.5*qy*yprd/ny_pppm;
               wy = powsinxx(argy,twoorder);
               qy *= qy;

               for (nz = -2; nz <= 2; nz++) {
                 qz = unitkz*(mper+nz_pppm*nz);
-                sz = exp(-0.25*square(qz/g_ewald));
+                sz = expmsq(0.5*qz*inv_gew);
                 argz = 0.5*qz*zprd_slab/nz_pppm;
                 wz = powsinxx(argz,twoorder);
                 qz *= qz;
@@ -1288,7 +1289,7 @@ double PPPM::newton_raphson_f()
   double zprd = domain->zprd;
   bigint natoms = atom->natoms;

-  double df_rspace = 2.0*q2*exp(-g_ewald*g_ewald*cutoff*cutoff) /
+  double df_rspace = 2.0*q2*expmsq(g_ewald*cutoff) /
        sqrt(natoms*cutoff*xprd*yprd*zprd);

   double df_kspace = compute_df_kspace();
@@ -1329,7 +1330,7 @@ double PPPM::final_accuracy()

   double df_kspace = compute_df_kspace();
   double q2_over_sqrt = q2 / sqrt(natoms*cutoff*xprd*yprd*zprd);
-  double df_rspace = 2.0 * q2_over_sqrt * exp(-g_ewald*g_ewald*cutoff*cutoff);
+  double df_rspace = 2.0 * q2_over_sqrt * expmsq(g_ewald*cutoff);
   double df_table = estimate_table_accuracy(q2_over_sqrt,df_rspace);
   double estimated_accuracy = sqrt(df_kspace*df_kspace + df_rspace*df_rspace +
                                    df_table*df_table);
@@ -1570,22 +1571,23 @@ void PPPM::compute_gf_ik()
           numerator = 12.5663706/sqk;
           denominator = gf_denom(snx,sny,snz);
           sum1 = 0.0;
+          const double inv_gew = 1.0/g_ewald;

           for (nx = -nbx; nx <= nbx; nx++) {
             qx = unitkx*(kper+nx_pppm*nx);
-            sx = exp(-0.25*square(qx/g_ewald));
+            sx = expmsq(0.5*qx*inv_gew);
             argx = 0.5*qx*xprd/nx_pppm;
             wx = powsinxx(argx,twoorder);

             for (ny = -nby; ny <= nby; ny++) {
               qy = unitky*(lper+ny_pppm*ny);
-              sy = exp(-0.25*square(qy/g_ewald));
+              sy = expmsq(0.5*qy*inv_gew);
               argy = 0.5*qy*yprd/ny_pppm;
               wy = powsinxx(argy,twoorder);

               for (nz = -nbz; nz <= nbz; nz++) {
                 qz = unitkz*(mper+nz_pppm*nz);
-                sz = exp(-0.25*square(qz/g_ewald));
+                sz = expmsq(0.5*qz*inv_gew);
                 argz = 0.5*qz*zprd_slab/nz_pppm;
                 wz = powsinxx(argz,twoorder);

@@ -1653,6 +1655,7 @@ void PPPM::compute_gf_ik_triclinic()
           numerator = 12.5663706/sqk;
           denominator = gf_denom(snx,sny,snz);
           sum1 = 0.0;
+          const double inv_gew = 1.0/g_ewald;

           for (nx = -nbx; nx <= nbx; nx++) {
             argx = MY_PI*kper/nx_pppm + MY_PI*nx;
@@ -1673,13 +1676,13 @@ void PPPM::compute_gf_ik_triclinic()
                 x2lamdaT(&b[0],&b[0]);

                 qx = unitk_lamda[0]+b[0];
-                sx = exp(-0.25*square(qx/g_ewald));
+                sx = expmsq(0.5*qx*inv_gew);

                 qy = unitk_lamda[1]+b[1];
-                sy = exp(-0.25*square(qy/g_ewald));
+                sy = expmsq(0.5*qy*inv_gew);

                 qz = unitk_lamda[2]+b[2];
-                sz = exp(-0.25*square(qz/g_ewald));
+                sz = expmsq(0.5*qz*inv_gew);

                 dot1 = unitk_lamda[0]*qx + unitk_lamda[1]*qy + unitk_lamda[2]*qz;
                 dot2 = qx*qx+qy*qy+qz*qz;
@@ -1716,6 +1719,7 @@ void PPPM::compute_gf_ad()
   int k,l,m,n,kper,lper,mper;

   const int twoorder = 2*order;
+  const double inv_gew = 1.0/g_ewald;

   for (int i = 0; i < 6; i++) sf_coeff[i] = 0.0;

@@ -1724,7 +1728,7 @@ void PPPM::compute_gf_ad()
     mper = m - nz_pppm*(2*m/nz_pppm);
     qz = unitkz*mper;
     snz = square(sin(0.5*qz*zprd_slab/nz_pppm));
-    sz = exp(-0.25*square(qz/g_ewald));
+    sz = expmsq(0.5*qz*inv_gew);
     argz = 0.5*qz*zprd_slab/nz_pppm;
     wz = powsinxx(argz,twoorder);

@@ -1732,7 +1736,7 @@ void PPPM::compute_gf_ad()
       lper = l - ny_pppm*(2*l/ny_pppm);
       qy = unitky*lper;
       sny = square(sin(0.5*qy*yprd/ny_pppm));
-      sy = exp(-0.25*square(qy/g_ewald));
+      sy = expmsq(0.5*qy*inv_gew);
       argy = 0.5*qy*yprd/ny_pppm;
       wy = powsinxx(argy,twoorder);

@@ -1740,7 +1744,7 @@ void PPPM::compute_gf_ad()
         kper = k - nx_pppm*(2*k/nx_pppm);
         qx = unitkx*kper;
         snx = square(sin(0.5*qx*xprd/nx_pppm));
-        sx = exp(-0.25*square(qx/g_ewald));
+        sx = expmsq(0.5*qx*inv_gew);
         argx = 0.5*qx*xprd/nx_pppm;
         wx = powsinxx(argx,twoorder);
```
","Need to start over, since the branch of PR #371 has become stale.",12007030
492,[Feature Request] Extra parameters for USER-REAXC lg correction ignored; replaced by hard-coded values,open,2016-06-10T22:42:30Z,2018-05-09T19:17:28Z,,CONTRIBUTOR,"1. Update the reaxc_ffield.cpp and reaxc_nonbonded.cpp to use extra parameters
2. Make sure all fourth and fifth to last parameters are 1.0 in all parameter files, except for our HNS-lg2 forcefield for HNS.
",,12007030
493,Discontinuity of energy in reaxFF,open,2016-06-03T02:58:27Z,2018-03-20T20:32:42Z,,MEMBER,"Reported by Michał Kański on lammps-users:

Hello all,

I encountered a discontinuity of energy when using ReaxFF. Namely, there is a rapid change of energy (few kcals/mol) when a bond in a diatomic molecule is being broken. The issue also occurs when an atom is being detached from a molecule. I checked the code and I believe that the change occurs, because the undercoordination term is not calculated when an atom does not have any bond. The simplest resolution I have found is removing if-statements from reaxc_multibody.cpp (lines 190, 205, 211) which restrict calculation of undercoordination term to bonded atoms.

Could someone confirm the presence of the issue?

I’m attaching a simple input script which shows the problem. I used the 31 May 2016 version of LAMMPS.

Cheers,
Michal

[discontinuity_reaxFF.in.txt](https://github.com/lammps/lammps/files/296867/discontinuity_reaxFF.in.txt)
","Maybe fixed in addd87c0f7a47fd54c3ccfb7edc11a166e2bc2e3, someone needs to confirm",12007030
494,Explosive Spirits gives you the wrong buff,open,2020-03-24T04:06:43Z,2020-03-24T04:06:43Z,,NONE,"Explosive Spirits doesn't give you the Fury status. It gives you ""Abrasive"" which is a +5 to crit and not +20. And it stacks with Rising Dragon which definitely means it's a different buff.

And the worst part is, Guillotine Fist and Tiger Cannon doesn't work while you have this ""abrasive"" status up. It works with Rising Dragon so the skill definitely is applying the wrong status condition.

**To Reproduce**
Cast Explosive Spirits. More info: Try to cast Guillotine Fist or Tiger Cannon with explosive spirits on. It doesn't happen.

**Expected behavior**
Needs to give the Explosive Spirits buff which increases crit by 20 and not 5, doesn't stack with Rising Dragon, and enables the use of Guillotine Fist and Tiger Cannon.

**System specs (please complete the following information):**
 - OS: Windows 10
 - Hercules Version dd7f653b00239299cdecb7ca826c21e5957863da (latest one as of post)
 - Mode: renewal
 - Packet version: no idea.
 - Client type: no idea. Copied from a ""newbie pack"" for Hercules Ragnarok.
",,7551429
495,Add UNIQUE KEY to column `login`.`userid`,open,2020-03-22T02:43:46Z,2020-03-22T03:47:13Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

The `login`.`userid` column should be unique to prevent 3rd party tools from creating multiple accounts with identical user name.

**Replaces PR:** #2169

**Issues addressed:** None.


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
496,Expand column size of `ipbanlist`.`list` from 13 to 39,open,2020-03-22T01:22:01Z,2020-03-22T03:45:56Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

In #2583 the column size of `ipbanlist`.`list` was changed to 13 to match the server specific format. @pazkero [mentioned](https://github.com/HerculesWS/Hercules/pull/2583#issuecomment-586376498) that custom code may uses a complete IP for bans. Thus the column size should be expanded at least to 15.
To enable custom code to even use IPv6 addresses it should be expanded to 39.

**Issues addressed:** #2631 


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
497,Update packets up to 2020-03-18,open,2020-03-19T03:55:47Z,2020-03-19T03:55:47Z,,CONTRIBUTOR,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
Update packets table.
Update shuffle packets and packet keys.
",,7551429
498,Passivel Skills not inflicting critical damage,open,2020-03-18T08:07:32Z,2020-03-18T08:07:32Z,,NONE,"**Describe the bug**
passive skills do not inflict critical damage as intended

**Expected behavior**
on kRO, multiple hit passives like Double Attack, Trifecta and Fear Breeze proc off critical damage

**System specs (please complete the following information):**
 - OS: [Windows 10 Education 1903]
 - Hercules Version [v2020.03.08+1]
 - Mode: [RE]
 - Packet version: [e.g. 20181031]
 - Client type: [main]


**Additional context**
https://www.midgard-community.com/forums/topic/1429-kro-december-7th-2016-maintenance/

> - Certain successive blows that are activated as passive will be changed to Critical when activated. 
> → Skill List: Double Attack, Chain Action, Shadow Warrior, Crossbow, Peer Breeze ",,7551429
499,Use of wrong ammo with wrong weapon.,open,2020-03-15T22:45:27Z,2020-03-15T22:45:27Z,,NONE,"**Describe the bug**
Whenever the skill uses two different weapons with two different ammo types, it will accept either type of ammo. This makes grenade launchers work with bullets and shotguns with grenades.

",,7551429
500,Make skills check if equipped ammunition type is appropriate for equipped weapon,open,2020-03-15T04:30:03Z,2020-03-19T07:49:28Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Liete mentioned that skills don't check if the equipped ammunition type is appropriate for equipped weapon and thus can be cast with wrong ammunition type equipped.

> Liete
> Hello.
> Can anyone help me out with this issue:
> I have set certain skill - Spread Shot to be working with grenade launchers, but there is a problem it uses both bullets and grenades be it shotgun or launcher equipped.

The actual problem is that you can equip bullets or grenades regardless of the equipped weapon type. This issue has already been reported: #2579
Since this needs some more information before completely get fixed this PR is a quick workaround for the time being.

**Issues addressed:** #2661, Partially #2579


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","> Wasn't this intended for example, an assassin is able to wear arrows and gain effects on Grimtooth, is that an athena thing or maybe pre-re thing? regardless I would like to have a battle conf for this one.

This change doesn't affect Grimtooth+Arrows. Grimtooth doesn't have `Requirements`->`AmmoTypes` defined, so the changed code block is never reached. Thus there is no need for a battle flag.",7551429
501,Add new status changes and update related items,open,2020-03-13T06:28:24Z,2020-03-16T11:42:29Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Add 7 new status changes and use them for the related items.

**Replaces PR:** #1177

**Issues addressed:** None.


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
502,Clean up auto-cast related code,open,2020-03-13T06:06:57Z,2020-03-14T22:05:30Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Currently the auto-cast related code is a mess.
 * We have `map_session_data->state.autocast` which is used to temporarily flag a skill as auto-cast for skills cast by `bAutoSpell*` bonuses or by Auto Shadow Spell. It's also (mis)used to prevent damage reflection from infinite looping.
 * We have `map_session_data->state.abra_flag` which isn't actually used. It's just set when casting Abracadabra or Improvised Song, but then never used for validation.
 * We have `map_session_data->skillitem` and `map_session_data->skillitemlv` which hold the auto-cast skill's ID and level. `map_session_data->skillitem` is misused to validate auto-casting all over the code.
 * As of late we have the `itemskill()` script command related states and helper variables.
 * Unsetting/validating the auto-cast data in the right place currently is more likely gambling.

\------------------------------------------------------------------------------------------------------------------

I spent some days in getting into the subject and cleaned it up as far as possible.
 * I added an enumeration for auto-cast types to be able to handle each one separately and use those types for validation instead of the auto-cast skill's ID.
 * I added a structure to unify all auto-cast related data in one place.
 * I added a function which validates the plausibility of auto-cast related data.
 * I revised where and when `pc_autocast_clear()` (former `pc_itemskill_clear()`) gets called.
 * I removed obsolete code parts.
 * I made skills cast by Improvised Song ignore all requirements.


**Issues addressed:** #1211


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
503,Fix overflowing pointer in getiteminfo() script command,open,2020-03-12T21:34:13Z,2020-03-12T22:46:42Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Using `ITEMINFO_NAME` or `ITEMINFO_AEGISNAME` in `getiteminfo()` script command causes an overflowing pointer error when the respective stack element gets freed.

> [Error]: Memory manager: args of aFree 0x052B7B62 is overflowed pointer ...\src\map\script.c line 3774

Therefore `script_pushstrcopy()` should be used instead of `script_pushstr()` to push the item's name to the script stack.

**Issues addressed:** None.


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
504,Fix memory leak in npc_expanded_barter_fromsql() function,open,2020-03-11T17:01:09Z,2020-03-11T23:56:09Z,,MEMBER,"### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

The `StringBuf` in `npc_expanded_barter_fromsql()` function isn't freed if the statement preparation/execution fails and thus generates a memory leak.

**Issues addressed:** None.


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
505,Refactor mapflags code,open,2020-03-09T15:23:47Z,2020-03-11T23:55:46Z,,MEMBER,"
<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

<!-- Describe the changes that this pull request makes. -->
- refactor mapflag related codes
- rearranged the codes based on mapflag index (easier for future to find and refer?)
- added missing mapflags.  
```
	mf_nomapchannelautojoin:    61
	mf_noknockback:             62
	mf_cvc:                     63
	mf_src4instance             64
```

**Issues addressed:** <!-- Write here the issue number, if any. -->
none

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",I'd prefer upper case for the sake of consistency.,7551429
506,Errors in status calculation and display,open,2020-03-08T06:47:34Z,2020-03-15T04:35:05Z,,MEMBER,"**Describe the bug**
 * Some calculations (e.g. ATK/MATK) can't work correctly, because `struct status_data` uses unsigned integers. AEGIS allow negative stats and thus calculates different results. For testing I used Death_Note (ID: 1565).
![WITH WEAPON](https://user-images.githubusercontent.com/3476227/76157783-13551180-610e-11ea-95a5-47d1d7a0f644.png)

 * Status changes (`SC_*`) which modify MATK don't use the base MATK for calculating but the MATK modified by other status changes and equipment bonuses. Thus the result gets falsified.

 * Status changes (`SC_*`) which modify MATK can't be displayed because their value isn't stored.

 * Status changes (`SC_*`) which modify ATK are displayed on the left side (base ATK). AEGIS displays them on the right side (bonus ATK).

**Expected behavior**
Correct calculation and display.

**System specs (please complete the following information):**
 - OS: Windows 10 Pro Version 1809
 - Hercules Version v2020.02.09
 - Mode: renewal
 - Packet version: 20190220
 - Client type: RE

**Plugins used or source modifications**
None.

**Additional context**
None.
",,7551429
507,Add NoPet mapflag,open,2020-03-07T21:26:57Z,2020-03-09T12:25:56Z,,MEMBER,"
<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

<!-- Describe the changes that this pull request makes. -->
- mapflag to disable pet, and force return to egg.
- allow to set `mf_nopet` mapflag at any maps.

**Issues addressed:** <!-- Write here the issue number, if any. -->
Enable to control pet restriction in any maps, not just `mf_gvg` or `mf_gvg_castle` maps.

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",Please leave enable pet by default.,7551429
508,Validate duplicated item_db entries,open,2020-03-07T14:31:12Z,2020-03-08T03:44:55Z,,MEMBER,"
<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

<!-- Describe the changes that this pull request makes. -->
- Enable user to detect ""used"" item_db (happen when server has custom item_db that clashed with latest update from Herc if any)
- able to detect duplicated items where inherit field aren't used.
- Enable user to detect ""duplicated"" item_db (happen when user aren't aware of multiple duplicated entries in the past, only happen if `inherit: true` aren't used.)
- Encourage user to use `inherit: true` field for their custom changes to existing item_db.

**Issues addressed:** <!-- Write here the issue number, if any. -->
Detect whichever item_db ID are currently clashed with each other (if any)
Lesser duplicated entries of item_db, especially server who has alot custom items.

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","may be better if need really duplicate, add some special flag into duplicated db entry?
",7551429
509,Fixed Experience Gain message,open,2020-03-01T14:22:55Z,2020-03-07T19:09:17Z,,MEMBER,"<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.


### Changes Proposed

<!-- Describe the changes that this pull request makes. -->

Since macro is used in message, I believe we can't move it to messages.conf yet, and it will display the format specifier instead of value

**Issues addressed:** <!-- Write here the issue number, if any. -->
None

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
510,Rodex Mail (nullpo),open,2020-02-26T08:21:43Z,2020-03-01T00:55:30Z,,NONE,"**Describe the bug**
I still see this nullpo info in the log.  Some player still complains missing items in mail.

**To Reproduce**
Steps to reproduce the behavior:
i dont know how to reproduce.
> (02/26/2020 15:11:53) [ Error ] : --- nullpo info --------------------------------------------
> (02/26/2020 15:11:53) [ Error ] : rodex.c:403: 'msg' in function `rodex_read_mail'
> (02/26/2020 15:11:53) [ Error ] : ./map-server() [0x62f973]
> (02/26/2020 15:11:53) [ Error ] : ./map-server() [0x4a6dcb]
> (02/26/2020 15:11:53) [ Error ] : ./map-server() [0x6422ae]
> (02/26/2020 15:11:53) [ Error ] : ./map-server(main+0x2d2) [0x408462]
> (02/26/2020 15:11:53) [ Error ] : /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f75925f2505]
> (02/26/2020 15:11:53) [ Error ] : ./map-server() [0x40861b]
> (02/26/2020 15:11:53) [ Error ] : --- end nullpo info ----------------------------------------

**System specs (please complete the following information):**
 - OS: Centos7 64x
 - Hercules Version latest git
 - Mode: PRE-RE
 - Packet version: 20150429
 - Client type: main

**Plugins used or source modifications**
none
","@4144 
`(03/01/2020 06:58:38) [ Error ] : --- failed assertion --------------------------------------------
(03/01/2020 06:58:38) [ Error ] : rodex.c:163: 'idx >= 0 && idx < sd->status.inventorySize' in function `rodex_remove_item'
(03/01/2020 06:58:38) [ Error ] : ./map-server() [0x62f993]
(03/01/2020 06:58:38) [ Error ] : ./map-server() [0x4a6deb]
(03/01/2020 06:58:38) [ Error ] : ./map-server() [0x6422ce]
(03/01/2020 06:58:38) [ Error ] : ./map-server(main+0x2d2) [0x408482]
(03/01/2020 06:58:38) [ Error ] : /lib64/libc.so.6(__libc_start_main+0xf5) [0x7f1ffbf46505]
(03/01/2020 06:58:38) [ Error ] : ./map-server() [0x40863b]
(03/01/2020 06:58:38) [ Error ] : --- end failed assertion ----------------------------------------
`
Also that one sir.  Full in my logs with those :D",7551429
511,Fix/extend @fakename,open,2020-02-22T00:41:12Z,2020-03-13T09:08:03Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

 * Fix the issue, where not even the fake name shows up, when using `@fakename` in RE clients.
 * Add parameter `options` to `@fakename`, to be able to select which names will be displayed.

**Replaces PR:** #2168

**Issues addressed:** #1966


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
512,IPban table size is less than length of IP,open,2020-02-14T20:10:25Z,2020-02-15T02:37:42Z,,MEMBER,"**Describe the bug**
https://github.com/HerculesWS/Hercules/pull/2583#issuecomment-586376498 (Copied Question below by @pazkero) 

> some custom plugins which I've saw on the forums add a command called ""@ipban"", for example, which is a non-automatic way of adding IP Bans.
> 
> An IP official length is 15 or 16 (xxx.xxx.xxx.xxx). Wouldn't this cause issues when IP bans are not done automatically? (Also, in some rather specific cases, it might be a desired behavior to ban only the specific IP. Yes, I am aware of how dynamic IP works and why we usually use a star.)
> 
> TL;DR Doesn't this causes issues or SQL errors if there are IP Bans of length 15?
> 
> PS. Feel free to open an issue about it, if you think it relevant. I'm just curious.

**Expected behavior**
IP should be stored even if length is 15.

**Additional context**
We changed the IP length in SQL to 13 in IP Ban Table. Reference PR: #2583 
","Afaik,  client doesn't support IPv6, but, Yes, maybe we can change it to 39",7551429
513,missing some packets,open,2020-01-14T18:13:05Z,2020-02-02T15:46:30Z,,NONE,"**Describe the bug**
some newer packets are not implemented in hercules

Pet Capture:

```c
0x8B4 2   PACKET_ZC_START_COLLECTION
0x8B5 6   PACKET_CZ_TRYCOLLECTION                                                   
0x8B6 3   PACKET_ZC_TRYCOLLECTION
```

Some client versions for banking packets

```c
0x9A7 10  PACKET_CZ_REQ_BANKING_DEPOSIT
0x9A9 14  PACKET_CZ_REQ_BANKING_WITHDRAW
0x9AB -1  PACKET_CZ_REQ_BANKING_CHECK 
```

Cash Shop Control

```c
0x9AC 20  PACKET_CZ_REQ_CASH_BARGAIN_SALE_ITEM_INFO
0x9AD 6   PACKET_ZC_ACK_CASH_BARGAIN_SALE_ITEM_INFO
0x9AE -1  PACKET_CZ_REQ_APPLY_BARGAIN_SALE_ITEM
0x9AF -1  PACKET_ZC_ACK_APPLY_BARGAIN_SALE_ITEM
0x9B0 8   PACKET_CZ_REQ_REMOVE_BARGAIN_SALE_ITEM
0x9B1 6   PACKET_ZC_ACK_REMOVE_BARGAIN_SALE_ITEM
0x9B2 -1  PACKET_ZC_NOTIFY_BARGAIN_SALE_SELLING
```
Some client versions for Rodex

```c
0x9E8 18  PACKET_CZ_OPEN_RODEXBOX
0x9E9 2   PACKET_CZ_CLOSE_RODEXBOX
0x9ED -1  PACKET_ZC_ACK_SEND_RODEX
0x9EE -1  PACKET_CZ_REQ_NEXT_RODEX
```

These are just some packets, there are other packets that are in the same situation

**System specs (please complete the following information):**
 - OS: [10 version 1809]
 - Hercules Version [v2020.01.12]
 - Mode: [renewal]
 - Packet version: [20190228]
 - Client type: [main]

**Plugins used or source modifications**
no.
",,7551429
514,GTB card has silence immunity ,open,2020-01-06T10:28:09Z,2020-01-06T21:49:33Z,,NONE,"Golden thief bug card script has wrong script 
	//Status that are blocked by Golden Thief Bug card or Wand of Hermod
	if (status->isimmune(bl))
		switch (type) {
		case SC_DEC_AGI:
		case **SC_SILENCE:**
		case SC_COMA:
		case SC_INC_AGI:
		case SC_BLESSING:
		case SC_SLOWPOISON:
		case SC_IMPOSITIO:
		case SC_LEXAETERNA:
		case SC_SUFFRAGIUM:
		case SC_BENEDICTIO:
		case SC_PROVIDENCE:
		case SC_KYRIE:
		case SC_ASSUMPTIO:
		case SC_ANGELUS:
		case SC_MAGNIFICAT:
		case SC_GLORIA:
		case SC_WINDWALK:
		case SC_MAGICROD:
		case SC_ILLUSION:
		case SC_STONE:
		case SC_QUAGMIRE:
		case SC_NJ_SUITON:
		case SC_SWING:
			return 0;
		}
it has silence
![Screen Shot 2020-01-06 at 18 03 29](https://user-images.githubusercontent.com/59560882/71812437-27e74000-30b2-11ea-9e99-15607ab9b8ea.png)
",I will compile full list soon for pre-re/re,7551429
515,Preparation for upcoming pet DB update.,open,2019-12-26T08:28:25Z,2020-03-13T09:04:49Z,,MEMBER,"<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

<!-- Describe the changes that this pull request makes. -->
* Added enumerations for pet hunger/intimacy levels
* Added value capping to `pet_set_intimate()` function.
* Adjusted pet catch rate calculation. (Thanks to @hemagx.)
* Adjusted pet intimacy calculation when feeding. (Thanks to @hemagx.)
* Made `pet_hungry_timer` only be added if a pet's `HungerDelay` is greater than 0.
* Added a `HungerDelay` validation to `pet_hungry()` function.
* Added a base rate validation to `pet_target_check()` function.
* Added a monster ID validation to `pet_read_db_sub()` function.
* Removed `SpriteName` field from pet DB.
* Changed `EggItem` field in pet DB to be mandatory.
* Added default values and limits to pet DB fields.
* Added new field `HungerDecrement` to pet DB.
* Added new field `Intimacy.StarvingDelay` to pet DB.
* Added new field `Intimacy.StarvingDecrement` to pet DB.
* Removed `pet_hungry_friendly_decrease` config setting.
* Increased `MAX_MOB_DB` to 22000.
* Added some layout changes to the pet DB file headers. (entry structure)
* Added pet DB documentation file. (doc/pet_db.txt)
* Removed fields from pet DB where default values can be used.
* Added intimacy validation to pet DB `EquipScript` fields.
* Removed `pet_equip_min_friendly` config setting.
* Adjusted `inter_pet_tosql()` and `inter_pet_fromsql()` functions to use prepared statements.
* Added `pet_set_hunger()` function.
* Applied code style to touched functions in src/char/int_pet.c.
* Applied code style to touched functions in src/map/atcommand.c.
* Applied code style to touched functions in src/map/clif.c.
* Applied code style to touched functions in src/map/pc.c.
* Applied code style to touched functions in src/map/pet.c.
* Applied code style to touched functions in src/map/script.c.
* Applied code style to pet related part of `status_calc_pc_()` function.
* Won't apply code style to touched functions in src/map/unit.c, because of https://github.com/HerculesWS/Hercules/pull/2546.

**Issues addressed:** #2434. #303


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","Code style is applied, too, now.
Ready for re-review.",7551429
516,Deprecate set() script command.,open,2019-12-14T22:05:37Z,2020-03-08T14:47:18Z,,MEMBER,"<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
In my opinion it's pointless to have two script commands, which do the same thing in different ways.
That's why I'd like to deprecate `set()` completely, as already mentioned in doc/script_commands.txt, and where needed use `setd()` instead.

Modified `BUILDIN(setd)` to accept references to variables, too.
Marked `set()` as deprecated.
Updated doc/script_commands.txt.
Updated non-custom scripts to **not** use `set()` anymore. (Custom scripts will follow.)

**Issues addressed:** None.


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","Deprecating `set` is really wanted, but I'm absolutely against having `setd` take the role of set (if anything, the use of `setd` should ALSO be discouraged - but we can't do that, since the language isn't expressive enough, and several things would become impossible to do).

But the reason why I marked this as in need of edits is that it breaks existing behavior in the way it dereferences variables (I insist it does, see the following test case). And we should never break existing behavior silently.

Test case:
```
-	script	test_npc	FAKE_NPC,{
OnInit:
	.foo$ = "".foo$"";
	.bar$ = ""hello1"";
	.foo_d$ = "".bar_d$"";
	.bar_d$ = ""world1"";

	sleep(1000);
	// The following line should set the variable .foo$ of other_npc to ""EDITED1"" (set expects variable references and treats them as such)
	set(getvariableofnpc(.foo$, ""other_npc""), ""EDITED1"");
	// The following line reads the variable .foo_d$ of other_npc as a string, and then sets the variable of test_npc whose name is equal to the value of that string, to ""EDITED2"" (setd expects strings, and treats them as such)
	setd(getvariableofnpc(.foo_d$, ""other_npc""), ""EDITED2"");

	consolemes(CONSOLEMES_DEBUG, ""variables in test_npc:"");
	consolemes(CONSOLEMES_DEBUG, ""set foo: %s; bar: %s"", .foo$, .bar$);
	consolemes(CONSOLEMES_DEBUG, ""setd foo: %s; bar: %s"", .foo_d$, .bar_d$);
}

-	script	other_npc	FAKE_NPC,{
OnInit:
	.foo$ = "".foo$"";
	.bar$ = ""hello2"";
	.foo_d$ = "".bar_d$"";
	.bar_d$ = ""world2"";

	sleep(2000);
	consolemes(CONSOLEMES_DEBUG, ""variables in other_npc:"");
	consolemes(CONSOLEMES_DEBUG, ""set foo: %s; bar: %s"", .foo$, .bar$);
	consolemes(CONSOLEMES_DEBUG, ""setd foo: %s; bar: %s"", .foo_d$, .bar_d$);
}
```

Documented existing behavior:

```
[Debug]: consolemes: variables in test_npc:
[Debug]: consolemes: set foo: .foo$; bar: hello1
[Debug]: consolemes: setd foo: .bar_d$; bar: EDITED2
[Debug]: consolemes: variables in other_npc:
[Debug]: consolemes: set foo: EDITED1; bar: hello2
[Debug]: consolemes: setd foo: .bar_d$; bar: world2
```

New unexpected behavior:

```
[Debug]: consolemes: variables in test_npc:
[Debug]: consolemes: set foo: .foo$; bar: hello1
[Debug]: consolemes: setd foo: .bar_d$; bar: world1
[Debug]: consolemes: variables in other_npc:
[Debug]: consolemes: set foo: EDITED1; bar: hello2
[Debug]: consolemes: setd foo: .bar_d$; bar: EDITED2
```

As you can see, after this patch, the behavior of setd changes completely, and it no longer treats its argument as a string. In order to restore the old behavior, people would need to get creative and dereference their string explicitly (i.e. `setd(sprintf(""%s"", getvariableofnpc(.foo_d$, ""other_npc"")), ""value"");`. What's worse, any script that uses the currently documented behavior would be broken.

This is why I'm against moving the set functionality to setd, since they're two different commands with different goals.",7551429
517,Correct and Fix player/homonculus/elemental/mercenary natural HP/SP heal behavior,open,2019-12-08T09:49:46Z,2020-03-08T22:28:03Z,,CONTRIBUTOR,"<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
There's many and several player, homunculus, mercenary and elemental natural heal behaviors which was either designed or assumed based on guesses, wrong calculations on unreliable player sources, this pull request aims to fully fix it and it was based on heavy aegis research on different episodes.
(EP 8 (Pre-trans), EP 9 and 10 (After trans), EP 14.3 (Renewal)

the changes proposed is as the following
#### Finished Changes
* Removal of several unused variables from struct regen_data
* Change naming of misleading member names in struct regen_data
* Change the HP/SP heal frequency rate from a base of 1 to a base of 100, as some skills increase in percentages
* Fixing castle owning natural heal bonus, as it was only applied when players moves to castle, disregarding the case of when enemy guild take over a castle
* Removal of unsigned short hp/sp heal amounts as it made calculation more difficult and code messy, the final value is still capped however as older clients can't process anything further UINT16_MAX for those values
* Rewrite status_calc_regen and status_calc_regen and turn them into separate sub functions based on object type as not all objects benefit of same bonuses and to disregard mega switches.
* Fix status effects that was affecting several object types while it should only affect specific objects type (Player, Homu, Mercenary, Elemental)
* Fixed several item effects that was affecting regen rate instead of regen values, possibly a misunderstanding of the meaning of rate as it changes heal frequency instead of heal amounts
* Correcting how heal rate is calculated as it's a cumulative percentage not a summed one, with this also fixed the order to match Aegis one
* Implemented the correct different heal intervals for each object type, previously we only had Player and Homunculs, and homunclus heal rates was wrongly assumed
* Fix homunculus brain surgery skill effect as it should affect heal frequency not heal amounts
* Aegis puts a limit on how fast a heal interval can be, however Hercules doesn't, this is implemented and fixed within this PR.
* Fixed Tension Relax behavior as it was increasing HP regeneration rate when overweight instead of just allowing it, and also allowed SP regeneration when it should not.
* Fixed Magnificant increasing HP regeneration rate, it was wrongly assumed that it was removed in renewal when it was actually removed with Comodo update with the new HP regeneration formula
* Fixed HAMI_SKIN affecting HP heal amounts instead of HP regeneration rate

<!-- Describe the changes that this pull request makes. -->

**Issues addressed:** <!-- Write here the issue number, if any. -->
None which I'm aware of right now, i will check issues when RP is complete and link them if applicable.

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",,7551429
518,WIP: Add proper backtrace logging even if functions is hidden.,open,2019-11-18T03:23:40Z,2020-03-08T14:54:11Z,,CONTRIBUTOR,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
Add support for libbacktrace for logging call stack.
Current solution based on execinfo.h not works for hidden functions. And current hercules link flags hiding all functions.
Libbacktrace show stack based on debug information and not related to linkage flags.

Enabled for linux only. For macosx need update xcode project.",,7551429
519,Unequipping [Bow] bug,open,2019-11-15T06:01:53Z,2020-02-18T22:39:17Z,,NONE,"In official server the arrow will only be unequipped when you are not using bow/musical/whip
The case on our server is that when switching from BOW to BOW or Bow to Musical instrument the arrows are unequipped.

Notes:
Please fix guns/bullets too.
Incomplete implementation: https://github.com/HerculesWS/Hercules/pull/1663
Rathena fixes: https://github.com/rathena/rathena/commit/d3d8f3c5a7459ef1f76ae379e9d6013dc489bc1a",This needs additional info/discussion on how to implement this.,7551429
520,MSC_MAGICATTACKED for mob_skill_db,open,2019-11-13T13:09:58Z,2019-11-13T13:09:58Z,,CONTRIBUTOR,"**Is your feature request related to a problem? Please describe.**
I want mobs to be able to counter magic.

**Describe the solution you'd like**
Add  `CastCondition: ""MSC_MAGICATTACKED""` in mob_skill_db.

**Describe alternatives you've considered**
Only other alternative was to make mob counter using MSC_SKILLUSED.

**Additional context**

",,7551429
521,pseudo Random Number Generator improvements?,open,2019-10-20T12:13:52Z,2020-02-28T10:05:54Z,,NONE,"First of all excuse my ad hoc approach. If time allows I'll come up with a more scientific approach with better documentation.
**Is your feature request related to a problem? Please describe.**
1. The following is actually more a question and less a request or proposal. Therefore I cannot present any solution or alternatives since I might be missing here something. If I'm not mistaken the frequently used method to calculate random numbers is genrand_int31() from mt19937ar.c (according to random.c and random.h). I'm wondering why the return value is shifted by 1 bit >>, since this pretty much removes 2^31 entries of the set of potential numbers.

2. If I'm not mistaken the pRNG in mt19937ar.c is a multiplicative congruential generator. This could lead to repetitions and alternations especially in the lower bits field.  This itself can lower the quality of random numbers but it might be increased if not even exponentiated by the fact how for example items to be dropped are chosen.  According to mob.c this calculation is used: ""if (rnd() % 10000 >= drop_rate)"". So only entries of ~0x3F of a random number are used to determine whether to drop an item or not. All of the mentioned above might result in a poor distribution.

I ask you for any input or feedback. Please do correct me if anything is wrong or seems to be wrong. I really really appreciate it.

**Describe the solution you'd like**
One could contemplate to use a more sophisticated pRNG overall. To my knowledge there are a lot of very capable generators which to my understanding should be free to use, either published CC0 or GPL. They could improve the load on the server though which might not be desirable.


**Describe alternatives you've considered**
If you should choose not to change the pRNG there could be another improvement. To my understanding changing the line ""if (rnd() % 10000 >= drop_rate)"" to ""if (Math.floor((rnd() * 10000)/ 2^32) >= drop_rate)"" [assuming int32 architecture and overflows to be carried over] could improve the significance of higher bits of random numbers for the distribution.
Please do correct me on any mistakes and errors. Thank you for your time.
","There are [many alternatives](https://github.com/peteroupc/peteroupc.github.io/blob/master/random.md#high-quality-prng-examples) to the Mersenne Twister, which is a generator with a number of disadvantages explained in further detail in ""[It Is High Time We Let Go of the Mersenne Twister](https://arxiv.org/pdf/1910.06437.pdf)"" by @vigna.

Perhaps the biggest disadvantage to Mersenne Twister is its big state (2500 bytes) compared to other modern PRNGs, which are typically 128 to 256 bits in size and have comparable randomness quality.  

-----

It would be better if this project used a cryptographic RNG in most places, especially since this is an online game. Unfortunately, however, due to the way this project uses a global RNG and allows plugins to seed that global RNG for reproducibility, it may be difficult to change the RNG without affecting compatibility with plugins.  

In general, as I explain in my [RNG recommendations](https://peteroupc.github.io/random.html), an API that ""implements an automatically-seeded RNG ... SHOULD NOT allow applications to initialize that same RNG with a seed for reproducible 'randomness'"", because doing so ""would hamper forward compatibility"".

As it is, this project can change the RNG's implementation (given in [random.c](https://github.com/HerculesWS/Hercules/blob/c03722679a01e5f181c2138565e95a6b0981a124/src/common/random.c)) without affecting backward compatibility &mdash; until some code in the entire program (whether in a plugin or elsewhere) calls `rnd_seed`, and then the entire program would have to rely on the sequence determined by that seed, and by extension, rely on what implementation the RNG uses.

Moreover, the seed taken by `rnd_seed` can only be 32 bits long, which, in the case of Mersenne Twister, is a tiny fraction of the number of seeds the PRNG can admit in theory (namely 2^19937 - 1 seeds).

",7551429
522,Equipment Switch,open,2019-10-11T00:01:33Z,2020-02-23T11:14:09Z,,NONE,"**Is your feature request related to a problem? Please describe.**
No

**Describe the solution you'd like**
None

**Describe alternatives you've considered**
None

**Additional context**
![swtich](https://user-images.githubusercontent.com/39016868/66614874-0f45b780-eba1-11e9-93aa-cafa683cd951.png)


This feature has existed in kRO for a long time, it allows to switch between equipment and also switch between custom.

rAthena has already implemented for quite some time, would be interesting in hercules

https://github.com/rathena/rathena/pull/3548",up,7551429
523,Ignition Break Skill Animation,open,2019-07-24T01:44:02Z,2019-10-24T18:42:58Z,,NONE,"Hercules Version: Last Version

Client Date: 20190703

Server Mode: Renewal

Description of Issue:
Ignition Break not showing skill animation on using new clients. (2018-06-20 and to 2019-07-03)

Modifications that may affect results: None","What More skill this affects?
",7551429
524,Cash Food + Normal Food Stacks,open,2019-06-02T03:49:38Z,2019-06-02T22:20:37Z,,NONE,"**Describe the bug**
The normal foods will stack with cash foods when you died.

**To Reproduce**
Steps to reproduce the behavior:
1. Use normal food (eg. str+10) first then use the cash food (str + 10)
2. At first it will have no effect (your str is still +10).
3. After you die you can use the normal food and will give you additional +10 (resulting to +20str)


**Expected behavior**
It should not stack.

**Screenshots**
https://imgur.com/jlJXYHC

**System specs (please complete the following information):**
 - OS: [centos 7 x64]
 - Hercules Version [e.g. v2019.05.05+3]
 - Mode: [pre-renewal]
 - Packet version: [e.g. 20180620]
 - Client type: [RE]

**Plugins used or source modifications**
If you are using any plugins besides the ones that come bundled with Hercules,
please enumerate them here.

**Additional context**
Add any other context about the problem here. If the bug report is about a
crash, please attach the core/stack-dump or crash-log, if any.
","In official server, does normal food and cash food stacks?",7551429
525,Lif mental charge cooldown not reseted after vaporize,open,2019-05-29T10:15:49Z,2019-10-10T15:07:38Z,,NONE,"In battle.conf, hom_setting : 0x7D should permit skill cooldown reset for homunculus after vaporize. Works for every homunculus except Lif Mental Charge.

Any idea ?","Same also goes for Lif's Urgent Escape, because both these skills have an AfterCastActDelay set and are not using SkillData2 for cooldown + skill.c logic using skill->blockhomun_start() as all other Homunculus skills.

It's questionable if this is the official behavior. Especially since Lv. 5 Mental Charge has a global cooldown of 30 minutes! Which means that you can't use Helping Hands or any other skills of your Lif in that time!!

If you think that ""cooldowns"" that work similar to Lif Mental Charge or Urgent Escape should be reset as well with that setting, then change the following lines in homunculus.c at the function homunculus_vaporize:
```C
	if(battle_config.hom_setting&0x40)
		memset(hd->blockskill, 0, sizeof(hd->blockskill));
```

to this:
```C
	if (battle_config.hom_setting & 0x40) {
		memset(hd->blockskill, 0, sizeof(hd->blockskill));
		hd->ud.canact_tick = 0;
	}
```",7551429
526,Episode 17.1 : Illusion,open,2019-05-22T07:11:00Z,2019-07-18T16:27:04Z,,MEMBER,"This is a TODO list for updates from [Episode 17.1 : Illusion](http://ro.gnjoy.com/news/update/View.asp?seq=224)

- [ ] [EP 17.1 Updates](http://ro.gnjoy.com/news/update/View.asp?seq=224&curpage=1)
- [ ] [Max Level Increased to 185](http://ro.gnjoy.com/news/update/View.asp?seq=225&curpage=1)
- [ ] [Cards Update](http://ro.gnjoy.com/news/update/View.asp?seq=226&curpage=1)
- [ ] Illusion Dungeon
  - [ ] [Illusion of Labyrinth](http://ro.gnjoy.com/news/update/View.asp?seq=231&curpage=1)
- [ ] [Glast Heim Challenge Mode](http://ro.gnjoy.com/news/update/View.asp?seq=237&curpage=1)
- [ ] [Cooking Improvement](http://ro.gnjoy.com/news/update/View.asp?seq=238&curpage=1)
- [ ] [EDDA Bio Lab Update](http://ro.gnjoy.com/news/update/View.asp?seq=233&curpage=1)
- [ ] [Job Improvement](http://ro.gnjoy.com/news/update/View.asp?seq=235&curpage=1)
  - [ ] [Bishop New Skills + Update](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2725)
  - [ ] [Warlock Skills Update](http://ro.gnjoy.com/news/update/View.asp?seq=239&curpage=1)
- [ ] [Card Coin Trader NPC](http://ro.gnjoy.com/news/devnote/View.asp?category=1&seq=3964476&curpage=1)
- [ ] [Paradise Quest Completion Report Improvement](http://ro.gnjoy.com/news/devnote/View.asp?category=1&seq=3964476&curpage=1)



",,7551429
527,Episode 16.2 : Terra Gloria,open,2019-05-22T07:09:35Z,2019-05-25T15:19:15Z,,MEMBER,"This is a TODO list for updates from [Episode 16.2 : Terra Gloria](http://ro.gnjoy.com/news/update/View.asp?seq=182)

- [ ] [Rebellion Class Changes](http://ro.gnjoy.com/news/update/View.asp?seq=183&curpage=3)
- [ ] [Card Removal System Update](http://ro.gnjoy.com/news/update/View.asp?seq=188&curpage=2) [(GnjoyTW)](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2111) / [(iRO Wiki)](https://irowiki.org/wiki/Card_Desocketing)
- [ ] [Eden Group 2.0](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2775)
  - [ ] [Eden Group Changes (100-140)](http://ro.gnjoy.com/news/update/View.asp?seq=190&curpage=2)
- [ ] [Marriage System Update (Doram x Human)](http://ro.gnjoy.com/news/update/View.asp?seq=196&curpage=2)
- [ ] New Illusion Dungeon
  - [ ] [Illusion of Moonlight](http://ro.gnjoy.com/news/update/View.asp?seq=197&curpage=2)
  - [ ] [Illusion of Vampire](http://ro.gnjoy.com/news/update/View.asp?seq=199&curpage=2)
  - [ ] [Illusion of Frozen](http://ro.gnjoy.com/news/update/View.asp?seq=201&curpage=2)
  - [ ] [Illusion of Abyss](http://ro.gnjoy.com/news/update/View.asp?seq=205&curpage=2)
  - [ ] [Illusion of Teddy Bear](http://ro.gnjoy.com/news/update/View.asp?seq=219&curpage=1)
  - [ ] [Illusion of Luanda](http://ro.gnjoy.com/news/update/View.asp?seq=221&curpage=1)
- [ ] Memorial Dungeon
  - [ ] [Charleston Update](http://ro.gnjoy.com/news/update/View.asp?seq=220&curpage=1)
  - [ ] [Glastheim Changes](http://ro.gnjoy.com/news/update/View.asp?seq=198&curpage=2)
  - [ ] [Orc Memory Update](http://ro.gnjoy.com/news/update/View.asp?seq=211&curpage=1)
  - [ ] [Day Dungeon](http://ro.gnjoy.com/news/update/View.asp?seq=191&curpage=3)
- [x] [Party System UI Update](http://ro.gnjoy.com/news/update/View.asp?seq=208&curpage=2)
- [ ] [Autotrading / Vending Overhaul](http://ro.gnjoy.com/news/update/View.asp?seq=209&curpage=2)
- [ ] [Equipment Switch System](http://ro.gnjoy.com/news/update/View.asp?seq=210&curpage=1)
- [ ] [Monster Racing Revamp (Racing Cap Enchant)](http://ro.gnjoy.com/news/update/View.asp?seq=212&curpage=1)
- [ ] Card Updates
  - [ ] [New Cards](http://ro.gnjoy.com/news/update/View.asp?seq=214&curpage=2)
  - [ ] [Moscovia Card](http://ro.gnjoy.com/news/update/View.asp?seq=215&curpage=1)
  - [ ] [Brasilis Card](http://ro.gnjoy.com/news/update/View.asp?seq=207&curpage=2)
- [x] [World Map Improvements](http://ro.gnjoy.com/news/update/View.asp?seq=223&curpage=1)
- [ ] Global Project
  - [ ] [Castle of Dragon](http://ro.gnjoy.com/news/update/View.asp?seq=31)
  - [ ] [Rock Ridge](http://ro.gnjoy.com/news/update/View.asp?seq=194&curpage=2)
    - [ ] [Introduction](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2368#tab-1)
    - [ ] [New Maps & NPC](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2368#tab-2)
    - [ ] [Quests](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2368#tab-3)
    - [ ] [Item & Enchant](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2368#tab-4)
    - [ ] [Card Update](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2368#tab-5)
- [ ] [Expanded Class](http://ro.gnjoy.com/news/update/View.asp?seq=54)
- [ ] [Poring Village](http://ro.gnjoy.com/news/update/View.asp?seq=203&curpage=2)
- [ ] [Cart Expansion 2](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2866)
------------

Content that I am not so sure about it, found in Gnjoy TW. Could be just custom content for TWRO.
- [ ] Poring Village
  - [ ] [Event](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2362)
  - [ ] [Quests](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2348)
- [ ] [Runstone Update](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2112)
- [ ] [Homunculus Update](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2352)
- [ ] [Wild Wild Mt. Mjolnir](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2424)
- [ ] [Card Recycle](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2564)
- [ ] [Shadow Gear Enchant](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2636)
- [ ] [New Novice Walkthrough & Quests](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2778)",,7551429
528,Episode 16.1 : Banquet of Heroes,open,2019-05-22T07:07:46Z,2019-05-25T14:42:35Z,,MEMBER,"This is a TODO list for updates from [Episode 16.1 : Banquet of Heroes](http://ro.gnjoy.com/news/update/View.asp?seq=164&curpage=1)

- [x] [Achievement and Title System](http://ro.gnjoy.com/news/update/View.asp?seq=163&curpage=1)
- [ ] [Banquet Preparation](http://ro.gnjoy.com/news/update/View.asp?seq=165&curpage=1)
- [ ] [New Dungeon](http://ro.gnjoy.com/news/update/View.asp?seq=166&curpage=1)
- [ ] [Honor Tokens and New Enchant Item](http://ro.gnjoy.com/news/update/View.asp?seq=167&curpage=1)
- [ ] Memorial Dungeon
  - [ ] [Half Moon In The Daylight](http://ro.gnjoy.com/news/update/View.asp?seq=178)
  - [ ] [Infinite Space Improvements](http://ro.gnjoy.com/news/update/View.asp?seq=170&curpage=3)
- [x] [Item Link System (show your items via PM)](http://ro.gnjoy.com/news/update/View.asp?seq=175&curpage=3)
- [ ] [Eden Group Revamp (missions changed)](http://ro.gnjoy.com/news/update/View.asp?seq=176&curpage=3)
- [ ] [Reputation System](http://ro.gnjoy.com/news/update/View.asp?seq=177&curpage=3)
- [x] [Styling Shop Interface](http://ro.gnjoy.com/news/update/View.asp?seq=181&curpage=3)
",,7551429
529,Add *duplicate/remove npc  script command,open,2019-05-14T17:58:33Z,2020-01-18T08:59:08Z,,MEMBER,"<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
- `npc_duplicate(....)` duplicate any existing npc.
- `npc_duplicate_remove(...)` will remove any existing NPC other than itself.

Recently [kRO seem like added an item that will create a Treasure Chest NPC](https://forum.gamer.com.tw/C.php?bsn=4212&snA=421473&tnum=1&subbsn=23) nearby player to retrieve item. 
<details>

1. click on the item
![consume item](https://i.imgur.com/yxezZaU.jpg)

2. create a npc, talk to it, select to consume 1 key or 10 keys.
![create npc](https://i.imgur.com/ZiXqZOK.jpg)

3. obtain item
![obtain item](https://i.imgur.com/0x27CjF.jpg)

</details>

Anyway, its a useful script command.
Original src :  https://github.com/dastgirp/HPM-Plugins/blob/master/src/plugins/npc-duplicate.c

**Issues addressed:** <!-- Write here the issue number, if any. -->
none

**Known Issue:**
https://github.com/dastgirp/HPM-Plugins/issues/40 
Not sure if this issue still persists, cant seem to duplicate this issue for now.

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",@Asheraf ,7551429
530,Achievement update,open,2019-05-12T08:51:44Z,2019-05-12T16:56:43Z,,CONTRIBUTOR,"<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Implemented the following new achievement types:
1. ACH_ZENY_SPEND_VENDING - Spend a specific amount of zeny in one transaction to a vending player)
2. ACH_ZENY_SPEND_VENDING_TOTAL - (Accumulative) Spend a specific amount of zeny in total to a vending player
3. ACH_PET_INTIMACY - (Accumulative) Successfully reach a specific pet intimacy
4. ACH_PET_RUNAWAY - (Accumulative) Successfully make a pet runaway

Updated the following achievement criteria:
1. MobId criteria now accepts 0 as valid value for a wildcard achievement monster class

Update the following in script constant:
1. Moved Achievement types from constants.conf to script.c

<!-- Describe the changes that this pull request makes. -->

**Issues addressed:** <!-- Write here the issue number, if any. -->


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2470)
<!-- Reviewable:end -->
",7551429
531,"Missing addToSKILLDB, getFromSKILLDB and removeFromSKILLDB for plugins",open,2019-04-13T17:59:15Z,2019-04-13T17:59:15Z,,CONTRIBUTOR,"http://herc.ws/board/topic/11296-onpcuseskillevent/?do=findComment&comment=91025
missing `addToSKILLDB`, `getFromSKILLDB` and `removeFromSKILLDB` for plugins
if this is added, there's no need for the vector anyway

related topic/issue/commit
http://herc.ws/board/topic/7161-plugin-missing-hook-to-struct-item_data-and-mob_data/
https://github.com/HerculesWS/Hercules/pull/362
https://github.com/HerculesWS/Hercules/pull/416",,7551429
532,Loyal pet has extra bonus,open,2019-04-12T21:44:34Z,2019-04-15T02:15:43Z,,CONTRIBUTOR,"**Is your feature request related to a problem? Please describe.**
https://rathena.org/board/topic/105838-renewal-pet-bonus-implementation/?tab=comments#comment-359384

**Describe the solution you'd like**
[rathena pet_db.yml](https://github.com/rathena/rathena/blob/master/db/re/pet_db.yml)
```yml
  - Mob: PORING
    TameItem: Unripe_Apple
    EggItem: Poring_Egg
    EquipItem: Backpack
    FoodItem: Apple_Juice
    Fullness: 3
    IntimacyFed: 50
    CaptureRate: 2000
    Script: >
      .@i = getpetinfo(PETINFO_INTIMATE);
      
      if( .@i >= PET_INTIMATE_LOYAL ){
        bonus bLuk,2;
        bonus bCritical,1;
      }
    Evolution:
      - Target: MASTERING
        ItemRequirements:
          - Item: Leaf_Of_Yggdrasil
            Amount: 10
          - Item: Unripe_Apple
            Amount: 3
```

**Describe alternatives you've considered**
not really sure about just adding 
```
	EquipScript: <""
		bonus(bLuk, 2);
		bonus(bCritical, 1);
		if ( getpetinfo(PETINFO_INTIMACY) >= PET_INTIMATE_LOYAL )
			bonus(bLuk, 1);
	"">
```
maybe something like ... ?
```
	EquipScript: <""
		.@intimacy = getpetinfo(PETINFO_INTIMACY);
		if ( .@intimacy >= PET_INTIMATE_LOYAL ) {
			bonus(bLuk, 3);
			bonus(bCritical, 1);
		} else if ( .@intimacy >= PET_INTIMATE_CORDIAL ) {
			bonus(bLuk, 2);
			bonus(bCritical, 1);
		}
	"">
```

**Additional context**
I think this is official, otherwise rathena wont do it
```lua
	[9001] = {
		unidentifiedDisplayName = ""Poring Egg"",
		unidentifiedResourceName = ""수속성알"",
		unidentifiedDescriptionName = {
		},
		identifiedDisplayName = ""Poring Egg"",
		identifiedResourceName = ""수속성알"",
		identifiedDescriptionName = {
			""An egg in which a Poring Cute Pet rests."",
			""Can be hatched by using a ^6666CCPet Incubator^000000."",
			""If pet intimacy is Cordial, LUK +2, CRIT +1."",
			""If pet intimacy is Loyal, LUK +3, CRIT +1."",
			""^ffffff_^000000"",
			""Class:^6666CC Monster Egg^000000""
		},
		slotCount = 0,
		ClassNum = 0,
		costume = false
	},
```","Will the bonus stack? 

Hmm my pre re database doesnt have the same pet_db but re does . . . great ",7551429
533,pets after evolve by pet evolution are acting like monsters,open,2019-04-12T16:29:23Z,2019-12-26T08:48:23Z,,CONTRIBUTOR,"**Describe the bug**
pets after evolve by pet evolution are acting like monsters

**To Reproduce**
1. `@makeegg 1002` create a poring egg
2. `@hatch` hatch the poring egg
3. `@petfriendly 1000` intimacy to max
4. `@item Leaf_Of_Yggdrasil 10` `@item Unripe_Apple 3` and select pet evolution to Mastering
5. `@hatch` the mastering egg
-> now your mastering is uncontrollable

**Expected behavior**
this mastering pet should behave like poring

**Screenshots**
none

**System specs (please complete the following information):**
 - OS: Windows 7 Service Pack 1 Ultimate
 - Hercules Version: 2019-04-07
 - Packet version: 20180620
 - Mode: Renewal
 - Client type: ~[2018-06-20eRagexeRE](https://rathena.org/board/topic/117168-packetver-20180620-client-release-2018-06-20eragexere/)~ [2019-02-20aRagexeRE](http://nemo.herc.ws/clients/2019-02-20aRagexeRE/) tested both


**Plugins used or source modifications**
none

**Additional context**
_Originally posted by @AnnieRuru in https://github.com/HerculesWS/Hercules/pull/2428#issuecomment-482582880_",I'll work on that. Additionally some pet bonuses needs to be updated.,7551429
534,Cell Basilica block monster attack but didn't block monster entering/use skill.,open,2019-04-02T14:46:01Z,2020-01-14T09:18:55Z,,MEMBER,"**Describe the bug**
Monster that entered basilica area doesn't chase player who left the basilica area.

**To Reproduce**
Steps to reproduce the behavior:
1. Load this npc script
```
map,45,45,4	script	Sample	4_F_KAFRA1,{
	end;
	
	OnInit:
		getmapxy(.@map$, .@x, .@y, UNITTYPE_NPC);
		.@range = 3;
		setcell(.@map$, (.@x - .@range), (.@y - .@range), (.@x + .@range), (.@y + .@range), cell_basilica, true);
		end;
}
```
2. summon any aggresive monsters _(I tried with MVP monster)_
3. allow the monster to chase the character and enter the basilica area
4. move the character out from basilica area

**Expected behavior**
1. ~Monster shall be pushed away or refrain from entering basilica area. _(not sure if MVP should be refrain from entering too, skill description seem allow it)_~ [Any non-boss monsters in a 5 X 5 area next to the caster when Basilica's cast time is complete will be instantly pushed out of the area.](https://irowiki.org/wiki/Basilica)
2. If monster currently within the basilica area, it shall chase any characters if the they aren't within basilica area (within monster seen/chase/attack range).
3. ~Monster shouldn't able to cast/place AOE skills within the basilica area, although it doesn't deal any damage.~ [AOE Skills seem like still possible, Ex: Venom Splasher](https://irowiki.org/wiki/Basilica)

**Screenshots**
![pic](https://i.imgur.com/6F07PsB.png)

**System specs:**
 - OS:  window 10
 - Hercules Version https://github.com/HerculesWS/Hercules/commit/e1e951c805916853e55ff5b9ce0531e0cf483ebf
 - Mode: renewal
 - Packet version: 20180620
 - Client type: RE

**Plugins used or source modifications**
None

**Additional context**
Probably related Issues : https://github.com/HerculesWS/Hercules/issues/789 and https://github.com/HerculesWS/Hercules/issues/1991

Not sure if this is the actual behavior that currently work in kRO. ","MVPs interaction with Basilica is bugged until this is merged:
https://github.com/HerculesWS/Hercules/pull/2612",7551429
535,Achievement Parents Bug.,open,2019-04-01T03:10:29Z,2019-04-01T07:57:12Z,,NONE,"**Describe the bug**
Achievement with parents, Its simple just try to tame a Poring and the date of achievement will show 1970.1.1 and cannot redeem the reward.

**To Reproduce**
Steps to reproduce the behavior:
1. Clean herc
2. Clean client
3. Tame poring
4. See achievement date.

**Screenshots**
https://imgur.com/a/muYLQOd

**System specs (please complete the following information):**
 - OS: Windows 10
 - Hercules Version: Latest
 - Mode: Pre-renewal
 - Packet version: 20150916
 - Client type: RE","is this what they call **a race condition** ?
<details>
<summary>I tested with this diff</summary>

```diff
 src/map/achievement.c | 19 +++++++++++--------
 1 file changed, 11 insertions(+), 8 deletions(-)

diff --git a/src/map/achievement.c b/src/map/achievement.c
index 057ea29c3..709d27b05 100644
--- a/src/map/achievement.c
+++ b/src/map/achievement.c
@@ -159,7 +159,7 @@ static bool achievement_check_complete(struct map_session_data *sd, const struct
 	for (i = 0; i < VECTOR_LENGTH(ad->objective); i++)
 		if (ach->objective[i] < VECTOR_INDEX(ad->objective, i).goal)
 			return false;
-
+ShowDebug( ""check_complete '%s'\n"", ad->name );
 	return true;
 }
 
@@ -180,23 +180,26 @@ static void achievement_progress_add(struct map_session_data *sd, const struct a
 
 	Assert_retv(progress != 0);
 	Assert_retv(obj_idx < VECTOR_LENGTH(ad->objective));
-
+ShowDebug( ""run achievement_progress_add '%s'\n"", ad->name );
 	if ((ach = achievement->ensure(sd, ad)) == NULL)
 		return;
-
+ShowDebug( ""before ach->completed_at '%s'\n"", ad->name );
 	if (ach->completed_at)
 		return; // ignore the call if the achievement is completed.
-
+ShowDebug( ""after ach->completed_at '%s'\n"", ad->name );
 	// Check and increment the objective count.
 	if (!ach->objective[obj_idx] || ach->objective[obj_idx] < VECTOR_INDEX(ad->objective, obj_idx).goal) {
 		ach->objective[obj_idx] = min(progress + ach->objective[obj_idx], VECTOR_INDEX(ad->objective, obj_idx).goal);
-
+ShowDebug( ""before if (achievement->check_complete(sd, ad)) { '%s'\n"", ad->name );
 		// Check if the Achievement is complete.
 		if (achievement->check_complete(sd, ad)) {
+ShowDebug( ""inside if (achievement->check_complete(sd, ad)) { 1. '%s' %d %d\n"", ad->name, ad->id, ach->completed_at );
 			achievement->validate_achieve(sd, ad->id);
+ShowDebug( ""inside if (achievement->check_complete(sd, ad)) { 2. '%s' %d %d\n"", ad->name, ad->id, ach->completed_at );
 			ach->completed_at = time(NULL);
+ShowDebug( ""inside if (achievement->check_complete(sd, ad)) { 3. '%s' %d %d\n"", ad->name, ad->id, ach->completed_at );
 		}
-
+ShowDebug( ""ach->completed_at '%s' %d %d\n"", ad->name, ad->id, ach->completed_at );
 		// update client.
 		clif->achievement_send_update(sd->fd, sd, ad);
 	}
@@ -219,7 +222,7 @@ static void achievement_progress_set(struct map_session_data *sd, const struct a
 
 	Assert_retv(progress != 0);
 	Assert_retv(obj_idx < VECTOR_LENGTH(ad->objective));
-
+ShowDebug( ""Run achievement_progress_set '%s'\n"", ad->name );
 	if (progress >= VECTOR_INDEX(ad->objective, obj_idx).goal) {
 
 		if ((ach = achievement->ensure(sd, ad)) == NULL)
@@ -885,7 +888,7 @@ static void achievement_validate_achieve(struct map_session_data *sd, int achid)
 
 	nullpo_retv(sd);
 	nullpo_retv(ad);
-
+ShowDebug( ""run achievement_validate_achieve '%d'\n"", achid );
 	if (sd->achievements_received == false)
 		return;
```

</details>

display showdebug as
```
[Debug]: run achievement_progress_add 'Poring - taming'
[Debug]: before ach->completed_at 'Poring - taming'
[Debug]: after ach->completed_at 'Poring - taming'
[Debug]: before if (achievement->check_complete(sd, ad)) { 'Poring - taming' 
[Debug]: check_complete 'Poring - taming'
[Debug]: inside if (achievement->check_complete(sd, ad)) { 1. 'Poring - taming' 230101 0
[Debug]: run achievement_validate_achieve '230101'
[Debug]: Run achievement_progress_set 'Poring is Love'
[Debug]: Run achievement_progress_set 'Achieve Level 1'
[Debug]: check_complete 'Achieve Level 1'
[Debug]: run achievement_validate_achieve '240001'
[Debug]: check_complete 'Achieve Level 1'
[Debug]: inside if (achievement->check_complete(sd, ad)) { 2. 'Poring - taming'
230101 0
[Debug]: inside if (achievement->check_complete(sd, ad)) { 3. 'Poring - taming'
230101 1554104302
[Debug]: ach->completed_at 'Poring - taming' 230101 1554104302
[Debug]: check_complete 'Poring - taming'
```
why does the 'Achieve Level 1' cuts in to this function ?

and also when read the `char_achievements` table, only 1 achievement is mark as complete
which is, not surprisingly, achievement ID 240001, which is 'Achieve Level 1'

<details>
<summary>the result get from `char_achievements` table</summary>

char_id | ach_id | completed_at | rewarded_at | obj_0 | obj_1 | obj_2 | obj_3 | obj_4 | obj_5 | obj_6 | obj_7 | obj_8 | obj_9
-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --
150000 | 230101 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 230100 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240001 | 1554104302 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240002 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240003 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240004 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240005 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240006 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240007 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240008 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240009 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240010 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240011 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240012 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240013 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240014 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240015 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240016 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240017 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240018 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240019 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 240020 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 220023 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 220024 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 220025 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 220026 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 220027 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 220028 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
150000 | 220029 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0

</details>

perhaps some function has to rewrite to eliminate this race condition ...

so yes, if there are 2 or more achievement update at the same time,
only 1 achievement will set the `ach->completed_at` value

PS: truncate the `char_achievements` table ...",7551429
536,(WIP) Add skill_check_invalid_level for plugin,open,2019-03-25T13:30:50Z,2019-04-10T11:22:24Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Issues addressed
` skill TF_HIDING, -1;` <-- actually gives you hiding skill level 255

### Changes Proposed
Add skill_check_invalid_level for plugin
http://herc.ws/board/topic/16616-portal-skill/?do=findComment&comment=91018

### Affected Branches
* Master

### Known Issues and TODO List
none","For example in ``skill_get_range``
But need check all herc code what this arrays never used directly as ``array[skill_level]``",7551429
537,Delay on skill and walk,open,2019-03-25T07:32:30Z,2019-03-25T09:06:10Z,,NONE,"**Describe the bug**
Herc: The next skill will only be activated AFTER the previous skill has finished its casting time.

**Expected behavior**
Official: When your character is about to finish casting it's recent skill, (like the picture shown below) and you prompted to use a new skill by pressing its corresponding hotkey even before it finished it's casting, it will automatically be casted right after your recent skill.

Official Video: https://youtu.be/MR-RLcTnfqA

Screenshot:
![1](https://user-images.githubusercontent.com/4656578/54901989-12ce6580-4f13-11e9-9014-b6831cbd5eea.jpg)

Notes:
	- Also, the Skill being casted is about 95%~ complete and you prompted your character to WALK, its going to WALK RIGHT AWAY. (Maybe because it only reads a command AFTER you fully used/casted a skill)
	- Ground skills are good. You can compare the Ground Skills to Self-Skills (with no delay skill like Energy Coat, CH_SOULCOLLECT etc.) for you guys to reproduce the bug easily.
	- The ""95%"" casting is only based on my observation wherein you can follow up a next skill after the cast time of your recent skill. (Again, by clicking the desired skill to be used/casted before it finished its casting)
",I believe hercules behavior was done to prevent 3rd party hack ....,7551429
538,Deprecate *getunitname script command,open,2019-02-27T18:17:16Z,2019-03-02T21:04:36Z,,CONTRIBUTOR,"After I give it some thought, I think better split the `*getunitname` deprecation out from https://github.com/HerculesWS/Hercules/pull/2391

-----------------------------------

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Issues addressed
we have 2 script command do the same thing, `*rid2name` and `*getunitname`

### Changes Proposed
deprecate `*getunitname` because rid2name has been exist since eathena times
also minor fix rid2name to support elementals

### Affected Branches
* Master

### Known Issues and TODO List
we have to decide which one to deprecate,
better don't have 2 script commands do exact same thing again, like this https://github.com/HerculesWS/Hercules/pull/2089","..... I was lost in making getmercinfo/getpetinfo/gethominfo/geteleminfo,

actually I want to keep both

getunitname will be real time name, and rid2name will be database name

example 1.
if player having `@fakename`,
getunitname will display fakename
rid2name will display real character name

example 2
`monster(""this"", -1,-1,""BOSSS"",PORING,1)`
getunitname will display `BOSSS`
rid2name will display `Poring`

I read through the source code and found getunitname call the function status_get_name,
which was use in clif ..... to display in client-side

.... another thing worth mention
DO NOT use `getnameditem Knife, getunitname(getcharid(CHAR_ID_ACCOUNT));`
because if the player under `@fakename`,
`*getunitname` script command will return fakename of the character
has to use rid2name


_..... ok go back complete my getpetinfo script command ...._
scrap this one, redo the above
https://github.com/AnnieRuru/customs/blob/master/plugin/rid2name.diff",7551429
539,Client still crashes on disguise (party window),open,2019-02-27T07:57:37Z,2019-10-05T19:02:41Z,,NONE,"**Describe the bug**
Client still crashes when party member are in Disguise and you check party-windows.

**To Reproduce**
Steps to reproduce the behavior:
1. 2 players on party.
2. Player A: @disguise Poring
3. Player B: While Alt+Z, Walk far on the screen without seeing player A, then go Back then do Alt+Z twice.
4. See error

**Expected behavior**
I think its the HP bar that makes the client crash.

**System specs (please complete the following information):**
 - OS: Windows 10
 - Hercules Version: Latest
 - Mode: Pre-renewal
 - Packet version: 20150916
 - Client type: RE

**Additional context**
It is related to https://github.com/HerculesWS/Hercules/commit/3e6e76b8c673e99d240a700912eb4d4a68b3be30 But its still bug.
","I did some tests (using 2018-10-02) and **my guess** is that the problem is the objectType we send to clients. If you disguise as a player class, it works fine, but once you disguise as a npc, the problem shows up.

disguising calls `clif_spawn` which calls `clif_spawn_unit`. If you change `p.objecttype = clif->bl_type(bl);` to always send the object as a ""player"", the HP bar and party window keeps working, but everybody will see your character as a novice (probably because the client can't find the monster ID as a player job, so it uses the default sprite)

The HP bar going to 0 when you undisguise seems to be fixable if you call `clif->party_hp` after `clif->spawn` in `pc->disguise`. But this doesn't fix the real problem.",7551429
540,Documentation and warnings related to mapflags scripts commands,open,2019-02-25T18:59:48Z,2019-03-08T12:31:56Z,,NONE,"**Describe the bug**
Documentation of commands like ```setmapflag```, ```gatmapflag``` and ```removemapflag``` specify the use of *mf_xxx* constants in lower case, but if you use lower case they dont do anything. I looked at script.h for those constants and they are all UPPER CASE.

Using those constants in upper case make those commands work, but a warning appears in the terminal/console saying you should use lower case.",for case-sensitivity may refer @MishimaHaruna's https://github.com/HerculesWS/Hercules/issues/685#issuecomment-136308412 for reference.,7551429
541,Add battleconf for party leave behavior,open,2019-02-25T11:35:58Z,2019-02-26T10:22:18Z,,CONTRIBUTOR,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

_Note: Was unsure of the best way to go about this._

Some time ago the behavior was changed for when a party leader leaves the party. I feel a config option should have been added to retain the old behavior.

**Old:** Disband the party.
**Current:** Pass the party leader to another player.
**New:** Uncomment `#define PARTY_LEADER_LEAVE` in `src/config/classes/general.h`

Perhaps others can input on a better way to implement a config option.

**Issues addressed:** <!-- Write here the issue number, if any. -->

N/A

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",I changed it to a battleconf option. I don't really understand it all. Let me know what you think.,7551429
542,Job_Super_Novice_E is not supposed to be 3rd job,open,2019-02-23T10:14:56Z,2019-03-10T22:28:07Z,,CONTRIBUTOR,"**To Reproduce**
`@job 4190` change job into Job_Super_Novice_E 
`@bodystyle 1` instantly crash the client


**Describe the bug**
Supposely only 3rd jobs can change body style,
but currently Job_Super_Novice_E (4190) is consider a 3rd class job
`EAJ_SUPER_NOVICE_E:        0x4100`
which break down as
EAJL_THIRD | EAJL_2_1


**Expected behavior**
Asheraf said in discord

> @AnnieRuru that is more of a mistake with super novice, it should be in 2nd jobs category not 3rd (from decompiled aegis, job 23 is 1st class, job 4190 is second class)


**System specs (please complete the following information):**
 - OS: Windows 7 Service Pack 1 Ultimate
 - Hercules Version: 2019-2-11
 - Packet version: 20180620
 - Mode: Renewal
 - Client type: [2018-06-20eRagexeRE](https://rathena.org/board/topic/117168-packetver-20180620-client-release-2018-06-20eragexere/)


**Additional context**
our eaclass() doesn't have EAJL_1 ...
should we make a new one ?
https://github.com/AnnieRuru/customs/blob/master/plugin/ea_super_novice.diff","@AnnieRuru you can create a pr with that temporary fix, but we're keeping this open since the source problem is not fixed.",7551429
543,"Adds UDT_MOBID for getunitdata & setunitdata, which retrieves actual mob id",open,2019-02-21T00:09:56Z,2019-02-28T15:25:30Z,,CONTRIBUTOR,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

<!-- Describe the changes that this pull request makes. -->
Adds `UDT_MOBID` for `getunitdata()` and `setunitdata`.

This is necessary because `getunitdata(<Mob GID>, UDT_CLASS)` retrieves the Sprite ID for BL_MOB. Which means if you use it on a mob which was generated using **db\mob_avail.txt**, then you will not get the actual Monster ID.

**Issues addressed:** <!-- Write here the issue number, if any. -->
N/A

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","I never encounter this problem, so its probably your bad scripting method
should place each group into separated event labels
and if you want to kill all monsters in the map, there are `*killmonsterall` and `*killmonster` with ""All"" flag

custom, so I make a plugin
```
#include ""common/hercules.h""
#include ""map/mob.h""
#include ""map/script.h""
#include ""common/HPMDataCheck.h""

HPExport struct hplugin_info pinfo = {
	""getmonsterlabel"",
	SERVER_TYPE_MAP,
	""0.1"",
	HPM_VERSION,
};

BUILDIN(getmonsterlabel) {
	struct mob_data *md = map->id2md( script_getnum(st,2) );
	if ( !md ) {
		ShowWarning( ""buildin_getmonsterlabel: Error in finding object GID or target GID is not a monster.\n"" );
		return false;
	}
	script_pushconststr( st, md->npc_event );
	return true;
}

HPExport void plugin_init(void) {
	addScriptCommand( ""getmonsterlabel"", ""i"", getmonsterlabel );
}
```
and get the script done as ...
```
prontera,155,185,5	script	qwer	1_F_MARIA,{
	monster ""this"", -1,-1, ""--ja--"", PORING, 10, strnpcinfo(NPC_NAME)+""::Onaaa"";
	monster ""this"", -1,-1, ""--ja--"", POPORING, 10, strnpcinfo(NPC_NAME)+""::Onbbb"";
	end;
Onaaa:
Onbbb:
	end;
}

prontera,160,185,5	script	asdf	1_F_MARIA,{
	.@count = getunits( BL_MOB, .@mobid, false, strnpcinfo(NPC_MAP) );
	for ( .@i = 0; .@i < .@count; ++.@i ) {
//		sscanf getmonsterlabel(.@mobid[.@i]), ""%s::%s"", .@npc_name$, .@label$; // f*cking sscanf doesn't work
//		if ( .@npc_name$ == ""qwer"" ) // alright, let's use regular expression
		if ( getmonsterlabel(.@mobid[.@i]) ~= ""([^:]*)::([A-Za-z_]*)"" )
			if ( $@regexmatch$[1] == ""qwer"" )
				unitkill .@mobid[.@i];
	}
	end;
}
```

by the way this question should be asked on the forum ....",7551429
544,Missing several features for Random Option ,open,2019-02-19T18:49:52Z,2019-08-07T13:48:20Z,,CONTRIBUTOR,"A full list of (Missing) Random Options

- [x] Initial commit for Item Random Option (https://github.com/HerculesWS/Hercules/pull/1598)
- [ ] getitem3/delitem3/countitem3
- [ ] makeitem3
- [ ] rentitem3
- [ ] getitembound3
- [x] Support monster drops with Random Options (https://github.com/HerculesWS/Hercules/pull/2309)
- [ ] getinventorylist/getcartinventorylist <-- I think script.c already done, just not yet update documentation
- [ ] rodex_sendmail3
- [ ] @sold_option_id/@sold_option_val/@sold_option_param from `OnSellItem:` label, `*callshop` script command

btw I don't really have time to do this ... hopefully some kind souls can help out","because `*getinventorylist` script command ignore the missing index in your inventory
just try [my `*getinventorylistidx` script command](http://herc.ws/board/topic/16604-retrieve-inventory-index-getinventorylistidx-delitemidx-equipidx/#comment-90658)",7551429
545,progressbar should allow movement,open,2019-02-15T03:47:26Z,2019-03-08T13:59:01Z,,CONTRIBUTOR,"**Describe the bug**
https://rathena.org/board/topic/118266-npcscriptcont-unexpected-state-2-for-continue-call/?sortby=date

**To Reproduce**
```
prontera,155,185,5	script	F_PetTrader	1_F_MARIA,{
	progressbar """", 5;
//	progressbar_unit """", 5, getnpcid();
}
```

**Expected behavior**
https://github.com/rathena/rathena/issues/1425

**Screenshots**
click on the link above

**System specs (please complete the following information):**
 - OS: Windows 7 Service Pack 1 Ultimate
 - Hercules Version: 2019-2-11
 - Packet version: 20180620
 - Mode: Renewal
 - Client type: [2018-06-20eRagexeRE](https://rathena.org/board/topic/117168-packetver-20180620-client-release-2018-06-20eragexere/)


**Plugins used or source modifications**


**Additional context**
should we emulate official bug ?
although I can tell people going to yell why hercules doesn't allow movement to break free from progressbar","I think kRO changed the behavior later on, like annie commented above:
> I talked to aleos in discord about this issue,
> he said the progressbar behavior has changed since ... dunno when ...

that's another reason that might be a good idea to make it a battle option, as this could be a re-only behavior",7551429
546,Adds BUILDIN(equipidx); BUILDIN(equip) now returns 0 or 1.,open,2019-01-22T14:00:28Z,2019-09-12T10:59:32Z,,CONTRIBUTOR,"### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
1. Adds new buildin **equipidx()**.
i.e. `equipidx(<index>{, <item id>})`

The reason for this change is it allows you the option to choose the specific inventory index to equip. Of course, you need to know the inventory index.

Currently I am using this in a mass refiner script. Since you need to equip an item to refine it, I was having trouble due to the equip() command always equipping the lowest index (I believe that's what it was doing).

Here is a sample in which all the different versions of 'Knife' are cycled through and equipped every 1 second.
```
.@id = Knife;
getinventorylist();
for (.@i = 0; .@i < @inventorylist_count; .@i++) {
	if (@inventorylist_id[.@i] == .@id) {
		.@Index[.@j] = .@i;
		.@j++;
		.@count++;
	}
}

for (.@i = 0; .@i < .@count; .@i++) {
	equipidx(.@Index[.@i], .@id);
	sleep2(1000);
}
end;
```

2. equip(<item id>) now returns 0 or 1 depending on whether the item successfully equipped.

**Issues addressed:** <!-- Write here the issue number, if any. -->
N/A

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","```
/*=================================================
 * Checks if the player can equip the item at index n in inventory.
 * Returns 0 (no) or 1 (yes).
 *------------------------------------------------*/
static int pc_isequip(struct map_session_data *sd, int n)
```
try introduce a new script command `*canequip` to check if that item can be equip ?",7551429
547,Adds support for <account id> param for getcharid(). Deprecates charid2rid.,open,2019-01-13T04:16:32Z,2020-01-11T08:04:26Z,,CONTRIBUTOR,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
- Adds support for **account id** to `getcharid()`.
I.e.
`getcharid(<type>{, ""<character name>""})`
`getcharid(<type>{, <account id>})`

- Deprecates `charid2rid()` in favour of `getcharid(CHAR_ID_ACCOUNT, <char id>)`.

**Issues addressed:** <!-- Write here the issue number, if any. -->
N/A

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","@MishimaHaruna 
> What does everyone else think?

I do agree with you. In my opinion this special case unnecessary. If someone is able to pass a character ID to retrieve the corresponding account ID, he should also be able to pass the character's name instead.",7551429
548,HerculesWS Dockerized,open,2019-01-04T02:15:21Z,2019-12-29T19:07:28Z,,NONE,"**Is your feature request related to a problem? Please describe.**
I'm always frustrated when I'm setting up to develop and then for production.

**Describe the solution you'd like**
create an environment with docker that contains everything you need: dockerfile, docker-compose.dev docker-compose.productiont. and that is ready to swarm or k8s

",,7551429
549,Added configuration to fullprotect skill,open,2018-11-27T11:37:28Z,2018-12-14T00:23:35Z,,CONTRIBUTOR,"- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
Today, the equip protect status (SC_PROTECTWEAPON, SC_PROTECTHELM, SC_PROTECTARMOR, and SC_PROTECTSHIELD) only apply if there's equip on a respective slot.

Old days, the protect status, apply without the test. So, protect shield work with no shield equip. This PR creates a config that allows going back old days =]

**Issues addressed:**
There is no issues


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","instead of having `1` or `0` to set the configuration, why not create it as a bitmask value that allow different type of combination depend on user need? It would allow much better customization that user may need?
Ex:
```
1 - Enable for Strip Helm Skill
2 - Enable for Strip Armer Skill
4 - Enable for Strip Shoes Skill
8 - Enable for Strip Weapon Skill
16 - Enable for Strip Accessory Skill
32 - Enable for FCP Skill
etc...
``` ",7551429
550,Implementation of bargain sale,open,2018-11-23T14:03:59Z,2018-12-31T09:56:09Z,,NONE,"**Is your feature request related to a problem? Please describe.**
No
**Describe the solution you'd like**

This feature does have a certain time in the ragnarök. It allows placing items in purchase promotion and with limited quantity.

This would be interesting to be able to add promotions on special date sales

![2qduatc](https://user-images.githubusercontent.com/38480564/48947307-d44e7d00-ef17-11e8-853f-faa6d0930970.png)

",,7551429
551,Error creating instance for character,open,2018-11-18T00:08:01Z,2019-07-31T23:58:44Z,,NONE,"**Describe the bug**

When creating an instance using **CHAR_ID_CHAR** and character relogin the instance window does not appear, but the instance is already created, if you make use of **CHAR_ID_PARTY** when relogin character appears the window normally.

This bug causes a big problem because it is possible for a player to generate multiple instances because when the character does relogin it is not possible to enter the instance, it needs to generate another, and the one that was previously opened continues

**To Reproduce**
Earth Tower Test:
1. change `.@party_id = getcharid(CHAR_ID_PARTY);`
2. to `.@party_id = getcharid(CHAR_ID_CHAR);`
3. change `.@instance = instance_create(.@md_name$, .@party_id);`
4. to `.@instance = instance_create(.@md_name$, .@party_id, IOT_CHAR);`
5. Now run the emulator and create the instance and relogin character

**Expected behavior**

The correct one would be to show the instance window with the remaining time.

![test](https://user-images.githubusercontent.com/39016868/48667031-730c5100-eab4-11e8-9032-86d0b99937b6.png)


**System specs (please complete the following information):**
 - OS: [windows 8]
 - Hercules Version [v2018.10.21]
 - Mode: [pre-renewal]
 - Packet version: [20181017]
 - Client type: [main]

**Plugins used or source modifications**
None

**Additional context**
None
","@marcosbucarte Change `.@party_id = getcharid(CHAR_ID_CHAR);` to `.@party_id = getcharid(CHAR_ID_ACCOUNT);`
",7551429
552,"Reflex, SAFETYWALL, letter bonus vs CARTTERMINATION",open,2018-11-16T13:15:43Z,2018-11-16T13:16:54Z,,NONE,"I've been getting a lot of complaints about these two issues from both emulators and administrators so I can do my services.

1 - Wall holding Wizz, is blocking damage, more reflecting if the player has a reflex card like OL.

2- Shock of the cart suffering in the same way for the bonus of reflecting cards or equipment.

Reference the following topics.

http://herc.ws/board/tracker/issue-7792-safety-wall-reflect-bug-body-relocation-error/

http://herc.ws/board/tracker/issue-6938-autoguard-safety-wall-with-damage-return/?gopid=15952#entry15952

http://herc.ws/board/tracker/issue-5328-bonus-bshortweapondamagereturn-vs-cart-termination/?gopid=7043#entry7043


I'll leave the solution for you that suits you.


Cart Termination:

> Search for:
> ----------------------------------------------------------------
> if (flag & BF_SHORT) {//Bounces back part of the damage.
> ---------------------------------------------------------------
> 
> 
> add below:
> ---------------------------------------------------------------
> 		if (!status_reflect && skill_id == WS_CARTTERMINATION && !status_bl_has_mode(src, MD_STATUS_IMMUNE)) // ignorando todo o refletir (psyz)
> 		{
> 			rdamage = 0;
> 			return 0;
> 		}
> ------------------------------------------------------------------
> 
> change:
> -----------------------------------------------
> if (!status_reflect && sd && sd->bonus.short_weapon_damage_return) {
> ------------------------------------------------
> 
> per:
> --------------------------------------------------------------------------
> else if (!status_reflect && sd && sd->bonus.short_weapon_damage_return) {
> --------------------------------------------------------------------------


SAFETYWALL:

> search for: (battle_calc_return_damage)
> -----------------------------------------------------
> 	if (ssc && ssc->data[SC_INSPIRATION]) {
> 		rdamage += damage / 100;
> #ifdef RENEWAL
> 		rdamage = cap_value(rdamage, 1, max_damage);
> #else
> 		rdamage = i64max(rdamage, 1);
> #endif
> 	}
> ---------------------------------------------------------
> 
> add below:
> 
> -------------------------------------------------------------
> 		if (sc && sc->data[SC_SAFETYWALL] ||  sc->data[SC_BASILICA] && !status_bl_has_mode(src, MD_STATUS_IMMUNE))
> 		{
> 			rdamage = 0;
> 			return false;
> 		}",,7551429
553,Slave clone can't hit an evil clone.,open,2018-11-08T22:34:19Z,2020-01-25T00:53:46Z,,MEMBER,"**Describe the bug**
Clone that made using `@slaveclone` doesn't capable to attack clone made by `@evilclone`.

**To Reproduce**
Steps to reproduce the behavior:
1. Summon a clone using `@clone Emistry`
2. Summon an evil clone using `@evilclone Emistry`
3. Summon a slave clone using `@slaveclone Emistry`
4. let them fight each other, observe the `@clone` and `slaveclone` attack the `@evilclone`.

**Expected behavior**
Slave clone shall not miss when attacking the `@evilclone`.

**Screenshots**
Preview : 
> Char Information:  
> Level 175 - All stats 99
> No armor equipped, only a Spear

`@clone` - the clone located at top left, attacking `@evilclone` without fail.
`@evilclone` - the clone located at top right, attacking `@clone` without fail.
`@slaveclone` - the clone located at bottom, attacking `@evilclone` **but failed**.
![Image of Yaktocat](https://i.imgur.com/CHWnP2A.gif)

**System specs (please complete the following information):**
 - OS: [Windows 10]
 - Hercules Version https://github.com/HerculesWS/Hercules/commit/1f7d4f00a52a6b32981ef54fb4a5514ece6f75df
 - Mode: [renewal]
 - Packet version: [e.g. 20150513]

**Plugins used or source modifications**
none

**Additional context**
none
","@Emistry
I did some more testing and you're right. `dmg_taken_rate` isn't related to this issue explicitly.
Adding `db->dmg_taken_rate = 100;` to `mob_clone_spawn()` only fixes the invulnerability of the other clones. The evil clone is still invulnerable to the attacks of the slave clone.

I investigated the damage calculation a bit deeper and it seems, that this is not a bug. The evil clone's defense simply is too high for the slave clone to be able to hit.
A good way to show the slave clone's low hit rate is to make it fight an ordinary clone (`@clone`).
The slave clone will miss most of the time, but rarely is able to land a hit...",7551429
554,Equipping Arrow,open,2018-10-24T19:15:21Z,2019-11-21T07:00:20Z,,NONE,"On official Renewal, you can't put arrow on if your Bow/Musical/Whip is not equipped. 

Official screenshot:
![1](https://user-images.githubusercontent.com/4656578/47455320-29597f00-d804-11e8-95ee-aa28deba348c.jpg)

",Rathena fixes: https://github.com/rathena/rathena/commit/d3d8f3c5a7459ef1f76ae379e9d6013dc489bc1a,7551429
555,mesf npc/other,open,2018-10-23T21:30:06Z,2018-12-19T05:06:14Z,,CONTRIBUTOR,"<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
mes to mesf npc/other
<!-- Describe the changes that this pull request makes. -->

**Issues addressed:** <!-- Write here the issue number, if any. -->
https://github.com/HerculesWS/Hercules/issues/2233

<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2306)
<!-- Reviewable:end -->
",7551429
556,Images,open,2018-10-23T17:02:42Z,2019-06-08T09:17:04Z,,NONE,"Image corporate.

<!-- Before you continue, please change ""base: stable"" to ""base: master"" and
     enable the setting ""[√] Allow edits from maintainers."" when creating your
     pull request if you have not already enabled it. -->

<!-- Note: Lines with this <!-- syntax are comments and will not be visible in
     your pull request. You can safely ignore or remove them. -->

### Pull Request Prelude

<!-- Thank you for working on improving Hercules! -->
<!-- Please complete these steps and check the following boxes by putting an `x`
     inside the [brackets] before filing your Pull Request. -->

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR may be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

<!-- Describe the changes that this pull request makes. -->

**Issues addressed:** <!-- Write here the issue number, if any. -->


<!-- You can safely ignore the links below:  -->

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","Instead of putting the logo under the header (which looks weird), we could put it directly on the header:
```markdown
# ![Hercules Logo](https://user-images.githubusercontent.com/3507758/48214059-222a8900-e34d-11e8-871f-9036112c8aa4.png) Hercules
```

Which renders to:

# ![Hercules Logo](https://user-images.githubusercontent.com/3507758/48214059-222a8900-e34d-11e8-871f-9036112c8aa4.png) Hercules",7551429
557,Added some missing events.,open,2018-10-22T02:52:53Z,2020-01-12T16:13:55Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

- (Master)

**Issues addressed:**

Surprisingly I'm not completely done contributing to this project. :p

I took some time this last week or so to go through some of the missing event scripts as well as fix some stuff up.

This Pull Requests does the following:

* Adds 2006 Xmas event script.
* Adds 2007 Xmas event script.
* Adds 2009 Xmas event script.
* Adds 2010 Xmas event script.
* Adds 2010 Valetine's Day event script.
* Adds 2010 April Fool's Day event script.
* Properly dates the existing Xmas, Whiteday, and Valetine's Day scripts.

The dates for the 2004 scripts were confirmed by looking through jAthena files and comparing the quest's contents with event posts from jRO, iRO, and kRO.

I'll be back with more scripts later.

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2303)
<!-- Reviewable:end -->
",7551429
558,MSC_MYSTATUSOFF,open,2018-10-21T04:51:10Z,2018-10-21T04:51:23Z,,NONE,"Since it isn't used by anything it seems like this went ignored for a long time.

It takes the ""lack of status x"" condition quite literally and the skill will be used regardless of that specific status being applied at any point at all, it's basically the same as MSC_ALWAYS.",,7551429
559,HULD Compatibility for amatsu.txt,open,2018-10-19T14:36:48Z,2019-04-28T15:39:15Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Minor edits to npc/cities/amatsu.txt to make it HULD compatible.
**Affected Branches:** 

[//]: # (Master? Slave?)
stable
**Issues addressed:**

[//]: # (Issue Tracker Number if any.)
#2233 
### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2295)
<!-- Reviewable:end -->
",7551429
560,Adds @who4 command (excludes vendors from @who list).,open,2018-10-16T07:20:47Z,2018-10-26T01:04:25Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Adds the `@who4` command. Same as regular `@who`, but excludes vendors from the list.

**Affected Branches:** 

[//]: # (Master? Slave?)
- [x] master
- [x] stable

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)
N/A

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)
N/A

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",probably better convert all this ``@whoN`` into one ``@who`` command with bit field parameter for include or exclude each type of players,7551429
561,Checkwall,open,2018-10-12T08:56:33Z,2018-10-26T01:09:00Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
1. Adds the `checkwall()` script command, which will return if wall exists. Needed for scripts which attempt to delete non-existent walls.
2. Adds the new `checkwall()` to agit_main_se script, which attempts to delete a non-existent wall when War of Emperium starts.

**Affected Branches:** 

[//]: # (Master? Slave?)
- [x] master
- [x] stable

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)
#2119 

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)
None known.

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","```
<info> can be:
WALLINFO_MAP        map name
WALLINFO_X          X axis location
WALLINFO_Y          Y axis location
WALLINFO_DIR        direction
WALLINFO_SHOOTABLE  whether or not it's shootable
```
Dont forget `WALLINFO_SIZE` too, to return the size of the wall 
",7551429
562,#2060 updated map_cache documentation in markdown syntax to reflect t…,open,2018-10-08T22:30:25Z,2019-10-12T18:24:29Z,,NONE,"…he new map_cache system

[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
The documentation for the map_cache system did not match with the new system. So I created a markdown document to reflect the changes as shown in this [guide](http://herc.ws/board/topic/15868-guide-mapcache-generation-2018/)

**Affected Branches:** 
Master

**Issues addressed:**
#2060 

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","please not create fix commits for not pushed to master changes.
if you want fix your own commits in this pull request, you should squash you commit and fix for it into one commit",7551429
563,HULD Compatibility for aldebaran.txt,open,2018-10-08T03:07:38Z,2019-04-28T15:39:14Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 
npc/cities/aldebaran.txt
[//]: # (Master? Slave?)
stable
**Issues addressed:**
HULD Compatibility
[//]: # (Issue Tracker Number if any.)
#2233 
### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2272)
<!-- Reviewable:end -->
",7551429
564,LGTM Alert Fixes,open,2018-10-07T16:12:34Z,2020-02-02T20:10:28Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

Fixes Several warnings that were displayed by LGTM (still many more are left, which I may do it later on other PR)
Some warnings are suppressed like ""Poor global variable name"" which requires global variable to be > 3 characters
Most fixes are of multiplication overflow. some are of comparison result always true/false

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)


[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","This pull request **fixes 23 alerts** when merging 8424b78631eee097be089b6c845225384b49f6ad into baeb7a1742b0fd7ac5d3a4cecd90f74d461895fe - [view on LGTM.com](https://lgtm.com/projects/g/HerculesWS/Hercules/rev/pr-a3ee88ea885c0b28e249210693b929e0f9bcd0c4)

**fixed alerts:**

* 20 for Multiplication result converted to larger type
* 3 for Comparison result is always the same

---

*Comment posted by [LGTM.com](https://lgtm.com)*",7551429
565,Minor logic change to @recallall to only warp players which can act,open,2018-10-07T13:22:32Z,2018-10-26T01:16:19Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [X] I have followed [proper Hercules code styling][code].
- [X] I have read and understood the [contribution guidelines][cont] before making this PR.
- [X] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Adds an additional conditional statement before setting a particular player's position. Re-used  `pc_cant_act` which covers all the conditions mentioned in the issue. In addition, it also checks for players who are active in the past 300 seconds.

Since i don't see any configuration variable storing a value that denotes something like -> **how many seconds before we determine a user is idle?** I'm not sure if I should introduce a new global variable since such a timeout is only used for this command.

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 
- master

**Issues addressed:**
-  https://github.com/HerculesWS/Hercules/issues/203

[//]: # (Issue Tracker Number if any.)

[//]: https://github.com/HerculesWS/Hercules/issues/203

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","> just a suggestion, maybe allow GM to self define the `active duration`? this way we wont need to hardcode the value of `300` in the source, and enable more flexibility to define idle duration.
> Ex: `@recallall 60`
> recall all players who hasn't been idle for the past 60 seconds.

This sounds like a great suggestion. I'll probably go along the lines of -> let the GM define the number of seconds, else default to 300.",7551429
566,mesf npc/warps,open,2018-10-06T17:25:41Z,2018-10-19T08:34:02Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
npc/warps concatenation in mes replaced with mesf.
[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

[//]: # (Master? Slave?)
master
**Issues addressed:**
https://github.com/HerculesWS/Hercules/issues/2233
[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2263)
<!-- Reviewable:end -->
",7551429
567,mesf npc/woe-fe,open,2018-10-06T16:43:27Z,2019-02-28T16:38:18Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
npc/woe-fe concatenation in mes replaced with mesf.

**Affected Branches:** 
master
[//]: # (Master? Slave?)

**Issues addressed:**
https://github.com/HerculesWS/Hercules/issues/2233
[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2262)
<!-- Reviewable:end -->
",7551429
568,item_formatter + tools improvements,open,2018-10-05T04:39:32Z,2019-04-28T15:39:14Z,,NONE,"@Asheraf asking me to make this script
Working only with python 3.5+

This script will read old-styled item_db.conf and make it compatible with new style.
Usage help:
`item_db_formatter.py -h`

[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)
Todo:
- [x] Make all .py files work with one python version (3.5+ preferred)
- [x] Make all .py files be compatible with PEP8

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","This pull request **introduces 1 alert** and **fixes 7** when merging 58f64355debaf139e2902ca69ae21139832d9210 into 852c13305f67948531bd0277eb1922dbd02b1f26 - [view on LGTM.com](https://lgtm.com/projects/g/HerculesWS/Hercules/rev/pr-3aa7c9f872e842e123f5eb2515e0398b842b2868)

**new alerts:**

* 1 for Syntax error

**fixed alerts:**

* 3 for Comparison using is when operands support \_\_eq\_\_
* 3 for Except block handles &#39;BaseException&#39;
* 1 for Unused local variable

---

*Comment posted by [LGTM.com](https://lgtm.com)*",7551429
569,Convert atcommand documentation into markdown,open,2018-10-02T14:41:41Z,2019-10-05T05:37:15Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # 
https://github.com/HerculesWS/Hercules/issues/2214

### Known Issues and TODO List
none

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","some of the formatting seem like accidentally changed due to markdown format.
- Paragraphs become 1 line of text 
- strikethrough text

might as well consider to envelope the email/commands/constants that appear in description using the code tag too?",7551429
570,Packets Documentation,open,2018-10-02T12:27:34Z,2018-10-19T08:54:55Z,,MEMBER,"### Description

Add Packet Documentation in markdown format.

Reference: https://github.com/rathena/rathena/blob/master/doc/packet_interserv.txt
The packets listed on that site, and on our are almost similar, with few additions/deletions in some packets, so you might find it great for start.

You can see our packets on:
https://raw.githubusercontent.com/HerculesWS/Hercules/master/src/map/intif.c
https://raw.githubusercontent.com/HerculesWS/Hercules/master/src/map/chrif.c
https://raw.githubusercontent.com/HerculesWS/Hercules/master/src/char/inter.c
https://raw.githubusercontent.com/HerculesWS/Hercules/master/src/char/mapif.c
https://raw.githubusercontent.com/HerculesWS/Hercules/master/src/char/loginif.c

What to look for in these files?
search WFIFOHEAD or WBUFHEAD (All Packets start with this)
Next line might have something like 
> WFIFOW(fd, 0) = 0x3804;

OR 

> WBUFW(buf, 0) = 0x3804;

0x3804 is the PacketID
There are variations in WFIFO/WBUF commands, which are listed below:

WFIFOW/WBUFW = 2 bytes
WFIFOL/WBUFL = 4 bytes
WFIFOQ/WBUFQ = 8 bytes

","Yes, atm, nobody is doing this.",7551429
571,Making Scripts compatible with Hercules Ultimate Localization Design (HULD),open,2018-10-01T17:51:01Z,2018-10-02T12:04:13Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

Currently, we do not have all the scripts which are compatible with HULD (if you want to know what's HULD, you can visit here: http://herc.ws/board/topic/8687-hercules-ultimate-localization-design/ , but I would be explaining the issue and solution here so it's easy to do)

Currently our translation only recognizes following commands:

> mes
select


So, let's take npc/cities/aldebaran.txt (https://github.com/HerculesWS/Hercules/raw/master/npc/cities/aldebaran.txt) for example,

The changes we need to make:
1) The commands/functions should start with bracket and not space, so
> mes ""[Munster]"";

will be converted to

> mes(""[Munster]"");



2) concatenation in mes to be replaced with mesf

> mes ""If you want to sell them to us, you will receive ""+ .@kafrapassmoney +"" zeny. Would you like to sell these back to the Kafra Corporation?"";

will be converted to

> mesf(""If you want to sell them to us, you will receive %d zeny. Would you like to sell these back to the Kafra Corporation?"", .@kafrapassmoney);

Note: mesf is mes + sprintf, if you want more info, you can visit here : https://raw.githubusercontent.com/HerculesWS/Hercules/master/doc/script_commands.txt and search mesf



3) If the command is not mes and there's concatenation, use following format:
> .@list$ += .@choices[.@i] + ""- "" + getitemname(.@choices[.@i+1]) + "" "" + .@choices[.@i+2] + "" ea:"";

To

> .@list$ += sprintf(_$(""%d- %s %d ea:""), .@choices[.@i], getitemname(.@choices[.@i+1]), .@choices[.@i+2]);

Example 2:

> dispbottom(""Your Name is ""+ strcharinfo(PC_NAME));

To

> dispbottom(sprintf(_$(""Your Name is %s""), strcharinfo(PC_NAME)));

Note: You may find many more functions/commands for the same, some of them are listed below, but not limited to:
```
announce
mapannounce
showscript
dispbottom
message
npctalk
mes
select
```



4) Select to be converted to comma separated

In some script, the select would be in the following format, which needs to be changed
> select(""About Insects:End Conversation"")

To

> select(""About Insects"", ""End Conversation"")



5) Some strings are directly assigned to variable which needs to be changed
> .@changepage$ = ""Next items"";

To 

> .@changepage$ = _(""Next items"");

Note: Remember, The variables can have either empty suffix or $ as suffix, if it's $ in suffix, it's a string, and %s should be there in sprintf/mesf, for no suffix, %d should be used

### Files to be changed:

Files ending with extension .txt in npc/ folder (some files in that folder are already changed to support this, while many are remaining to be changed)

This issue can be done in parts (multiple PR's), as we know that there are lots of scripts to be changed, and a single person cannot do them all

### Additional Info

If there's any doubt or need information, you can ask any of the contributor or join the discord channel https://discord.gg/ZUzbRSp

### Reference

You can refer to already converted scripts such as:
https://github.com/HerculesWS/Hercules/blob/stable/npc/re/instances/MalangdoCulvert.txt
https://github.com/HerculesWS/Hercules/blob/stable/npc/re/instances/BakonawaLake.txt
https://github.com/HerculesWS/Hercules/blob/stable/npc/re/instances/EclageInterior.txt",@linton-dawson you can ask your doubts anywhere you feel comfortable,7551429
572,Refactored Party Booking defines.,open,2018-10-01T15:54:13Z,2020-01-11T07:35:18Z,,MEMBER,"Adjusted the name of defines to better suit their purpose.

[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** master

[//]: # (Master? Slave?)

**Issues addressed:**
https://github.com/HerculesWS/Hercules/issues/1234  references: https://github.com/rathena/rathena/commit/ed7157c80b0da86aa81d3cfee5e9b9679938b4e2

[//]: # (Issue Tracker Number if any.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2231)
<!-- Reviewable:end -->
",7551429
573,Party skill behavior battleconf for party skills vs enemy party members,open,2018-09-25T10:22:43Z,2019-10-05T05:34:44Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Addresses #2223 and #1649 by adding a battleconf option for the old behavior.
```
// Party Skill Behavior
// 0: (official) On gvg_noparty and pvp_noparty mapflags, party-based buffs such as Devotion can be used on all party members.
// 1: (eAthena) On gvg_noparty and pvp_noparty mapflags, party-based buffs such as Devotion cannot be used on enemy party members.
party_skill_behavior: 0
```

**Affected Branches:** 

[//]: # (Master? Slave?)
- [x] master
- [x] stable

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)
#2223 

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2225)
<!-- Reviewable:end -->
",7551429
574,Max Guild Storage Warning,open,2018-09-24T10:12:27Z,2018-12-31T10:03:20Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [ ] I have not modified the source prior to reproducing this issue.
-  [ ] I am using the latest version of Hercules.
-  [ ] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

When changing MAX_GUILD_STORAGE to greater than 744.

It will produce this > **mapif.c(1826): warning C4305: '=': truncation from 'unsigned int' to 'uint16'**
**Line 1826: WFIFOW(fd, 2) = sizeof(struct guild_storage) + 13;**

**Hercules rev. hash/commit:** 

Git revision (src): '852c13305f67948531bd0277eb1922dbd02b1f26'
Git revision (scripts): '852c13305f67948531bd0277eb1922dbd02b1f26'

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

OS version: 'Windows 8 Professional (build 9200) [x86_64]'
CPU: 'x86_64 CPU, Family 6, Model 60, Stepping 3 [4]'
Compiled with Microsoft Visual C++ 2015 (v1900)

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
","Possible Solution: 
Split the packets into multiple packets",7551429
575,PVP NO PARTY broken.,open,2018-09-24T09:22:43Z,2019-03-08T12:48:32Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [/ ] I have not modified the source prior to reproducing this issue.
-  [/ ] I am using the latest version of Hercules.
-  [ /] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description
Current latest svn PVP NO PARTY mapflag are not hitable among party members. 

this due to this fix: https://github.com/HerculesWS/Hercules/pull/1649

i reverted back from last part of that fix back to current git that i use and its fix it.
current git version:

[Info]: Git revision (src): '7f7b8060cba8f0aba60f43cf343bdf3f773f3438'
[Info]: Git revision (scripts): '7f7b8060cba8f0aba60f43cf343bdf3f773f3438'
",Can you please try out my PR to see if it works?,7551429
576,New configure options,open,2018-09-19T01:39:11Z,2020-01-11T06:34:15Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Added new ways to configure Hercules.
Now, can run configure with new parameteres, like:

`
./configure --enable-max-inventory=100 --enable-max-storage=800 --enable-max-zeny=1000000000 --enable-max-cart=200
`
Allowing change environment without using CPPFLAGS or chaning the source.

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

Master

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","No activity for more than a year and it conflicts with current master. Close?

#clean_up_frenzy",7551429
577,turn the atcommand documentation into markdown,open,2018-09-13T21:22:16Z,2019-03-08T12:49:38Z,,MEMBER,"`doc/atcommand.txt` should be rewritten in markdown for easier reading in the browser and better organization.

proposed syntax:

```markdown
# Atcommand documentation

(description)

**Table of contents**
- System commands
- Database commands
  . . .

## system commands

### version
(description)

### rates
(description)


## database commands
. . .
```",yes,7551429
578,Implement Aegis MapTypeProperty: HIDING_DAMAGE,open,2018-09-03T07:23:12Z,2019-03-04T03:37:46Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description
This mapflag hide the damage of player/mob in the current zone.

Source: https://github.com/skyiing/Aegis/blob/master/ZoneServer/MapTypeProperty.txt#L724

```
// // Hurting damage
// // TRUE: Do not show any damage.
//			ADD_PROPERTY(HIDING_DAMAGE, TRUE);
```

Suggestion name: hide_damage
```
	name: ""GvG"" 
	mapflags: (
		""hide_damage"",
	)
```
","I just test `@pvpon` will show that amount of damage
`@gvgon` will show 1 damage

so I think the correct way to do this is ...
take the code that mask the damage into 1 ... into a separate function
then gvg mapflag and hide damage mapflag access this function ...
having a function so we can manipulate it with plugin",7551429
579,Fixed Issue #2181,open,2018-09-02T05:37:18Z,2020-03-08T18:04:19Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

PetDB2 no longer overrides entry of PetDB

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)
#2181 

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","This should probably go in after #2600 since it would make it easier to address the override issue (the unique id to use for overriding could be the egg id, since it becomes a mandatory field, and it doesn't make any sense to have multiple pets with the same egg)",7551429
580,Guild Storage becomes locked by unknown causes,open,2018-08-29T09:00:48Z,2018-10-15T07:41:16Z,,CONTRIBUTOR,"### Issue Prelude

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

For some reason, guild storage is getting locked sometimes, I can't figure out what is causing it.

`gstorage->open` is always returning 1, returning the message, *""Your guild's storage has already been opened by another member, try again later.""*

This is happening to people who are the only member online in their guild, so the situation described is inaccurate.

### Current Behavior
### Expected Behavior
.

### Steps To Reproduce The Issue

Not sure how to reproduce. While my server was live I tried:
1. Back up SQL using `--single-transcation` flag on mysqldump.
2. Move SQL to another server and start it up.
3. Login to a character of the person who reported being unable to open guild storage.
4. Guild storage opens fine.

So I suspect the issue is something to do with live game value not being correctly set?

**Branch(es):**
- [x] master
- [x] other
","Ever since I performed the steps in my post above, there has not been a single complaint about locked guild storage.",7551429
581,inline constant definitions,open,2018-08-26T19:24:00Z,2018-08-30T10:52:44Z,,MEMBER,"being able to set constants inline rather than in the const db would allow for easier script maintenance, because we could keep the constants and the function definitions together

example:
```c
// Function to show narrator text.
// the first argument can take the following flags:
const	N_BLANK_START	0x1      // blank line at the beginning
const	N_BLANK_END	0x2      // blank line at the end
const	N_LAST_NEXT	0x4      // use last next()
const	N_NO_NAME	0x8      // don't display the npc name

function	script	narrator	{
	.@argc = getargcount();
	.@flags = getarg(0);

	if (.@flags & N_BLANK_START)
		mes("""");

	if (!(.@flags & N_NO_NAME))
		mes(""[ Narrator ]"");

	for (.@i = 0; .@i < .@argc; .@i++) {
		mes(getarg(.@i));

		if (.@i < .@argc - 1)
			next();
	}

	if (.@flags & N_LAST_NEXT) {
		next();
	} else if (.@flags & N_BLANK_END) {
		mes("""");
	}

	return;
}
```

we could even go further and allow anonymous enums:

```c
enum { FOO, BAR, BAZ }
```","i like the idea of having user to be able to declare these by their own in npc script. 
its convenient, and dont have to restart server everytime i wanted to add a new one.

make it throw warning if re-declared with same constant in any other place.
Give priority to the constant that declared in source.",7551429
582,Adds 'cell_noskill' which blocks skill usage.,open,2018-08-23T09:53:30Z,2019-02-27T14:31:08Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Adds the `cell_noskill` cell, which allows the setting of cells which players cannot cast skills.

**Affected Branches:** 

[//]: # (Master? Slave?)
- [x] master
- [x] stable

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","just had a thought. Is constants.md file auto-updated, or should I manually add these changes to it?",7551429
583,GM Perfect Hiding,open,2018-08-22T13:05:59Z,2019-10-29T11:46:24Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

Whenever a player use a skill at a cell with a GM who is using a perfect hide (example hunter's Ankle Snare), it seems that the skill is unable to cast. 
",@dastgirp I think so.,7551429
584,Stops tsd client crashing if party inviter is disguised.,open,2018-08-21T21:55:54Z,2018-08-22T16:45:14Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
Stops disguised party invites if disguised. If the party inviter is disguised, they can crash anyone's client just by inviting them to their party (not sure if it will crash on partylock or if player already has party).

Confirmed to crash the target's client in 20160113.

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

[//]: # (Master? Slave?)
- [x] master
- [x] stable

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

- [ ] Test in other clients to see if it is a packetver related thing.

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","If someone else can test for which client it crashes, it would be great.",7551429
585,Mapflag NOVIEWID is not working properly,open,2018-08-21T03:33:22Z,2018-10-21T04:41:44Z,,NONE,"-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Steps To Reproduce The Issue

• Prontera as a map that disable display of Upper Costume
   `prontera	mapflag	noviewid	1024`
• Payon as a map that enables display of costumes (no mapflag)
• Crown and C_Sunflower as an example item to test..

1 .
I was at Prontera and I put on Crown and C_Sunflower.. The C_Sunflower did not appear so its correct.

2 .
Still wearing same equipments I'd go to Payon which enables the display of costumes but the C_Sunflower did not display. 
**Expected Behavior:** The C_Sunflower should be displayed automatically because I'd go to the map that enable costumes.

3 .
Re-equiping the items Crown and C_Sunflower in Payon did it right, the C_Sunflower was displayed. But going back to Prontera (noviewid 1024) the C_Sunflower was still displayed, it did not automatically display the Crown.
**Expected Behavior:** The C_Sunflower should NOT be displayed,  because I'd go to the map that disable costumes.

4 .
And lastly, if you equip the costume first in Prontera (noviewid 1024) the headgear will not display too.
Example: You first equip the C_Sunflower it won't display and then equip the Crown it won't display too.. To display the Crown you must first equip the Crown and then the C_Sunflower..

NoViewID implementation: https://github.com/HerculesWS/Hercules/pull/926",Up❤,7551429
586,pet_db2 overrides pet_db,open,2018-08-20T15:25:09Z,2018-08-20T15:25:09Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description
Whenever I define anything in `pet_db2.conf`, it causes everything in `pet_db.conf` to break.

### Expected Behavior
pet_db2 should be additions to pet_db, or have some sort of inherit flag like item_db2 does.

**Branch(es):**
- [x] master
- [x] stable

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
",,7551429
587,"Adds extra option to 'mob_npc_event_type' for who did most damage, unless Emperium.",open,2018-08-13T09:01:46Z,2018-08-13T10:17:01Z,,CONTRIBUTOR,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

An extra option will be added to `mob_npc_event_type` so that people can choose if they want NPC event to trigger for most damage, except on Emperium mob.

**Affected Branches:** 
- [x] master
- [x] stable

**Issues addressed:**

N/A","@Emistry the code does ignore the players who are dead or not in same map or logged out.
But I sort of agree with configurable things, probably should have something which would not have performance hit.

Also, it only triggers that if it have event attached (by monster command)

",7551429
588,Fixes issue where SA_DISPELL does not work in @duel on non-vs map.,open,2018-08-11T17:40:27Z,2020-01-11T06:52:04Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Fixes the issue where if two players use @duel on a non-vs (BG, GVG, PVP) map, SA_DISPELL will not work.

*Needs testing and review 🌊*

**Affected Branches:** 
- [x] master
- [x] stable

**Issues addressed:**

#1847 ","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2178)
<!-- Reviewable:end -->
",7551429
589,Make userid UNIQUE,open,2018-08-07T08:51:43Z,2018-10-01T09:31:50Z,,NONE,"Now you can create two accounts with same userid (login)

[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","Updated. Don't know about default values, I left it. Also fixed char_achievements table. Someone forgot about `IF NOT EXISTS`",7551429
590,Adds options to @fakename so guild and party names can be displayed.,open,2018-08-06T15:31:55Z,2018-08-30T10:08:00Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Adds a parameter to the `@fakename` command, allowing the display of guild/party names. I previously made this PR, but deleted due to resetting my fork.

E.g.
`@fakename 0 Great Name` - would display the fake name 'Great Name' and hide party, guild and position names.
`@fakename 1 Great Name` - would display the fake name 'Great Name' and hide party name, but not guild and position.

**Affected Branches:** 

[//]: # (Master? Slave?)
- [x] master
- [x] stable

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","As 4144 said, it's better to add it as new commands",7551429
591,add some missing bounds checking for map->list in map.c,open,2018-08-03T03:24:03Z,2018-08-03T04:14:44Z,,MEMBER,"see http://herc.ws/board/topic/16205-mapc-error/?do=findComment&comment=88875
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2167)
<!-- Reviewable:end -->
",7551429
592,checkwall ScriptCommand,open,2018-07-26T04:47:47Z,2018-10-13T11:18:18Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

Added new scriptcommand ""checkwall"".

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

#2119 
### TODO List
[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)
* [ ] As per @EyesOfAHawk , we need to modify WoE SE script

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","wouldn't something like this be more versatile?

```c
getwallinfo(""<name>"", <info>)

Gets misc info on a wall set with setwall().
If the wall doesn't exist, returns false.

info:

	WALL_INFO_MAP - wall map
	WALL_INFO_X   - wall position on the X axis
	WALL_INFO_Y   - wall position on the Y axis
	WALL_INFO_DIR - wall direction
```

no need for `WALL_INFO_SHOOTABLE` because this can be checked with checkcell once the location is known",7551429
593,"WIP: allow to export local functions, and disallow calling them as npc events",open,2018-07-23T14:46:04Z,2018-11-14T16:00:54Z,,MEMBER,"This is my proposal to fix #2137:

* local functions can no longer be called as events, even if their label begins with `On`
* local functions may be explicitly exported by prepending their name with a colon (`:`).
this allows other scripts to call them as if they were part of their own script
* exported local functions can be called from any script by doing `""npc name""::MyFunction();`

<br>

```c
-	script	npc1	FAKE_NPC,{

	function NonExported {
		return ""[1] non-exported"";
	}

	function :Exported {
		return ""[1] exported"";
	}

	// local call:
	debugmes(NonExported()); // => [1] non-exported
	debugmes(Exported()); // => [1] exported

	// foreign call:
	debugmes(""npc2""::NonExported()); // ERROR: not exported
	debugmes(""npc2""::Exported()); // => [2] exported
}


-	script	npc2	FAKE_NPC,{

	function NonExported {
		return ""[2] non-exported"";
	}

	function :Exported {
		return ""[2] exported"";
	}

	// local call:
	debugmes(NonExported()); // => [2] non-exported
	debugmes(Exported()); // => [2] exported

	// foreign call:
	debugmes(""npc1""::NonExported()); // ERROR: not exported
	debugmes(""npc1""::Exported()); // => [1] exported
}
```

```c++
// local call syntax (unchanged):
<function>({<arg>...})

// foreign call syntax:
""<npc name>""::<function>({<arg>...})
```

<br>

---

Once we all agree I'll edit the script documentation","moving this to the next milestone

I felt the `:` prefix was ugly, so I will change the syntax to
```c
function MyFunction { … } // implicitly private
private function MyFunction { … } // explicitly private
public function MyFunction { … } // explicitly public
```

It's cleaner, and the `public` and `private` keywords could also be reused in the future for other things",7551429
594,local functions can be called as events,open,2018-07-18T00:35:17Z,2018-07-23T22:02:08Z,,MEMBER,"since local function names and labels are both stored in the same strdb it is possible to call a local function as if it were an event when it has a name that begins with `On`
```c
// define a function in MyNPC
function OnMyFunction {
	debugmes(""hello!"");
	return;
}

// then it can be called from anywhere:
donpcevent(""MyNPC::OnMyFunction"");
```

```ini
[Debug]: script debug : 0 110000354 : hello!
[Warning]: script:run_func: return without callfunc or callsub!
```
This affects not just custom events but rather every single event calls (oninit, onlogin, mob death, timers, clock, woe, …) since they all use the same functions

<br>

---
We should either make it illegal or officially support it, which would be a great idea as we could get rid of most labels and use functions everywhere. As syntax for the event string we could use
```c++
MyNPC::MyFunction()
```
so if parentheses are found it is a function call, else it is a normal label call","this is far from urgent, I just put severity 3 because it is [defined](https://github.com/HerculesWS/Hercules/wiki/Bugtracker-Labels#severitymedium-incorrect-mechanics-or-behavior
) as `Script command not behaving accordingly to what's expected`",7551429
595,WIP: allow duplicate NPCs to not share their variables,open,2018-07-04T22:19:12Z,2018-11-08T03:47:34Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [X] I have followed [proper Hercules code styling][code].
- [X] I have read and understood the [contribution guidelines][cont] before making this PR.
- [X] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

**Issues addressed:** http://herc.ws/board/topic/16098-duplicate-npcs-use-the-same-variable/


### TODO

in a future PR we should review all usage of `duplicate(npc)` and instanced NPCs and update scripts accordingly, then we can set `true_npc_duplicate` to `true`

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","I'll finish this another time, it's giving me a headache
can't reproduce the [access violation](https://travis-ci.org/HerculesWS/Hercules/jobs/452185941#L1235) whether or not I enable or disable asan and the manager",7551429
596,Need checkwall() buildin to stop console spam,open,2018-07-04T09:13:51Z,2018-07-04T16:22:38Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)
Reference: #2017 
*`delwall()` is now giving a warning/debug if the wall doesn't exist, this causes spamming of console. Some scripts, such as woe-se. dynamically delwall/setwall, so the wall won't always exist when `delwall` is used.


### Changes

That's why we need a `checkwall()` buildin, which will return true or false if wall exists. Then we can check it exists before performing action on it.

What do you think of this buildin?
```
static BUILDIN(checkwall)
{
	const char *name = script_getstr(st, 2);

	if (((struct iwall_data *)strdb_get(map->iwall_db, name)) == NULL)
		script_pushint(st, 0);
	else
		script_pushint(st, 1);

	return true;
}
```

**Branch(es):**
- [x] master
- [x] stable",,7551429
597,Fixed guild bound items not saved.,open,2018-07-01T04:27:33Z,2019-04-28T15:39:13Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Creates storage is storage is not yet created.

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

#691 

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2113)
<!-- Reviewable:end -->
",7551429
598,Mobs (visually) reappear after death under certain circumstances,open,2018-06-27T22:26:32Z,2018-07-24T00:48:13Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

Under some circumstances, e.g. with certain skills causing knockback like *Magnum Break*, players may see mobs that have died reappear with 0 HP in an idle animation.

### Current Behavior

Hercules may send `ZC_NOTIFY_MOVEENTRYn` packets concerning units that have already died. If the client has already removed the unit from its state before receiving that packet, it will recreate it, thus displaying a stuck mob with 0 HP to the player until they relog. (I believe this is not a client bug as this packet type may also be used to notify clients of units they have legitimately not seen before.)

A fairly consistent the problem manifests is when mobs whose movement speed has changed through *Increase AGI* die to some knockback skills. In these cases, the offending packet is sent at https://github.com/HerculesWS/Hercules/blob/c419726752ebd1b532f487e5683f63232a6c237b/src/map/clif.c#L1866 However, this is not necessarily the *only* place that can send it. I'm aware of MvP slaves sometimes displaying the glitch after their master dies on a live server (with source modifications), however I've not been able to reproduce that on unmodified Hercules, personally.

Lowering the unit removal notification delay in https://github.com/HerculesWS/Hercules/blob/c419726752ebd1b532f487e5683f63232a6c237b/src/map/mob.c#L2728 makes the issue occur more frequently but is not required.

Issue has been reproduced on `2018-06-21aRagexeRE` and `2018-04-04cRagexeRE` but most likely affects clients many years older as well.

### Expected Behavior

`ZC_NOTIFY_MOVEENTRYn` packets, as crafted in https://github.com/HerculesWS/Hercules/blob/c419726752ebd1b532f487e5683f63232a6c237b/src/map/clif.c#L1303 should never be sent after `ZC_NOTIFY_VANISH` (unless the mob is intended to be recreated on client).

### Steps To Reproduce The Issue

1. Log on with a *Swordsman* that can kill *Orc Lady* in 2-3 *Magnum Breaks*
2. Mob *Orc Ladies*, wait for a few to use *Increase AGI*
3. Kill them with *Magnum Break*

It's not 100% consistent, but a few iterations of this should cause at least one *Orc Lady* to reappear with 0 HP.

**Branch(es):**
- [x] master
- [x] stable

**Hercules rev. hash/commit:** 

Git revision src: 'c419726752ebd1b532f487e5683f63232a6c237b'

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )
","The easiest way to recreate this issue is killing monsters with skills that knockback, root/stun, or a combination of those, and the issue #2047 involves monsters appearing as ""walking"" under the same conditions, and it happens much in the same way. The sprite of a monster that's supposed to be dead or unable to move, ""walks"" for some distance then stops and rubberbands back to its original spot once the status ends and it's still alive, if it's dead then doing a refresh fixes the position.
Maybe there are different causes but some of them might be involved in both issues.",7551429
599,Bug when using hide with disguise,open,2018-06-21T18:30:05Z,2020-03-06T14:00:42Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

When the character is on the **disguise effect** and enter the **state of hide** and exit the state hide sometimes your character is in permanent hide mode, so you can exit hide state need to use command **refresh**.

**Hexed: 2018-05-02**

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)


**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src: 81d02447f733ff802614c338cecfd88adad76ace

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

","@SombraRO  Some questions:
 * Which client are you using? (There are 3 from 2018-05-02 -> 2018-05-02bRagexe, 2018-05-02bRagexeRE, 2018-05-02dRagexeRE)
 * Can you list all patches your client contains?
 * Did you notice this bug with other clients?
 * Did you notice this bug with a newer version of Hercules than 81d0244?
 * Is your server running in RE or pre-RE mode?
 * Is disguise done by script command or @<span></span>disguise?
 * When saying ""hide"", do you mean GM hide (@<span></span>hide) or something else?
 * Did you notice any other circumstances which may trigger that bug?


I tested with latest Hercules in RE mode and 2019-02-20aRagexeRE by using @<span></span>disguise/@<span></span>hide. No chance to reproduce this. :disappointed_relieved:",7551429
600,Bad interaction with multi-area headgears and costumes,open,2018-06-21T05:55:55Z,2018-07-26T04:42:34Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

When you equip a normal headgear that covers more than one slot, then also equip a costume, sometimes there is inconsistent behaviors. Sometimes the costume sprite will override the normal sprite, while others can show both normal and costume at the same time.

### Behavior

**Example 1:**
Equip Hat of the Sun God [Upp+Mid] and Costume Sunglasses [cMid]: https://i.imgur.com/ugVc5bD.png
Observed: Both sprites are showing.
Expected: Hat of the Sun God should not show, as Costume Sunglasses will override.

**Example 2:**
Equip Mr Smile [Mid+Low] and Costume Sunglasses [cMid]: https://i.imgur.com/FOLctYb.png
Observed: cMid (Costume Sunglasses) are overriding the Mr Smile.
Expected: cMid (Costume Glasses) should override Mr Smile.

**Example 3:**
Equip Sphinx Hat [Upp+Low] and Costume Romantic Leaf [cLow]: https://i.imgur.com/3oWgXMt.png
Observed: Both sprites are showing.
Expected: Only the Costume Romantic Leaf should show.
*Note: in this example I made a mistake and left Costume Sunglasses on.*

**Example 4:**
Equip Mr Smile [Mid+Low] and Costume Sphinx Hat [cUpp+cLow]: https://i.imgur.com/JA9tvpd.png
Observed: Both sprites are showing.
Expected: Only the Costume Sphinx Hat should show.

### Expected Behavior

I don't know what the official behavior is, but shouldn't the costume always take priority? If it's not official behavior, then we should add a battleconf option for it.

**Branch(es):**
- [x] master
- [x] stable","I confirm this, I found it odd because it happened the same with me I thought it would be client problem.

@4144 Could you confirm?",7551429
601,Stylist UI Missing Behavior,open,2018-06-21T01:56:03Z,2018-07-18T15:04:10Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Current Behavior
You can walk, use usable items when the stylist ui is active.

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior
In official server, you can't walk and use usable items when ui is active.

[//]: # (Tell us what should happen instead.)

### Steps To Reproduce The Issue

1. Step 1
2. Step 2
3. Step 3

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
",i agree can't walk before finish change stylist or close,7551429
602,Attendance System missing behavior,open,2018-06-21T01:49:35Z,2018-06-21T01:49:57Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Current Behavior
When logged in to the game, the ui of attendance system is not shown when there is unclaimed item

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior
In official server, when you logged in to the game and there's unclaimed item in your attendance, the ui will pop up first.

[//]: # (Tell us what should happen instead.)

### Steps To Reproduce The Issue

1. Step 1
2. Step 2
3. Step 3

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
",,7551429
603,Add *array_find script command,open,2018-06-18T10:09:48Z,2018-10-19T04:01:05Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Issues addressed
Fix my hunger for https://github.com/rathena/rathena/pull/3071 ... grrr ...
there is a [`ARR_FIND` macro](https://github.com/HerculesWS/Hercules/blob/stable/src/common/db.h#L986) in the source code, might as well turn it into a script command as well
reminds me of [`*swap`](https://github.com/HerculesWS/Hercules/pull/1012) script command ~

### Changes Proposed
Add *array_find script command

### Tested with
```
prontera,155,185,5	script	test#1	1_F_MARIA,{
	input .@input;
	setarray .@a[5], 2,4,6,8,10;
	.@test1 = array_find( .@a[1], .@input );
	dispbottom .@test1 +"""";
	end;
}

prontera,158,185,5	script	test#2	1_F_MARIA,{
	setarray .@map$, ""prontera"", ""payon"", ""izlude"", ""yuno"", ""alberta"", ""geffen"";
	.@test$ = .@map$[2];
//	.@test2 = array_find( .@map$, .@test$ );
	.@test2 = array_find( .@map$, ""yuno"" );
	dispbottom .@test2 +"""";
	end;
}
```

### Affected Branches
* Master

### Known Issues and TODO List
This is weird, rathena version and @mekolat version return -1 when value not found
but the source code return the array size when value not found ...
which one is correct ??
I personally prefer return array size because this is just a script command without having to use loop
```
	for ( .@i = 0; .@i < getarraysize(.@test); ++.@i )
		if ( .@test[.@i] == 3 )
			break;
	if ( .@i == getarraysize(.@test) )
		dispbottom ""not found"";
```
<----------- SIMPLIFY AS ----------->
```
	.@i = array_find( .@test, 3 );
	if ( .@i == getarraysize(.@test) )
		dispbottom ""not found"";
```",+1 I'm using meko's script for these but would be much better if they are in the repo as script commands.,7551429
604,Deprecate *strmobinfo script command,open,2018-06-16T22:49:12Z,2018-08-26T18:30:13Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Issues addressed
My own https://github.com/HerculesWS/Hercules/issues/2011 ~

### Changes Proposed
1. Deprecate `*strmobinfo` script command
2. `*getmonsterinfo` gets `MOB_ENAME` field
the reason its `MOB_ENAME` but not `MOB_INAME` is because of `--ja--` and `--en--`

### Affected Branches
* Master

### Known Issues and TODO List
as you can see on the 5th patch, some script uses `--ja--` some use `--en--`
so which one to be standardize ?

conf\map\monster.conf
```
// Should the mob_db names override the mob names specified in the spawn files?
// 0: No
// 1: always use the mob_db Name column (english mob name)
// 2: always use the mob_db JName column (original Kro mob name)
override_mob_names: 0
```
what should we do with this ?","> and also move the constants from ``db/` folder into into source?

you mean do like rathena did ?
https://github.com/rathena/rathena/blob/master/src/map/script_constants.hpp
that's an interesting subject, if the core developers here gives the green light, I also vote for a `yes`

--------------------------------------------------------------

> about the MOB_ENAME, why not its named MOB_JNAME?

because MOB_NAME is actually `mob->db(class_)->jname` right now
there are still 2 more fields that listed as name
which is `mob->db(class_)->name` and [`mob->db(class_)->sprite`](https://github.com/HerculesWS/Hercules/blob/stable/src/map/mob.c#L4257)
I didn't include the sprite name in this PR, because I think that's useless ?

-----------------------------------------------

> in mob_db we have the JNAME field but not ENAME or kNAME or iNAME etc...
MOB_NAME -> default name
MOB_JNAME > optional name / JNAME.

silently change their script ? this is also what I have in mind
so the default MOB_NAME change into `mob->db(class_)->name` ... hmm ... sounds better to me too

this is the exact reason I want to deprecate `*strmobinfo` script command
after all, I also prefer to standardize in all scripts, as you can see the description in the 5th patch
some uses MOB_ENAME, some uses MOB_NAME

--------------------------------------------------

> another random thought, maybe drop the getmobdrop too? and merge into getmonsterinfo ?

[`getmobdrops`](https://github.com/HerculesWS/Hercules/blob/stable/doc/script_commands.txt#L3899) generate an array ... hell no ...
I think that's different thing though",7551429
605,Add *getinstancelist script command,open,2018-06-16T06:36:16Z,2018-06-16T23:31:06Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Issues addressed
heck, this is very dirty method to get the owner ID of each instance
<details>

```
prontera,155,180,0	script	Test Instance	1_F_MARIA,{
	for ( .@i = 0; .@i < .total; ++.@i ) {
		if ( getmapusers( .id[.@i] +""Test"" ) == -1 ) {
			deletearray .id[.@i], 1;
			--.@i;
			--.total;
		}
	}
	mes ""Total Instances -> ""+ .total;
	for ( .@i = 0; .@i < .total; ++.@i )
		.@menu$ += ""[""+ .id[.@i] +""] has ""+ getmapusers( .id[.@i] +""Test"" ) +"" players:"";
	.@s = select( .@menu$ +""continue"" ) -1;
	if ( .@s < .total ) {
		if ( getmapusers( .id[.@i] +""Test"" ) < 0 )
			close;
		warp .id[.@s] +""Test"", 49,49;
		end;
	}
	if ( ( .@ins = instance_create( ""test_bg"", 0, IOT_NONE ) ) < 0 ) {
		announce ""Fail to create instanced."", bc_all;
		end;
	}
	if ( !getstrlen( instance_attachmap( ""guild_vs2"", .@ins, true, .@ins +""Test"" ) ) ) {
		announce ""Fail to create instanced battleground."", bc_all;
		end;
	}
	instance_set_timeout 86400, 86400, .@ins;
	instance_init .@ins;
	warp .@ins +""Test"", 49,49;
	end;
}
guild_vs2	mapflag	src4instance
guild_vs2,49,49,5	script	test dialog	1_F_MARIA,{
	mes strnpcinfo(NPC_MAP);
	select ""Destroy"";
	.@total = getvariableofnpc( .total, ""Test Instance"" );
	while ( getvariableofnpc( .id[.@i], ""Test Instance"" ) != instance_id() && .@i < .@total ) { ++.@i; }
	deletearray getvariableofnpc( .id[.@i], ""Test Instance"" ), 1;
	set getvariableofnpc( .total, ""Test Instance"" ), .@total -1;
	instance_destroy;
	end;
OnInstanceInit:
	instance_set_respawn has_instance(""guild_vs2""), 0,0;
	.@total = getvariableofnpc( .total, ""Test Instance"" );
	set getvariableofnpc( .id[.@total], ""Test Instance"" ), instance_id();
	set getvariableofnpc( .total, ""Test Instance"" ), .@total +1;
	end;
}
```

</details>

### Changes Proposed
Add `*getinstancelist` script command to simplify the above script

### Tested with
<details>

```
prontera,163,185,5	script	Test Instance#2	1_F_MARIA,{
	dispbottom has_instance2(""guild_vs2"") +"""";
	dispbottom has_instance2( .@ins +""INST"" ) +"""";
	dispbottom getmapusers(""guild_vs2"") +"""";
	dispbottom getmapusers( .@ins +""INST"" ) +"""";
}

prontera,160,185,5	script	Test Instance#3	1_F_MARIA,{
	if ( ( .@ins = instance_create( ""Test Instance"", getcharid(CHAR_ID_ACCOUNT), IOT_CHAR ) ) < 0 ) {
		mes ""error : ""+ .@ins;
		close;
	}
	if ( !getstrlen( instance_attachmap( ""guild_vs2"", .@ins, true, .@ins +""INST"" ) ) ) {
		mes ""error : 5"";
		instance_destroy .@ins;
		close;
	}
	instance_set_timeout 3600, 15, .@ins;
	instance_init .@ins;
	end;
}

prontera,158,180,5	script	Test Instance#4	1_F_MARIA,{
	if ( ( .@ins = instance_create( ""Test Instance"", getcharid(CHAR_ID_PARTY), IOT_PARTY ) ) < 0 ) {
		dispbottom ""error : ""+ .@ins;
		end;
	}
	if ( !getstrlen( instance_attachmap( ""guild_vs1"", .@ins, true, .@ins +""TestINS"" ) ) ) {
		dispbottom ""error : 5"";
		instance_destroy .@ins;
		end;
	}
	instance_set_timeout 3600, 15, .@ins;
	instance_init .@ins;
	end;
}

prontera,161,180,5	script	Test Instance#5	1_F_MARIA,{
	if ( ( .@ins = instance_create( ""Test Instance"", getcharid(CHAR_ID_GUILD), IOT_GUILD ) ) < 0 ) {
		dispbottom ""error : ""+ .@ins;
		end;
	}
	if ( !getstrlen( instance_attachmap( ""guild_vs4"", .@ins, true, .@ins +""MultiINS4"" ) ) ) {
		dispbottom ""error : 5"";
		instance_destroy .@ins;
		end;
	}
	if ( !getstrlen( instance_attachmap( ""guild_vs5"", .@ins, true, .@ins +""MultiINS5"" ) ) ) {
		dispbottom ""error : 5"";
		instance_destroy .@ins;
		end;
	}
	instance_set_timeout 3600, 15, .@ins;
	instance_init .@ins;
	end;
}

prontera,160,190,5	script	kaksjdh	1_F_MARIA,{
	getinstancelist ""guild_vs2"";
	getinstancelist ""guild_vs2"", 1;
	getinstancelist ""guild_vs2"", 2;
	getinstancelist ""guild_vs2"", 3;
	for ( .@i = 0; .@i < $@instancelistcount; ++.@i ) {
		dispbottom ""ID -> ""+ $@instancelistid[.@i];
		dispbottom ""map name -> ""+ $@instancelistmap$[.@i]; // return map name
		dispbottom ""Instance owner type -> ""+ $@instancelistiot[.@i]; // return IOT_ ...
		dispbottom ""Instance owner ID -> ""+ $@instancelistowner[.@i];
	}
	dispbottom ""Total -> ""+ $@instancelistcount;

	getinstancelist ""guild_vs1"", 3;
	for ( .@i = 0; .@i < $@instancelistcount; ++.@i )
		dispbottom getpartyname($@instancelistowner[.@i]);
	dispbottom ""Another Total ->""+ $@instancelistcount;

	getinstancelist ""guild_vs5"", 3;
	for ( .@i = 0; .@i < $@instancelistcount; ++.@i )
		dispbottom getguildname($@instancelistowner[.@i]);
	dispbottom ""Multiple Total ->""+ $@instancelistcount;
	end;
}
```

</details>

### Affected Branches
* Master

### Known Issues and TODO List
1. conflict with 1 of my PR -> https://github.com/HerculesWS/Hercules/pull/2080, **Don't merge this until that one get merge 1st**
2. still using global variable `$@var` ... should change into scope `.@var` ?","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2085)
<!-- Reviewable:end -->
",7551429
606,"Allow checkidle(), checkchatting() and checkidle() to take account id.",open,2018-06-15T10:06:26Z,2018-10-19T08:42:09Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Allows `checkvending()`, `checkchatting()` and `checkidle()` to take an Account ID as the optional param as well as Character Name.

I.e.
```
checkidle(""Player"");
checkidle(getcharid(CHAR_ID_ACCOUNT));
```

**Affected Branches:** 

[//]: # (Master? Slave?)
master

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)
N/A

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)
N/A

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","As the script already accepts character name, I guess it would be fine to expand it to account_id as well.",7551429
607,Remove a single debug message from mapindex_name2id function... and add all onto others,open,2018-06-15T01:11:56Z,2019-03-05T12:01:23Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### 3 Issues addressed
1. ever wondered when your gm type `@warp morroc` wrong map name, it spam an error
`[Debug] mapindex_name2id: Map ""morroc"" not found in index list!`
yeah no anymore !
this large PR will remove this debug message if execute by GM commands

2. same as above, when using `*getmapusers` script commands,
although the [script_commands.txt mentioned it](https://github.com/HerculesWS/Hercules/blob/52360f0cee7916f58da6eda0399f74199f957c44/doc/script_commands.txt#L3572),
but when players input wrong map name, it still display an error !

3. this is also useful to use `*getmapusers` to check an instanced map is available or not
since we usually emulate the map ...

### Changes Proposed
1. remove the debug message line in mapindex.c
2. add `script_mapname2mapid` function
3. use `return false;` this time, if `return true;` later 4144 gonna comment on my work :P

this changes DOES NOT break any script, source code or plugins
well .... although your plugin might want to update a little bit to display an error message

### Affected Branches
* Master

### Known Issues and TODO List
NONE !! ","And something i forgot to say during the review (lalala 5am review), the change of behavior in many functions, changing true to false returns makes sense however please again separate those in a different commit so they won't go unnoticed.",7551429
608,Fix *getvariableofpc,open,2018-06-09T01:00:05Z,2018-06-09T01:11:12Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### 2 Issues addressed
```
prontera,155,185,5	script	sfsdfs	1_F_MARIA,{
//	Issue No.1
	mes """"+ getvariableofpc( BaseLevel, getcharid(3) );

//	Issue No.2
	mes """"+ getvariableofpc( @var, -1 );
	close;
}
```
No. 1 - display an error
```
[Error]: --- nullpo info --------------------------------------------
[Error]: d:\ragnarok\hercules\src\map\pc.c:8330: 'sd' in function `unknown'
[Error]: --- end nullpo info ----------------------------------------
```

No. 2 - this should display player not found error ...

### 2 Changes Proposed
1. now getvariableofpc can retrieve player's parameter (readparam)
2. display an error when player not found and no default value given

### Affected Branches
* Master

### Known Issues and TODO List
I compare this script command with rathena's version ...
```
	if (reference_toparam(data)) {
		ShowError(""buildin_getvar: '%s' is a parameter - please use readparam instead\n"", name);
		script_reportdata(data);
		script_pushnil(st);
		st->state = END;
		return SCRIPT_CMD_FAILURE;
	}
```
I wonder why they refuse to read player's parameter ??
I can understand bStr, bVit ... but Zeny, BaseLevel cannot be read too ? hmm ....","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/2074)
<!-- Reviewable:end -->
",7551429
609,Fix *atcommand cannot be use when PCBLOCK_COMMANDS is true,open,2018-06-05T05:00:53Z,2019-02-20T09:12:55Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Issues addressed
```
prontera,155,185,5	script	jskdhfjshfd	1_F_MARIA,{
	setpcblock PCBLOCK_COMMANDS, true;
	atcommand ""@kick ""+ strcharinfo(0);
	end;
}
```
cause map-server.exe to show warning
```
[Warning] buildin_atcommand: failed to execute command '@kick AnnieRuru'
```

### Changes Proposed
`*atcommand` should bypass the restriction
I also failed to noticed the `player_invoked` variable in the function
> * @param player_invoked true if the command was invoked by a player, false if invoked by the server (bypassing any restrictions)


### Affected Branches
* Master

### Known Issues and TODO List
none, this is minor edit",bump,7551429
610,Allow OnNPCKillEvent to run on monsters with event label,open,2018-06-04T21:11:41Z,2018-06-08T07:21:54Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### 2 Issues addressed
1. https://github.com/rathena/rathena/issues/1949
2. https://github.com/rathena/rathena/issues/1278
http://herc.ws/board/topic/15799-killedrid-variable-dont-work-with-script-command-monster/#comment-87230


### 2 Changes Proposed
1st. yes aleos has a point that OnNPCKillEvent shouldn't trigger with monster has event labels
however there are also cases that we want OnNPCKillEvent to trigger both of them together

let's say for example [my mission board script](https://rathena.org/board/topic/109667-mission-board-made-by-annieruru/?do=findComment&comment=344774) or [tr0n's quest board](https://github.com/rathena/rathena/blob/master/npc/custom/quests/questboard.txt)
members keep on complaining that when they setup a board nearby an instanced npc
the board doesn't trigger the kill for them, because those instanced npc already has event label attached

and the reason why I make this configurable so when members change the false into true
they should also change how their script going to work
... just like changing the `check_gotocount` means you don't have to use `*freeloop` as often

2nd. currently monster with event labels doesn't save the `killedrid` variable
suddenly remember this bug, and just add 2 lines in the process

### Tested with
```
prontera,155,185,5	script	ksjdfsdk	1_F_MARIA,{
	monster ""this"", -1,-1, ""OnNPCKillEvent"", PORING, 1;
	monster ""this"", -1,-1, ""Event Label"", PORING, 1, strnpcinfo(0)+""::Onaaa"";
	end;
OnNPCKillEvent:
	dispbottom ""OnNPCKillEvent"";
	end;
Onaaa:
	dispbottom ""Event Label"";
	end;
}
```
### Affected Branches
* Master

### Known Issues and TODO List
none","screw the previous post, github markdown just feels entirely different than using IPB forum
so I post a full description of this PR on the forum
http://herc.ws/board/topic/15991-onnpckillevent-changes/

I want @MishimaHaruna to fully understand what is this change
and discuss maybe [this patch is better](http://upaste.me/5a9a4993288206b46) ?
before merging this ...",7551429
611,doc\map_cache.txt is outdated,open,2018-06-04T01:45:52Z,2018-10-08T21:20:24Z,,CONTRIBUTOR,"https://github.com/HerculesWS/Hercules/blob/stable/doc/map_cache.txt

somebody has to update this file,
many members are confuse how the new map_cache system works",I can do this,7551429
612,Update waitingroom script commands.,open,2018-05-29T21:01:18Z,2020-01-18T08:59:55Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Added checking if target npc exists.
Enable the script to specify which NPC to execute the commands.
_(most of the waitingroom related script commands enable to specify which NPC to execute, except these 2.)_

**Affected Branches:** 
Master

**Deprecated script command :**
`*kickwaitingroomall({""<NPC object name>""})`
### Sample:
```
*waitingroom(""<chatroom name>"", <limit>{, <event label>, <trigger>, <required zeny>, <min lvl>, <max lvl>, ""<NPC Object Name>""})
*warpwaitingpc(""<map name>"", <x>, <y>{, <number of people>{, ""<NPC object name>""}})
*waitingroomkick({""<NPC object name>""{,""<player name>""|<account_id>}})
```

<details>

```
prontera,155,181,5	script	main	4_F_KAFRA1,{
	switch (select(
		""waitingroom"",
		""warpwaitingpc"",
		""waitingroomkick""
	)) {
		case 1:
			.@i = select(""NPC 1"", ""NPC 2"");
			delwaitingroom ""npc_""+.@i;
			waitingroom ""TITLE ""+.@i, 20, """", 0, 0, 1, 99, ""npc_""+.@i;
			npctalk ""created a waitingroom for NPC - npc_""+.@i;
			break;
		case 2:
			.@i = select(""NPC 1"", ""NPC 2"");
			warpwaitingpc ""prontera"", 155, 181, getwaitingroomstate(0, ""npc_""+.@i), ""npc_""+.@i;
			npctalk ""warped ""+$@warpwaitingpcnum+"" player"";
			break;
		case 3:
			.@i = select(""NPC 1"", ""NPC 2"");
			if (select(""All player"", ""enter player name"") == 1) {
				waitingroomkick(""npc_""+.@i);
				npctalk ""kicked all player from npc_""+.@i;
			}
			else {
				input .@name$;
				waitingroomkick(""npc_""+.@i, .@name$);
				npctalk ""kicked '""+.@name$+""' from npc_""+.@i;
			}
			break;
	}
	close;
}

prontera,150,185,5	script	npc_1	4_F_KAFRA1,{
	waitingroomkick();
	end;
	
	OnInit:
		waitingroom ""NPC_1"", 20;
		end;
}

prontera,160,185,5	script	npc_2	4_F_KAFRA1,{
	waitingroomkick();
	end;
	
	OnInit:
		waitingroom ""NPC_2"", 20;
		end;
}
```
</details>

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","that's why I only point to 1 script command which is waitingroompc, all others don't touch yet",7551429
613,Knockback effects on monsters.,open,2018-05-25T04:50:28Z,2018-06-03T00:58:14Z,,NONE,"There are a few issues regarding this and they're all very old.

1. Knocking back a monster that's affected by a hard status effect (namely SC_STUN) will cause it to ""walk"" back to you and then teleport back to its real location once the status ends. This is most easily reproduced by skills that both knockback and stun like CR_SHIELDCHARGE or RL_SLUGSHOT used on monsters with fast movement speed. It can also happen when a monster was previously stunned by something and then knocked back by another skill. 

2. Using knockback effects on monsters that are unable to move (SC_STOP, SC_ANKLESNARE, etc) causes them to move a bit and sometimes act in completely crazy ways like walking long distances backwards and similar.

3. Applying any status effect that disables movement, then knocking the monster back, then hitting it with a ranged attack. This will cause the monster to ""dance"" back and forth, moving a couple of cells when hit.

In all cases, those glitches are merely visual but impair your ability to deal with monsters as their real location isn't what it seems. Also, while it is possible to fix those issues on a local server by adding a short canmove tick upon a knockback or removing amotion/dmotion (seems to be related to the flinch animation?) from skills that knock back, it won't work on a real server due to the latency involved.",,7551429
614,Packet not updated when removing player from party,open,2018-05-15T00:58:18Z,2018-05-17T01:11:22Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

The packet `ZC_DELETE_MEMBER_FROM_GROUP ` is not working correctly, when the player of the party enters another character and the owner of the party tries to remove the player the packet is not updated and player is not removed from the window until the owner of the party moves map or Relogin character again

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)


**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src: 5c9056c183421df41b546dc3031d251ee6c963b5

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

",@4144 I used 20180502,7551429
615,Monster transform,open,2018-05-07T17:47:29Z,2019-07-31T23:29:56Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

When this system was implemented only the part of the scrolls were made, however there is the bonus part of applying damage and receiving damage.

Aegis uses another effect called `EFST_ACTIVE_MONSTER_TRANSFORM`, this effect was not applied in Hercules.

Several items use this effect, here some videos about this bonus.

This effect there is a **rate** and **time** that keeps the player transformed

https://youtu.be/UkVmNCXdnFY?t=1m
https://www.youtube.com/watch?v=sFOc7W5QY1Q&feature=share

![2zya8a8](https://user-images.githubusercontent.com/8175669/39715901-1ad09c6e-5205-11e8-949f-61003af91441.jpg)




[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)


**Branch(es):**
- [x] Stable
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src: 5c9056c183421df41b546dc3031d251ee6c963b5

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )
",@Emistry something about it?,7551429
616,Add MD_NORANDOM_WALK monster mode flag,open,2018-05-04T14:10:07Z,2018-06-05T02:41:31Z,,CONTRIBUTOR,"[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
### Pull Request Prelude
- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.
### Issues addressed
This is part of unit controller script commands -> https://github.com/HerculesWS/Hercules/issues/998
### Changes Proposed
Add **MD_NORANDOM_WALK** monster mode flag

### Affected Branches
* Master

### Tested with
```
prontera,155,185,5	script	jskdhfjshfd	1_F_MARIA,{
	.@a = monster( ""this"", -1,-1, ""monster A"", PORING, 1 );
	.@b = monster( ""this"", -1,-1, ""monster B"", PORING, 1 );
	setunitdata .@a, UDT_MODE, getunitdata(.@a, UDT_MODE) | MD_NORANDOM_WALK;
	end;
}
```
### Known Issues and TODO List
is it true that bg_monster spawn inside battleground map, the monster will follow you around ?
both rathena and hercules has this behavior","yeah tested working ...
```
	PORING: {
		NPC_EMOTION: {
			SkillState: ""MSS_IDLE""
			SkillLevel: 1
			Rate: 5000
			Delay: 100000
			Cancelable: true
			SkillTarget: ""MST_SELF""
			CastCondition: ""MSC_ALWAYS""
			val0: 3
			val1: 0x87
		}
		NPC_EMOTION: {
			SkillState: ""MSS_IDLE""
			SkillLevel: 1
			Rate: 5000
			Delay: 100000
			Cancelable: true
			SkillTarget: ""MST_SELF""
			CastCondition: ""MSC_ALWAYS""
			val0: 57
			val1: 0x10083
		}
	}
```
so ?",7551429
617,script-checker.bat always throw missing map file,open,2018-04-05T07:12:51Z,2019-02-20T11:48:15Z,,CONTRIBUTOR,"-  [ ] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.

I think I have modify the mapcache a little bit ?
but can somebody confirm this ?

when I try to execute **Hercules\script-checker.bat**
and throw in WHATEVER file ... ANY file will do
```
[Warning]: map_readfromcache: Could not open the mapcache file for map 'poring_c01' at path 'maps/re/poring_c01.mcache'.
[Warning]: map_readfromcache: Could not open the mapcache file for map 'poring_c02' at path 'maps/re/poring_c02.mcache'.
```
yup ~ like this ~
![script-checker](https://raw.githubusercontent.com/AnnieRuru/customs/master/screenshots/script_checker.png)

but my map_server.exe runs just fine
```
[Status]: Loading maps using map cache files...
[Info]: Successfully loaded '880' maps.
[Status]: Done reading '62' command aliases in 'conf/atcommand.conf'.
[Status]: Done reading '4' channels in 'conf/channels.conf'.
......
```","curious ... is there any difference with poring_c01 and poring_w01 ?
I think ... they are similar ...

maybe gravity changed their map name from poring_c01 into poring_w01 ... or something",7551429
618,please deprecate *strmobinfo script command,open,2018-04-04T08:57:37Z,2018-10-01T16:02:14Z,,CONTRIBUTOR,"woohoo ~ I see many script command getting squash ..... yesh ...
there's 1 more ...

*strmobinfo <-- should be deprecate
*getmonsterinfo <-- everyone use this one ~

the only good thing about `strmobinfo` is ...
it can display both IRO name and Aegis name
but `getmonsterinfo` can only display Aegis name
so we can just add another constant `MOB_ENAME` or `MOB_INAME` ?? for `getmonsterinfo`",,7551429
619,cannot retrieve *getnpctimer value when a player is atttached with *attachnpctimer,open,2018-04-04T08:31:58Z,2019-02-27T19:24:42Z,,CONTRIBUTOR,"I see this https://github.com/HerculesWS/Hercules/pull/1636 and hahaha
so any chance you guys wanna do this one too ?

https://github.com/HerculesWS/Hercules/blob/3514f4405c2a822be2350fed27fe2d15cad7152c/src/map/npc.c#L813

how to reproduce
```
prontera,158,185,5    script    dfgdgdfg    1_F_MARIA,{
    attachnpctimer; // comment this line, it shows the timer
    initnpctimer;
    sleep2 1000;
    stopnpctimer;
    dispbottom getnpctimer(0);
    end;
}
```
if the attachnpctimer is leave on, the timer always show 0, 
but when I remove it, which makes it attach to npc, the timer start showing",,7551429
620,Monster ATK not calculated properly with Level+STR(Renewal),open,2018-03-23T17:33:06Z,2018-03-31T11:15:48Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
The Monster ATK is shown properly in @mi returned info, but not applied in actual practice.
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)
I am using Renewal config. With all Renewal settings enabled, except EXP and Item algorithm.
I have changed FLEE/DEF PENALTY from Mobbing from 3 to 6.
No other changes were made to the battle configs.

### Current Behavior

[//]: # (Describe at length what you noticed during your analysis.)
Make a custom monster with Level 100, 100 STR (all other stats 0) and 1000 ATK1.
Ingame the ATK will be shown properly if you examine the monster with @mi command.
In this case, the monster will show (800 - 1200 ATK) + (STR+LVL) = 1000 - 1400 ATK.
When the monster attacks, it will not take STR and LVL into consideration for damage calculation.
So ingame, the monster can only deal up to 1200 damage, not 1400.
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior

[//]: # (Tell us what should happen instead.)
The Damage of the monster should be up to 1400.

### Steps To Reproduce The Issue

1. Step 1 : Give the Monster Level 100, 100 STR and 1000 ATK1.
2. Step 2 : Give the monster Maximize on attack.
3. Step 3 : Watch as the Monster only deals 1200 damage, not 1400 as intended.

**Branch(es):**
- [x] master

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )
Hercules 64-bit for Linux
Git revision (src): 'd89690fbdbaa5dc78f98d96ee91403e329c12af1'
Git revision (scripts): 'd89690fbdbaa5dc78f98d96ee91403e329c12af1'


### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
OS version: 'Debian GNU/Linux 7.11 (wheezy) [x86_64]'
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
",,7551429
621,Incorrect whisper packet,open,2018-03-15T03:44:47Z,2018-03-15T04:58:25Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

Whisper packet is incorrect in hercules, in 2013 it has been updated, here is the result of zone_server.

```c
// packet 0x9DE
struct PACKET_ZC_WHISPER_V2 {
  short PacketID;
  short PacketLength;
  unsigned long GID;
  char senderName[24];
  char msg[];
};
```
```c
// packet 0x9DF
struct PACKET_ZC_ACK_WHISPER_V2 {
  short PacketID;
  unsigned char result;
  unsigned long GID;;
};
```

`p.unknown = 0;` is incorrect change to `p.GID = sd->status.char_id`

https://github.com/HerculesWS/Hercules/blob/d89690fbdbaa5dc78f98d96ee91403e329c12af1/src/map/clif.c#L6082-L6084

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src: d89690fbdbaa5dc78f98d96ee91403e329c12af1

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

","This packets look like too old.
Atleast packet 0x9de wrong for 2017 clients.
Probably it was changed after 2013.
",7551429
622,Cell_Basilica,open,2018-03-11T16:09:38Z,2018-03-11T16:09:38Z,,NONE,"-  [ x] I have not modified the source prior to reproducing this issue.
-  [x ] I am using the latest version of Hercules.
-  [ x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

* Git Revision: 59f02f1
* Pre-Renewal

Is this normal? cell_basilica is on but Hunter can cast Arrow Shower inside basilica protected cell? What I know is you can't cast any skill when you step on basilica cell.",,7551429
623,Some issues/queries with new mapcache system and db2sql,open,2018-02-20T02:05:06Z,2018-02-20T15:57:50Z,,CONTRIBUTOR,"### Issue Prelude

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

Some things I have found with the new mapcache system.
- When I use `./map-server --convert-old-mapcache`, it reads item, mob and skill dbs, as if I also used db2sql.
- Need some document for the command, unclear how to use, especially in relation to the data folder. Can you still have your map files in the /data folder to build maps? Cause before I was using mapcache.exe on my Windows, with my maps in the Hercules/data folder to create map_cache.dat, then committing map_cache.dat to be used on Linux.
- In relation to db2sql, it gives me an error if I have a custom script command being used in it.
```
[Error]: script error in file 'item_db2.conf' item ID 22360
    parse_line: expect command, missing function name or calling undeclared function
    aura(.@aura, 0);
```
- After db2sql runs, I get the message **Segmentation fault**
```
[Status]: Done reading '4481' entries in 'item_db2.conf'.
[Status]: Done reading '1124' entries in 'db/pre-re/skill_db.conf'.
[Status]: Done reading '1006' entries in 'pre-re/mob_db.conf'.
[Status]: Done reading '553' entries in 'mob_db2.conf'.
Segmentation fault
```

**Branch(es):**
- [x] master

### Operating System

CentOS 7
","Ok, I'll try to reproduce it.

In any case, I recommend against adding the plugins you don't want to run every time (such as db2sql, mapcache, itemdb2doc, naviluagenerator, etc) to plugin.conf. The recommended way to run those those ""developer's"" plugins is to pass their name to the map server's command line. For example:

```
./map-server --load-plugin db2sql --db2sql
```

or

```
./map-server --load-plugin mapcache --convert-old-mapcache
```

That way you never risk running functions from a plugin you don't need. Plugins that define custom commands, or anything that is necessary every time you run the server, can still go into plugins.conf.",7551429
624,fakename stops guild/party names from showing,open,2018-02-08T15:44:35Z,2020-03-08T22:58:35Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

When you have a fakename from using **@fakename**, your guild and party names and guild positions won't be shown.

In the function `clif_charnameack`, I was able to resolve this issue. I'm unsure if it has side effects, but seems to work okay so far!

Find:
```
			if (ssd->fakename[0] != '\0') {
				WBUFW(buf, 0) = cmd = 0x195;
				memcpy(WBUFP(buf,6), ssd->fakename, NAME_LENGTH);
				WBUFB(buf,30) = WBUFB(buf,54) = WBUFB(buf,78) = 0;
- 				break;
			}
+			else
- 			memcpy(WBUFP(buf,6), ssd->status.name, NAME_LENGTH);
+ 				memcpy(WBUFP(buf,6), ssd->status.name, NAME_LENGTH);
```

Also, this is not a bug, rather an undesired feature. I will try to figure out how PR works to see if I can do it myself.

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
","When using RE client (I used 2019-02-20aRagexeRE), every character info vanishes. (Names and guild emblem.)
Even the fake name won't show up.",7551429
625,Adoption Fixes and some new commands,open,2018-01-15T23:21:57Z,2018-04-07T14:03:02Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Changes the behavior when adding skills via `skill()` script command. When sending the packet `0x111` with wedding skills, it tells the client to enable the adoption option when right clicking and with all the other required stuff in order to enable it.
Adds support to adoption via @atcommands and script_commands.
Fixes #1440

**Affected Branches:** 

[//]: # (Master? Slave?)
Master

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)
#1440 

### Credits
rAthena - the whole concept for commands
@Asheraf - By figuring out the relation between the packet `0x0111` and the Adoption Bug.","opps, skill TF_DOUBLE breaks status window info.",7551429
626,fontcolor command with some problems,open,2017-12-10T06:29:42Z,2018-04-25T06:32:35Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

When character is with cart and enter some message in the chat about the effect of the command fontcolor the cart disappears, this applies to all visual effects. 

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Expected Behavior

[//]: # (Tell us what should happen instead.)

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src: 082e635672c12be20e660091004c28920d9e2d43

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )","http://herc.ws/board/tracker/issue-8502-fontcolor-usage-will-strip-gm-cloth/
I am quite sure this thing is unable to fix ... too",7551429
627,Guild Storage,open,2017-11-28T16:48:47Z,2018-07-12T15:07:27Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

Guild storage is not working as official, exclusive packages for guild storage were added on 2013-04-24aRagexe. Currently the storage guild uses the same packet as normal storage.

**2013-04-24aRagexe**
```c
PACKET_CZ_REQ_OPEN_GUILD_STORAGE = 0x9ba
PACKET_ZC_ACK_OPEN_GUILD_STORAGE = 0x9bb

```

**2013-05-02aRagexe**
```c
PACKET_CZ_REQ_CLOSE_GUILD_STORAGE = 0x9be
PACKET_ZC_ACK_CLOSE_GUILD_STORAGE = 0x9bf
```

**2013-08-28bRagexe**
```c
PACKET_ZC_GUILDSTORAGE_ITEMLIST_NORMAL_V5 = 0x9d2
PACKET_ZC_GUILDSTORAGE_ITEMLIST_EQUIP_V5 = 0x9d3
```

**2013-09-11aRagexe**
```c
PACKET_CZ_REQ_GUILDSTORAGE_LOG = 0x9d9
PACKET_ZC_ACK_GUILDSTORAGE_LOG = 0x9da
```

**2013-11-06aRagexe**
```c
PACKET_CZ_MOVE_ITEM_FROM_BODY_TO_GUILDSTORAGE = 0x9e1
PACKET_CZ_MOVE_ITEM_FROM_GUILDSTORAGE_TO_BODY = 0x9e2
PACKET_CZ_MOVE_ITEM_FROM_CART_TO_GUILDSTORAGE = 0x9e3
PACKET_CZ_MOVE_ITEM_FROM_GUILDSTORAGE_TO_CART = 0x9e4
```

**2014-04-02aRagexe**
```c
PACKET_ZC_GUILDSTORAGE_ITEMLIST_EQUIP_V6 = 0xa11
```

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src: fb1fbee39e38a901311b0c1c44f704b1545e9576

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )
","Being an official feature I believe that implementation should occur. 

Maybe @Asheraf  has some information on this.",7551429
628,IgnoreDefense in skill_db.conf is not working,open,2017-11-17T07:39:25Z,2017-12-28T13:58:41Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x ] I have not modified the source prior to reproducing this issue.
-  [x ] I am using the latest version of Hercules.
-  [x ] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description
""IgnoreDefense"" is not working, the damage is still reduced with the target defense. IgnoreDefense is set to true but its really not working see photo below.

Tested on Pre-Renewal and Renewal mode

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Current Behavior

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)
IRO Wiki Asura Strike: http://irowiki.org/wiki/Guillotine_Fist
### Expected Behavior
Asura Strike is always ignored the defense of target
[//]: # (Tell us what should happen instead.)


**Branch(es):**
- [x ] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[/x/]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[/x/]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)

![report1](https://user-images.githubusercontent.com/4656578/32935943-3a618950-cbad-11e7-8e35-33548af36ce3.jpg)
![report2](https://user-images.githubusercontent.com/4656578/32935944-3b2e2848-cbad-11e7-9f73-85c1d11fac46.jpg)
![rep](https://user-images.githubusercontent.com/4656578/32935930-316e58b4-cbad-11e7-800b-e7e1439515a0.jpg)
","This isn't a bug, asura's damage is reduced by a flat amount equal to DEF, the same goes for some other skills such as acid demonstration. You can look it up in source.",7551429
629,Item DB improvements,open,2017-10-23T18:54:13Z,2017-10-24T12:55:15Z,,MEMBER,"Currently, most checks in the Item DB are done in the `script<>` section so it's impossible to make commands to get item requirements/effects. I think we should reduce overall usage of `script<>` while also making it more readable, both to humans and to the engine.

I suggest adding the following sections:

## Requirements
```applescript
{
	Id: 1
	AegisName: ""My_Item""
	Name: ""My Item""

	Requirements: {
		OnPickup: {}
		OnUse: {}
		OnEquip: {
			job: {
				whitelist: @all
				blacklist: [Crusader, Ninja]
				level: 9
			}

			gender: [M, F]

			stat: {
				level: 35
				agi: 6
				luk: 17
			}

			skill: [
				(MG_COLDBOLT, 3)
			]

			inventory: [
				(Frozen_Heart, 1),
				(RJC_Golden_Necklace, 1)
			]
		}
	}
}
```

The above would add requirements for `My_Item` on equip:
- The player can be of any job, except `Crusader` and `Ninja`
- The job level of the player must be at least `9`
- The player must be male or female
- The player must have a base level of at least `35`
- The player must have at least `6` Agi and `17` Luk
- The player must have the skill `MG_COLDBOLT` at level `3` or greater
- The player must have at least `1` `Frozen_Heart` and `1` `RJC_Golden_Necklace` in their inventory

If any condition is unmet, equipping fails

## Restrictions
```applescript
{
	Id: 1
	AegisName: ""My_Item""
	Name: ""My Item""

	Restrictions: {
		cards: {
			whitelist: [Rune_Of_Magic1, Rune_Of_Magic2]
			blacklist: @all
			max: 1
		}
	}
}
```

The above would add the following restrictions on `My_Item`:
- No cards can be inserted, except `Rune_Of_Magic1` and `Rune_Of_Magic2`
- Only 1 card be inserted at most

## Effects
```applescript
{
	Id: 1
	AegisName: ""My_Item""
	Name: ""My Item""

	Effects: {
		OnEquip: {
			bonus: [
				(bInt, 3),
				(bDoubleRate, 25)
			]

			skill: [
				(TF_DOUBLE, 5, false)
			]
		}

		weight: 150
	}
}
```


The above would apply the following effects on use:
- give the bonus `bInt` with value `3`
- give the bonus `bDoubleRate` with value `25`
- give the skill `TF_DOUBLE` at level 5, temporarily

And the following persistent effects:
- Increase item burden by `150`
","looks nice. seems nightmare to convert. hopefully, if it goes thru, you could retain support for the current format.",7551429
630,Applied standardization to WolfchevLaboratory script,open,2017-10-22T08:21:34Z,2017-10-29T18:13:37Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Applied a few changes to fit script with official one and applied standardization to entire script.

**Affected Branches:** `Master`

**Issues addressed:** `None`

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[v]: # (**NOTE** Enable the setting ""[v] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1885)
<!-- Reviewable:end -->
",7551429
631,Applied standardization to BangungotHospital script,open,2017-10-22T07:48:35Z,2018-01-28T07:53:53Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Applied a few changes to fit script with official one and applied standardization to entire script.

**Affected Branches:** `Master`

**Issues addressed:** `None`

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[v]: # (**NOTE** Enable the setting ""[v] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1876)
<!-- Reviewable:end -->
",7551429
632,Reduce the amount of gitlab-ci pipeline jobs by half,open,2017-10-21T21:30:51Z,2018-04-08T11:05:35Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Pre-renewal and renewal builds for each configuration are now built as part of the same job.
This should reduce the burden on the gitlab-ci infrastructure, and will become necessary when the changes discussed on https://gitlab.com/gitlab-com/infrastructure/issues/2885 will take place.

**Affected Branches:** 

- master
- stable

**Issues addressed:**

https://gitlab.com/gitlab-com/infrastructure/issues/2885

### Known Issues and TODO List

- [ ] This currently reduces the number of jobs from 49 to 25, which is still larger than the planned maximum limit. Further changes will be necessary.


[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","Updated and tested now that gitlab-ci can complete our builds again.

https://gitlab.com/MishimaHaruna/Hercules/commit/48a89d3f54aed8a70d25858ce91522b832939d2c/pipelines

http://mishimaharuna.gitlab.io/Hercules",7551429
633,script engine strict mode,open,2017-10-17T01:35:57Z,2019-03-23T02:14:14Z,,MEMBER,"Since it doesn't seem we're getting a new script engine any time soon, we could at least make the existing one stricter meanwhile.

> @kisuka 
just re-write the whole parser, make it super fucking strict

Yeah... let's not rewrite it, but let's instead just add more checks

<br>

I suggest adding a strict mode, which would make the following illegal:
* lack of parentheses when calling a function
    > do_something foobar;
* space between the function name and the opening parenthesis
    > do_something (foobar);
* lack of space between control statements (`if`, `for`, `while`, `switch`) and the opening parenthesis
    > if(condition) { do_something(); }
    else if(condition) { do_something(); }
    while(condition) { do_something(); }
* implicit conversion from string to integer, or from integer to string
    > ""5"" + 2
* use of NPC variables (`.var`) from within a function. this is almost always not what the scripter intended anyway
    > .foo = 1;
* use of deprecated script commands (`menu` et al)
* use of numeric values where the script engine expects an enum constant
    > strnpcinfo(3)
* use of tabs in npc/function/… definitions, which would allow us to use another separator, such as a semicolon

<br>

To switch on strict mode for the whole file we could just add something like this to the top:
```c
#pragma strict on
```
Or we could switch it on for all files by adding a config flag

<br><br>

---

Of course there's still some problems that we can't address in a simple way and would merit more thoughts:
* differentiating char variables from constants
* declaring variables before use
","> Or we could switch it on for all files by adding a config flag

https://github.com/HerculesWS/Hercules/blob/stable/conf/map/script.conf
you can do what-ever you like here with the config off",7551429
634,@channel ban #channel not saved,open,2017-10-14T03:05:52Z,2018-06-29T15:37:43Z,,CONTRIBUTOR,"### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

Sorry for always reporting so much.
When I use `@channel ban #irc`, the bans don't persist once the server closes.

### Current Behavior

Once you close the server `./athena-start stop`, all channel bans are cleared.

### Expected Behavior

I would expect these bans to persist and be permanent.

### Steps To Reproduce The Issue

1. Ban somebody in a channel, e.g. `@channel ban #irc MyCharacter`
2. Restart your server `./athena-start stop`, `./athena-start start`
3. Check `@channel banlist #irc`, it will be empty.
",Bump. Channel ban is a useless feature as it stands.,7551429
635,Compartmentalize everything,open,2017-10-10T02:21:43Z,2017-10-10T02:21:43Z,,MEMBER,"- [ ] move the IRC interface to a plugin
- [ ] move the Ragnarok-related skills and jobs to a plugin

- [ ] <sup><sub>finish writing this list</sub></sup>",,7551429
636,Initial commit of Eden Market,open,2017-09-29T02:49:04Z,2017-10-21T16:15:16Z,,CONTRIBUTOR,"Source: http://ragnarok.wikia.com/wiki/Para_Market
original script by Nyalin

[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- I have followed [proper Hercules code styling][code].
- I have read and understood the [contribution guidelines][cont] before making this PR.
- I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

[//]: # (Master? Slave?)

**Issues addressed:**

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1848)
<!-- Reviewable:end -->
",7551429
637,SA_DISPELL doesn't work when in @duel on non-vs map,open,2017-09-26T05:52:02Z,2017-09-26T09:14:06Z,,CONTRIBUTOR,"-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

I think the title explains it well enough. When in a duel (using @duel atcommand), if you are not already on a `map_flag_vs` map, you will not be able to use Sage skill 'Dispell' on your opponent.

### Test Conditions
Neither player had a party or guild. Map was Lighthalzen with default mapflags.

### Expected Behavior
Should be able to Dispell your duel opponent if you are both inside a duel.

[//]: # (Tell us what should happen instead.)

### Steps To Reproduce The Issue

1. Go to any map without PVP, GVG, BG, PK, etc. (such as Lighthalzen, it was the map I was on).
2. Initiate a duel, using your Sage with a leveled Dispell skill, using the @duel command.
3. Try to dispel your opponent. It will fail (`break`)

### Fix (Maybe)
Should be able to fix by altering the 'fail and no skill message' clause. 
```
if (sd && dstsd && !map_flag_vs(sd->bl.m) &&
((sd->status.party_id == 0 || sd->status.party_id != dstsd->status.party_id) &&
(!sd->duel_group || sd->duel_group != dstsd->duel_group)))
	// Outside PvP and Duels it should only affect party members and no skill fail message.
	break;
```
I tested the above and it works.

**Branch(es):**
- [x] master",,7551429
638,Fix re-equip & misceffect in Set Item Option,open,2017-09-23T20:51:47Z,2017-10-21T02:38:21Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
Fix re-equip & misceffect in Set Item Option:
- When setequipotion is successful, item is not re-equipped.
- Wrong value in misceffect, it shows failed refinement.

[//]: # (Describe at length, the changes that this pull request makes.)

**Affected Branches:** 

[//]: # (Master? Slave?)

- [x] Master

**Issues addressed:**

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1846)
<!-- Reviewable:end -->
",7551429
639,Monsters Summoned by Script Cannot Get boss_monster status,open,2017-09-17T14:58:24Z,2019-04-09T02:47:56Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

Boss monsters, such as the lhz_dun03/04 ones, that are summoned through scripts can never attain the same setting as monsters spawn through the `boss_monster` NPC definition.

### Why make this change?

It will allow people to take advantage of the Tombstone system for script-spawned monsters.

### New Behavior

There should be an optional parameter or a new script command `bossmonster` for summoning these monsters, with the appropriate respawn delays able to be set for tombstones.

**Branch(es):**
- [x] master
","I believe the main reason to enable npc script to spawn a monster with `boss_monster` are because of the usage of convex mirror item, that used to track the location of MVP monster.

Perhaps we could consider a new script command that spawn monster that has `md->spawn->state.boss`. auto respawn are optional.
Might as well consider a separate script command to handle create/destroy for Tombstone. 

Tombstone for LHZ bosses, its possible to be done even at current stage, just the location might differ since we can't get the exact coordinate of the monster when it died. and it is ugly way to do it. 
_(`md` data no longer available when the mob died and trigger OnNPCKillEvent, need to find a way to store the `md` data for this case.)_
![Image of Yaktocat](https://i.imgur.com/j6xu6ZS.png)",7551429
640,WIP: allow buildin_callshop to work with any shop type,open,2017-08-24T17:52:34Z,2017-09-06T17:36:07Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [X] I have followed [proper Hercules code styling][code].
- [X] I have read and understood the [contribution guidelines][cont] before making this PR.
- [X] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

* make `buildin_callshop` use proper Hercules coding style
* make `buildin_callshop` work with any shop type (zeny, cash, market, custom)


[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
",putting this aside for now as I will need to add new config flags and do extensive testing on both the Gravity client and ManaPlus (with Evol plugin). I got more important things to deal with first so this goes in my backlog for the time being,7551429
641,WIP - Change various dynamically allocated array into VECTOR types,open,2017-08-17T00:36:16Z,2018-04-25T16:14:16Z,,MEMBER,"### Pull Request Prelude

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)

This pull request fixes issue #738, by changing some variable-sized, dynamically allocated, arrays into VECTOR types (through some minor refactoring).

Some quality-of-life improvements to the VECTOR_ macros are also introduced:

- The `VECTOR_ENSURE()` macro now defaults to using a step of 1 (and the old version is renamed to `VECTOR_ENSURE_STEP()` for the cases where a custom step is desirable)
- The `VECTOR_ENSURE()` macro is now called automatically by the various `VECTOR_INSERT*` and `VECTOR_PUSH*` macros that require additional space (but it is still available to be manually called, for pre-allocations).

**Affected Branches:** 

master

**Issues addressed:**

#738

### Known Issues and TODO List

- Untested
- To be checked whether more arrays need a similar treatment

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1824)
<!-- Reviewable:end -->
",7551429
642,WIP: Deprecate hardcoded variables,open,2017-08-12T16:57:52Z,2017-09-20T02:57:08Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [X] I have followed [proper Hercules code styling][code].
- [X] I have read and understood the [contribution guidelines][cont] before making this PR.
- [X] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

The aim of this PR is to remove hardcoded variables and allow to explicitly specify the variables, or when not possible, reduce the scope to the lowest possible (ie `.@` vars).

<br><br>

### To-Do

- [X] Update buildins that use global hardcoded variables so they allow to specify a variable instead
    - [X] `buildin_getguildmember`
    - [X] `buildin_getmobdrops`
    - [X] `buildin_getwaitingroomstate`
    - [X] `buildin_warpwaitingpc`
    - [X] `buildin_waitingroom2bg`

<br>

- [ ] Update buildins that use PC hardcoded variables so they allow to specify a variable instead
    - **➜** Those buildins are already scoped to the PC and they are PC-related so imho they could stay as-is... Any thoughts?
    - [ ] `buildin_getinventorylist`
        - not sure it would be possible to de-hardcode this as it uses dynamic var names for item options
    - [ ] `buildin_getcartinventorylist`
        - not sure it would be possible to de-hardcode this as it uses dynamic var names for item options
    - [ ] `buildin_getskilllist`
    - [ ] `buildin_countbound`
    - [ ] ~~`buildin_menu`~~ (deprecated so we don't care)

<br>

- [x] Make edge cases (ie the `~=` operator) use the lowest possible scope
    - [x] Add a `use_deprecated_variables` config flag and set to `true` by default when not specified and to `false` in the .conf file. This means new installations will use the low-scope (`.@`) variables by default (because present in the conf file) and old installations will continue to use the high-scope (`$@`) variables for backward-compatibility
    - [x] Also update other components that have hardcoded variables

<br>

- [ ] Update existing scripts
- [ ] Update `script.conf` to add `use_deprecated_variables: false`
- [ ] Do extensive testing to make sure everything works as intended
    - [ ] review every line
    - [ ] DRY it up
- [ ] Update the documentation

<br><br>

# WORK IN PROGRESS: *DO NOT MERGE*

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","@MishimaHaruna since we now have a way to inject variables into the scope we could allow passing arguments to events/timers; is this desirable?

The syntax could be something like this:
```c
addtimer(<ticks>, ""<npc>::<event>"", <account id>{, <variable>[<index>] ...});
```

Which would allow to do things like:
```c
addtimer(5000, ""NPC::OnMyEvent"", .@account_id,
	.@foo, .@bar[50], .@baz$);
```

The above would add a timer to the player and store a pointer to a `struct argrec_t` which would contain the variables to inject. After `5000` ticks, `NPC::OnMyEvent` is called and the variables from `argrec_t` are injected into the new scope, with the same name and index they had when passed to addtimer",7551429
643,Logged Error Messages shown DOS color codes when display in text editor.,open,2017-08-12T14:43:16Z,2017-11-19T03:48:25Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Current Behavior

The log text files display the color code that indicate the errors/warnings.
However when the log files are open in both notepad and notepad++ editor, it show slightly different contents probably due to encoding? not so sure. _(was using UTF-8)_

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior

It should display only the raw error messages in the text files, **without the color code** that used in DOS.
and perhaps both notepad and notepad++ should be able to display same contents?
 
[//]: # (Tell us what should happen instead.)

Error Messages:
![Image of Yaktocat](http://i.imgur.com/UW7Mg09.png)

Logged Error Messages (Preview in Notepad):
![Image of Yaktocat](http://i.imgur.com/7WEFoFQ.png)
_Notice that the color code that used in DOS are displayed in the notepad.
and there exist a ""small dot"" in front of the line. Unable to copy it to here, probably is encoding issue i guess.

Logged Error Messages (Preview in Notepad++):
![Image of Yaktocat](http://i.imgur.com/vWK8gM2.png)

### Steps To Reproduce The Issue

1. Enable warning/errors log settings.
2. Randomly generate any warnings/errors, for example item_db / mob_db / etc...
3. Check your log folder for the logged errors message.

**Branch(es):**
- [x] master
- [x] other

**Hercules rev. hash/commit:** 

Git revision src: 00db1dd28778180603098b56cbf0fa12b58df4bb

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

Window 10

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
","This has actually been there for a long time (it was just less visible, because the script parsing error messages weren't colored before).

The `[Error]`, `[Warning]`, `[Status]`, etc text isn't affected, because the color gets added by `vShowMessage()` only in the case it's logging to the console, but every other message that contains colors or any kind of formatting, will end up in the log file with the control codes.

I personally don't mind the control codes in the log files (since I use a vim plugin that uses them to show the right formatting), but I understand that people might want to skip the control codes in their log files.

I believe that adding an option to strip the control codes would be reasonable (it can be enabled by default, if that's what people wish). It'd need to scan through the string, detect the control codes, and copy to another string, after stripping them.",7551429
644,Reflect/Auto-guard interaction,open,2017-07-21T13:34:21Z,2018-09-27T19:23:03Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)
Reflecting physical damage while auto-guard is active on a devoted target has weird behavior.

### Current Behavior

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)
Dodging an attack from auto-guard still causes reflect.

### Expected Behavior

[//]: # (Tell us what should happen instead.)
No reflect damage should take place when auto-guard causes an attack to miss.

### Steps To Reproduce The Issue

Auto-guard, then devote somebody. Have a third person attack the devoted target.
When auto-guard causes an attack to miss, the reflect damage will still be calculated.

**Branch(es):**
- [x] master
- [x] other

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
",@EyesOfAHawk  can you help us in this? ,7551429
645,script engine self-test on (ficticious) PC,open,2017-07-11T14:54:46Z,2017-07-25T10:44:28Z,,MEMBER,"After patching `set()` (#1800) I've had this conversation with @4144 

- - -

>\<meko\>
maybe I should add unit tests for getting / setting pc vars of another pc

>\<meko\>
nvm, wouldn't work

>\<meko\>
because self-test doesn't and can't attach a rid

>\<4144\>
yes

>\<4144\>
only if add some mock user object. then will be possible

>\<meko\>
feels overkill for just one or two test

>\<4144\>
can be not one or two. most functions related to players

- - - 

Would this be desirable?","I'd personally love it. I did something like this a few times, locally (well, as a quick and dirty hack), to be able to bisect issues related to commands that needed a RID attached, so that I could automate the bisection.

This could also be done as a plugin (so that it won't be loaded in production), if feasible.
",7551429
646,Handling IRC channel messages,open,2017-07-06T01:57:29Z,2017-07-25T13:42:34Z,,MEMBER,"I recently added a buildin for reading messages from channels (#1719). However there's a problem: it cannot handle the `#irc` channel fully. This is because the way I set it up the event triggers when a player sends a message to a channel and not when a channel receives a message. When the player sends something, an event is dispatched with the player attached and the `@channelmes$` variable is set.

For IRC this works when sending messages from Hercules to IRC but not the other way around, because it only triggers when sending. This means if a user in the IRC channel says something the server has no way to read the message, unless it was sent through Hercules.

<br>

There's two ways I could solve this:

* Make the `addchannelhandler()` command also call the event when a message is *received*, only in the `#irc` channel, without an attached player and making it register `$@channelmes$` instead of `@channelmes$`
    * 👍 no need for an extra global event or config flag
    * 👎 adds an extra layer of complexity for one single edge case

<br>

* Make the server call `::OnIRCEvent` globally when an incoming event occurs in the IRC channel. This could be triggered on/off via a config flag
    * 👍 keeps `addchannelhandler()` simple
    * 👍 could be used to retrieve not only messages but also other events (join, part, quit, ...)
    * 👎 adds an extra global event (affects performance)

<br>

Thoughts? Any other idea?","That looks correct @mekolat 

In the list of triggers, where would CTCP 'ACTION' (i.e. `/me`) fall? Same trigger as `message`?
`kick` could also be added, and perhaps `other`, although I'm not sure it can be of much use.",7551429
647,Scriptable skills,open,2017-07-01T02:54:19Z,2017-07-12T10:07:23Z,,MEMBER,"Here's a proposal: a new command that allows to bind skill invocations to script events. This would allow for dynamic skills that rely on quest state and such, and would allow scripters to make new skills without having to modify the engine or write a plugin.

```c
bindskill(<id>, ""<name>"", ""<NPC::Event>"");
```

<br>

When the skill is invoked it would call `NPC::Event` with the invoking player attached, and would register the following array:

* `@skill_target`
    * first element is the type of target, ie area, pc, npc, ...
    * second element is _GID_ if target is a unit or  _x_, _y_ if target is an area

<br>

<sub>In the past I did something similar for tmwAthena, but it used chat commands (bound with the `registercmd` buildin) instead of skills, although using skills was the plan but it never came to fruition... If you're curious, see the files here: https://github.com/themanaworld/tmwa-server-data/tree/master/world/map/npc/magic </sub>","I don't mind this, if there are concrete use cases that require it.
Considering how the client needs to know the skill information in advance, I believe the skill db approach is reasonable, since it wouldn't be possible to dynamically create new skills.

Using the event queue requires some tests with reasonable skill scripts, to see if the current size of the queue is appropriate (`MAX_EVENTQUEUE == 2`, `MAX_EVENTTIMER == 32`). I'd prefer if those wouldn't get increased unless really necessary though, to avoid affecting resource use and performance for those that aren't interested in this feature.",7551429
648,callshop() not disabling walking around,open,2017-06-30T04:46:33Z,2018-06-29T15:36:31Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

When using the script command `callshop()`, characters can still walk around, click NPCs, etc.

### Current Behavior

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)
When you use `callshop()`, you will still be able to walk around, click NPCs, etc.

### Expected Behavior

[//]: # (Tell us what should happen instead.)
`openshop()` does not seem to have this behavior. When I `callshop()`, I shouldn't be able to walk around.

### Steps To Reproduce The Issue

Create a script that uses `callshop(""My_Shop"", 1)` and you will still be able to walk around.

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
",Bump.,7551429
649,quest data commands,open,2017-06-18T16:13:26Z,2017-11-19T03:48:25Z,,MEMBER,"@Asheraf wants a way to return data from the quest db.

```rust
<Asheraf> ok so we have getiteminfo() and getmonsterinfo()
<Asheraf> but we dont have getquestinfo()
<Asheraf> which is simply returns informations about quests from the db
```

---

So yeah, let's discuss the implementation details. I suggest:


```go
getquestinfo(<id>, QUEST_NAME) => quest name

getquestinfo(<id>, QUEST_TIMELIMIT) => time limit

getquestinfo(<id>, QUEST_TARGETS, <mob_id array>, <count array>) => length

getquestinfo(<id>, QUEST_DROPS, <item_id array>, <rate array>, <mod_id array>) => length
```",http://herc.ws/board/topic/8969-script-command-getquestinfo/,7551429
650,Configuration for disabling status on zone,open,2017-06-13T06:58:43Z,2019-10-02T07:31:36Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

[//]: # (Describe at length, the changes that this pull request makes.)
Adds configuration for disabling status on zone, i.e if some status is disabled on zone, that status won't be enabled and ended as soon as player warps to the map.
Format:
```
disabled_status: {
	SC_NAME: true/false
}
```
**Affected Branches:** 

[//]: # (Master? Slave?)
* all

**Issues addressed:**
Topic: http://herc.ws/board/topic/4401-map-zone-debuff/

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

[//]: # (Insert checklist here)
[//]: # (Syntax: - [ ] Checkbox)

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

None

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","@4144 Updated and rebased, please check",7551429
651,BUG when skipping previous classes SNE.,open,2017-06-08T01:37:09Z,2017-06-14T00:20:34Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description
I have already opened a issue related to this and the problem has been resolved. 
https://github.com/HerculesWS/Hercules/issues/1603
However, after more testing I encountered a specific problem directly related to the Super_Novice_Expanded class (ID: 4190). I'm trying to get it to the maximum level of base and class via script command, however, I'm not able to restrict the amounts of skills that should be used in each profession, as can be seen in the structure below:
9 - Novice skill points (Job_Novice_High -ID: 4001) ""Basic skills"".
99 - Super Novice points (Job_Super_Novice - ID: 23) - 1rt
49 - Super Novice Expanded Skill Points (Job_Super_Novice_E - ID: 4190) - 2nd
[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Current Behavior
I tested with both variables and none restricted the amounts of skills used by profession.
jobchange_level = 99;
jobchange_level_3rd = 99;
novice_skill = 99;
[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior
The player should need to use the 99 points of the profession Id: 23 before using the 49 points of the profession id: 4190
[//]: # (Tell us what should happen instead.)

### Steps To Reproduce The Issue

1. Step 1
2. Step 2
3. Step 3

**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src:
[Info]: Hercules 32-bit for Windows
[Info]: Exported revision (src): 'Unknown'
[Info]: Exported revision (scripts): 'Unknown'
[Info]: OS version: 'Windows 8 Workstation (other) (build 9200) [x86_64]'
[Info]: CPU: 'x86_64 CPU, Family 6, Model 142, Stepping 9 [4]'
[Info]: Compiled with Microsoft Visual C++ 2015 (v1900)
[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System
Windows 10 Home - x64 64 bits
[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)

```
prontera,150,150,3	script	master	4_F_HIMEL,{
	
	//--------------------------
	set @nome$,""[^FF8000Master^000000]"";
	set @level,160;
	set @job,99;
	//--------------------------
	
	jobchange 4190;
	set BaseLevel,BaseLevel+@level;
	set JobLevel,JobLevel+@job;
	set SkillPoint,Skillpoint+148;
	next;
	mes @nome$;
	mes ""You will be logged in..."";
	jobchange_level = 100;
	jobchange_level_3rd = 100;
	atcommand(""@kick ""+strcharinfo(0)+"""");
	cutin """",255;
	close;
}
```",,7551429
652,Setunitdata don't work.,open,2017-06-07T21:36:16Z,2018-06-13T00:17:46Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x ] I have not modified the source prior to reproducing this issue.
-  [x ] I am using the latest version of Hercules.
-  [x ] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description
The first issue is that the monster continues to summon its mobs, even though I block via setunitdata and they do not attack, but use abilities.

As I'm trying to prevent the monster from using skills, I tried to find a mode for setunitdata, but I found none. I was suggested these options by dev. Meko, as a workaround, however, to no avail.
[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Current Behavior
Monster continues to invoke his mobs even blocking with setunitdata and no setunitdata has been found to block the skills of monsters and mobs.
[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior
Monster should not use skills and summon his mobs.
[//]: # (Tell us what should happen instead.)

### Steps To Reproduce The Issue

1. Step 1:Click on npc.
2. Step 2:Enter the ID of a MvP monster (which has mob).
3. Step 3:Advance and the monster will be invoked.
4. Step 4:Wait and the monster will summon your mob and use skills.

**Branch(es):**
- [x] master
- [x] other

**Hercules rev. hash/commit:** 

Git revision src:
[Info]: Hercules 32-bit for Windows
[Info]: Exported revision (src): 'Unknown'
[Info]: Exported revision (scripts): 'Unknown'
[Info]: OS version: 'Windows 8 Workstation (other) (build 9200) [x86_64]'
[Info]: CPU: 'x86_64 CPU, Family 6, Model 142, Stepping 9 [4]'
[Info]: Compiled with Microsoft Visual C++ 2015 (v1900)
[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System
Windows 10 Home - x64 64 bits
[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)

```
prontera,170,170,3	script	Test	4W_M_03,{	
    // YOUR INPUT FUNCTIONS GO HERE

function input_mob_id {
    do {
        mes(""Please enter the desired mob ID."");
        input(.@id, 1001, 10000);
    } while(getmonsterinfo(.@id, MOB_LV) < 0);

    // ^ the above will keep asking the player over and over until
    //   they enter the ID of a monster that exists

    next();
    return .@id;
}
    // YOUR MAIN SCRIPT GOES HERE

    do {
        mes(""Hi there, please enter the desired values.""); // print a message
        next(); // require the player to click ""next""

        .@mobID = input_mob_id(); // call the mob id menu, store the value

        // ^ HERE ADD MORE CALLS AS NEEDED
         
        mes(""Do you wish to proceed?""); // print a message
        select(""Start over."", ""Proceed.""); // ask the player if they wish to continue

    } while (@menu != 2);

    mes(""Please close the dialog to continue."");
    close2(); // require the player to close the dialog

    // HERE SPAWN YOUR MONSTER
    .@unitID = monster(""prontera"",170,170, getmonsterinfo(.@mobID, MOB_NAME), .@mobID, 1); // MAKE SURE TO CHANGE THE map, x and y

    // NOW MANIPULATE THE MONSTER WITH THE DATA YOU GATHERED
	// to prevent from moving:
	setunitdata(.@unitID, UDT_MODE, getunitdata(.@unitID, UDT_MODE) &~ 1);
	
	// to prevent from attacking:
	setunitdata(.@unitID, UDT_MODE, getunitdata(.@unitID, UDT_MODE) &~ 128);
	
	//to prevent from summon mob
	setunitdata(.@unitID, UDT_MODE, getunitdata(.@unitID, UDT_MODE) &~ 8);
	//or
	setunitdata(.@unitID, UDT_AI, 0);  //value retired from constant.db
	
	//to prevent skills
	setunitdata(.@unitID, UDT_ATKMAX, 0);	setunitdata(.@unitID, UDT_MATKMAX, 0);
	//or
	setunitdata(.@unitID, UDT_CANMOVETICK, 2147483647);
    
	end; // terminate the script
}
```
Topic with more information: http://herc.ws/board/topic/14706-script-that-runs-a-custom-monster-for-testing/#comment-82274

","currently there is no script command to disable a monster to summon mobs
although its not that hard to do ...
rathena add `MD_NOCAST_SKILL` ... which I personally think that is unofficial
I *think* ... add something else with `*setunitdata` like UDT_FLAG something that uses bitmask value ...
so can control more than 1 things

now your script
```
	//to prevent from summon mob
	setunitdata(.@unitID, UDT_MODE, getunitdata(.@unitID, UDT_MODE) &~ 8);
	//or
	setunitdata(.@unitID, UDT_AI, 0);  //value retired from constant.db
```
1st one is... wrong
`MD_ASSIST` is like ant_hell, where all the ants attack you if you just attack 1 of them

2nd one also wrong ...
UDT_AI defines the monster behavior, which most of them are hard-coded
```
<ai> can be:
	0 = none (default)
	1 = attack/friendly
	2 = sphere (Alchemist skill)
	3 = flora (Alchemist skill)
	4 = zanzou (Kagerou/Oboro skill)
```
I'll take this one then",7551429
653,Implementation of Hercules Ultimate Storage System (HUSS),open,2017-06-04T16:15:51Z,2019-05-30T18:12:28Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

## Design

Implementation of the Hercules Ultimate Storage System
Storages can now be created through a configuration file that describes their attributes.
Example storage configuration:
    
```
{
        Id: (int)                              (required|unique) Unique Identifier
        Name: (string)                         (required) Name of the storage sent to the client.
        Capacity: (int)                        (required) Maximum capacity of the storage.
}
```

Additional storages are handled with dynamic arrays that will save a tonne of memory when created, as opposed to a design in which they were implemented using fixed length arrays. In simple terms, a storage of 600 items would approximately cost the same amount of memory as 600 storages with 1 item each.
They are saved in the same storage database (SQL) as the original separating them by a storage identifier.
An infinite number of storages can be created, there are no limits.
The current design implementation only allow saving/loading of approximately 1600 items per storage due to packet size limits.
    
PS. Make sure you apply SQL upgrades for this patch!

## Access Modes

Storage access modes can be set through the `openstorage` builtin command.

```
	STORAGE_ACCESS_VIEW     // View storage only
	STORAGE_ACCESS_GET      // Allow getting items from storage.
	STORAGE_ACCESS_PUT      // Allow putting items to storage.
	STORAGE_ACCESS_ALL      // Allow all actions.
```

Default storage mode : STORAGE_ACCESS_ALL

## Script Commands

Changed: `openstorage(<storage_id>{, <storage_mode>})`

**Affected Branches:** master

**Issues addressed:** #1762 

### Known Issues and TODO List

- [ ] Allow resending packets with remaining item data that exceeds packet size (in the case where storage capacity is above the limit).
- [ ] Alternatively, Screw sending any storage details to the character server and handle everything on the map server level.
- [x] Test storage modes.
- [ ] Storage names are only sent client side when an item is present in the storage. (part of the `clif_storagelist` clause in `storage_storageopen`
 
[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","> Umm will this System merged?

not yet merged, here code too outdated...",7551429
654,Storage and teleporting,open,2017-06-04T05:07:55Z,2017-11-19T03:48:25Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Current Behavior
Using teleportation skill while storage is open wont close it.

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior
Test on kRO shows that the storage got closed when the player uses teleportation skill

[//]: # (Tell us what should happen instead.)

### Steps To Reproduce The Issue

1. Open storage.
2. use teleport skill.

**Branch(es):**
- [x] master

```
[Info]: Hercules 64-bit for Linux
[Info]: Git revision (src): '10cb83a30cc50d757e05924fb29c11fc68abda49'
[Info]: Git revision (scripts): '10cb83a30cc50d757e05924fb29c11fc68abda49'
[Info]: OS version: 'Ubuntu 14.04.5 LTS [x86_64]'
[Info]: CPU: 'Intel(R) Core(TM) i5-4200H CPU @ 2.80GHz [4]'
[Info]: Compiled with GCC v4.8.4
[Info]: Compile Flags: -g -O2 -pipe -ffast-math -Wall -Wextra -Wno-sign-compare -std=c99 -Wno-unused-parameter -Wno-clobbered -Wempty-body -Winit-self -Wpointer-arith -Wformat-security -Wformat -Wformat-y2k -Wsuggest-attribute=noreturn -Wundef -Wnested-externs -Wold-style-definition -Woverlength-strings -Wredundant-decls -Wcast-qual -Wno-format-nonliteral -Wno-switch -Wno-missing-field-initializers -Wno-suggest-attribute=format -Wshadow -fno-strict-aliasing -g -fno-omit-frame-pointer -DHAVE_EXECINFO -DMAXCONN=16384 -I../common -DHAS_TLS -DHAVE_SETRLIMIT -DHAVE_STRNLEN -DDEBUG -DHAVE_MONOTONIC_CLOCK
```","- Current Hercules behaviour

https://drive.google.com/open?id=0B8s-sa51NSkgWjV5cFJWb2dqSzA

- kRO Sakray

https://drive.google.com/open?id=0B8s-sa51NSkgUDZ6cmI1WnJMa0k",7551429
655,script_getval() discards references,open,2017-06-03T19:16:26Z,2017-09-22T17:51:53Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [X] I have not modified the source prior to reproducing this issue.
-  [X] I am using the latest version of Hercules.
-  [X] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

The `swap()` buildin disregards the reference (`reg->ref`)

### Current Behavior
```c
// define a function
function	script	foobar	{
    swap(getarg(0), getarg(1));
}


// in another script:
.@foo = 1;
.@bar = 2;

foobar(.@foo, .@bar);
```
The above will NOT swap the values of `.@foo` and `.@bar` in the outer scope (because the reference is lost) but will instead swap it in the scope of the `foobar` function. This means in the outer scope foo is still 1 and bar is still 2 (while it should be 2 and 1 instead), and in the scope of the foobar function foo is 2 and bar is 1 (while they should both be 0, undeclared)

#1765 closes this",The workaround in #1765 looks good. Modifying get_val() could cause problems with other code that relies on it. I'll doublecheck to make sure,7551429
656,Switch statement with string expressions,open,2017-05-25T01:33:24Z,2017-06-03T21:06:12Z,,MEMBER,"The switch statement currently only supports integer input and integer comparison; I want to add support for strings too, so you'd be able to do the following:

```c
switch(.@fruit$) {
case ""orange"":
    // you chose ""orange""
    break;
case ""apple"":
    // you chose ""apple""
    break;
case ""banana"":
    // you chose ""banana""
    break;
}
```

Currently the alternative is either doing a long else-if chain, or getting the first letter and converting to ascii value, which is much less pretty:
```c
switch(ord(charat(.@fruit$, 0))) {
case 111:
    // you chose ""orange""
    break;
case 97:
    // you chose ""apple""
    break;
case 98:
    // you chose ""banana""
    break;
}
```

Any objections before I start putting time into this?","Ok, sounds good to me!",7551429
657,Macro WFIFOHEAD not always clean buffer.,open,2017-05-19T23:48:47Z,2017-11-19T03:48:25Z,,CONTRIBUTOR,"### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

Macro WFIFOHEAD not always clean allocated buffer.

### Current Behavior

Because this server may send to client garbage in unused fields in packets.

### Expected Behavior

Unused fields in packet should be always 0.

**Branch(es):**
- [x] master

**Hercules rev. hash/commit:** 

Git revision src: be118c7fad6df29dc691452ef511ac12fea37a06
","@mekolat 4144 has included the commit that he tested on, and not blaming that commit for this issue.",7551429
658, Why not add mac adress address support?,open,2017-05-14T22:26:54Z,2017-07-10T14:44:15Z,,NONE,"We all know of such need in the emulator and how important that would be. Here's the question: Why not add mac adress address support?
NOTE: This was implemented here in Brazil, in an emulator that is fork of Hercules.
https://github.com/brAthena/brAthena/commit/d1ebe6dd5424bd92ec6bbd0e1b9ff033105f80f7","I don't believe the MAC address is of any use, but okay, since the field exists there, we can accept pull requests that handle it.

The reasons why I won't waste time on it unless a pull request comes are (summarized from the above):

- The MAC address is very easy to spoof, and doesn't really identify an user
- From my experience, it's always set to zero",7551429
659,Long Physical Damage,open,2017-05-13T15:28:29Z,2017-06-03T21:09:34Z,,NONE,"I'm using last version hercules

Rune Knight 
Skill:
Dragon Breath/Dragon Breath Water
Damage don't increase using Weapon with Archer Skeleton Card/Expert Archer Enchants 
and Garment Heroic Backpack +9 with Menblatt card Damage don't increase",,7551429
660,WIP: make `@set` atcommand handle params properly,open,2017-05-06T16:31:53Z,2017-05-12T13:16:18Z,,MEMBER,"### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [X] I have followed [proper Hercules code styling][code].
- [X] I have read and understood the [contribution guidelines][cont] before making this PR.
- [X] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed
Currently if you try to do `@set Zeny 500` (or any other param) it would output `Zeny value is now :0` because `@set` does not handle params at all. This PR fixes this.

**Affected Branches:** `master`
**Issues addressed:** *(none)*
**Type:** [bug](https://github.com/HerculesWS/Hercules/labels/type%3Abug)
**Severity:** [1 (trivial)](https://github.com/HerculesWS/Hercules/labels/severity%3A1-trivial)
**Components:** [script engine](https://github.com/HerculesWS/Hercules/labels/component%3Acore%3Ascriptengine)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1727)
<!-- Reviewable:end -->
",7551429
661,"Bard, dance effect time bug",open,2017-04-25T14:00:35Z,2017-06-03T21:14:29Z,,NONE,"1. Login 2 bard, clown to buff
2. 1st bard Use skill The Apple of Idun
3. 2nd bard use another skill like Assassin Cross of Sunset or something
4. 1st bard use Adaptation to Circumstances first
5. 2nd bard use Adaptation to Circumstances then.
6. U will get bug of The Apple of Idun for 3 mins.

https://youtu.be/mPGpWNeo944

I just tried to use lastest Hercules.",,7551429
662,Creature Academy. kRO updated maps?,open,2017-04-23T16:02:39Z,2017-05-01T01:35:57Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [ X ] I have not modified the source prior to reproducing this issue.
-  [ X ] I am using the latest version of Hercules.
-  [ X ] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

I have problems to complete Creature Academy novice tutorial, I follow this tutorial to accomplish them. [Guide](https://forums.warpportal.com/index.php?/topic/144833-r-new-izlude-tutorial-guide/)
I use this client: Full kRO 2017-4-11 + ClientSide Translation Project + 2014-02-05bRagexe Patched
I dont know if the guide is outdated or not implemented in the project.
I would like to be able to collaborate with this task and the project since I would like to return to development after 10 years of inactivity

### Current Behavior

* ~~Missing NPC for complete tutorial? I not find any info in script folder from Late Student and Prof. Oldman~~ @Jedzkie Only avaliable on iRO
* Blocked map iz_ac01. I cant move well.
Client map
![captura de pantalla 2017-04-23 a las 16 55 57](https://cloud.githubusercontent.com/assets/4316088/25314859/c7d6d0ac-284b-11e7-8df6-cfd205d2f95f.png)

Older map?
http://www.atlantis-ro.com/foro/uploads/monthly_2016_05/Criatura1.png.c5fad3e076a32a9edabbcc434dad200f.png

I tried to generate new mapcache with the actual map, same result as project mapcache. If i load older map i can move very well. kRO introduces a rework of map?
* Left and right warps to go upper floor go to stucked map (iz_ac02).
![captura de pantalla 2017-04-23 a las 17 48 30](https://cloud.githubusercontent.com/assets/4316088/25315064/4383bf00-284f-11e7-881f-6097024542ad.png)


### Expected Behavior

[//]: # (Tell us what should happen instead.)
Be able to complete the novice tutorial without problems.

### Steps To Reproduce The Issue

Try to follow the tutorial and accomplish them.

**Branch(es):**
- [ X ] master

**Hercules rev. hash/commit:** 

Git revision src:

[Info]: Hercules 64-bit for Mac OS X
[Info]: Git revision (src): '116d69f454a04453c26f9c3d0f2bb1231de03173'
[Info]: Git revision (scripts): '116d69f454a04453c26f9c3d0f2bb1231de03173'

### Operating System

[Info]: OS version: 'Mac OS X 10.11.2 15C50 [x86_64]'
[Info]: CPU: 'Intel Core i7 (3,50 GHz) [4]'
","Thanks for the info, now i try to search info about novice tutorial based on kRo

Issue updated",7551429
663,"deprecate UNITTYPE_ constants, switch to hardcoded BL_ constants",open,2017-04-12T17:18:43Z,2019-03-23T02:06:25Z,,MEMBER,"For the sake of simplicity I believe we should deprecate the `UNITTYPE_` constants so we only have the `BL_` constants.
* The `BL_` constants have the same values as in the `bl_type` enum
* The `BL_` constants can be bitmasked, enabling to pass more than one type to a command
* The `BL_` constants are hardcoded in script.c so if the enum ever changes they will still be up-to-date","> we'd just bump the script engine version whenever we make breaking changes and in the script documentation we could put use version >=X to use feature Y

that sounds like a bad idea to me ... we should always make scripts backward compatible ...
using a version > X, we don't have a clear definition when to increase the version anyway

this actually reminds me long ago I talked with Haru,
that we should have a server revision date in constant, just like PACKETVER
what I proposed was, have the hercules bot automatically `#define SERVER_DATE 20190323` in mmo.h
but Haru dislike the idea having the hercules bot to spam the [commits](https://github.com/HerculesWS/Hercules/commits/)
so this never happens

better be like
```c
#if SERVER_DATE >= 20190323

ra_in01,384,246,3	script	Vincent#ra_in01	1_M_01,{
	if (BaseLevel < 60) {
		mes ""[Vincent]"";
		mes ""You're inside Sir Zhed's"";
		mes ""looking for new employees,"";
...
```",7551429
664,[DIS] array syntactic sugar,open,2017-04-08T15:46:21Z,2017-05-17T20:02:56Z,,MEMBER,"I wanna hear your thoughts before I start implementing some script shorthands so we can all agree on the syntax first.

- - - 

### array shorthand methods
* `.@var = {1, 2, 3, 4, 5};`
    * shorthand for `setarray(.@var[0], 1, 2, 3, 4, 5);`

<br>

* `.@var += {1, 2, 3, 4, 5};`
    * shorthand for `setarray(.@var[getarraysize(.@var)], 1, 2, 3, 4, 5);`

<br>

* `.@var = {1 .. 5};`
    * two dots syntax: run from the beginning to the end inclusively
    * shorthand for `setarray(.@var[0], 1, 2, 3, 4, 5);`

<br>

* `.@var = {1 ... 5};`
    * three dots syntax: run from the beginning to the end exclusively
    * shorthand for `setarray(.@var[0], 1, 2, 3, 4);`

<br>

### math shorthand methods
* `5 ** 2`
    * shorthand for `pow(5, 2)`
    * **UPDATE:** implemented in #1739  

- - - 

<details>
<summary>old proposal (<b>click here</b>)</summary>

### array shorthand methods
* `.@var = 1, 2, 3, 4, 5;`
    * shorthand for `setarray .@var[0], 1, 2, 3, 4, 5;`


* `.@var = 1...5;`
    * shorthand for `setarray .@var[0], 1, 2, 3, 4, 5;`


* `.@var = ...#var2;`
    * passes every element of `#var2` as an argument to the array shorthand method
    * shorthand for `copyarray(.@var[0], #var[0], getarraysize(#var[0]));`


* `some_buildin(...array);`
    * passes every element of `array` as arguments to `some_buildin`

### destructuring
* `.@a, .@b, .@c = .@d, .@e, .@f;`
    * shorthand for `.@a = .@d; .@b = .@e; .@c = .@f;`


* `.@a, .@b, .@c = ....@d;`
    * shorthand for `.@a = .@d[0]; .@b = .@d[1]; .@c = .@d[2];`

### math shorthand methods
* `5 ** 2`
    * shorthand for `pow(5, 2)`

</details>","if you want something simple then yeah python makes sense, or even javascript (if we add nodejs bindings)",7551429
665,Item Effect - bDoubleRate occurances rate,open,2017-04-01T21:04:14Z,2017-06-13T10:55:04Z,,MEMBER,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)

### Current Behavior
The existing skill level doesn't improve the double attack occurances rate.

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)

### Expected Behavior
The skill level of ""Double Attack"" should affect the rate of Double Attack that provided by the card bonus.
http://www.divine-pride.net/database/item/4117
http://www.divine-pride.net/database/item/19129
The item description of this 2 items showing that the rate should be affected by the existing skill level.

[//]: # (Tell us what should happen instead.)

### Steps To Reproduce The Issue

1. Use an Assassin Class for example.
2. Up Double Attack skill level to max.
3. Compound the sidewinder card into any Katar
2. Attack monster using the Katar that compounded with Sidewinder card

**Branch(es):**
- [x] master
- [x] other

**Hercules rev. hash/commit:** 

Git revision src: https://github.com/HerculesWS/Hercules/commit/5f3d37c89c60ecc89186fa8d6cba333369a8f4cf

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )
","I am not exactly sure with the rate calculation, but I do believe its higher than current implementation. Probably `( 5% * Skill Level )` no penalty? not sure about this ..  

Best I think we should get a some equipment to test in kRO. ",7551429
666,Bound items comparison,open,2017-03-31T11:55:58Z,2017-04-13T11:26:32Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description
First i know this has been discussed in #822 and it was rejected as its a bug, however the current system that we have actually makes a real bug with the `alt+right click` item move shourtcut, what i mean is in aegis when you try to put a bound item in the storage/trade/cart... you'll get the item again and the item would be moved to the end of your inventory list, in Hercules when using `alt+right click` on a bound item you'll get the message that said ""'This item cannot be dropped/stored/..."" and after that you cant use the shortcut again even on normal items unless you moved 1 item manually and then you can use it again here are 2 videos that shows how it works on both aegis (kRO Sakray) and Hercules.

- kRO : https://drive.google.com/file/d/0B8s-sa51NSkgclhGalV5S3BFUXM/view
- Hercules : https://drive.google.com/file/d/0B8s-sa51NSkgSGJjRElSc1lSd3M/view

I hope if we could at least get a config that allows aegis behaviour.

**Branch(es):**
- [x] master

**Hercules rev. hash/commit:** 

Git revision src: 5f3d37c89c60ecc89186fa8d6cba333369a8f4cf

Client Version: 2017-03-15cRagexeRE

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[//]: # ( [Info]: Hercules 64-bit for Mac OS X )
[//]: # ( [Info]: Git revision src: 'a5918b329ca0826b04dca32ede783586403f58db' )
[//]: # ( [Info]: Git revision scripts: 'a5918b329ca0826b04dca32ede783586403f58db' )

### Operating System

Debian 8.0 (Jessie)

","@Smokexyz this is the official behavior, the item goes to the end of the inventory list.",7551429
667,Add cell_pvp or cell_pk,open,2017-03-27T00:43:56Z,2019-04-13T15:02:36Z,,NONE,"Hello, I have been checking the script cell commands that are used in conjunction with setcell and realized that we just do not have: cell_pvp or cell_pk. I've been thinking and I do not understand the reason for this since we have all the others we need. So why not add it to the emulator?

Diff Example:
```
 db/const.txt     | 1 +
 src/map/battle.c | 5 +++++
 src/map/map.c    | 3 +++
 src/map/map.h    | 5 ++++-
 4 files changed, 13 insertions(+), 1 deletion(-)

diff --git a/db/const.txt b/db/const.txt
index 778ed35..6417bae 100644
--- a/db/const.txt
+++ b/db/const.txt
@@ -391,6 +391,7 @@ cell_novending	6
 cell_nochat	7
 cell_maelstrom	8
 cell_icewall	9
+cell_pk	10
 
 //cell_gettype	0
 cell_chkwall	1
diff --git a/src/map/battle.c b/src/map/battle.c
index 76f7fc1..246d19c 100644
--- a/src/map/battle.c
+++ b/src/map/battle.c
@@ -6828,6 +6828,8 @@ int battle_check_target( struct block_list *src, struct block_list *target,int f
 						return (BCT_ENEMY&flag)?1:-1; // Duel targets can ONLY be your enemy, nothing else.
 					else if (src->type != BL_SKILL || (flag&BCT_ALL) != BCT_ALL)
 						return 0;
+				} else if( map->getcell( s_bl->m, src, s_bl->x, s_bl->y, CELL_CHKPK ) && map->getcell( t_bl->m, src, t_bl->x, t_bl->y, CELL_CHKPK ) ) {
+					 state |= BCT_ENEMY;
 				}
 			}
 			if (map_flag_gvg(m) && !sd->status.guild_id && t_bl->type == BL_MOB && BL_UCCAST(BL_MOB, t_bl)->class_ == MOBID_EMPELIUM)
diff --git a/src/map/map.c b/src/map/map.c
index 6bd8b2b..1586436 100644
--- a/src/map/map.c
+++ b/src/map/map.c
@@ -2678,6 +2678,8 @@ int map_getcellp(struct map_data* m,int16 x,int16 y,cell_chk cellchk)
 			return (cell.maelstrom);
 		case CELL_CHKICEWALL:
 			return (cell.icewall);
+		case CELL_CHKPK:
+			return (cell.pk);
 
 		// special checks
 		case CELL_CHKPASS:
@@ -2732,6 +2734,7 @@ void map_setcell(int16 m, int16 x, int16 y, cell_t cell, bool flag)
 		case CELL_NOCHAT:        map[m].cell[j].nochat = flag;        break;
 		case CELL_MAELSTROM:	 map[m].cell[j].maelstrom = flag;	  break;
 		case CELL_ICEWALL:		 map[m].cell[j].icewall = flag;		  break;
+		case CELL_PK:		 	 map[m].cell[j].pk = flag;			  break;
 		default:
 			ShowWarning(""map_setcell: invalid cell type '%d'\n"", (int)cell);
 			break;
diff --git a/src/map/map.h b/src/map/map.h
index 3e44813..f084213 100644
--- a/src/map/map.h
+++ b/src/map/map.h
@@ -460,6 +460,7 @@ typedef enum {
 	CELL_NOCHAT,
 	CELL_MAELSTROM,
 	CELL_ICEWALL,
+	CELL_PK,
 
 } cell_t;
 
@@ -484,6 +485,7 @@ typedef enum {
 	CELL_CHKNOCHAT,
 	CELL_CHKMAELSTROM,
 	CELL_CHKICEWALL,
+	CELL_CHKPK,
 
 } cell_chk;
 
@@ -503,7 +505,8 @@ struct mapcell
 		novending : 1,
 		nochat : 1,
 		maelstrom : 1,
-		icewall : 1;
+		icewall : 1,
+		pk : 1;
 
 #ifdef CELL_NOSTACK
 	unsigned char cell_bl; //Holds amount of bls in this cell.
```","I said the same thing before -> https://rathena.org/board/topic/73850-pvp-only-on-certain-cell/
until someone show me this video -> https://rathena.org/board/topic/89732-is-possible-pvp-specific-area/
totally custom, should be a plugin release ...",7551429
668,Zone Mapflags,open,2017-03-21T08:21:33Z,2017-04-02T22:36:15Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Maps related to a same kind of zone shares same type of mapflags. This pr moves the mapflags seted individually on npc\mapflag folder to set through zone mapflag.

This includes some fixes to maps missing mapflags, such as all maps of 3rd job change quest misses noteleport mapflag allowing to bypass in most cases the test to change, also fixes gvg zone to woe fe castles, and some other minnor fixes.

The main goal for all this changes is to make easier the implementation of new maps an avoid chances of error at setting mapflags.

All the changes are detailed on every commit message. This still can be improved by adding zones ""Special Quest Places"" and ""Interiors"".

**Affected Branches:** `master` 

[//]: # (Master? Slave?)

**Issues addressed:** `Suggestion`

[//]: # (Issue Tracker Number if any.)

### Known Issues and TODO List

- Make non pvp/gvg zones inherit 'Normal' zone, to disable skills disabled on normal maps to non pvp/gvg zones (such as instances).
- Compare mapflags combinations with aegis source.
- Discuss about new possible zones of mapflags (like 'Interiors', 'Special Quest Places' or others needed).

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1645)
<!-- Reviewable:end -->
","@iRagno I found the root of the unexpected behaviors.

The `GvG` and `PvP` zones is special, and so are the `gvg` and `pvp` mapflags.
When you set the `gvg` or `pvp` mapflag to a map, it'll automatically apply the `GvG` or `PvP` zone to that map, merging it with the current zone.

This means that you should never include `mapflags: (""gvg"")` in a zone (and especially not in the `GvG` zone, since it'll cause some nasty recursion and all sorts of unexpected flags). The same applies to `mapflags: (""pvp"")`.",7551429
669,Gentle Touch Change doesnt add damage correctly,open,2017-03-13T10:26:21Z,2017-03-17T01:25:16Z,,NONE,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

[//]: # (Description of the problem or issue at length.)
[//]: # (Please specify any battle configuration related to the components of this issue that have been changed from the default values. This will allow quicker determination of the cause of the problem.)
I've only modified the source to make gentle touch change viewable from the status window.
### Current Behavior

[//]: # (Describe at length what you noticed during your analysis.)
[//]: # (If this is a crash, post the core/stack-dump or crash-log to https://gist.github.com/)
[//]: # (If you are referencing from sources such as iROwiki or ratemyserver.net, please quote specific information rather than providing the links alone.)
Gentle touch change should add their respected stats right away but it will only add after you've casted asura strike on a target.

### Expected Behavior

[//]: # (Tell us what should happen instead.)
Right after you've casted gentle touch change, stats should already be applied.

### Steps To Reproduce The Issue
This is without editing the viewable src to see the difference.
1. Spawn a Monster/Barricade
2. Use Asura strike and record your damage.
3. Use Finger Offensive and record your damage.
4. Cast gentle touch change
5. Use Asura strike and record your damage.
6. Use Finger Offensive and record your damage.
7. Repeat 5 and 6.

Also Reproduceable by having gentle touch change buffed and relogging.

### Screenshots (Viewable edited)
Without Gentle Touch Change
![a](https://cloud.githubusercontent.com/assets/9050808/23850381/1afe2ee4-081a-11e7-9390-c310bf158f4b.jpg)
With Just Buffed Gentle Touch Change after using Asura strike
![b](https://cloud.githubusercontent.com/assets/9050808/23850382/1b04f364-081a-11e7-8fdc-6872dcc0fef2.jpg)
With Gentle Touch Change right after giving gentle touch's change attack buff from 2nd Asura Strike
![c](https://cloud.githubusercontent.com/assets/9050808/23850383/1b0711f8-081a-11e7-9570-3fd42d2db7dc.jpg)



**Branch(es):**
- [x] master
- [ ] other

**Hercules rev. hash/commit:** 

Git revision src:

[//]: # (Copy the first 3 lines of the login-server, char-server or map-server startup.)
[Info]: Hercules 32-bit for Windows
[Info]: Git revision (src): '7b4d4fb92603ef1e622b52e777cd5ac1b7f97d55'
[Info]: Git revision (scripts): '7b4d4fb92603ef1e622b52e777cd5ac1b7f97d55'

### Operating System

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
","This buff needs SCB_WATK declaration in the initChangeTables block, it's currently missing.

`status->set_sc( SR_GENTLETOUCH_CHANGE    , SC_GENTLETOUCH_CHANGE          , SI_GENTLETOUCH_CHANGE    , SCB_ASPD|SCB_MDEF|SCB_MAXHP );`",7551429
670,Usage of bonus2 bSubRace on renewal db,open,2017-03-11T09:10:49Z,2017-03-11T20:45:05Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Issue Prelude

[//]: # (Please complete these mandatory steps and check the following boxes by putting an `x` inside the brackets _before_ filing your issue)

-  [x] I have not modified the source prior to reproducing this issue.
-  [x] I am using the latest version of Hercules.
-  [x] I am aware that this report will be closed or deleted if it becomes obvious that I am stating the false.

### Description

DB renewal (item_db.conf and item_combo_db) are still using pre-renewal `bonus2 bSubRace` bonus script instead of `bonus2 bAddRaceTolerance` intended for renewal.

### Current Behavior

Having bonus2 bSubRace causes a weird behaviour when reducing damage, it doesn't reduce all the damage that should do.

### Expected Behavior

Have a proper reduction damage acording to race resistance.

**Branch(es):**
- [x] master

**Hercules rev. hash/commit:** 

Git revision src: 9fba7e8c5966bb0aa5ce1c31ebe5cec96180e1d5

```
[Info]: Hercules 32-bit for Windows
[Info]: Exported revision (src): 'Unknown'
[Info]: Exported revision (scripts): 'Unknown'
```

### Operating System

- [Info]: OS version: 'Windows 7 Home Premium Service Pack 1 (build 7601) [x86_64]'

[//]: # (Mac OS X 10.12.3 16D32 [x86_64])
[//]: # (Thank you for adhering to this process! It ensures your issue is resolved quickly and that neither your nor our time is needlessly wasted.)
[//]: # (This template is for problem reports. For other types of report, edit it accordingly.)
[//]: # (For fixes please create a Pull Request.)
","I'm almost sure this is a bug, but has been for so many time that I need to ask if there is a chance of that may be intended behaviour.",7551429
671,Skill Picky Peck Summoner,open,2017-03-09T04:05:56Z,2017-03-09T04:05:56Z,,NONE,"The skill Picky Peck don't do anything, i checked skill_db.conf and battle.c and no look any anormal thing.
just, on the skill_db.conf the number of hits was setted to -5, i changed this to 5 but the skill still with error.",,7551429
672,Guild Configs & Script Commands,open,2017-03-08T01:02:57Z,2017-09-03T15:18:04Z,,NONE,"Hello.

I wonder why we do not have it yet?
https://rathena.org/board/topic/97728-guild-configs-script-commands/
https://github.com/rathena/rathena/pull/95/commits/4832808787aa4be7f4347abaf6df88d08537bb32

I know we already have getguildmember, and some listed in the above pull would be useless, but we can still take advantage of many things like this:

- [ ] 'Emblem_woe_change'
- [ ] 'Disable_invite'
- [ ] 'Disable_expel'
**Script Command Updates**
- [ ] 'Guild_info'
- [ ] 'Guild_create'
- [ ] 'Guild_delmember'
- [ ] 'Guild_addmember'

I know AnnieRuru is no longer with us, but he approves of that and it was from the Hercules team.
Http://herc.ws/board/topic/7033-add-getguildmember-script-command/

Please, look carefully. ",,7551429
673,"Add db file job_noenter_map.txt with format: JobID,FlagZone,GroupLevelBypass.",open,2017-03-03T23:40:53Z,2017-03-06T06:52:21Z,,NONE,https://github.com/rathena/rathena/pull/1526/commits/91799eb2b1e9187d083eda4360cf2b95991cab97,"Now I understand what both said. You are thinking of adding a new constraint to map_zone_db. I had understood that map_zone_db already had this function, when in fact it does not yet exist. Excuse me, gentlemen.",7551429
674,some bugs skills.,open,2017-03-01T04:03:08Z,2018-03-05T12:21:25Z,,NONE,"Skill kunai splash take the element of weapon and no the element of kunai.

Skill Intense Telekinesis dont give triple dmg with ghost element skills, i tested this and  2.2k of dmg up just to 3.6k and no to 6.6k.

dragon breath dont take racial modifiers, bonus long rang atk and element bonus http://irowiki.org/wiki/Dragon_Breath","just a lil bump for a intense telekinesis fix, it's been a year alreasy...",7551429
675,Pre-Renewal instances cooldown mode,open,2017-02-27T08:05:07Z,2017-03-21T14:19:36Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

Fixes entrance exploits and changes behavior of instances cooldown with these values:
0 - Classic behaviour with exploit entrance (not recommended)
1 - Classic behaviour without exploit entrance (default)
2 - Updated behaviour to disable re-entrance on same instance


**Affected Branches:** `master`

**Issues addressed:**
- #732 Endless Tower CD only applies to party leader
- #1582 Pre-Re instances cooldown check
- #1320 Endless Tower Fix (Pull Request)

### Known Issues and TODO List

- None

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1594)
<!-- Reviewable:end -->
","@Ridley8819 it's true that a more centralized place to handle this would be better, to avoid having to edit several scripts and end up forgetting some, but this feels like a misuse of a battle configuration flag. The alternatives aren't really appealing though (using a global server variable like many scripts do is even more wrong), so we might as well go with the battle configuration flag.

The other viable option would be to use an approach similar to how `F_GM_NPC()` works. Up to you which approach to take, whichever feels more convenient.",7551429
676,support types for openshop(),open,2017-02-26T15:47:15Z,2017-02-26T15:47:15Z,,CONTRIBUTOR,"I suggest supporting types for openshop() function same as callshop()
	`
	0 = The normal window (buy, sell and cancel)
	1 = The buy window
	2 = The sell window
	`
so it could be used with trader npc's.",,7551429
677,Pre-Re instances cooldown check,open,2017-02-20T17:17:46Z,2017-03-14T03:00:48Z,,CONTRIBUTOR,"#Ok so I had a longer discussion with @iRagno regarding instances, and the way we do check for CD in athena, how its done on iRO, and how its done on kRO. So we thought to have a new battleflag in features.conf to offer the following behaviour for instances.

--> athena behaviour = check CD on party leader, allow leader switch (bug?) 
--> iro behaviour = CD quest got applied to every party member, but it doesn't get checked until the instance is completed/destroyed. This allows party member who disconnect, for whatever reason, to rejoin.
--> kro behaviour (will not be implemented immediately since we're missing dialogues for it) = instant apply CD on all party member, no reenter possible

This would fix the leader switch bug for all pre re instances, as well as allowing disconnecting party member to reenter in time.
Why a setting and not simply fix it? Well, this bug is in athena since forever, it was also a long time available in aegis. I think a setting is good, because there are a lot people who want to do ""classic"" servers with that old behaviour, or server owners simply don't want that fix since players are used to it (best example is ET).
When talking with @iRagno, he was excited to take this task.","Added pull request with fix to entrance exploit in Endless Tower, Nydhogur Nest and Orcs Memorial instance dungeons.

Sealed Shrine has disabled reentering instance once was created and needs more investigation if that should be default behaviour. I assume it could be fixed with this, but messages are kind of weird, needs to confirm behaviour with officials.",7551429
678,NPC_METAMORPHOSIS (mob_class_change) with immobile and fixed spawns.,open,2017-02-19T16:41:07Z,2017-03-06T03:47:00Z,,NONE,"This is a rather old issue, this is what happens:

1. Immobile monster with fixed spawn coordinates (Ant Egg is the most iconic example) transforms into a mobile monster.

2. That monster moves somewhere else and gets killed.

3. The original immobile monster respawns at its coordinates.

4. Now just hit that monster and see it glide to the spot where the monster it transformed into had died.

There's no actual movement involved, just a client visual glitch, refreshing, hiding and unhiding or teleporting/changing maps will bring the monster to its original spot, until hit again.",Respawn timer doesn't seem to affect anything.,7551429
679, Implement New skill GD,open,2017-02-11T01:27:13Z,2017-05-20T22:38:49Z,,NONE,"Currently the official form does not work, there is a skill to this.
 
GD_ITEMEMERGENCYCALL
 
http://ratemyserver....b&item_id=12968
http://ratemyserver....b&item_id=12969
http://ratemyserver....b&item_id=12970
topic open in Jul 17 2013: http://herc.ws/board/topic/1584-implement-new-skill-gd/",https://github.com/rathena/rathena/commit/1f85dab,7551429
680,Certain Skills now Apply Critical Attacks,open,2017-01-23T19:31:31Z,2018-01-15T18:01:51Z,,CONTRIBUTOR,"kRO released a patch / maintenance back in December with a new update to certain skills that will apply the crit affect:

> Certain successive blows that are activated as passive will be changed to Critical when activated. → Skill List: Double Attack, Chain Action, Shadow Warrior, Crossbow, Peer Breeze

Rough translation of skills. 

**kRO Post Information -**
- https://www.midgard-community.com/forums/topic/1429-kro-december-7th-2016-maintenance/
- Videos of Crits being applied through Double Attack in topic","It's a new value to `battle_dmg_type` with value 13, for Multi-Hit Critical",7551429
681,Removing invisible state with @option on hidden GM,open,2017-01-22T21:02:15Z,2017-09-03T15:53:04Z,,CONTRIBUTOR,"This is a minnor issue. In maps with pvp activated, when setting `@option 0` on GM with /hide state and then update it's location, will crash to every player that enters on is area of vision.

How to reproduce it:

1. Use `@pvpon` on a map
2. Use `/hide` command
3. Use `@option 0` command
4. Use `@jump` or a _warp portal_ to reenter the map
5. Every player who walks nearby the gm, will have a client crash

Tested on 2015-05-13aRagexe.","in hercules invisible gms is not really invisible. most packets from gms visible for all players. But normal clients ignoring it. Exists pr for fix this, but it may break other ""invisible"" things not related to gms.

Probably here client issue because it see partial visible gms and crashing.
",7551429
682,Huld doesn't support \r in mes command,open,2017-01-22T00:32:04Z,2019-02-22T20:16:35Z,,CONTRIBUTOR,"Huld doesn't support \r in mes command (tested on 68947c86d5fe3eb2686c9b3393e3db0df083bb11  and 9795505a14327d5d2603a1d756633485e7e2ba94).
 
Example:
 
Script:

```
mes(""It seems those limbs belong to that ugly octopus. That monster should be taken care of,\r""
	""but it's hard for ourselves only to make it happen, hehe."");
```

Generated translation:

```
#: npc/re/instances/octopus_cave.txt
# mes(""It seems those limbs belong to that ugly octopus. That monster should be taken care of,\r""
msgctxt ""Starfish""
msgid ""It seems those limbs belong to that ugly octopus. That monster should be taken care of,\rbut it's hard for ourselves only to make it happen, hehe.""
msgstr ""Parece que esas extremidades pertenecen a ese horrible pulpo. Alguien debería encargarse de ese monstruo,\rpero el hacerlo es muy difícil para nosotros solos, hehe.""
```
Even when there is a translation, huld always shows English text.
","I know about `_(""string"")`

actually I wish there is another function `_!(""string"")` to NOT get pick up from HULD",7551429
683,Horror Toy Factory Instance implementation based on official conversion.,open,2017-01-02T07:25:02Z,2020-03-10T11:01:30Z,,CONTRIBUTOR,"[//]: # (**********************************)
[//]: # (** Fill in the following fields **)
[//]: # (**********************************)

[//]: # (Note: Lines beginning with syntax such as this one, are comments and will not be visible in your report!)

### Pull Request Prelude

[//]: # (Thank you for working on improving Hercules!)

[//]: # (Please complete these steps and check the following boxes by putting an `x` inside the brackets _before_ filing your Pull Request.)

- [x] I have followed [proper Hercules code styling][code].
- [x] I have read and understood the [contribution guidelines][cont] before making this PR.
- [x] I am aware that this PR will be closed if the above-mentioned criteria are not fulfilled.

### Changes Proposed

This is a conversion from the script provided by _esu1214_ from Hercules' Boards in a collaboration with @Ridley8819 and @AtlantisRO, with the translation from Traditional Chinese language by Steph.

**Affected Branches:** `master`

**Issues addressed:** #240 Episode 14.2 : Eclage (Part of TODO list of updates)

### Known Issues and TODO List

- Requires to update npctalk script command to not show npc name by default (Pull Request #1571).
- Requires implementation of unit controlling script commands (Pull Request #1584).
- Requires skills 716 and 719 for Spectrum Celine and Hidden Mob monsters.

[//]: # (**NOTE** Enable the setting ""[√] Allow edits from maintainers."" when creating your pull request if you have not already enabled it.)

[cont]: https://github.com/HerculesWS/Hercules/blob/master/CONTRIBUTING.md
[code]: https://github.com/HerculesWS/Hercules/wiki/Coding-Style

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1539)
<!-- Reviewable:end -->
","I have solved the conflicts. Conflict was originated on f75bfaedaa2d72a195d2b0c39b717ead1ea289ba, when was moved all mapflags for instances to zone db, making it easier to bring mapflags to new instances. As result, files changed was reduced from 17 to only 9.

About the merge, this instance is completely playable even without the unit controlling script commands in #1584, but this instance is easier without it. Same for #1571, this is playable, but `#fac1bs` npc will add npc name in npctalks, showing it ugly.

The script is prepared to use those pr, I'm with @Asheraf, it would be better to have those pr applied before merging this into master.",7551429
684,"Asura damage should not be affected by Provoke, Curse and INCATKRATE",open,2016-12-22T04:01:24Z,2017-01-20T19:10:31Z,,NONE,"Provoke, Curse and INCATKRATE (e.g. from Gospel or Tarot Card) do change the Asura damage at all.
BATKFOOD and ATKPOTION however do increase Asura damage.

This would indicate that Provoke, Curse and INCATKRATE should not actually be part of the base attack calculation but instead add / substract damage in the damage calculation.

This applies to both pre-re and re.

Credits to @Playtester","I assumed it would just use SP_ADDRACE's implementation or something similar, which would explain it not affecting spiral pierce and shield boomerang, but asura also? Someone with access to aegis files should check it up.",7551429
685,Monster walking mode,open,2016-12-09T03:01:26Z,2019-05-21T16:12:23Z,,MEMBER,"Let's said you implemented a custom script to force a mob to walk to specific cell.
```
OnInit:
.@gid = monster( ""this"",155,170,""--ja--"",1002,1"" );
while ( true ) {
	unitwalk .@gid,155,175;
	sleep 2000;
	unitwalk .@gid,155,170;
	sleep 2000;
}
```
When the monster walking (trigger by unitwalk), during the time the monster walking to the said cell.... the destination get overwritten by the monster's original walk mode destination. The monster trying to walk to another cell that trigger by the random walk I guess... and due to the script above keep looping to force the monster to walk to specific cell, it create a result that make the monster walk to the said cells unwillingly, it's like the monster trying to escape from where they should walk to. LOL
","my bad, it was actually a different branch... currently Herc don't have these field.
https://github.com/HerculesWS/Hercules/pull/2031 will probably fix the issue.",7551429
686,Monster Mode - Random Walk,open,2016-12-09T02:55:16Z,2019-05-21T16:12:10Z,,MEMBER,"I think this mode is missing or not implemented.
Or does it changed to other?

I think there is a mode that doesn't allow monster to random walk around when idle.
or doesn't random walk around when there are no players around them.
","my bad, it was actually a different branch... currently Herc don't have these field.
https://github.com/HerculesWS/Hercules/pull/2031 will probably fix the issue.",7551429
687,Feature.conf,open,2016-11-18T05:59:20Z,2016-11-18T06:11:38Z,,NONE,"It seems that conf/import/battle.conf is not working for feature.conf
i'm using the latest git version","It should be working, however I see conflicting file names of import on conf/battle.conf:

```
    // Your custom config goes here.
    @include ""conf/import/battle.conf""
}

import: ""conf/import/battle.conf
```

@MishimaHaruna
",7551429
688,No WSACleanup when closing a socket on Windows,open,2016-11-14T02:54:18Z,2017-02-08T21:44:17Z,,MEMBER,"I noticed there is no WSACleanup. Is it intended, not necessary?

References:
* http://i.imgur.com/P784Uu2.png
* http://i.imgur.com/YXpkk79.png","WSACleanup must not called after closing socket.
If some one want to use it, it must be called only on server termination.
",7551429
689,Monster Wall Jumping,open,2016-11-07T21:33:56Z,2016-11-08T01:50:01Z,,CONTRIBUTOR,"Herc is updated to Commits on Oct 22, 2016, just prior to the summoner commits.
Client date is: 20150513
The bug was first noticed in a previous version of herc in August. But I believe there is some position lag going on that gives the monsters the appearance of teleporting through walls. This is most evident on maps like sphinx or lhz where there are walls as shown in this video. If you go around a wall and leave range, you most likely wouldn't even see this, but on maps such as this, you get to see monsters behave pretty weirdly. I have tried modifying the ai settings and editing everything in the conf but the result is always the same.

Video showing what is happening: https://www.youtube.com/watch?v=GImSNx3_xD4&feature=youtu.be
Original bug report: http://board.playelaria.com/index.php?/topic/780-monster-jumping-over-obstacles/

While investigating something else, I ran into something that may give more insight. When using a bow and arrow and attacking around obstacles, the player position doesn't always get updated. The character appears to be in the same position, however they have moved, only after using @refresh do you get to see the player's true position.
Video: https://www.youtube.com/watch?v=sphhcgV3gRQ&feature=youtu.be",,7551429
690,"SONG EXPLOIT (Poem Of Bargi, Apple and etc )",open,2016-10-31T11:54:18Z,2017-05-10T14:37:35Z,,NONE,"Hi there,

Player should only have 30 second buff from song if he/she setop out from the field. But by using this way they can have effect lasting for 3 minutes.

How to reproduce.

1. Must have 2 clown (for clown skill)  or 2 Dancer (for dancer skill)
2. Target for buff.

before clown or dancer play song target or person who want 3 mins buff need near the clown or dancer before they cast the skill. (Must in field before song casted). And then 1st clown cast Poem Bargi Skill, And then Another clwon cast Magic String Skill. Then player inside that field will get EXTRA HP and if he get out from skill filed he will get 3 mins effect, altough it should be 30 second only.

This is serious bug and can be applied to all song skill. 

Hope this can be fixed.

Thanks @MishimaHaruna @hemagx @dastgir ","i belive this bug also lead to this:

 status_change_end: SC_DANCING is missing skill unit group (val1=655690, val2=1211309, val3=0, val4=0, timer=-1, tid=1235, char_id=9900, map=louyang, x=215, y=93, prev=<none>:0, from=status.c:11895). Please report this! (#3504)
",7551429
691,Waking delay when attacked,open,2016-10-26T08:47:16Z,2016-10-26T09:04:01Z,,NONE,"I have confirmed that monsters cannot be attacked to stop walking in rAthena, but it is very different in Aegis.
Monsters even Mvps can be attacked to stop walking by high ASPD attcker in Aegis. I have just tested it in my Aegis test server.

I can confirmed that it is related by attcker's amotion, monster's dmotion, monster's speed and the most important is the distance between the attacker and the monster.
For example, a Ranger with 190 ASPD or more can hit BAPHOMET to stop walking by normal attack, but the condition is that the distance between them should be the longest range of a bow.

Players in Aegis Server hitlock a Mvp through their mouse-skill, but in emulation, they can never do that.

All emulaters based on Athena has this bug.
","I Confirm on renewal at least (it's usually strategy to kill mvps)
",7551429
692,Warg Dash distance required from target,open,2016-10-08T02:10:28Z,2017-04-23T12:08:33Z,,CONTRIBUTOR,"Players can use Warg Dash standing right next to the target making them capable to spam lots of damage.

On iRO, when you use Warg Dash right next to the target (example, Ranger is on cell 320, 245 and target is on cell 321, 245), the Warg Dash executes, it consumes sp, but there is no damage generated. You can stand right next to some plant and use Warg Dash until sp is all consumed, but the plant will not receive any damage. Damaged is calculated when there is at least 1 free cell between ranger and target.

Tested on iRO Chaos: 10/07/2016
Tested on Hercules Rev. Version: a2329f4f10a3ab2e70141766a16981e69e2a71ba
","This is already solved on rAthena:

https://github.com/rathena/rathena/commit/09e91d4cd4508e81666f49daa787b8a8644211b8

Would be of help to solve this?",7551429
693,Adopt menu issue,open,2016-09-24T05:53:41Z,2016-10-08T00:47:07Z,,NONE,"Original Topic by Napster: http://herc.ws/board/tracker/issue-8363-adopt-menu-issue/?gopid=23756#entry23756

client date 2014-03-05
when join party (father , mother, baby)
father , mother = base level > 70
baby = base level 1, job novice
item ring = yes , both and equip
when father click right over baby  not show menu adoption

can confirm this, thank you
","At first i thought it's only for the 20140305 client and only for the father, but this is actually missing for both parents and not only in this client. It seems it is missing since ~201308 until now. 
Will investigate this further
the command sounds nice, regardless if this is fixable or not *likes new commands
",7551429
694,Herc no longer support Old Client (sakray) ?,open,2016-09-18T03:51:30Z,2016-10-06T16:44:57Z,,NONE,"Hi,

i have been try all of 'old client' here http://herc.ws/board/topic/11730-r-clients-2006-and-2007/
and Herc happens like rAthena, broken packet, and the other problem.
(example case: when you drop item, then take it, there is no notification 'item obtained' -2007-05-21)
(no relogin effect, player change their job and gender _visual only_ - 2005 client)

Thus, about 6 months ago, i tried in Herc, all old client working as well.
","i know you could run 2005 and 06 sakray client but it was never really recommended. I can't tell when this was removed (if it ever was, i just know it worked last time i tested it). 
",7551429
695, Unknown Item Issue,open,2016-07-12T10:26:43Z,2017-04-05T18:19:21Z,,NONE,"hi guys! i'm using 2005-09-20 Sakexe with PRE-RE config. it works perfectly w/o disconnections or any packet related issues. but unfortunately, i found a bug when i have atleast 2 or more kinds of usable items such as, Novice Potion, Fly Wing, Butterfly Wing, and Magnifier. the item will become unknown item.

How to reproduce?
1. All of the items that i said must be in your inventory. (which is in the ITEM tab)
2. Then try to change map, use @refresh, or relog.

i make a video for referrence aswell.

https://youtu.be/ASyWYQeJ8U0
","From clients packet tables:

0x991 was added in 2012-09-25aRagexe and was not changed

0x2e8 was added in 2008-01-02aRagexe and was not changed

0x1ee was added in 2003-12-08aRagexe but after in 2008-01-24aRagexe and future versions it changed size from -1 to other values. This mean probably this is last valid date for 0x1ee

0xa3 probably exists always. In 2008-02-19aRagexe it changed size to 44. This mean this is probably last valid date for this packet.

This dates not equal but similar to haru's suggestion.
",7551429
696,Snap + Sit + Hide + Asura Bug,open,2016-06-14T23:55:27Z,2017-02-20T15:53:11Z,,NONE,"There is a bug when performing this fast enough the delay of snap asura is bypassed can we have a delay on /sit after and during the snap skill?
",bump on this,7551429
697,Fix some skills bugs,open,2016-05-26T10:58:39Z,2018-10-18T19:43:38Z,,NONE,"Fix the skill type of RK_DRAGONBREATH and RK_DRAGONBREATH_WATER, they should be BF_WEAPON in official server, and they support bLongAtkRate bonus.

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1304)
<!-- Reviewable:end -->
",@Smokexyz since it's `BF_WEAPON` and its range is 9 on `skill_db.conf` it will be considered as `BF_LONG` as well.,7551429
698,Knight Auto Counter animation,open,2016-05-23T13:03:36Z,2016-05-23T13:03:36Z,,NONE,"When forcing Auto Counter Proc via click ( attack ) or Aura Blade, Concentration + atk sometimes animation doesn't shows up
",,7551429
699,LG_Overbrand correct formula ?,open,2016-05-23T09:59:16Z,2017-03-14T03:18:16Z,,NONE,"`skillratio += -100 + 400 * skill_lv + 50 * ((sd) ? pc->checkskill(sd,CR_SPEARQUICKEN) : 1); RE_LVL_DMOD(100);`
`skillratio += -100 + 300 * skill_lv + status_get_str(src) + status_get_dex(src);`

is this formula correct cause currently overbrand is very weak compared to megged cannon spear builds on iRO if so should we follow the posted overbrand post-balance formula ? ( i can only test to some extent since i have friends still playing official , will test xD )

based from the listed post balance formula
`skillratio += 200 * skill_lv + 50 * ((sd) ? pc->checkskill(sd,CR_SPEARQUICKEN) : 1);`
`skillratio += 100 * skill_lv + status_get_str(src) + status_get_dex(src);`
","I noticed in the zone that the formulas for all 3 hits does not match the info in the 2011 balance update documents. I tested this in iRO's sakray test server and found the damage there also didnt not match the 2011 document, but it perfectly matched the formulas found in the zone. More info here....

http://forums.irowiki.org/showthread.php?t=106899
",7551429
700,missing homunS eleanor skills,open,2016-05-18T21:50:14Z,2017-03-14T03:19:43Z,,NONE,"I'm trying to merge it from ra but I don't want to mess SC up.
Hope we can have it asap, it's been missing for 3 years and it's really horrible.
",,7551429
701,RE:RK Spear / 2 Hand Spear Attackspeed Penalties,open,2016-05-18T06:41:33Z,2016-05-25T02:30:44Z,,NONE,"![untitled](https://cloud.githubusercontent.com/assets/8035101/15349596/7e84b83e-1d06-11e6-93b0-37490e98c4aa.png)
1H Spear should be -8 , 2H Spear should be -12
in my status 1h Spear is -20 while 2h Spear is -19
other weapon penalties are correct.
","the values are correct problem is the data is switched in which axes currently the slowest attackspeed is interchanged witch spears
",7551429
702,Earth Strain Multiple Hits,open,2016-05-05T23:40:14Z,2016-05-09T06:15:35Z,,NONE,"called ""ES Dancing"" to most players, allows Earth Strain to deal multiple hits when walking diagonally, animation would bug showing different directions from Earthstrain and dealing x3~x5 its damage making it easily abused 
","just walking diagonally doesn't matter if its away or toward the casting point , ES's different cast points, back and forth, the direction in which the earth strain follows changes multiple times all of which hits the target. iirc it doesn't follow the caster anymore after rebalancing so technically it does not allow it anymore regardless.
",7551429
703,RG_GRAFFITI wipes all ground skills of caster,open,2016-05-01T10:10:53Z,2017-03-14T03:23:01Z,,CONTRIBUTOR,"``` C
int skill_castend_pos2(struct block_list* src, int x, int y, uint16 skill_id, uint16 skill_lv, int64 tick, int flag) {
...
        case RG_GRAFFITI:
            skill->clear_unitgroup(src); // <-- deletes all units of caster
            skill->unitsetting(src,skill_id,skill_lv,x,y,0); // <-- places new unit
```

This is ancient, pre-r1-eaSVN code. It is a very poor way of ensuring the caster can only have one scribbled text on the ground at a time. A more appropriate way might be to adapt skill_graffitiremover(), or perhaps to scan through sd->skillunit[] and remove the old unit.

On Aegis it seems that trying to place a second graffiti on the floor will succeed, but do nothing.

I've looked into this recently because I've been told that people were abusing that RG_GRAFFITI code with chaser's SC_MANHOLE. Normally you can't stack them to keep the target trapped indefinitely (but you can still spam-cast, so meh). But because the status doesn't immediately end when the ground unit goes away (unlike ankle snare), you can alternate casting manhole and graffiti to pull this off.
","Just following it up. This commit https://github.com/rathena/rathena/commit/4c617bcd598fe1b5ea8b8e1e6276ee62b7d19143 fixes the bug.  
Currently like ultramage said, if you use Manhole and Graffiti after, the Manhole will disappear but the effect will still linger and you can re-cast Manhole in a cell next to where Manhole was, effectively perma-trapping a player.
Also re-casting Graffiti will remove the previous and replace it with another. But you shouldn't be able to as well.

I recorded a video of the bug: https://www.youtube.com/watch?v=L2vBgHElsgg
Fixed with rathena commit: https://www.youtube.com/watch?v=7oFsa-i_m5I
(don't mind the pc audio didn't realize it was being recorded :thinking: )
",7551429
704,WL_SUMMON skill visual effects,open,2016-04-29T08:05:18Z,2016-08-16T22:07:52Z,,NONE,"This is an ancient issue that hasn't received much attention and wasn't even reported on Hercules.

(reference: https://rathena.org/board/tracker/issue-8144-warlock-summon-balls-issue/)

The relog issue is gone but the rest remains:
1. After casting release, balls are invisible when you summon them again. This is based on the type of previously released balls so let's say you summoned 5 fire balls and released them, summoning them again won't show any effect. If you summon and release 4, the final fifth ball will appear once you resummon all 5. This issue doesn't happen for different ball types and if you summon and release balls of a different type and try again with the original, they will show up now.

This somehow doesn't happen with tetra vortex even though both skills have pretty much the same implementation.
1. The amount of balls will double if you teleport or change maps, those fake balls remain even if you die and get resurrected but go away upon teleport/map change.
","Long due bump.
",7551429
705,Asura Strike vs Dead Target,open,2016-04-29T06:34:50Z,2017-03-06T17:12:30Z,,NONE,"When you cast Asura Strike and your target dies during the cast time, you still lose all sphere, fury mode and SP.

On rAthena/hercules the removal of Fury mode and drain of SP only happens if the target is still alive.

Credits: Playtester
","seems not only asura but all skills perform in the same way
",7551429
706,RG inspiration,open,2016-04-15T13:39:50Z,2016-04-15T13:40:03Z,,CONTRIBUTOR,"Hello, I found a small problem with RG inspiration skill that it's remove all buffs even cash shop food and battle manual .. bubble gum.... , is that official or a bug ?
",,7551429
707,NC_Pilebunker requirements not supported ,open,2016-04-12T03:02:05Z,2020-02-01T23:47:22Z,,MEMBER,"in skill_require_db.txt
2257,0,0,50,0,0,0,99,0,0,mado,0,**1549:16030:16031:16032**,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0    //NC_PILEBUNKER#Pile Bunker#

The bold portion probably represents that either one of those IDs that can be used, but source code doesn't allow for checking in such a way, for skill required items.
`
    for( j = 0; j < MAX_SKILL_ITEM_REQUIRE; j++ ) {
        skill->dbs->db[idx].itemid[j] = atoi(split[12+ 2*j]);
        skill->dbs->db[idx].amount[j] = atoi(split[13+ 2*j]);
    }
`
","I had a closer look at the skill DB and there are many more issues:
- **FixedCastTime** Missing a note in the entry structure that this field will only be read if `RENEWAL_CAST` is enabled.
- **Requirements**
  * **MaxHPTrigger** Completely missing in the entry structure.
  * **SpiritSphereCost** Doubly read in `skill_read_skilldb`.
  * **State**
    * Entry structure says it can be grouped by levels, which isn't implemented, yet.
    * Possible improvement: Convert states to bitmask to be able to combine them.
  * **Items**
    * Entry structure says it can be grouped by levels, which isn't implemented, yet.
    * No support for ""on of these items"". (This issue.)
    * No support for item must be equipped. (This issue.) (Maybe use `amount = -1` to achieve this.)
 - **Unit**
   * **Interval** Entry structure says it can be grouped by levels, which isn't implemented, yet.
   * **Target**
     * Missing types in entry structure: NotParty, NotGuild, Self
     * Completely missing types: BCT_GUILDALLY, BCT_NEUTRAL
     * Incorrect assigned types: Guild, SameGuild
     * Types should be combinable, since they bitmask fields.

Well, a lot of work...",7551429
708,Asura over fench and stairs,open,2016-04-11T01:01:40Z,2016-04-26T18:38:58Z,,NONE,"I am using the latest git, is this normal? https://youtu.be/vPV_C-tQ18A
","this bug.
",7551429
709,"Inspiration - 1% self damage is dealt to targets, not self",open,2016-04-06T13:44:44Z,2016-04-06T13:44:44Z,,NONE,"During Inspiration buff, 1% all damage dealt is supposed to be returned to the player. Instead, it's redirected back to targets.
",,7551429
710,CR_ACIDDEMONSTRATION skill type,open,2016-04-05T21:11:28Z,2016-04-11T08:06:56Z,,CONTRIBUTOR,"currently CR_ACIDDEMONSTRATION set to misc type skills, this type ignore % modifiers from cards.
however in official this modifiers affect it.
","probably.
need to confirm this skill type tho, @malufett 
",7551429
711,missing packet PACKET_ZC_DEFINE_CHECK,open,2016-04-05T16:54:01Z,2020-01-27T23:27:52Z,,NONE,"The PACKET_ZC_DEFINE_CHECK packet is not implemented in hercules, saw that it applies in the drop rare items and package items

```
// packet 0x7ff
struct PACKET_ZC_DEFINE_CHECK {
  /* this+0x0 */ short PacketType
  /* this+0x2 */ short PacketLength
  /* this+0x4 */ int Result
}
```

```
// result enumeration
enum PACKET_ZC_DEFINE_CHECK::<unnamed-tag>{
    DEFINE__BROADCASTING_SPECIAL_ITEM_OBTAIN =  0x1,
    DEFINE__RENEWAL_ADD_2 =  0x2,
    DEFINE__CHANNELING_SERVICE =  0x4,
};
```
","This packet was removed in 2011-07-19aRagexeRE and 2011-07-18aRagexe and was never exists in zero.
Probably exists some newer replacement for this packet?
",7551429
712,Unable to get item,open,2016-04-04T14:53:19Z,2016-04-06T21:14:12Z,,NONE,"Picking up an item that is across you while there is something (player/NPC/mob) blocking the cell between you and the item will result to making you back and forth trying to get the item.
This bug only happens when the item you're trying to pick up was on your left side of the screen. (Just like in the video.)
Hercules:
https://youtu.be/QmmX846hu30

Aegis Video:
https://youtu.be/vbMF2s8xUEo
","Once again, emulating obvious official bugs isn't a goal of this project. Fixing them is part of our goal. Providing a way for the users to enable the bugs (or disable them) via configuration gains bonus points.
",7551429
713,Map Zone in PK Mode.,open,2016-03-29T16:19:31Z,2017-09-06T05:57:59Z,,MEMBER,"When enable the PK Mode.
Went into the Guild Castle maps.

the Map Zone become ""GvG + PK Mode""
checked using `@mapinfo` command.

initially some items that was disabled in ""PK Mode"" zone
then I try to enabled these items in ""Gvg"" zone
but it  still get overwritten by the ""PK Mode"" zone, end up still disabled

somehow, now I unable duplicate this issue. Out of the sudden, this issue isn't appearing.
the `@mapinfo` return map zone ""GvG"" now, not ""GvG + PK Mode"".

So I create an issue here in case anyone face the same issue or did happened in your server.

*\* I noticed that `*removemapflag,mf_zone;`  doesn't support extra parameter for zone type too. it will remove all zone of that map.
",,7551429
714,rA Merges,open,2016-03-29T14:12:03Z,2019-07-30T07:14:29Z,,MEMBER,"I am just gathering commits, so that it's easy to track it down and merge (and get inputs from others)

rA commits to be merged:
- [x] Meteor Storm - https://github.com/HerculesWS/Hercules/pull/1230
- [x] Volcanic Ash Effect - https://github.com/HerculesWS/Hercules/pull/1231
- [x] Chemical Protection - https://github.com/HerculesWS/Hercules/pull/1232
- [x] Defense overflow Exploit - https://github.com/HerculesWS/Hercules/pull/1233
- [x] Power Swing - https://github.com/HerculesWS/Hercules/pull/1235
- [ ] SP Damage by Vellum - https://github.com/rathena/rathena/commit/6dc437fd08c961cc8caa86e55b9853e541ba63fe / https://github.com/rathena/rathena/commit/e071256247a05084bf2a699e736eb0e19423396a
- [ ] Monster Log - https://github.com/rathena/rathena/commit/0bd337d9ad9cc1dbebb93f2f1ebbde1b1de8ba6a
- [ ] Knuckle Damage - https://github.com/rathena/rathena/commit/0bd337d9ad9cc1dbebb93f2f1ebbde1b1de8ba6a
- [ ] Fire Expansion - https://github.com/rathena/rathena/commit/7f7af2e97ec52df96e4f1b2d17779e816685ccdc
- [x] MvP Exp Message - https://github.com/rathena/rathena/commit/85749e84b91087960e868e30a7a052b0c0cdce5b
- [ ] Snap - https://github.com/rathena/rathena/commit/b5de854b90353f2decf83a95fba8c19fbe641fb7
- [ ] Fear Status - https://github.com/rathena/rathena/commit/fbb8edba3949035b10fa1eaf112a2e2319c2ae57
- [ ] Skill Bypass - https://github.com/rathena/rathena/issues/984 (#841)
- [ ] WOE TE - https://github.com/rathena/rathena/commit/6aed7e0245cf7e54e1dde2ccb042fac475274489
- [ ] No Costume Mapflag - https://github.com/rathena/rathena/commit/23b271c9582c5c5e1ab60b8a356facd69e90f905
- [ ] Eclage Skill Animation - https://github.com/rathena/rathena/commit/0feabf30cee1c3cdf11de52d1ac3a5b3ca7536fc
- [x] Stat Reduce Pot -https://github.com/rathena/rathena/commit/51ef9118a8dce1c70fcd22a16ccdc4aad894f50d (#2483 / #2246)
- [ ] Status Icons - https://github.com/rathena/rathena/commit/371f619cb4f3ba37df4afe16d60a387ebe8c1142
- [x] Juperos Quest - https://github.com/rathena/rathena/commit/c488268d8c2fa74e1d16daf0c04a6bf2d36e2350
- [x] GX Poison Duration - https://github.com/rathena/rathena/commit/72b61d742fd8d0c27f97e25fa8a255ec58740550
- [x] Voice of Siren Duration - https://github.com/rathena/rathena/commit/f7a276ec7389389b6b56653ad87b21eb937aace6
- [x] Swing Dance ASPD Bonus - https://github.com/rathena/rathena/commit/b99114c0cedaf9218bcbc0371819cf12256d4527
- [ ] Updated HT_BLASTMINE and HT_CLAYMORETRAP renewal behavior - https://github.com/rathena/rathena/commit/b99114c0cedaf9218bcbc0371819cf12256d4527
- [x] @reloadnpc - https://github.com/rathena/rathena/commit/9c2026d
  *\* Non rA Merges ** (#2476)
- [ ] Eden NPC's

**Anyone is welcomed to list more commits**
**List can be expanded/**_edited_
","Checked off the ASPD Bonus because it seems we already have it https://github.com/HerculesWS/Hercules/blob/master/src/map/status.c#L6130

Thanks for the help @Asheraf ",7551429
715,Tarot Card/Gospel vs Chemical Protection,open,2016-03-29T13:52:34Z,2018-03-20T22:13:11Z,,MEMBER,"- The High Priestess Card from Tarot Card of Fate now removes Chemical Protection (all)
- Gospel now removes Chemical Protection (all) on the caster

Merge of https://github.com/rathena/rathena/commit/894d6f2fe64a401a62ceb57ec48f803e1e7f72be
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1232)
<!-- Reviewable:end -->
",7551429
716,Updated Volcanic Ash effect,open,2016-03-29T13:52:13Z,2018-03-20T22:13:12Z,,MEMBER,"- No longer gives 150% increased damage to fire type attacks.(http://forums.irowiki.org/showthread.php?p=1392305#post1392305)
- No longer damages self and allies on normal map types. (kRO Maintenance: 09-12-2012)

rA merge: https://github.com/rathena/rathena/commit/88d2dde63222ef0c480a5341315f7f2ed044f6a5
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1231)
<!-- Reviewable:end -->
",7551429
717,Meteor Storm Update,open,2016-03-29T12:58:35Z,2019-10-22T08:32:38Z,,MEMBER,"- Official implementation of Meteor Storm behavior
  -- It deploys all units directly at castend
  -- Each unit has a different expiration time
  -- On the last interval of a unit the meteor will appear
  -- When the unit expires, it will deal damage
  -- If the unit gets removed at any time, no meteor will appear and no damage will be dealt
- It is now easily possible to configure Meteor Storm behavior via database files, no more extra coding required
- Fixed Meteor Storm sometimes dealing damage even though no meteor appeared
- Fixed Meteor Storm being able to hit through walls when the caster has moved in the meantime

Credits: Playtester (https://github.com/rathena/rathena/commit/1365d9418e96c028cad903fe5cab8edb7c8ae0fc)
",@dastgirp can you update this? Thank you.,7551429
718,NPC allow changing of equipments while interacting,open,2016-03-26T09:41:58Z,2016-03-28T18:33:26Z,,MEMBER,"# issue Preview

When first talk to the NPC...
![GitHub Logo](http://i.imgur.com/1kvuwGO.png)

After the **Shop Window** opened.
![GitHub Logo](http://i.imgur.com/dMwNqN3.gif)
# How to Reproduce the Issue

```
// Enable all NPC to allow changing of equipments while interacting? (Note 1)
// Script commands 'enable_items/disable_items' will not be override. (see doc/script_commands.txt)
// 1 : yes(official)
// 0 : no
item_enabled_npc: 0
```
1. Change the setting in **conf/battle/item.conf**.
2. Create several items with same ID. _(Example: Katana [3])_
3. Place the items in the Hotkey bars.
4. Load the NPC script. https://pastebin.com/kZmUQx8D
5. Talk to the NPC and spam click the Hotkey to switch equipments.
# Result
- At first, your character unable to switch equipment no matter how you spam click the hotkey.
- After **Enter** pressed, the **Shop window** is opened.
  - first few click, might still success to block equipment switching.
  - **afterward, it will success to switch the equipment**.
- although success to switch equipment at the end, the selling progress might still failed, but the behaviour isn't correct. Players are suppose remain unable to exchange equipment.
","Well, it does seem that it should be the way it is. It only looks weird because the script called `end` and left the NPC dialogue window still open, even though the state has already been cleaned. My memory is foggy, but I do remember now that a certain preview headgear script was exploitable during the NPC dialogue (not the shop display), hence remedied by `item_enabled_npc`.
",7551429
719,Script Variables int64 Supporting,open,2016-03-24T20:02:42Z,2016-10-06T05:54:26Z,,NONE,"Is it possible to support int64 or uint64 variable in scripts?
","int64 support will be processed after variables system overhaul in Hercules.
Still not planned any sooner, but this issue can stay as part of milestone when we start it.
",7551429
720,Party buffs on dead characters,open,2016-03-22T14:33:11Z,2016-03-24T17:50:33Z,,NONE,"In official even if your character dies, party buff still applies, except toggle required buff.
Example: Angelus, Gloria etc.

Official:
![ss1](https://cloud.githubusercontent.com/assets/4656578/13954936/c59bfb84-f07d-11e5-959d-cb2e3febc9c0.jpg)

Hercules:
![ss2](https://cloud.githubusercontent.com/assets/4656578/13954949/caca8eea-f07d-11e5-9605-8e5143ac29da.jpg)
","@Playtester 
yeah..that's why I added a note after...but most of them are post renewal skills and non damage type...
",7551429
721,Raid bug?,open,2016-03-21T20:23:29Z,2016-04-12T14:45:11Z,,NONE,"A sucessful hit will cause the enemy to revice 20% more damage for a certain number of hits.

580 dmg w/o raid.
raid -> stun
580 dmg.

This is bug, or i just don't know how to use Raid?
https://www.youtube.com/watch?v=mlPhp_0sics
","@Jedzkie 
",7551429
722,Improvised Song not working,open,2016-03-21T09:35:09Z,2020-03-08T23:18:48Z,,NONE,"Improvised Song not release any magic skill.
I tried use @addperm skill_unconditional to spam but nothing.
","This happens because `sd->state.abra_flag` is set to 0 in `skill_check_condition_castbegin()`.
For Hocus-Pocus skills, this is correct, because they require catalyst items.
Since skills, casted by Improvised Song, do **NOT** require catalyst items, `sd->state.abra_flag` should only be set to 0 in `skill_check_condition_castbegin()`, if it's value is 1 (Hocus-Pocus).
If `sd->state.abra_flag` is 2 (Improvised Song), it should be kept for usage in `skill_check_condition_castend()`.",7551429
723,Comet and Land Protector Border,open,2016-03-20T16:19:38Z,2017-03-14T03:27:13Z,,NONE,"Renewal
Last update Hercules

Land Protector can't protect damage from skill Comet.
player on LP Border
see my clip
https://youtu.be/CpNMIo74RIw
","Yeah it doesn't hit on LP.

In fact I think Frost Nova and Comet should be unit skills. Just like Snow Flake Draft, Exploding Dragon and Lightning Jolt.

Haven't tested how far they can splash into LP yet, though.
",7551429
724,Monsters changes mode when changing to aggressive from iddle state.,open,2016-03-20T11:48:31Z,2016-03-21T08:26:07Z,,CONTRIBUTOR,"The following monsters changes to aggresive when are in iddle state, but they changes to a different mode in comparison with their original mode state defined in mob_db, making them lose some of their original AI in almost all the cases.

Monster ID - Monster Name. Mode in mob_db -> Mode when changing to aggressive
- 1098 - **Anubis**. 0x3695 -> 0x3095
- 1131 - **Joker**. 0x3695 -> 0x83
- 1207 - **Sting**. 0x3695 -> 0x3095
- 1675 - **Venatu**. 0x3885 -> 0x3095
- 1676 - **Venatu**. 0x3885 -> 0x3095
- 1677 - **Venatu**. 0x3885 -> 0x3095
- 1678 - **Venatu**. 0x3885 -> 0x3095
- 1679 - **Venatu**. 0x3885 -> 0x3095
- 1823 - **Freezer**. 0x3695 -> 0x3095
- 1825 - **Christmas Goblin**. 0x3695 -> 0x3095
- 1827 - **Sasquatch**. 0x3695 -> 0x3095
- 1867 - **Banshee**. 0x3795 -> 0x3095
- 1868 - **Banshee**. 0x3795 -> 0x3095
- 1987 - **Centipede**. 0x3795 -> 0x3195
- 1991 - **Tendrilion**. 0x37B5 -> 0x36B5
- 1995 - **Pinguicula**. 0x308D -> 0x3885
- 1997 - **Tatacho**. 0x108B -> 0x3095
- 2010 - **Majoruros**. 0x120 -> 0x3095
- 2015 - **Dark Pinguicula**. 0x308D -> 0x3885
- 2083 - **Scaraba**. 0x1089 -> 0x3195
- 2084 - **Scaraba**. 0x1089 -> 0x3195

Modes changes:
- 1098 - **Anubis**: Loses MD_CASTSENSOR_CHASE and MD_CHANGECHASE
- 1131 - **Joker**: Loses MD_LOOTER, MD_CASTSENSOR_IDLE, MD_CASTSENSOR_CHASE, MD_CHANGECHASE, MD_CHANGETARGET_MELEE and MD_CHANGETARGET_CHASE.
- 1207 - **Sting**: Same as Anubis.
- 1675 - **Venatu**: Loses MD_CASTSENSOR_IDLE, MD_CANATTACK, MD_DETECTOR, MD_CASTSENSOR_CHASE, MD_CHANGECHASE
- 1676 - **Venatu**: Same as 1675 - **Venatu.
- 1677 - **Venatu**: Same as 1675 - **Venatu.
- 1678 - **Venatu**: Same as 1675 - **Venatu.
- 1679 - **Venatu**: Same as 1675 - **Venatu.
- 1823 - **Freezer**: Same as Anubis
- 1825 - **Christmas Goblin**: Same as Anubis
- 1827 - **Sasquatch**: Same as Anubis
- 1867 - **Banshee**: Loses MD_DETECTOR + same as Anubis
- 1868 - **Banshee**: Same as 1867-Banshee
- 1987 - **Centipede**: Same as Anubis
- 1991 - **Tendrilion**: Loses MD_DETECTOR
- 1995 - **Pinguicula**: Changes MD_ASSIST to MD_ANGRY
- 2015 - **Dark Pinguicula**: Same as Pinguicula.
","Some monsters change to diffferent modes than they start with and never can come back.
But monsters should never lose ""Detector"", ""Plant"" or ""Boss"" as that's not part of the Aegis mode in the first place.
",7551429
725,Missed monsters AI changing to passive mode when in follow state,open,2016-03-20T10:34:57Z,2017-03-09T11:35:39Z,,CONTRIBUTOR,"Monsters should change to passive mode when they are following player. However, monsters changes to passive mode only when they are in chase state.

**Monsters affected**:
1029 - Isis
1033 - Elder Willow
1044 - Obeaune
1098 - Anubis
1099 - Argiope
1101 - Baphomet Jr.
1106 - Desert Wolf
1122 - Goblin
1123 - Goblin
1124 - Goblin
1125 - Goblin
1126 - Goblin
1130 - Jakk
1133 - Kobold
1134 - Kobold
1135 - Kobold
1139 - Mantis
1146 - Matyr
1148 - Medusa
1149 - Minorous
1154 - Pasana
1155 - Petite
1156 - Petite
1179 - Whisper
1180 - Nine-Tail
1193 - Alarm
1194 - Arclouse
1199 - Punk
1206 - Anolian
1207 - Sting
1213 - High Orc
1214 - Choco
1243 - Sasquatch
1254 - Raggler
1255 - Neraid
1264 - Merman
1289 - Maya Purple
1292 - Mini Demon
1294 - Killer Mantis
1295 - Owl Baron
1303 - Giant Hornet
1304 - Giant Spider
1306 - Leib Olmai
1310 - Majoruros
1311 - Gullinbursti
1315 - Assaulter
1317 - Seal
1318 - Heater
1319 - Freezer
1320 - Owl Duke
1323 - Sea Otter
1369 - Grand Peco
1384 - Deleter
1385 - Deleter
1391 - Galapago
1675 - Venatu
1676 - Venatu
1677 - Venatu
1678 - Venatu
1679 - Venatu
1714 - Ferus
1823 - Freezer
1825 - Christmas Goblin
1827 - Sasquatch
1867 - Banshee
1868 - Banshee
1974 - Banshee Master
1986 - Tatacho
1987 - Centipede
1995 - Pinguicula
2010 - Majoruros
2015 - Dark Pinguicula
2083 - Scaraba
2084 - Scaraba

**Tested in iRO Classic**. Confirmed with 
1033 - Elder Willow
1044 - Obeaune
1045 - Marc
1106 - Desert Wolf
1206 - Anolian.

**Note.** The follow mode state changing to passive mode is present and working in this other monsters:

1023 - Orc Warrior
1026 - Munak
1035 - Hunter Fly
1041 - Mummy
1045 - Marc,
1077 - Poison Spore
1178 - Zerom
1381 - Grizzly
1387 - Gig
",,7551429
726,Frost Diver Bug,open,2016-03-06T12:29:14Z,2016-03-15T02:10:36Z,,NONE,"Bug: Even if you're wearing an MDEF set, (example 70 MDEF above) the duration of its freeze it still 8 seconds.

Tested on pre-renewal
","Depends on Frost Diver Level and Luk of caster I guess?
",7551429
727,NPC Updates,open,2016-03-04T14:20:31Z,2017-03-12T23:16:24Z,,CONTRIBUTOR,"Based on kRO (Baphomet Server)
Fixes #1153

<!-- Reviewable:start -->

---

This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1182)

<!-- Reviewable:end -->
","Squashing is not the problem, since we can do this on merge. But the thing is, this is still in progress. Also i doubt we need any additional infos for the actual changes, since only thing changed are sold items.",7551429
728,Item Updates:,open,2016-03-02T07:24:56Z,2018-03-20T22:13:16Z,,CONTRIBUTOR,"Item Updates based on kRO Server.
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1177)
<!-- Reviewable:end -->
",7551429
729,Skills that go through walls but shouldn't,open,2016-03-01T05:43:35Z,2016-03-15T02:08:35Z,,NONE,"RK_WINDCUTTER
RK_IGNITIONBREAK
RK_DRAGONBREATH
RK_DRAGONBREATH_WATER
NC_COLDSLOWER
WL_COMET
WL_EARTHSTRAIN
WL_CRIMSONROCK
WL_CHAINLIGHTNING
WL_FROSTMISTY
","Related rAthena commit: https://github.com/rathena/rathena/commit/7906f0a3ff3742bb519b19b0cadbca9db0d35b32

Note: I only checked and fixed the skills mentioned in the commit message. I didn't have the time to test and fix all the 3rd class skills.

On a sidenote, Dragon Breath and Arrow Shower are different from all the other skills in that they can actually hit through walls if it's a one-tile wall and you target the wall directly. This is proof that they can't be unit skills as units couldn't be placed on walls. Compare to Thunder Storm which doesn't hit at all when you cast it on a wall.
",7551429
730,npc variable are shared by all his duplicated npc,open,2016-02-24T11:55:57Z,2016-02-29T01:49:39Z,,NONE,"```
> 2@bif,22,28,0 script  system  1_ETC_01,{
> mes "".variable is set to ""+.variable;
> close2;
> .variable = 1;
> end;
> }
> 2@bif,20,28,0 duplicate(system)   system2 1_ETC_01
```

Try this npc, if you speak to the first one. he'll say "".variable is set to 0""
And if you speak now to the second one, he'll say "".variable is set to 1""
It's absolutely not normal, it is said in the doc that each npc has its own npc variable '.'

And for example, if I do this code, I don't have any problem...

```
> 2@bif,22,28,0 script  system  1_ETC_01,{
> mes "".variable is set to ""+.variable;
> close2;
> .variable = 1;
> end;
> }
> 2@bif,20,28,0 script  system2 1_ETC_01,{
> mes "".variable is set to ""+.variable;
> close2;
> .variable = 1;
> end;
> }
```
","Yes I came across this when I made one of my instances. What if there could be two commands like

""shareduplicatenpc""

""noshareduplicatenpc""

That way we could choose which duplication process for whether or not we want variables sent to the other duplicate npc or not.
",7551429
731,"ModExp, ModDrop, ModDeath const.",open,2016-02-15T11:18:49Z,2018-10-03T00:03:21Z,,NONE,"after updating I tried and tested but it seems that ModExp, ModDrop and ModDeath doesn't work like it used too, no exp mod was applied, no death penalty was applied. I'll try to get the version where it was working because I have it saved, I'll post it once I got it.
","It seems to be working fine on 2018.09.23. Tried changing each value, checked that it affected my character and relogging/restarting server also kept the values.

Test Script:
```
prontera,150,150,4	script	TestExpMod	1_M_01,{
	input .@val;
	setparam(ModExp, .@val);
	end;
}

prontera,152,150,4	script	TestDropMod	1_M_01,{
	input .@val;
	setparam(ModDrop, .@val);
	end;
}

prontera,154,150,4	script	TestDeathMod	1_M_01,{
	input .@val;
	setparam(ModDeath, .@val);
	end;
}
```",7551429
732,Intravision doesn't work on disguised characters,open,2016-02-13T04:42:51Z,2016-03-15T02:05:33Z,,CONTRIBUTOR,"While this was tested on a revision from October 10th 2015, I couldn't find newer commits that would seem to be related to either disguise/intravision. 
I am not sure if this is official behavior or perhaps a client thing (Using 2013/12 one).

When you use Maya Purple card, you can no longer see players who Cloak while disguised.

Ex.-
Player 1 Puts on Maya Purple
Player 2 Cloaks --> Player 1 can see player 2's silhouette
Player 2 Disguises --> Player 1 can no longer see player 2's silhouette
Player 2 Undisguises --> Player 1 can see player 2's silhouette again.

However, if Player 2 has Maya Purple, he can see his own silhouette while either disguised or undisguised (But two players in the same party doesn't work, kinda thinking it could be an ally target thing)
","Maya purple mess again...
i gave up.
",7551429
733,[RE] Service NPCs coordinate,open,2016-02-09T13:03:14Z,2016-10-10T20:55:08Z,,CONTRIBUTOR,"According Towninfo.lub ,
Herc has some NPCs that has wrong coordinate, well not many.
Some that i've found
Payon:
![screenlocal000](https://cloud.githubusercontent.com/assets/10024221/12916837/f7680c34-cf67-11e5-8674-25ce974562c7.jpg)

Morocc:
![screenlocal001](https://cloud.githubusercontent.com/assets/10024221/12916846/06f29d2c-cf68-11e5-9696-ba0c0c4234ee.jpg)

Lighthalzen:
![screenlocal002](https://cloud.githubusercontent.com/assets/10024221/12916850/104a3ba0-cf68-11e5-80dc-98bcca82cc88.jpg)
","Morroc and Payon Problems are already fixed. I'll continue update the remaining cities by tomorrow.
",7551429
734,Skills overflow issue,open,2016-02-09T11:25:05Z,2016-03-15T02:04:09Z,,CONTRIBUTOR,"sanitizer detected this error
skill.c:3418:81: runtime error: left shift of negative value -1

This issue happens with skill GN_CRAZYWEED_ATK,
Probably in code missing break between GN_CRAZYWEED_ATK and WL_EARTHSTRAIN

git top commit ed3387430588f2786d2e9b72723c1d54401f65da
",,7551429
735,Solar/Stellar/Lunar bug,open,2016-02-08T14:08:44Z,2016-03-15T02:03:53Z,,NONE,"When a buff is applied (i.e blessing) when heat of the moon/stars/sun is activated, the damage does not change until you take a few steps back and re-attack the monster. 

This isn't suppose to happen, the damage should be changing instantly.
",,7551429
736,"Fixed Land Mine, Blast Mine and Claymore Mine not ignoring damage red…",open,2016-02-08T02:10:59Z,2017-08-02T23:04:42Z,,CONTRIBUTOR,"…uction cards

Merge rAthena @ 5971745dfd36451ecae766f7e4e9afb8f293ca5a
Credit: Playtester
",Any news here?,7551429
737,Sura Gentle Touch,open,2016-02-07T06:32:40Z,2016-03-15T02:03:27Z,,NONE,"Apologize in advance if of someone already posted it before.
I just want to re-point out and ask for confirmation regarding Sura Gentle Touches as the sphere consumption is a bit weird.

Note: I compared these skills behaviour with iRO wiki (as the kRO balancing data says nothing)
GT - Cure consume 2 Spheres 
GT - Revitalize consume 1 sphere
(I only tested with Cure and Revitalize)

Anyway in comparison, in Hercules they work like this:
(using GT - Cure as example)
GT Cure Level 1 - Up to 1 Sphere Consumption
GT Cure Level 2 - Up to 2 Sphere Consumption
GT Cure Level 3 - Up to 3 Sphere Consumption
GT Cure Level 4 - Up to 4 Sphere Consumption
GT Cure Level 5 - Up to 5 Sphere Consumption

I used the word ""Up to"" to describe the behaviour as even if you have 1 Sphere or 5 spheres, depending on the level of the skill you can still use it.

p.s Sorry no reference attached for this
",,7551429
738,Misleading Status Window Info (DEF),open,2016-02-07T06:03:13Z,2017-08-09T04:37:49Z,,NONE,"In Official, you see the right number of DEF on your Status Window according to the refinement of your Equips. But here in Hercules, it doesnt show the right info for DEF. (Theres nothing wrong with the Refine Formula, its just the Status Window that is bugged)

Official:
![official def](https://cloud.githubusercontent.com/assets/4656578/12871088/0520ddae-cda3-11e5-9575-2448c6e11928.jpg)

Hercules:
![def](https://cloud.githubusercontent.com/assets/4656578/12871090/096149ee-cda3-11e5-8037-cf5f5deb3224.jpg)

PS: It also show a wrong number ATK but I will make an different report about this since I still dont know the cause of this problem.

Photo source:
http://z4.invisionfree.com/pROsins/ar/t1471.htm
","@malufett
",7551429
739,Status Effect delay,open,2016-02-05T04:55:32Z,2018-11-25T00:15:44Z,,NONE,"Status Effects such as Sleep, Frost, Blind Stun etc.. have slight delays before the status fully take effect.

Video: https://youtu.be/WJQSwdSANoI

Old Topic http://herc.ws/board/tracker/issue-6622-stormy-knight-card-frosting-effect/?gopid=14086#entry14086

> Playtester, on 09 Dec 2014 - 15:10, said:
> I don't think this is related to the freeze status effect.
> 
> When I tested delays and hitlocks on officials I noticed that when I have low ASPD that my damage is applied very late (long after damage number shows). Consequently status changes also occur at a later time (as they have to be applied AFTER the damage or else the ice would instantly break again).
> 
> I think we need to measure the delay between damage applied and status change applied. I might only be 20ms (min timer interval).
> 
> But I can say for sure that the delay until a status effect is applied is there, but this is not related to freeze or stormy card. For example when Magnolia uses NPC_STUNATTACK on me I also can walk like 5 cells before I'm stunned. I was always thinking that it's related to the delay between attack and until the damage is applied.
","@4144 @Asheraf @dastgirp @MishimaHaruna 
Something about it? This delay is important as it can prevent player death if it heals in that range.",7551429
740,NPC_EVILLAND and PR_SANCTUARY,open,2016-02-04T10:50:22Z,2016-03-28T04:58:30Z,,NONE,"NPC_EVILLAND:
- Should always hit
- Should ignore devotion
- Should have a target range of 7
- Should hit and heal [skill_lv+3] times, regardless of how many targets there are
- Should have an AoE of 11x11 on level 1-9 and 27x27 on level 10

PR_SANCTUARY:
- Should heal [skill_lv*3]+1 times, regardless of how many targets there are (e.g. on level 1, even if 5 are standing on sanctuary it should still heal all 5 of them 4 times, rather than disappearing immediately; and when alone on it, it still only heals 4 times)
- Should disappear after hitting [skill_lv+3] targets, regardless of how many are healed by it and when it disappears, it still should hit all targets on it during that tick

My commit on rAthena: https://github.com/rathena/rathena/commit/9721dc94a524b5044d65194a524b178d57f0d726
(Some of the cleanup is not necessary on Herc as it's already cleaned up there.)
","@dastgir 
Sorry for the late reply. I already confirmed it and its correct.
",7551429
741,Range type check,open,2016-02-04T08:39:08Z,2016-11-25T18:00:05Z,,NONE,"**Official**: If a monster attacks within a 7x7 area, the attack is considered melee, otherwise ranged 
**Herc**: 11x11

**Official**: If a player attacks with a skill of range 3 or lower, the attack is considered melee, otherwise ranged
**Herc**: Skills with 4 range are considered melee on Herc (e.g. Spear Stab) except for Gate of Hell (that exception can actually be removed, it's a common rule!)

**Official**: When monsters use Arrow Shower it is considered a melee skill regardless of range. It is always blocked with Safety Wall and its damage doesn't get reduced by Horn Card, even if you are standing far away.
**Herc**: Currently depends on range to the monster, e.g. you can just tank Cecil Damon from far away in pneuma and never be hit.

These can fairly easily be fixed by updating battle_range_type in battle.c.

rAthena version:

``` c
static int battle_range_type(struct block_list *src, struct block_list *target, uint16 skill_id, uint16 skill_lv)
{
    // [Akinari] , [Xynvaroth]: Traps are always short range.
    if( skill_get_inf2( skill_id ) & INF2_TRAP )
        return BF_SHORT;

    // When monsters use Arrow Shower, it is always short range
    if (src->type == BL_MOB && skill_id == AC_SHOWER)
        return BF_SHORT;

    //Skill Range Criteria
    if (battle_config.skillrange_by_distance &&
        (src->type&battle_config.skillrange_by_distance)
    ) { //based on distance between src/target [Skotlex]
        if (check_distance_bl(src, target, 3))
            return BF_SHORT;
        return BF_LONG;
    }

    //based on used skill's range
    if (skill_get_range2(src, skill_id, skill_lv) < 4)
        return BF_SHORT;
    return BF_LONG;
}
```
",,7551429
742,Homunculus behavior,open,2016-02-01T07:28:06Z,2017-09-24T05:20:58Z,,NONE,"1. In Aegis, Homunculus skills are not affected by Bard/Dancer songs. However in Hercules Homunculus skills are being spammed due to the effect of Bard Songs (Bragis of Poem) example is Caprice skill.
2. Aegis: There should be skill name over head on homunculus when using skills.
   ![screenmichiro001](https://cloud.githubusercontent.com/assets/4656578/12711137/502649b0-c8f8-11e5-90c3-1a7aa1de309e.jpg)
","@Jedzkie Only tested in Bard/Dancer skills

Bug#3: Invalid
Official: Whenever the player dies and the Homunculus' HP is above 80%, it will automatically be Vaporized. Otherwise it will not vaporize and is able to continue to fight, and the player continues to receive Experience from Homunculus, but manual commands cannot be issued.
Source: http://irowiki.org/wiki/Vaporize",7551429
743,Party item share,open,2016-01-24T19:24:51Z,2016-03-15T02:00:25Z,,CONTRIBUTOR,"Test mode: Pre-renewal
Client: 2010-04-20aRagexeRE
hash: 0ed2d09e9aa88af01698707fd701363bdbd92b4b

If I'm not mistaken (pre-renewal and renewal),
when party item share is set to ""shared"", only member in ""same screen"" are affected by this setting,
but in herc, even you're not in same screen, you still get the items from other member that pick the item.

Has this been changed in kRO, so herc use this mechanic?

and one more thing,
so does with the ""Kill count"", but I haven't tested it in herc.

Thanks
","Its always like this, its used to be a way of scamming people in official servers.
",7551429
744,GN_WALLOFTHORN > UNT_FIREWALL transition,open,2016-01-23T14:21:38Z,2016-03-15T01:59:59Z,,NONE,"The created firewalls have negative duration tick right (the same used by the base unit's interval). The base unit is also missing the 20 hit limit and damage formula.
",,7551429
745,"Usable item ""Delay"" function",open,2016-01-22T17:52:52Z,2016-03-15T01:59:48Z,,NONE,"Right now the delay triggers even if the item isn't actually used either due to the previous delay being active or something else preventing the use (mapflag, some other restriction, etc).
",,7551429
746,Event Notification Implemented,open,2016-01-18T13:36:15Z,2017-06-07T01:15:10Z,,MEMBER,"#1021

Image: http://imgur.com/hG4gSed
Video: https://youtu.be/DgXpfnQdzNc
",@dastgir still working on this?,7551429
747,MD_PLANT's damage calculation and its interaction with SC_PNEUMA and SC_SAFETYWALL,open,2016-01-17T00:38:35Z,2016-03-15T01:59:09Z,,NONE,"Currently monsters with this mode do not benefit from those SC statuses at all, always receiving 1 damage, this applies to Emperium and battleground stones as well, which is a rather big deal.
","My plant code itself should be fine, it's just that I didn't touch the exception for Emperium because I thought there must be some reason why someone put them in there in the first place.

Unfortunately I'm not really a PVP player so I have no means to test on active WoE/BG grounds.

If you just spawn an Emperium on an Aegis server Safety Wall works just fine, though...
",7551429
748,Soul Destroyer Range,open,2016-01-15T17:59:56Z,2016-03-15T01:58:39Z,,CONTRIBUTOR,"Reference:
https://github.com/rathena/rathena/issues/905
kRO Renewal Client's = \data\luafiles514\lua files\skillinfoz\skillinfolist.lub

```
    [SKID.ASC_BREAKER] = {
        ""ASC_BREAKER"",
        SkillName = ""Soul Destroyer"",
        MaxLv = 10,
        SpAmount = { 20, 20, 20, 20, 20, 30, 30, 30, 30, 30 },
        bSeperateLv = true,
        AttackRange = { 9, 9, 9, 9, 9, 9, 9, 9, 9, 9 },
        _NeedSkillList = {
            { SKID.TF_DOUBLE, 5 },
            { SKID.TF_POISON, 5 },
            { SKID.AS_CLOAKING, 3 },
            { SKID.AS_ENCHANTPOISON, 6 }
        }
    },
```

It's says the range maxed at 9 cells,
but in Herc is 7:

```
379,7,6,1,-1,0x40,0,10,1,yes,0,0,0,misc,0,
```
","Not on Aegis and rAthena for PC ranges. Not sure about Herc.

As said 9 range = 9 cells between caster and target.
",7551429
749,Poem of Bragi + bCastrate,open,2016-01-15T03:04:06Z,2016-03-15T01:58:33Z,,NONE,"I've already confirmed that it's not working unlike in the official server. In the official server, it is possible to attain no casting time even if you don't have 150dex. As long as you have Poem of Bragi  and the effect of Isillia Card (-50% casting).

Lvl 10 Music Lesson: -10% Casting Time
Lvl 10 Bragi of Poem: -30% Casting Time
Bard with 100 Dexterity: -10% Casting Time
Isilla Card (chance): -50% Casting Time
Total = -100% Casting TIme

This is not working here in Hercules ^

http://herc.ws/board/tracker/issue-4721-poem-of-bragi-bcastrate/?gopid=23744#entry23744
","Aegis Video:
https://www.youtube.com/watch?v=iv1MRFSCogk
The skill I used here is 'Laudaramus' because this skill doesn't have Fixed Casting Time. You can see on the video that it is possible to achieve no cast even if you don't have 150 DEX. (I'm referring to Pre-Renewal). This is also possible on Renewal as long as the skills used doesn't have Fixed Casting Time like Laudaramus skill.

@Playtester 
Sorry but I can't confirm it on Imp Card (Fire Bolt) because the test server I'm using is in Renewal and the Firebolt here have Fixed Casting Time.
",7551429
750,Mind Breaker,open,2016-01-15T02:22:35Z,2018-08-16T12:52:29Z,,NONE,"Official: When under Mind Break the matk effect and mdef reduction should not show on status window (ALT + Q or ALT + A)

Hercules:
![3](https://cloud.githubusercontent.com/assets/4656578/12343791/df54459a-bb71-11e5-87c2-de6dd1bc66fd.jpg)
![4](https://cloud.githubusercontent.com/assets/4656578/12343793/e0c5c9da-bb71-11e5-974e-be9559fe1ccd.jpg)
","this is retlated to a post i made on the rathena forums, about the atkpercent, matkpercent, defpercent, and mdefpercent being their own separate stats. none of them are ever shown on the client window.",7551429
751,Official behavior when reached max level,open,2016-01-13T15:43:24Z,2017-03-03T20:34:49Z,,MEMBER,"

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1097)
<!-- Reviewable:end -->
",@dastgir Why is there no description to this ? This PR also has conflicts.,7551429
752,Guild Storage Skill,open,2016-01-11T11:17:36Z,2020-03-08T14:53:34Z,,MEMBER,"Tested with 2014-10-22, it works now :)
Needs rebase though, can you do rebase and review @MishimaHaruna

<!-- Reviewable:start -->

---

This change is [<img src=""https://reviewable.io/review_button.svg"" height=""35"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1092)

<!-- Reviewable:end -->
",Does this one will really merged in the coming Release ?,7551429
753,WL_WHITEIMPRISON,open,2016-01-06T12:54:11Z,2016-03-15T01:57:25Z,,NONE,"The skill is canceling the cast of buff skills. And that was not to be.

Example

I'm cast AB_CLEMENTIA and in the middle of casting I'm stuck in WL_WHITEIMPRISON at the end of the casting AB_CLEMENTIA it is to give the normally buff.
But in rAthena to suffer it the skill to cast is canceled and has no effect

In the Brazilian server is the skill to buff it finishes casting normally now if the skill is damage it has no effect

Version: 9ed4dcf15079f50adef392087e0537acef0ac672
Client : 20130807
model : renewal
",,7551429
754,cell_shootable can't work without cell_walkable,open,2016-01-05T23:39:29Z,2016-03-15T01:57:14Z,,CONTRIBUTOR,"https://github.com/rathena/rathena/issues/876

same issue with rathena
the discussion there is much more complete
",,7551429
755,Official Refine Behavior,open,2016-01-05T13:51:14Z,2020-01-11T05:54:34Z,,CONTRIBUTOR,"Commit No.1

Reference Video:
https://www.youtube.com/watch?v=tnr5W8Eir4Y

Commit No.2

Reference Video:
https://www.youtube.com/watch?v=dsAZcMLrMmY
","@MishimaHaruna
No activity for a years, source branch doesn't exist anymore and it conflicts with current master. Close?

#clean_up_frenzy",7551429
756,"code review needed for mob_dead()'s SC_CASH_RECEIVEITEM, SC_OVERLAPEXPUP, RENEWAL_DROP",open,2015-12-31T09:35:50Z,2016-03-15T01:57:03Z,,CONTRIBUTOR,"``` C
// Increase drop rate if user has SC_CASH_RECEIVEITEM
if (sd && sd->sc.data[SC_CASH_RECEIVEITEM]) // now rig the drop rate to never be over 90% unless it is originally >90%.
    drop_rate = max(drop_rate, cap_value((int)(0.5 + drop_rate * (sd->sc.data[SC_CASH_RECEIVEITEM]->val1) / 100.), 0, 9000));
if (sd && sd->sc.data[SC_OVERLAPEXPUP])
    drop_rate = max(drop_rate, cap_value((int)(0.5 + drop_rate * (sd->sc.data[SC_OVERLAPEXPUP]->val2) / 100.), 0, 9000));

drop_rate = drop_rate * drop_modifier / 100; // RENEWAL_DROP
drop_rate = drop_rate * sd->status.mod_drop / 100;

// attempt to drop the item
if (rnd() % 10000 >= drop_rate)
    continue;
```

The SC_CASH_RECEIVEITEM line is from eathena (formerly SC_ITEMBOOST), and it used to be the only thing that altered rates. It's from https://github.com/HerculesWS/Hercules/commit/c405daa5223c0f6d0f74bf98a89d918263d4de08 and the author unfortunately decided to bundle the 90% cap together with the droprate modification, making it unreadable.

The SC_OVERLAPEXPUP line was added this month in https://github.com/HerculesWS/Hercules/commit/f00431e91557205ae5373a8afb1b91c6b1350590 and the author just blindly copy-pasted the whole thing.

The RENEWAL_DROP adjustment is from an early rathena commit, which is too large to view here.

Currently the droprate computation is a mess. The RMS item description for the overlapexp consumable item says that it stacks additively, yet here it multiplies. The 90% cap is applied twice because of copy-pasting, instead of splitting it off. And the renewal level difference droprate adjustment is applied near the end, after the cap, negating the effect of drop boost on higher droprates.

I suggest re-evaluating the changes done so far, cleaning the thing up and maybe figuring out what the correct order and type of operations should be.
","i wonder, was not 80% and not 90% the cap ?
",7551429
757,SC_BLOODING,open,2015-12-30T08:44:07Z,2016-01-04T10:05:38Z,,NONE,"If we follow this balancing notes:
https://docs.google.com/document/pub?id=1ESSiUmNwAbD4RA63vKSAgbUq4c98pykuOjCd9uaCFFs

we should be able to AB_CLEARANCE, SC_BLOODING
It cannot be removed at the moment.

I think this didn't get to your rebalance patch
@dastgir 
","Thats 3 year old one, still the data was provided by @Michieru, so if he can confirm it again, it would be good
",7551429
758,TraderShop,open,2015-12-29T06:59:04Z,2018-08-04T17:06:28Z,,MEMBER,"Saving amount and ID's in array
",@mekolat @4144 ,7551429
759,Return before WFIFOSET,open,2015-12-29T06:26:33Z,2017-02-19T07:13:44Z,,CONTRIBUTOR,"There's few function where a return exist before WFIFOSET, we should do all checks and gather data before making the packet and return before allocate the packet buffer.
",,7551429
760,"Validate string variable (mapreg, charreg, etc) length",open,2015-12-28T20:17:26Z,2015-12-28T20:17:26Z,,MEMBER,"This is similar to #1003, but with the string variable content, rather than its name.

We currently limit the length to 255 (should we increase it to something larger maybe?), but in some places that length isn't enforced or checked correctly. More info in the discussion of #1003.
",,7551429
761,Implement the correct formula for status points past level 99,open,2015-12-28T20:10:24Z,2017-09-16T00:56:25Z,,MEMBER,"Right now we're defaulting to a table-based (config-file based) status points list. In fact, a formula could be used.

We have an option to enable the formula-based calculation (battle/exp.conf):

```
// Use the contents of db/statpoint.txt when doing a stats reset and leveling up? (Note 1)
// If no, an equation will be used which preserves statpoints earned/lost
// through external means (ie: stat point buyers/sellers)
use_statpoint_table: yes
```

When switching to the formula-based calculation, values are correct for pre-renewal (or in general before level 100), but over that level our progression doesn't match the official one (introduced with Renewal).

Our progression is purely linear, while theirs changes coefficient as the level increases (in large steps). More detail about this can be found in my comment on issue #752.

We should implement the correct formula past level 100, and consider whether to switch to the formula-based calculation by default. Once that is done, we can consider deprecating the file-based tables, since they would no longer have reason to exist.
","Hi,
I have been wondering about this my self for a couple of months now..
While making test and comparing to the table, I found that the table is inconsistent.. 
At lvl 176, it only adds 17 stat points, and it jumps or adds double on 228 and 248..
The Pre-Renewal Calculation is when leveling up is (level+15) / 5 , where level is actually the level gained or (level - 1)..
Its the same with Renewal, until lvl 100...
101-175 is (level+46) / 7...
176-255 is (level+139) / 10 .. Except on what I noted above... Maybe it goes on till 1000 or maybe it will change in some point..",7551429
762,Added isguildally script command. Checks if guilds are allies.,open,2015-12-26T22:47:34Z,2018-03-20T22:13:32Z,,CONTRIBUTOR,,"

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/1027)
<!-- Reviewable:end -->
",7551429
763,Using item scroll while casting skill,open,2015-12-26T14:45:58Z,2016-03-15T01:54:56Z,,NONE,"On Official, even if you're still casting a skill, (example, Storm Gust) and you use an Item Scroll like Heal Scroll, after the said skill has finished its casting, the effect of the said Item Scroll will work automatically. 

On Hercules, this doesn't happen. Please watch my video from iRO.
https://www.youtube.com/watch?v=LimA7o2Umo8
",,7551429
764,kRO Event Notification,open,2015-12-26T04:38:08Z,2016-01-18T14:44:56Z,,CONTRIBUTOR,"Hi! since november, i saw this kRO's notification if they have events.

Reference Video:

https://youtu.be/DgXpfnQdzNc
","http://imgur.com/hG4gSed
",7551429
765,Move libcre interface to the core,open,2015-12-25T14:41:34Z,2015-12-27T03:53:12Z,,MEMBER,"As suggested by @AnnieRuru, we could use libpcre outside the map server (to deny character creation based on pattern for example), so it would work well as a common interface.

This ticket tracks the migration of the pcre interface to the core, and all the necessary refactoring.

I'd also like to remove the optional dependency on pcre (and make it a mandatory dependency), so that we can assume it's enabled, and use it in more places than we do now. If there is any reason why it should stay optional (having ""one more package to install"" isn't such a reason, we already have a good deal of dependencies, and this would be just one more, and I don't believe there are any distributions that don't offer it), please speak up now.
","while you are at it,
please make `*preg_match` and `*defpattern` use the same regular expression syntax
currently `defpattern` is not case sensitive, and return **$@p1$**
and `pcre_match` is case sensitive, and return **$@regexmatch$[0]**

btw, don't worry about changing defpattern into case-sensitive,
I'm going to rewrite those 2 scripts release that uses `*defpattern` anyways
",7551429
766,Char stopping attack,open,2015-12-24T02:04:14Z,2020-02-28T18:07:54Z,,NONE,"Well I don't know if it's a bug or is something official.

When I'm hitting a monster with the char X and go into another account with the char Y, when the char Y enters the monster screen that the char X is attacking the char X makes the movements of attack. More if the char Y out of Monster screen and stay only on the screen of char X. then the char X does not attack moves, the more he is attacking.

This problem occurs in classes that attack the distance as hunter and range

Bug track topic: http://herc.ws/board/tracker/issue-7375-char-stopping-attack/
",@Kenpachi2k13 thanks for confirming this.,7551429
767,Elementals damage,open,2015-12-24T01:46:51Z,2016-12-08T22:35:28Z,,NONE,"I was testing elemental ventus in iro and compared with hercules. in hercules the elementals are not  capable of hitting a poring, damage and movement speed is too low if compared to aegis.

Source iRO.

Post Bug track: http://herc.ws/board/tracker/issue-8623-elementals/
","any news on when this bug is going to get fixed? as it stands now, the elemental spirits CAN""T hit any mobs with melee hits. they ALWAYS miss.",7551429
768,GN_SLINGITEM Bug,open,2015-12-23T03:23:51Z,2015-12-23T13:13:51Z,,CONTRIBUTOR,"I found a Bug in GN_SLINGITEM skill wherein you cant cast the skill after you logout.

How to reproduce?
1. Create 2 Genetics, make them max level and max stats, all skills.
2. @pvpon on any map
3. Use the skill 5-10 times w/ equipped throwable items like, HP_Inc_PotsL_To_Throw or any other throwable items execpt (ID13260 - 13267)
4. then logout, then login again. You can't cast the skill anymore. (No Skill Effect / Visual Effect)
",,7551429
769,some of *gettimestr time format crash map server,open,2015-12-22T13:23:04Z,2015-12-28T20:29:36Z,,CONTRIBUTOR,"http://herc.ws/board/tracker/issue-8177-some-of-gettimestr-time-format-crash-map-server/

yes, I'm using ~~stupid~~ microsoft build
`[Info]: Compiled with Microsoft Visual C++ 2010 (v1600)`

I JUST updated the wiki,
http://herc.ws/wiki/Gettimestr
and then angelmelody show me that bug report

which makes me think, if you guys actually interested to disallow map-server to crash
maybe can use an hardcoded value like [pan posted](https://code.google.com/p/vx32/source/browse/src/libvxc/strftime.c?spec=svn501ad9c86dffb9b79671e798421b0da263f0dad0&r=ba907a8c82639445a761410ddcddcc55a4e18a90) ?
","We can indeed add our own implementation of strftime, based on the linked file. I think that's the best option right now. The linked code is released under the MIT license, which allows us to include it in Hercules.
",7551429
770,Casting Position Bug,open,2015-12-21T17:16:36Z,2016-03-31T03:56:57Z,,NONE,"Whenever I click on a cell and I cast a self -skill before stepping on that certain cell my charactter goes back to the cell where I was.

Video: https://youtu.be/PVRk7I59dmw

Bug tracker: http://herc.ws/board/index.php?app=tracker&showissue=7255
","@MishimaHaruna @malufett 
",7551429
771,merge rAthena's Unit Controller Script Commands,open,2015-12-21T06:05:49Z,2019-02-15T02:30:02Z,,CONTRIBUTOR,"https://github.com/rathena/rathena/commit/2cee5b6ff1bf53c4ae53bc1278b09ae84b8a0a76
this one commit has a lot of stuffs in it, if wanna break it up, there are
- [x] Add `*getunittype` and update `*getmapxy` (#871)
- [x] extend `*monster` and `*areamonster` script command to support array
pull twice -> https://github.com/HerculesWS/Hercules/pull/1393 https://github.com/HerculesWS/Hercules/pull/1410 and rejected
- [ ] add `MD_NORANDOM_WALK` and `MD_NOCAST_SKILL` monster flag
- [ ] split `*unitstop` into `*unitstopwalk` and `*unitstopattack`
- [ ] extend `*unitskilluseid`/`*unitskillusepos` for fixed cast time
- [x] `*setmobdata`/`*getmobdata`
- [x] `*setmoblook`/`*getmoblook`
- [ ] extend homun/pet/merc/elementals to return GID
- [x] `setunitdir`/`getunitdir`

and these are missing in rathena but I feel like add in
- [ ] `*mobattach`/`*getmasterid` script command
- [ ] `*mobevent` script command
- [x] `*setunitsize`/`*getunisize` (#895) <- I already tried but failed to do it
- [ ] `*mob_sc_start` - UMOB_CANMOVETICK is missing in rathena ??

also means I have to make 13 total pull request
before we have ourselves a full capable unit-controller commands like rathena has =/
","no way
I seriously don't like the way rathena do it all at once
its better to split out 1 by 1, do it slowly

when I did that `*getunittype` script command, I never thought about using existing `*getmapxy`
until I suddenly found out can use `*getmapxy` to retrieve the coordinate of the monster by using GID
and Haru also update all `*getmapxy` script commands to use UNITTYPE_ constant,
I never thought about that before too

if we do it slowly, examine the system part by part, we wont suffer the same fate like rathena
rathena `*getunittype` is fuck up
rathena `*setunitdata` has `UMOB_SLAVECPYMSTRMD` but doesn't have `*mobattach` script command
rathena `UMOB_MAPID` return map index, WTF ??
rathena `UNPC_DMGIMMUNE` <-- isn't npc already immune to attack ??
and some others I find it very ridiculous

wanna know how fuck up rathena system is ? read here
http://herc.ws/board/topic/8974-script-command-setmobdata-getmobdata/?p=65553
https://rathena.org/board/topic/103785-add-parameters-for-setunitdata/?p=293176
https://rathena.org/board/topic/104023-setunitdata-parameters-what-are-these-for/
",7551429
772,Login Server code cleanup,open,2015-12-21T04:47:19Z,2017-02-19T07:13:44Z,,CONTRIBUTOR,"our login server have never been maintained in long time, we were just add more and more code to it and follow it current awful code.
during this clean up it's expected to:
- split up many functions into various functions.
- rewrite our login server config with libconf library and remove any settings related to login server from inter-server.conf as it's marked as deprecated.
- remove many leftovers of removed settings
- remove leftovers TXT DB removal update
- merge ipban_sql.c and login.c
- remove syntax _sql for files name
- cleanup comments and add documentation to current functions if possible
","well yea, you've got point.
will keep it then, it's not huge deal :) just after read config we just call the read function again and let it read the import version instead and overwrite :3
",7551429
773,HPM Interface for login-server,open,2015-12-21T04:32:42Z,2017-02-19T07:13:44Z,,CONTRIBUTOR,"We've got login-server interfaced some time ago, however it's not yet fully interfaced and need more work.
","it's only an pointer inside the interface :)
you will be able to preview this update pretty soon, if i could survive for next hours ( pretty sick ).
the config update should be ready and will be pushed to login-server_rewrite branch :)
",7551429
774,[RE] Unable to Reproduce skill when Preserve is active,open,2015-12-19T08:41:39Z,2016-03-15T01:53:02Z,,CONTRIBUTOR,"In official you can copy skill when Preserve and Reproduce are active,
so it's possible to get 2 OF 1st or 2nd class skills at the same time.
Source: experience from idRO and iRO
",,7551429
775,changecharsex bug,open,2015-12-18T08:59:26Z,2016-07-25T05:20:59Z,,NONE,"Related: http://herc.ws/board/tracker/issue-8504-changesex/?gopid=24468#entry24468

Can anyone confirm this?

Step 1: make gypsy/clown and use the command 'changecharsex'
Step 2: Login again and you will get the error ""first character of profession is more than .. ...""
![4](https://cloud.githubusercontent.com/assets/4656578/11893081/9243b238-a5a8-11e5-8c9d-b593ec013cbb.jpg)

Im using 2015-05-13 client and 2014 10 22
","~Up~ 
",7551429
776,[RE] Wrong and missing item script list,open,2015-12-18T07:06:15Z,2019-07-29T17:50:52Z,,CONTRIBUTOR,"I've found many wrong and missing renewal item script in herc,
according kRO desc and 'Aegis' script : 

- [ ] [[1282](http://divine-pride.net/database/item/1282)] Krieger_Katar2 = should be crit damage +20% not ignore def rate (kRO and Aegis)
- [ ] [[1661](http://divine-pride.net/database/item/1661)] Mental_Destroyer = there is bonus based on refine level (Aegis)
- [ ] [[2126](http://divine-pride.net/database/item/2126)] Guyak_Shield = there are no autobonus, only bShortWeaponDamageReturn and bLongWeaponDamageReturn at 5% (kRO)
- [ ] [[2274](http://divine-pride.net/database/item/2274)] Ghost_Bandana = missing bonus2 bSubEle,Ele_Ghost,10; (kRO and Aegis)
- [ ] [[2936](http://divine-pride.net/database/item/2936)] Recovery_Ring = missing bMaxHP,250; bMaxHPrate,5; and bHealPower2,5; (kRO)
- [ ] [[2968](http://divine-pride.net/database/item/2968)] RWC_2012_Pendant = missing bMatkRate,1; (kRO)
- [ ] [[2969](http://divine-pride.net/database/item/2969)] RWC_2012_Pendant_ = missing bMatkRate,1; (kRO)
- [ ] [[5387](http://divine-pride.net/database/item/5387)] Neko_Mimi_Kafra = missing status effects (kRO and Aegis)
- [ ] [[5462](http://divine-pride.net/database/item/5462)] Spiked_Scarf = wrong item script, it's following iRO, should be bBaseAtk,30; and bonus bMaxHPrate,-2; (kRO)
- [ ] [[5463](http://divine-pride.net/database/item/5463)] Rainbow_Scarf = wrong item script, it's following iRO, should be bMatk,30; and bMaxSPrate,-2; (kRO)
- [ ] [[5467](http://divine-pride.net/database/item/5467)] Helm_Of_Dragoon = wrong item script, it's following euRO, refine level will add bExpAddRace,RC_Dragon (kRO)
- [ ] [[5469](http://divine-pride.net/database/item/5469)] Noble_Hat = wrong item script, it's following iRO (kRO)
- [ ] [[5497](http://divine-pride.net/database/item/5497)] King_Tiger_Doll_Hat = missing bAddRace,RC_Brute,10; and autobonus (kRO and Aegis)
- [ ] [[5579](http://divine-pride.net/database/item/5579)] Wanderer's_Sakkat = should delete bonus bAgi,2; (kRO)
- [ ] [[5580](http://divine-pride.net/database/item/5580)] Red_Beret = wrong item script, it's following euRO, should be bAllStats,3; and bMdef,3; (kRO)
- [ ] [[5595](http://divine-pride.net/database/item/5595)] Eye_Of_Juno = missing item script (Aegis)
- [ ] [[18528](http://divine-pride.net/database/item/18528)] Tare_Neko_Cru = missing item script (kRO)
- [ ] [[18540](http://divine-pride.net/database/item/18540)] Evil_Mask = missing bonus2 bSPLossRate,1,2000; (Aegis)
- [ ] [[18549](http://divine-pride.net/database/item/18549)] Nabi_Hair_Pin = wrong Aegis name, should be Butterfly_Hairpin, and has wrong script (Aegis)


There are still many wrong and missing item script that I haven't check.
if you need english desc for related item, you can check translation I made : 
 [iteminfo.lua](https://github.com/zackdreaver/ROenglishRE/blob/master/System/itemInfo.lua)
 ","kRO has changed cards 4684 to 4696 's script on Main server.
Each of them has different % and skill bonus now.

What you add right now are based on sakray server
",7551429
777,[Pre-Renewal] SP potion still works upon death,open,2015-12-16T11:04:55Z,2016-01-09T17:04:28Z,,NONE,"Bug: SP potion still works upon death if I spam it.

Example If I cast Asura Strike on a Paladin with Reflect Shield and spam SP Potion upon death I still have SP (depends on the amount of spammed sp pots)
![fenjxb0](https://cloud.githubusercontent.com/assets/4656578/11839325/d38f0fbc-a427-11e5-8bf1-39f6571090a0.jpg)
","Is this really a bug? I have been trying to reproduce it, but all I see is this order of events:
1. Asura Strike cast (goes off, target is damaged)
2. All SP drained, because of 1.
3. Blue Potion restores SP, amount depending on number used before
4. reflect / other damage occurs, and being checked against player's health to decide that
5. Player dies; Blue Potion can no longer be used and hence SP restoration stops

I haven't tried suiciding against a Reflect Shield, but instead running a naked char into MVPs. To me, it seems to be a case of ""working as intended"", unless someone wants to test this on official servers? But I doubt the Reflect Damage effect is instant even there, as there must always be a delay in an ability that is reactive by nature.

PS: I faintly... very faintly... remember this being similar on the old official EuRO servers. Don't quote me on that, though.
",7551429
778,"5 secs invulnerability  on positive/negative ""targeted"" skills",open,2015-12-16T05:40:21Z,2015-12-20T22:27:34Z,,NONE,"in Official there are no 5 secs invulnerability on positive/negative targeted skills.

~ In Hercules upon respawning there is a 5 secs invulnerability.
~ In Official you will be affected by targeted skills (example Dispell, Absorb Spirit Sphere etc.) once you respawn without 5 secs invulnerability as long as the skill has no damage.
","Or make configuration in conf

invulnerability_target_skill: 5000 // in milliseconds
",7551429
779,5 secs invulnerability on positive/supportive AOE buff,open,2015-12-16T05:22:00Z,2015-12-20T22:27:47Z,,NONE,"In Official the moment you respawn any AOE positive buffs on ground will take effect on you while in Hercules you need to wait 5 secs until the buffs take effect.
","sorry for the confusion, I edited my 1st post

In Official the moment you respawn any AOE positive buffs on ground will take effect on you while in Hercules you need to wait 5 secs until the buffs take effect.
",7551429
780,Self Destruction Skill,open,2015-12-15T10:43:35Z,2015-12-28T19:57:02Z,,CONTRIBUTOR,"there a problem on self destruction skill
just the same on this link
https://rathena.org/board/tracker/issue-8941-problem-in-self-destruction-skill/
","This is a problem with unsigned variables. They're generally tricky to use (unless one understands very well what their use implies), and, considering there are very little benefits in using them, we should refrain from using unsigned variables everywhere.

While it's possible to work around this specific issue, my advise is that we change various variables to signed, so that code maintenance becomes easier.

I understand this is a very controversial topic but changing a variable to unsigned to increase its range is rarely a good idea (it's usually better to just increase its size), just how it is very wrong to define a variable as unsigned to simply document that it won't be negative (assertions should be used for that).
The only places where unsigned variables should be used are in bitmasks and when bit-shift operations are to be used.
",7551429
781,Correct item type 11 to be Restricted usable item type.,open,2015-12-14T19:20:42Z,2018-03-20T22:13:34Z,,CONTRIBUTOR,"Now this type gonna make the usable item not usable on sit/mount and not
delayed consumer anymore.
to make an item delayed consumer you have to use KeepAfterUse option.

Current Tasks to be done before merge :
- [x] Source Edit
- [x] Check all items in database to make sure all items that should be delayed updated
- [ ] Update Wiki  And inform community

Correct issue #888 
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/953)
<!-- Reviewable:end -->
",7551429
782,Strange issue with area and splash skills,open,2015-12-14T01:01:27Z,2016-01-27T10:58:25Z,,NONE,"Right now, some skills trigger the animation for every affected target, saturating the screen and possibly causing performance issues such as fps drops, input delay, etc.
Further investigation is needed.

This was introduced with these two commits some time ago:

https://github.com/HerculesWS/Hercules/commit/027f124cbb96bb99d00bc31ad51345024edadf66
https://github.com/HerculesWS/Hercules/commit/aaa82f2f8fb70858048d1e199b40bbb797b9604d

To illustrate this issue better; 
Make a Rune Knight for example and use Ignition Break or Wind Cutter without any targets in range, the animation is triggered correctly in this case. Now spawn a target in range and use them again, you will notice that the animation is now triggered twice at once, overlapping. Now spawn many targets and try again, the animation will replicate and overlap for every affected target, saturating the screen.
This doesn't affect all skills handled under that block though and seems inconsistent.

This might also happen to support skills in some cases.
","I'm not really sure how these two commits could have an effect on what you describe... I know that some client update messed up the skill display though...

In any case, I think this probably needs a list of skills that need to be checked, because it's kind of a skill-by-skill issue.
",7551429
783,When creating name of character,open,2015-12-13T06:05:27Z,2015-12-15T12:20:09Z,,NONE,"Note: If your char-server.conf config is disabled symbols

Official response: This server provides English Text Characters Only.
its use msgstringtable.txt line 191 https://github.com/zackdreaver/ROenglishRE/blob/master/data/msgstringtable.txt#L191

![official1](https://cloud.githubusercontent.com/assets/4656578/11765773/f55222ac-a1a1-11e5-92c4-0a4801cba435.jpg)

Hercules: Character Creation is denied.
![herc1](https://cloud.githubusercontent.com/assets/4656578/11765774/01bcc7ea-a1a2-11e5-9b31-875421efdd08.jpg)
![herc2](https://cloud.githubusercontent.com/assets/4656578/11765775/0811a71e-a1a2-11e5-9044-1a98679a07e1.jpg)
","the line below is even senseless
when `char_name_option` is 2, it should disable creating character with `char_name_letters` included
means I can only create character with symbols
but when I really create a character like 'annie' it throw error as `Symbols in Character Name are forbidden`
or ... maybe it was meant for them to edit .... to include symbols
",7551429
784,Sleeping monster still can continue attacking.,open,2015-12-12T13:42:06Z,2016-01-27T11:20:51Z,,MEMBER,"The monsters still can continue to attack the players when sleep status is casted on the monsters.

But, if i walk away from the monsters and return to them, it will not attacking because they're still under sleep status.

Skill used : Goodnight, Sweetie from Angra Manyu (item id: 1599).

![Image of Yaktocat](http://i.imgur.com/NoYqSPO.gif)
","If it was just a client issue, why are there damage numbers in the GIF? They can only be calculated by the server. So seems that the monster still keeps attacking.

Unlike PC, monster don't actually have any checks if they can attack, the only reason they don't is because their AI becomes lazy.

In ""status_change_start"" you need to call unit->stop_attack on SC_SLEEP, but that's already in the code on Herc. So I assume why it doesn't work is because you don't actually call status_change_start at all or it returns too early.

``` c
    // Abnormalities
    if(( md->sc.opt1 > 0 && md->sc.opt1 != OPT1_STONEWAIT && md->sc.opt1 != OPT1_BURNING && md->sc.opt1 != OPT1_CRYSTALIZE )
      || md->sc.data[SC_DEEP_SLEEP] || md->sc.data[SC_BLADESTOP] || md->sc.data[SC__MANHOLE] || md->sc.data[SC_CURSEDCIRCLE_TARGET]) {
        //Should reset targets.
        md->target_id = md->attacked_id = 0;
        return false;
    }
```

Also need to make sure that md->sc.opt1 > 0, but that's also correctly set in status.c already.
",7551429
785,Message BUG,open,2015-12-12T10:34:24Z,2016-01-19T16:09:31Z,,NONE,"Hi,
`message strcharinfo(0),""Text"";`
Actually have the same behaviour of
`dispbottom ""Text"";`
-> message in the first case is not displayed above the head. (2014-10-22bRagexe).

Problem with packets?
","Anyone got to know the pattern?
",7551429
786,SC_LEECHESEND inflicted through UNT_POISONSMOKE,open,2015-12-12T08:02:02Z,2015-12-30T08:18:12Z,,NONE,"The damage dealt is extremely low in this case, looks like the calculation isn't being applied.

To make this more clear, the damage is correct when the poison is inflicted with GC_VENOMPRESSURE or normal hits, but when done though GC_POISONSMOKE the damage is extremely low.
",,7551429
787,pcre_match can't do wildcard using bracket expression,open,2015-12-11T16:45:57Z,2015-12-25T14:56:25Z,,CONTRIBUTOR,"```
prontera,159,183,5  script  pcre_match  1_F_MARIA,{
    input .@t$;
    if ( ""^[a-z]$"" ~= .@t$ )
        npctalk ""It's a ""+ $@regexmatch$[0];
    close;
L_1:
    npctalk ""It's a ""+ $@p2$;
    end;
OnInit:
    defpattern 1, ""^[^:]+: (\\|\\d{2})?([a-z]).$"", ""L_1"";
    activatepset 1;
    end;
}
```

defpattern works fine, can accept any 1 character from abcdef...xyz
but pcre_match is weird, can only accept 3 characters, which is a,z,-

on a side note, for defpattern, although in this script written as a-z, but it also accept A-Z
case sensitive is ignore in defpattern
","Adding #1019 as prerequisite for this
",7551429
788,SC_SPELLFIST and SC_LEXAETERNA,open,2015-12-11T00:14:18Z,2016-03-15T01:50:05Z,,NONE,"There's no damage boost yet the status is removed, considering that hits with this status are coded to be treated like normal attacks, this is pretty strange.
",,7551429
789,Changed avg_increment formula,open,2015-12-10T15:27:22Z,2018-03-20T22:13:30Z,,MEMBER,,"

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/929)
<!-- Reviewable:end -->
",7551429
790,hp sp calculation issue,open,2015-12-07T15:30:38Z,2016-03-15T01:49:52Z,,NONE,"Currently, the bMaxHPrate and bMaxSPrate do not apply to bonus Vit and Int from status (SC_FOOD_VIT and etc.), while the bonus from equipment does not have this issue.
","Actually I have checked the code in calculating maxhp, the calculation ... seems weird.
Another issue is the multiplicative calculation for the status bonus max hp rate.
For example, the first half part of the code is

``` javascript
unsigned int status_calc_maxhp(struct block_list *bl, struct status_change *sc, uint64 maxhp)
{
    if(!sc || !sc->count)
        return (unsigned int)cap_value(maxhp,1,UINT_MAX);

    if(sc->data[SC_INCMHPRATE])
        maxhp += maxhp * sc->data[SC_INCMHPRATE]->val1/100;
    if(sc->data[SC_INCMHP])
        maxhp += (sc->data[SC_INCMHP]->val1);
    if(sc->data[SC_MTF_MHP])
        maxhp += (sc->data[SC_MTF_MHP]->val1);
    if(sc->data[SC_APPLEIDUN])
        maxhp += maxhp * sc->data[SC_APPLEIDUN]->val2/100;
    if(sc->data[SC_DELUGE])
        maxhp += maxhp * sc->data[SC_DELUGE]->val2/100;
    if(sc->data[SC_BERSERK])
        maxhp += maxhp * 2;
    if(sc->data[SC_MARIONETTE_MASTER])
        maxhp -= 1000;
    if(sc->data[SC_SOLID_SKIN_OPTION])
        maxhp += 2000;// Fix amount.
    if(sc->data[SC_POWER_OF_GAIA])
        maxhp += 3000;
    if(sc->data[SC_EARTH_INSIGNIA] && sc->data[SC_EARTH_INSIGNIA]->val1 == 2)
        maxhp += 500;
    if(sc->data[SC_MER_HP])
        maxhp += maxhp * sc->data[SC_MER_HP]->val2/100;
    if(sc->data[SC_EPICLESIS])
        maxhp += maxhp * 5 * sc->data[SC_EPICLESIS]->val1 / 100;
    if(sc->data[SC_VENOMBLEED])
        maxhp -= maxhp * 15 / 100;
    if(sc->data[SC__WEAKNESS])
        maxhp -= maxhp * sc->data[SC__WEAKNESS]->val2 / 100;
    if(sc->data[SC_LERADS_DEW])
        maxhp += sc->data[SC_LERADS_DEW]->val3;
    if(sc->data[SC_BEYOND_OF_WARCRY])
        maxhp -= maxhp * sc->data[SC_BEYOND_OF_WARCRY]->val4 / 100;
    if(sc->data[SC_FORCEOFVANGUARD])
        maxhp += maxhp * 3 * sc->data[SC_FORCEOFVANGUARD]->val1 / 100;
    if(sc->data[SC_INSPIRATION])
        maxhp += maxhp * 5 * sc->data[SC_INSPIRATION]->val1 / 100 + 600 * sc->data[SC_INSPIRATION]->val1;
    if(sc->data[SC_RAISINGDRAGON])
        maxhp += maxhp * (2 + sc->data[SC_RAISINGDRAGON]->val1) / 100;
```

Please notice that the input maxhp has already taken the effect from bMaxHPrate on equipment.
So if one has 100 maxhprate from equipment, and he gets SC_FORCEOFVANGUARD, SC_RASINGDRAGON, SC_EPICLESIS (all val1 is assumed to be 5).

Instead of 1 + 100% + 25% + 15% + 12% = 252%
It ends up with
(1+100%)_(1+25%)_(1+15%)*(1+12%) = 322%
It is a huge difference! Is this multiplicative behavior official?
",7551429
791,Random Start Point,open,2015-12-07T00:02:27Z,2017-04-10T10:59:54Z,,CONTRIBUTOR,"Fix issue #007750 (from old tracker)

<!-- Reviewable:start -->
---
This change is [<img src=""https://reviewable.io/review_button.svg"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/913)
<!-- Reviewable:end -->
",@Asheraf can you also confirm if the start point is different or the same? I don't remember starting on different maps with a novice on kRO.,7551429
792,"""Please don't forget me"" skill affect self",open,2015-12-02T16:18:50Z,2016-01-09T12:52:18Z,,CONTRIBUTOR,"can somebody confirm this ?
DC_DONTFORGETME skill shouldn't reduce the movement speed on dancer itself,
but on hercules it can affect self

there are also some other problem like .. `@allskill` doesn't give all skills for dancer

PS: I made sure to disable all plugins to confirm this issue
","@AnnieRuru just tested the skill Dont Forget Me in Aegis, and we got equal behavior. Im not sure in Pre-renewal if the speed affects the caster.
",7551429
793,Anti Element and Anti Race not working,open,2015-12-02T11:45:26Z,2015-12-20T05:37:47Z,,CONTRIBUTOR,"Hello,

I noticed that SC_PROVIDENCE not reducing the attacks of Holy monsters, and also the Geffen Scrolls not increasing its damage on a Boss, Holy, and Angel monsters. 

@AnnieRuru confirmed this already, please confimed @dastgir @MishimaHaruna @4144 

PRE-RE and RE, both aren't working.
","```
prontera,155,185,5  script  kjsdhfdksfj 1_F_MARIA,{
    sc_end SC_DISTRUCTIONSCROLL;
    getitem Destruction_Scroll, 1;
    monster ""this"", -1,-1, ""--ja--"", ARCHANGELING, 1, """";
    end;
}
```

before the typo fix
76675->101857
after the typo fix
76675->101857

eh ? how come suddenly its fixed even without that typo ?
I remember that time I tested, it didn't increase the damage

and ... its 32% increase damage LOL

now test on pre-renewal
65912->87728
33% increase damage ....

huh ?

~~I'm so confused now~~
EDIT: previously I tested with T_ARCHANGELING =.=
now yeah, both re and pre-re also 33% increase
",7551429
794,HP/SP Table,open,2015-11-30T18:05:49Z,2015-12-10T15:14:32Z,,MEMBER,"- [ ] avg increment have some problem: I guess somewhere problem lies in avg_increment which is int, so for current avg_increment is calculated as (460-13)/149(Taking Merchant as example) which is ~2.98, but as its int, it will be stored as 2 , so each avg_increment loses much of its sp part.
- [x] InheritSP:
  Missing base addition in
  status->dbs->SP_table[idx][i] = min(avg_increment \* i, battle_config.max_sp);
- [x] SPTable and HPTable,
  The level starts from 0, shouldn't that start from level 1?
","uhm,, is there a way to like have the server just read the HP/SP table under the job_db.txt?? instead of calculating it?? like if manually put these under Rune Knight:

```
HPTable:[  40,    48,    58,    69,    82,    96,   112,   129,   148,   168,   // 1 - 10
           190,   213,   238,   264,   292,   321,   352,   384,   418,   453,  // 11 - 20
           490,   528,   568,   609,   652,   696,   742,   789,   838,   888,  // 21 - 30
           940,   993,  1048,  1104,  1162,  1221,  1282,  1344,  1408,  1473,  // 31 - 40
          1540,  1608,  1678,  1749,  1822,  1896,  1972,  2049,  2128,  2208,  // 41 - 50
          2290,  2373,  2458,  2544,  2632,  2721,  2812,  2904,  2998,  3093,  // 51 - 60
          3190,  3288,  3388,  3489,  3592,  3696,  3802,  3909,  4018,  4128,  // 61 - 70
          4240,  4353,  4468,  4584,  4702,  4821,  4942,  5064,  5188,  5313,  // 71 - 80
          5440,  5568,  5698,  5829,  5962,  6096,  6232,  6369,  6508,  6648,  // 81 - 90
          6790,  6933,  7078,  7224,  7372,  7521,  7672,  7824,  8100,  8133,  // 91 - 
```

it would just read it ??
",7551429
795,rAthena-main-upgrade.sql and rAthena-logs-upgrade.sql outdated !,open,2015-11-29T14:20:09Z,2016-03-15T01:47:55Z,,NONE,"Please update these file, me and lot of people want to convert rathena to hercules but the sql upgrade too old !

Thank all so much !
",,7551429
796,Clear up misunderstanding by changing SZ_ constant into MOBSIZE,open,2015-11-24T18:31:36Z,2018-05-06T20:58:03Z,,CONTRIBUTOR,"- [x] change SZ_ constant into MOBSIZE_
- [x] change the rest into UNITSIZE_
- [x] add setcharsize and getcharsize script command (YIPPEE!!)
- [ ] confirm SC_GS_GATLINGFEVER dealing different damage to which size ?
- [ ] estun can deal full damage to small size mobs ?
- [ ] what is the damage formula for NC_ARMSCANNON dealing damage to which size of monster ?

yes I know the 1st patch is bug ... wait till I do the 2nd one
","

<!-- Reviewable:start -->
This change is [<img src=""https://reviewable.io/review_button.png"" height=""34"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/895)
<!-- Reviewable:end -->
",7551429
797,Monster size,open,2015-11-24T11:13:46Z,2016-03-15T01:47:32Z,,MEMBER,"1) SZ_MEDIUM is handled as small monster on the source

2) mob_db says

```
Size: size                            (int, defaults to 1)
```

but default value is 0 in the source.
@4144 
","reference no.3
http://herc.ws/board/topic/7219-character-npc-are-small-by-default-issue
this was how Mumble screw it up last time, I hope I'm not going to repeat the same tragedy
",7551429
798,Problem with the Warlock Summon Balls,open,2015-11-24T08:16:16Z,2016-03-15T01:47:19Z,,NONE,"When a warlock use one of the Summon balls skills, there's no limit to the balls summon.
At lvl 1, players are able to summon up to 5 balls, instead of 1 per level.
",,7551429
799,Item usable with delayed consumption (Type 11),open,2015-11-21T01:49:08Z,2017-02-19T07:13:44Z,,NONE,"On Official the number of item should be lessen upon clicking or using it on the target . However when clicking it, the number of item doesnt change until it is successfuly casted on the target.

Bug tracker: http://herc.ws/board/tracker/issue-5966-item-usable-with-delayed-consumption-item-scroll/?gopid=10219#entry10219
","Bump
",7551429
800,Mdef effect on official servers.,open,2015-11-20T14:56:25Z,2016-03-15T01:45:37Z,,CONTRIBUTOR,"https://github.com/rathena/rathena/issues/693

@MishimaHaruna @4144 @kyeme @dastgir @AnnieRuru take a look on this.
","I have to correcting something here
1. It's not only MDEF, there are STR, AGI, VIT, DEX, LUK, Element, MHP, MSP
2. If it went to @AnnieRuru sample, it may works 'official' feature that Hercules has, by using map zone, there is DISABLE_ITEM thing to block item. Beside, there are more than 2000 items that have 'absolute' parameters.
3. By using libconfig item_db, it'll be easy to add more fields for those parameters, or add script field.
",7551429
801,Spell Breaker,open,2015-11-19T18:38:59Z,2016-10-13T01:48:00Z,,NONE,"In aegis the skill SA_SPELLBREAKER applies damage when used on target.

Link post: http://herc.ws/board/tracker/issue-8457-spell-breaker/?gopid=24195#entry24195
","@MishimaHaruna @hemagx 

Someone looking at this.
",7551429
802,Visual Bug with Taekwon's Sprint,open,2015-11-18T10:41:19Z,2016-03-15T01:44:12Z,,NONE,"Good day everyone.

Scenario:
I found a problem with Taekwon's Sprint or Running skill. It appears to be FINE if you are the one using this skill. You will see your character Running at constant speed in one straight direction.

Problem:
However when someone else sees you using the Running or Sprint skill, it appears that you are TELEPORTING or BODY RELOCATING. Your character suddently blinks on the final stop cell of the running skill. Again, it will appear fine on your end if you're the one using the skill. But to someone else seeing you, that's where the problem is.

The downside of this bug is that, while you are running, players are unable to 'see' you nor will be able to stop you from Running. You'll be able to dodge a lot of targetting skills since people won't be able to target you.. Please have this checked. Thanks

Client ver: 2014-02-05
I'm using the latest SVN. 
","Oops yea I forgot, added my client ver. I'm using the latest svn.
",7551429
803,Visual Bug with Devotion,open,2015-11-17T21:14:43Z,2018-05-18T23:34:58Z,,NONE,"Sometimes when you Devotion a character, the line that is showing that you're under devotion is not present. 
The Information known so far are:
1. It occurs on a random character.
2. The issue is permanent with the character, and only that character in the account.
3. The issue cannot be replicated intentionally (even after 100 tries).
4. Not confirmed with Crusader or Paladin - Only Royal Guard

Unfortunately, no screenshots for this as you'll just see nothing but the damage being passed on to the Royal Guard when the devoted character is in Devotion range.
It could be an issue as we don't know when to refresh the skill.
Anyone has similar issue?
",@Megasantos thank you so much. Now the effect of devotion skill appears correctly. I was using account_id 30000000 and above,7551429
804,Pre-Renewal: When Talking to NPC,open,2015-11-13T16:35:10Z,2015-11-17T19:48:32Z,,NONE,"On Ofifcial pre-renewal you can use usable items and self skills (Energy Coat, Sight etc..) while talking to NPC. 
","+1 for this
",7551429
805,CR_ACIDDEMONSTRATION and ASC_BREAKER reduction calculations,open,2015-11-08T16:53:03Z,2016-03-15T01:43:26Z,,NONE,"The whole thing is pretty strange, it seems like Demihuman reductions apply twice due to the skills having two parts (ATK and MATK) even though it's all md in the end. Soft and hard DEF/MDEF also seem to have a multiplied effect. CR_ACIDDEMONSTRATION also does absolutely absurd damage if no reductions are involved yet falls down to triple digits with basic reductions.
",,7551429
806,Skill is blocked until the server restart,open,2015-11-07T16:57:54Z,2016-03-15T01:43:14Z,,NONE,"Hi, I have encountered some timer_do_delete error, when this happens to skill_blockpc_end, the player cannot use a certain skill (have seen it on RA_ARROWSTROM and SR_RAISINGDRAGON) until the server restart.
I have no idea how to reproduce it, it just randomly happens once per a few days, and there will be an error message like

```
timer_do_delete error: function mismatch 00606501 (unit_walktoxy_timer) != 00603824 (skill_blockpc_end)
```

My version is d2e3acb.
Since it is really rare, happens once ~ twice per week with tens of online players, so I cannot test it myself with the latest version, but I have not seen any changes related to this issue recently.
This problem makes the player very frustrated, and I have to restart the whole server to help him/her. 
Any idea about how to solve or track this issue will be greatly appreciated.
","thx for this info, it is really helpful
",7551429
807,no farrah npc + WoE Supply Box not working,open,2015-11-07T01:17:41Z,2019-07-30T07:42:45Z,,NONE,"Hello..

Where's the WoE supply girl? The one that let you exchange WPS tokens for WoE supplies?

its not in prontera

and i think there is problem with this item http://ratemyserver.net/index.php?page=re_item_db&item_id=12582

i think its from item script
","if i recall correctly, [only iRO is using the WPS token](https://irowiki.org/wiki/WoE_Point_System), but they [removed it many years ago](https://forums.warpportal.com/index.php?/topic/9682-the-end-of-the-wps-system-as-we-know-it/).
",7551429
808,pdef2 flag (Ice Pick/Thanatos Card) and critical attacks,open,2015-11-06T03:43:34Z,2016-03-15T01:42:36Z,,NONE,"Currently the damage of crits is decreased instead.
","Yeah, this did the trick.
",7551429
809,"getvariableofnpc is messy, why not .'npc'.var ?",open,2015-11-04T08:51:31Z,2017-05-27T15:49:22Z,,CONTRIBUTOR,"I'm sure many of you experienced using `getvariableofnpc` script command will make your script looks messy
so, how about I suggest using `.'npc'.var` instead ?

```
set getvariableofnpc( ""start"", .capturedamount ), getvariableofnpc( ""start"", .capturedamount ) +1; // old
.'start'.capturedamount++; // new
set getvariableofnpc( ""start"", .capturedid ), getvariableofnpc( ""start"", capturedid ) | (1<<.@flagid); // old
.'start'.capturedid |= 1 << .@flagid; // new
```

looks cleaner, right ???
# 

there are 3 reasons why it is `.'npc'.var` and not `.'npc'var`

reason no.1
`.'` <-- start the operation for getvariableofnpc
`'npc'` means another npc, and `.var` means a npc variable, and `var` means a player variable
if it were look like `.'npc'var`, it somehow read as another npc's player variable ...
ok even if you say it is possible, there is another reason

reason no.2
npc name can contain `'` or `''` single quotation or double quotation
`prontera,100,100,5   script   AnnieRuru's ~Poring~ PORING,{`
tested, it shows this npc name
if it were `.'npc'var` kind of format, server will read `s ~Poring~` and throw error

reason no.3
this format looks nice in Notepad++ :-)

_PS: can I add tag: enhancement on this ?_ :D
","My goals are:

- Constants should always be un-prefixed, they must be the easiest to use, and must match the Aegis ones where possible (item's AegisNames for example)
- I don't care whether the other variables are prefixed (as long as we don't have half a dozen different prefixes to mean different variable types like it happens right now)
- I want to be able to show an error at parse time in case of a typo in a variable or constant name, or if an used constant is unavailable (missing item in the item db for example). This means that, if we allow other types of variables to stay unprefixed, we'll want to enforce variable declaration before use. This is my top requirement.

The retrieve/store approach makes things much simpler (nothing is saved unless explicitly said), but it might be annoying for scripters. The good part is that it would discourage the use of permanent variables unless they are needed.

",7551429
810,Body Relocation + Sit = Cell Bug,open,2015-11-02T11:15:09Z,2017-02-19T16:53:15Z,,NONE,"Original Topic by Zirius: http://herc.ws/board/tracker/issue-8489-body-relocation-sit-cell-bug/?gopid=24396#entry24396

I am using pre-RE

There seems to be 3 bugs arising from this, and all of them seems to be affecting on how the client perceive where the players's position are.
1. The caster's final position after using body relocate + sit is not getting updated to the client of the caster, but is getting updated to the others.
- The reason why the player in the video keep asking that he is getting detected by my Ruwach even though he is NOT where I am using the Ruwach
1. The caster's final position after using body relocate + sit is not getting updated to the other players, but is getting updated to the caster.
2. The reason why the caster knows where should I use Ruwach instead of where I thought I have him in my screen
3. The final position of the caster who use body relocate + site is not getting updated to the caster and to the other players.
4. The reason why (at the last part) when he casted asura on me, we both said ""he jumped/flew"", so we both perceive that he is not actually beside me.

The video can be downloaded here:
https://www.mediafir...1tuj13diu0xrh4m

This bug seems to be well known on most private servers since a player from other private server told this to me. LOL. They are calling it ""cell bug"".

Video: https://youtu.be/BihyM5pOSwI
","Well, this is just a visual glitch, and it also happens on official servers. It's probably possible to work around it, but someone needs to sit, come up with a decent implementation proposal and test it, then submit it. Whether I will is unknown (but unlikely), since there are many other things in my backlog that have higher priority than this (in general, if something involves the client, I tend not to do it, since testing something that I need the client for, is extremely annoying to set up).

Now, in response to the last comments (that really disappointed me by the way), why do you expect people to do things for you (and for free) when you want them to and how you want them to? Want this fixed quickly? Fix it and submit the fix, or pay someone to do so. Or wait for someone to fix it out of their own goodwill, but in that case you can't pressure them to do so. Documentation sucks? I know that much. I wrote some, but my lifetime won't be enough to write all the documentation that you wish we had. Does it bother you? Submit some documentation then.

On a side note, although many people are here for money, or to build a fame they can then sell on the market (who am I to blame them? FIY, people need food to live, there are many people that revolve around the Hercules community and are unemployed), that isn't true for everyone. I never took one dollar here, and I don't want anyone's stinky money. But don't mistake me, I'm not here for sheer altruism either (who would be so stupid? Investing thousands of hours on something for no reason?), I'm here because I want Hercules to work reasonably well (perhaps so that I can use it for myself for example?), and I invest my time on it so that it keeps working well, and to fix the things that don't. Although, out of all the bugs that Hercules has (and it has many, along with years and years of spaghetti code that was added without ever taking a break to do some review or planning), why do you think that YOU get decide which ones take priority?

I'm locking this issue for the time being, since it got completely out of hands. If anyone wants to add anything, feel free to open a pull request, and mention this issue ID.",7551429
811,(default server misconfiguration) Skill range bypass: 14 cells skills usage,open,2015-10-31T05:36:52Z,2016-06-26T12:51:13Z,,NONE,"Just a followup to this issue:

http://herc.ws/board/tracker/issue-8302-potnd-bypass-range-skill-delay/

This bug is still existent in the present build of Hercules ( and rathena too! ) but not on any eathena servers.

How to reproduce:

1 - Record packet via WPE / RPE.
2 - Send the recorded packet.
3 - Try to send the packet outside the range of skills.

NOTE: If you followed the temporary fix on the link above...it would only fix the vertical and horizontal range of the skill..but if you try the diagonal way - the bug still persists! I have a screenshot of a guild abusing this, please see screenshot below:

http://i.imgur.com/TPmzNxt.jpg

As you can see, their guild programmer made a program that modify the client binaries to prevent the client from sending the move packet when using skills...that's why it turns out to be behaving like it's only sending packets without moving - and the bug shows up! Notice how he is casting dispell outside the correct range. Please fix this, a cheat that is on its way on becoming famous is abusing it ( xrag ) and its not healthy for the competitive WoE community and the whole RO community in general.
","Don't worry @Keysito nobody will fix bugs posted by me above. You will not find any motivated and experienced guy with a lot of time for developing complete product and for supporting this product for next 2-3 years. I'm talking about server-client side protection, where around 99% checks should be done at server-side (yes, it will be heavy CPU application).

#### For people who will try to fix problems above:

You can do that. Because mostly all cheaters with whom i have contacts in past - newbies, and not professional developers, they just know several tips and tricks, and nothing more, and time to time they are using solutions developed by really smart asians (japanese / chinese guys). But even with them nobody can fight, because of luck in motivation. 
",7551429
812,server randomly crash,open,2015-10-28T10:48:41Z,2018-07-26T06:03:51Z,,NONE,"I dont know how to reproduce this one, cannot figure it out where is the problem

<quote>
(gdb) bt full
#0  bl_getall_area (type=27, m=<optimized out>, x0=83, y0=67, x1=103,

```
y1=<optimized out>, func=func@entry=0x4f3880 <bl_vgetall_inrange>)
at map.c:662
    args = {{gp_offset = 48, fp_offset = 48,
        overflow_arg_area = 0x7fffffffda58,
        reg_save_area = 0x7fffffffd960}}
    bx = 11
    by = <optimized out>
    bl = 0xfdfdfdfdfdfdfdfd
    found = 1
```
#1  0x0000000000500fcb in map_vforeachinrange (

```
func=0x5124a0 <mob_ai_sub_hard_activesearch>, center=<optimized out>,
range=<optimized out>, type=<optimized out>, ap=0x7fffffffdab8)
at map.c:739
    returnCount = 0
    blockcount = 9
    apcopy = {{gp_offset = 32, fp_offset = 48,
        overflow_arg_area = 0x7fffffffdb90,
        reg_save_area = 0x7fffffffdad0}}
```
#2  0x00000000004f7a8b in map_foreachinrange (func=<optimized out>,

```
center=center@entry=0x7fffed14ef24, range=range@entry=10,
type=<optimized out>) at map.c:765
    returnCount = -515
```

</qoute>

another from console

![screenshot_2015-10-28-11-23-11-1](https://cloud.githubusercontent.com/assets/4579493/10786424/adf98ebe-7d9c-11e5-95f6-dc32e90be64f.png)
",,7551429
813,Check bot incomplete,open,2015-10-27T14:30:17Z,2015-11-17T19:23:09Z,,NONE,"I was looking in I noticed a packet that char.c is not implemented yet. I wonder if it is not possible in hexed kro or if it was forgotten?

code char.c :

```
        // captcha code request (not implemented)
        // R 07e5 <?>.w <aid>.l
        case 0x7e5:
            chr->parse_char_request_captcha(fd);
            break;

        // captcha code check (not implemented)
        // R 07e7 <len>.w <aid>.l <code>.b10 <?>.b14
        case 0x7e7:
            chr->parse_char_check_captcha(fd);
        break;
```

packets:

```
// packet 0x7e5
struct PACKET_CH_ENTER_CHECKBOT {
    /* this+0x0 */ short PacketType
    /* this+0x2 */ short PacketLength
    /* this+0x4 */ unsigned long dwAID
    /* this+0x8 */ char szStringInfo[...]
}

// packet 0x7e7
struct PACKET_CH_CHECKBOT {
    /* this+0x0 */ short PacketType
    /* this+0x2 */ short PacketLength
    /* this+0x4 */ unsigned long dwAID
    /* this+0x8 */ char szStringInfo[24]
}

// packet 0x7e8
struct PACKET_HC_CHECKBOT {
    /* this+0x0 */ short PacketType
    /* this+0x2 */ short PacketLength
    /* this+0x4 */ unsigned char img[...]
}

// packet 0x7e9
struct PACKET_HC_CHECKBOT_RESULT {
    /* this+0x0 */ short PacketType
    /* this+0x2 */ short PacketLength
    /* this+0x4 */ unsigned char Result
}
```
","On 2015-02+ clients there's 2 more packets
REQ_BOT_CU and
ACK_BOT_CU (something like that)
",7551429
814,Item Skill Scroll not working properly,open,2015-10-24T02:50:13Z,2015-11-17T10:57:22Z,,CONTRIBUTOR,"Follow up! XD

http://herc.ws/board/tracker/issue-7739-item-skill-scroll-not-working-properly/
",,7551429
815,Desperado reflected by equipment's bShortWeaponDamageReturn,open,2015-10-20T09:39:25Z,2015-11-17T10:56:00Z,,CONTRIBUTOR,"```
skill_attack => battle_calc_attack()
...
    if( wd->flag & BF_SHORT ) {
        if ( tsd && tsd->bonus.short_weapon_damage_return ) {
            NORMALIZE_RDAMAGE(damage * tsd->bonus.short_weapon_damage_return / 100);
```

This will process on all sources of short-range weapon damage, including land skills. The only reason most skills (like Arrow Shower or Demonstration) don't have this happen is because their 'range' is taken from the originating skill's casting distance for some reason, making their attack BF_LONG. Some skills, like Desperado and Flip Tatami, do stay short range and they do trigger the damage reflect.

Now for the fun part. On aegis, flip tatami gets reflected, but desperado doesn't. It's probably an implementation-specific thing, might have to add an exception for that skill. If you look at the lines after the abovementioned code, the handling of shield reflect does include an exception for desperado.
",,7551429
816,Shadow Item Switching equip,open,2015-10-20T06:02:24Z,2016-03-15T01:37:23Z,,NONE,"Equipped with two-handed weapons (ex: bow) switches the EQP SHADOW WEAPON items.

Two-Handed option disappears.
","```
{
    Id: 1702
    AegisName: ""Bow_""
    Name: ""Bow""
    Type: 4
    Buy: 1000
    Weight: 500
    Atk: 15
    Range: 5
    Slots: 4
    Job: 0x000A0848
    Loc: 393216
    WeaponLv: 1
    EquipLv: 4
    View: 11
},
```

equip this item ID 1702
my client doesn't show it actually equip a bow in shadow part ....
and then I make another knife ID 1202 as shadow

```
{
    Id: 1202
    AegisName: ""Knife_""
    Name: ""Knife""
    Type: 4
    Buy: 50
    Weight: 400
    Atk: 17
    Range: 1
    Slots: 4
    Job: 0x228F5EEF
    Loc: 131072
    WeaponLv: 1
    View: 1
},
```

equip it and client crash ...
",7551429
817,Neutral barrier and Stealth Field dont work on portal,open,2015-10-20T01:16:30Z,2016-03-15T01:36:39Z,,NONE,"Neutral barrier and Stealth Field is disabling when crossing the map portals, the correct would it stay active , your animation is getting stuck in the previous portal. 
https://www.youtube.com/watch?v=4vUJk7pydMo
",,7551429
818,mineffect,open,2015-10-17T13:34:20Z,2017-11-25T23:34:03Z,,NONE,"The commit 75444c7 has been implemented incorrectly, the status applied is not the lesseffect, the correct status is mineffect.

Link Hercules: http://herc.ws/board/tracker/issue-7868-mineffect/
",bump @MishimaHaruna @4144 ,7551429
819,Guild Aura,open,2015-10-13T05:22:16Z,2017-06-13T13:31:27Z,,NONE,"// Guild Aura Skills setting (add as appropriate).
// (This affects GD_LEADERSHIP, GD_GLORYWOUNDS, GD_SOULCOLD and GD_HAWKEYES)
// Note that for the skill to be usable at all, 
// you need at least one of 1/2 and 4/8
// 1: Skill works outside of woe.
// 2: Skill works during woe.
// 4: Skill works outside of GvG grounds
// 8: Skill works on GvG grounds
//16: Disable skill from affecting Guild Master
guild_aura: 31

The guild aura is not working on PVP maps
On official it will work on all maps. 
","Yes, in all maps
",7551429
820,Basilica does not push enemies,open,2015-10-11T10:53:24Z,2016-05-01T05:20:53Z,,CONTRIBUTOR,"In https://github.com/HerculesWS/Hercules/commit/813908c6d116b6afe92cf128cdbb84131860f2c6 (dec 2013) it says ""Fixed cell basilica which was broken 5 years ago in https://github.com/HerculesWS/Hercules/commit/7d4cef5d03815911547efb37dce1c5ee9d5b05fa"". This adds a check to the beginning of battle_check_target(), cancelling anything happening to any two units in a BCT_ENEMY relationship if at least one of them is standing on a Basilica cell.

This goes wrong when the Basilica skill unit tries to push enemies out of its AoE. Both skill_unit_timer_sub_onplace() and skill_unit_onplace_timer() case UNT_BASILICA do a BCT_ENEMY check between the skill unit and the unit standing inside. The check added in that changeset cancels the pushback effect.

I don't think battle_check_target() is an appropriate place to put things like that. I would start by undoing that change, and then figuring out (and documenting!) what problem that change was trying to address.
","~ UP ~ 
",7551429
821," Memory leak detected at ERS 'db.c::db_alloc_ers', 2 objects not freed.",open,2015-10-10T22:46:46Z,2016-03-15T01:35:31Z,,NONE,"Hello there.

It happens sometime after closing the servers.

[Warning]: Memory leak detected at ERS 'db.c::db_alloc_ers', 2 objects not freed.

Memory manager: Memory leaks found at 2015/10/10 15h43m14s (Git rev 'd70d9d4d19f0deae2a2aceb047872611d5047ae0').
0001 : chat.c line 40 size 328 address 0x0x7ffb5902eb7c
0002 : chat.c line 40 size 328 address 0x0x7ffb5902ecec
[Warning]: Memory manager: Memory leaks found and fixed.
",,7551429
822,SC_FATALMENACE,open,2015-10-06T16:42:54Z,2016-03-15T01:34:50Z,,NONE,"Currently doesn't work properly and teleports randomly, sometimes only the caster the teleported, sometimes only the mobs and sometimes both (which is what it should do).
There doesn't seem to be any randomization involved in the code so this is pretty strange, could it be map->search_freecell acting up with multiple targets involved? It is also employed twice.
",,7551429
823,error occur for unitskillusepos script command.,open,2015-10-04T05:58:41Z,2016-03-15T01:34:31Z,,MEMBER,"Sample Script : http://pastebin.com/raw.php?i=cjmDVb5A
## GIT Version

```
[Info]: Git revision (src): '4db986b93566d673c226971fa045f1dc99645242'
[Info]: Git revision (scripts): '4db986b93566d673c226971fa045f1dc99645242'
```
## Step to Reproduce :

Load the Sample Script given using by restart server / @reloadscript (First Error Shown) 
![Image](http://i.imgur.com/0CvStyT.png)

After that, execute @reloadscript ( second error below shown ) , you may try several times, it will show same result.
![Image](http://i.imgur.com/4ZThFxR.png)
Skill ID 85 = Lord of Vermillion.
## In-game Screenshot :

![Image](http://i.imgur.com/kx04Jwq.png)
The skill will continue cast by the NPC, but the error will not shown in map-server.
## Side Note :

Beside, somehow when I first try it, the map-server spam some other error from the core, I unable to reproduce the errors at the moment, but if I recall correctly, it's something related to nullpo reference I guess.
## Off-Topic :

It seem like NPC casting area skill is kinda useless... it's only 1 damage.. :-1: 
","ya, but it become kinda useless if cast by NPC since NPC has no status build. only deal 1 damage.
",7551429
824,reaching C_NOP inside subroutine call breaks script instance counting,open,2015-09-30T14:32:28Z,2015-09-30T19:43:32Z,,CONTRIBUTOR,"A strange error reporting ""over 65k instances"" of a script state led me to a script with a missing ""end;"" call. Here it is, reproduced in minimal form:

```
-   script  Test1   -1,{
OnInit:
    callnpcevent ""Test2::OnTest"";
    end;
}

-   script  Test2   -1,{
OnTest:
}
```

The difference between hitting the end of a script (C_NOP trap) and calling ""end"" is that the former just sets st->state = END, while the latter also restores the st->script context of the topmost parent.

The above case breaks https://github.com/HerculesWS/Hercules/commit/f4b1ff7426b1c4cd5e8cac37f7e3983cc03c706e since the caller's counter stays at '1' while the callee underflows from 0 to USHRT_MAX. It will probably also produce a memory leak. Place a breakpoint here to see it happen:

``` diff
+   if( st->script && st->script->instances == 0 ) ShowError(""imminent underflow"");
    if( st->script && st->script->instances != USHRT_MAX && --st->script->instances == 0 ) {
```

Some thoughts:
Is the 'instances' variable really needed to solve whatever that donpcevent problem was?
The silent C_NOP termination is likely meant to avoid putting 'end' into every itemdb script block, so making it an error condition probably won't work. How about directly calling buildin_end() in case C_NOP?

A more disturbing thought:
Won't hitting any of the bunch of error checks inside the run_script_main() loop do this too? They all just set st->state = END; and call script_free_state(). Really reconsider having that 'instances' variable there.
","Oops, my bad, didn't realize.

Regarding the check, I think it's not checking for underflow, it's complementary to the USHRT_MAX stopgap in the place that increments it. Apparently, the author realized that if you reach the limit when incrementing and stop counting, then letting all of them decrement properly would make the value go negative... so it's better to just give up entirely and take the memleak. One could use a 4-byte int instead, and remove the checking - or raise a fatal error if the limit is reached. The whole concept is pretty awkward.

And regarding the amount of `st->state = END` occurrences, yeah. I only considered the error cases in run_script_main(), but any place anywhere in script.c will probably cause the same failure. Makes me wonder even more what this special crash is that would require such a massive modification to address it.
",7551429
825,Missing packet at character login when admin,open,2015-09-26T13:53:20Z,2016-03-15T01:33:36Z,,NONE,"Main problem: you need 2 client, one must be admin account. Login Admin, then login normal player (it must be logged at actual screen of admin). 

Well you don't receive PACKET_ZC_NOTIFY_HP_TO_GROUPM_R2  in this situation
then use of @ refresh fix that problem. Maybe it should be added on login too?? (only for admins!)

rev. e6d9b55 Date: Mon Aug 31 16:30:03 2015 +0800
packet version: 20130807
","bump
",7551429
826,Unsafe usage of pointers as vectors,open,2015-09-24T13:48:40Z,2015-09-25T11:11:08Z,,MEMBER,"In several places through the code, we're using various kinds of homebrew vectors (variable-length arrays), using a pointer and a counter, using the following pattern:

```
struct {
    // ...
    struct Bar **bar;
    int barc;
} foo;
// ...
void init_foobar(void)
{
    foo.bar = NULL;
    foo.barc = 0;
}
void append_to_foobar(struct Bar *value)
{
    RECREATE(foo.bar, struct Bar *, ++foo.barc);
    foo.bar[foo.barc-1] = value;
    // ...
}
void destroy_foobar(void)
{
    if (foo.bar != NULL) {
        for (i = 0; i < foo.barc; ++i) {
            // ...
            aFree(foo.bar[i]);
        }
        aFree(foo.bar);
    }
    foo.bar = NULL;
    foo.barc = 0;
}
```

That's inherently unsafe, since it is not clear (or in any case not easily enforced, other than using comments) that `bar.foo` is a vector, rather than a single pointer, and that `foo.barc` is related to it.

In db.h we have a set of macros to declare and use a similar structure, in a standardized manner (the `VECTOR_...` macros). Those are self-documenting and show clear intent to use a pointer as a vector, abstracting the implementation details away from the caller code. In addition, they allow better optimization of the allocations, since they differentiate between size and capacity.

The above snippet, transformed, would look like:

```
struct {
    // ...
    VECTOR_DECL(Bar *) bar;
} foo;
void init_foobar(void)
{
    VECTOR_INIT(foo.bar); // Initialize the vector, settings size and capacity to zero
}
void append_to_foobar(struct Bar *value)
{
    VECTOR_ENSURE(foo.bar, 1, 1); // Ensure at least one extra unit of capacity.
    VECTOR_PUSH(foo.bar, value); // Create a new entry in the free space, and push the value into it.
    // ...
}
// ...
void destroy_foo(void)
{
    while (VECTOR_LENGTH(foo.bar) > 0) {
        // ...
        aFree(VECTOR_POP(foo.bar)); // Remove an entry, and free its pointed data
    }
    VECTOR_CLEAR(foo.bar); // Clear the array, freeing memory and setting its size and capacity back to zero
}
```
",,7551429
827,The rcode field in the loginlog table is ambiguous,open,2015-09-24T12:55:28Z,2017-02-19T07:13:44Z,,MEMBER,"Certain error conditions (an example is the _incorrect pincode_ condition) set the rcode field in loginlogs to `100`, which is also used for the _login OK_ condition.

In general, we're filling that field with a mix of clientside error codes (the ones used by `login_auth_failed` and server error codes.

We should disambiguate the values, and possibly use a serverside only, well-defined enum for them. Since the client doesn't handle all the possible login errors, it doesn't make sense to use the same values serverside.

This depends on issue #734, in order to correctly migrate old loginlog entries to the newly defined rcode values.
",,7551429
828,SQL upgrades should specify their destination database,open,2015-09-24T11:14:20Z,2017-02-19T07:13:44Z,,MEMBER,"While we support (and encourage) using different databases for main and logs, we don't differentiate between upgrades that affect the main database and those that affect the logs database.

The two types of upgrades should be separated (and kept track of separately, in each database).
",,7551429
829,Endless Tower CD only applies to party leader,open,2015-09-23T06:42:55Z,2017-02-27T08:05:13Z,,CONTRIBUTOR,"So the Endless Tower's 7 day cool down only applies to a party's leader.
Leaving the party after completion and assigning someone else as a party leader allows for infinite entry to Endless Tower.

I have no solution, honestly. Just quite concerned since this allows for some early level MVPs and Mini-MVPs to be farmed non-stop.
","any update?
",7551429
830,Warning,open,2015-09-17T03:06:16Z,2015-12-28T20:39:03Z,,NONE,"When you're going to PM someone using the PM Box whose name is compose of 24 characters or more, theres a warning msg that will appear on the console.
![error_pm](https://cloud.githubusercontent.com/assets/4656578/9923834/16574d5c-5d2c-11e5-9813-c5f71d42a74b.jpg)
Im using 2015-05-13client
","If the client allows sending names longer than 23 characters (or in other words, can send names without a NULL terminator, then we can remove the warning message.
",7551429
831,Infinite Flee,open,2015-09-15T06:02:08Z,2016-03-15T01:31:13Z,,NONE,"Video demonstrating the bug.
https://youtu.be/F2A8Ff7aN8s

This bug is PURELY from thara frog card as I thought from first sight

The rules of the bug are

1) you must have the shield equipped to dodge

2) you must equip the shield, go through a PORTAL, and then you can unequip the shield and the bug will still carry through without the shield

there are a few monsters that can actually hit you, also as of course this bug is ONLY with demi human race, magic attacks cant miss on you so they just do 1 damage
The only two monsters that can hit you through this effect is eremes and seyren (eremes and seyren summoned by the mvp as minions do not count)
","@hemagx 
",7551429
832,UNT_EPICLESIS,open,2015-09-08T19:00:15Z,2016-03-15T01:30:46Z,,NONE,"Has a very strange behavior, tick timers are all over the place, sometimes it ticks very fast, sometimes it skips ticks, affected players randomly get no benefits or only restore either HP or SP but not both, etc.
","It might be better to move the healing functions to the SC status, though, the status doesn't always apply either.
",7551429
833,Force Serial,open,2015-09-07T09:47:32Z,2016-03-15T01:29:09Z,,NONE,"When you opened a box (type:18) and its contents has a ForceSerial: true, the items are not stackable. This is normal but the bug arises when you reconnect your character and you open another Box, the first one you opened are now stacked to the old one and to your next box opening, it will not be stack-able. So in the first place, the bug happens when you reconnect.

@MishimaHaruna and sir I have a suggestion here http://herc.ws/board/topic/10570-official-uid/#entry62547 thanks
","Your suggestion is actually official behavior that i totally missed, accidentally mixed between it and a bug.

Basically any box have UID should give it little members UID too, i don't remember if it's same UID or new one but possibly same one.
however i believe I'm still missing something, i need to test and see ~
About the issue, I'm gonna test and debug it as soon as kRO client arrive here.
",7551429
834,ForceSerial not working,open,2015-09-07T06:41:00Z,2015-11-23T14:03:31Z,,CONTRIBUTOR,"Hi All!

I tried to put force serial in this item ID#13921 (Antique_Pipe_Box) and by using getitem, the items stacked, it does not separate the items one by one,  Im using 2010-06-16aRagexeRE and pre-re configuration, using the latest herc version.

Thanks!
","I see, then we shouldn't emulate aegis bug ...
",7551429
835,Gentle Touch-Convert (Sura Skill) reduces HP by too much,open,2015-09-06T19:13:53Z,2015-11-17T09:17:20Z,,NONE,"The Gentle Touch-Convert (Sura Skill) should reduce your max HP by 5% at level 5. I have tested it and found that it reduces max HP by 20% at level 5 instead. The reduction rate is off for all levels, starting at 4% at level 1 and incrementing by 4% for each level.

http://irowiki.org/wiki/Gentle_Touch-Convert - this corresponds with the current in-game skill description we have.

Cheers <3
",,7551429
836,Impositio Manus,open,2015-09-05T03:34:32Z,2017-04-20T02:58:50Z,,NONE,"Original topic: from Atemo https://github.com/rathena/rathena/issues/610

http://irowiki.org/wiki/Impositio_Manus

Lower levels of Impositio Manus will overwrite higher levels. For example, someone with level 5 IM activated will have +25 ATK from the skill, but if level 1 IM were used on them their ATK would drop to only +5. Therefore, this skill can be used offensively.
Confirmed on aegis.
",@MishimaHaruna is this good to merge now? ,7551429
837,"Server crash pre-renewal, lastest revision",open,2015-09-04T19:43:31Z,2015-11-21T01:22:37Z,,NONE,"Process information:
Command line: map-server.exe
Platform: Windows Server 2012 Standard (build 9200)
 CPU: x86_64 CPU, Family 6, Model 26, Stepping 5
Application architecture: x86
Compiler: Microsoft Visual C++ 2012 (v1700)
Git: f7a97b556e05373711998d4f819cf7d89e4b0ce8

Exception:
0xc0000005 EXCEPTION_ACCESS_VIOLATION at location 0x00814E02 reading from location 0x078B0F84

Registers:
eax=078a12b0 ebx=7ffde000 ecx=0856d24c edx=078a12b0 esi=0018fbe4 edi=0018fce0
eip=00814e02 esp=0018fbe4 ebp=0018fce0 iopl=0         nv up ei pl nz na pe nc
cs=0023  ss=002b  ds=002b  es=002b  fs=0053  gs=002b             efl=00010202

Stacktrace:
#0  0x00814E02 in party_send_xy_timer+0x112 (tid=(int)18, tick=(long long)1645604315, id=(int)<no data>, data=(int)<no data>) at c:\users\administrator\desktop\loki server\src\map\party.c:885

885             if( !sd || sd->bg_id ) continue;
    sd = (struct map_session_data_)0x078A12B0 <invalid memory>
    i = (int)<no data>
    iter = (struct DBIterator_)0x05C4F6BC bytes:69146100CC566100C7566100255861003F02610067026100C6346100
    p = (struct party_data*)0x0856D24C bytes:D001000066656664660000000000000000000000000000000000000001000000000000002C851E00B24A02004C656F6E6172646F00000000000000000000000000000000A20F2D003F00CCCCCFCCCCCC00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000B0128A07AE20000099005600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
#1  0x0065657D in do_timer+0x54D (tick=(long long)1645604330) at c:\users\administrator\desktop\loki server\src\common\timer.c:398

398                 timer_data[tid].func(tid, timer_data[tid].tick, timer_data[tid].id, timer_data[tid].data);
    tid = (int)18
    diff = (long long)-15
#2  0x006292DC in main+0x24C (argc=(int)1, argv=(char**)0x0115FFA8) at c:\users\administrator\desktop\loki server\src\common\core.c:444

444         int next = timer->perform(timer->gettick_nocache());
    next = (int)50
    retval = (int)<no data>
#3  0x009CDC8C in __tmainCRTStartup+0x10C () at f:\dd\vctools\crt_bld\self_x86\crt\src\crt0.c:240

```
mainret = (int)<no data>
managedapp = (int)<no data>
initret = (int)<no data>
```
#4  0x009CDE6D in mainCRTStartup+0xD () at f:\dd\vctools\crt_bld\self_x86\crt\src\crt0.c:164
#5  0x753C8543 in BaseThreadInitThunk+0xE (<failed enumerating symbols>)

!!failed enumerating symbols!!#6  0x7776AC69 in RtlInitializeExceptionChain+0x85 (<failed enumerating symbols>)
!!failed enumerating symbols!!#7  0x7776AC3C in RtlInitializeExceptionChain+0x58 (<failed enumerating symbols>)
!!failed enumerating symbols!!

Loaded modules:
0x00400000  C:\Users\Administrator\Desktop\Loki Server\map-server.exe  (0.0.0.0, 12587008 bytes)
0x77710000  C:\Windows\System32\ntdll.dll  (6.2.9200.16384, 1404928 bytes)
0x753A0000  C:\Windows\System32\kernel32.dll  (6.2.9200.16384, 1245184 bytes)
0x75C30000  C:\Windows\System32\KERNELBASE.dll  (6.2.9200.16384, 679936 bytes)
0x75350000  C:\Windows\System32\ws2_32.dll  (6.2.9200.16384, 327680 bytes)
0x10000000  C:\Users\Administrator\Desktop\Loki Server\libmysql.dll  (0.0.0.0, 1462272 bytes)
0x00020000  C:\Users\Administrator\Desktop\Loki Server\zlib1.dll  (1.2.7.0, 81920 bytes)
0x00240000  C:\Users\Administrator\Desktop\Loki Server\pcre3.dll  (8.30.910.0, 159744 bytes)
0x760D0000  C:\Windows\System32\user32.dll  (6.2.9200.16384, 1138688 bytes)
0x75DC0000  C:\Windows\System32\rpcrt4.dll  (6.2.9200.16384, 704512 bytes)
0x75A90000  C:\Windows\System32\nsi.dll  (6.2.9200.16384, 32768 bytes)
0x74100000  C:\Windows\System32\wsock32.dll  (6.2.9200.16384, 32768 bytes)
0x756E0000  C:\Windows\System32\advapi32.dll  (6.2.9200.16384, 712704 bytes)
0x75590000  C:\Windows\System32\msvcrt.dll  (7.0.9200.16384, 724992 bytes)
0x75EB0000  C:\Windows\System32\gdi32.dll  (6.2.9200.16384, 1036288 bytes)
0x74DB0000  C:\Windows\System32\sspicli.dll  (6.2.9200.16384, 114688 bytes)
0x75E70000  C:\Windows\System32\sechost.dll  (6.2.9200.16384, 212992 bytes)
0x74DA0000  C:\Windows\System32\CRYPTBASE.dll  (6.2.9200.16384, 36864 bytes)
0x74D40000  C:\Windows\System32\bcryptPrimitives.dll  (6.2.9200.16384, 331776 bytes)
0x73A90000  C:\Windows\System32\cryptsp.dll  (6.2.9200.16384, 106496 bytes)
0x73A50000  C:\Windows\System32\rsaenh.dll  (6.2.9200.16384, 253952 bytes)
0x75550000  C:\Windows\System32\imm32.dll  (6.2.9200.16384, 131072 bytes)
0x75CE0000  C:\Windows\System32\msctf.dll  (6.2.9200.16384, 901120 bytes)
0x749D0000  C:\Windows\System32\NapiNSP.dll  (6.2.9200.16384, 65536 bytes)
0x749C0000  C:\Windows\System32\nlaapi.dll  (6.2.9200.16384, 65536 bytes)
0x73B10000  C:\Windows\System32\mswsock.dll  (6.2.9200.16384, 303104 bytes)
0x744A0000  C:\Windows\System32\dnsapi.dll  (6.2.9200.16384, 479232 bytes)
0x74930000  C:\Windows\System32\winrnr.dll  (6.2.9200.16384, 36864 bytes)
0x73CA0000  C:\Windows\System32\IPHLPAPI.DLL  (6.2.9200.16384, 139264 bytes)
0x73C90000  C:\Windows\System32\winnsi.dll  (6.2.9200.16384, 32768 bytes)
0x74770000  C:\Windows\System32\FWPUCLNT.DLL  (6.2.9200.16384, 258048 bytes)
0x74760000  C:\Windows\System32\rasadhlp.dll  (6.2.9200.16384, 28672 bytes)
0x74750000  C:\Users\Administrator\Desktop\Loki Server\plugins\dbghelpplug.dll  (0.0.0.0, 57344 bytes)
0x72C80000  C:\Windows\System32\MSVCR110D.dll  (11.0.50727.1, 1683456 bytes)
0x74350000  C:\Users\Administrator\Desktop\Loki Server\dbghelp.dll  (6.12.2.633, 1314816 bytes)
0x74310000  C:\Windows\System32\powrprof.dll  (6.2.9200.16384, 258048 bytes)
","Unfortunately, I still can't :(

Those are just taken from the hex dumps the user provided in the ticket, I analyzed them to look for correlations...
",7551429
838,Guild bound items can disappear.,open,2015-09-03T16:38:04Z,2018-06-30T12:29:49Z,,CONTRIBUTOR,"How to reproduce:
1.) Create a new guild and invite an extra member
2.) Make sure to not open guild storage at any point before kicking the member
3.) Create a guild bound item, trade it to the member
4.) kick the member while he is still online.
-> item gets deleted from member and is not returned to guild storage.

Doesn't have to be a new guild, this happens when guild storage has not been opened after server reboot. If the character is offline everything works fine. Someone else might want to doublecheck to be sure.

Good thing guild bound system isnt that widely used, else this would be a prety huge bug.
Ran into this while creating a pretty nifty feature using guild bound items.

I believe the reason is that intif->request_guild_storage has not been used before this action thus the guild storage doesnt exists on the map server yet.
",Any update?,7551429
839,Bearer's shadow set infinite endure continues after unequip,open,2015-09-01T20:32:09Z,2015-12-28T20:55:49Z,,CONTRIBUTOR,"When you're wearing the Bearer's shadow set with the sum of refines equal or greater than 45, you get infinite endure, but when you unequip it, the effect doesn't go away (I believe it should) even if you die/relog.

How to reproduce:
- Create and equip the items: 24180, 24181, 24182, 24183, 24184, 24185
- refine them ( refine 0 10 )
- You'll notice that now you have endure (OK)
- Unequip some parts (or all of them)
- You still have endure (wrong?)
","@Jedzkie 
What I say is a walk-around, due to the way the infinite endure is implemented (by starting a infinite status, the way to end it is to put a sc_end in the unequip script)
",7551429
840,Eden Crystal Synthesis 2.,open,2015-09-01T10:31:33Z,2017-09-03T15:04:31Z,,NONE,"Follow up on https://github.com/HerculesWS/Hercules/issues/660
Issues I found on the npc:

- [ ] case 2: Quest to Energy Crystals 

> Max level character can take a quest from the 3 different tiers. and when taken after completion of another, the cooldown of previous quest disappeared.

- [ ] case 3: Energy Crystal Buff

> If you request for different buff, the cooldown for another buff, and overrides it.
> Purified crystal can be received before the buff time: 3 hours finishes

- [x] case 5: Exchange Energy Crystal for equipment 

> case 1: See Equipment List; Catalogue (in book format) is not there. //no clientside source
> case 4: High Energy Crystal; > case 4: Hat of the Sun God [0](x/1000); //this item not meant to be there
> case 4: High Energy Crystal; > case 5: Hat of the Sun God [1](x/100); //suppose to be 300
> 
> Typo on  Case 6: Random Gear for Crystal. should be ->  Exchange Crystals for Random Gears

Note: please also review the wording of the NPC.
e.g. ""Do you want to donate Energy Crystals to get a random new headgear""

-SH
","Update: The cool down for case 1 and case 3 has fixed it self
",7551429
841,Invalid timer for step_timer,open,2015-08-29T15:37:34Z,2016-01-02T17:44:12Z,,MEMBER,"So this popped up on the console not sure if it's a known issue - 

[Error]: timer_do_delete error : function mismatch 0x5fa3d0(console_parse_timer) != 0x5dc1c0(unit_step_timer)

TID isn't invalid when trying to delete the step_timer in one of the functions of unit.c.
","bump?
",7551429
842,Acid demonstration renewal,open,2015-08-29T03:07:03Z,2015-08-29T22:33:38Z,,NONE,"Hello, we think this formula is working with the pre renewal features, instead with renewal, we don't know certainly, but i want to know the way is working, i'm on renewal.
","@AnisotropicDefixation i will test tomorrow on aegis and show results ^^
",7551429
843,Dragon Breath Damage,open,2015-08-28T10:32:21Z,2015-09-04T19:38:27Z,,NONE,"Old DB Formula:
{(Caster’s HP / 50) + (Caster’s MSP / 4)} x (Dragon Breath Skill Level x Caster’s Base Level / 150)} x Dragon Training This is Current formula on DB damage. 

New DB Formula:
{[(Caster's HP / 50) + ( Caster's MSP / 4)] × (Dragon Breath Skill Level × Base Level / 150)} × Dragon Training × Elemental modifier(1.25~2) × Ranged Damage(Expert Archer and so on)
","I don't think that those extra modifiers are exclusive to this skill. As i'm testing right now with
LongAtkRate: 0
HP:38657
MaxSP: 1861 
AddEle:0
AddRace:0
Output Damage: 18321

LongAtkRate: 7
HP: 38757
MaxSP: 1861 
AddEle: 25
AddRace: 0
Output Damage: 18351

with a 25% increase of damage on that particular race, there is no significant increase in damage. is this AddEle % increase not supposed to be added on all monsters of that element? Also LongAtkRate and AddRace?
",7551429
844,SR_SKYNETBLOW and SR_TIGERCANNON,open,2015-08-25T23:47:17Z,2016-01-03T13:13:34Z,,NONE,"These skill only deal bonus damage from combo to the main target, those in area take normal damage.
","Anyone has any input on this?
",7551429
845,Solar/Stellar/Lunar bug,open,2015-08-25T11:37:29Z,2016-05-14T10:16:01Z,,NONE,"I've noticed a strange bug with the warmth skills.

If you have warmth of the sun/moon/stars activated as a star gladiator and are attacking a monster and are buffed/debuffed during you attacking it, the damage does not increase/decrease until you walk away from the monster and re-touch it (or use a fly wing). Even if you strip your gears entirely, your damage would not change one bit.

If it makes any difference, I come from eAthena and only recently transfered to Hercules, this wasn't the case at the eAthena emulator. Power up would change damage right away in warmth mode.

Thanks for the efforts to make hercules a stable emulator!
",,7551429
846,SC_BURNING,open,2015-08-25T10:07:58Z,2016-10-06T19:17:15Z,,NONE,"Old issue, posting it here to bring more attention.

Refer to:
http://herc.ws/board/tracker/issue-8437-burning-status-to-mob-doesnt-have-damage/
","Still open.
",7551429
847,Eden Crystal Synthesis,open,2015-08-23T22:28:03Z,2016-01-08T15:23:42Z,,NONE,"https://github.com/HerculesWS/Hercules/commit/146247c3e466542949a9ebee709633360a67778c

Problem =
- SC_QUEST_BUFF1, SC_QUEST_BUFF2, SC_QUEST_BUFF3 are not applied because it doesnt exist in current repository
- Safety Ring[1] and Good Ring of Resonance + Ring of Flame Lord are not included in current itemdb
","SC_QUEST_BUFF1 2 3 already implemented, going to add missing items in my next pull.
",7551429
848,Cart Tornado formula is wrong,open,2015-08-23T21:51:38Z,2015-08-29T16:33:17Z,,NONE,"On Hercules this skill damage become insane when Genetic reach 149 or more total str. The current formula from repository take total str while in official it use base str.

Current repository battle.c
skillratio = 50 \* skill_lv + (sd ? sd->cart_weight : battle_config.max_cart_weight) / 10 / max(150 - strbonus, 1) + 50 \* (sd ? pc->checkskill(sd, GN_REMODELING_CART) : 5);

With that formula a 149 or more total str Genetic will get (250+10500+250)% skill ratio. This should be 150 minus base str like official so 130 base str Genetic will get (250+525+250)% skill ratio
","In game test with current formula. Lv 1 cart tornado with Lv 5 cart remodeling and full cart (10500/10500)

1 base str , 150 bonus str , 37883 damage
http://114.imagebam.com/download/087LO_XqzaOudG89z-nmgQ/43128/431270826/screenNTRO010.jpg

130 base str , 2558 damage
http://113.imagebam.com/download/4lKDpS8khuwIE-7i8VK0pw/43128/431272129/screenNTRO012.jpg
",7551429
849,SR_KNUCKLEARROW knockback.,open,2015-08-18T12:20:34Z,2015-08-29T16:29:08Z,,NONE,"Currently defaults to west.

Adding

dir = unit->getdir(bl);
unit->setdir(src, (dir+4)%8);

works but only if you hit the target first, no proper facing like it happens with KN_CHARGEATTACK.
",,7551429
850,NPC_RUN,open,2015-08-15T08:39:38Z,2018-10-09T17:24:55Z,,NONE,"Doesn't cancel the aggressive state so mobs using this will just ping-pong back and forth instead of running away.
","oh, sorry, seems I added the hacktoberfest tag here by mistake",7551429
851,SCB_MODE implementation.,open,2015-08-15T08:27:59Z,2016-01-28T16:31:02Z,,NONE,"```
//Out of range...
if (!(mode&MD_CANMOVE) || (!can_move && DIFF_TICK(tick, md->ud.canmove_tick) > 0)) {
    //Can't chase. Immobile and trapped mobs should unlock target and use an idle skill.
    if (md->ud.attacktimer == INVALID_TIMER)
    { //Only unlock target if no more attack delay left
        //This handles triggering idle/walk skill.
        mob->unlocktarget(md,tick);
    }
    return true;
}
```

This is the current implementation, which causes an issue with SC statuses that stop movement.

When a passive monster gets affected by statuses like SC_STOP, SC_FALLENEMPIRE or SC_WHITEIMPRISON, anything that stops movement, after the status ends, they remain idle instead of resuming their attack/chase towards the aggressor.
","Tested Spiral Pierce: There doesn't seem to be any perceivable stop effect other than the normal dMotion hitlock and monster stays aggressive.
",7551429
852,Dispell skill is not working on @duel state,open,2015-08-12T15:25:17Z,2015-08-13T15:36:35Z,,NONE,"SA_DISPELL skill is not working on @duel state ^^
","It only checks for map_flag_vs and not duel_group currently.
",7551429
853,Snap_dodge bug,open,2015-08-12T06:53:53Z,2017-04-11T03:34:36Z,,NONE,"http://herc.ws/board/topic/10359-snap-dodge-bug/#entry61364

Hi,
I tried turning the setting ON and OFF on conf/battle/battle.conf
[code]
// Should the target be able of dodging damage by snapping away to the edge of the screen?
// Official behavior is ""no""
snap_dodge: yes
[/code]
but the result are the same. Snap can't dodge all skill even my setting is yes or no.

please fix 
",Still Bumping this one.,7551429
854,GC_WEAPONBLOCKING,open,2015-08-09T23:40:11Z,2015-08-29T16:05:50Z,,NONE,"As stated on irowiki, it's supposed to trigger even if you dodge/block the attack, which is currently not the case.

It is also blocking monster's spells when in melee range since they're considered BF_SHORT.
",,7551429
855,Fire Expansion Level 1-4 are not working Properly,open,2015-08-09T11:15:31Z,2015-08-29T16:05:37Z,,NONE,"From IroWiki :
Information 

Level 1: Increases Demonic Fire damage by 50% & increase duration by 10 seconds
Level 2: Increases Demonic Fire damage based on caster's INT. Cancels Demonic Fire
Level 3: Demonic Fire becomes SmokeScreen which reduces ranged damage and increases evasion
Level 4: Demonic Fire becomes Tear Gas, which drains HP, reduces accuracy and evasion
Level 5: Activates the highest level of Acid Bomb learned.

Problem : 

Level 1: Applies the Increase Damage, does not increase the duration by 10 seconds.
Level 2: Does not end the skill, instead deals increased damage on Demonic Fire.
Level 3: Ceases the damage done by Demonic Fire but does not turn into Purple Gas. No Flee increase and does not decrease damage in the area.
Level 4: Ceases the damage done by Demonic Fire but does not become Gray Smoke: Does not reduce Flee and Hit nor drains HP or forces the use of /cry emote.
Level 5: Working as intended.
","https://github.com/rathena/rathena/tree/96c768f9b78de65d69887df3600b3173e413e32a
",7551429
856,Mob matk with NPC_POWERUP,open,2015-08-04T14:19:56Z,2016-03-24T16:28:05Z,,NONE,"Mobs magic type attack only deals 1 damage with the skill NPC_POWERUP
","I was able to successfully replicate this 100% of the time by making a custom mob with Invisible. Its damage with magic attacks drop to 1 when it's forced out of hiding in any way (Sight or taking a hit). I added the if statement AnisotropicDefixation gave, and it at least works for me.
",7551429
857,pre-re OCA and Gift Box not complete,open,2015-08-04T05:02:01Z,2015-12-05T13:12:43Z,,NONE,"OCA list in /db/pre-re/item_group.conf is super incomplete. For example, a card is implemented from a later episode such as Byorgue card (Thors Volcano). But, Abyss Lake / Kiel Dungeon / Biolabs / Thanatos Tower cards are not implemented. I don't know how to prove this to you, because reading from Aegis is not the best. and RMS is not a reliable source. 

Same with Gift Boxes missing R.Elu/R.Ori/Elu/Ori/Gold/Emperium.  

I spoke to @MishimaHaruna  about this before. 
","Creamy is blocked to force kro players to buy it by $$$. So copycat official behaviour here is a step back IMO.
",7551429
858,SD_Animation is not working. -> some skill animations not working correctly,open,2015-07-29T22:06:25Z,2015-08-31T04:16:01Z,,CONTRIBUTOR,"Skills like Sharpshooting/North wind show animation vs each target, grand cross does the animation for each target making it really bright, ++ more skill animations messed up due to this
I have tested this on client versions 20130807 and 20140416. Most likely everything above x client version. Packet could have been changed earlier too.
","This was caused by malufett's fix in @ aaa82f2f8fb70858048d1e199b40bbb797b9604d

Related:

http://herc.ws/board/tracker/issue-8682-bakuretsu-kunai/?gopid=25327#entry25327
",7551429
859,Genetic Sling Items banana and mysterious powder,open,2015-07-29T10:53:35Z,2016-01-08T15:23:42Z,,NONE,"http://herc.ws/board/tracker/issue-8647-genetic-sling-item-banana-bomb-and-mysterious-powder/

From my old report

what i do not know is the official sit chance with Banana bomb

a small info on this
http://ragnarok.wikia.com/wiki/Sling_Item
","Sorry, my internet sucks, that's why i spammed the assignee. xD
",7551429
860,Metallic Sound & Deep Sleep / Sleep damage,open,2015-07-23T18:17:59Z,2015-08-29T15:33:07Z,,NONE,"http://valhabar.roserver.net/foro/index.php?topic=17.0
http://irowiki.org/wiki/Metallic_Sound

Damage is not being increased in Sleep Status nor deep sleep... 
According to skill description:  
Targets affected by Sleep or Deep Sleep receive 1.5x the damage. The SP drain is not increased.
Targets affected by Deep Sleep also receive the 1.5x damage that Deep Sleep causes on the next attack (total of 2.25x damage) 
Targets affected by Deep Sleep also receive the 1.5x damage that Deep Sleep causes on the next attack (total of 2.25x damage). 

Please, check it, it's tested in PVP...
",,7551429
861,Old Glast Heim Missing NPCs,open,2015-07-22T08:19:05Z,2015-08-29T15:39:30Z,,NONE,"I don't know if this has reported before, i didn't find someting relative to this, but anyway:

missing npc's
Temporal Boots & Enchants

• Hugin's Butler
• Hugin's Craftsman
• Hugin's Magic

OGH instance monsters (including mini boss and boss monsters) not dropping loots, (especially Coagulated spells)

I found here the script but its not compatible with Hercules:

http://pastebin.com/sfxVq8LY
","It's also missing traps, event during the final boss that spawns invisible dummies using NPC_GRANDDARKNESS and mobs, treasury room, etc.
",7551429
862,OB_OBOROGENSOU,open,2015-07-16T02:57:57Z,2015-08-29T15:42:57Z,,NONE,"Doesn't seem to recover or reduce HP/SP no matter what and the SC_GENSOU status isn't always applied, takes a few tries.
","@malufett 
I missed one of the bracket pairs in the PER, you are right about that. And yes, then it seems the 100 as divisor is then the only problem here.
Still int is increasing the chance and the level is decreasing it:
Image the skill being level 5 and having 100 int:
(25 + 10 \* 5) - 100/2 = 75-50=25
The random value needs to be ""lower or equal"" to 25 to NOT return 0.
If it is 26 or higher the if will return 0.

To the makro part (I don't want to open a huge discussion here, and it could be that you are right on this one, but I'll state my opinion for clarity anyways):
Makros will be inserted as real text and then artificially increase the file size during compilation. As such makros are saving us work if we would have to write the whole code multiple times and can't put it into a function. A good example in map/script.c: 

```
#define RETURN_OP_NAME(type) case type: return #type
    switch( op ) {
    RETURN_OP_NAME(C_NOP);
    RETURN_OP_NAME(C_POS);
    RETURN_OP_NAME(C_INT);
// ....
```

On the other hand the compiler can't optimize functions which are parsed as real code in a makro. As such it might (often times, not always) be wiser to create an inline function which might only be called once or twice, as the compiler can then decide himself if it is call-worthy or just inlining it.

---

Back to Topic: Somebody volunteering to fix it?
",7551429
863,pk mode no gain exp,open,2015-07-11T17:25:58Z,2016-03-15T00:35:25Z,,NONE,"The way this bug pk in pk so players do not earn exp normally, the test was performed: enable pk 100 set to level mode, pj novice did not gain exp any mob 
Pj level 100-101 not gain exp from mob
(Sorry my bad english)
",,7551429
864,"King's Grace Skill no cool down, root effect, and no skill usage disabled when cast",open,2015-07-10T10:29:20Z,2020-02-19T23:25:35Z,,CONTRIBUTOR,"As said on title, King's Grace has:
No cool down
LG_KINGS_GRACE 5013,1000,0,0,5000,0,0,-1
to
LG_KINGS_GRACE 5013,1000,0,0,5000,0,60000,-1
?
No root effect,
and let's the caster use skills when activated.

Cooldown should be at 1 minute at Level 5.

http://youtu.be/xFJeUxULtx4

See video comments for further confirmation
","I don't suppose there is an update on this?
",7551429
865,Status Icon Timer of  sc_monster_transform disappear after loading a map,open,2015-07-04T06:04:13Z,2016-04-02T12:16:11Z,,CONTRIBUTOR,"The status icon timer of sc_monster_transform dispears after changing map or re-login,
It should not be so and hope devs fix this bug thanks
","@HerculesWS/developers

One year has passed , Any news about sc redesign?
",7551429
866,Input command for Invisible Npc,open,2015-06-28T15:03:27Z,2016-10-25T15:43:00Z,,CONTRIBUTOR,"Using the *input command will cause Npc to freeze if used on an invisible Npc.

By freeze I mean that you will be stuck, and need to log in & out to move again (Like when you forget a *close in a script).

By Invisible I mean a Npc with Sprite Id = -1
Input works fine on all other Sprite Id (works fine with 111 too)

If you want to test it quickly(just change the rid for the 4th Npc): http://pastebin.com/AEy6wyja
","hmm ... weird, I am currently using `2015-05-13` client i think.
the issue still exist.

# Steps to Reproduce :
1. Load the NPC provided in above comment.
2. in-game type `@testinput4`
3. The NPC dialog popup, but the `input` didn't popup. Hence stucked.
4. Try to use `@jump` or teleport, the dialog got terminated.
5. **Repeat steps 2**, type the command again.
6. The NPC dialog popup, but the `input` ALSO popup this time. Hence, it ""work"".
7. **Repeats steps 2 ~ 6 again**. It repeat at the same sequences. ( first time, not working, second time work fine, and repeat).
",7551429
867,Eff_Stone,open,2015-06-28T12:29:22Z,2015-08-29T22:55:46Z,,NONE,"This is from item scripts.

It's skipping OPT1_STONEWAIT entirely when it should still employ it but with a lower duration (a couple of seconds).

On a side note, where the hell are item scripts handled in src?
","@MishimaHaruna
actually I found the code in aegis however I have lack of time to check it further..
according to it, it accepts a parameter for the delay before the effect take into action..like what Kyeme has discussed in his previous reports..however I need to confirm all instances where the delay is computed, all I found is 0 delay set on the param...regarding with SC_STONE I need to decode it first in aegis..
mostly in skills this is called the 0 delay and use to EFST_IDs
![image](https://cloud.githubusercontent.com/assets/3251821/9564765/95e5cc2c-4ee2-11e5-9473-18015421d4d6.png)
but in scripts and in sienna it uses this and use to OPTION_STATUS
![image](https://cloud.githubusercontent.com/assets/3251821/9564810/becb25b4-4ee3-11e5-974f-f96f8cf933d3.png)
it has 3 types of delay but I haven't figure out how those 3 affects the status effect..
",7551429
868,Monster Aggressive Bug,open,2015-06-27T12:39:12Z,2017-10-17T03:28:19Z,,CONTRIBUTOR,"Hi!

I just update my hercules up to date and i found a bug, all of the aggressive monsters are not aggressive unlike before. for example. MVP Monsters.

Regards,
Frost
",@MishimaHaruna no news about this one?,7551429
869,kick vendor in autotrade mode crashes map server,open,2015-06-23T17:17:31Z,2018-03-17T19:02:33Z,,CONTRIBUTOR,"long story short ,when npc script attach a @at state vendor then kick him map server will go crashed,but if npc script doesn't attach @at state vendor ,kick command was working fine..
Here are my test scripts:

<pre><code>
prt_fild08,174,367,5    script  kick@ATvendor   100,{
    input.@name$;
    query_sql(""SELECT `account_id` FROM `char` WHERE `name` = '""+escape_sql(.@name$)+""'"", .@aid);
    attachrid(.@aid); 
    atcommand ""@kick ""+strcharinfo(0);
    end;
}
</code></pre>


<pre><code>
prt_fild08,174,362,5    script  kick@ATvendor2  100,{
    input.@name$;
    query_sql(""SELECT `account_id` FROM `char` WHERE `name` = '""+escape_sql(.@name$)+""'"", .@aid);
    //attachrid(.@aid);
    atcommand ""@kick ""+rid2name(.@aid);
    end;
}
</code></pre>
","While I agree with ""easily reproducible"", I disagree with ""that can hurt any server"". The very easy workaround for a server owner is to avoid running a poorly designed script that attaches to a character in autotrade mode and kicks it, no?",7551429
870,Missing logging code for login and char server,open,2015-06-21T19:26:26Z,2015-06-24T12:36:28Z,,CONTRIBUTOR,"Always forgot this issue.

Look like code what reading configuration about logging options missing in login and char server.
As result log file for login and char server even not created.

Default settings prevent this server write to log files.
",,7551429
871,White Wing Suit and Black Wing Suit drop rate,open,2015-06-18T05:40:56Z,2016-03-15T00:25:16Z,,CONTRIBUTOR,"Question,
- where do you guys know this 2 item's drop rate?

I see only 2 sites that mention its drop rate, which is : 

http://www.divine-pride.net/database/monster/1098 < white wing suit from anubis with drop rate 1% (is this even kRO's official? can't see any mention of its server) too high if i think for rare gear
http://ro.silk.to/mob/1098.html < white wing suit from anubis with drop rate 0.06 % (official jRO) seems normal for ""rare"" gears

http://www.divine-pride.net/database/monster/2773 < Black wing suit from Elusive Luciola Vespa with INSANE drop rate 90%, seriously? I know you got higher drop rate from ""Champion Monster"", but 90%? (this mob is not exist in jRO) The drop rate from normal Luciola Vespa is Okay (0.1%)
","@dastgir or any developer mind checking?
",7551429
872,New item script for reducement based on Monster's element (not elemental attack),open,2015-06-10T08:29:59Z,2017-03-08T20:40:50Z,,CONTRIBUTOR,"Based on : 
http://herc.ws/board/tracker/issue-7769-tatacho-card-effect/

Hercules need new script for this reducement.
List items that affected : 
2684 Ring_Of_Wind
4442 Tatacho Card
4443 Aqua Elemental Card
4444 Draco Card
4445 Luciola Vespa Card
4447 Centipede Card
4448 Cornus Card
4449 Dark Shadow Card
5508 Shark_Hat
5509 Sting_Hat
5593 K_Rabbit_Bonnet
15008 Flame_Sprits_Armor__
","This has been already introduced on rAthena:

https://github.com/rathena/rathena/commit/5a4cd7426ee67bc87a845651bedc55bce2ff4487

Would be possible to solve this?",7551429
873,Shadow equipments are not working properly,open,2015-06-10T08:23:37Z,2016-10-08T21:56:52Z,,CONTRIBUTOR,"Based on
http://herc.ws/board/tracker/issue-8593-shadow-weapon-make-spesific-skill-cant-be-used/

Current bugs:
- Spesific skill can't be used when wearing Shadow weapon and Shadow shield, eg: Sonic Blow which require Katar (try to re-equip if you still can't reproduce)
- The damage became weird (tested on katar, see ss)
  http://s11.postimg.org/xcklswrz7/screen_Hercules002.jpg

(ps: shadow equipment already present in item_db)
","This will be fixed by the item_viewid branch (but it's at an early stage and still needs quite a bit of work)
",7551429
874,cast ninja spell,open,2015-06-07T04:16:37Z,2016-06-19T15:12:21Z,,NONE,"is the chance of this skill is official behavior? super high chance.
","no i think cast ninja spell still 100ms
",7551429
875,NPC shop window and dialogue.,open,2015-06-07T03:36:14Z,2019-01-23T19:42:49Z,,NONE,"http://hercules.ws/board/tracker/issue-1707-buy-window-npc/

http://hercules.ws/board/tracker/issue-5345-callshop-npc-check-near/

Probably related to those issues.

With a shop window open (not all but those called with callshop), you can speak to other NPCs and even move, which is a door for exploits.
","not sure about bumping old bug report, and not sure if this is related

```
prontera,155,185,5	shop	test1	1_F_MARIA,501:1000
prontera,158,185,5	script	test2	1_F_MARIA,{
	mes ""haha"";
	close2;
	callshop ""test1"", 1;
	end;
}
prontera,161,185,5	script	test3	1_F_MARIA,{
	mes ""normal msg"";
	close;
}
```
open a shop normally with `test1` can't walk, can't click npc, which is fine
but if using `test2` to open a shop, player can walk around

so this is a bug
1. click on test2, got a shop window, you can walk around
2. click on test3, you actually get a npc window
3. click the shop window close
and you got stuck
https://raw.githubusercontent.com/AnnieRuru/customs/master/screenshots/screen2019Hercules002.jpg",7551429
876,Cast ninja spells (wind),open,2015-06-07T03:16:51Z,2015-06-07T16:43:21Z,,NONE,"still affect players even though they are using immunity cards like nightmare card etc.
",,7551429
877,New PBKDF2 Authentication System,open,2015-03-07T03:50:07Z,2018-04-28T23:16:57Z,,NONE,"Hello.

I've been talking with some guys on irc, and I decided on implementing a sane and secure password authentication system.

What is the problem with the current authentication system? The methods of authenticating are all ridiculously easy to break / are already broken.
# The current problems

First, we have the plaintext storage of passwords. I have nothing to comment, I think we should respect our clients enough to not store their passwords on our database.
Second, we have the MD5 storage of passwords. Well, this is pretty easy to break with a rainbow table, so it doesn't offer anything else apart from a fake notion of protection.
Third, we have the passwordencrypt client authentication method, which asks for a salt to the server and sends the password encrypted with MD5 together with the hash. I couldn't make this work on recent clients, and this forces the storage of unencrypted passwords on the database, what I already said is terrible.
# Do I need to change anything to make my server work with it?

My implementation is COMPLETELY backwards compatible. No tutorial will have to be changed, and no conversors will have to be run.

Inf act, my implementation uses all state-of-the-art technologies and works seamlessly: you just update Hercules, the MySQL database, and you're good to go. You don't need to change or execute a single line of anything (except with use_md5_passwords, where you need to set old_md5_passwords to yes and that's it).
# How does it work?

Three new columns were added to the login table: `auth_hash`, `auth_salt`, `auth_iter_count`. These three are responsible for the new authentication using PBKDF2 with HMAC-SHA512 and a salt of 64 bytes generated with a cryptographically strong pseudo-random algorithm.

When a new connection is made, the emulator first looks for the old `user_pass` column. If it is empty, this means that the account already uses the new authentication system, so it just authenticates using PBKDF2.
If `user_pass` is not empty, Hercules first looks if old_md5_passwords is defined (the same as use_md5_passwords, but renamed to avoid confusion) and authenticates using md5 if it is. If not, it authenticates using the plaintext password stored in the DB. After that, a conversion is made from the legacy authentication system (either plaintext or md5) to the new system. Then, the `user_pass` column is cleaned.

I've already tested the system using plaintext and md5, and everything is working fine. I didn't test the code with passwordencrypt (when the client sends the password already hashed with MD5 together with a salt) because I couldn't get a client to use it, does any modern client supports it or is it broken? Even so, the code that makes the authentication is still there, it should work normally.

When designing the code, I've restricted any access to the plaintext password to the maximum. The passwords are not printed or written to the logs anymore, there is no global access to the passwords (they are only accessible as local variables in only a handful of functions).
I've followed these guidelines when designing the system: https://crackstation.net/hashing-security.htm
# New Dependencies

As I believe no one should make their own cryptographic function implementation, there is a new dependency on OpenSSL's libcrypto. All Visual Studio projects have been updated and the makefile has been also updated to require libcrypto. It is a fast and secure library, so I believe this is a good decision.
# Drawbacks

All systems that use authentication will have to rewrite the authentication code to work. I am already working at FluxCP to make it work with the new authentication system.
# Conclusion

This is kind of a big update, but the extra security added is very important and present in any serious project nowadays. This addition will be good for Hercules.

<!-- Reviewable:start -->

---

This change is [<img src=""https://reviewable.io/review_button.svg"" height=""35"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/466)

<!-- Reviewable:end -->
","I am kind of very busy at my university at the moment (since my last comment hehe), this semester is proving more difficult than I expected.

When I get some free time I'll dedicate myself to this and see if I can find a solution to the DoS problem.
",7551429
878,Roulette giving out coin ??,open,2014-12-03T19:29:39Z,2016-03-15T00:16:30Z,,MEMBER,"The Roulette System, sometime (random) when it move to upper level  it give coin to players.
The system give the coin the moment I clicked on the ""Start"" button.
The previous prize isnt a Silver Coin, but when I click start to move on to next level, it give a coin.
This happen randomly, probably 1 / 10 rounds ?

![Preview](http://i.imgur.com/n5Q8E2I.png)
As you can see from the picture, I get a few coins . (ignore the Refine Deed)
","In very recent client, its available if you diff it from nemo
",7551429
879,Deprecation of legacy script commands,open,2014-10-18T23:35:27Z,2017-10-22T13:14:15Z,,MEMBER,"Marking some legacy script commands as deprecated, for future removal.

**_NOTE: This is a work in progress, please DO NOT merge.**_

Goals of the project:
- Discourage the use in new scripts of certain legacy script commands that would promote bad scripting habits.
- Press users to update their custom scripts to remove said commands.
- Provide user documentation on how to replace those commands from custom scripts.
- Prepare for the complete removal of those script commands.

Non goals:
- Prevent any existing scripts from working.
- Remove any script commands.

Commands slated for removal and suggested alternatives (list will be integrated with other commands)
- [x] `menu` -> `select`, `prompt`
- [ ] `set` -> direct assignment (NOTE: This can't be done at the moment, as there are some edge cases where `set` is still necessary, unfortunately. We may provide a non-deprecated synonym for those edge cases.
- [x] `setr` (internal use only)
- [x] `checkquest` -> `questprogress` (NOTE: This requires a re-commit of 4ac673941714032ada6d26fb60936ec510bbe496)
- [ ] `goto` -> proper use of `if`, `while`, `for`, `switch`. A synonym for edge cases (and for internal use) might be provided.
- [x] `jump_zero` -> proper use of `if`, `while`, `for`, `switch`. A prefixed synonym internal use is provided.
- [x] `setdragon`, `setmadogear`, `setriding` -> `setmount`
- [x] `checkriding`, `checkdragon`, `checkmadogear` -> `checkmount`
- [x] `petheal` -> `petskillsupport`
- [ ] `cardscnt` -> `getequipcardcnt`
- [ ] `basicskillcheck` -> `getbattleflag(""basic_skill_check"")`
- [x] `save` -> `savepoint`
- [x] `cmdothernpc` -> `donpcevent`
- [x] `enablearena`, `disablearena` -> `enablewaitingroomevent`, `disablewaitingroomevent`
- [ ] `setmapflagnosave` -> `setmapflag` (requires source changes to `setmapflag`)
- [x] `petskillattack` -> `petskillattack2` (and rename back to `petskillattack`, eventually). `petskillattack` is the same as `petskillattack2` with the `div` argument set to 0.
- [x] `isday` -> `!isnight()`
- [ ] `checkequipedcard` -> Never used. Loop through `getinventorylist`'s results if necessary.
- [ ] `getusersname` -> Never used. It could be replaced by a new command that returns an array of users (IDs, names), since we now have support for very large arrays.
- [ ] `recovery` -> Never used. It could be replaced by a new command that returns an array of users (IDs, names), and a loop on said array.
- [ ] `globalmes` -> Never used. It could be replaced by a new command that returns an array of users (IDs, names), and a loop on said array.
-    `awake` -> use of NPC timers instead. [keeping it for the time being, see discussion below]
- [x] `checkre` -> We should export a constant instead.
- [ ] `consumeitem` -> `itemeffect` (misleading name, and two synonyms for the same command is one too many)
- [ ] `classchange`

`petheal` can't be replaced by `petskillsupport` - see comment below -- nevermind, it can be replaced after all, it's custom.

<!-- Reviewable:start -->

---

This change is [<img src=""https://reviewable.io/review_button.svg"" height=""35"" align=""absmiddle"" alt=""Reviewable""/>](https://reviewable.io/reviews/herculesws/hercules/374)

<!-- Reviewable:end -->
","please add `classchange`, its useless now
we already have `changebase` and `changelook`
",7551429
880,"Increase MAX_MOB_DB to support newest mobs w/ID 3,000+",open,2014-07-04T12:22:01Z,2020-03-08T22:32:27Z,,NONE,"Because the last thousand entries to MAX_MOB_DB are reserved for clones, requesting src/map/mob.h to be increased at least to 5,000 rather than the current:
# define MAX_MOB_DB 4000

... to support mobs with ID range of 3,000-4,000 (Jitterbug, Faceworm Queen, etc).
","@jTynne 
This was done in https://github.com/HerculesWS/Hercules/commit/228a826dfdde3581f8e5d757ec458119d6079524

However, I keep this issue open as that causes serious problem of clone's being conflicted with JobID as warning says..

@hemagx @MishimaHaruna 
",7551429
881,Episode 15.2 : Memory Record,open,2014-06-30T16:22:11Z,2019-05-25T15:20:35Z,,CONTRIBUTOR,"This is a TODO list for updates from [Episode 15.2 : Memory Record](http://ro.gnjoy.com/news/update/View.asp?seq=143)

- [x] UI Update
- [x] New World Map
- [x] Shop History (Buy/Sell Log)
- [ ] Eden Group Market Hall
- [ ] Summons & Homuculus S Update
- [ ] Monster EXP Increased (Base 75% & Job 100%)
- [ ] Monster HP/ATK Adjustment
- [ ] [WoE TE Items](http://ro.gnjoy.com/news/update/View.asp?seq=156&curpage=2)
- [ ] [Lucky Roulette](http://ro.gnjoy.com/news/update/View.asp?seq=157&curpage=2)
- [ ] [Pet Evolution](http://ro.gnjoy.com/news/update/View.asp?seq=158&curpage=2)
- [ ] Memorial Dungeon
  - [ ] [Infinite Space](http://ro.gnjoy.com/news/update/View.asp?seq=159&curpage=2)
  - [ ] Central Laboratory
- [ ] [Clan System](http://ro.gnjoy.com/news/update/View.asp?seq=160&curpage=1)
- [ ] [RoDex (Revamped Mail System)](http://ro.gnjoy.com/news/update/View.asp?seq=161&curpage=1)
- [ ] Pazudora Island (JRO)
","UI Update and New World Map isn't related to server side, and works fine if your client is >=2014-06-xx(UI) , >=2014-02-05(World Map)
",7551429
882,RE Job Repair Script,open,2014-06-16T19:56:44Z,2016-03-15T00:11:19Z,,CONTRIBUTOR,"This issue is regarding https://github.com/HerculesWS/Hercules/blob/master/npc/re/jobs/repair.txt

I honestly don't see the point in having this NPC enabled by default or to exist at all. Allow me to explain...

From what it seems, this NPC was created on kRO / Official as a means to reset quest logs and quest variables of players who had gotten stuck in the middle of quests when RE was implemented. How would this happen? Easy, by using the exact same variable names & quest log IDs on the RE scripts, for job quests that was used on pre-RE. Correct me if I'm wrong in this.

This honestly seems a bit overkill for something so simple to fix, it could have easily been a fix applied with a sql-upgrade file.

On another note, this NPC does not seem to apply to servers which are new / fresh. This NPC would only apply to those that upgraded from pre-RE to RE.

Does this script even apply to us? Were the same variable names used in our scripts when using RE instead of pre-RE?

Would there be any complaints if this NPC was removed and replaced by an optional sql-upgrade file?

Perhaps Euphy can chime in regarding this script.
","I'd like to point out that Gravity typically will implement things in a weird manner at times due to limitations in AEGIS that they aren't willing to fix or can't fix. recall_completequest is a perfect example of this. As for this being added way after renewal, that makes sense. They most likely didn't start getting reports of this until people who logged out of RO during a job quest in pre-RE logged back in awhile after RE was implement. IE: old players returning once they heard about RE. I'd also like to point out that last time I checked, this NPC is currently only present on kRO. It appears to have been removed from iRO if it was ever there at some point.

After breaking down this NPC, it's exact functions:

lines 84 ~ 88
    Deletes items given to player during Warlock quest. The items are used in a hunting quest (11107) and removed during completion.

Line 102
    Resets rebirth quest.

Lines 115 ~ 132
    Deletes quest log entry for the last quest log variable in 2nd job quests (the one that gets marked as a completed quest) and resets entire job quest variable to 0 (restart the quest). tl;dr: resets the job quest completely.

Lines 184 ~ 197
    Same as above but for third class.

(The weird part about these sections is it's deleting a completed quest, it checks if the quest variable that marks a job quest as completed if completed and then deletes it and resets the quest. So at this point u could have a knight class but appear as if u never did the quest cuz ur variables are now gone/reset, if we didnt have Class checks on job quests this would cause an exploit).

Lines 237 ~ 271
    A GM NPC which is for debugging the Valerie NPC. It gives the character the highest possible variable # for all job quests so they could check if the npc worked in-game. It serves no other purpose but this.

Diffing a pre-RE jobs folder from AEGIS with an RE one, the 2nd job quests don't change much, other than quest log support actually being used in production. Variables don't even appear to overlap as I previously thought.

The only reason I can come up with for this NPC is that it's for the process at which characters can go either directly into third or into trans then 3rd for extra sk points. Perhaps once thirds were implemented there was a demand for people who were either in the process of transing, who just wanted to go third instead. And those that wanted to go trans first but couldn't.

Still looking for a news / forum post on kRO to confirm this or find out more info.
",7551429
883,Completion of error handling,open,2014-06-07T13:15:40Z,2015-06-07T15:52:28Z,,NONE,"I have looked at a few source files for your current software. I have noticed that some checks for return codes are missing.

Would you like to add more error handling for return values from functions like the following?
- [fprintf](http://pubs.opengroup.org/onlinepubs/9699919799/functions/fprintf.html) ⇒ [WriteDump](https://github.com/HerculesWS/Hercules/blob/3def3af50a09d934f7a288e930aa3376b8c2d02f/src/common/utils.c#L36)
- [pthread_mutex_init](http://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_init.html) ⇒ [ramutex_create](https://github.com/HerculesWS/Hercules/blob/bc1d286cc71a7ae82d9639f4a832970a287c0d71/src/common/mutex.c#L53)
",,7551429
884,Complete build options for Pthread API,open,2014-06-07T12:35:50Z,2015-09-25T02:04:11Z,,NONE,"Would you like to add the configuration script ""[AX_PTHREAD](http://www.gnu.org/software/autoconf-archive/ax_pthread.html)"" to [your build specification](https://github.com/HerculesWS/Hercules/blob/b7373b6de5b41a4b420741da9ebf0570e36c11c7/configure.in#L1101)?
","Good to know. I wasn't aware of `AX_PTHREAD`.
",7551429
885,SQL date/time fields and general improvements,open,2014-04-25T09:32:51Z,2016-07-08T00:23:39Z,,MEMBER,"Starting with MySQL 5.7, strict mode throws an error when you try to insert a `0000-00-00` date/datetime value.

The easy fix would be to replace all our `0000-00-00` with other values (either `1970-01-01` or `CURRENT_TIMESTAMP` / `CURRENT_DATE` depending on the context), but we could use this to improve how we handle various things:
- (not strictly related to timestamps) We currently don't support `NULL` values (last time I tried, I remember the emulator crashing with some nullpointer access). We could remove many `NOT NULL` and use `NULL` as default value several tables. An example of this would be the last login field in the login table (NULL when the user has never logged in), or the partner/parent/child IDs in the character table (NULL when the character isn't married/adopted or has no children), or the party/guild IDs in the char table, and so on.
- We currently don't support timezones. Many of our `datetime` fields should be converted into `timestamp` fields, which natively support timezones (rather than storing a local time, they store the unix timestamp -- thus UTC timezone), and they're converted to localtime when you query it or when you save to it. I have done that in past in a private repository (running a server with different timezone than its host machine, and having a control panel running on a webserver with yet another timezone, so I had to add some rudimentary timezone support in order for it to work correctly), so I know some of the issues that may arise when doing this.  I'll have to dust my patch off, and see if it needs improvements.

I'll work on this in a branch as soon as I have enough time available.
","Partly relates to PR #1344
",7551429
886,About AB_OFFERTORIUM,open,2014-01-02T09:28:43Z,2015-08-30T09:19:28Z,,NONE,"Skill Name: AB_OFFERTORIUM

SkillID: 5011

BUG: 
Increase the therapeutic effect of its own subject, should increase their healing effects.
Similar Items Bouns:  bonus2 bSkillHeal, n, x; and bonus2 bSkillHeal2, n, x;
It is now bonus2 bSkillHeal2, n, x; effect, but it should bonus2 bSkillHeal, n, x; effect
","up???
",7551429
887,"""AUTHORS"" FILE",open,2013-12-30T06:32:00Z,2018-09-13T20:19:41Z,,MEMBER,"Discussion originally started in #226 i'm moving it into a issue so that it doesn't count as a pull request (since its not one anymore).
I'll repost the original messages by date below.
","Can this be closed?
",7551429
888,Episode 15.1 : Fantasmagorica,open,2013-12-22T12:35:14Z,2019-05-25T15:20:42Z,,CONTRIBUTOR,"This is a TODO list for updates from [Episode 15.1 : Fantasmagorica](http://ro.gnjoy.com/news/update/View.asp?seq=137)

- [ ] NPC Placement Changes
- [ ] 15.1 Quests (5 Quests)
- [ ] [Rebellion Class](http://ro.gnjoy.com/news/update/View.asp?seq=138)
- [ ] [Rebellion Weapons](http://ro.gnjoy.com/news/update/View.asp?seq=139)
- [ ] Rebellion Quest
- [ ] Memorial Dungeon
  - [ ] Charleston Factory
  - [ ] Fenrir and Airship Assault
- [ ] [Heroes' Trail Part 3](http://ro.gnjoy.com/news/update/View.asp?seq=140)
- [ ] [Bio Labs Nightmare Mode](http://ro.gnjoy.com/news/update/View.asp?seq=142)
- [x] Clothing Dyes for Kagerou & Oboro
- [ ] Max HP Limits (lvl 99 = 330k, 150 = 660k, 175 = 1.1m)
- [ ] New Guild Skill - Guild Storage
- [ ] [Card Update](http://ro.gnjoy.com/news/update/View.asp?seq=186&curpage=3)
",About _New Guild Skill - Guild Storage_: #1092  Guild Storage Skill,7551429
889,Episode 14.3 : Decisive Battle,open,2013-12-17T01:24:13Z,2019-05-25T15:20:50Z,,CONTRIBUTOR,"This is a TODO list for updates from Episode 14.3 : Decisive Battle

- [ ] [14.3 Decisive Battle: Part 1](http://ro.gnjoy.com/news/update/View.asp?seq=133)
  - [ ] Equipment Comparison System
  - [x] Clock Tower Dungeon Nightmare Mode
  - [ ] Quests
- [ ] [14.3 Decisive Battle: Part 2](http://ro.gnjoy.com/news/update/View.asp?seq=134)
  - [x] Max Level Increase to 175 / 60
  - [x] New Third Class Skills
  - [x] Max Vending Price = 1 Billion z 
  - [x] Bank System
  - [x] [Clan System / Guild Representation System](http://ro.gnjoy.com/news/update/View.asp?seq=135)
  - [ ] [New Cards](http://ro.gnjoy.com/news/update/View.asp?seq=229&curpage=1)
  - [ ] Quests
",,7551429
890,Episode 14.2 : Eclage,open,2013-12-17T01:23:49Z,2019-05-25T15:20:58Z,,CONTRIBUTOR,"This is a TODO list for updates from [Episode 14.2 : Eclage](http://ro.gnjoy.com/news/update/View.asp?seq=10)

- [ ] Battlegrounds Queue System _[ See #69 ]_
- [x] New Carts (Levels: 101, 111, 121 & 131)
- [x] 14.2 Quests / Eclage
- [x] Eden Quests 
  - [x] Levels 111 ~ 120
  - [x] Levels 121 ~ 130
  - [x] Levels 131 ~ 140
- [x] Falcon Flute
- [x] Navigation System
- [x] [New Izlude (Izlude split Into 5 Copies)](http://ro.gnjoy.com/news/notice/View.asp?BBSMode=10001&seq=6085)
- [x] [Novice Training Academy](http://ro.gnjoy.com/news/notice/View.asp?BBSMode=10001&seq=6085)
- [x] [New Character Creation Method](http://ro.gnjoy.com/news/notice/View.asp?BBSMode=10001&seq=6085)
- [x] Monster HP Bar
- [ ] [Changes to Enchanting on Malangdo](http://ro.gnjoy.com/news/update/View.asp?seq=105)
- [ ] [WoE : Training Edition](http://ro.gnjoy.com/news/update/View.asp?seq=121)
  - [ ] Mini God Item Quests
  - [ ] Guild & Daily Quests in siege areas
- [ ] Transcendent quest to waive the cost of transcending.
- [ ] Monster Shadow Size
- [ ] Memorial Dungeon
  - [x] [Old Glastheim](http://ro.gnjoy.com/news/update/View.asp?seq=122)
  - [ ] Wave Mode 
    - [ ] Sky Mode
    - [ ] Forest Mode
- [x] Champion Monsters
- [ ] ﻿﻿Job EXP increased from Monsters with lvl 100+﻿
- [x] Max level increased to 160/50
- [ ] Skill Timers
- [ ] Ranger Falcon changed to Owl
- [x] [Crystal Synthesis](http://irowiki.org/wiki/Eden_Group_Crystal_Synthesis) / [Headgear Synthesis Quests](http://ro.gnjoy.com/news/update/View.asp?seq=124)
- [ ] [Heroes' Trails : Part 1](http://ro.gnjoy.com/news/update/View.asp?seq=127)
  - [ ] [New Cards](http://ro.gnjoy.com/news/update/View.asp?seq=216&curpage=2) [(GnjoyTW)](https://ro.gnjoy.com.tw/notice/notice_view.aspx?id=2543)
  - [ ] Memorial Dungeon
    - [ ] Faceworm Nest
    - [ ] Sarah's Memory
- [ ] [Heroes' Trails : Part 2](http://ro.gnjoy.com/news/update/View.asp?seq=130)
  - [ ] Memorial Dungeon
    - [ ] Devil's Tower
    - [ ] Cursed Knight
    - [ ] Geffen Magic Tournament
    - [ ] [Horror Toy Factory](http://ro.gnjoy.com/news/update/View.asp?seq=132)
  - [ ] Shadow System",,7551429
891,@command Usage: messages,open,2013-11-27T12:30:53Z,2015-09-25T02:02:22Z,,MEMBER,"In https://github.com/HerculesWS/Hercules/commit/8ffe8285453b33d0f4266a16517ba3a6dc54e909 for example there was this

```
Please enter ban time and a player name (usage: @charban/@ban/@banish/@charbanish <time> <char name>).
```

which displayed many removed or outdated aliases, some other commands have this too, my proposal is to make those usage messages dynamic (at least where it displays the aliases), so that the information can always be up to date with atcommand.conf
","I agree. I never liked the command names hardcoded in a string, since they're configurable and the messages always tend to become outdated.

The easiest fix would probably be to show the version of the command that was issued (If you are using the 'ban' command, there's no need for it to also display 'banish'), and the help strings could simply contain a %s token where the command name should be displayed.
",7551429
892,"SC_NOCHAT val1, is a ""wtf"".",open,2013-11-26T18:23:43Z,2013-11-26T18:24:16Z,,MEMBER,"in all sc_nochat restrictions it compares against val1, e.g.

```
    if (sd->sc.data[SC_NOCHAT] && sd->sc.data[SC_NOCHAT]->val1&MANNER_NOROOM)
        return;
```

at first I was like hum so that enables sc_start calls to customise individually the restrictions, however: 

```
            case SC_NOCHAT:
                tick = 60000;
                val1 = battle_config.manner_system; //Mute filters.
                if (sd)
                {
                    clif->changestatus(sd,SP_MANNER,sd->status.manner);
                    clif->updatestatus(sd,SP_MANNER);
                }
                break;
```

somehow, it stores battle_config.manner_system in val1 for no apparent use, which causes modifications to battle_config.manner_system applied by e.g. @reloadbattleconf (or even a server restart) to not take affect on pre-existing mutes (muted users).
",,7551429
893,Whisper Logs,open,2013-11-16T22:52:23Z,2016-03-15T00:05:45Z,,MEMBER,"1. clif_parse_WisMessage 'W' type is logged even without a target, does this make any sense?
2. clif_parse_WisMessage 'W' is used even for NPC: calls, shouldn't it have its own? (would allow for users to log NPC: calls without 'W' logs)
3. clif_parse_WisMessage 'W' also serves to log #channel conversations, however this isn't consistent since in clif_parse_GlobalMessage the gcbind state has no logs, how about we create a log type for channel conversations?
","1. Wouldn't it make more sense to create a log specifically for all channels (i.e. 'channellog') that stores who said what on a channel from a certain map (because of #map)? Maybe even include the (x, y) coordinates as well?
",7551429
894,@recallall suggestion,open,2013-10-24T22:39:05Z,2018-09-13T20:14:21Z,,MEMBER,"Either, modify @recallall or create a new command such as @recallmost.
The purpose of the new or modified command would be to disregard venders (buyer & seller) and chat room operators/users, possibly also users that are currently in a NPC chat as they might else get stuck when used during a quest, and teleport/warp everyone else to the person who used the command.
","i already got this one over mine i think im going to create a PR of it
",7551429
895,Status resistance,open,2013-10-01T00:09:18Z,2016-03-15T00:00:58Z,,MEMBER,"Do we need this?

Commits to consider:
- 5f59e50f462873f9607ffd233550bb2e68f6d38f: - Second phase of the big status resistance update:
  - Created a structure to consider status change source (we are still missing the information and use a copy of target instead right now, lighta is working on a solution)
  - Entered the fully official formulas of all status changes based on an Aegis leak (since source is not in right now the level difference will always give ""0"")
  - As tick_def2 is never equal to sc_def2, it will not use it by default anymore
  - Applied Deep Sleep's kRO balance update, duration can now be reduced by 50ms for each int and each base level, minimum duration is 5000ms
  - The final chance for the status change will now consider Aegis accuracy (everything between 0.01% and 0.09% should actually be 0.1%, etc.)
- 044c78412164b5a576a71305e1e44582ac00ec53: - Fixed the order of parameters in a nullpo_retr call (bugreport:7402)   [Follow-up]
- cb0f255506ef8463dc4dc962a2a439c3ebbcdd37: -Follow up r17206, transfert *src on status_get_sc_def to properly calculate defense.  nb :  NULL is transmitted for atcommand and npc call since they shouldn't be reduced.
  src = direct user, so we can compare directly, if you want to compare to master please cast so.
  saved status from char won't have *src currently since I don't believe we need to recalculate def.
- fda7f9d5354ef20e5db70dba823ffd7c58560354: -Remove unwanted debuginfo from r17211 
","set to pending, #154 is awaiting for cb0f255 
",7551429
896,Item database corrections,open,2013-09-30T23:55:15Z,2016-03-14T23:59:12Z,,MEMBER,"Commits to consider:
- 5f59e50f462873f9607ffd233550bb2e68f6d38f: - Fixed chances for inflicting status changes on Spectral Spear (self), Ivory Lance and Pagdayaw (see note [1] below)
- 7ef1e80cb34a13f1d002eddb83028c671a997668 (all parts)
- ecdd78c13f4955a862e05cc3aebf5c9ec2268cf6 (fixup)
- 0b68607fb780b884e47221f0ba5319ac4e3e27b3:\* Minor update to some item scripts.

[1]: It might be worth to check these items against special.sc.  If the special.sc I have is accurate and up to date (I'm afraid I cannot guarantee that), in the Spectral_Spear script we're adding a bonus against the Undead race while Aegis adds a bonus against the Undead element.

```
item Spectral_Spear
    event OnStartEquip:
        AddRaceTolerace RACE_Undead 10
        AddRaceTolerace RACE_Demon 10
        AddAttrTolerace PROPERTY_Darkness 10
        AddDamage_Property Target PROPERTY_Darkness 20
        AddDamage_Property Target PROPERTY_Undead 20
        RaceAddDamage RACE_Demon 20
        AddState_MLEATK User HEALTHConfusion 100
        AddHealAmount_Kill VAR_HP 50
    return
    event OnFinishEquip:
        SubRaceTolerace RACE_Undead 10
        SubRaceTolerace RACE_Demon 10
        SubAttrTolerace PROPERTY_Darkness 10
        SubDamage_Property Target PROPERTY_Darkness 20
        SubDamage_Property Target PROPERTY_Undead 20
        RaceSubDamage RACE_Demon 20
        SubState_MLEATK User HEALTHConfusion 100
        SubHealAmount_Kill VAR_HP 50
    return
```

Also, I do not have a special.sc entry for Ati_Atihan_Hat.
","Confirmed to be up to date, as for anti_atihan_hat

```
item Ati_Atihan_Hat                 
    event OnStartEquip:
        AddAttrTolerace  PROPERTY_Water 1
        AddAttrTolerace  PROPERTY_Fire 1
        AddAttrTolerace  PROPERTY_Wind 1
        AddState_MLEATK Target HEALTHCurse 30
    return
    event OnFinishEquip:
        SubAttrTolerace  PROPERTY_Water 1
        SubAttrTolerace  PROPERTY_Fire 1
        SubAttrTolerace  PROPERTY_Wind 1
        SubState_MLEATK Target HEALTHCurse 30
    return
```
",7551429
897,pc_autosave interval improvement,open,2013-09-28T19:38:36Z,2016-03-14T23:57:35Z,,MEMBER,"pc_autosave is a timer that is run continuously but unlike interval timers it resets itself on every run (which in my opinion, is a waste).

```
    interval = map->autosave_interval/(map->usercount()+1);
    if(interval < map->minsave_interval)
        interval = map->minsave_interval;
    timer->add(timer->gettick()+interval,pc->autosave,0,0);
```

wouldn't it be more efficient to have it be a interval timer, and then when it is run do: measure interval, check if different from current, and if so just update the timer's interval? that way the timer is reused instead of needlessly removing itself and adding it over
",,7551429
898,Centralize Job ID/Name/Data,open,2013-09-28T18:38:16Z,2016-03-14T23:54:39Z,,MEMBER,"Doesn't really belong to performance but I didn't feel well on another milestone, anyway:
Its all over the place, really. By aggregating it smartly we could duck hundreds of lines of code and make the whole process of adding or modifying job data waaaay more flexible (and thus faster).
Glance job names:

```
const char* job_name(int class_)
{
    switch (class_) {
    case JOB_NOVICE:
    case JOB_SWORDMAN:
    case JOB_MAGE:
    case JOB_ARCHER:
    case JOB_ACOLYTE:
    case JOB_MERCHANT:
    case JOB_THIEF:
        return msg_txt(550 - JOB_NOVICE+class_);

    case JOB_KNIGHT:
    case JOB_PRIEST:
    case JOB_WIZARD:
    case JOB_BLACKSMITH:
    case JOB_HUNTER:
    case JOB_ASSASSIN:
        return msg_txt(557 - JOB_KNIGHT+class_);

    case JOB_KNIGHT2:
        return msg_txt(557);

    case JOB_CRUSADER:
    case JOB_MONK:
    case JOB_SAGE:
    case JOB_ROGUE:
    case JOB_ALCHEMIST:
    case JOB_BARD:
    case JOB_DANCER:
        return msg_txt(563 - JOB_CRUSADER+class_);

    case JOB_CRUSADER2:
        return msg_txt(563);

    case JOB_WEDDING:
    case JOB_SUPER_NOVICE:
    case JOB_GUNSLINGER:
    case JOB_NINJA:
    case JOB_XMAS:
        return msg_txt(570 - JOB_WEDDING+class_);

    case JOB_SUMMER:
        return msg_txt(621);

    case JOB_NOVICE_HIGH:
    case JOB_SWORDMAN_HIGH:
    case JOB_MAGE_HIGH:
    case JOB_ARCHER_HIGH:
    case JOB_ACOLYTE_HIGH:
    case JOB_MERCHANT_HIGH:
    case JOB_THIEF_HIGH:
        return msg_txt(575 - JOB_NOVICE_HIGH+class_);

    case JOB_LORD_KNIGHT:
    case JOB_HIGH_PRIEST:
    case JOB_HIGH_WIZARD:
    case JOB_WHITESMITH:
    case JOB_SNIPER:
    case JOB_ASSASSIN_CROSS:
        return msg_txt(582 - JOB_LORD_KNIGHT+class_);

    case JOB_LORD_KNIGHT2:
        return msg_txt(582);

    case JOB_PALADIN:
    case JOB_CHAMPION:
    case JOB_PROFESSOR:
    case JOB_STALKER:
    case JOB_CREATOR:
    case JOB_CLOWN:
    case JOB_GYPSY:
        return msg_txt(588 - JOB_PALADIN + class_);

    case JOB_PALADIN2:
        return msg_txt(588);

    case JOB_BABY:
    case JOB_BABY_SWORDMAN:
    case JOB_BABY_MAGE:
    case JOB_BABY_ARCHER:
    case JOB_BABY_ACOLYTE:
    case JOB_BABY_MERCHANT:
    case JOB_BABY_THIEF:
        return msg_txt(595 - JOB_BABY + class_);

    case JOB_BABY_KNIGHT:
    case JOB_BABY_PRIEST:
    case JOB_BABY_WIZARD:
    case JOB_BABY_BLACKSMITH:
    case JOB_BABY_HUNTER:
    case JOB_BABY_ASSASSIN:
        return msg_txt(602 - JOB_BABY_KNIGHT + class_);

    case JOB_BABY_KNIGHT2:
        return msg_txt(602);

    case JOB_BABY_CRUSADER:
    case JOB_BABY_MONK:
    case JOB_BABY_SAGE:
    case JOB_BABY_ROGUE:
    case JOB_BABY_ALCHEMIST:
    case JOB_BABY_BARD:
    case JOB_BABY_DANCER:
        return msg_txt(608 - JOB_BABY_CRUSADER + class_);

    case JOB_BABY_CRUSADER2:
        return msg_txt(608);

    case JOB_SUPER_BABY:
        return msg_txt(615);

    case JOB_TAEKWON:
        return msg_txt(616);
    case JOB_STAR_GLADIATOR:
    case JOB_STAR_GLADIATOR2:
        return msg_txt(617);
    case JOB_SOUL_LINKER:
        return msg_txt(618);

    case JOB_GANGSI:
    case JOB_DEATH_KNIGHT:
    case JOB_DARK_COLLECTOR:
        return msg_txt(622 - JOB_GANGSI+class_);

    case JOB_RUNE_KNIGHT:
    case JOB_WARLOCK:
    case JOB_RANGER:
    case JOB_ARCH_BISHOP:
    case JOB_MECHANIC:
    case JOB_GUILLOTINE_CROSS:
        return msg_txt(625 - JOB_RUNE_KNIGHT+class_);

    case JOB_RUNE_KNIGHT_T:
    case JOB_WARLOCK_T:
    case JOB_RANGER_T:
    case JOB_ARCH_BISHOP_T:
    case JOB_MECHANIC_T:
    case JOB_GUILLOTINE_CROSS_T:
            return msg_txt(681 - JOB_RUNE_KNIGHT_T+class_);

    case JOB_ROYAL_GUARD:
    case JOB_SORCERER:
    case JOB_MINSTREL:
    case JOB_WANDERER:
    case JOB_SURA:
    case JOB_GENETIC:
    case JOB_SHADOW_CHASER:
        return msg_txt(631 - JOB_ROYAL_GUARD+class_);

    case JOB_ROYAL_GUARD_T:
    case JOB_SORCERER_T:
    case JOB_MINSTREL_T:
    case JOB_WANDERER_T:
    case JOB_SURA_T:
    case JOB_GENETIC_T:
    case JOB_SHADOW_CHASER_T:
            return msg_txt(687 - JOB_ROYAL_GUARD_T+class_);

    case JOB_RUNE_KNIGHT2:
    case JOB_RUNE_KNIGHT_T2:
        return msg_txt(625);

    case JOB_ROYAL_GUARD2:
    case JOB_ROYAL_GUARD_T2:
        return msg_txt(631);

    case JOB_RANGER2:
    case JOB_RANGER_T2:
        return msg_txt(627);

    case JOB_MECHANIC2:
    case JOB_MECHANIC_T2:
        return msg_txt(629);

    case JOB_BABY_RUNE:
    case JOB_BABY_WARLOCK:
    case JOB_BABY_RANGER:
    case JOB_BABY_BISHOP:
    case JOB_BABY_MECHANIC:
    case JOB_BABY_CROSS:
    case JOB_BABY_GUARD:
    case JOB_BABY_SORCERER:
    case JOB_BABY_MINSTREL:
    case JOB_BABY_WANDERER:
    case JOB_BABY_SURA:
    case JOB_BABY_GENETIC:
    case JOB_BABY_CHASER:
        return msg_txt(638 - JOB_BABY_RUNE+class_);

    case JOB_BABY_RUNE2:
        return msg_txt(638);

    case JOB_BABY_GUARD2:
        return msg_txt(644);

    case JOB_BABY_RANGER2:
        return msg_txt(640);

    case JOB_BABY_MECHANIC2:
        return msg_txt(642);

    case JOB_SUPER_NOVICE_E:
    case JOB_SUPER_BABY_E:
        return msg_txt(651 - JOB_SUPER_NOVICE_E+class_);

    case JOB_KAGEROU:
    case JOB_OBORO:
        return msg_txt(653 - JOB_KAGEROU+class_);
    case JOB_REBELLION:
        return msg_txt(694);

    default:
        return msg_txt(655);
    }
}
```

...

```
    struct {
        const char *name;
        int id;
    } jnames[] = {
        { ""Novice"", JOB_NOVICE },
        { ""Swordsman"", JOB_SWORDMAN },
        { ""Magician"", JOB_MAGE },
        { ""Archer"", JOB_ARCHER },
        { ""Acolyte"", JOB_ACOLYTE },
        { ""Merchant"", JOB_MERCHANT },
        { ""Thief"", JOB_THIEF },
        { ""Knight"", JOB_KNIGHT },
        { ""Priest"", JOB_PRIEST },
        { ""Wizard"", JOB_WIZARD },
        { ""Blacksmith"", JOB_BLACKSMITH },
        { ""Hunter"", JOB_HUNTER },
        { ""Assassin"", JOB_ASSASSIN },
        { ""Crusader"", JOB_CRUSADER },
        { ""Monk"", JOB_MONK },
        { ""Sage"", JOB_SAGE },
        { ""Rogue"", JOB_ROGUE },
        { ""Alchemist"", JOB_ALCHEMIST },
        { ""Bard"", JOB_BARD },
        { ""Dancer"", JOB_DANCER },
        { ""Super_Novice"", JOB_SUPER_NOVICE },
        { ""Gunslinger"", JOB_GUNSLINGER },
        { ""Ninja"", JOB_NINJA },
        { ""Novice_High"", JOB_NOVICE_HIGH },
        { ""Swordsman_High"", JOB_SWORDMAN_HIGH },
        { ""Magician_High"", JOB_MAGE_HIGH },
        { ""Archer_High"", JOB_ARCHER_HIGH },
        { ""Acolyte_High"", JOB_ACOLYTE_HIGH },
        { ""Merchant_High"", JOB_MERCHANT_HIGH },
        { ""Thief_High"", JOB_THIEF_HIGH },
        { ""Lord_Knight"", JOB_LORD_KNIGHT },
        { ""High_Priest"", JOB_HIGH_PRIEST },
        { ""High_Wizard"", JOB_HIGH_WIZARD },
        { ""Whitesmith"", JOB_WHITESMITH },
        { ""Sniper"", JOB_SNIPER },
        { ""Assassin_Cross"", JOB_ASSASSIN_CROSS },
        { ""Paladin"", JOB_PALADIN },
        { ""Champion"", JOB_CHAMPION },
        { ""Professor"", JOB_PROFESSOR },
        { ""Stalker"", JOB_STALKER },
        { ""Creator"", JOB_CREATOR },
        { ""Clown"", JOB_CLOWN },
        { ""Gypsy"", JOB_GYPSY },
        { ""Baby_Novice"", JOB_BABY },
        { ""Baby_Swordsman"", JOB_BABY_SWORDMAN },
        { ""Baby_Magician"", JOB_BABY_MAGE },
        { ""Baby_Archer"", JOB_BABY_ARCHER },
        { ""Baby_Acolyte"", JOB_BABY_ACOLYTE },
        { ""Baby_Merchant"", JOB_BABY_MERCHANT },
        { ""Baby_Thief"", JOB_BABY_THIEF },
        { ""Baby_Knight"", JOB_BABY_KNIGHT },
        { ""Baby_Priest"", JOB_BABY_PRIEST },
        { ""Baby_Wizard"", JOB_BABY_WIZARD },
        { ""Baby_Blacksmith"", JOB_BABY_BLACKSMITH },
        { ""Baby_Hunter"", JOB_BABY_HUNTER },
        { ""Baby_Assassin"", JOB_BABY_ASSASSIN },
        { ""Baby_Crusader"", JOB_BABY_CRUSADER },
        { ""Baby_Monk"", JOB_BABY_MONK },
        { ""Baby_Sage"", JOB_BABY_SAGE },
        { ""Baby_Rogue"", JOB_BABY_ROGUE },
        { ""Baby_Alchemist"", JOB_BABY_ALCHEMIST },
        { ""Baby_Bard"", JOB_BABY_BARD },
        { ""Baby_Dancer"", JOB_BABY_DANCER },
        { ""Super_Baby"", JOB_SUPER_BABY },
        { ""Taekwon"", JOB_TAEKWON },
        { ""Star_Gladiator"", JOB_STAR_GLADIATOR },
        { ""Soul_Linker"", JOB_SOUL_LINKER },
        { ""Gangsi"", JOB_GANGSI },
        { ""Death_Knight"", JOB_DEATH_KNIGHT },
        { ""Dark_Collector"", JOB_DARK_COLLECTOR },
        { ""Rune_Knight"", JOB_RUNE_KNIGHT },
        { ""Warlock"", JOB_WARLOCK },
        { ""Ranger"", JOB_RANGER },
        { ""Arch_Bishop"", JOB_ARCH_BISHOP },
        { ""Mechanic"", JOB_MECHANIC },
        { ""Guillotine_Cross"", JOB_GUILLOTINE_CROSS },
        { ""Rune_Knight_Trans"", JOB_RUNE_KNIGHT_T },
        { ""Warlock_Trans"", JOB_WARLOCK_T },
        { ""Ranger_Trans"", JOB_RANGER_T },
        { ""Arch_Bishop_Trans"", JOB_ARCH_BISHOP_T },
        { ""Mechanic_Trans"", JOB_MECHANIC_T },
        { ""Guillotine_Cross_Trans"", JOB_GUILLOTINE_CROSS_T },
        { ""Royal_Guard"", JOB_ROYAL_GUARD },
        { ""Sorcerer"", JOB_SORCERER },
        { ""Minstrel"", JOB_MINSTREL },
        { ""Wanderer"", JOB_WANDERER },
        { ""Sura"", JOB_SURA },
        { ""Genetic"", JOB_GENETIC },
        { ""Shadow_Chaser"", JOB_SHADOW_CHASER },
        { ""Royal_Guard_Trans"", JOB_ROYAL_GUARD_T },
        { ""Sorcerer_Trans"", JOB_SORCERER_T },
        { ""Minstrel_Trans"", JOB_MINSTREL_T },
        { ""Wanderer_Trans"", JOB_WANDERER_T },
        { ""Sura_Trans"", JOB_SURA_T },
        { ""Genetic_Trans"", JOB_GENETIC_T },
        { ""Shadow_Chaser_Trans"", JOB_SHADOW_CHASER_T },
        { ""Baby_Rune_Knight"", JOB_BABY_RUNE },
        { ""Baby_Warlock"", JOB_BABY_WARLOCK },
        { ""Baby_Ranger"", JOB_BABY_RANGER },
        { ""Baby_Arch_Bishop"", JOB_BABY_BISHOP },
        { ""Baby_Mechanic"", JOB_BABY_MECHANIC },
        { ""Baby_Guillotine_Cross"", JOB_BABY_CROSS },
        { ""Baby_Royal_Guard"", JOB_BABY_GUARD },
        { ""Baby_Sorcerer"", JOB_BABY_SORCERER },
        { ""Baby_Minstrel"", JOB_BABY_MINSTREL },
        { ""Baby_Wanderer"", JOB_BABY_WANDERER },
        { ""Baby_Sura"", JOB_BABY_SURA },
        { ""Baby_Genetic"", JOB_BABY_GENETIC },
        { ""Baby_Shadow_Chaser"", JOB_BABY_CHASER },
        { ""Expanded_Super_Novice"", JOB_SUPER_NOVICE_E },
        { ""Expanded_Super_Baby"", JOB_SUPER_BABY_E },
        { ""Kagerou"", JOB_KAGEROU },
        { ""Oboro"", JOB_OBORO },
        { ""Rebellion"", JOB_REBELLION },
    };
```

... (char-server)

```
#define MAX_JOB_NAMES 106
static char* msg_table[MAX_JOB_NAMES]; //  messages 550 ~ 655 are job names

const char* msg_txt(int msg_number) {
    msg_number -= 550;
    if (msg_number >= 0 && msg_number < MAX_JOB_NAMES &&
        msg_table[msg_number] != NULL && msg_table[msg_number][0] != '\0')
        return msg_table[msg_number];

    return ""Unknown"";
}
```

...

```
//550 -> 650: Job Names
550: Novice
551: Swordsman
552: Magician
553: Archer
554: Acolyte
555: Merchant
556: Thief
557: Knight
558: Priest
559: Wizard
560: Blacksmith
561: Hunter
562: Assassin
563: Crusader
564: Monk
565: Sage
566: Rogue
567: Alchemist
568: Bard
569: Dancer
570: Wedding
571: Super Novice
572: Gunslinger
573: Ninja
574: Christmas
575: High Novice
576: High Swordsman
577: High Magician
578: High Archer
579: High Acolyte
580: High Merchant
581: High Thief
582: Lord Knight
583: High Priest
584: High Wizard
585: Whitesmith
//585: Mastersmith //IRO name
586: Sniper
587: Assassin Cross
588: Paladin
589: Champion
590: Professor
//590: Scholar //IRO name
591: Stalker
592: Creator
//592: Biochemist //IRO Name
593: Clown
//593: Minstrel //IRO Name
594: Gypsy
595: Baby Novice
596: Baby Swordsman
597: Baby Magician
598: Baby Archer
599: Baby Acolyte
600: Baby Merchant
601: Baby Thief
602: Baby Knight
603: Baby Priest
604: Baby Wizard
605: Baby Blacksmith
606: Baby Hunter
607: Baby Assassin
608: Baby Crusader
609: Baby Monk
610: Baby Sage
611: Baby Rogue
612: Baby Alchemist
613: Baby Bard
614: Baby Dancer
615: Super Baby
616: Taekwon
617: Star Gladiator
618: Soul Linker
//619: FREE
//620: FREE
621: Summer
622: Gangsi
623: Death Knight
624: Dark Collector
625: Rune Knight
626: Warlock
627: Ranger
628: Arch Bishop
629: Mechanic
630: Guillotine Cross
631: Royal Guard
632: Sorcerer
633: Minstrel
//633: Maestro //IRO Name
634: Wanderer
635: Sura
636: Genetic
//636: Geneticist //IRO Name
637: Shadow Chaser
638: Baby Rune Knight
639: Baby Warlock
640: Baby Ranger
641: Baby Arch Bishop
642: Baby Mechanic
643: Baby Guillotine Cross
644: Baby Royal Guard
645: Baby Sorcerer
646: Baby Minstrel
647: Baby Wanderer
648: Baby Sura
649: Baby Genetic
650: Baby Shadow Chaser
651: Expanded Super Novice
652: Expanded Super Baby
653: Kagerou
654: Oboro
655: Unknown Job
```

...

```
jobchange: ""Params: <job name|ID>\n"" ""Changes your job.\n""
    ""----- Novice / 1st Class -----\n""
    ""   0 Novice              1 Swordman            2 Magician            3 Archer\n""
    ""   4 Acolyte              5 Merchant               6 Thief\n""
    ""----- 2nd Class -----\n""
    ""   7 Knight               8 Priest                     9 Wizard               10 Blacksmith\n""
    ""  11 Hunter           12 Assassin            14 Crusader          15 Monk\n""
    ""  16 Sage              17 Rogue                 18 Alchemist         19 Bard\n""
    ""  20 Dancer\n""
    ""----- High Novice / High 1st Class -----\n""
    ""4001 Novice High     4002 Swordman High    4003 Magician High    4004 Archer High\n""
    ""4005 Acolyte High     4006 Merchant High       4007 Thief High\n""
    ""----- Transcendent 2nd Class -----\n""
    ""4008 Lord Knight      4009 High Priest             4010 High Wizard      4011 Whitesmith\n""
    ""4012 Sniper               4013 Assassin Cross   4015 Paladin              4016 Champion\n""
    ""4017 Professor         4018 Stalker                    4019 Creator               4020 Clown\n""
    ""4021 Gypsy\n""
    ""----- 3rd Class (Regular) -----\n""
    ""4054 Rune Knight    4055 Warlock                 4056 Ranger            4057 Arch Bishop\n""
    ""4058 Mechanic         4059 Guillotine Cross  4066 Royal Guard   4067 Sorcerer\n""
    ""4068 Minstrel            4069 Wanderer              4070 Sura                 4071 Genetic\n""
    ""4072 Shadow Chaser\n""
    ""----- 3rd Class (Transcendent) -----\n""
    ""4060 Rune Knight    4061 Warlock                 4062 Ranger             4063 Arch Bishop\n""
    ""4064 Mechanic         4065 Guillotine Cross  4073 Royal Guard    4074 Sorcerer\n""
    ""4075 Minstrel            4076 Wanderer              4077 Sura                  4078 Genetic\n""
    ""4079 Shadow Chaser\n""
    ""----- Expanded Class -----\n""
    ""     23 Super Novice      24 Gunslinger              25 Ninja                 4045 Super Baby\n""
    ""4046 Taekwon           4047 Star Gladiator     4049 Soul Linker            4050 Gangsi\n""
    ""4051 Death Knight    4052 Dark Collector    4190 Ex. Super Novice  4191 Ex. Super Baby\n""
    ""4211 Kagerou            4212 Oboro            4215 Rebellion\n""
    ""----- Baby Novice And Baby 1st Class -----\n""
    ""4023 Baby Novice      4024 Baby Swordman    4025 Baby Magician   4026 Baby Archer\n""
    ""4027 Baby Acolyte      4028 Baby Merchant       4029 Baby Thief\n""
    ""---- Baby 2nd Class ----\n""
    ""4030 Baby Knight     4031 Baby Priest         4032 Baby Wizard         4033 Baby Blacksmith\n""
    ""4034 Baby Hunter    4035 Baby Assassin   4037 Baby Crusader    4038 Baby Monk\n""
    ""4039 Baby Sage       4040 Baby Rogue        4041 Baby Alchemist   4042 Baby Bard\n""
    ""4043 Baby Dancer\n""
    ""---- Baby 3rd Class ----\n""
    ""4096 Baby Rune Knight  4097 Baby Warlock     4098 Baby Ranger           4099 Baby Arch Bishop\n""
    ""4100 Baby Mechanic       4101 Baby Glt. Cross  4102 Baby Royal Guard  4103 Baby Sorcerer\n""
    ""4104 Baby Minstrel          4105 Baby Wanderer   4106 Baby Sura             4107 Baby Genetic\n""
    ""4108 Baby Shadow Chaser\n""
    ""---- Modes And Others ----\n""
    "" 22 Wedding            26 Christmas          27 Summer           4048 Star Gladiator (Union)\n""
```

... (the following could even get out of the file and populated during runtime by the server using the centralized data)

```
Job_Novice  0
Job_Swordman    1
Job_Mage    2
Job_Archer  3
Job_Acolyte 4
Job_Merchant    5
Job_Thief   6
Job_Knight  7
Job_Priest  8
Job_Wizard  9
Job_Blacksmith  10
Job_Hunter  11
Job_Assassin    12
Job_Knight2 13
Job_Crusader    14
Job_Monk    15
Job_Sage    16
Job_Rogue   17
Job_Alchem  18
Job_Alchemist   18
Job_Bard    19
Job_Dancer  20
Job_Crusader2   21
Job_Wedding 22
Job_SuperNovice 23
Job_Gunslinger  24
Job_Ninja   25
Job_Xmas    26
Job_Summer  27

Job_Novice_High 4001
Job_Swordman_High   4002
Job_Mage_High   4003
Job_Archer_High 4004
Job_Acolyte_High    4005
Job_Merchant_High   4006
Job_Thief_High  4007
Job_Lord_Knight 4008
Job_High_Priest 4009
Job_High_Wizard 4010
Job_Whitesmith  4011
Job_Sniper  4012
Job_Assassin_Cross  4013
Job_Lord_Knight2    4014
Job_Paladin 4015
Job_Champion    4016
Job_Professor   4017
Job_Stalker 4018
Job_Creator 4019
Job_Clown   4020
Job_Gypsy   4021
Job_Paladin2    4022

Job_Baby    4023
Job_Baby_Swordman   4024
Job_Baby_Mage   4025
Job_Baby_Archer 4026
Job_Baby_Acolyte    4027
Job_Baby_Merchant   4028
Job_Baby_Thief  4029
Job_Baby_Knight 4030
Job_Baby_Priest 4031
Job_Baby_Wizard 4032
Job_Baby_Blacksmith 4033
Job_Baby_Hunter 4034
Job_Baby_Assassin   4035
Job_Baby_Knight2    4036
Job_Baby_Crusader   4037
Job_Baby_Monk   4038
Job_Baby_Sage   4039
Job_Baby_Rogue  4040
Job_Baby_Alchem 4041
Job_Baby_Alchemist  4041
Job_Baby_Bard   4042
Job_Baby_Dancer 4043
Job_Baby_Crusader2  4044
Job_Super_Baby  4045

Job_Taekwon 4046
Job_Star_Gladiator  4047
Job_Star_Gladiator2 4048
Job_Soul_Linker 4049

Job_Gangsi  4050
Job_Death_Knight    4051
Job_Dark_Collector  4052

Job_Rune_Knight 4054
Job_Warlock 4055
Job_Ranger  4056
Job_Arch_Bishop 4057
Job_Mechanic    4058
Job_Guillotine_Cross    4059

Job_Rune_Knight_T   4060
Job_Warlock_T   4061
Job_Ranger_T    4062
Job_Arch_Bishop_T   4063
Job_Mechanic_T  4064
Job_Guillotine_Cross_T  4065

Job_Royal_Guard 4066
Job_Sorcerer    4067
Job_Minstrel    4068
Job_Wanderer    4069
Job_Sura    4070
Job_Genetic 4071
Job_Shadow_Chaser   4072

Job_Royal_Guard_T   4073
Job_Sorcerer_T  4074
Job_Minstrel_T  4075
Job_Wanderer_T  4076
Job_Sura_T  4077
Job_Genetic_T   4078
Job_Shadow_Chaser_T 4079

Job_Rune_Knight2    4080
Job_Rune_Knight_T2  4081
Job_Royal_Guard2    4082
Job_Royal_Guard_T2  4083
Job_Ranger2 4084
Job_Ranger_T2   4085
Job_Mechanic2   4086
Job_Mechanic_T2 4087

Job_Baby_Rune   4096
Job_Baby_Warlock    4097
Job_Baby_Ranger 4098
Job_Baby_Bishop 4099
Job_Baby_Mechanic   4100
Job_Baby_Cross  4101
Job_Baby_Guard  4102
Job_Baby_Sorcerer   4103
Job_Baby_Minstrel   4104
Job_Baby_Wanderer   4105
Job_Baby_Sura   4106
Job_Baby_Genetic    4107
Job_Baby_Chaser 4108

Job_Baby_Rune2  4109
Job_Baby_Guard2 4110
Job_Baby_Ranger2    4111
Job_Baby_Mechanic2  4112

Job_Super_Novice_E  4190
Job_Super_Baby_E    4191

Job_Kagerou 4211
Job_Oboro   4212
Job_Rebellion   4215
```
","agree in centralization and I suggest to store it in const.txt
",7551429
899,Misc NPC skills,open,2013-09-23T22:40:35Z,2016-03-14T23:53:18Z,,MEMBER,"Commits to consider
- 2d01ad77c388051ff3f3d30e160e914c3e3361be: NPC_PIERCINGATT, NPC_COMBOATT, NPC_RANDOMATT (to be checked)
","no idea. don't know where the info from this is stored officially
",7551429
900,Level 48 Decrease Agi duration,open,2013-09-23T22:23:56Z,2016-03-14T23:49:53Z,,MEMBER,"Commits to consider:
- a4b7719bde71b7fa82a2fcebb9084a3dafb1dc5c: - When bosses use level 48 decrease agi, it will now have a base duration of 65 seconds on players (bugreport:5085)
","the data for this is now available in `int status_get_sc_def(struct block_list *src, struct block_list *bl, enum sc_type type, int rate, int tick, int flag)` however I don't seem to recall why we needed it (from the looks of it this still hasn't been fixed)
",7551429
901,Post-balance skill updates,open,2013-09-23T17:07:08Z,2016-03-14T23:48:10Z,,MEMBER,"Commits to consider:

Please check if we're missing any parts of them, and if they're correct, since I'm very bad with game mechanics-related updates (@rud0lp20: can you take care of verifying these whenever you're free?)
- fee77a8c01edcf196f9c715c13b59d6273bfbf8c: Rune Knight
- a8f29a77841f9647742711702d86677a9073b523: (follow-up to the above)
- ecfb06e3b452bf80309fe6cf869e846f10911549: Arch Bishop
",,7551429
902,Athena-Start,open,2013-09-22T17:20:04Z,2018-09-13T20:09:18Z,,CONTRIBUTOR,"```
./athena-start: line 60: kill: (27190) - No such process
./athena-start: line 60: kill: (27191) - No such process
./athena-start: line 60: kill: (27192) - No such process
```

I noticed that the PID is wrong.. the right PID was

```
20547
20548
20549
```

i think it checks PID wrong....
","The PID checks are correct, though they may be unreliable in case of hercules crash, OS restart or manual killing of the Hercules processes.

Since I didn't really like the startup script, I rewrote it from scratch, in case you want to give it a try. (I have not pushed it yet to the main repository)
You can get the file at MishimaHaruna/Hercules@b49040b for the time being.
",7551429
903,[minor] item_drop_ratio_db dump.,open,2013-09-17T11:59:36Z,2016-03-14T23:44:56Z,,MEMBER,"```
static struct item_drop_ratio *item_drop_ratio_db[MAX_ITEMDB];
```

I've come to realise this while working on #116 
item_drop_ratio_db is a processing waste, I'd propose it be dropped given that there would be no change on memory usage if it were to be placed within the item_data struct entry (neither there would be functionality loss) it would however bring a minor processing change, since moving it would render procedures such as this to be unnecessary

```
    for (i = 0; i < MAX_ITEMDB; i++) {
        if (item_drop_ratio_db[i]) {
            aFree(item_drop_ratio_db[i]);
            item_drop_ratio_db[i] = NULL;
        }
    }
```
",,7551429
904,About doc/script_commands.txt,open,2013-09-09T19:16:59Z,2018-09-13T20:07:04Z,,CONTRIBUTOR,"I think this documentation is still good to go but each new read I give it I find brand new problems and issues. That's a reason why I've started to proofread it and thoroughly challenge/check each section for validity myself.

You all are welcome to point out current deficiencies of this documentation. Current task list at the moment is this:
- [ ] Improvement of the quality of the text throughout all of the document trying to make clear and update the text;
- [ ] Some restructuring of the text so that its reading is as sequential as possible, keeping a minimum of jumps to know what is what.
- [ ] Changing all of the script commands descriptions to a whole new format, similar to this one:

```
*Name of the command and how to call it, with a full list of parameters.

->  Short description: 
    Short descriptive text about what the command does.
->  Parameters: 
    Any required or optional parameters the command needs for working.
->  Returns: 
    What the command usually returns. Expect sometimes a list in case one 
    of the parameters specifies a type of return.
->  Notes:
    Notes about the script command. It'll be only present if needed. 
->  Examples:
    Small example if possible/needed. Will usually be incomplete, it's 
    there just to give you an idea of how it works in practice. Some 
    commands will have more than one example.
```
- [ ] Changing top level commands to a better parameter-by-parameter ordered description;
- [ ] Making a table of contents with a list of every section of the document (making as I work on it);
- [ ] Putting all constants references in the text on a new, separated section;
- [ ] Making a table of operator precedence on the operators section;

Aside for these relatively big changes, I've thought of these particular small changes at the moment:
- [ ] Put a note in end; that it's not required to put it, but it's in fact a good practice;
- [ ] Put the var++ statement in it, since right now it isn't anywhere on the text;
- [x] Add the import: thingy on the script loading structure section (done);
- [x] Remark that scripts can be in any file extension, not only .txt (it's a frequent question and some people prefer to save them in .c so that their text editor highlights its syntax; done);
- [ ] Removing references to limited arrays for when our scripting improvements are made.

Soooo come on, throw here all your comments on how to improve it since I'm trying to make it better as much as I can and your suggestions and criticism are important for making it possible!

P.S.: I might take quite a lot of time for finishing it since this is one of my least important priorities and it's a huge document, but anyways I'll still be working on it.
","New: must upgrade my local copy from 84e4e6ee1dcaf37d73ec6f590c675ce4b17352b9 onwards.

Also note about the continue script command. Really, who the hell made the documentation?
",7551429
905,Result value of timers is unused,open,2013-08-22T17:39:59Z,2016-03-14T23:38:27Z,,MEMBER,"timer.c::do_timer

```
        if( timer_data[tid].func ) {
            if( diff < -1000 )
                // timer was delayed for more than 1 second, use current tick instead
                timer_data[tid].func(tid, tick, timer_data[tid].id, timer_data[tid].data);
            else
                timer_data[tid].func(tid, timer_data[tid].tick, timer_data[tid].id, timer_data[tid].data);
        }
```

timer.h

```
typedef int (*TimerFunc)(int tid, unsigned int tick, int id, intptr_t data);
```
",,7551429
906,Script Function Override Fail,open,2013-08-07T17:48:42Z,2016-03-14T23:38:08Z,,MEMBER,"Code has been the same since eAthena and as I understand this problem is this old, lies at how npc functions try to override if got 2 with same name

```
npc_parse_function
```

```
    func_db = script_get_userfunc_db();
    oldscript = (struct script_code*)strdb_put(func_db, w3, script);
    if( oldscript != NULL )
    {
        ShowInfo(""npc_parse_function: Overwriting user function [%s] (%s:%d)\n"", w3, filepath, strline(buffer,start-buffer));
        script_free_vars(&oldscript->script_vars);
        aFree(oldscript->script_buf);
        aFree(oldscript);
    }
```

ours looks sightly different but the design is the same and remains broken

```
    func_db = script->userfunc_db;
    if (func_db->put(func_db, DB->str2key(w3), DB->ptr2data(scriptroot), &old_data))
    {
        struct script_code *oldscript = (struct script_code*)DB->data2ptr(&old_data);
        ShowInfo(""npc_parse_function: Overwriting user function [%s] (%s:%d)\n"", w3, filepath, strline(buffer,start-buffer));
        script->free_vars(oldscript->script_vars);
        aFree(oldscript->script_buf);
        aFree(oldscript);
    }
```

Pretty much if you have a function sleeping/timer'd while this is performed (e.g. by doing @loadnpc on a file already loaded that has a function) the previous pointer stuff screw up and ends up crashing in run_script_main ( claims st->script->script_buf is empty aka 0xfdfdfdfdfd'd by the memory manager ).
","Example (assuming both are in the same file):

```
OnInit:
while(1) callfunc(""my_broken_func"");
```

```
my_broken_func (somewhere) {
do_anything;
sleep 1000;
return;
}
```

this causes the data to this function be persistently on memory since it never goes away (since the script sleeps itself to not end it always remains in a timer), if this is mistakenly loaded again (as I said by @loadnpc), the overwrite happens and this timer ends up with a broken pointer that eventually crashes the server (that in the best scenario where it doesnt corrupt other memory depending on what it tries to run, in the case server isn't run with debug mode the memory manager doesnt 0xfdfdfdfd the memory which can then point to garbage which then can do a huge amount of things if by chance the values it tries to read are within the boundaries expected in get_com)
",7551429
907,Storing user passwords,open,2013-07-27T07:05:15Z,2019-01-09T18:17:14Z,,MEMBER,"Currently in Hercules there are 2 ways to store user passwords in database:
- unsalted one-round MD5 hash (bad)
- plain text (arguably unacceptable)

I've done little research on storing passwords in safe manner these days, and it looks like `bcrypt` is generally recommended and widespread solution. It also has ready to use implementations in many languages, most importantly PHP and C.

I think we should provide a way to store passwords in a way that is considered safe. MD5 maybe was good enough several years ago, but with increasing computing power it no longer is.
","How about this?
https://github.com/trusch/libbcrypt

I've added a pull request that adds support on windows.

Client would have to send the password over in plaintext, unless someone can mod it to bcrypt on that end. Unless you want to bcrypt a md5 hash but that seems silly...

Lib usage:
```cpp
std::string hash = BCrypt::generateHash(password, 10);
BCrypt::validatePassword(password, hash);
```

Adding bcrypt on fluxcp should be simple enough.

```php
password_hash ( $password, PASSWORD_BCRYPT, [ 'cost' => 10 ] );
```

Notes on php:
- Maximum password length of 72 characters.
- PHP Defaults to BCRYPT from PHP 5.5.0 onwards, but could change in future versions so being explicit.
- Output always a 60 character string or FALSE on failure.
- You can store this as bytes and save some space but prefer simplicity.

",7551429
908,Battle & skill code cleanup,open,2013-07-26T08:15:10Z,2015-09-25T01:59:17Z,,MEMBER,"This is something I've been thinking about for long time now.
- proper separation of battle and skill code into their own modules (eg `int battle_calc_skillratio` is placed in `battle.c` now, instead of `skill.c`)
- splitting code into smaller functions responsible of performing exactly one task (ideally) for improved readability and reusability of code
- moving as many hardcoded numbers and flags into `skill_db*.txt` files (eg already mentioned skill damage ratios, certain skills that bypass X, etc)
- removing awful `switch (skill_id)` in favor of expanding internal skill database representation with function pointers to perform extra actions unique for given skill id (eg. overriding default skill damage ratio calculation, adding extra conditions or extra effects that would be too complex to represent in plain txt db files); in future allow overriding these functions by plugins for easy skill modifications

Opinions, suggestions?
","Okay, sounds good then.  I was worried about excessive amounts of symbols requiring to be defined, in case you wanted to make them assignable (i.e. by function name) directly from the skill_db.
",7551429
909,missing official map flags for maptypeproperty2,open,2013-07-24T16:17:21Z,2015-06-07T14:54:38Z,,MEMBER,"clif.c

```
void clif_maptypeproperty2(struct block_list *bl,enum send_target t) {
    struct packet_maptypeproperty2 p;

    p.PacketType = maptypeproperty2Type;
    p.type = 0x28;
    p.flag.usecart = 1;
    p.flag.party = 1;
    p.flag.guild = 1;
    p.flag.siege = map_flag_gvg2(bl->m) ? 1: 0;
    p.flag.mineffect = 1;
    p.flag.nolockon = 0;
    p.flag.countpk = map[bl->m].flag.pvp ? 1 : 0;
    p.flag.nopartyformation = 0;
    p.flag.noitemconsumption = 0;
    p.flag.summonstarmiracle = 0;
    p.flag.bg = map[bl->m].flag.battleground ? 1 : 0;

    clif->send(&p,sizeof(p),bl,t);
}
```

as its visible the ones with 0 are missing mapflags, some with a straight 1 could be made into mapflags too (e.g. usecart)
","Here's what I figured out so far:

```
unsigned int party             : 1; // Show attack cursor on non-party members (PvP)
unsigned int guild             : 1; // Show attack cursor on non-guild members (GvG)
unsigned int siege             : 1; // Show emblem over characters' heads and attack cursor on enemy guilds (WoE)
unsigned int mineffect         : 1; // Automatically enable /mineffect
unsigned int nolockon          : 1; // TODO: What does this do? (shows attack cursor on non-party members)
unsigned int countpk           : 1; // TODO: What does this do?
unsigned int nopartyformation  : 1; // Prevent party creation
unsigned int bg                : 1; // TODO: What does this do?
unsigned int noitemconsumption : 1; // TODO: What does this do? (shows a ""Nothing found in the selected map"" message)
unsigned int usecart           : 1; // Allow opening cart inventory
unsigned int summonstarmiracle : 1; // TODO: What does this do?
```

Ideas?
",7551429
910,Battlegrounds Queue,open,2013-07-24T15:46:37Z,2016-03-22T20:40:06Z,,MEMBER,"- [x] Enable party/guild support (existent but disabled) and add the splitting algorithm, as Shikazu drafted ( staff link; http://hercules.ws/board/topic/1192-bg-queue-splitting-teams/ )
- [ ] in battlegrounds.c `bg_canqueue` gdelay_var and arena->delay_var checks are checking against time() instead of time()+proper_setting
- [x] `script->hq[arena->queue_id].items` is apparently not being cleared (after one bg takes place users get their position as if the previous queue was still in place), even though it is thrown in queue delete (might be a queue problem instead of the bg)
- [x] the feature should save your position when you're warped into the bg and warp you back when it ends ( no support for this is currently present )
- [x] when you're in a queue the client has a window displaying your position and a 'leave' button (beside the windows close button), this button is currently doing nothing while it should get you out of the queue.

( taken from http://hercules.ws/board/topic/1302-bg-queue-debug/ )
","The KvM scripts sended in last post have customized the reward giving an item instead of giving kvm_points, here it is with the kvm_points reward corrected:

[kvm01.txt](https://github.com/HerculesWS/Hercules/files/184941/kvm01.txt)
[kvm02.txt](https://github.com/HerculesWS/Hercules/files/184942/kvm02.txt)
[kvm03.txt](https://github.com/HerculesWS/Hercules/files/184943/kvm03.txt)

However, @dastgir , this scripts (flavius, tierra and kvm) has been partially customized from the standard scripts, we will send a non-customized version soon.
",7551429
911,ers.c documentation is off,open,2013-07-24T14:59:26Z,2016-03-14T23:35:52Z,,MEMBER,"GreenBox has remade the system from the ground up a couple months ago but the description in the top of the file is still the same as previous and some are off (I'm not sure about the others), for example:

```
 *  - A  manager will only auto-destroy when all of its instances are        *
 *    destroyed so memory will usually only be recovered near the end.       *
```

This is no longer true
",,7551429
912,Ability to import/override libconfig files,open,2013-07-21T07:26:27Z,2016-03-14T23:34:53Z,,MEMBER,"e.g. conf/atcommand.conf
",,7551429
913,"Fix #309, avoid catastrophic backtracking in searchcommands.internals",open,2020-03-03T15:29:53Z,2020-03-03T15:29:53Z,,NONE,"Adding `\\` to `[^""]` avoids overlap with `\\.` in the branch. Without this the regex can catastrophically backtrack between the two branches.",,1504670
914,Regular expression in CommandLineParser exhibits catastrophic backtracking,open,2020-02-25T15:04:42Z,2020-03-02T17:50:08Z,,NONE,"Hi there! I've been working on a new Python static analysis tool called [Dlint](https://github.com/dlint-py/dlint). Most recently I've been working on a rule that searches for regular expression denial-of-service: [DUO138](https://github.com/dlint-py/dlint/blob/master/docs/linters/DUO138.md). When running this rule against your codebase I found the following violations:

```
$ python -m flake8 --select=DUO138 splunklib/
splunklib/searchcommands/internals.py:217:21: DUO138 catastrophic ""re"" usage - denial-of-service possible
splunklib/searchcommands/internals.py:235:22: DUO138 catastrophic ""re"" usage - denial-of-service possible
splunklib/searchcommands/internals.py:237:19: DUO138 catastrophic ""re"" usage - denial-of-service possible
splunklib/searchcommands/search_command.py:834:22: DUO138 catastrophic ""re"" usage - denial-of-service possible
```

After further investigation, it appears the violation in `internals.py` at line 235 is a true positive and the rest are false positives. If we dig in further:

```python
class CommandLineParser(object):
    ...
    _fieldnames_re = re.compile(r""""""(""(?:\\.|""""|[^""])+""|(?:\\.|[^\s""])+)"""""")
```

The violation occurs due to `(?:\\.|""""|[^""])+`. This is due to [mutually inclusive alternation](https://www.regular-expressions.info/redos.html) within a quantifier. Since `\\.` and `[^""]` have character overlap. We can confirm the bug with a specially crafted string and the following code:

```python
from splunklib.searchcommands import internals
internals.CommandLineParser._fieldnames_re.search('""' + r'\\.' * 64 + ""'"")
...Spins...
```

To fix the issue we should avoid the character overlap between `\\.` and `[^""]`. One way to accomplish this is with the following expression:

```python
_fieldnames_re = re.compile(r""""""(""(?:\\.|""""|[^""\\])+""|(?:\\.|[^\s""])+)"""""")
```

Note that the other false positives found contain similar expressions, and despite not being vulnerable to this issue, it may be worth updating them as well. This will avoid them becoming vulnerable in the future.

If you'd like to learn more about ReDoS and catastrophic backtracking I recommend checking out [this blog post](https://blog.r2c.dev/posts/finding-python-redos-bugs-at-scale-using-dlint-and-r2c/). I hope this helps, let me know if you have any questions!","Thanks for the bug report @mschwager, this is very helpful information. We are unable to implement these changes at the moment but we are always open to a pull request",1504670
915,fix  AttributeError: 'module' object has no attribute '_create_unverified_context',open,2020-02-25T02:39:09Z,2020-02-25T02:39:09Z,,NONE,v1.6.12 contains PR #283 which breaks on legacy python without PEP 476 support,,1504670
916,TextIOWrapper regression bug in 1.6.12: 'file' object has no attribute 'readable',open,2020-02-24T22:10:59Z,2020-03-09T19:20:59Z,,CONTRIBUTOR,"I think I stumbled onto a bug in 1.6.12 that impacts at least 7.1.4 and 7.3.0.  It seems to be related to python 2 vs 3 and athe TextIOWrapper around the output stream.    The initial registration seems to be fine (`--scheme`), but whenever the script is run to collect data that's when it fails.

When I downgrade splunk-sdk version to 1.6.11 my modular input (TA) works fine again.

Here's the traceback from the 1.6.12 version from a local 7.3 instance running on a Mac:
```
Traceback (most recent call last):
  File ""/Users/lalleman/splunk73/splunk/etc/apps/TA-oam_dms/bin/OAM_DMS.py"", line 422, in <module>
    sys.exit(OamDmsModularInput().run(sys.argv))
  File ""/Users/lalleman/splunk73/splunk/etc/apps/TA-oam_dms/bin/../lib/splunklib/modularinput/script.py"", line 56, in run
    return self.run_script(args, EventWriter(), sys.stdin)
  File ""/Users/lalleman/splunk73/splunk/etc/apps/TA-oam_dms/bin/../lib/splunklib/modularinput/event_writer.py"", line 49, in __init__
    self._out = TextIOWrapper(output)
AttributeError: 'file' object has no attribute 'readable'
```","Hi @lowell80, this seems like an oversight in our testing. We're open to pull requests, however we do not have the bandwidth to address this issue at the moment. Thank you for your patience and understanding",1504670
917,Update README.md,open,2020-02-14T17:50:02Z,2020-02-14T20:02:18Z,,CONTRIBUTOR,"Remove reference to zip, update to 8.0, typo.","Also note that the existing published readme (https://github.com/splunk/splunk-sdk-python/blob/master/README.md) has ""build failing"" and ""docs failing"" badges up top; should be fixed",1504670
918,Ensure event XML is a string before writing.,open,2020-02-04T19:37:53Z,2020-02-04T19:43:22Z,,NONE,"Fixes following issue.  See stacktrace.

Traceback (most recent call last):
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/ta_1password/aob_py3/modinput_wrapper/base_modinput.py"", line 128, in stream_events
    self.collect_events(ew)
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/onepassword_event_logs.py"", line 76, in collect_events
    input_module.collect_events(self, ew)
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/input_module_onepassword_event_logs.py"", line 216, in collect_events
    event_stream.stream_events(CACHE_FOLDER, stanza_name)
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/input_module_onepassword_event_logs.py"", line 175, in stream_events
    self._process_event(event, input_name)
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/input_module_onepassword_event_logs.py"", line 150, in _process_event
    SplunkWriter.write_event(splunk_event)
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/onepassword_lib/splunk_writer.py"", line 10, in write_event
    SplunkWriter.writer.write_event(event)
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/ta_1password/aob_py3/solnlib/packages/splunklib/modularinput/event_writer.py"", line 57, in write_event
    event.write_to(self._out)
  File ""/Applications/Splunk/etc/apps/TA-1password/bin/ta_1password/aob_py3/splunklib/modularinput/event.py"", line 107, in write_to
    stream.write(ET.tostring(event))
TypeError: write() argument must be str, not bytes",,1504670
919,Fix chunk synchronization,open,2020-01-21T17:17:43Z,2020-01-22T20:58:31Z,,NONE,"The external search command should be sending one chunk response for every chunk received, but extra flushing in the case of large chunks was producing multiple responses per request.

This changes partial flush() to be a noop for v2, and is more explicit about matching up read_chunk and write_chunk calls.

Fixes #150 ",,1504670
920,Modular Input Decorators,open,2020-01-14T19:45:44Z,2020-01-14T19:45:44Z,,NONE,"In an attempt to have similar design patterns to how custom search commands are created, and also to make the definition of the scheme, member access to configuration values, automatic casting of configuration types, and convenient .spec file generation, I implemented a proof of concept for decorators for the Script class.
It mimics much of how the search command decorators are implemented, with changes where necessary.
The functionality isn't fully complete, and is lacking validation of decorator parameters, but before spending a lot more time polishing and making it complete I wanted to get feedback regarding the willingness of the SDK team to merge such a PR, and also to get early feedback regarding which pieces the team would want implemented differently.

The summary of what this PR accomplishes is shown in this code snippet:

```from __future__ import absolute_import
from splunklib.modularinput import Configuration, Script, Argument
import sys

@Configuration(use_single_instance=True)
class DevSDKScript(Script):
    a_string_argument = Argument(data_type=Argument.data_type_string, description=""A String Argument"")
    a_boolean_argument = Argument(data_type=Argument.data_type_boolean, description=""A Boolean Argument"")
    a_number_argument = Argument(data_type=Argument.data_type_number, description=""A Number Argument"")

    # for inputs that need to perform preliminary actions (preparation) with knowledge of the entire set of inputs
    def preflight(self, input_items, ew):
        for input_name, input_item in input_items:
            ew.log(""INFO"", ""{0} preflight"".format(input_name))

    # process_input is called once per configured input to be more convenient, not requiring the developer
    #  to implement the interation themselves
    # stream_events is still overrideable if the developer prefers the existing method
    def process_input(self, input_name, input_item, ew):
        ew.log(""INFO"", ""{0} stream_event"".format(input_name))
        ew.log(""INFO"", "" a_string_argument: {0}"".format(input_item.a_string_argument))
        ew.log(""INFO"", "" a_boolean_argument: {0}"".format(input_item.a_boolean_argument))
        ew.log(""INFO"", "" a_number_argument: {0}"".format(input_item.a_number_argument))

    # for inputs that need to perform post actions (cleanup) with knowledge of the entire set of inputs
    def postflight(self, input_items, ew):
        for input_name, input_item in input_items:
            ew.log(""INFO"", ""{0} postflight"".format(input_name))

if __name__ == ""__main__"":
    sys.exit(DevSDKScript().run(sys.argv))",,1504670
921,README includes deprecated support process,open,2019-12-11T20:35:20Z,2019-12-11T20:35:20Z,,MEMBER,"See https://github.com/splunk/splunk-sdk-python/blame/master/README.md#L289:

The email address ""support@splunk.com"" can no longer be used to open support cases. Instead, customers should login to the Support Portal using their Splunk.com account, and open a case that way. See: https://www.splunk.com/en_us/support-and-services.html and https://login.splunk.com/page/sso_redirect?type=portal",,1504670
922,Basic metadata search returns the same results over and over,open,2019-12-04T21:20:30Z,2019-12-04T21:21:57Z,,NONE,"Project version: 1.6.11
Platform: CentOS 
Framework: Python 2.7.4
Splunk: Splunk Cloud (7.2.9)

Problem:

I'm getting multiple iterations of results for each search I make. I've tried this with a very basic search:

```
| metadata type=sourcetypes index=*
| table sourcetype, type, totalCount
```

For the time range of the past 30 minutes. In Splunk Cloud via the GUI, this gives me results in the hundreds (ranges between ~200 and ~500 so far). When I run the script to just print out each row in results:

1. I get the same results repeated over and over and over.
2. At some point it dies out:

```
xml.etree.ElementTree.ParseError: mismatched tag: line 6706, column 2
```

What am I missing?","This happens on both CentOS and Python, in both Python 2.7 and Python 3.6.

The sample code, once one changes it to .py:
[example.txt](https://github.com/splunk/splunk-sdk-python/files/3923973/example.txt)
",1504670
923,Send additional headers with Delete Requests.,open,2019-12-02T00:10:04Z,2020-01-26T12:34:24Z,,NONE,"Send additional headers with a delete request. Currently only GET, POST and REQUEST allow this.",,1504670
924,EventWriter is writing bytes on stdout which is not supported in pyth…,open,2019-11-26T13:57:05Z,2019-12-13T17:33:10Z,,NONE,"…on3 #274

Resolved bug #274 for event_writer.py and event.py for modular input ",Hi @chinmay2197 - thanks for the PR! Can you please fill out the contribution agreement located here: https://www.splunk.com/en_us/form/contributions.html before we proceed? ,1504670
925,Maximum recursion depth exceeded,open,2019-11-26T07:10:21Z,2019-12-02T21:53:03Z,,NONE,"Hi,

I created a simple splunk app to test splunk SDK, it works but I get an error when there are lots of events (~20000): 
> `RuntimeError: maximum recursion depth exceeded while calling a Python object`

I have already checked the python recursionlimit (= 1000 by default)

Here my code:

```python
@Configuration()
class test(ReportingCommand):

    """"""  TODO

    ## Requirements:
		TODO
    ## Description:
        TODO

    ## Syntax:
        TODO

    ## Example:
        TODO


    """"""

    @Configuration()
    def map(self, events):
        return events

    def reduce(self, events):
        events_list = list(events)
        event={}
        for evt in event_list:
            event[""test""]=evt
            yield event

dispatch(test, sys.argv, sys.stdin, sys.stdout, __name__)
```

Here the error:
```11-26-2019 07:49:39.104 INFO  ChunkedExternProcessor - Running process: /opt/splunk/bin/python2.7 /opt/splunk/etc/apps/test/bin/test.py
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr: Traceback (most recent call last):
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:   File ""/opt/splunk/etc/apps/test/bin/test.py"", line 104, in <module>
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:     class test(ReportingCommand):
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:   File ""/opt/splunk/etc/apps/test/bin/splunklib/searchcommands/decorators.py"", line 85, in __call__
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:     o.ConfigurationSettings.fix_up(o)
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:   File ""/opt/splunk/etc/apps/test/bin/splunklib/searchcommands/reporting_command.py"", line 274, in fix_up
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:     ConfigurationSetting.fix_up(f.ConfigurationSettings, settings)
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:   File ""/opt/splunk/etc/apps/test/bin/splunklib/searchcommands/decorators.py"", line 159, in fix_up
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:     setting = setting.getter(fget(backing_field_name, value))
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:   File ""/opt/splunk/etc/apps/test/bin/splunklib/searchcommands/decorators.py"", line 127, in getter
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:     return self._copy_extra_attributes(property.getter(self, function))
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:   File ""/opt/splunk/etc/apps/test/bin/splunklib/searchcommands/decorators.py"", line 115, in __init__
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr:     property.__init__(self, fget=fget, fset=fset, fdel=fdel, doc=doc)
11-26-2019 07:49:39.192 ERROR ChunkedExternProcessor - stderr: RuntimeError: maximum recursion depth exceeded while calling a Python object
11-26-2019 07:49:39.198 ERROR ChunkedExternProcessor - EOF while attempting to read transport header
11-26-2019 07:49:39.198 ERROR ChunkedExternProcessor - Error in 'test' command: External search command exited unexpectedly with non-zero error code 1.
```
The error seems to come from splunklib.

Thanks

",,1504670
926,Add optional retries to connection attempts,open,2019-11-19T22:26:17Z,2020-03-25T17:35:21Z,,CONTRIBUTOR,"I have a long running process that connects to Splunk and executes and manages multiple jobs over (potentially) hours. Every now and then I'll get a `Connection reset by peer` error that blows everything up. This should allow me to build my Splunk connection object with a little retry logic built into the sdk.

Traceback I'm getting for reference:
```python
Traceback (most recent call last):
  File ""/opt/myCode/myCode.py"", line 2130, in <module>
    main()
  File ""/opt/myCode/myCode.py"", line 1308, in main
    config_data['fields']['matchFields'])
  File ""/opt/myCode/myCode.py"", line 839, in rebuild_lookups_from_database
    while not all([z.is_done() for z in jobs]):
  File ""/usr/lib/python2.7/site-packages/splunklib/client.py"", line 2703, in is_done
    if not self.is_ready():
  File ""/usr/lib/python2.7/site-packages/splunklib/client.py"", line 2715, in is_ready
    response = self.get()
  File ""/usr/lib/python2.7/site-packages/splunklib/client.py"", line 1009, in get
    return super(Entity, self).get(path_segment, owner=owner, app=app, sharing=sharing, **query)
  File ""/usr/lib/python2.7/site-packages/splunklib/client.py"", line 766, in get
    **query)
  File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 290, in wrapper
    return request_fun(self, *args, **kwargs)
  File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 71, in new_f
    val = f(*args, **kwargs)
  File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 680, in get
    response = self.http.get(path, all_headers, **query)
  File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 1184, in get
    return self.request(url, { 'method': ""GET"", 'headers': headers })
  File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 1242, in request
    response = self.handler(url, message, **kwargs)
  File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 1386, in request
    response = connection.getresponse()
  File ""/usr/lib64/python2.7/httplib.py"", line 1113, in getresponse
    response.begin()
  File ""/usr/lib64/python2.7/httplib.py"", line 444, in begin
    version, status, reason = self._read_status()
  File ""/usr/lib64/python2.7/httplib.py"", line 400, in _read_status
    line = self.fp.readline(_MAXLINE + 1)
  File ""/usr/lib64/python2.7/socket.py"", line 476, in readline
    data = self._sock.recv(self._rbufsize)
  File ""/usr/lib64/python2.7/ssl.py"", line 757, in recv
    return self.read(buflen)
  File ""/usr/lib64/python2.7/ssl.py"", line 651, in read
    v = self._sslobj.read(len or 1024)
error: [Errno 104] Connection reset by peer```","Hi @mew1033, we unfortunately have not had a chance to look at this PR due to resource constraints. I will personally see if we can get this merged in sooner rather than later. Thank you for your patience and understanding.",1504670
927,WIP: add storage passwords get(),open,2019-11-12T23:05:14Z,2019-11-12T23:05:14Z,,MEMBER,,,1504670
928,Remove clear_password assertions for storage/passwords tests,open,2019-11-05T23:16:29Z,2020-02-05T19:41:13Z,,NONE,POST requests to the /storage/passwords endpoint should not return the clear_password back in plaintext. The POST response should mask the clear_password but the Python SDK tests specifically check for the created or updated password. I removed those assertion checks.,"Hey @dgao1029 I think the change that we actually want that will ensure that the clear_password is available as it was before to end-users is to force a state refresh after password creation. Following the Java SDK which you were just investigating this will update our `StoragePassword` model using the GET response.

So if you revert your testing changes and change this line: https://github.com/splunk/splunk-sdk-python/blob/develop/splunklib/client.py#L1847

to
```python
storage_password = StoragePassword(self.service, self._entity_path(state))
```

I believe that will allow users to retrieve the `password.clear_password` as they were before without removing functionality.",1504670
929,StreamingCommand failed when input contains non-ascii character,open,2019-10-25T09:46:37Z,2019-11-05T07:18:18Z,,NONE,"Environment:
- splunk8.0
- splunk sdk 1.6.11
- python 3

When I create StreamingCommand   ""testcommand"" with following code:

```
#!/usr/bin/env python
#-*- coding: utf-8 -*-
import sys
from splunklib.searchcommands import \
    dispatch, StreamingCommand, Configuration, Option, validators
import splunk
@Configuration()   
class TestCommand(StreamingCommand):
    def stream(self, events):   
        for event in events:        
            yield event
dispatch(TestCommand, sys.argv, sys.stdin, sys.stdout, __name__)
```

testcommand will hang when I use following SPL:
sourcetype=XXX| search url = ""http://例子.卷筒纸"" | testcommand

There has follwing error log in splunkd.log:

> 10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: During handling of the above exception, another exception occurred:
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: Traceback (most recent call last):
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: File ""C:\Program Files\Splunk\etc\apps\XXXX\bin\testcommand.py"", line 22, in
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: dispatch(TestCommand, sys.argv, sys.stdin, sys.stdout, name)
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: File ""C:\Program Files\Splunk\etc\apps\XXXX\bin\splunklib\searchcommands\search_command.py"", line 1118, in dispatch
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: command_class().process(argv, input_file, output_file)
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: File ""C:\Program Files\Splunk\etc\apps\XXXX\bin\splunklib\searchcommands\search_command.py"", line 435, in process
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: self._process_protocol_v2(argv, ifile, ofile)
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: File ""C:\Program Files\Splunk\etc\apps\XXXX\bin\splunklib\searchcommands\search_command.py"", line 787, in _process_protocol_v2
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: self.finish()
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: File ""C:\Program Files\Splunk\etc\apps\XXXX\bin\splunklib\searchcommands\search_command.py"", line 393, in finish
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: self._record_writer.flush(finished=True)
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: File ""C:\Program Files\Splunk\etc\apps\XXXX\bin\splunklib\searchcommands\internals.py"", line 775, in flush
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: self._write_chunk(metadata, self._buffer.getvalue())
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: File ""C:\Program Files\Splunk\etc\apps\XXXX\bin\splunklib\searchcommands\internals.py"", line 820, in _write_chunk
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: self._ofile.flush()
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: OSError: [Errno 22] Invalid argument
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: Exception ignored in: <_io.TextIOWrapper name='' mode='w' encoding='utf-8'>
10-25-2019 16:34:42.808 +0800 ERROR ChunkedExternProcessor - stderr: OSError: [Errno 22] Invalid argument
","When I use search command protocol version 1, this issue is not replicate
```
[testcommand]
filename=testcommand.py
enableheader = true
outputheader = true
requires_srinfo = true
stderr_dest = message
supports_getinfo = true
supports_rawargs = true
supports_multivalues = true
```",1504670
930,Implement Circle Builds with tox,open,2019-10-10T19:54:50Z,2019-10-11T12:39:41Z,,MEMBER,"This PR implements CircleCI builds with tox and Splunk 7.2, The current travis builds also implement 7.0 however this version is EOL. A followup enhancement should add 7.1 and 7.3 to the matrix. 

A number of tests are sensitive to timing or make use of client port binding which is not a good practice. Those tests continue to fail with this PR. This is not yet ready to replace travis but can be incremented upon by the community

Project admin will need to enable the circle CI project on the Splunk account",,1504670
931,"  Splunk SDK ""output_mode : json"" -  decode('utf-8', 'xmlcharrefreplace'), match)",open,2019-10-10T07:58:17Z,2019-11-22T13:52:13Z,,NONE,"I am trying to export splunk result into json format using splunk sdk.
Below is the code I am using, this works when output_mode is csv, but when I use json, it fails with the error mentioned below.


```
       job = service.jobs.create(searchquery, **{""exec_mode"": ""blocking"",
                                                  ""earliest_time"": default_timeline,
                                                  ""latest_time"": ""now"",
                                                  ""output_mode"": ""json"",
                                                  ""maxEvents"": 10000000})
        offset = 0;
        count = 10000;
        thru_counter = 0
        resultCount = int(job[""resultCount""])

        if rescount == 0:
            print ""No Results Found for the above searchquery""
            return False

        while (offset < rescount):
            kwargs_paginate = {""count"": count, ""offset"": offset, ""output_mode"": ""json""}
            rs = job.results(**kwargs_paginate)
            output = rs.read()
            print rs.read() 

```
Below error:

```
    ""maxEvents"": 10000000})
  File ""/Library/Python/2.7/site-packages/splunklib/client.py"", line 2944, in create
    sid = _load_sid(response)
  File ""/Library/Python/2.7/site-packages/splunklib/client.py"", line 228, in _load_sid
    return _load_atom(response).response.sid
  File ""/Library/Python/2.7/site-packages/splunklib/client.py"", line 203, in _load_atom
    .decode('utf-8', 'xmlcharrefreplace'), match)
  File ""/Library/Python/2.7/site-packages/splunklib/data.py"", line 85, in load
    root = XML(text)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py"", line 1311, in XML
    parser.feed(text)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py"", line 1659, in feed
    self._raiseerror(v)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/xml/etree/ElementTree.py"", line 1523, in _raiseerror
    raise err
ParseError: not well-formed (invalid token): line 1, column 0
```

I updated the sdk version to 1.6.11, still the same. 
","And then realized that the results() call comes back with XML by default.
So I'd recommend: don't change the code for the search; specify output_mode='json' when calling job.results(output_mode='json')",1504670
932,Handle `b''` strings in Python 3,open,2019-09-18T15:22:36Z,2019-09-19T09:21:36Z,,NONE,Adds logic to fix bug described https://github.com/splunk/splunk-sdk-python/issues/275 where byte strings `b''` do not work for indexing or concatenation in Python 3. This causes `ReportingCommands` to fail if they have a `map()` func. ,The failed travis CI is unrelated to the code changes. c7f9a0c and 038138f are identical apart from a dummy file used to trigger the build.  ,1504670
933,`ReportingCommand` not compatible with python 3,open,2019-09-17T16:06:13Z,2019-09-18T15:29:48Z,,NONE,"I'm using a virtual env (similar to how [Splunk Scientific Computing app](https://splunkbase.splunk.com/app/2882/) does) to develop Python 3 applications whilst Splunk is still running Python 2.

The `splunk-sdk-python` says: 

> The Splunk SDK for Python requires Python 2.7+, including Python 3. The Splunk SDK for Python has been tested with Python v2.7 and v3.5.

However, I don't think this is true for `ReportingCommand` search commands. Any reporting command with a `def map():` function with `@Configuration()` decorator gives the following error:

```py
f = vars(command)[b'map']   # Function backing the map method
KeyError: b'map'
```

Which references this line:

https://github.com/splunk/splunk-sdk-python/blob/07278fafb1bef8b65638c2662d8962ecdf35326f/splunklib/searchcommands/reporting_command.py#L256

## Tests

Testing shows that the `b'map'` byte string indexing is not compatible with Python 3.

```py
class Test():
    def map():
        pass

vars(Test)[b'map']

print('Done!')
```

### Python 3

```sh
➜ python --version & python decorator_test.py

Python 3.5.7

Traceback (most recent call last):
  File ""decorator_test.py"", line 5, in <module>
    vars(Test)[b'map']
KeyError: b'map'
```

### Python 2

```
➜ python --version & python decorator_test.py
Python 2.7.9
Done!
```

","@shakeelmohamed submitted a PR https://github.com/splunk/splunk-sdk-python/pull/276

Not familiar with the splunk-sdk but the patch seems to fix the example code here on my development build (Splunk 7.0.1): https://github.com/splunk/splunk-sdk-python/blob/master/examples/searchcommands_app/package/bin/sum.py",1504670
934,EventWriter is writing bytes on stdout which is not supported in python3,open,2019-09-17T07:29:18Z,2019-11-06T12:13:15Z,,NONE,"Python `sys.stdout.write()` does not supporting writing bytes to stdout stream
In event_writer.py `self._out.write(b""<stream>"")` at line 54 and `self._out.write(b""</stream>"")` at line 81 
In event_writer.py `write_xml_document` method try to write encoded xml document to stream with `self._out.write(ET.tostring(document))`
In event.py `self._out.write(ET.tostring(document))`  in `write_to` method

This causes ERROR in modular input ingesting event like below:
`TypeError: write() argument must be str, not bytes`

","Same for me. The write() function in python3 expects `str` and not `bytes`. And when I want to write and event to Splunk it just throws TypeError.
Are there any clues on when this may be fixed?",1504670
935,Parse is required because of line,open,2019-09-11T21:48:28Z,2019-09-11T21:50:22Z,,NONE,"Try running this, it doesn't work.  Not only do you need parse, you need to handle the cmd","Noted if you chmod +x part of the parsing issue goes away, but you still need the import in the example code",1504670
936,Issue with HTTPError and writing XML.,open,2019-09-11T10:04:23Z,2019-09-26T05:48:05Z,,NONE,"While using the _HTTPError_ (splunklib/binding.py) on Python3, the error shown is form of bytes. Example: `b'{""messages"":[{""type"":""ERROR"",""text"":""<the error message that is to be raised>""}]}'`
And when using the _write_xml_document()_ method (splunklib/modularinput/event_writer.py), we are recieving `ERRORwrite() argument must be str, not bytes.` on Python3 without any stacktrace.
",@shakeelmohamed I've created the PR (#273 ) for the same.,1504670
937,Blocking searches that take longer than 5 minutes time out,open,2019-08-30T17:56:43Z,2020-02-03T16:37:32Z,,CONTRIBUTOR,"I don't know if this is a byproduct of my setup, but I consistently run into this problem. If a search takes longer than 5 minutes to run, and it's set to blocking mode, it'll time out after almost exactly 300 seconds every time. Here's an example:

```python
from splunklib import client
    import time
    import salt.client

    splunk_object = client.connect(host='splunk-endpoint.domain.com',
                                   port=8089,
                                   username=""SPLUNK_USERNAME"",
                                   password=""SPLUNK_PASSWORD"",
                                   verify=False,
                                   autologin=True)

    spl = """"""search index=big value=""take a long time"" | eventstats c BY othervalue""""""
    search_kwargs = {""exec_mode"": ""blocking"", ""earliest_time"": ""-7d"", ""latest_time"": ""now""}

    start = time.time()
    # This should return immediately.
    splunk_search_job = splunk_object.jobs.create(spl, **search_kwargs)

    end = time.time()
    print(end-start)
```

And here's what happens when you run that:

```shell
    >>> start = time.time()
    >>> splunk_search_job = splunk_object.jobs.create(spl, **search_kwargs)
    Traceback (most recent call last):
      File ""<stdin>"", line 2, in <module>
      File ""/usr/lib/python2.7/site-packages/splunklib/client.py"", line 2930, in create
        response = self.post(search=query, **kwargs)
      File ""/usr/lib/python2.7/site-packages/splunklib/client.py"", line 808, in post
        return self.service.post(path, owner=owner, app=app, sharing=sharing, **query)
      File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 289, in wrapper
        return request_fun(self, *args, **kwargs)
      File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 71, in new_f
        val = f(*args, **kwargs)
      File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 742, in post
        response = self.http.post(path, all_headers, **query)
      File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 1208, in post
        return self.request(url, message)
      File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 1225, in request
        response = self.handler(url, message, **kwargs)
      File ""/usr/lib/python2.7/site-packages/splunklib/binding.py"", line 1369, in request
        response = connection.getresponse()
      File ""/usr/lib64/python2.7/httplib.py"", line 1113, in getresponse
        response.begin()
      File ""/usr/lib64/python2.7/httplib.py"", line 444, in begin
        version, status, reason = self._read_status()
      File ""/usr/lib64/python2.7/httplib.py"", line 400, in _read_status
        line = self.fp.readline(_MAXLINE + 1)
      File ""/usr/lib64/python2.7/socket.py"", line 476, in readline
        data = self._sock.recv(self._rbufsize)
      File ""/usr/lib64/python2.7/ssl.py"", line 757, in recv
        return self.read(buflen)
      File ""/usr/lib64/python2.7/ssl.py"", line 651, in read
        v = self._sslobj.read(len or 1024)
    socket.error: [Errno 104] Connection reset by peer
    >>> end = time.time()
    >>> print(end-start)
    300.682859898
```

Repeated attempts to run it result in the same thing. This can be solved by changing the `exec_mode` to `normal`, but then you have to do something like this:

```python
    spl = """"""search index=big value=""take a long time"" | eventstats c BY othervalue""""""
    search_kwargs = {""exec_mode"": ""normal"", ""earliest_time"": ""-7d"", ""latest_time"": ""now"", ""enable_lookups"": ""true""}

    start = time.time()
    # This should return immediately.
    splunk_search_job = splunk_object.jobs.create(spl, **search_kwargs)

    while not splunk_search_job.is_ready():
        time.sleep(2)

    while not splunk_search_job.is_done():
        time.sleep(5)

    end = time.time()
    print(end-start)

    834.357920885
```

There should probably be something in the sdk that catches those errors and reconnects.",That could very well be it. Is that the expected result of running a blocking search via the sdk? Should the sdk reconnect under the hood and continue blocking on the search? Or is it appropriate for the sdk to throw an error if the blocking search times out?,1504670
938,Compatibility between Python 2 and 3,open,2019-08-28T17:31:15Z,2019-09-24T00:30:23Z,,NONE,"These are some minor updates for compatibility between Python2 and Python3. 

Example changes:
- import \_\_future__ modules
- it.next() -> next(it)
- list(items) ",Closed and reopened to rerun the build tests. Different tests are failing on each run. I think the failing checks may not be related to this change. ,1504670
939,Issue with splunklib searchcommand validators in python 3,open,2019-08-27T21:02:55Z,2019-08-27T21:18:22Z,,NONE,"TypeError at ""/opt/splunk/etc/apps/splunk_app_infrastructure/bin/external_lib/splunklib/searchcommands/validators.py"", line 270 : ""delimiter"" must be string, not bytes

Python 3.7

If I change delimiter, quotechar and lineterminator to unicode, I don't see errors.
```python
class List(Validator):
    """""" Validates a list of strings

    """"""
    class Dialect(csv.Dialect):
        """""" Describes the properties of list option values. """"""
        strict = True
        delimiter = b','
        quotechar = b'""'
        doublequote = True
       lineterminator = b'\n'
        skipinitialspace = True
        quoting = csv.QUOTE_MINIMAL

```",,1504670
940,Getting error while running custom command on Splunk windows build having python 3.7,open,2019-08-09T13:01:39Z,2019-08-12T05:19:56Z,,CONTRIBUTOR,"The custom command is throwing (which uses splunklib) following error on Splunk installed on Windows machine (having python 3 build)

`Error in 'script': Getinfo probe failed for external search command 'ldapsearch'.`

**Details**
splunklib version: 1.6.6
platform: Windows
framework version: Python 3.7.2
Splunk version: splunk-8.0.0-86b1693e81bb-windows-64

The same command **is working properly** on the following builds
1) Splunk Linux build 8.0.0 (Py2)
2) Splunk Linux build PY3 8.0.0 (Py3)
3) Splunk Windows build 8.0.0 (Py2)

**Code Snippet**
==================
from __future__ import absolute_import, division, print_function, unicode_literals
import default

from splunklib.searchcommands import dispatch, GeneratingCommand, Configuration, Option, validators
import datetime
from splunklib.six.moves import map
from splunklib.six import iteritems, b, binary_type

@Configuration(retainsevents=True)
class LdapSearchCommand(GeneratingCommand):
    """""" Retrieves results from the specified search in a configured domain and generates events.

    This command must be placed at the beginning of a search pipeline:

        .. code-block:: text
        | ldapsearch domain=splunk.com search=""(objectCategory=User)"" attrs=""distinguishedName""

    """"""

    search = Option(
        doc=''' Specifies an RFC 2254 compliant search string.
        ''',
        require=True)

     domain = Option(
        doc=''' Specifies the LDAP or Active Directory domain directory to search.
        ''',
        default='default')

	def generate(self):
        try:

            # Some code for generating events

        except Exception as error:
            self.error_exit(error, message)

        return

dispatch(LdapSearchCommand, module_name=__name__)

Adding search.log from job inspect 
==============================================================
08-09-2019 15:21:40.378 INFO  SearchParser - PARSING: |ldapsearch debug=true search=""(sAMAccountName=*)""|fields *
08-09-2019 15:21:40.380 INFO  dispatchRunner - SearchHeadInitSearchMs=15
08-09-2019 15:21:40.380 INFO  SearchParser - PARSING: |ldapsearch debug=true search=""(sAMAccountName=*)""|fields *
08-09-2019 15:21:40.381 INFO  SearchParser - PARSING: |ldapsearch debug=true search=""(sAMAccountName=*)""|fields *
08-09-2019 15:21:40.381 INFO  dispatchRunner - Executing the Search orchestrator and iterator model (dfs=0).
08-09-2019 15:21:40.381 INFO  SearchOrchestrator - SearchOrchestrator getting constructed
08-09-2019 15:21:40.381 INFO  SearchOrchestrator -  Initialized the SRI
08-09-2019 15:21:40.391 INFO  ISplunkDispatch - Not running in splunkd. Bundle replication not triggered.
08-09-2019 15:21:40.391 INFO  SearchOrchestrator - Initialzing the run time settings for the orchestrator.
08-09-2019 15:21:40.392 INFO  UserManager - Setting user context: admin
08-09-2019 15:21:40.392 INFO  UserManager - Done setting user context: NULL -> admin
08-09-2019 15:21:40.401 INFO  SearchOrchestrator - Creating the search DAG.
08-09-2019 15:21:40.401 INFO  SearchParser - PARSING: |ldapsearch debug=true search=""(sAMAccountName=*)""|fields *
08-09-2019 15:21:40.426 INFO  script - found script file=C:\Program Files\Splunk\etc\apps\SA-ldapsearch\bin\ldapsearch.py
08-09-2019 15:21:40.426 INFO  script - stderr for script ldapsearch will be added to search.log
08-09-2019 15:21:41.948 WARN  SearchResultsCSVSerializer - CSV file  contains invalid field '', ignoring column.
08-09-2019 15:21:42.027 ERROR script - Getinfo probe failed for external search command 'ldapsearch'.
08-09-2019 15:21:42.030 INFO  SearchParser - PARSING: |ldapsearch debug=true search=""(sAMAccountName=*)""|fields *
08-09-2019 15:21:42.030 INFO  script - found script file=C:\Program Files\Splunk\etc\apps\SA-ldapsearch\bin\ldapsearch.py
08-09-2019 15:21:42.031 INFO  script - stderr for script ldapsearch will be added to search.log
08-09-2019 15:21:43.553 WARN  SearchResultsCSVSerializer - CSV file  contains invalid field '', ignoring column.
08-09-2019 15:21:43.553 ERROR script - Getinfo probe failed for external search command 'ldapsearch'.
08-09-2019 15:21:43.553 INFO  ScopedTimer - search.optimize 1.531
08-09-2019 15:21:43.553 INFO  SearchPhaseGenerator - Failed to create phases using AST:Error in 'script': Getinfo probe failed for external search command 'ldapsearch'.. Falling back to 2 phase mode.
08-09-2019 15:21:43.553 INFO  SearchPhaseGenerator -  Executing two phase fallback for the search=|ldapsearch debug=true search=""(sAMAccountName=*)""|fields *
08-09-2019 15:21:43.553 INFO  SearchParser - PARSING: |ldapsearch debug=true search=""(sAMAccountName=*)""|fields *
08-09-2019 15:21:43.554 INFO  script - found script file=C:\Program Files\Splunk\etc\apps\SA-ldapsearch\bin\ldapsearch.py
08-09-2019 15:21:43.554 INFO  script - stderr for script ldapsearch will be added to search.log
08-09-2019 15:21:45.074 WARN  SearchResultsCSVSerializer - CSV file  contains invalid field '', ignoring column.
08-09-2019 15:21:45.074 ERROR script - Getinfo probe failed for external search command 'ldapsearch'.
08-09-2019 15:21:45.074 ERROR SearchPhaseGenerator - Fallback to two phase search failed:Error in 'script': Getinfo probe failed for external search command 'ldapsearch'.
08-09-2019 15:21:45.097 ERROR SearchOrchestrator - Error in 'script': Getinfo probe failed for external search command 'ldapsearch'.
08-09-2019 15:21:45.097 ERROR SearchStatusEnforcer - sid:1565344299.8 Error in 'script': Getinfo probe failed for external search command 'ldapsearch'.
08-09-2019 15:21:45.257 ERROR dispatchRunner - RunDispatch::runDispatchThread threw error: Error in 'script': Getinfo probe failed for external search command 'ldapsearch",,1504670
941,Modify ReadMe to remove Easy_install references due to deprecation,open,2019-07-26T16:11:31Z,2019-07-26T20:58:04Z,,NONE,"The readMe points to using easy_install https://github.com/splunk/splunk-sdk-python/blob/master/README.md for the SDK.

It looks like easy_install has been deprecated, with pip being the better package option:

https://setuptools.readthedocs.io/en/latest/easy_install.html
https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install","@NicholasLeader thanks for the issue, we're open to a PR if you'd like to make the change",1504670
942,properly add parameters to request based on the method of the request,open,2019-07-24T03:02:36Z,2019-09-04T22:43:04Z,,NONE,"This PR resolves #261 related to improper handling of `body` parameters within the `Context.request` method. The method used (`GET` or `POST`) will determine if the body is encoded as part of the url or passed as body into the request.

GET method requests (with and without a body) were tested and worked as expected.","@billmurrin This is not a high priority issue for us to investigate as we are severely under resourced at the moment. Unless this is 10/10 we will not look at it this week. Thank you for your patience & understanding.

cc @tdhellmann ",1504670
943,Possible Bug with binding class request method related to GET parameters,open,2019-07-24T01:27:57Z,2019-07-24T01:45:02Z,,NONE,"I created a lookup on `/servicesNS/-/-/data/lookup-table-files` to obtain the lookup table files. I noticed that the result was limited to 30 results per request. With that in mind, I attempted to pass in parameters for `output_mode=json&count=0`. The following code has been modified slightly and is based on a snippet found in the `invoke` function of `spurl.py` SDK example:

```
return binding.connect(**kwargs).request(path, method=method, body=urllib.urlencode({'output_mode': 'json', 'count': 0}))
```

The `output_mode` works properly and returns `json`, however when using `count` (or `offset`), it results in a 400 error:

```
HTTP 400 Bad Request -- {""messages"":[{""type"":""ERROR"",""text"":""Argument \""count\"" is not supported by this handler.""}]}
```

Now, if I use `binding.connect(**kwargs).get` and pass in the same dictionary `{'output_mode': 'json', 'count' 0}` it gets properly passed as part of the GET request and returns all of the records.

```
return binding.connect(**kwargs).get(path, **{'output_mode': 'json', 'count': 0})
```

I believe the desired behavior on the `request` method would be to allow the use of Pagination and filtering parameters.","I believe the piece of code that is missing from the `Context.request` method is similar to portion found within the `self.http.get` method being called by `Context.get`:
```
        if kwargs:
            # url is already a UrlEncoded. We have to manually declare
            # the query to be encoded or it will get automatically URL
            # encoded by being appended to url.
            url = url + UrlEncoded('?' + _encode(**kwargs), skip_encode=True)
        return self.request(url, { 'method': ""GET"", 'headers': headers })
```

In `Context.request`, it adds `body` to the dict, but is not appending it to the baseURL, unlike `self.http.get`. Both methods appear to be calling `http.request`.

```
response = self.http.request(path,
                                     {'method': method,
                                     'headers': all_headers,
                                     'body': body})
        return response
```",1504670
944,Support Bearer Token,open,2019-07-16T11:24:48Z,2019-10-01T15:12:43Z,,NONE,"Splunk added the feature of creating and using Bearer Tokens for Rest API authentication.
https://docs.splunk.com/Documentation/Splunk/7.3.0/Security/UseAuthTokens

 Afaik, there is no possibility now to use Bearer token on the SDK",Please review my PR #282 ,1504670
945,Error while processing bytes data in python 3,open,2019-07-05T12:12:27Z,2019-07-08T21:18:32Z,,CONTRIBUTOR,"Faced this issue while using **splunklib** with **pyhton 3**
lib version: 1.6.0
platform: Linux(centos)
framework version: **Python 3.7.2**
Splunk version: **8.0.0 (build: 7f1fa0caa96a)**

The error is coming when some of the data is coming in bytes format, following is the trace of the error.

> 2019-07-04 17:28:11,907, Level=ERROR, Pid=28569, File=search_command.py, Line=981, **TypeError at ""/opt/splunk/etc/apps/SA-ldapsearch/bin/packages/splunklib/searchcommands/internals.py"", line 590 : **can't concat str to bytes****
Traceback:
  File ""/opt/splunk/etc/apps/SA-ldapsearch/bin/packages/splunklib/searchcommands/search_command.py"", line 603, in _process_protocol_v1
    self._execute(ifile, None)
  File ""/opt/splunk/etc/apps/SA-ldapsearch/bin/packages/splunklib/searchcommands/streaming_command.py"", line 54, in _execute
    SearchCommand._execute(self, ifile, self.stream)
  File ""/opt/splunk/etc/apps/SA-ldapsearch/bin/packages/splunklib/searchcommands/search_command.py"", line 848, in _execute
    self._record_writer.write_records(process(self._records(ifile)))
  File ""/opt/splunk/etc/apps/SA-ldapsearch/bin/packages/splunklib/searchcommands/internals.py"", line 522, in write_records
    write_record(record)
  **File ""/opt/splunk/etc/apps/SA-ldapsearch/bin/packages/splunklib/searchcommands/internals.py"", line 590, in _write_record
    **sv += value + '\n'****

In below code snippet, it is trying to concat **bytes** with **str**, so that it is throwing an error. Issues I can identify is,

- type **bytes** is not handled
- line `value = repr(value).encode('utf-8', errors='backslashreplace')` is converting incoming data in bytes format
- concat performed in line `sv += value+ '\n'`, which will try to concat string and bytes.

                       if value_t is not bytes:
                            if value_t is bool:
                                value = str(value.real)
                            elif value_t is six.text_type:
                                value = value
                            elif value_t is int or value_t is int or value_t is float or value_t is complex:
                                value = str(value)
                            elif issubclass(value_t, (dict, list, tuple)):
                                value = str(''.join(RecordWriter._iterencode_json(value, 0)))
                            else:
                                value = repr(value).encode('utf-8', errors='backslashreplace')

                        sv += value+ '\n'
                        mv += value.replace('$', '$$') + '$;$'

I changed above code like this to make it work, though I am not sure about decoding format. could you please look into it?

                     if value_t is not bytes:

                            if value_t is bool:
                                value = str(value.real)
                            elif value_t is six.text_type:
                                value = value
                            elif value_t is int or value_t is int or value_t is float or value_t is complex:
                                value = str(value)
                            elif issubclass(value_t, (dict, list, tuple)):
                                value = str(''.join(RecordWriter._iterencode_json(value, 0)))
                            else:
                                if six.PY2:
                                    value = repr(value).encode('utf-8', errors='backslashreplace')
                                else:
                                    value = repr(value)

                        if six.PY3 and value_t is bytes:
                            value = value.decode('utf-16')

                        sv += value + '\n'
                        mv += value.replace('$', '$$') + '$;$'
","@bj8798 thanks for reporting the bug, can you try upgrading to the latest SDK? If that doesn't work, please open a PR if you've got a working fix",1504670
946,Add support for licenser endpoint,open,2019-05-01T21:09:17Z,2019-05-01T23:07:53Z,,CONTRIBUTOR,"The current `Service` class seems to be missing the `licenser/...` endpoints, it would be great if it can be added. 
In the meantime, is there a way to query any custom spulnkd endpoint that's not covered under the `Service` class with the SDK today?","Hi @DrakeW, feel free to create a pull request to add any missing endpoints.
For reference, you can see the `b` example: https://github.com/splunk/splunk-sdk-python/blob/master/examples/abc/b.py",1504670
947,SDK unicode issue for multi value fields.,open,2019-03-11T22:50:34Z,2019-10-30T23:54:34Z,,NONE,This is a fix for supporting multi value unicode fields. ,,1504670
948,Any interest in moving wiki content into the docs?,open,2019-02-22T23:35:24Z,2019-02-22T23:35:24Z,,CONTRIBUTOR,"So I just recently found that this site has a wiki, which seems to be mostly untouched (besides the frequently updated ""Release"" doc) for about 5 years now.  But I think the info is still valuable an could be more helpful if it was put in a more prominent place.   In particular, I found the Architecture page to be a high quality intro to how the various classes are organized inside of the SDK.

I took a stab at importing most of the wiki pages (from Markdown to ReST; using pandoc, so it didn't take long.)  Feel free to take a look here:

https://github.com/lowell80/splunk-sdk-python/tree/wiki2sphinx

If there's interest, I can throw this in a pull request.  But wanted to start with a question / discussion.

I know for myself, I'm most frequently using [readthedocs](https://splunk-python-sdk.readthedocs.io/en/latest/) as my reference for the SDK.  This change would promote this information to that location too.",,1504670
949,"External search command 'acblblockcmd' returned error code 1. ""RuntimeError at search_command.py line 865 Failed to parse transport header: splunkVersion:7.2.0",open,2019-02-07T00:07:57Z,2019-07-31T17:27:27Z,,NONE,"Hi There,

I got the below exception when I run my python command:

 External search command 'acblblockcmd' returned error code 1. Script output = ""chunked 1.0,219,0 {""inspector"":{""messages"":[[""ERROR"",""RuntimeError at \""/opt/splunk/etc/apps/botcop/bin/splunklib/searchcommands/search_command.py\"", line 865 : Failed to parse transport header: splunkVersion:7.2.0\n""]]},""finished"":true}"" 

--
The commands.conf 

[acblblockcmd]
filename = acblblockcmd.py
type = python
chunked = false

--
And the command definition as follows:
import sys
from splunklib.searchcommands import dispatch, EventingCommand, Configuration
@Configuration()
class ExEventsCommand(EventingCommand):
        def transform(self, records):
                l = list(records)
                l.sort(key=lambda r: r['_raw'])
                return l
if __name__ == ""__main__"":
        dispatch(ExEventsCommand, sys.argv, sys.stdin, sys.stdout, __name__)



Anybody seen this error and how did you fix it?

Thanks in advance.","It's 7.3.. Seems to relate to access rights to .conf files, at least for Windows installs.

Den tis 30 juli 2019 22:39Shakeel Mohamed <notifications@github.com<mailto:notifications@github.com>> skrev:

@christofferTP<https://github.com/christofferTP> which version of Splunk Enterprise are you running?

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/splunk/splunk-sdk-python/issues/242?email_source=notifications&email_token=ABVTCHN6LZZPLH4V2LAC25DQCCRIDA5CNFSM4GUZOSR2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3FHZOQ#issuecomment-516586682>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABVTCHOZRWPBFNAMIGJNW6TQCCRIDANCNFSM4GUZOSRQ>.
",1504670
950,Don't output close tags if you haven't written a start tag,open,2019-01-08T18:03:36Z,2019-01-08T18:03:36Z,,NONE,"In looking at Splunk I found lots of events with just `</stream>` as the text. Looking at the code, the event_write class will always output the closing tag even if it doesn't output a start tag or any event. So, I added a check to see if there was a start tag written. If so, put a valid close tag. Otherwise, do not",,1504670
951,Possible fix for #207?,open,2019-01-06T07:04:23Z,2019-01-06T08:03:51Z,,NONE,"Could anyone please check if this would be ok for fixing #207 ? 

Uses __ for service.post() on binding.py for arguments like app, owner, sharing needed for example for post requests to the /acl path for changing permissions and also adds an access_update() to client.py so that the client can transparently call an update in permissions without having to use the __ in the start of those arguments. 

At least I believe this approach won't cause a breaking change by changing the method signature as said by @tdhellmann on https://github.com/splunk/splunk-sdk-python/pull/208",Ok I'll look into the tests better later to see what's happening but it still seems to be due to the prefix addition/strip. ,1504670
952,owner in KVStoreCollection should default owner to 'nobody',open,2018-11-19T03:28:24Z,2018-11-19T15:21:04Z,,NONE,"Attempts to use client for kvstore access fails with `user context of 'nobody' ` error. 
```
import splunklib.client as client

HOST = ""localhost""
PORT = ""8089""

'''
### BROKEN ###
service = client.connect(
        host=HOST,
        port=PORT,
        username='admin',
        password='changeme')

kv_client = service.kvstore
for kv in kv_client:
    print(kv)
# HTTPError: HTTP 400 Bad Request -- Must use user context of 'nobody' when interacting with collection configurations (used user='admin')
```

Manually this can be solved: 

```
### Solution By Modifying Owner ###

service = client.connect(
        host=HOST,
        port=PORT,
        username='admin',
        password='changeme') 

print(service.namespace)
#{'owner': None, 'app': None, 'sharing': None}
service.namespace['owner'] = 'Nobody' #<- change namespace owner to Nobody

kv_client = service.kvstore
for kv in kv_client:
    print(kv)
# <splunklib.client.KVStoreCollection object at 0x...>
# <splunklib.client.KVStoreCollection object at 0x...>
```

Since all interactions with kvstores must be done with an owner of `Nobody`, this should be set by default in `client.py`. I haven't spent much time with this library, but possibly: 

```
class KVStoreCollectionData(object):
    """"""This class represents the data endpoint for a KVStoreCollection.

    Retrieve using :meth:`KVStoreCollection.data`
    """"""
    JSON_HEADER = [('Content-Type', 'application/json')]

    def __init__(self, collection):
        self.service = collection.service
        self.collection = collection
      #self.owner, self.app, self.sharing = collection._proper_namespace() # replace this line
        self.owner = 'Nobody' # <- add default
        self.app, self.sharing = collection._proper_namespace() 
```
",Hi @SyraD - thanks for the report! I appreciate all your investigation into this issue. We're tracking this internally and will work on getting a fix out. ,1504670
953,Splunk _handle_auth_error masks authentication errors as login errors ,open,2018-11-19T01:49:36Z,2018-11-19T15:34:53Z,,NONE,"```
@contextmanager
def _handle_auth_error(msg):
    """"""Handle reraising HTTP authentication errors as something clearer.

    If an ``HTTPError`` is raised with status 401 (access denied) in
    the body of this context manager, reraise it as an
    ``AuthenticationError`` instead, with *msg* as its message.

    This function adds no round trips to the server.

    :param msg: The message to be raised in ``AuthenticationError``.
    :type msg: ``str``

    **Example**::

        with _handle_auth_error(""Your login failed.""):
             ... # make an HTTP request
    """"""
    try:
        yield
    except HTTPError as he:
        if he.status == 401:
            raise AuthenticationError(msg, he)
        else:
            raise
```",@SyraD - thanks for the bug report! We're now tracking this internally. We appreciate your help with identifying and fixing these issues. ,1504670
954,There should be a way to get sids or job objects from subsearches spawned by append via a specific job object or sid,open,2018-11-07T21:07:41Z,2018-11-09T18:53:14Z,,NONE,"When creating jobs through client there is no way to get the information about any jobs that are spawned by commands like append. This information is important as these jobs might need to be deleted and the information they give back is certainly helpful. 

splunklib.client is excellent for running many of the same search with different time. As a user I would like to delete my searches (*and* the sub searches they create) to not take up too much disk space and exceed my limit. 

`import splunklib.client as client`
`service=client.connect(...)`
`...`
`search=""| search index=bla | append [ | makeresults bla] ""` (_two searches are created here_)
`...`
`jobs=service.jobs`
`job=jobs.create(""search"", **kwargs)` 
`...`
`jobs.delete(job[""sid""])` (_only one is deleted as the appended search has a different sid_)

Which is a problem if I am making hundreds of these with a `while` loop.

The sid of the appended searches does have the sid of the parent in it as well as their own unique identifiers. They should be easy to find and return. ","Hi @tjh2822 - I think I understand the problem, but I'd like to hear a little more about:
- your use case
- the solution you're looking for (are you looking for the deletion of a parent search to automatically delete all child searches?) ",1504670
955,Python ResultsReader class is incredibly slow,open,2018-10-01T19:52:16Z,2020-02-14T14:13:19Z,,CONTRIBUTOR,"_It's possible that I don't understand what all the ResultsReader class is doing, so take this issue with a grain of salt._

When using the `ResultsReader` class to get results from a Splunk search, as indicated here: https://github.com/splunk/splunk-sdk-python/blob/master/splunklib/results.py#L173-L181, it takes an incredibly long time to get all the results. Using the `jobs.results` function is orders of magnitude faster. 

For example, on a search with 175k results, it takes 4+ minutes to get the results with `ResultsReader` objects, and 3.7 seconds with the `results` function. The following snippet shows what I'm talking about:

    import splunklib.results as results
    import splunklib.client as client
    from datetime import datetime
    import json
    
    
    splunk_object = client.connect(
        host=""host"",
        port=""port"",
        username=""username"",
        password=""password"",
        app=""app"",
        verify=True,
        autologin=True)
    
    spl = '| makeresults count=175000'
    
    splunk_search_kwargs = {""exec_mode"": ""blocking"",
                            ""earliest_time"": ""-48h"",
                            ""latest_time"": ""now"",
                            ""enable_lookups"": ""true""}
    
    splunk_search_job = splunk_object.jobs.create(spl, **splunk_search_kwargs)
    
    
    start_time_json = datetime.now()
    # Get the results from the Splunk search
    search_results_json = []
    # log_general.debug(""Getting Splunk search results."")
    get_offset = 0
    max_get = 49000
    result_count = int(splunk_search_job['resultCount'])
    while (get_offset < result_count):
        r = splunk_search_job.results(**{""count"": max_get, ""offset"": get_offset, ""output_mode"": ""json""})
        obj = json.loads(r.read())
        search_results_json.extend(obj['results'])
        get_offset += max_get
    # log_general.debug(""Found %d results"" % len(search_results))
    
    end_time_json = datetime.now()
    
    
    start_time = datetime.now()
    # Get the results from the Splunk search
    search_results = []
    # log_general.debug(""Getting Splunk search results."")
    get_offset = 0
    max_get = 49000
    result_count = int(splunk_search_job['resultCount'])
    while (get_offset < result_count):
        rr = results.ResultsReader(splunk_search_job.results(**{""count"": max_get, ""offset"": get_offset}))
        for result in rr:
            if isinstance(result, results.Message):
                # Diagnostic messages may be returned in the results
                print '%s: %s' % (result.type, result.message)
            elif isinstance(result, dict):
                # Normal events are returned as dicts
                search_results.append(result)
        get_offset += max_get
    # log_general.debug(""Found %d results"" % len(search_results))
    
    end_time = datetime.now()
    
    print (""ResultsReader time: %s"" % (end_time-start_time).seconds)
    print (""json_results time: %s"" % (end_time_json-start_time_json).seconds)

Is `ResultsReader` doing anything special that I miss out on by just getting the results is json mode directly? I know that `ResultsReader` uses XML under the hood, but that doesn't really matter to me; at the end of the day, I just need the results in a python object.","Hello there! thanks for these helpful tips... I am having the same issue and I am not quite sure how to use the proposed workaround `results.ResultsReader(io.BufferedReader(ResponseReaderWrapper(rs)))` mentioned above.

I am using a simple `service.jobs.export()` and my goal is to actually save the data to a dataframe. At the moment I am using

```
exportsearch_results = service.jobs.export(searchquery, **kwargs_export)
reader = results.ResultsReader(exportsearch_results)    

thislist = []
for item in reader:
 thislist.append(item)

```
and then I create the dataframe using the list. This is quite slow.

Any suggestion greatly appreciated.
Thanks!!",1504670
956,"splunklib.binding.AuthenticationError: Autologin succeeded, but there was an auth error on next request. Something is very wrong.",open,2018-08-29T22:27:36Z,2018-08-31T23:08:46Z,,NONE," * Version of the project : `splunk-sdk==1.6.5`
 * Platform version : `Ubuntu 16.04.3 LTS x86_64`
 * Framework version : `Python 3.5.2`
 * Splunk version : `Splunk Enterprise  7.1.1`

Code that produces the exception : 
```
import splunklib.client as client
import splunklib.results as results
service = client.connect(host='xx', username='xx', password='xx', autologin=True)

search_oneshot = 'search index=xx sourcetype=xx .......'
kwargs_export = {""earliest_time"": ""-4Hr"",
                 ""latest_time"": ""now"",
                 ""search_mode"": ""normal""}

oneshot_results = service.jobs.oneshot(search_oneshot, **kwargs_export)
reader = results.ResultsReader(oneshot_results)
for item in reader:
        print(item)
```

This simple script executes sometimes without any issue. But when not, it produces : 
```
Traceback (most recent call last):
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 289, in wrapper
    return request_fun(self, *args, **kwargs)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 71, in new_f
    val = f(*args, **kwargs)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 742, in post
    response = self.http.post(path, all_headers, **query)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 1208, in post
    return self.request(url, message)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 1228, in request
    raise HTTPError(response)
splunklib.binding.HTTPError: HTTP 401 Unauthorized -- call not properly authenticated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 231, in _handle_auth_error
    yield
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 300, in wrapper
    return request_fun(self, *args, **kwargs)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 71, in new_f
    val = f(*args, **kwargs)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 742, in post
    response = self.http.post(path, all_headers, **query)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 1208, in post
    return self.request(url, message)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 1228, in request
    raise HTTPError(response)
splunklib.binding.HTTPError: HTTP 401 Unauthorized -- call not properly authenticated

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""splunk_ex.py"", line 10, in <module>
    oneshot_results = service.jobs.oneshot(search_oneshot, **kwargs_export)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/client.py"", line 3041, in oneshot
    **params).body
  File ""path_to_env/lib/python3.5/site-packages/splunklib/client.py"", line 808, in post
    return self.service.post(path, owner=owner, app=app, sharing=sharing, **query)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 300, in wrapper
    return request_fun(self, *args, **kwargs)
  File ""/usr/lib/python3.5/contextlib.py"", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File ""path_to_env/lib/python3.5/site-packages/splunklib/binding.py"", line 234, in _handle_auth_error
    raise AuthenticationError(msg, he)
splunklib.binding.AuthenticationError: Autologin succeeded, but there was an auth error on next request. Something is very wrong.
```
I am not able to predict when it fails and when not. Its pretty random.  Am I hitting the resource limit or is it something else?

","@anumpatel Thanks for the detailed bug report! It's certainly possible to hit a limit like maximum concurrent connections. I would take a look through `$SPLUNK_HOME/var/log/splunk/splunkd.log` for any errors.

@swedishmike Yes, Python 3 has been supported since #191 which landed in v1.6.3.



",1504670
957,Ability to select search modes,open,2018-08-27T17:40:35Z,2019-11-22T17:21:03Z,,NONE,"Currently I don't think there is an ability to select a search mode via the splunk python sdk, ie Fast, Smart, or Verbose. 

We are having an issue with Splunk search time field extracting in Smart mode which breaks any query using the stats function. The splunk python sdk currently defaults to Smart mode, which means all the requests/queries we make via this module and the stats function break. 

","Hi, i was wondering if there was any resolution to this issue?  I was having a specific issue outputting all the fields in XML (json, csv are fine).  I tested this with curl and works fine, but i need this parameter in python sdk.   Without this parameter **adhoc_search_level = verbose**, it won't populate all the fields. ",1504670
958,Python ssl.SSLError: [SSL: UNKNOWN_PROTOCOL] unknown protocol (_ssl.c:661),open,2018-08-14T05:07:35Z,2019-12-20T17:36:47Z,,NONE,"Hi,
i'm getting SSLError while connecting splunk using python splunk sdk.
Code:
from splunklib import client
splunk_service=client.connect(host=""localhost"",port=8000,username=""admin"",password=""*********"")
print (splunk_service)

python version:
2.7.15
splunk sdk version : 1.6.5

Error:
Traceback (most recent call last):
  File ""splunk_python.py"", line 9, in <module>
    username='admin', password='kasi@777')
  File ""C:\Python27\lib\site-packages\splunklib\client.py"", line 325, in connect
    s.login()
  File ""C:\Python27\lib\site-packages\splunklib\binding.py"", line 861, in login
    cookie=""1"") # In Splunk 6.2+, passing ""cookie=1"" will return the ""set-cookie"" header
  File ""C:\Python27\lib\site-packages\splunklib\binding.py"", line 1208, in post
    return self.request(url, message)
  File ""C:\Python27\lib\site-packages\splunklib\binding.py"", line 1225, in request
    response = self.handler(url, message, **kwargs)
  File ""C:\Python27\lib\site-packages\splunklib\binding.py"", line 1366, in request
    connection.request(method, path, body, head)
  File ""C:\Python27\lib\httplib.py"", line 1042, in request
    self._send_request(method, url, body, headers)
  File ""C:\Python27\lib\httplib.py"", line 1082, in _send_request
    self.endheaders(body)
  File ""C:\Python27\lib\httplib.py"", line 1038, in endheaders
    self._send_output(message_body)
  File ""C:\Python27\lib\httplib.py"", line 882, in _send_output
    self.send(msg)
  File ""C:\Python27\lib\httplib.py"", line 844, in send
    self.connect()
  File ""C:\Python27\lib\httplib.py"", line 1263, in connect
    server_hostname=server_hostname)
  File ""C:\Python27\lib\ssl.py"", line 363, in wrap_socket
    _context=self)
  File ""C:\Python27\lib\ssl.py"", line 611, in __init__
    self.do_handshake()
  File ""C:\Python27\lib\ssl.py"", line 840, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: UNKNOWN_PROTOCOL] unknown protocol (_ssl.c:661)


Thanks,
Mani","> @JuxhinDB Tried what you mentioned above , but getting below error
> 
> Traceback (most recent call last):
> File ""check_splunk_conn.py"", line 15, in
> scheme='http'
> File ""/usr/local/lib/python2.7/site-packages/splunklib/client.py"", line 331, in connect
> s.login()
> File ""/usr/local/lib/python2.7/site-packages/splunklib/binding.py"", line 875, in login
> session = XML(body).findtext(""./sessionKey"")
> File ""/usr/lib64/python2.7/xml/etree/ElementTree.py"", line 1300, in XML
> parser.feed(text)
> File ""/usr/lib64/python2.7/xml/etree/ElementTree.py"", line 1642, in feed
> self._raiseerror(v)
> File ""/usr/lib64/python2.7/xml/etree/ElementTree.py"", line 1506, in _raiseerror
> raise err
> xml.etree.ElementTree.ParseError: syntax error: line 1, column 0

I'm getting this error, and cause is that the server, when trying to login returns a redirect and the code can't handle that:
To server:
```
POST /services/auth/login HTTP/1.1
Accept-Encoding: identity
Content-Length: 42
Host: localhost
User-Agent: splunk-sdk-python/1.6.11
Accept: */*
Connection: Close

username=admin&password=********&cookie=1
```
Response:
```
HTTP/1.1 303 See Other
Date: Fri, 20 Dec 2019 17:12:44 GMT
Content-Type: text/html; charset=UTF-8
X-Content-Type-Options: nosniff
Content-Length: 359
Location: http://localhost/en-US/services/auth/login
Vary: Accept-Language
Connection: Close
X-Frame-Options: SAMEORIGIN
Server: Splunkd

<!doctype html>
...
```
The code doesn't appear to handle this and tries to find a sessionKey and fails. The odd thing is that the comments in the code clearly state that it should follow 303 redirects, I can't find the actual code that should do it.",1504670
959,event.py time parameter generate wrong _time in the index time,open,2018-07-19T04:20:15Z,2018-07-19T14:29:37Z,,NONE,"I am developing a Python add-on and I am trying to specify a `_time` composed by two JSON fields `lastTstamp` and `lastDate` in the index time. Therefore, the extraction is getting a different and wrong timestamp.

     JSON input:
     {  
        firstTstamp: 16:04:00Z
        lastTstamp: 15:32:02Z    
        lastDate: 2015-10-23        
        id: a4ec1ba0-ab74-11e6-a19f-0a7e67dda05f    
        status: new
     }

event output: `_time: 2015-11-18T16:04:00.000+00:00`

So far I tried two approaches:
1st approach: Using `helper.new_event` + `ew.write_event(event)`

     utc_dt = datetime.strptime(data_json['lastDate'] + 'T' + data_json['lastTstamp'], '%Y-%m-%dT%H:%M:%SZ')
     event = helper.new_event(time=time.mktime(utc_dt.timetuple()),
                                          source=helper.get_input_type(),
                                          index=helper.get_output_index(),
                                          sourcetype=helper.get_sourcetype(),
                                          data=json.dumps(data_json))
     ew.write_event(event)

2nd approach: Edit props.conf and transforms.conf

transform.conf:

     [alert_time]
     REGEX = 'lastDate': u'(\d{4}-\d{2}-\d{2}).*lastTstamp': u'(\d{2}:\d{2}:\d{2})
     FORMAT = $1T$2.000+00:00
     DEST_KEY = _time

props.conf:

      [json_alert]
     KV_MODE = json
     SHOULD_LINEMERGE = 0
     category = Splunk App Add-on Builder
     pulldown_type = 1
     TRANSFORMS-datetime = alert_time`

I some cases a time zone difference is expected as normal, but as depicted in the example above, there is a huge gap between input and output timestamp.

Also, notice that even passing `lastTstamp` to `time` parameter, the data from `firstTstamp` was used.

Setup information:
    splunk-sdk version: 1.6.5
    Platform version: docker image
    Framework version: Python 2.7.14
    Splunk version: 6.5.3, 7.1.0, 7.1.2 (tested with all three versions)
",,1504670
960,Ability to pass through args when deleting from collection,open,2018-06-28T01:40:44Z,2018-10-09T22:42:13Z,,NONE,"Could not specify an app when trying to delete an index because an ""app"" argument could not be passed to the service.indexes.delete method. This allows the user to pass through arguments to Collection.delete.",@Frechetta - did you ever have a chance to look into those tests?,1504670
961,Fix HTTP 400 errors for certain post requests,open,2018-06-12T18:35:57Z,2018-11-19T15:19:35Z,,NONE,"This is one possible fix I came up with for issue #207. By moving owner, app, and sharing from arguments to kwargs in the post method, they will be included in the request body. This will fix any 400 errors that result from owner, app, or sharing being left out of REST requests that require them to be explicitly defined in the body of the request.",See also: https://github.com/splunk/splunk-sdk-python/issues/231,1504670
962,400: Bad Request for POST Requests to Change Permissions,open,2018-06-12T16:01:38Z,2019-02-21T00:33:11Z,,NONE,"# Issue Description
Using splunklib.client.post to change permissions on eventtypes fails because the client strips out the owner and sharing fields from the body of the request. This results in the body only containing perms.read and perms.write without specified owner or sharing fields. Since these fields are missing, the request returns a 400 Bad Request error code from the Splunk server.

## Instance Information
* splunk-sdk version: 1.6.4
* Platform version: macOS 10.13.5
* Framework version: Python 3.6.5
* Splunk version: 7.0.3

## Example Code Snippet
```
# Where self is a wrapper for the Splunklib client
# o = self.service.username
# sharing = 'user'
# perms.read = '*'
# perms.write = '*'
path = '/' + '/'.join([SPLUNK_REST_NAMESPACE, self.service.username, self.app, SPLUNK_REST_EVENT_TYPES, name, SPLUNK_REST_PERMISSION])
body_dict = {
            'owner': owner,
            'sharing': sharing,
            'perms.read': perm_read,
            'perms.write': perm_write,
}
self.service.post(path, **body_dict, output_mode='json')
```

## Correct REST API Request
`curl -k -u <user>:<password> <splunk_address>/servicesNS/<user>/<app>/saved/eventtypes/<name>/acl -d owner=<user> -d sharing=user -d perms.read=* -d perms.write=*`

## Stack Trace
File ""/opt/project/splunk_utils/event.py"", line 312, in chmod_event_type
    return self.service.post(path, **body_dict, output_mode='json')
  File ""/usr/local/lib/python3.6/site-packages/splunklib/binding.py"", line 289, in wrapper
    return request_fun(self, *args, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/splunklib/binding.py"", line 71, in new_f
    val = f(*args, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/splunklib/binding.py"", line 742, in post
    response = self.http.post(path, all_headers, **query)
  File ""/usr/local/lib/python3.6/site-packages/splunklib/binding.py"", line 1208, in post
    return self.request(url, message)
  File ""/usr/local/lib/python3.6/site-packages/splunklib/binding.py"", line 1228, in request
    raise HTTPError(response)
splunklib.binding.HTTPError: HTTP 400 Bad Request -- b'{""messages"":[{""type"":""ERROR"",""text"":""The following required arguments are missing: owner, sharing.""}]}'","I'm running into the same limitation trying to post to the `/acl` endpoint.   @sketchypotato, did you come up with another workaround?

I thought about dropping down to using `binding`, but still looks like `Context` would have the same issue, so I'd have to go all the way down to `HttpLib`, ugh.

Anyone know if #235 works, or when it's scheduled to be merged?",1504670
963,Update client.py,open,2018-05-30T14:40:26Z,2019-05-08T21:14:08Z,,NONE,encode slashes for kvstore update to ensure proper checking for existing items,Hey @tjgeorgen - would you mind adding a test case to demonstrate that the issue you were experiencing is fixed by this PR? ,1504670
964,index_earliest parameter for search jobs not respected if search has sub-searches,open,2018-04-13T10:56:09Z,2018-09-27T22:43:18Z,,NONE,"Hi! 
Then running basic search command (without sub-searches) with the only index_earliest provided everything works fine - search return results based on index_earliest parameter.
Then running the search with sub-searches and passing index_earliest parameter, for example:
`search index=main | append [search index=info ]` 
It ignores index_earliest and query all index events. 
I have tested this with every available search type from http://dev.splunk.com/view/python-sdk/SP-CAAAEE5

Also, the documentation is very poor, for example, how to query whole search result using normal search? It always return only 100 events, even if provide additional count parameter for search job.

",@spellanser can you share a code example to reproduce the issue?,1504670
965,Support internal search command logging without enforcing splunklib l…,open,2017-06-23T00:03:41Z,2017-06-23T16:02:15Z,,NONE,"This ensures that logs from search commands go to the configured logger/handle in logging.conf. And Eliminates the use of the statically chosen logger in environments.py. This was tested with a reporting command.

This pull request also includes update to external_search_command.py to also do the same as above. No example commands to test this with.",Timed out again,1504670
966,Adding more deployment endpoint code to Service,open,2016-10-28T16:10:05Z,2016-10-28T20:45:10Z,,NONE,"- Fixes the URL for PATH_DEPLOYMENT_SERVERCLASSES
- Exposes deployment_apps, deployment_clients and server_classes in the Service class
- Adding virtualenv related entries to .gitignore
","@vegitron OK, we appreciate the flexibility. The test failure is a recent regression around SSL certs,  it's unrelated to your changes
",1504670
967,Error on pull and push records to splunk,open,2016-08-02T07:54:53Z,2019-08-08T00:47:07Z,,CONTRIBUTOR,"Suppose I have 300 million events in my local Splunk instance. I write a chunked streaming search command read records from Splunk and write to Splunk then. Then I got a error:
`ChunkedExternProcessor - Failure writing result chunk, buffer full. External process possibly failed to read its stdin.`

Seems it's a very common issue when handling big scale data. Maybe it's a bug?

Another issue is when I write a big data to Splunk, I can also get this exception sometime:

```
File=search_command.py, Line=1016, IOError at ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/internals.py"", line 820 : [Errno 32] Broken pipe
Traceback:
  File ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/search_command.py"", line 801, in _process_protocol_v2
    self._execute(ifile, None)
  File ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/streaming_command.py"", line 54, in _execute
    SearchCommand._execute(self, ifile, self.stream)
  File ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/search_command.py"", line 869, in _execute
    self._record_writer.write_records(process(self._records(ifile)))
  File ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/internals.py"", line 528, in write_records
    write_record(record)
  File ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/internals.py"", line 651, in _write_record
    self.flush(partial=True)
  File ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/internals.py"", line 774, in flush
    self._write_chunk(metadata, self._buffer.getvalue())
  File ""/Applications/Splunk/etc/apps/searchcommands_app/bin/packages/splunklib/searchcommands/internals.py"", line 820, in _write_chunk
    write(body)
```

I think maybe you guys want to know this.
","This issue is discussed in Splunk Answers ticket 686940 (https://answers.splunk.com/answers/686940) and I have offered a proposed SDK-side workaround (that is actually also an SDK efficiency improvement) in GitHub here:
  https://github.com/TiVo/splunk-sdk-python/commit/5188f7d709cadd80e786692b371a64c4ae0991d2",1504670
968,"""handlers"" stanza missing in examples/searchcommands_template/default/logging.conf",open,2016-07-30T12:17:53Z,2016-07-31T10:48:29Z,,NONE,"Please see diff.
","I think there's a problem with the automated travis-ci checks. When using the searchcommands_template app on Splunk 6.4.1 the diff I've put in this pull request is valid and required to fix a bug.
",1504670
969,Identical entity names will cause an infinite loop,open,2016-07-27T02:00:35Z,2016-07-27T02:10:20Z,,NONE,"Identical entity names will cause an infinite loop ""RuntimeError: maximum recursion depth exceeded"". Give a clear message about which applications have this entity.
Trying to `self.name` in `Raise AmbiguousReferenceException` will result in a dead loop. 

```
splunklib\client.py"", line 928, in _load_atom_entry
    raise AmbiguousReferenceException(""Fetch from server returned multiple entries for name %s."" % self.name)
  splunklib\client.py"", line 1067, in name
    return self.state.title
  splunklib\client.py"", line 1091, in state
    if self._state is None: self.refresh()
  splunklib\client.py"", line 1011, in refresh
    self._state = self.read(self.get())
  splunklib\client.py"", line 1071, in read
    results = self._load_state(response)
splunklib\client.py"", line 934, in _load_state
    entry = self._load_atom_entry(response)
client.py"", line 928, in _load_atom_entry
    raise AmbiguousReferenceException(""Fetch from server returned multiple entries for name %s."" % self.name)
client.py"", line 1067, in name
    return self.state.title
.
.
.
```

[test.json.zip](https://github.com/splunk/splunk-sdk-python/files/385147/test.json.zip)
","@itay 
I have signed the CLA and attached the sample json for testing.
",1504670
970,[Snyk] Security upgrade mkdirp from 0.5.1 to 0.5.2,open,2020-03-18T04:51:29Z,2020-03-18T04:51:29Z,,NONE,"<h3>Snyk has created this PR to fix one or more vulnerable packages in the `yarn` dependencies of this project.</h3>

#### Changes included in this PR

- Changes to the following files to upgrade the vulnerable dependencies to a fixed version:
    - package.json
    - yarn.lock



#### Vulnerabilities that will be fixed
##### With an upgrade:
Severity                   |  Issue                   | Breaking Change                   | Exploit Maturity
:-------------------------:|:-------------------------|:-------------------------|:-------------------------
![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Prototype Pollution <br/>[SNYK-JS-MINIMIST-559764](https://snyk.io/vuln/SNYK-JS-MINIMIST-559764) |  No  | Proof of Concept 










Check the changes in this PR to ensure they won't cause issues with your project.



------------



**Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*

For more information:

🧐 [View latest project report](https://app.snyk.io/org/jonathan-casarrubias/project/7a0a5ab5-e97d-4c49-8efa-6f6889de3c12)

🛠 [Adjust project settings](https://app.snyk.io/org/jonathan-casarrubias/project/7a0a5ab5-e97d-4c49-8efa-6f6889de3c12/settings)

📚 [Read more about Snyk's upgrade and patch logic](https://snyk.io/docs/fixing-vulnerabilities/)

[//]: # (snyk:metadata:{""dependencies"":[{""name"":""mkdirp"",""from"":""0.5.1"",""to"":""0.5.2""}],""packageManager"":""yarn"",""projectPublicId"":""7a0a5ab5-e97d-4c49-8efa-6f6889de3c12"",""projectUrl"":""https://app.snyk.io/org/jonathan-casarrubias/project/7a0a5ab5-e97d-4c49-8efa-6f6889de3c12?utm_source=github&utm_medium=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-JS-MINIMIST-559764""],""upgrade"":[""SNYK-JS-MINIMIST-559764""],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title""]})
",,60712558
971,Add set filter and where on QueryString,open,2020-03-17T09:58:31Z,2020-03-17T09:58:31Z,,NONE,fix #653 ,,60712558
972,Unicode character can't set in headers!,open,2020-03-17T09:53:44Z,2020-03-17T09:53:44Z,,NONE,"#### What type of issue are you creating?
- [ x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ x] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

I using unicode character to find (filter and where) and get message: 
""Cannot convert string to ByteString because the character at index ""

In headers, i can't set unicode character without base64 encode.

Please allow change this setting via LoopbackConfig

#### Please add a description for your issue:",,60712558
973,updateAttributes makes null all attributes which are not defined,open,2020-01-13T22:10:06Z,2020-01-13T22:19:45Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

I trying to use the method ....updateAttributes(id, data) the data object has many elements but not all of the table, then this method rewrite everything as null if not exist on data object",,60712558
974,Wrong api service generation,open,2019-10-28T08:52:57Z,2019-10-28T08:52:57Z,,NONE,"#### What type of issue are you creating?
- [ x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ x] 2.3.1

Hi when generating the service for a model, the typescript function does not post the request data.

here is my model remote method config:

```
""methods"": {
    ""upload"": {
      ""http"": [
        {
          ""path"": ""/upload"",
          ""verb"": ""post""
        }
      ],
      ""accepts"": [
        {
          ""arg"": ""req"",
          ""type"": ""object"",
          ""required"": true,
          ""http"": {
            ""source"": ""req""
          },
          ""description"": ""The http request""
        }
      ],
      ""returns"": [{
        ""arg"": ""response"",
        ""type"": ""string"",
          ""required"": true,
        ""description"": ""The http response""
      }],
      ""description"": ""Upload a file""
    }
  }
```

And here is the generated function :

```
 public upload(req: any, customHeaders?: Function): Observable<any> {
    let _method: string = ""POST"";
    let _url: string = LoopBackConfig.getPath() + ""/"" + LoopBackConfig.getApiVersion() +
    ""/Attachments/upload"";
    let _routeParams: any = {};
    let _postBody: any = {};
    let _urlParams: any = {};
    let result = this.request(_method, _url, _routeParams, _urlParams, _postBody, null, customHeaders);
    return result;
  }
```
The `_postBody` is empty, the `req` parameter is not used.

In older versions it used to be `let _postBody = {data: req}`",,60712558
975,Proper use of Container Model SDK,open,2019-10-08T15:19:35Z,2019-11-27T20:46:52Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

So I've been searching any clue on how to properly use the container model generated for the sdk, I'm using angular 8 to try to upload to my loopback 3 server;

` onFileSelect(event) {
    if (event.target.files.length > 0) {
      const file = event.target.files[0].name;
      const formData = new FormData();
      var reader = new FileReader();
        formData.append('file ',event.target.files[0]);
       // console.log(formData)
        for (var [key, value] of formData.entries()) { 
          console.log(key, value);
        }
        
    
        this.containerapi.upload('docs',formData,(response)=>
        {
         // console.log(response)
        }).subscribe((d)=>
        {
          console.log(d)
        },(error)=>{
          console.log(error)
        })
    
     
    
    }
  }`
this is my component.ts

` <div class=""image-upload"">
                        <label for=""file-input"">
                            <img src=""../../assets/icon/pdf-64.png""/>
                        </label>
                    
                        <input #file id=""file-input"" type=""file""  (change)=""onFileSelect($event)""/>
                    </div>`

this si the html part where the user selects the file and then its supposed to upload it.
I can understand the first parameter on the upload method, but what exactly I'm supposed to put on the request parameter?
I made it work testing the server endpoint with insomnia, as a multipart form and having a parameter called 'file', selecting the file, submitting and it uploaded it perfectly, but now trying with the sdk I cant figure out what Im doing wrong, any idea?","Did you get any further?

I haven't tried uploading files, but may be doing this shortly.

If I do, I'll try to come back here and update it.

        == John ==",60712558
976,Loopback 3 mounted on Loopback 4,open,2019-09-16T08:21:11Z,2019-11-27T20:45:48Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
Hello,
As said by Loopback, Loopback 3 can be mounted on a Loopback 4 application. This is fine for the moment.
Does anyone has any experience generating the SDK with this kind of configuration please?

Thanks and regards,
","I have to admit we're using Loopback 3 only, mostly due to the ACL's not being in LB4 yet. It just isn't feature complete.

I ended up forking the SDK generator due to issues, such as #636 , and wasn't getting any responses at all here.

The maintainer left to work on another project which is also abandoned.

        == John ==",60712558
977,Set parameter customHeader in all server calls,open,2019-05-29T08:59:38Z,2019-05-29T08:59:38Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X] Other

Write other if any: 2.3.1

#### Please add a description for your issue:

On my client, I need to set a parameter in the HTTP header for any calls to the server's API.

Occasionally, I set a value to the customHeaders parameter but this time I want to perform this operation on all server calls.

Is this possible without using the customHeaders parameter?
",,60712558
978,Problem with LoopBackConfig.setApiVersion(''),open,2019-05-28T13:54:51Z,2019-05-28T13:54:51Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

When the API is not versioned, if you write as suggested in your component:
`LoopBackConfig.setBaseURL('https://localhost:3000');
    LoopBackConfig.setApiVersion('');`

an additional '/' is generated.
So the request are made towards: //Customers/login.

Sometimes APIs are not versioned and this is blocking.

Kind Regards for your help.

",,60712558
979,AccountApi Not Found in Sdk,open,2019-04-10T23:39:44Z,2019-04-10T23:39:44Z,,NONE,"#### What type of issue are you creating?
- [ x ] Bug
- [ ] Enhancement
- [ x ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ x ] Other

Write other if any: 2.3.1

#### Please add a description for your issue:

When i want to use the sdk, i notice that *AccountApi* not found. I find it in all the skd files ( Sublime Text full search ) and effectively, **AccountApi** Not Found.",,60712558
980,Question: How to reset password sample,open,2019-03-25T12:20:41Z,2019-04-20T10:38:06Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
Hello,
I am in the process of developing the password rest functionality client side and I am wondering where I could find the same previously provided by mean expert official on loopback sdk builder. I am pretty sure this sample has this feature in it.
Am I right?

Otherwise I am ok for a nice sample :)",I've responded on StackOverflow.  Hopefully it is helpful for you.,60712558
981,VueJS,open,2019-03-01T21:05:54Z,2019-03-01T21:05:54Z,,NONE,"#### What type of issue are you creating?
- [x ] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x ] Other 2.1.2 and you need to fix this template

Write other if any:

#### Please add a description for your issue:

VueJS seems to be broken, unless you intended the <todo> to be without an oxford comma:

```

[f:\OurApp]./node_modules/.bin/lb-sdk server\server.js -l ""vuejs"" sdk/VueJS


Swagger: skipping unknown type ""Binary"".
Loading Framework vuejs
Generating ""sdk"" for the API endpoint ""/api""
f:\OurApp\node_modules\@mean-expert\loopback-sdk-builder\bin\lb-sdk:167
  generator[context.framework](context);
                              ^

TypeError: generator[context.framework] is not a function
    at runGenerator (f:\OurApp\node_modules\@mean-expert\loopback-sdk-builder\bin\lb-sdk:167:31)
    at Function.verifyPath (f:\OurApp\node_modules\@mean-expert\loopback-sdk-builder\bin\lb-sdk:118:5)
    at Object.onceWrapper (events.js:273:13)
    at Function.emit (events.js:182:13)
    at f:\OurApp\node_modules\loopback-boot\lib\executor.js:63:9
    at f:\OurApp\node_modules\loopback-boot\node_modules\async\lib\async.js:251:17
    at f:\OurApp\node_modules\loopback-boot\node_modules\async\lib\async.js:154:25
    at f:\OurApp\node_modules\loopback-boot\node_modules\async\lib\async.js:248:21
    at f:\OurApp\node_modules\loopback-boot\node_modules\async\lib\async.js:612:34
    at process._tickCallback (internal/process/next_tick.js:61:11)
    at Function.Module.runMain (internal/modules/cjs/loader.js:745:11)
    at startup (internal/bootstrap/node.js:266:19)
    at bootstrapNodeJSCore (internal/bootstrap/node.js:596:3)
```

It is mentioned in the arg list:

```

******************************************* LoopBack SDK Builder 2.0 *******************************************

Generate Client SDK for your LoopBack Application.
Usage:
 ./node_modules/.bin/lb-sdk server/server app/shared/sdk -d [ng2web | ng2native | ng2universal] -i [enabled | disabled] -v [enabled | strict | disabled]

Options:
  -l, --library         Client's library (angular, react, vuejs <todo> ...)                     [default: ""angular2""]
  -d, --driver          Platform specific drivers (ng2web, ng2native, ng2universal, react-web)  [default: ""ng2web""]
  -i, --io              Enable PubSub, IO and FireLoop functionality                            [default: ""enabled""]
  -n, --ngrx            Enable NGRX functionality (enabled | orm) EXPERIMENTAL FEATURE
  -w, --wipe            Automatically wipe SDK Directory                                        [default: ""disabled""]
  -v, --default-values  Add default values in models                                            [default: ""disabled""]
  -f, --fireloop-only   Generate only FireLoop SDK + Auth Services                              [default: ""disabled""]
  -q, --quiet           quiet mode - no console output (forces -w)                              [default: false]
  -t, --typescript      Enable Typescript default true ( React Only )                           [default: true]

Not enough non-option arguments: got 0, need at least 1

```",,60712558
982,Use HttpClientModule for SDKNodeModule,open,2019-02-21T10:30:15Z,2019-02-21T10:30:15Z,,CONTRIBUTOR,"#### What type of pull request are you creating?
- [x] Bug Fix
- [ ] Enhancement
- [ ] Documentation

#### How many unit test did you write for this pull request?

None.

Write a reason if none (e.g just fixed a typo):

Just renamed a module to import.

#### Please add a description for your pull request:

Angular Universal apps now also use the HttpClientModule. This commit replaces the HttpModule with the HttpClientModule.",,60712558
983,SDK compatibility with Angular 5.2,open,2019-02-20T12:58:06Z,2019-03-01T20:49:28Z,,NONE,"#### What type of issue are you creating?
- [ ] Question

#### What version of this module are you using?
NA

Write other if any:

#### Please add a description for your issue:
Will the SDK generated by this generator work with Angular 5.2 (as I am using IONIC 3)
","I got it to work OK with Angular7, but had severe issues with getting ANY of the API's to generate. See: https://github.com/mean-expert-official/loopback-sdk-builder/issues/636

This has nothing to do with Angular, of course. I ended up editing the EJS code to generate my own client files, and used a template from here:

https://github.com/bezael/loopback3_angular6_bootstrap4 

to do it. It seemed to work, and was a simple example of a client front end and how to use the Loopback API to access the back end, something that's missing in nearly all of the documentation on either @ Mean or at Loopback

        == John ==

",60712558
984,REACT MAINTAINERS are welcome ,open,2019-02-08T11:14:53Z,2019-02-08T11:24:21Z,,NONE,"hi
because of inactivity of main project manager  and so many bugs in react sdk  I’ve created new repo(fork)
please help me to improve react version and fix bugs . 
https://github.com/Amenocy/loopback-sdk-builder-react
thank you.",,60712558
985,Only PATCH methods ,open,2019-02-03T17:16:47Z,2019-03-01T08:21:07Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X ] Other
2.1.2

Write other if any: 2.1.2

#### Please add a description for your issue:

I'm looking at service.ejs, and note that there's code there to generate GET, PUT, UPSERT, etc. verbs.
 
My Loopback API is fairly generic and absolutely does have full API capability, including get, put, etc.

Yet the generated code ONLY has the Patch method.

I was very confused. There's very little documentation on how to use these API's, for example in Angular, to obtain current values; I start to implement 'GET' verbs, then notice that they should be generated, I think.

Does anyone have any ideas, or is this project dead?

Seems to be related to https://github.com/mean-expert-official/loopback-sdk-builder/issues/608

Is only Loopback 2 supported? That would have been good to know.

        == John ==","I know the main maintainer's abandoned this project to work on another project (which seems abandoned too, I hope everything is OK), but this is a serious problem. No one has any ideas? Is it a MySQL connector issue? If I write my own methods everything works fine.

        == John ==",60712558
986,Doc bug; Architecture Diagram missing,open,2019-01-31T08:03:35Z,2019-01-31T08:03:35Z,,NONE,"#### What type of issue are you creating?
- [x] Bug


#### What version of this module are you using?
- [X] Other
Website

#### Please add a description for your issue:

In the documentation on this page: 

[https://github.com/mean-expert-official/loopback-sdk-builder/wiki/Architecture ](https://github.com/mean-expert-official/loopback-sdk-builder/wiki/Architecture )

There is a diagram (https://camo.githubusercontent.com/d71031301ccbbaf0f487b6e999b2e66a7d3f7bad/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f6d65616e2d6578706572742d696d616765732f73646b2d6275696c6465722d686c612e7376673f73616e6974697a653d74727565) that seems to be missing.

Can someone re-upload it? It would help n00bs (like myself) come to terms with it.

Also, I've looked at the source code, and any architecture documentation on that would be great too :)

",,60712558
987,"Fireloop mentioned in docs, but doesn't resolve",open,2019-01-31T07:57:49Z,2019-01-31T07:57:49Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
Website and wiki

#### Please add a description for your issue:

I realize there's some issues with Fireloop, but the docs still point to it, and it's gone.

I know it's probably a lot of work to remove it, and maybe not necessary, but we should change the docs to say something about it. ""Support is left here for legacy projects ..."" or whatever.
",,60712558
988,fix pipe/map bug in react version ,open,2019-01-27T10:37:40Z,2019-02-07T20:53:30Z,,NONE,"#### What type of pull request are you creating?
- [* ] Bug Fix
- [ ] Enhancement
- [ ] Documentation

#### How many unit test did you write for this pull request?


Write a reason if none (e.g just fixed a typo):


#### Please add a description for your pull request:
related to this https://github.com/mean-expert-official/loopback-sdk-builder/issues/632",,60712558
989,React SDK and rxjs version problem,open,2019-01-27T08:05:32Z,2019-01-27T09:36:03Z,,NONE,"#### What type of issue are you creating?
- [* ] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

in react SDK output code is like this : 
```
 return from(request)
        .map((res) => res.data)
        .catch((e) => errorHandler.handleError(e));
```
and it is not working with rxjs 5.6 and 6.3
`Uncaught TypeError: (0 , _rxjs.from)(...).map is not a function`
but in angular code it uses pipes .
","problem for base services fixed in this commit : 
https://github.com/InovaMind/loopback-sdk-builder/commit/0eb195b84abb2eabc40088ecc07c66a5e8427877

but problem already exist for custom model services (lib/templates/shared/services/custom/service.ejs).
please merge that and fix for custom models.",60712558
990,updateAll AssertionError: The where argument must be an object,open,2018-12-29T19:27:24Z,2018-12-29T19:27:24Z,,NONE,"Hi,

Facing the above issue.

Angular version - 7.0
Node version - 8.11.3
Npm version - 5.6.0
SDK version - 2.2.0

Thanks.

_Originally posted by @kuljeetsingh31 in https://github.com/mean-expert-official/loopback-sdk-builder/issue_comments#issuecomment-450514522_",,60712558
991,What version of rxjs should I use in my Angular 4 client,open,2018-12-17T16:42:15Z,2019-01-26T21:19:56Z,,NONE,"#### What type of issue are you creating?
- [x  ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x ] 2.3.1

Write other if any:

#### Please add a description for your issue:

I'm upgrading from an old version of the builder     ""@mean-expert/loopback-sdk-builder"": ""2.1.0-rc.9"",
to 2.3.1 (the current version)

In my angular 4 client, I've been using rxjs 5.4.3, but I get errors like: 
datasdk/services/core/error.service.ts (4,22): Module '""/node_modules/rxjs/Rx""' has no exported member 'throwError'

I've tried the latest rxjs releases from 6 up, but can't seem to find one that builds.

Any suggestions? Is this in the docs somewhere and I missed it?","when compile with webpack , rxjs 6.3
```
TypeError: (0 , _rxjs.from)(...).map is not a function
    at MemberApi.request (base.service.js:146)

```
for this code : 
```
 return from(request)
        .map((res) => res.data)
        .catch((e) => errorHandler.handleError(e));
```

i have this line but it seems not working 
`import { mergeMap, delay, map, catchError } from 'rxjs/operators';
`",60712558
992,Are there plans to support Loopback 4?,open,2018-11-02T11:55:54Z,2019-11-01T14:22:48Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [ x] Question

#### What version of this module are you using?
- [x ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Are there any plans to support Loopback 4?",Another [example](https://github.com/joschne/loopback4-example-ngx-sdk) based on looback 4 todo-list,60712558
993,Why aren't custom filters getting pick up in loopback?,open,2018-10-16T22:51:37Z,2018-11-15T08:19:56Z,,NONE,"#### What type of issue are you creating?
- [X ] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X ] Other (2.3.1)

Write other if any:

I've added a mixin to my loopback instance that handles a custom parameter in the filter object. However, it's not getting picked up from the Angular client. I've noticed the filter params are passed in the headers instead of a string in the query url--i'm guessing this has something to do with the reason it isn't working, but I'm kind of at a loss here. Any suggestions?","@jonathanwoahn Change your remote method prefix `find`  to something else, such as  `get`",60712558
994,IO Service - What is ME:RT:1://event ?,open,2018-10-08T16:28:45Z,2018-10-08T16:28:45Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [x] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Hi,

I try to use Realtime interface which use IO Service...  in which we have 2 functions

```
  emit(event: string, data: any): void {
    this.socket.emit('ME:RT:1://event', {
        event : event,
        data  : data
    });
  }

  on(event: string): Observable<any> {
    if (this.observables[event]) { return this.observables[event]; }
    let subject: Subject<any> = new Subject<any>();
    this.socket.on(event, (res: any) => subject.next(res));
    this.observables[event] = subject.asObservable();
    return this.observables[event];
  }
```

for ""on"", ok . I can got emit from the server, but to emit to the server it's not working like IO Socket usually work  this.socket.emit('event', 'data')... 
If I change this function to 

```
  emit(event: string, data: any): void {
    this.socket.emit(event, data);
  }
```
it will work again... But each time I will regenerate the SDK, it will be back.. I would like understand this function. Why it not work like usually emit ? What is ""'ME:RT:1://event',"" ?

Thank's

Mike",,60712558
995,Realtime ? What the good way ? ,open,2018-10-04T16:00:23Z,2018-10-04T16:00:23Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x ] Question

#### What version of this module are you using?
- [ x] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Hi,

I'm looking for a solution to use the API generated to provide realtime data... 
For now, the only way that it work for me has been to use createChangeStream() and unscubscibe/subscribe again to update my data, but I think it's not the good way to do as it seem the connexion expire fast and I got some error after some time. 

![sans-titre-1](https://user-images.githubusercontent.com/24215428/46486632-79918280-c7fe-11e8-8422-eb1e27fc273c.jpg)


I try to follow the example https://github.com/mean-expert-official/loopback-sdk-builder/wiki/5.-Usage-Examples

But without success..  there is nothing about ""onCreateMessages"" function in my generated API. This example is up to date ? 

I see also [Fireloop](https://github.com/mean-expert-official/loopback-sdk-builder/wiki/8.-FireLoop-API)

This is the solution ? But the link to the documentation do not work... [http://docs.fireloop.io/](http://docs.fireloop.io/)

There is not a simple way to use the services generated as realtime service ?

Someone can provide an simple example from a service generated by this component ? 

Any help is welcome

Mike
",,60712558
996,Question:,open,2018-10-01T14:16:47Z,2018-10-01T14:16:47Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Hello,
On my Category model, I have the following relation:
`   
""subscriptions"": {
      ""type"": ""hasMany"",
      ""model"": ""Subscription"",
      ""foreignKey"": """",
      ""options"": {
        ""nestRemoting"": true
      }
    }
  },`

How could I get the Count() result when running: 

`this.userService.getCategories(this.currentUser.id, {include: {relation: 'subscriptions', scope: {type: 'count'}}} )
            .subscribe((data: any[]) => {
                this.categories = data;
`
I would like to count the number of subscription when getting the categories belonging to the user, in the same observable().

Thanks for any help.",,60712558
997,fix: read property error of undefined when DOMException occured,open,2018-09-29T07:54:27Z,2018-09-29T07:54:27Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any:

#### Please add a description for your issue:

I passed a wrong baseUrl to config accidently

```
const baseUrl = window.location.host;
LoopBackConfig.setBaseUrl(baseUrl);
```

when I call api, an DOMException error occured, and report the error as title.
The DOMException error message is 
```
DOMException: Failed to execute 'open' on 'XMLHttpRequest': Invalid URL
```

Related code:
[LINK](https://github.com/mean-expert-official/loopback-sdk-builder/blob/d3041e443ed9683a96dbbbb4330e9f8d632f81a3/lib/angular2/shared/services/core/error.ejs#L11)

we should make sure `errorResponse.error` exists, PTAL",,60712558
998,fixed missing type information on related models,open,2018-09-27T18:38:11Z,2019-04-30T10:26:11Z,,NONE,"#### What type of pull request are you creating?
- [x ] Bug Fix
- [ ] Enhancement
- [ ] Documentation

#### How many unit test did you write for this pull request?
zero. small fix that runs without any problems on my big project.

#### Please add a description for your pull request:
**Issue**
Related models will not be typed (i.e. get the type `any` or `any[]`) if they do not appear in a scope method (like `__get__related_model""). This leads to a lot of missing type information if you have a clean rest api, where you only expose a few remote methods but not the whole bunch of methods exposed by default.

**Solution**
This Pull Request adds the type information about the related model to the model description. 
",Additionally I added a '?' to optional class properties in order to support this feature [introduced with TypeScript 2](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-0.html#optional-class-properties) ,60712558
999,a generic question,open,2018-09-23T16:27:43Z,2018-09-23T16:27:43Z,,NONE,"- [X] Question
- [X] 2.1.0-rc.n (2.1 Release Candidate n)

in the base service class , the methods are defined with a generic parameter as such :
    export abstract class BaseLoopBackApi {
    ...snip...
    public onUpdateAll<T>(where: any = {}, data: T): Observable<{ count: 'number' }> {
    ...snip...

does anyone have an idea why ? Wouldn't defining `<T>` on the class itself have the same effect ?

ie

    export abstract class BaseLoopBackApi<T> 

and then remove all the <T> definitions on the methods ... 


    export abstract class BaseLoopBackApi<T> {
    ...snip...
    public onUpdateAll(where: any = {}, data: T): Observable<{ count: 'number' }> {
    ...snip...

I may be missing something obvious, so I thought I'd ask
",,60712558
1000,Update index.ejs,open,2018-09-21T10:11:17Z,2018-09-21T10:11:17Z,,NONE,"#### What type of pull request are you creating?
- [ x] Bug Fix
- [ ] Enhancement
- [ ] Documentation

#### How many unit test did you write for this pull request?

HttpModule -> HttpClientModule

Write a reason if none (e.g just fixed a typo):

Updated HttpModule to HttpClientModule

#### Please add a description for your pull request:

When generating SDKNodeModule using lb-sdk -d ng2universal - the HttpModule is not found as it has been deprecated in favour of HttpClientModule.
",,60712558
1001,Add support for calling lb-sdk from electron default app,open,2018-09-13T15:55:22Z,2018-09-13T21:37:45Z,,NONE,"#### What type of pull request are you creating?
- [ ] Bug Fix
- [X ] Enhancement
- [ ] Documentation

#### How many unit test did you write for this pull request?
None

Write a reason if none (e.g just fixed a typo):
Tests already in place should suffice.

#### Please add a description for your pull request:

See associated issue #618",,60712558
1002,Electron default app support,open,2018-09-13T15:55:02Z,2018-09-13T15:55:02Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [X ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X ] Other

Write other if any:
2.3.1
#### Please add a description for your issue:

Running loopback inside main process of electron.  In pursuit of that, I would like to run this script in electron's default app so that I may fully integrate the server into an electron user interface.  This may be ill-advised I understand, but there you have it.

Essentially, I want to:
```
electron --require ./node_modules/ts-node/register ./node_modules/@mean-expert/loopback-sdk-builder/bin/lb-sdk <electron entry point> <sdk location> <options>
```
The only real roadblock that I see is that, when running as an argument to electron's default app, the argv._ array has an extra entry at the beginning. See [here](https://github.com/electron/electron/issues/4690#issuecomment-192775451) for a better description of that phenomenon.

I have committed a PR adding support by looking for presence of the process.defaultApp variable and taking the second argument in argv._ accordingly as the script target.",,60712558
1003,Remote method parameter defaults.,open,2018-09-13T09:37:18Z,2018-09-13T10:25:32Z,,NONE,"#### What type of pull request are you creating?
- [X] Bug Fix
- [ ] Enhancement
- [ ] Documentation

#### How many unit test did you write for this pull request?
0

Write a reason if none (e.g just fixed a typo):
Just fixed a small default problem (numbers, strings etc defaulted to a object)

#### Please add a description for your pull request:
My pull requests sets defaults for parameters in remote methods which have a default defined. Right now it just generates an object for any type.","I added a commit that does not default parameters if they are not required. I don't expect empty ""objects"" on my back-end if I don't require the parameter.",60712558
1004,Deprecation Warning,open,2018-08-29T10:04:28Z,2018-08-29T10:04:28Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
Hello,
I am using PatchOrCreate method like `this.souscriptionApi.patchOrCreate(this.subscr).subscribe();`
where this.subscr is an object of subscription type.

When inserting the row (insertion is ok in the database), I am getting this message : 
**(node:13177) DeprecationWarning: collection.insert is deprecated. Use insertOne, insertMany or bulkWrite instead.**

Issue seems to be known: 
https://github.com/strongloop/loopback-connector-mongodb/issues/455",,60712558
1005,Question : warnings when generating sdk,open,2018-08-27T09:29:39Z,2018-08-27T09:38:57Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
If I do not expose USER to REST, like recommended by Loopback, why do I receive the warnings : 

WARNING in ./src/app/shared/auth.guard.ts
29:69-76 ""export 'UserApi' was not found in './sdk/services'

WARNING in ./src/app/shared/auth.guard.ts
29:96-103 ""export 'UserApi' was not found in './sdk/services'

Maybe is it another issue ?

Thanks and Regards,","Also if I set in model-config.json: 

""User"": {
    ""dataSource"": ""database"",
    ""public"": **true**
  },

no more warning and also, the app is working fine.
That means that having User public set to true is mandatory ....",60712558
1006,Update WIKI and add NgRx tutorial,open,2018-08-06T14:14:44Z,2018-10-04T10:03:22Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ x] Enhancement
- [ ] Question

#### What version of this module are you using?
- [x ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
I just noticed that the WIKI is quite outdated. I did not even know I can build ngrx stuff with sdk. Kindly update the WIKI and provide a brief tutorial to use the generated ngrx in app.","@jmls Actually no. I had to go through the code and customize it according to my needs specifically NgRx and I think those were required features e.g 
1 - If you want your store to use primary key other than ""id"" i.e slug, there was no option for that.
2 -  There was no implementation to exclude models e.g You dont want some specific models to include in sdk because they are for backend only.
3 - If you have multiple User models then the sdk used the first model to authenticate but I changed it and now you can specify which model to use to authenticate.
4 - Model isProcessing, isProcessingSuccess, isProcessingFail, isProcessingResponse, isProcessingError implementations so you can show loaders after dispatching actions.
",60712558
1007,SDKNodeModule not found while generating ng2universal sdk,open,2018-08-06T14:10:51Z,2018-08-06T14:13:14Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [x] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
The wiki says to add SDKNodeModule  too in case of Angular Universal but I've tried generating sdk using both ng2web and ng2universal flags. SDKNodeModule does not gets generated.",,60712558
1008,Problem on generating services for Rest Connector?,open,2018-08-01T11:27:33Z,2018-08-04T16:00:18Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X] Other: 2.3.1

Write other if any:
2.3.1 as using angular 6.0.3
#### Please add a description for your issue:
I have a server side model like:
`
{
  ""name"": ""etablissement"",
  ""plural"": ""etablissements"",
  ""base"": ""Model"",
  ""idInjection"": true,
  ""options"": {
    ""validateUpsert"": true
  },
  ""properties"": {},
  ""validations"": [],
  ""relations"": {},
  ""acls"": [],
  ""methods"": {}
}`

- model-config.json:

`
 ""etablissement"": {
    ""dataSource"": ""etablissementREST"",
    ""public"": true
  },`

- datasource.json:

`
  ""etablissementREST"": {
    ""name"": ""etablissementREST"",
    ""crud"": false,
    ""connector"": ""rest"",
    ""debug"": false,
    ""options"": {
      ""headers"": {
        ""accept"": ""application/json"",
        ""content-type"": ""application/json""
      },
      ""strictSSL"": false
    },
    ""operations"": [
      {
        ""template"": {
          ""method"": ""GET"",
          ""url"": ""https://data.education.gouv.fr/api/records/1.0/search/?dataset=fr-en-adresse-et-geolocalisation-etablissements-premier-et-second-degre"",
          ""query"": {
            ""dataset"": ""{dataset}""
          },
          ""options"": {
            ""strictSSL"": true,
            ""useQuerystring"": true
          },
          ""responsePath"": ""$.records.*""
        },
        ""functions"": {
          ""/"": []
        }
      }
    ]
  }`

and when I use my ng serve, I am getting a lot of error (Only on this model):

`
ERROR in src/app/shared/sdk/services/custom/Etablissement.ts(46,10): error T
S1005: ';' expected.
src/app/shared/sdk/services/custom/Etablissement.ts(46,11): error TS1161: Un
terminated regular expression literal.
src/app/shared/sdk/services/custom/Etablissement.ts(55,3): error TS1128: Dec
laration or statement expected.
src/app/shared/sdk/services/custom/Etablissement.ts(72,3): error TS1128: Dec
laration or statement expected.
src/app/shared/sdk/services/custom/Etablissement.ts(72,24): error TS1005: ',
' expected.
src/app/shared/sdk/services/custom/Etablissement.ts(72,50): error TS1109: Ex
pression expected.
src/app/shared/sdk/services/custom/Etablissement.ts(72,61): error TS1005: ';
' expected.
src/app/shared/sdk/services/custom/Etablissement.ts(73,9): error TS1005: ':'
 expected.
src/app/shared/sdk/services/custom/Etablissement.ts(73,16): error TS1005: ',
' expected.
src/app/shared/sdk/services/custom/Etablissement.ts(73,33): error TS1005: ',
' expected.
src/app/shared/sdk/services/custom/Etablissement.ts(74,9): error TS1005: ':'
 expected.
src/app/shared/sdk/services/custom/Etablissement.ts(74,13): error TS1005: ',
`

- The loopback explorer is working fine.

- Here is the generated faulty?? Etablissement.ts:

`
  public invoke(request: any = {}, customHeaders?: Function): Observable<any> {
    let _method: string = ""POST"";
    let _url: string = LoopBackConfig.getPath() + ""/"" + LoopBackConfig.getApiVersion() +
    ""/etablissements/invoke"";
    let _routeParams: any = {};
    let _postBody: any = {
      request: request
    };
    let _urlParams: any = {};
    let result = this.request(_method, _url, _routeParams, _urlParams, _postBody, null, customHeaders);
    return result;
  }

  /**
   * The name of the model represented by this $resource,
   * i.e. `Etablissement`.
   */
  public getModelName() {
    return ""Etablissement"";
  }
}`

Any idea ?? 

Thanks to all.","Just retried the SDK generation...
It mainly adds a / like here: 
public **/**(dataset: any = {}, q: any = {}, customHeaders?: Function): Observable<any> {

I do not think it grabs a comment or something else as all is ok server side.

Hope this helps.",60712558
1009,Instance Methods,open,2018-07-20T22:44:31Z,2018-07-20T22:45:26Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:


Theres is some instance methods integrated ? 
Like as we do something like 

`this.userApi.findById(1).subscribe((user : User)=>user.updateAttributes({ name : 'test', age : 20}).subscribe(res=>console.log(res),err=>console.log(err))`


?",,60712558
1010,lb-wsdk does not generate class and interface for embedsOne and embedsMany relation,open,2018-07-06T03:45:43Z,2018-07-09T15:54:41Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug

#### What version of this module are you using?
- [ ] Other
2.3.1

Write other if any:

#### Please add a description for your issue:

I am using     ""@mean-expert/loopback-sdk-builder"": ""^2.3.1"",
to generate sdk. for loopback3.0 project

I have a model which has beloe embeded relation  in a parent model.
""eventInfo"": {
      ""type"": ""embedsOne"",
      ""model"": ""EventInfo"",
      ""property"": ""eventInfo"",
      ""options"": {
        ""validate"": true,
        ""forceId"": false
      }
    },

the lb-sdk generates .ts file (class and interface definition)  for parent model, but does not generate .ts file for this embeded relation
","Hi @haresh333, that is not really a bug but a feature request, embedded objects are not supported.

If you believe you are able to extend the SDK and implement embedded objects the community would appreciate it.",60712558
1011,generated api issue,open,2018-06-29T06:49:35Z,2018-07-12T08:28:00Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [ X] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X ] Other

Write other if any:

I have a model called category and another model called Type, the category belongTo a Type.
I wanted to query the categories of a certain type.
The generated sdk have the following api:

 /**
   * Queries categories of Type.
   *
   * @param {any} id Category id
   *
   * @param {object} filter 
   *
   * @returns {object[]} An empty reference that will be
   *   populated with the actual data once the response is returned
   *   from the server.
   *
   * <em>
   * (The remote method definition does not provide any description.
   * This usually means the response is a `Category` object.)
   * </em>
   */
  public getTypeCategories(id: any, filter: LoopBackFilter = {}, customHeaders?: Function): Observable<any> {
    let _method: string = ""GET"";
    let _url: string = LoopBackConfig.getPath() + ""/"" + LoopBackConfig.getApiVersion() +
    ""/Categories/:id/type/categories"";
    let _routeParams: any = {
      id: id
    };
    let _postBody: any = {};
    let _urlParams: any = {};
    if (typeof filter !== 'undefined' && filter !== null) _urlParams.filter = filter;
    let result = this.request(_method, _url, _routeParams, _urlParams, _postBody, null, customHeaders);
    return result;
  }  

This api, which what I need, ask for a categoryId  which doesn't make sense, like how this api is supposed to query the categories of certain type as it says ""Queries categories of Type."" and it asks for a categoyId","If the Type is public, then there should be an endpoint (and a generated function) for /type/:typeId/categories.

Please check your explorer API first.",60712558
1012,hydrate an object by ignoring the extra field,open,2018-06-21T18:44:10Z,2018-06-21T18:44:42Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [x] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Hello,

I would like to know if there is a simple technique to hydrate a model to send it to the API without taking into account the additional fields.

I'm not a fan of the technique of creating a temporary object or removing elements from a form to send to the API such as:

```
const user: User = {
       username: this.registerForm.value.userName,
       lastname: this.registerForm.value.userName
};
```

or

`delete this.registerForm.value.confirmPassword`


So I wonder if there will be a technique to hydrate an object without taking into account the elements that are not present in the basic object.

Thank you for your answers.",,60712558
1013,error occured when i build angular module with loopback sdk,open,2018-06-18T06:38:57Z,2018-06-18T06:39:07Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [x] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any:
`2.2.7`
#### Please add a description for your issue:

i have an error when i build angular module include loopback sdk
```
Cannot call a namespace ('io')
Error: Cannot call a namespace ('io')
    at error (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:199:15)
    at Module.error (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:17170:9)
    at CallExpression.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:14725:30)
    at ReturnStatement.NodeBase.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:13499:23)
    at BlockStatement$$1.NodeBase.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:13495:31)
    at FunctionExpression.NodeBase.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:13499:23)
    at MethodDefinition.NodeBase.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:13499:23)
    at ClassBody.NodeBase.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:13495:31)
    at ClassDeclaration$$1.NodeBase.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:13499:23)
    at ExportNamedDeclaration.bind (/home/kms/dev/m2u/admin-web/web/node_modules/rollup/dist/rollup.js:15060:30)
```

this is error occur from `import * as io from 'socket.io-client';` in `socket.browser.ts` 

and this error not appear when i change  `socket.browser.ts` 
 ```
import * as io from 'socket.io-client';
``` 
to 
```
import * as ioImported from 'socket.io-client';
const io = ioImported;
```

If you think this is ok
please merge this commit 
",,60712558
1014,Some fixes for react native,open,2018-06-14T16:36:54Z,2019-02-07T20:56:01Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [x] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ x ] Other

Write other if any:
    ""@mean-expert/loopback-sdk-builder"": ""^2.3.1"",

#### Please add a description for your issue:
I was building this for react native and found some issues and seemed to have fixed them:
base.service.js

`if (postBodyKeys.length === 1) {
        body = postBody[postBodyKeys.shift()];
      } else if(postBodyKeys.length> 1) {
        body = postBody;
      }
      else{
        body=undefined;
      }`
instead of:
`      if (postBodyKeys.length === 1) {
        body = postBody[postBodyKeys.shift()];
      } else if(postBodyKeys.length> 1) {
        body = postBody;
      }`

because it was making the body ""{}"" instead of undefined which broke the get requests

moved the 'from' **from import { Observable, from, Subject } from 'rxjs'** to:
`import { from } from 'rxjs/observable/from';`
Because it wasn't getting the dependency for some reason

import {  _throw } from 'rxjs/observable/throw';
    return _throw(error || 'Server error');

instead of throwError in the error.service.js
","you can check my fork, i made some fixes , but bugs still remains ...",60712558
1015,Image links are broken,open,2018-06-14T15:39:41Z,2018-06-14T15:45:12Z,,NONE,Image links in the wiki are broken,,60712558
1016,Error when running  npm run build:sdk,open,2018-06-08T11:54:51Z,2018-07-09T16:59:51Z,,NONE,"**ERROR in src/app/shared/sdk/models/FireLoopRef.ts(2,10): error TS2305: Module '""
D:/DFI Build/dfi/DFIBuild/Application/DFI_Angular/node_modules/rxjs/Rx""' has no
exported member 'merge'.
src/app/shared/sdk/services/core/error.service.ts(4,22): error TS2305: Module '""
D:/DFI Build/dfi/DFIBuild/Application/DFI_Angular/node_modules/rxjs/Rx""' has no
exported member 'throwError'.**",Thanks!,60712558
1017,Missing types on remote methods,open,2018-06-01T19:37:12Z,2019-04-04T01:45:13Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [ * ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ * ] Other

Write other if any: 2.3.1

#### Please add a description for your issue:
I have tried several but did not succeed on getting the right types build from the SDK for remote methods.
The way I declare them is like this:
```javascript
User.remoteMethod(""getBook"", {
    accepts: [{ arg: ""options"", type: ""object"", http: ""optionsFromRequest"" }],
    returns: { arg: ""data"", type: ""Book"", root: true, description:""BusinessService"" },
    http: { path: ""/getBook"", verb: ""post"" }
  });
```
But the result never has the type Book, it is always type `any`
```javascript
public updateLastSeen(customHeaders?: Function): Observable<any> {
```
When the expected result should be:
```javascript
public updateLastSeen(customHeaders?: Function): Observable<Book> {
```
And similar behavior for arrays.

This is kind of similar to [331](https://github.com/mean-expert-official/loopback-sdk-builder/issues/311) and [475](https://github.com/mean-expert-official/loopback-sdk-builder/issues/475) but I could not get find my answer there.

After looking at it for a while I notice in `./loopback-sdk-builder/lib/angular2/index.js`
```
function buildObservableType(model, method) {
    let type = 'any';
    if (
      method.name.match(/(^createMany$|^find)/g) ||
      (
        typeof method.returns === 'object' &&
        (String(method.returns.type).toLowerCase() === 'array' || Array.isArray(method.returns.type))
      )
    ) type = `${model.name}[]`;
    if (method.name.match(/(^create$|upsert|^findBy|^findOne$)/g)) type = model.name;
    return type;
  }
```
Only adds the type for certain methods.

Is there something I am doing wrong when I defined the remote methods? If so why does it happens too that the return type is any when you have a relation for example User model has many Something, and then try to access the related model (Something) from the user.","Since there might be some imports needed depending on the return type, function `buildServiceImports` needs to be updated as well.
Here is a final copy of my `./loopback-sdk-builder/lib/angular2/index.js` in case it helps anyone:

```javascript

/**
 * @module Angular 2 Generator for loopback-sdk-builder
 * @author Jonathan Casarrubias <@johncasarrubias> <github:jonathan-casarrubias>
 * @license MIT
 * @description
 * Defines a SDK Schema and builds according configuration
 */
var fs = require('fs');
var path = require('path');
var mkdirp = require('mkdirp');
var rmdir = require('rimraf');
var ejs = require('ejs');
var utils = require('../utils');
var _ = require('underscore');
_.mixin(require('underscore.inflections'));
/**
 * EJS Q Filter
 * Deprecated in EJS 2 :(
 */
ejs.filters.q = obj => JSON.stringify(obj, null, 2);
ejs.filters.pluralize = text => _.pluralize(text);
/**
 * Generate Client SDK for the given loopback application.
 */
module.exports = function generate(ctx) {
	'use strict';
	// Describe models and remove those blacklisted
	ctx.models = utils.describeModels(ctx.app);
	/**
	 * Directory Management
	 */
	ctx.outputFolder = path.resolve(ctx.outputFolder);

	if (!ctx.quiet) {
		console.log('Removing base directory %s', ctx.outputFolder);
	}

	rmdir.sync(ctx.outputFolder);
	// Create required directories
	let directories = [
		ctx.outputFolder,
		ctx.outputFolder + '/models',
		ctx.outputFolder + '/services/core',
		ctx.outputFolder + '/services/custom',
		ctx.outputFolder + '/storage'
	];
	if (ctx.isIo === 'enabled') directories.push(ctx.outputFolder + '/sockets');
	if (ctx.isNgrx === 'enabled' || ctx.isNgrx === 'orm') {
		directories.push(ctx.outputFolder + '/actions');
		directories.push(ctx.outputFolder + '/effects');
		directories.push(ctx.outputFolder + '/guards');
		directories.push(ctx.outputFolder + '/reducers');
		directories.push(ctx.outputFolder + '/resolvers');
	}
	if (ctx.isNgrx === 'orm') {
		directories.push(ctx.outputFolder + '/orm');
		directories.push(ctx.outputFolder + '/orm/models');
	}
	directories.forEach(directory => mkdirp.sync(directory));
	/**
	 * Fix to decide which AcccessToken to get, since usually is private, but not
	 * Always, so  we need to import from the right place
	 */
	ctx.loadAccessToken = ctx.models.AccessToken ? false : true;

	if (!ctx.quiet) {
		console.log('DRIVER: ', ctx.driver);
	}

	const throughModels = {};
	if (ctx.isNgrx === 'orm') {
		Object.keys(ctx.models).forEach(modelName => {
			for (const rel in ctx.models[modelName].sharedClass.ctor.relations) {
				if (
					ctx.models[modelName].sharedClass.ctor.relations[rel].modelThrough
				) {
					const throughModel =
						ctx.models[modelName].sharedClass.ctor.relations[rel].modelThrough
							.definition.name;
					if (
						typeof ctx.models[throughModel] === 'undefined' &&
						!throughModels.hasOwnProperty(throughModel)
					) {
						throughModels[throughModel] = {
							from: modelName,
							to:
								ctx.models[modelName].sharedClass.ctor.relations[rel]
									.targetClass
						};
					}
				}
			}
		});
	}

	/**
	 * LoopBack SDK Builder Schema for Angular 2 and ng2native 2
	 **/
	let schema = [
		/**
		 * SDK INDEXES
		 */
		{
			template: './shared/index.ejs',
			output: '/index.ts',
			params: {
				isIo: ctx.isIo,
				isNgrx: ctx.isNgrx,
				models: ctx.models,
				driver: ctx.driver,
				buildModuleImports,
				buildNgModuleImports,
				buildNgProviders
			}
		},
		{
			template: './shared/models/index.ejs',
			output: '/models/index.ts',
			params: {
				isIo: ctx.isIo,
				models: Object.assign({}, ctx.models, throughModels)
			}
		},
		{
			template: './shared/services/index.ejs',
			output: '/services/index.ts',
			params: {}
		},
		{
			template: './shared/services/custom/index.ejs',
			output: '/services/custom/index.ts',
			params: { models: ctx.models }
		},
		{
			template: './shared/services/core/index.ejs',
			output: '/services/core/index.ts',
			params: { isIo: ctx.isIo }
		},
		/**
		 * MODEL LIST SERVICES
		 */
		{
			template: './shared/services/custom/models.ejs',
			output: '/services/custom/SDKModels.ts',
			params: { models: ctx.models }
		},
		/**
		 * SDK CONFIG
		 */
		{
			template: './shared/config.ejs',
			output: '/lb.config.ts',
			params: { app: ctx.app }
		},
		/**
		 * SDK STATIC BASE AND CORE FILES
		 */
		{
			template: './shared/models/base.ejs',
			output: '/models/BaseModels.ts',
			params: {
				loadAccessToken: ctx.loadAccessToken,
				isNgrx: ctx.isNgrx,
				buildServiceDI
			}
		},
		{
			template: './shared/services/core/auth.ts',
			output: '/services/core/auth.service.ts',
			params: { loadAccessToken: ctx.loadAccessToken }
		},
		{
			template: './shared/services/core/base.ejs',
			output: '/services/core/base.service.ts',
			params: {
				isIo: ctx.isIo,
				buildServiceDI,
				buildBaseServiceImports
			}
		},
		{
			template: './shared/services/core/error.ejs',
			output: '/services/core/error.service.ts',
			params: {}
		},
		{
			template: './shared/services/core/logger.ejs',
			output: '/services/custom/logger.service.ts',
			params: {}
		},
		/**
		 * STORAGE
		 */
		{
			template: './shared/storage/storage.swaps.ts',
			output: '/storage/storage.swaps.ts',
			params: {}
		}
	];
	// Add Browser Specific Code
	if (ctx.driver.match(/ng2web|ng2universal/)) {
		schema.push({
			template: './shared/storage/cookie.browser.ts',
			output: '/storage/cookie.browser.ts',
			params: {}
		});
		schema.push({
			template: './shared/storage/storage.browser.ts',
			output: '/storage/storage.browser.ts',
			params: {}
		});
	}
	// Add Server Specific Code
	if (ctx.driver === 'ng2universal') {
		schema.push({
			template: './shared/storage/cookie.node.ts',
			output: '/storage/cookie.node.ts',
			params: {}
		});
	}
	// Add NativeScript Specific Code
	if (ctx.driver === 'ng2native') {
		schema.push({
			template: './shared/storage/storage.native.ts',
			output: '/storage/storage.native.ts',
			params: {}
		});
	}
	/**
	 * NGRX SUPPORT
	 */
	if (ctx.isNgrx === 'enabled' || ctx.isNgrx === 'orm') {
		schema = schema.concat([
			/**
			 * NGRX Utils
			 */
			{
				template: './shared/state.ejs',
				output: '/state.ts',
				params: { models: ctx.models, throughModels }
			},
			{
				template: './shared/util.ejs',
				output: '/util.ts',
				params: {}
			},
			/**
			 * NGRX Actions
			 */
			{
				template: './shared/actions/auth.ejs',
				output: '/actions/auth.ts',
				params: {}
			},
			{
				template: './shared/actions/base.ejs',
				output: '/actions/base.ts',
				params: {}
			},
			{
				template: './shared/actions/error.ejs',
				output: '/actions/error.ts',
				params: {}
			},
			{
				template: './shared/actions/index.ejs',
				output: '/actions/index.ts',
				params: { models: Object.assign({}, ctx.models, throughModels) }
			},
			/**
			 * NGRX Effects
			 */
			{
				template: './shared/effects/auth.ejs',
				output: '/effects/auth.ts',
				params: {
					userModelName: getUserModelName()
				}
			},
			{
				template: './shared/effects/base.ejs',
				output: '/effects/base.ts',
				params: {}
			},
			{
				template: './shared/effects/resolver.ejs',
				output: '/effects/resolver.ts',
				params: {}
			},
			/**
			 * NGRX Guards
			 */
			{
				template: './shared/guards/index.ejs',
				output: '/guards/index.ts',
				params: { models: ctx.models }
			},
			{
				template: './shared/guards/auth.guard.ejs',
				output: '/guards/auth.guard.ts',
				params: {}
			},
			/**
			 * NGRX Reducers
			 */
			{
				template: './shared/reducers/auth.ejs',
				output: '/reducers/auth.ts',
				params: {
					userModelName: getUserModelName()
				}
			},
			{
				template: './shared/reducers/index.ejs',
				output: '/reducers/index.ts',
				params: {
					models: Object.assign({}, ctx.models, throughModels),
					isNgrx: ctx.isNgrx
				}
			},
			{
				template: './shared/reducers/base.ejs',
				output: '/reducers/base.ts',
				params: {}
			},
			{
				template: './shared/reducers/baseThrough.ejs',
				output: '/reducers/baseThrough.ts',
				params: {}
			},
			/**
			 * NGRX Resolvers
			 */
			{
				template: './shared/resolvers/auth-account.ejs',
				output: '/resolvers/auth-account.ts',
				params: {
					userModelName: getUserModelName()
				}
			},
			{
				template: './shared/resolvers/index.ejs',
				output: '/resolvers/index.ts',
				params: {}
			}
		]);
	}
	if (ctx.isNgrx === 'orm') {
		/**
		 * NGRX Orm
		 */
		schema = schema.concat([
			{
				template: './shared/orm/orm.ejs',
				output: '/orm/orm.ts',
				params: {
					isIo: ctx.isIo,
					models: ctx.models
				}
			},
			{
				template: './shared/orm/filter.ejs',
				output: '/orm/filter.ts',
				params: {}
			},
			{
				template: './shared/orm/base.ejs',
				output: '/orm/base.ts',
				params: { isIo: ctx.isIo }
			},
			{
				template: './shared/orm/index.ejs',
				output: '/orm/index.ts',
				params: {}
			},
			{
				template: './shared/orm/models/index.ejs',
				output: '/orm/models/index.ts',
				params: { models: ctx.models }
			}
		]);
	}
	if (ctx.isNgrx === 'orm' && ctx.isIo === 'enabled') {
		schema = schema.concat([
			{
				template: './shared/orm/io.ejs',
				output: '/orm/io.ts',
				params: {}
			}
		]);
	}
	/**
	 * REALTIME MODULE SUPPORT
	 */
	if (ctx.isIo === 'enabled') {
		// Add generic code to any environment
		schema = schema.concat([
			{
				template: './shared/sockets/connections.ts',
				output: '/sockets/socket.connections.ts',
				params: {}
			},
			{
				template: './shared/sockets/socket.driver.ts',
				output: '/sockets/socket.driver.ts',
				params: {}
			},
			{
				template: './shared/services/core/io.ejs',
				output: '/services/core/io.service.ts',
				params: {}
			},
			{
				template: './shared/services/core/realtime.ts',
				output: '/services/core/real.time.ts',
				params: {}
			},
			{
				template: './shared/models/fireloop.ejs',
				output: '/models/FireLoop.ts',
				params: {}
			},
			{
				template: './shared/models/flref.ts',
				output: '/models/FireLoopRef.ts',
				params: {}
			}
		]);
		// Add Browser Specific Code
		if (ctx.driver.match(/ng2web|ng2universal/)) {
			schema.push({
				template: './shared/sockets/socket.browser.ts',
				output: '/sockets/socket.browser.ts',
				params: {}
			});
		}
		// Add Server Specific Code
		if (ctx.driver === 'ng2universal') {
			schema.push({
				template: './shared/sockets/socket.node.ts',
				output: '/sockets/socket.node.ts',
				params: {}
			});
		}
		// Add NativeScript Specific Code
		if (ctx.driver === 'ng2native') {
			schema.push({
				template: './shared/sockets/socket.native.ts',
				output: '/sockets/socket.native.ts',
				params: {}
			});
		}
	}
	/**
	 * SDK DYNAMIC FILES
	 */
	Object.keys(ctx.models).forEach(modelName => {
		if (
			ctx.models[modelName].sharedClass.ctor.settings.sdk &&
			!ctx.models[modelName].sharedClass.ctor.settings.sdk.enabled
		) {
			if (!ctx.quiet) {
				console.warn('LoopBack SDK Builder: %s model was ignored', modelName);
			}

			return;
		} else {
			if (!ctx.quiet) {
				console.info('LoopBack SDK Builder: adding %s model to SDK', modelName);
			}

			schema.push(
				/**
				 * SDK MODELS
				 */
				{
					template: './shared/models/model.ejs',
					output: '/models/' + capitalize(modelName) + '.ts',
					params: {
						model: ctx.models[modelName],
						modelName: modelName,
						plural:
							ctx.models[modelName].sharedClass.ctor.settings.plural ||
							ejs.filters.pluralize(modelName),
						path:
							ctx.models[modelName].sharedClass.ctor.settings.http &&
							ctx.models[modelName].sharedClass.ctor.settings.http.path
								? ctx.models[modelName].sharedClass.ctor.settings.http.path
								: ctx.models[modelName].sharedClass.ctor.settings.plural,
						buildPropertyType: buildPropertyType,
						buildPropertyDefaultValue: buildPropertyDefaultValue,
						buildRelationType: buildRelationType,
						buildModelImports,
						buildModelProperties,
						capitalize
					}
				}
			);
			/**
			 * SDK CUSTOM SERVICES
			 */
			if (
				ctx.fireloopOnly === 'disabled' ||
				ctx.models[modelName].sharedClass.ctor.settings.base === 'User'
			) {
				schema.push({
					template: './shared/services/custom/service.ejs',
					output: '/services/custom/' + capitalize(modelName) + '.ts',
					params: {
						isIo: ctx.isIo,
						model: ctx.models[modelName],
						modelName: modelName,
						moduleName: ctx.moduleName,
						loadAccessToken: ctx.loadAccessToken,
						buildPostBody,
						buildUrlParams,
						buildRouteParams,
						buildMethodParams,
						buildPayloadParams,
						buildServiceDI,
						buildServiceImports,
						normalizeMethodName,
						buildObservableType,
						paramIsContext,
						paramIsFunction
					}
				});
			}
			/**
			 * SDK NGRX ACTIONS, EFFECTS, REDUCERS, GUARDS, ORM
			 */
			if (ctx.isNgrx === 'enabled' || ctx.isNgrx === 'orm') {
				schema.push({
					template: './shared/actions/model.ejs',
					output: '/actions/' + capitalize(modelName) + '.ts',
					params: {
						isIo: ctx.isIo,
						model: ctx.models[modelName],
						modelName: modelName,
						moduleName: ctx.moduleName,
						loadAccessToken: ctx.loadAccessToken,
						buildUrlParams,
						buildRouteParams,
						buildMethodParams,
						buildPayloadParams,
						buildPayloadParamsWithoutTypes,
						buildServiceDI,
						buildServiceImports,
						normalizeMethodName,
						upperCasedMethodName,
						buildObservableType,
						paramIsContext,
						paramIsFunction
					}
				});
				schema.push({
					template: './shared/effects/model.ejs',
					output: '/effects/' + capitalize(modelName) + '.ts',
					params: {
						isIo: ctx.isIo,
						model: ctx.models[modelName],
						modelName: modelName,
						moduleName: ctx.moduleName,
						loadAccessToken: ctx.loadAccessToken,
						buildUrlParams,
						buildRouteParams,
						buildMethodParams,
						buildMethodParamsFromPayload,
						buildServiceDI,
						buildServiceImports,
						normalizeMethodName,
						upperCasedMethodName,
						buildObservableType,
						paramIsContext,
						paramIsFunction,
						capitalize
					}
				});
				schema.push({
					template: './shared/reducers/model.ejs',
					output: '/reducers/' + capitalize(modelName) + '.ts',
					params: {
						isIo: ctx.isIo,
						model: ctx.models[modelName],
						modelName: modelName,
						moduleName: ctx.moduleName,
						loadAccessToken: ctx.loadAccessToken,
						buildUrlParams,
						buildRouteParams,
						buildMethodParams,
						buildMethodParamsFromPayload,
						buildServiceDI,
						buildServiceImports,
						normalizeMethodName,
						upperCasedMethodName,
						buildObservableType,
						paramIsContext,
						paramIsFunction
					}
				});
				schema.push({
					template: './shared/guards/model.ejs',
					output: '/guards/' + capitalize(modelName) + '.ts',
					params: {
						modelName: modelName
					}
				});
			}

			if (ctx.isNgrx === 'orm') {
				schema.push({
					template: './shared/orm/models/model.ejs',
					output: '/orm/models/' + capitalize(modelName) + '.ts',
					params: {
						isIo: ctx.isIo,
						model: ctx.models[modelName],
						modelName: modelName,
						moduleName: ctx.moduleName,
						loadAccessToken: ctx.loadAccessToken,
						buildUrlParams,
						buildRouteParams,
						buildMethodParams,
						buildPayloadParams,
						buildPayloadParamsWithoutTypes,
						buildServiceDI,
						buildServiceImports,
						normalizeMethodName,
						upperCasedMethodName,
						buildObservableType,
						paramIsContext,
						paramIsFunction
					}
				});
			}
		}
	});
	/**
	 * THROUGH MODELS
	 */
	if (ctx.isNgrx === 'orm') {
		Object.keys(throughModels).forEach(modelName => {
			schema.push({
				template: './shared/models/throughModel.ejs',
				output: '/models/' + capitalize(modelName) + '.ts',
				params: {
					model: throughModels[modelName],
					modelName: modelName[0].toUpperCase() + modelName.slice(1)
				}
			});
			schema.push({
				template: './shared/actions/throughModel.ejs',
				output: '/actions/' + capitalize(modelName) + '.ts',
				params: {
					modelName: modelName[0].toUpperCase() + modelName.slice(1)
				}
			});
			schema.push({
				template: './shared/reducers/throughModel.ejs',
				output: '/reducers/' + capitalize(modelName) + '.ts',
				params: {
					modelName: modelName[0].toUpperCase() + modelName.slice(1)
				}
			});
		});
	}
	/**
	 * PROCESS SCHEMA
	 */
	schema.forEach(config => {
		if (!ctx.quiet) {
			console.info('Generating: %s', `${ctx.outputFolder}${config.output}`);
		}

		fs.writeFileSync(
			`${ctx.outputFolder}${config.output}`,
			ejs.render(
				fs.readFileSync(require.resolve(config.template), {
					encoding: 'utf-8'
				}),
				config.params
			)
		);
	});
	/**
	 * @method getUserModelName
	 * @description
	 * Discovers User model name
	 */
	function getUserModelName() {
		let userModelName = '';
		Object.keys(ctx.models).forEach(modelName => {
			if (
				ctx.models[modelName].sharedClass.ctor.settings.base === 'User' ||
				ctx.models[modelName].sharedClass.ctor.settings.base === 'OAuthUser'
			) {
				userModelName = modelName;
			}
		});
		return userModelName;
	}
	/**
	 * @method buildModelImports
	 * @description
	 * Define import statement for those model who are related to other scopes
	 */
	function buildModelImports(model) {
		let relations = getModelRelations(model);
		let loaded = {};
		let modelName = capitalize(model.name);
		loaded[modelName] = true;
		let output = [];
		if (relations.length > 0) {
			relations.forEach((relationName, i) => {
				let targetClass =
					model.sharedClass.ctor.relations[relationName].targetClass;
				if (!loaded[targetClass] && targetClass !== modelName) {
					loaded[targetClass] = true;
					output.push(`  ${targetClass}`);
				}
			});
		}
		// Add GeoPoint custom type import
		Object.keys(model.properties).forEach(property => {
			var geoPointType = buildPropertyType(model.properties[property]);
			var hasGeoPointType = geoPointType.indexOf('GeoPoint') !== -1;
			if (hasGeoPointType) {
				output.push('  GeoPoint');
			}
		});
		if (output.length > 0) {
			var imports = output.join(',\n');
			output = ['import {', imports, ""} from '../index';\n""];
		}
		return output.join('\n');
	}
	/**
	 * @method buildModelProperties
	 * @description
	 * Define properties for the given model
	 */
	function buildModelProperties(model, isInterface) {
		let output = [];
		// Work around to fix a LoopBack update that won't provide
		// the password property anymore but is required for TypeScript purposes
		if (model.isUser && !model.properties.password) {
			model.properties.password = {
				type: String
			};
		}
		// Add Model Properties
		Object.keys(model.properties).forEach(propertyName => {
			if (model.isUser && propertyName === 'credentials') return;
			let property = model.properties[propertyName];
			let isOptional = isInterface && !property.required ? '?' : '';
			let defaultValue = !isInterface
				? ` = ${buildPropertyDefaultValue(property)}`
				: '';
			defaultValue =
				ctx.defaultValue !== 'enabled' && ctx.defaultValue !== 'strict'
					? ''
					: defaultValue;
			defaultValue =
				ctx.defaultValue === 'strict' && !property.hasOwnProperty('default')
					? ''
					: defaultValue;
			output.push(
				`  ""${propertyName}""${isOptional}: ${buildPropertyType(
					property
				)}${defaultValue};`
			);
		});
		// Add Model Relations
		Object.keys(model.sharedClass.ctor.relations).forEach(relation => {
			let relationType = buildRelationType(model, relation);
			let defaultTypeValue =
				!isInterface &&
				ctx.defaultValue === 'enabled' &&
				relationType.indexOf('Array') >= 0
					? ' = []'
					: '';
			defaultTypeValue =
				!isInterface &&
				ctx.defaultValue === 'enabled' &&
				relationType.indexOf('Array') === -1
					? ' = null'
					: defaultTypeValue;
			output.push(
				`  ${relation}${
					isInterface ? '?' : ''
				}: ${relationType}${defaultTypeValue};`
			);
		});
		return output.join('\n');
	}
	/**
	 * @method buildRelationType
	 * @description
	 * Discovers property type according related models that are public
	 */
	function buildRelationType(model, relationName) {
		let relation = model.sharedClass.ctor.relations[relationName];
		let targetClass = relation.targetClass;
		let basicType = ctx.models[targetClass] ? targetClass : 'any';
		let finalType = relation.type.match(/(hasOne|belongsTo)/g)
			? basicType
			: `${basicType}[]`;
		return finalType;
	}
	/**
	 * @method buildObservableType
	 * @description
	 * Define observable type
	 */
	function buildObservableType(model, method) {
		let type = 'any';
    if (
      method.name.match(/(^createMany$|^find)/g) ||
      (
        typeof method.returns === 'object' &&
        (String(method.returns.type).toLowerCase() === 'array' || Array.isArray(method.returns.type))
      )
    ) type = `${model.name}[]`;
    if (method.name.match(/(^create$|upsert|^findBy|^findOne$)/g)) type = model.name;

    if(type=='any' && method.returns && method.returns[0]){
        type=method.returns[0].type;
        type=method.isReturningArray() ? `${type}[]`: type;
        console.log(`Warning Custom Type Applied for ${method.name}:${type}`)
    }
    return type;
	}
	/**
	 * @method buildServiceImports
	 * @description
	 * Define import statement for those model who are related to other scopes
	 * IMPORTANT: This method have a very specific flow, changing it may create
	 * multiple issues on multiple different use cases.
	 */
	function buildServiceImports(model, loadAccessToken, isIo) {
		let modelName = capitalize(model.name);
		let imports = [
			{ module: 'Injectable, Inject, Optional', from: '@angular/core' },
			{ module: 'HttpClient, HttpResponse', from: '@angular/common/http' },
			{ module: 'SDKModels', from: './SDKModels' },
			{ module: 'BaseLoopBackApi', from: '../core/base.service' },
			{ module: 'LoopBackConfig', from: '../../lb.config' },
			{ module: 'LoopBackAuth', from: '../core/auth.service' },
			{
				module: `LoopBackFilter, ${
					model.isUser
						? `SDKToken${
								loadAccessToken && model.isUser ? ', AccessToken' : ''
						  }`
						: ''
				}`,
				from: '../../models/BaseModels'
			},
			{ module: 'ErrorHandler', from: '../core/error.service' },
			{ module: 'Subject', from: 'rxjs/Subject' },
			{ module: 'Observable', from: 'rxjs/Observable' },
			{ module: 'map', from: 'rxjs/operators' },
			{ module: modelName, from: `../../models/${modelName}` }
		];
		if (isIo === 'enabled') {
			imports.push({
				module: 'SocketConnection',
				from: '../../sockets/socket.connections'
			});
		}
		let loaded = {};
		loaded[modelName] = true;
		getModelRelations(model).forEach((relationName, i) => {
			let targetClass =
				model.sharedClass.ctor.relations[relationName].targetClass;
			// It is imperative to check first for through models, else we may miss some
			// Through Models. This is because multiple relationships to the same model may have
			// different Through models, in the next validation we avoid duplicating models, which
			// can lead to miss some through models.
			// Finally we will be adding through models only if these are Public
			if (
				model.sharedClass.ctor.relations[relationName].modelThrough &&
				model.sharedClass.ctor.relations[relationName].modelThrough.sharedClass
					.name !== 'Model' &&
				ctx.models[
					model.sharedClass.ctor.relations[relationName].modelThrough
						.sharedClass.name
				]
			) {
				let through = capitalize(
					model.sharedClass.ctor.relations[relationName].modelThrough
						.sharedClass.name
				);
				if (!loaded[through] && targetClass !== modelName) {
					loaded[through] = true;
					imports.push({ module: through, from: `../../models/${through}` });
				}
			}
			// Now and after the through model was included is the right time to verify if the current model
			// was loaded by another relationship, this way we don't duplicate the class during imports'
			if (!loaded[targetClass] && targetClass !== modelName) {
				loaded[targetClass] = true;
				imports.push({
					module: targetClass,
					from: `../../models/${targetClass}`
				});
			}
    });
    
    model.methods.forEach(function(method) {
      if (typeof method.returns === 'object' && method.returns && method.returns[0]) {
        let type = method.returns[0].type
        if(typeof type ==='string' && type.toLowerCase()!='any' &&
           type.toLowerCase()!='object' && type.toLowerCase()!='string' &&
           type.toLowerCase()!='number' && type.toLowerCase()!='date'){
          if(imports.indexOf(t=>t.module==type)==-1){
            imports.push({module:type,from:`../../models/${type}`})
          }
        }
      }
    })

		return buildImports(imports);
	}
	/**
	 * @method buildModuleImports
	 * @description
	 * Define import statement for the SDK Module
	 */
	function buildModuleImports(models, isIo, driver) {
		let imports = [
			{ module: 'ErrorHandler', from: './services/core/error.service' },
			{ module: 'LoopBackAuth', from: './services/core/auth.service' },
			{ module: 'LoggerService', from: './services/custom/logger.service' },
			{ module: 'SDKModels', from: './services/custom/SDKModels' },
			{
				module: 'InternalStorage, SDKStorage',
				from: './storage/storage.swaps'
			},
			{ module: 'HttpClientModule', from: '@angular/common/http' },
			{ module: 'CommonModule', from: '@angular/common' },
			{ module: 'NgModule, ModuleWithProviders', from: '@angular/core' }
		];

		switch (driver) {
			case 'ng2web':
				imports.push({
					module: 'CookieBrowser',
					from: './storage/cookie.browser'
				});
				imports.push({
					module: 'StorageBrowser',
					from: './storage/storage.browser'
				});
				if (isIo === 'enabled') {
					imports.push({
						module: 'SocketBrowser',
						from: './sockets/socket.browser'
					});
				}
				break;
			case 'ng2universal':
				imports.push({
					module: 'CookieBrowser',
					from: './storage/cookie.browser'
				});
				imports.push({ module: 'CookieNode', from: './storage/cookie.node' });
				imports.push({
					module: 'StorageBrowser',
					from: './storage/storage.browser'
				});
				if (isIo === 'enabled') {
					imports.push({
						module: 'SocketBrowser',
						from: './sockets/socket.browser'
					});
					imports.push({ module: 'SocketNode', from: './sockets/socket.node' });
				}
				break;
			case 'ng2native':
				imports.push({
					module: 'StorageNative',
					from: './storage/storage.native'
				});
				imports.push({
					module: 'NativeScriptHttpModule',
					from: 'nativescript-angular/http'
				});
				if (isIo === 'enabled') {
					imports.push({
						module: 'SocketNative',
						from: './sockets/socket.native'
					});
				}
				break;
		}

		if (isIo === 'enabled') {
			imports = imports.concat([
				{ module: 'SocketDriver', from: './sockets/socket.driver' },
				{ module: 'SocketConnection', from: './sockets/socket.connections' },
				{ module: 'RealTime', from: './services/core/real.time' }
			]);
		}

		Object.keys(models).forEach(modelName => {
			let name = capitalize(modelName);
			imports.push({ module: `${name}Api`, from: `./services/custom/${name}` });
		});

		return buildImports(imports);
	}
	/**
	 * @method buildNgModuleImports
	 * @description
	 * Define import statement for the SDK NG Modules
	 */
	function buildNgModuleImports(models, environment, isIo, driver) {
		let imports = ['LoopBackAuth', 'LoggerService', 'SDKModels'];
		if (isIo === 'enabled') {
			imports.push('RealTime');
		}
		Object.keys(models).forEach(modelName =>
			imports.push(`${capitalize(modelName)}Api`)
		);
		switch (environment) {
			case 'browser':
				if (driver === 'ng2web' || driver === 'ng2universal') {
					imports.push('internalStorageProvider');
					imports.push('{ provide: SDKStorage, useClass: StorageBrowser }');
					if (isIo === 'enabled') {
						imports.push('{ provide: SocketDriver, useClass: SocketBrowser }');
					}
				}
				break;
			case 'node':
				if (driver === 'ng2universal') {
					imports.push('{ provide: InternalStorage, useClass: CookieNode }');
					if (isIo === 'enabled') {
						imports.push('{ provide: SocketDriver, useClass: SocketNode }');
					}
				}
				break;
			case 'nativescript':
				if (driver === 'ng2native') {
					imports.push('{ provide: InternalStorage, useClass: StorageNative }');
					imports.push('{ provide: SDKStorage, useClass: StorageNative }');
					if (isIo === 'enabled') {
						imports.push('{ provide: SocketDriver, useClass: SocketNative }');
					}
				}
				break;
		}
		return imports.join(',\n        ');
	}
	/**
	 * @method buildNgProviders
	 * @description
	 * Define import statement for the SDK NG Modules
	 */
	function buildNgProviders(isIo) {
		let imports = ['ErrorHandler'];
		if (isIo === 'enabled') {
			imports.push('SocketConnection');
		}
		return imports.join(',\n    ');
	}
	/**
	 * @method buildServiceDI
	 * @description
	 * Define import statement for the SDK NG Modules
	 */
	function buildServiceDI(isIo) {
		let dependencies = ['@Inject(HttpClient) protected http: HttpClient'];
		if (isIo === 'enabled') {
			dependencies.push(
				'@Inject(SocketConnection) protected connection: SocketConnection'
			);
		}
		dependencies = dependencies.concat([
			'@Inject(SDKModels) protected models: SDKModels',
			'@Inject(LoopBackAuth) protected auth: LoopBackAuth',
			'@Optional() @Inject(ErrorHandler) protected errorHandler: ErrorHandler'
		]);
		return dependencies.join(',\n    ');
	}
	/**
	 * @method buildBaseServiceImports
	 * @description
	 * Define import statement for the SDK Module
	 **/
	function buildBaseServiceImports(isIo) {
		let imports = [
			{ module: 'Injectable, Inject, Optional', from: '@angular/core' },
			{
				module:
					'HttpClient, HttpHeaders, HttpRequest, HttpParams, HttpResponse, HttpParameterCodec',
				from: '@angular/common/http'
			},
			{ module: 'NgModule, ModuleWithProviders', from: '@angular/core' },
			{ module: 'ErrorHandler', from: './error.service' },
			{ module: 'LoopBackAuth', from: './auth.service' },
			{ module: 'LoopBackConfig', from: '../../lb.config' },
			{
				module: 'LoopBackFilter, AccessToken',
				from: '../../models/BaseModels'
			},
			{ module: 'SDKModels', from: '../custom/SDKModels' },
			{ module: 'Observable', from: 'rxjs/Observable' },
			{ module: 'Subject', from: 'rxjs/Subject' },
			{ module: 'ErrorObservable', from: 'rxjs/observable/ErrorObservable' },
			{ module: 'catchError, map, filter', from: 'rxjs/operators' }
		];

		if (isIo === 'enabled') {
			imports.push({
				module: 'SocketConnection',
				from: '../../sockets/socket.connections'
			});
		}

		return buildImports(imports);
	}
	/**
	 * @method buildImports
	 * @description
	 * Transform an array of objects describing which should be imported into
	 * the actual template strings
	 */
	function buildImports(imports) {
		return imports
			.map(
				item =>
					`import ${item.from ? `{ ${item.module} }` : `'${item.module}'`}${
						item.from ? ` from '${item.from}'` : ''
					};`
			)
			.join('\n');
	}
	/**
	 * @method normalizeMethodName
	 * @description
	 * Normalizes method name from loopback form to a more human readable form
	 */
	function normalizeMethodName(methodName, capitalize) {
		return methodName
			.split('__')
			.map((value, index) => {
				return index < 2 && !capitalize
					? value
					: value.charAt(0).toUpperCase() + value.slice(1);
			})
			.join('');
	}
	/**
	 * @method upperCasedMethodName
	 * @description
	 * Upper cases method name from loopback form to a more human readable form
	 */
	function upperCasedMethodName(methodName) {
		return methodName
			.split('__')
			.filter(value => value !== '')
			.map((value, index) => {
				if (index === 0) {
					return value
						.split(/(?=[A-Z])/)
						.map(value => value.toUpperCase())
						.join('_');
				} else {
					return value.toUpperCase();
				}
			})
			.join('_');
	}
	/**
	 * @method buildMethodParams
	 * @description
	 * Set which params should be defined for the given remote method
	 */
	function buildMethodParams(model, methodName, params, isIo) {
		//if (model.isUser && methodName === 'logout') return '';
		let output = new Array();
		let relations = getModelRelations(model);
		let availableClasses = relations.map(
			(relationName, index) =>
				model.sharedClass.ctor.relations[relationName].targetClass
		);

		params = params.filter(param => {
			return !paramIsContext(param) && !paramIsFunction(param);
		});

		relations.forEach(relationName => {
			if (model.sharedClass.ctor.relations[relationName].modelThrough) {
				let throughName = capitalize(
					model.sharedClass.ctor.relations[relationName].modelThrough
						.sharedClass.name
				);
				// Only add through models when they are Public
				if (ctx.models[throughName]) {
					availableClasses.push(
						capitalize(
							model.sharedClass.ctor.relations[relationName].modelThrough
								.sharedClass.name
						)
					);
				}
			}
		});
		if (isIo)
			params = params.filter(param => !param.arg.match(/(fk|data|options)/));
		params.forEach((param, i, arr) => {
			let type,
				isArray = false;
			if (param.type === 'object') {
				type = param.arg === 'filter' ? 'LoopBackFilter' : 'any';
			} else {
				type =
					param.type !== 'AccessToken' &&
					param.type !== 'any' &&
					param.type !== undefined
						? capitalize(param.type)
						: 'any';
			}
			if (
				!type.match(/(^any$|LoopBackFilter)/) &&
				availableClasses.indexOf(type) < 0
			) {
				type = 'any';
			}
			let value = '';
			// Accept Array on createMany method.
			if (methodName.match(/createMany/) && param.arg === 'data') {
				isArray = true;
			}
			// Set default value, usually will be {}, but on login we include user
			// Should not be undefined or will create request issues
			if (
				!param.required &&
				(model.isUser && methodName === 'login') &&
				param.arg === 'include'
			) {
				type = 'any';
				value = "" = 'user'"";
			} else if (type.match(/(any|LoopBackFilter)/)) {
				value = !param.required ? ` = ${isArray ? '[]' : '{}'}` : '';
			} else {
				value = !param.required
					? ` = ${isArray ? `new Array<${type}>()` : `new ${type}()`}`
					: '';
			}
			output.push(`${param.arg}: ${type}${isArray ? '[]' : ''}${value}`);
		});

		// When login, there is a property not coming from LoopBack that is needed.
		// so we need to add a rememberMe property to temporal o permanent store the user
		if (model.isUser && methodName === 'login') {
			output.push(`rememberMe: boolean = true`);
		}

		// When login, there is a property not coming from LoopBack that is needed.
		// so we need to add a rememberMe property to temporal o permanent store the user
		// UPDATE: it seems it is now coming from loopback, so now is duplicated
		/*if ((model.isUser && methodName === 'login')) {
      output.push(`rememberMe: boolean = true`);
    }*/

		if (!isIo) {
			output.push(`customHeaders?: Function`);
		}
		return output.join(', ');
	}
	/**
	 * @method buildPayloadParams
	 * @description
	 * Set which params should be defined for the given remote method
	 */
	function buildPayloadParams(model, methodName, params, isIo) {
		if (model.isUser && methodName === 'logout') return '';
		let output = new Array();
		let relations = getModelRelations(model);
		let availableClasses = relations.map(
			(relationName, index) =>
				model.sharedClass.ctor.relations[relationName].targetClass
		);

		params = params.filter(param => {
			return !paramIsContext(param) && !paramIsFunction(param);
		});

		relations.forEach(relationName => {
			if (model.sharedClass.ctor.relations[relationName].modelThrough) {
				let throughName = capitalize(
					model.sharedClass.ctor.relations[relationName].modelThrough
						.sharedClass.name
				);
				// Only add through models when they are Public
				if (ctx.models[throughName]) {
					availableClasses.push(
						capitalize(
							model.sharedClass.ctor.relations[relationName].modelThrough
								.sharedClass.name
						)
					);
				}
			}
		});
		if (isIo)
			params = params.filter(param => !param.arg.match(/(fk|data|options)/));
		params.forEach((param, i, arr) => {
			let type,
				isArray = false;
			if (param.type === 'object') {
				type = param.arg === 'filter' ? 'LoopBackFilter' : 'any';
			} else {
				type =
					param.type !== 'AccessToken' && param.type !== 'any'
						? capitalize(param.type)
						: 'any';
			}
			if (
				!type.match(/(^any$|LoopBackFilter)/) &&
				availableClasses.indexOf(type) < 0
			) {
				type = 'any';
			}
			let value = '';
			// Accept Array on createMany method.
			if (methodName.match(/createMany/) && param.arg === 'data') {
				isArray = true;
			}
			output.push(`${param.arg}: ${type}${isArray ? '[]' : ''}${value}`);
		});
		if (!isIo) {
			output.push(`customHeaders`);
		}
		return output.join(', ');
	}
	/**
	 * @method buildPayloadParamsWithoutTypes
	 * @description
	 * Set which params should be defined for the given remote method
	 */
	function buildPayloadParamsWithoutTypes(model, methodName, params, isIo) {
		if (model.isUser && methodName === 'logout') return '';
		let output = new Array();
		let relations = getModelRelations(model);
		let availableClasses = relations.map(
			(relationName, index) =>
				model.sharedClass.ctor.relations[relationName].targetClass
		);

		params = params.filter(param => {
			return !paramIsContext(param) && !paramIsFunction(param);
		});

		relations.forEach(relationName => {
			if (model.sharedClass.ctor.relations[relationName].modelThrough) {
				let throughName = capitalize(
					model.sharedClass.ctor.relations[relationName].modelThrough
						.sharedClass.name
				);
				// Only add through models when they are Public
				if (ctx.models[throughName]) {
					availableClasses.push(
						capitalize(
							model.sharedClass.ctor.relations[relationName].modelThrough
								.sharedClass.name
						)
					);
				}
			}
		});
		if (isIo)
			params = params.filter(param => !param.arg.match(/(fk|data|options)/));
		params.forEach((param, i, arr) => {
			output.push(`${param.arg}`);
		});
		if (!isIo) {
			output.push(`customHeaders`);
		}
		return output.join(', ');
	}
	/**
	 * @method buildMethodParamsFromPayload
	 * @description
	 * Set which params should be defined for the given remote method from the given payload
	 */
	function buildMethodParamsFromPayload(model, methodName, params, isIo) {
		if (model.isUser && methodName === 'logout') return '';
		let output = new Array();
		let relations = getModelRelations(model);
		let availableClasses = relations.map(
			(relationName, index) =>
				model.sharedClass.ctor.relations[relationName].targetClass
		);

		params = params.filter(param => {
			return !paramIsContext(param) && !paramIsFunction(param);
		});

		relations.forEach(relationName => {
			if (model.sharedClass.ctor.relations[relationName].modelThrough) {
				let throughName = capitalize(
					model.sharedClass.ctor.relations[relationName].modelThrough
						.sharedClass.name
				);
				// Only add through models when they are Public
				if (ctx.models[throughName]) {
					availableClasses.push(
						capitalize(
							model.sharedClass.ctor.relations[relationName].modelThrough
								.sharedClass.name
						)
					);
				}
			}
		});
		if (isIo)
			params = params.filter(param => !param.arg.match(/(fk|data|options)/));
		params.forEach((param, i, arr) => {
			output.push(`action.payload.${param.arg}`);
		});
		return output.join(', ');
	}
	/**
	 * @method paramIsRoute
	 * @description
	 * Testing if the param is route type
	 */
	function paramIsRoute(param) {
		return (
			(param.http && param.http.source === 'path') ||
			(param.arg && param.arg.match(/(^id$|fk|^file$|container)/))
		);
	}
	/**
	 * @method paramIsFunction
	 * @description
	 * Testing if the param is function type
	 */
	function paramIsFunction(param) {
		return typeof param.http === 'function';
	}
	/**
	 * @method paramIsContext
	 * @description
	 * Testing if the param is a http.context
	 */
	function paramIsContext(param) {
		return (
			typeof param.http !== 'undefined' &&
			typeof param.http.source !== 'undefined' &&
			param.http.source === 'context'
		);
	}
	/**
	 * @method paramIsBody
	 * @description
	 * Testing if the param is a http.body or form
	 */
	function paramIsBody(param) {
		return (
			typeof param.http !== 'undefined' &&
			typeof param.http.source !== 'undefined' &&
			(param.http.source == 'body' || param.http.source == 'form')
		);
	}
	/**
	 * @method paramIsQuery
	 * @description
	 * Testing if the param is a http.query or form
	 */
	function paramIsQuery(param) {
		return (
			(typeof param.http === 'undefined' && // Query is default, if http is not defined we treat it as query param
				(param.arg && !param.arg.match(/(^id$|fk|^file$|container)/))) || // But only if it is not id, fk, file or container
			(typeof param.http !== 'undefined' &&
				typeof param.http.source !== 'undefined' &&
				param.http.source == 'query')
		);
	}
	/**
	 * @method buildPostBody
	 * @description
	 * Define which properties should be passed while posting data (POST, PUT, PATCH)
	 */
	function buildPostBody(postData) {
		let output = [];
		if (Array.isArray(postData)) {
			postData = postData.filter(param => {
				// Filter out route params and function params
				if (
					paramIsRoute(param) ||
					paramIsFunction(param) ||
					paramIsContext(param) ||
					paramIsQuery(param)
				) {
					return false;
				}
				// Make sure the param is body or form data
				return paramIsBody(param);
			});
			if (postData.length > 0) {
				output.push('');
				let l = postData.length;
				let formData = [];
				postData.forEach((property, i) => {
					if (property.http.source == 'form') {
						formData.push(property);
					} else {
						output.push(
							`      ${property.arg}: ${property.arg}${i < l - 1 ? ',' : ''}`
						);
					}
				});
				if (formData.length > 0) {
					l = formData.length;
					output.push(`      data: {`);
					formData.forEach((property, i) => {
						output.push(
							`        ${property.arg}: ${property.arg}${i < l - 1 ? ',' : ''}`
						);
					});
					output.push(`      }`);
				}
				output.push('    ');
			}
		}
		return output.join('\n');
	}
	/**
	 * @method buildUrlParams
	 * @description
	 * Define which properties should be passed using query string
	 */
	function buildUrlParams(model, methodName, urlParams) {
		let output = [''];
		// filter params that should not go over url query string
		urlParams = urlParams.filter(param => {
			// Filter out route params and function params
			if (
				paramIsRoute(param) ||
				paramIsFunction(param) ||
				paramIsContext(param) ||
				paramIsBody(param)
			) {
				return false;
			}
			// Filter out body params
			return paramIsQuery(param);
		});
		if (model.isUser && methodName === 'logout')
			output.push(
				`       _urlParams.access_token = this.auth.getAccessTokenId();`
			);
		if (urlParams && urlParams.length > 0) {
			urlParams.forEach((param, i) => {
				output.push(
					`    if (typeof ${param.arg} !== 'undefined' && ${
						param.arg
					} !== null) _urlParams.${param.arg} = ${param.arg};`
				);
			});
		}
		return output.join('\n');
	}
	/**
	 * @method buildRouteParams
	 * @description
	 * Define which properties should be passed as route params
	 */
	function buildRouteParams(routeParams) {
		let output = [];
		if (routeParams) {
			routeParams = routeParams.filter(param => {
				if (
					paramIsQuery(param) ||
					paramIsFunction(param) ||
					paramIsContext(param) ||
					paramIsBody(param)
				) {
					return false;
				}
				return paramIsRoute(param);
			});
			if (routeParams.length > 0) {
				output.push('');
				routeParams.forEach((param, i) => {
					output.push(
						`      ${param.arg}: ${param.arg}${
							i < routeParams.length - 1 ? ',' : ''
						}`
					);
				});
				output.push('    ');
			}
		}
		return output.join('\n');
	}
	/**
	 * @author João Ribeiro <jonnybgod@gmail.com, http://jonnybgod.ghost.io>,
	 * @license MIT
	 * @method buildPropertyType
	 * @description
	 * Define which properties should be passed as route params
	 */
	function buildPropertyType(property) {
		if (!property || !property.type) {
			return 'any';
		}
		switch (typeof property.type) {
			case 'function':
				switch (property.type.name) {
					case 'String':
					case 'Number':
					case 'Boolean':
						return property.type.name.toLowerCase();
					case 'Date':
					case 'GeoPoint':
						return property.type.name;
					default:
						return 'any';
				}
			case 'object':
				if (Array.isArray(property.type)) {
					return `Array<${buildPropertyType(property.type[0])}>`;
				}
				return 'object';
			default:
				return 'any';
		}
	}
	/*
	 * @author Julien Ledun <j.ledun@iosystems.fr>,
	 * @license MIT
	 * @method buildPropertyDefaultValue
	 * @description
	 * Define defaults null values for class properties
	 */
	function buildPropertyDefaultValue(property) {
		let defaultValue = property.hasOwnProperty('default')
			? property.default
			: '';
		switch (typeof property.type) {
			case 'function':
				switch (property.type.name) {
					case 'String':
						return `'${defaultValue}'`;
					case 'Number':
						return isNaN(Number(defaultValue)) ? 0 : Number(defaultValue);
					case 'Boolean':
						return Boolean(defaultValue);
					case 'Date':
						return isNaN(Date.parse(defaultValue))
							? `new Date(0)`
							: `new Date('${defaultValue}')`;
					case 'GeoPoint':
					default:
						return '<any>null';
				}
			case 'object':
				if (Array.isArray(property.type)) {
					return '<any>[]';
				}
				return '<any>null';
			default:
				return '<any>null';
		}
	}
};

/**
 * HELPERS
 */
function capitalize(string) {
	return string[0].toUpperCase() + string.slice(1);
}

function getModelRelations(model) {
	return Object.keys(model.sharedClass.ctor.relations).filter(
		relationName =>
			model.sharedClass.ctor.relations[relationName].targetClass &&
			model.sharedClass.ctor.relations[relationName].targetClass !== model.name
	);
}


```",60712558
1018,Url Parameters not being passed in correctly,open,2018-06-01T16:12:47Z,2018-06-01T16:12:47Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [x] 2.3.1

Write other if any:

#### Please add a description for your issue:

Url Search Parameters are not being passed in correctly inside of base.service.ts. 

`search  : Object.keys(urlParams).length > 0
                  ? searchParams.getURLSearchParams() : null`

this can be fixed by doing the following

`params  : Object.keys(urlParams).length > 0
                  ? urlParams : null`
",,60712558
1019,Problems when using loopback-component-push,open,2018-04-11T04:47:07Z,2018-04-11T04:48:37Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any:
2.1.1
2.2.5
#### Please add a description for your issue:

I use Loopback and loopback-sdk-builder in the following environment.

**server**

- Loopback project
    - loopback-connector-mongodb
    - loopback-component-push

**client**

- Ionic 2 project
    - Place the build sdk ""src\app\shared\sdk""

However, an error occurs at this time.
That is the argument of the Installation model is incorrect.

To use loopback-component-push, I need to create Application and Installation in my custom model.
Like this:
``` 
server/models/application.json
{
  ""name"": ""application"",
  ""base"": ""Application"",
  ""idInjection"": true,
  ""options"": {
    ""validateUpsert"": true
  },
  ""properties"": {},
  ""validations"": [],
  ""relations"": {},
  ""acls"": [],
  ""methods"": {}
}
```
``` 
server/models/installation.json
{
  ""name"": ""installation"",
  ""base"": ""Installation"",
  ""idInjection"": true,
  ""options"": {
    ""validateUpsert"": true
  },
  ""properties"": {},
  ""validations"": [],
  ""relations"": {},
  ""acls"": [],
  ""methods"": {}
}
```

In order to solve this problem I am fixing the generated SDK by myself.
Like this:
```
public findBySubscriptions(deviceType: any = {}, subscriptions: any = {}, customHeaders?: Function): Observable<installation> {
```
↓
```
public findBySubscriptions(deviceType: any = {}, subscriptions: any = {}, customHeaders?: Function): Observable<Installation> {
```
I changed the last ""installation"" to ""Installation"".
There are three same fixes.

Is this a bug?
Or is there a way to respond?

Regards,
asuzuki",,60712558
1020,"core.base.service has ""any"" type for HttpResponse",open,2018-04-09T08:39:54Z,2018-04-09T08:45:02Z,,NONE,"#### What type of issue are you creating?
- [ x] Bug

#### What version of this module are you using?
- [2.5.5 ] Other

+ ""loopback"": ""3.18.3""

The SDK build process is successful, however any attempt to ng serve or build triggers an error referencing the SDK file: 

`client/src/app/shared/sdk/services/core/base.service.ts (150,14)`

With the error message: 

> The type argument for type parameter 'T' cannot be inferred from the usage. Consider specifying the 
> type arguments explicitly.
> 
>   Type argument candidate 'HttpEvent<{}>' is not a valid type argument because it is not a supertype of candidate 'HttpResponse<any>'.
>     Type 'HttpResponse<any>' is not assignable to type 'HttpResponse<{}>'.
>       Type 'any' is not assignable to type '{}'.
> 

And sure enough. If i change:
`HttpResponse<any>'`
to: 
`HttpResponse<{}>`

The error is resolved. It does however not explain the error, as the HttpResponse have not been assigned any data type, IMO 'any' could be used instead of hardtyping it to '{}'.

Maybe someone have a better explanation?",,60712558
1021,Test Case is not pass with angular sdk with api,open,2018-04-05T11:08:43Z,2018-09-28T03:54:31Z,,NONE,"I am writing unit test code for member login and signup API in angular 5 but I am not able to do as well please provide a solution for that how can I do a unit test with angular 5 with loopback-sdk-builder

login.component.spec.ts

```
import { async, ComponentFixture, TestBed } from '@angular/core/testing';

import { LoginComponent } from '../app/login/login.component';
import { BrowserModule } from '@angular/platform-browser';
import { FormsModule } from '@angular/forms';
import { MemberApi } from '../app/shared/sdk/services';
import { HttpModule } from '@angular/http';
describe('LoginComponent', () => {
  let component: LoginComponent;
  let fixture: ComponentFixture<LoginComponent>;

  beforeEach(async(() => {
    TestBed.configureTestingModule({
      imports: [FormsModule, BrowserModule, HttpModule],
      declarations: [ LoginComponent ],
      providers: [MemberApi]
    })
    .compileComponents();
  }));

  beforeEach(() => {
    fixture = TestBed.createComponent(LoginComponent);
    component = fixture.componentInstance;
    fixture.detectChanges();
  });

  it('should create', () => {
    expect(component).toBeTruthy();
  });
});
```

login.component.ts

```
import { Component, OnInit } from '@angular/core';
import { DataService } from '../data.service';
import { LoopBackConfig, BASE_URL, API_VERSION } from '../shared/sdk';
import { Member, AccessToken } from '../shared/sdk/models';
import { GrowlerService, GrowlerMessageType } from '../core/growler/growler.service';
import { MemberApi } from '../shared/sdk/services';
import { Router } from '@angular/router';

@Component({
  selector: 'app-login',
  templateUrl: './login.component.html',
  styleUrls: ['./login.component.scss']
})
export class LoginComponent implements OnInit {
  private addUser: Member = new Member();
  isLogin = false;

  /**
   * constructor for depandancy injection
   * @param memberApi
   * @param router
   * @param dataService
   */
  constructor(private memberApi: MemberApi,
              private router: Router,
              private growler: GrowlerService,
              private dataService: DataService) {
    LoopBackConfig.setBaseURL(BASE_URL);
    LoopBackConfig.setApiVersion(API_VERSION);
      if (this.memberApi.isAuthenticated()) {
        router.navigate(['dashboard']);
      }
  }

  /**
   * onload function
   */
  ngOnInit() {
    /*this.dataService.getDemoList().subscribe((data) => {
      console.log(data);
    });*/
  }

  /**
   * login user in portal
   */
  private login(): void {
    this.memberApi.login(this.addUser, {}).subscribe((data) => this.router.navigate(['/dashboard']),
      (err) => this.growler.growl(err.message, GrowlerMessageType.Danger));
  }

```
","Its a possible bug in the error class. This: 

```
export class ErrorHandler {
  public handleError(errorResponse: HttpErrorResponse): Observable<never> {
    return throwError(errorResponse.error.error || 'Server error');
  }
}
```
Should be: 
```
export class ErrorHandler {
  public handleError(errorResponse: HttpErrorResponse): Observable<never> {
      return throwError(errorResponse.error || 'Server error');
  }
}
```",60712558
1022, Real time application example not working,open,2018-03-30T01:12:23Z,2018-03-30T01:12:23Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x ] Question

#### What version of this module are you using?
- [x ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
My question refers to responding to real time events on the server. I could not get this part of the startup to work. How can I tap into a persisted models onCreate event or any for that matter? Thank you.

https://github.com/mean-expert-official/loopback-sdk-builder/wiki/5.-Usage-Examples#real-time-application-example",,60712558
1023,Error when compiling angular app,open,2018-03-26T10:50:06Z,2018-03-27T17:27:52Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x ] Question

#### What version of this module are you using?
- [x ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

I am gettung an error when webpack is compiling my client app. 
it says:
ERROR in /Users/milanj/em/client/sdk/services/core/base.service.ts (141,14): The type argument for type parameter 'T' cannot be inferred from the usage. Consider specifying the type arguments explicitly.
  Type argument candidate 'HttpEvent<{}>' is not a valid type argument because it is not a supertype of candidate 'HttpResponse<any>'.
    Type 'HttpResponse<any>' is not assignable to type 'HttpResponse<{}>'.
      Type 'any' is not assignable to type '{}'.

Please can anyone help?","I noticed that also in the 2.1.0 release.
Suddenly all params that are not stated in angular will get a {} value",60712558
1024,ErrorHandler throws TypeError,open,2018-03-19T13:31:18Z,2018-03-19T13:31:18Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any: 2.2.0

When there is no response from the serve throws the error: error.json is not a function, i think the error handler should be:
```
public handleError(error: Response): any {
    return Observable.throw(error.json? error.json().error : 'Server error');
 }
```
instead of:
```
public handleError(error: Response): any {
    return Observable.throw(error.json().error || 'Server error');
  }
```",,60712558
1025,Filters are not working when I generate it for Angular 4,open,2018-03-19T12:45:43Z,2018-03-19T13:17:55Z,,NONE,"#### What type of issue are you creating?
- [ x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ x] Other

Write other if any: 2.2.0

#### Please add a description for your issue:

When the base.service.ts is generated for Angular TS .. Its not concatenating the queryString (filter where cause which was generated). Due to this, when we pass LoopBackFilter in Find methods, its not filtering.. 
It need to be fixed in next release. ","It's a bug related to the headers, check #571  to fix it",60712558
1026,HttpHeaders bug,open,2018-03-12T11:02:28Z,2019-03-28T17:31:36Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any: 2.2.0 new realease

#### Please add a description for your issue:

urlParams. filter and urlParams.where in get request appends filter and where to headers

headers.append('filter', JSON.stringify(urlParams.filter));

It needs to repleace the headers variable to be sent.

headers = headers.append('filter', JSON.stringify(urlParams.filter));","I'm still unable to use 'where' within a filter:
`this.myApi.getRelatedModel(id, {
      where: {
        finished: {
          exists: false
        }
      },
      include: [
        { some: 'stuff' }
      ]
    }).subscribe(...)`

Am i to blame or is the filter still not working properly?

(the given code snippet above still returns results with the field ""finished"" set. It worked like this with the builtin loopback angular 1 sdk builder)

Version used to generate the SDK: @mean-expert/loopback-sdk-builder@2.3.1

Thanks in advance for any help or hints!",60712558
1027,Is it possible to replace the http module with httpclient module?,open,2018-03-12T07:52:37Z,2018-11-30T17:04:47Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [x ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:",It is merged since #565,60712558
1028,Final Announcement,open,2018-02-10T18:05:13Z,2018-04-30T03:14:54Z,,COLLABORATOR,"Final Announcement
===================

Hello guys, through this final announcement I want to communicate that I'm definitely stopping the support for the FireLoop project and all of the modules related to LoopBack like the SDK Builder.

I know I just published a couple of months ago that I was working on building FireLoop on top of LoopBack 4 again, but after some time, I found that following that path was a really wrong desition and I decided that I need to move on and completely leave LoopBack behind.

Therefore, since I'm leaving LoopBack as my back-end framework choice I'm leaving everything I built for them as well, hoping that these modules remain helping many of you to build applications while using LoopBack and maybe some of you might continue the work by forking my repos and modules that will be kept alive.

# Ooooook..... so... What is next?
After having an enormous amount of learnings while building all of those modules, even building a platform composed from other frameworks and some core integration modules.

I have decided to start a new project from scratch, following the same FireLoop spirit but without any ties, that will allow me to literally have the entire control and avoid a bunch of unexpected errors due to the huge amount of the dependencies.

# Then why not calling it FireLoop?
Because first of all it won't be built on top of LoopBack, and second because it won't imitate the FireBase API.

The new project is SOA and MSA oriented and is built from scratch with almost zero dependencies and with its own `Service Oriented Architecture` implementation providing a `Remote Call Procedure` API for communication between these services.

And for that reason, this new project is unable to be called FireLoop.

# Will my current FireLoop apps work on this new Project?
Unfortunately, it won't work on this new project, nor on LB4. And that is one of the reasons I'm starting this new project because I simply must not delegate the stability of my project to others.

# This new project... What is going to have in common with FireLoop?
First it is built on TypeScript but now, it will also be compatible with plain JS projects (for those hatin' TS)

Second, it will provide client SDK but this time won't be Angular specific but it will be compatible with any JavaScript front-end framework (React, Angular, Vue, Stencil, etc), even in plain JavaScript projects.

# Will it continue using http/rest and socket.io/websocket as transportation?
I'm also leaving socket.io and rest, this new project is being built using the latest technology features like async/await, WebWorkers, EventStreams and HTTP2 using gRPC.

# Is this new project an actual MicroServices platform or just another REST API Services framework
Of course, this is a true SOA project, each app / service runs on separated processes and communication between these services and clients can be done through the provided Remote Procedure Call (RPC) API.

Therefore if any of your apps crash, the rest of the loaded applications will remain up and running, then the server will try to start your crashed app again.

# It sounds like there is already some progress with this.
Yes, that is the reason I'm publishing this final announcement.

# When can we know more details?
FireLoop is done from now and so on, no more details will be communicated on that.

About the new project, we already have a very good progress and we even have a name, but will be posting details about it once we do some branding.

Thanks to all for your support on this project. I don't really want to say that this project is dead.

It is just a re-born as a new project but now with its own personality.

Cheers
Jon

","@villegasrfael don’t worry about this being unsupported I just personally won’t improve or extend the mean expert modules but I’m taking the time to integrate any community contribution, that will continue to happen as long as the community keeps sending patches.


Cheers
Jon",60712558
1029,All image links from wiki are broken,open,2018-02-06T16:54:38Z,2018-02-06T16:54:38Z,,NONE,"#### What type of issue are you creating?
- [X] Bug ?
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

All image links from wiki are returning the following: `Invalid upstream response (403)`
",,60712558
1030,EJS Dependency Version Update ,open,2018-02-04T22:32:27Z,2018-02-04T22:32:27Z,,NONE,"#### What type of issue are you creating?
- [x ] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [x ] 2.1.2 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Please update the EJS Dependency Version to the latest.",,60712558
1031,Error when running npm run build:sdk script,open,2018-02-02T15:50:30Z,2018-02-02T15:50:30Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X] Other

Write other if any: 2.1.2

#### Please add a description for your issue:  **Error when running npm run script**

After installing the sdk package in my loopback server packages. When I run ""npm run sdk:build"" I got the following error message:

lb-sdk server/server.js ../easy-stats-app/src/app/shared/sdk

module.js:557
    throw err;
    ^

Error: Cannot find module '../index'
    at Function.Module._resolveFilename (module.js:555:15)
    at Function.Module._load (module.js:482:25)
    at Module.require (module.js:604:17)
    at require (internal/module.js:11:18)
    at Object.<anonymous> (/Users/elviocavalcante/Dropbox/Projects/mbr-apps/mbr-pos-server/node_modules/.bin/lb-sdk:15:17)

",,60712558
1032,Access Token not being Stored / loaded when using Social Login and Angular 4,open,2018-01-26T17:04:18Z,2018-01-26T17:04:18Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
I created an app using Angular 4 and Loopback. When logging using local repository user, the process of login and use of the API created goes fine, but when I use a social provider, actually Facebook, it seems that the SDK is not setting the token in the request. Access token is saved in LoopBackAuth but not propagated in the authorization header
",,60712558
1033,"""JSON Parse error: Unterminated string"" only on iOS - broken string in $LoopBackSDK$user",open,2018-01-23T12:20:37Z,2018-02-21T16:14:09Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any: 2.1.2

#### Please add a description for your issue:
Guys,

We experienced a bug that happens only on iOS (Safari and Chrome). It happens when trying to store cookie with special characters  such as (àáâãèéê, etc). 

The error we get is ""JSON Parse error: Unterminated string"". We get this problem because if there is any of these characters the JSON string brakes in: **$LoopBackSDK$user**

So to solve that we have changed the following file:
`sdk/storage/stcookie.browser.ts`

we have added: 
`encodeURI(value)` in the **set** method

and
`decodeURI(value)` in **parse** method.

So that cookies are saved with special characters
","@thiagovito thanks for reaching out, hey so would you mind to send a PR to development with the patches you did to make it work.

I can publish that with the next version 2.2.0 which is about to be published.

Cheers
Jon",60712558
1034,"LoopBackAuth not persisting, BaseStorage methods empty",open,2018-01-23T00:41:45Z,2019-01-30T18:49:35Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X] Other

Write other if any:
2.1.2

#### Please add a description for your issue:

I don't know if this is a bug or I am missing something.  I was attempting for the last few days to get the social passport integration section of the wiki working but for the life of me I could not.  No cookie or localStorage properties were set, i could not log in or access my LoopBack api.  After diving into each call I found that ""persist"" in ""LoopBackAuth"" was using InternalStorage get, set and remove.  InternalStorage extends BaseStorage.  This was my auto-generated BaseStorage (removing comments for brevity):


""storage.swap.ts""
```
export class BaseStorage {

  get(key: string): any { }

  set(key: string, value: any, expires?: Date): void { }

  remove(key: string): void { }
}
```

As you can see those methods are completely empty, they do nothing.  If I inject StorageBrowser and pass the get, set, and remove from there into BaseStorage, all works fine.

```
export class BaseStorage {
  constructor(@Inject(StorageBrowser) protected storage: StorageBrowser)
  {

  }
  get(key: string): any {
    return this.storage.get(key);
  }
  set(key: string, value: any, expires?: Date): void {
    this.storage.set(key, value, expires);
  }
  remove(key: string): void {
    this.storage.remove(key)
  }
}
```

Did I miss a step in my config or build to get BaseStorage methods to populate?  Manually editing the generated files will not work for my build process. ","I was facing the same issue today, thanks to @mikeycrostar info about the access token, I was able to solve it with the following piece of code:
```
if (token.id && token.userId) {
    const access_token_object = {
          id: token.id,
          userId: token.userId,
          ttl: 1209600
    };
    const access_token = new SDKToken(access_token_object);
    this.lbAuth.setToken(access_token);
    this.lbAuth.setRememberMe(true);
    this.lbAuth.save();
}
```
(It could be possible that the above code can be enhanced)",60712558
1035,Use template-literal instead of EJS,open,2018-01-07T21:59:35Z,2018-01-08T21:21:47Z,,NONE,"[Template Literal](https://github.com/Drulac/template-literal) is fastest, smallest and simplest template engine, because it use JS's literal template feature.

It's  55 times faster than EJS, and it also use less CPU and RAM ressources, so it may be a good idea to use it instead of EJS 😀",Ok :-),60712558
1036,In Model Foreign key type must be any and not number,open,2017-12-19T17:14:43Z,2017-12-20T08:58:19Z,,NONE,"#### What type of issue are you creating?
- [ X] Bug
- [  ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ X] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other



#### Please add a description for your issue:

In my poject i am using mlab mongoDb db, so the id generated in the model are like this : 
    ""_id"": {
        ""$oid"": ""5a3943206cc9fb0d44c283bc""
    },

So the id is not a number ==> but in the generated sdk model it is a Number. 

Solution : The id must have the type any and not number.  Samething to do with the foreignkey....

Thankyou in advance","I found the solution, in fact i had to regenerate my sdk after changing my datasource to mongodb. 
",60712558
1037,Normalized paths not respected,open,2017-12-18T22:56:20Z,2017-12-18T22:56:20Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
When using `""normalizeHttpPath"": true` in loopback's config.json the generated functions in services no longer respect it (e.g. findOne -> find-one, MyModel -> my-model). This didn't occur in 2.0.x afaik. 

However, I cannot reproduce since installing 2.0.x versions gives me error:

> Cannot find module './drivers/ng2web/storage.driver.ejs'",,60712558
1038,Which driver to use for PWA with Angular Universal and possibly Ionic?,open,2017-12-15T18:58:48Z,2017-12-15T18:58:48Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [x] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other


Write other if any:

I'd like to create a PWA which also uses Angular Universal. 
At the installation [I have to choose a driver](https://github.com/mean-expert-official/loopback-sdk-builder/wiki/1.-Install-Builder-&-Build-SDK#sdk-builder-cli-tool), but as far as I understand **I'd need both the web and the universal driver in the same project? Is that possible?** 

Furthermore I'd like to **integrate an Ionic App in the same project** so that I can reuse the SharedModule, Models etc. 
To integrate Ionic I'll also need the native driver. But for that alternatively I could just create the Ionic App in a separate project and access the Models and **SharedModule** from outside I suppose? 

I am new to Loopback so if someone could point me in the right direction that would be great.",,60712558
1039,Problems with NGRX,open,2017-11-25T23:37:10Z,2017-12-10T20:19:23Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [X] Other _2.1.1_

Write other if any:

#### Generated SDK with -n tag enabled doesn't work with my Angular CLI project

I just installed newest Node.js, NPM, Angular CLI, Loopback, VSCode etc. on Windows 10.

Then I generated this SDK from my simple two model LoopBack project using following command:

```
.\node_modules\.bin\lb-sdk server/server client/src/app/shared/sdk -n enabled -w enabled
```

All goes fine. But then, when trying to run `ng serve ` on my Angular CLI frontend, I get these errors:

```
ERROR in src/app/shared/sdk/effects/auth.ts(12,10): error TS2305: Module '""C:/Users/mikko/Desktop/temp/health-goal-setter/client/src/app/shared/sdk/services/index""' has no exported member 'Api'.
src/app/shared/sdk/reducers/auth.ts(4,10): error TS2305: Module '""C:/Users/mikko/Desktop/temp/health-goal-setter/client/src/app/shared/sdk/actions/index""' has no exported member 'ActionTypes'.
src/app/shared/sdk/reducers/base.ts(4,30): error TS2307: Cannot find module 'loopback-filters'.
src/app/shared/sdk/resolvers/auth-account.ts(11,45): error TS2314: Generic type 'Resolve<T>' requires 1 type argument(s).
src/app/shared/sdk/resolvers/auth-account.ts(11,52): error TS1099: Type argument list cannot be empty.
```

Again, all goes fine if I remove the -n enabled tag from the SDK generator. Is this some kind of know bug or so? 

I thought I try and build my first NGRX client as this tool seems to support it, but apparently something went wrong. I guess I'll go without NGRX for now. 

Also, is there yet any documentation on how to configure NGRX to work with this LoopBack-SDK-Builder and Angular CLI?","Also having this issue after updating to the latest version. The generated file structure is completely different. After installing missing ngrx and loopback-filters modules, I am receiving warnings on relations with through tables, and the authorization does not seem to work.",60712558
1040,Unexpected token import,open,2017-11-25T10:39:34Z,2018-04-13T15:05:13Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other: 
2.1.1


#### Please add a description for your issue:
I received following exception when I was executing the sdk builder with default settings:
```
THE MAGIC IS ABOUT TO HAPPEN ...


/home/flo/catalogs/MobilityServiceCatalog/api-main/src/common/models/mobserviceuser.js:2
import { authenticateUser, findUser } from ""../../server/boot/ldap.conf"";
^^^^^^

SyntaxError: Unexpected token import
    at createScript (vm.js:74:10)
    at Object.runInThisContext (vm.js:116:10)
    at Module._compile (module.js:533:28)
    at Object.Module._extensions..js (module.js:580:10)
    at Module.load (module.js:503:32)
    at tryModuleLoad (module.js:466:12)
    at Function.Module._load (module.js:458:3)
    at Module.require (module.js:513:17)
    at require (internal/module.js:11:18)
    at requireNodeOrEsModule (/home/flo/catalogs/MobilityServiceCatalog/api-main/node_modules/loopback-boot/lib/require.js:7:17)
    at /home/flo/catalogs/MobilityServiceCatalog/api-main/node_modules/loopback-boot/lib/executor.js:248:20
    at Array.forEach (native)
    at defineModels (/home/flo/catalogs/MobilityServiceCatalog/api-main/node_modules/loopback-boot/lib/executor.js:229:23)
    at setupModels (/home/flo/catalogs/MobilityServiceCatalog/api-main/node_modules/loopback-boot/lib/executor.js:197:3)
    at execute (/home/flo/catalogs/MobilityServiceCatalog/api-main/node_modules/loopback-boot/lib/executor.js:40:3)
    at bootLoopBackApp (/home/flo/catalogs/MobilityServiceCatalog/api-main/node_modules/loopback-boot/index.js:154:3)
```

The reason is that I`m using import statemtent (es6 with Babel) in one of the Model.js files ....

```
'use strict';
import { authenticateUser, findUser } from ""../../server/boot/ldap.conf"";
```

Anyone has a clue how to fix it and keep this es6 feature ?


Greetings,

Flo

","@fleita9 so cool you were able to fix it. I'll keep this issue open for some time, so anyone having this issue can have the reference.

Cheers
Jon",60712558
1041,Cookies not stored,open,2017-11-14T15:31:51Z,2017-11-14T15:31:51Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any: 2.1.0

#### Please add a description for your issue:

I have problems with cookie storage. I use passport and have no problems logging in using the standard recipe, but when I reload the page I lose the login. No cookies are stored with the `$LoopBackSDK` prefix. If I set up the `SDKBrowserModule` with `StorageBrowser` the data is stored in local storage and preserved on reload. Not sure if this is a bug or just me missing something obvious. I use version 2.1.0 of the SDK builder and angular 4.4.3. The app is built with the option `ng2web`.

I tried printing window.document.cookie before and after line 51 in cookie.browser.ts (https://github.com/mean-expert-official/loopback-sdk-builder/blob/master/lib/angular2/shared/storage/cookie.browser.ts#L51) and it doesn't change after it is set (and it looks strange to me that it should be set this way, but I haven't worked directly with cookies before, so not sure what to expect).

(originally posted in #198)
",,60712558
1042,Logout is reported as failure erroneously,open,2017-11-06T12:56:57Z,2017-12-01T14:04:57Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
I'm using a set of generated classes for angular2 in a nativescript application. Logging in works fine, I get the token and all is well. Logging out works fine on the server (auth_token parameter is set) and completes with status 204. At this point the client-side framework classifies the response as an error and things go pear shaped. The response coming  out the generated logout function now reads ""Server Error"", mostly because of this line in error.service.ts:

`return Observable.throw(error.json().error || 'Server error');`

However, the error must happen further up, where the 204 or the logout response in general is handled badly and qualified as an error. 




","This is an issue in the underlying Angular of Nativescript, which has just been fixed in https://github.com/angular/angular/issues/19413#event-1364101975. Hopefully that fix will hit nativescript-angular soon.",60712558
1043,ngrx docs,open,2017-11-04T19:19:18Z,2018-10-03T11:44:59Z,,NONE,"
- [x] Question

#### What version of this module are you using?
- [x] 2.1.0

#### Please add a description for your issue:

Installed the latest version, eager to use the cool ngrx features ... but can't find any docs ... am I going blind ?

:)","I've found the base problem - it's when you have a scope then you get this error.

I've fixed it by adding 

`var targetName = model.sharedClass.ctor.relations[action.name.split('__').pop()] || {}`
under `methodName = action.name.split` (line 20 of shared/effects/model.ejs) and replacing all other instances of 

`model.sharedClass.ctor.relations[action.name.split('__').pop()]` with `targetName`",60712558
1044,Custom remoteMethod with POST is generated as GET,open,2017-11-03T18:34:42Z,2017-11-22T23:26:29Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Issue:
Data which should be posted in body is appended to URL. I discovered this when server gave me 414 URI Too Long.

Details:
The generated a custom function in service/custom/Mymodel.ts has correctly _method = POST, but data which should be in _postBody is in _urlParams.","+1

I am using version number: 2.1.1
@jonathan-casarrubias
having same exact issue on our side. I manually changed the code in the generated sdk on my end. to from _postbody instead of _urlParams. 

Any updates on this issue?",60712558
1045,Custom GET/POST parameters to auto generated methods,open,2017-11-03T15:36:03Z,2018-03-26T22:33:36Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Is it possible to add custom GET/POST parameters to auto generated services ? We have an in-place redis caching that is activated with parameter ""cache : duration"" and a mixin added to the to-be cached models. Generated method include only a custom function to modify headers.","im also looking for that kind of solution

@evilsephiroth  maybe you found out something?",60712558
1046,documentation on the errorhandler,open,2017-10-31T08:43:22Z,2017-11-14T17:34:14Z,,NONE,"- [X ] Question

#### What version of this module are you using?
- [X] 2.1.0-rc.n (2.1 Release Candidate n)

Is there any documentation on how to use / reuse the errorHandler ? I'm getting errors where a token has expired, and need to redirect the user to the login, but can't quite figure out how to handle the error ;)

Do I need to write my own errorhandler and drop that into the sdk somehow ?","@jmls ok cool thanks, take a look and see if you find it doable.... Any question I'll be glad to answer.. -as soon as I can-

Cheers
Jon",60712558
1047,Public Remote method with No authorization header,open,2017-10-26T10:50:09Z,2017-11-03T13:04:01Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

We have noticed that the SDK sends Authorization Header by default in every request when users are logged. Therefore, it adds an extra time on its execution. 

So our point is: Is there a way to remove the authorization header to methods(endpoints) that do not require Authorization?

","

````js
this.myServiceApi.myRemoteMethod(MyParam1, MyParam2, (headers) => {
  // do something with headers (e.g. remove authentication)
  return headers; // Return modified headers
})
````",60712558
1048,"Implements socket ""connect_error"",""connect_failed""",open,2017-10-20T19:16:33Z,2017-11-03T12:54:51Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ x] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x ] 2.1.0-rc.13.5 (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

I'm implementing using as functions generated by the SDK, but I did not find it to find a correct way to get socket connection problems.

in the implementation of socket.connections.ts, if I am not mistaken, does not contemplate receiving errors, I had to implement at least to test the following code snippet

`public connect(token: AccessToken = null): void {
....
      this.on('connect_error',  (error) => {
        console.log('connect_error:',error);        
      });
      this.on('connect_failed',  (error) => {
        console.log('connect_failed:',error);        
      });
...
`

But as I said, I do not know if I'm doing it the right way, I can thank you for that, if I may.","@eduardoarn look for the loopback-component-realtime on this org to see the instructions to setup the real-time, it seems the backend is not configured... might be?",60712558
1049,"Generating interfaces for ""anonymous"" types in a model",open,2017-10-20T04:52:36Z,2017-11-27T21:26:01Z,,NONE,"#### What type of issue are you creating?
Enhancement

Referencing https://loopback.io/doc/en/lb3/LoopBack-types.html#object-types, LoopBack allows for type definitions in model's ""object"" properties, but the sdk builder translates those into type ""any"" on model's typescript interface

I'm opening the issue as a suggestion for improvement and a discussion as to how to handle that","Same problem when define property as other model:
```js
""property"": {
  ""user"": {
    ""type"": ""ModelNameA""
  }
}
```
SDK build property `user` as type `any`",60712558
1050,TypeError: Cannot read property 'cookies' of undefined - Angular 2 Universal,open,2017-10-12T13:27:51Z,2018-06-09T02:00:28Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:
I'm using Angular 2 (with angular-cli) Universal
#### Please add a description for your issue:
Hi, I'm trying to get my Angular 2 project to work in Universal mode.  I've read some issues here and it seems that I should be able to get this working.  Although I am not sure if my setup is fine.  I'm using:
1- Angular-cli, setup as a univesal project (works fine, it's a basic project, nothing in it and it compiles without any issue).
2- I have a loopback server and..
3- Loopback-sdk-builder, version 2.1.0-rc.13.5

My understanding is that in an Angular Universal Project, I must use SDKNodeModule has the library.  I've created a basic find() on a model but when I call it, I get the following error:

TypeError: Cannot read property 'cookies' of undefined
![screen shot 2017-10-12 at 09 25 34](https://user-images.githubusercontent.com/4528815/31498194-59c5f8d4-af2f-11e7-888b-04da2ddd5f54.png)

I know that it's a pretty particular setup using Angular Universal but according to the docs, it should work?  So I need some help on this.

Thank you for your great help!!!!","Same problem.
Deps: 
`""@mean-expert/loopback-sdk-builder"": ""~2.3.1""`
```
Angular CLI: 6.0.8
Node: 8.11.2
OS: darwin x64
Angular: 6.0.4
... animations, common, compiler, compiler-cli, core, forms
... http, language-service, platform-browser
... platform-browser-dynamic, platform-server, router

Package                           Version
-----------------------------------------------------------
@angular-devkit/architect         0.6.8
@angular-devkit/build-angular     0.6.8
@angular-devkit/build-optimizer   0.6.8
@angular-devkit/core              0.6.8
@angular-devkit/schematics        0.6.8
@angular/cdk                      6.2.1
@angular/cli                      6.0.8
@angular/flex-layout              6.0.0-beta.16
@angular/material                 6.2.1
@ngtools/webpack                  6.0.8
@schematics/angular               0.6.8
@schematics/update                0.6.8
rxjs                              6.2.0
typescript                        2.7.2
webpack                           4.8.3
```

Fixed by combination of answers from https://github.com/angular/universal-starter/issues/271

*`server.ts`*
```
// ...
app.engine('html', (_, options, callback) => {
  let engine = ngExpressEngine({
                                 bootstrap: AppServerModuleNgFactory,
                                 providers: [
                                   provideModuleMap(LAZY_MODULE_MAP),
                                   {
                                     provide: 'request',
                                     useFactory: () => Object.assign({ cookies: {} }, options.req),
                                     deps: [],
                                   },
                                   { provide: 'response', useFactory: () => options.req.res, deps: [] },
                                 ],

                               });

  engine(_, options, callback);
});
// ...
```

*`cookie.node.ts`*
```
// ...
export class CookieNode {

constructor(private injector: Injector) { }
  get(key: string) {
    let cookies: { [ key: string ]: number } = this.injector.get('request').cookies;
    return cookies[ key ];
  }

  set(key: string, value: any): any {
    this.injector.get('response')
        .cookies(key, value)
        .send('Cookie is set');
  }

  remove(key: string, value: any): any {
    this.injector.get('response')
        .cookies(key, '; expires=Thu, 01 Jan 1970 00:00:01 GMT;')
        .send('Cookie is removed');
  }

}
```

@jonathan-casarrubias pr coming soon.",60712558
1051,Generate SDK Models when set as non public,open,2017-10-05T13:50:05Z,2018-04-30T20:22:52Z,,COLLABORATOR,"#### What type of issue are you creating?
- [ ] Bug
- [X] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

https://github.com/mean-expert-official/fireloop.io/issues/122","@Miced I'm not entirely sure that the app.models() would provide all the information required since it actually provides the instance of a model... But if you are able to test it and verify all the information can be successfully gathered I would say that is acceptable.

",60712558
1052,Dynamically Loading APIs,open,2017-10-05T11:22:55Z,2017-10-05T16:21:34Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

I want to create an App Builder where the User can choose which Service to use dynamically.

What I have done so far is to import the sdk like this:
`import * as sdkloopback from '../../shared/sdk/index';`

and then in my constructor:

```
constructor(
    public test: sdkloopback.EmployeeApi
  ) {
  this.test.find()
   // This is working perfectly
}


loadDynamically() {
 
 const test2 = sdkloopback['EmployeeApi'];
 test2.find()
// this is not working

}
```

Eventually I want EmployeeApi to be a Variable that depends on what the person is clicking,","Hi @jonathan-casarrubias 
I tried that and got this error ☹️ 

```error
ERROR TypeError: Cannot read property 'get' of undefined
    at PoliklinikApi.BaseLoopBackApi (base.service.ts:44)
    at new EmpployeeApi (Employee.ts:31)
    at CrudComponent.webpackJsonp.../../../../../src/app/crud/crud.component.ts.CrudComponent.loadData (crud.component.ts:116)
    at SafeSubscriber._next (crud.component.ts:85)
    at SafeSubscriber.webpackJsonp.../../../../rxjs/Subscriber.js.SafeSubscriber.__tryOrUnsub (Subscriber.js:238)
    at SafeSubscriber.webpackJsonp.../../../../rxjs/Subscriber.js.SafeSubscriber.next (Subscriber.js:185)
    at Subscriber.webpackJsonp.../../../../rxjs/Subscriber.js.Subscriber._next (Subscriber.js:125)
    at Subscriber.webpackJsonp.../../../../rxjs/Subscriber.js.Subscriber.next (Subscriber.js:89)
    at MapSubscriber.webpackJsonp.../../../../rxjs/operator/map.js.MapSubscriber._next (map.js:83)
    at MapSubscriber.webpackJsonp.../../../../rxjs/Subscriber.js.Subscriber.next (Subscriber.js:89)
```

I also tried using `class.prototype` to add it, but it didn't succeed.",60712558
1053,"Not able to create SDK, when I have a model inherited from User.",open,2017-09-26T11:20:36Z,2017-10-05T13:22:58Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
I created a model and inherited from PersistentModel, SDK worked fine with that. Then I created a model which inherited from User base class and tried to create SDK, but it failed and resulted in the following error:

npm ERR! Windows_NT 10.0.15063
npm ERR! argv ""C:\\Program Files\\nodejs\\node.exe"" ""C:\\Program Files\\nodejs\\node_modules\\npm\\bin\\npm-cli.js"" ""run"" ""build:sdk
""
npm ERR! node v6.10.0
npm ERR! npm  v3.10.10
npm ERR! code ELIFECYCLE
npm ERR! delete@1.0.0 build:sdk: `lb-sdk server/server.js ../easy-stats-app-1/src/app/shared/sdk`
npm ERR! Exit status 1
npm ERR!
npm ERR! Failed at the delete@1.0.0 build:sdk script 'lb-sdk server/server.js ../easy-stats-app-1/src/app/shared/sdk'.
npm ERR! Make sure you have the latest version of node.js and npm installed.
npm ERR! If you do, this is most likely a problem with the delete package,
npm ERR! not with npm itself.
npm ERR! Tell the author that this fails on your system:
npm ERR!     lb-sdk server/server.js ../easy-stats-app-1/src/app/shared/sdk
npm ERR! You can get information on how to open an issue for this project with:
npm ERR!     npm bugs delete
npm ERR! Or if that isn't available, you can get their info via:
npm ERR!     npm owner ls delete
npm ERR! There is likely additional logging output above.

npm ERR! Please include the following file with any support request:
npm ERR!     C:\Users\Muhammad Aaqil\Desktop\delete\npm-debug.log
","Hi @aaqilcs102 thanks for reaching out,

Hey so... It should work fine with api-server, actually I personally never tested with the empty-server configuration..

Anyway, there is an open issue related to user based models, where if you hide the username it crashes... There is a fix for that in development, it will be published during the next version, though I'm not sure is your exact issue.

Cheers
Jon",60712558
1054,How We use Common SDK for two Apps ?,open,2017-09-26T10:48:27Z,2017-10-05T13:14:43Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Are we able to use common SDK for two Apps ?
","@Destreyf because of this topic I just found that there already is a configuration method for defining  the prefix within the LoopBackConfig, but it seems it is not connected to the LoopBackAuth, the latter always uses a hardcoded prefix, I think is just matter of connecting the config",60712558
1055,Auto logout after a period of inactivity,open,2017-09-25T12:22:44Z,2017-10-06T08:15:46Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.13.5
- [ ] Other

#### Please add a description for your issue:
Is there a way to implement a service which performs auto-logout after a period of inactivity?
The behavious is well-described here: https://blog.sstorie.com/building-an-angular-2-reactive-auto-logout-timer-with-the-redux-pattern/ , but introducing redux pattern into my application is a bit impracticable right now. 

I found this on the Loopback github: https://github.com/strongloop/loopback-sdk-angular/issues/39
which describes a way...for angular 1.

In this moment I'm trying to develop a wrapping service for auth and login for managing the redirect to the login page when the access token becomes invalid (by handling 401 error in API requests)...but I'd like to extend it also when the user stops interacting with the app for an extended period of time, both leaving open and closing the browser tab.

Any suggestion? Anyone already stepped into this issue?","Mmh, I'm not sure I didn't understand this approach, could you please explain more?",60712558
1056,Validation issue with DEFAULT USER ID = 0 -- Should be null [ mongoDB ],open,2017-09-24T05:20:32Z,2017-10-05T13:41:11Z,,NONE,"There's a poor convention in the loopback-sdk-builder for angular2 that's been stumbled upon starting a new project.

Using fireloop, and mongoDB as our datasource for loopback models.

The loopback-sdk-builder is generating new Users with an id = 0; This fails loopback validation when creating a new instance and persisting it to the database w/ mongoDB, as you cannot set ID. This is a pretty fatal flaw for a newbie looking to simply follow the example documentation on getting started as they'll be stopped by an internal validation error while trying to upsert their first new user.

Take this following Component:
```js
export class RootComponent {
  private user: User = new User({username: ""foo"", email: ""foo@bar.com"",password:""bar""});
  private UserReference: FireLoopRef<User>;

  constructor(private realTime: RealTime) {
    this.realTime.onReady().subscribe(() => { this.UserReference = this.realTime.FireLoop.ref<User>(User) });
  }
  private create(): void {
   // need to set `this.user.id = null` for this upsert to not fail validation ""id cannot be set""!
    this.UserReference.upsert(this.user).subscribe((user: User) => {console.log(user)});
  }
}
```

What's happening, is when loopback cannot find a user of id 0, it tries to create one, but with the payload of id:0 - Which then triggers the validation error ""cannot set id"". 

User IDs should not have a default value when being instantiated for the first time. You're always supposed to let the database set your id automatically on generating a new document (mongoDB).
","@luncht1me thanks for reaching out,

Hey so... By default the SDK won't generate any default value, nor an ID. There is an option though, that enables default values for models properties, this option actually has to be enabled, so it is possible you did that.

If you don't want default values to be created, then disable that option when generating the SDK.

Anyway, if you require to set defaults enabled because other atributes, well then you have 2 options.

A) set ID to null,
B) add a PR to modify id defaults.

Default values is a community contribution so technically I have never even used that feature, so if you think it can be improved, maybe a PR is the best option.

Cheers
Jon

",60712558
1057,Rest Connector method,open,2017-09-22T19:46:11Z,2017-10-05T13:34:47Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
I'm trying to use loopback as a ""middleman"" with a remote server through rest call.  For this, I use the rest connector and it works fine through the explorer.  Model is generated in the SDK, methods are created also but I am facing 2 situation where I can't get it right;
1- when I need to use FormData instead of body
2- Passing parameter into the header (like a token value for authorization).

It seems that when I specify header / formData parameters, they are passed as params in url. 
 Anyone has this implemented and working? Any work around?

Beside that, what a great library, it's been more than a year that I'm using lookback with angular.js and angular 2 client (mobile also) and it works great!!!","Hi @benlegault thanks for reaching out,

Hey so, when the SDK generates API Methods, it will try to use the remote method accepts options to know which types of parameters are we passing

````json
        accepts: [
            {
                arg: ""id"",
                type: ""string"",
                http: { source: 'query | path | body' },
                required: true
            }
}
````

If there is no found http.source configuration it will use by default the query type, which it seems it is happening for you, since I understand you are using the REST Connector, I'm not entirely sure you are able to configure the http.source for those params, I have no lots of experience using the REST Connector.

So my recommendation for you is to verify if you can configure the params http.source, so you can set that has body.

Hope this answer helps you clarify the issue.

Cheers
Jon",60712558
1058,getting a service via injector,open,2017-09-22T16:04:09Z,2017-09-22T21:40:17Z,,NONE,"- [x] Question
- [x] 2.1.0-rc.n (2.1 Release Candidate n)

I was trying to write a generic base class, where it finds an api service using angular `injector` like this

`console.log(""xxxx"",injector.get('UserApi'))`

however, I kept getting a 'no provider for UserApi!' error

turns out I need to provide a ""string"" as well

so , by default `index.ts` has

` providers : [ UserApi ... ]`

in order to get the injector working I needed to add

` providers : [ UserApi, { provide: 'UserApi', useClass: UserApi}, ... ]`

Does anyone know of any other way of achieving my goal ? - alternatively, could this design be added to the default generated index.ts ? 

","Well thinking again on this, for the REACT since it does not provide injector we took a different approach to inject the services, it actually extends a class that provides that... so maybe sharing the code won't be the ideal.

Under this last thought I believe that for angularx we might simply use its own injector by updating the index.ts
",60712558
1059,Cannot create Model,open,2017-09-21T19:02:57Z,2017-09-21T19:05:52Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

When I'm trying to create sdk with "" ./node_modules/.bin/lb-sdk server/server.js client/src/app/shared/sdk -d ng2w
eb -i enabled""

```
Generating: \client\src\app\shared\sdk/models/Developer.ts
readline.js:1015
            throw err;
            ^

TypeError: ejs:5
    3| declare var Object: any;
    4| export interface <%- modelName %>Interface {
 >> 5| <%- buildModelProperties(model, true) %>
    6| }
    7|
    8| export class <%- modelName %> implements <%- modelName %>Interface {

Cannot read property 'type' of undefined
    at Object.buildModelProperties (\node_modules\@mean-expert\loopback-sdk-builder\lib\angular2\index.js:390:40)
    at eval (eval at exports.compile (\node_modules\@mean-expert\loopback-sdk-builder\node_modules\ejs\lib\ejs.js:242:14), <anonymous>:30:204)
    at eval (eval at exports.compile (\node_modules\@mean-expert\loopback-sdk-builder\node_modules\ejs\lib\ejs.js:242:14), <anonymous>:30:2632)
    at \node_modules\@mean-expert\loopback-sdk-builder\node_modules\ejs\lib\ejs.js:255:15
    at Object.exports.render (\node_modules\@mean-expert\loopback-sdk-builder\node_modules\ejs\lib\ejs.js:293:13)
    at schema.forEach.config (\node_modules\@mean-expert\loopback-sdk-builder\lib\angular2\index.js:335:13)
    at Array.forEach (native)
    at Object.generate [as angular2] (\node_modules\@mean-expert\loopback-sdk-builder\lib\angular2\index.js:327:10)
    at runGenerator (\node_modules\@mean-expert\loopback-sdk-builder\bin\lb-sdk:163:31)
    at rl.question (\node_modules\@mean-expert\loopback-sdk-builder\bin\lb-sdk:144:13)
    at Interface._onLine (readline.js:276:5)
    at Interface._line (readline.js:625:8)
    at Interface._ttyWrite (readline.js:904:14)
    at ReadStream.onkeypress (readline.js:157:10)
    at emitTwo (events.js:125:13)
    at ReadStream.emit (events.js:213:7)
```

My model JSON:
```
{
  ""name"": ""Developer"",
  ""base"": ""User"",
  ""excludeBaseProperties"": [
	""realm"", ""username""
  ],
  ""idInjection"": true,
  ""restrictResetPasswordTokenScope"": true,
  ""emailVerificationRequired"": false,
  ""validations"": [],
  ""relations"": {},
  ""strict"": true,
  ""acls"": [
    {
      ""principalType"": ""ROLE"",
      ""principalId"": ""$everyone"",
      ""accessType"": ""READ"",
      ""permission"": ""ALLOW""
    }
  ],
  ""properties"": {
    ""username"": {
      ""type"": ""string"",
      ""required"": true,
      ""index"": true,
      ""id"": true
    },
    ""description"": {
      ""default"": """",
      ""type"": ""string""
    },
    ""enabled"": {
      ""default"": true,
      ""type"": ""Boolean""
    },
    ""locked"": {
      ""default"": false,
      ""type"": ""Boolean""
    }
  },
  ""mixins"": {
    ""TimeStamp"" : true
  },
  ""methods"": []
}
```
",It looks like duplicate of  #478 ,60712558
1060,HttpClient instead of Http,open,2017-09-17T19:13:53Z,2018-10-16T14:08:43Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

Is there any plan to use HttpClient instead of simple Http in order to intercept requests and responses?

> https://angular.io/guide/http#intercepting-all-requests-or-responses","@jonathan-casarrubias 
Hey, great news!

Any reason why there is no official release yet? Currently I'd have to sit on the master branch or a specific commit hash..

Cheers,
Rob",60712558
1061,child_added returns the first 100 elements,open,2017-09-17T11:45:50Z,2017-09-17T12:03:53Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.13.5 (2.1 Release Candidate 13.5)
- [ ] Other

Write other if any:

#### Please add a description for your issue:


Using FireloopApi for real-time events, the ""child_added"" event on any model returns the first 100 elements of the model instead of the added element like stated in the docs:

> This event will fire once for each persisted items and will keep firing when new values are added in the current Model Reference, returning only the newly created child element

Also, it is not fired once but for each element returned up to 100. Therefore if there are 10 elements it will fire 10 times.
Thank you for your fantastic job!",,60712558
1062,SDK Compatible with React (Milestone),open,2017-09-13T16:33:11Z,2017-09-13T16:33:11Z,,COLLABORATOR,"#### What type of issue are you creating?
- [ ] Bug
- [X] Enhancement
- [ ] Question

#### Please add a description for your issue:

We are officially starting to work on the react SDK withing the following PRs:

PR1: https://github.com/mean-expert-official/loopback-sdk-builder/pull/494",,60712558
1063,Shouldn't observables returned by an api be hot by default?,open,2017-09-11T17:59:51Z,2017-09-11T17:59:51Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [X ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ X] 2.1.0-rc.13.2
- [ ] Other

Write other if any:

#### Please add a description for your issue:

I'm new to reactive programming and I've just bumped into an issue that probably you might have already noticed.

Subscribing more than once to an observable returned by an api call makes that api call get executed more than once (once per subscriber). This can be an undesirable side effect when calling an api to make changes and also a performance issue when just making queries because it could cause an api to make the same request for every subscriber.

I've solved it by adding `.share()` before subscribing or doing anything with an observable returned from an api call. That way I can subscribe as many times as needed without having the api make more the same request more than once.

Btw, I'm coming from Angular 1.5 and I have to say you've done a great work, this is a great replacement for the official sdk generator.

Thanks,
Mariano.

",,60712558
1064,Shorthand route parameters added incorrectly to service method (with workaround),open,2017-09-05T16:08:57Z,2017-09-05T16:08:57Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [X] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:
@mean-expert/loopback-sdk-builder@2.1.0-rc.13.5

#### Please add a description for your issue:

Note, **non-critical**, as explicitly defining the argument with ""http: {source: 'path'}"" will make it work correctly. But it should ideally support the same shorthand as Loopback does.

Shorthanded route parameters (source not explicitly defined) for custom remote methods are not correct added to the models service definition. 

eg:
```
Screen.remoteMethod('login', {
    accepts: {arg: 'uuid', type: 'string', required: true, description: 'The UUID of the screen'},
    returns: {arg: 'returnVal', type: 'object', root: true},
    http: {verb: 'get', path: '/:uuid/login/'}
  });
```

results in:
```
public login(uuid: any, customHeaders?: Function): Observable<any> {
    let _method: string = ""GET"";
    let _url: string = LoopBackConfig.getPath() + ""/"" + LoopBackConfig.getApiVersion() +
    ""/Screens/:uuid/login/"";
    let _routeParams: any = {};
    let _postBody: any = {};
    let _urlParams: any = {};
    if (typeof uuid !== 'undefined' && uuid !== null) _urlParams.uuid = uuid;
    let result = this.request(_method, _url, _routeParams, _urlParams, _postBody, null, customHeaders);
    return result;
  }
```

resulting in a call syntax: 
[API_ROOT]/Screens/:uuid/login/?uuid=[uuid]
where ""/:uuid/"" is written as part of the static path and the passed uuid parameter is passed as a urlparam.

Interestingly however, is that if I rename the parameter to ""id"" or ""fk"", then it works as expected, so presumably, the parameters ""id"" and ""fk"" are hardcode-identified as being routeparams, presumable to match this exact shorthand syntax in the Loopback native code. 

Workaround for the example above:
```
Screen.remoteMethod('login', {
    accepts: {
      arg: 'uuid', 
      type: 'string', 
      required: true, 
      description: 'The UUID of the screen', 
      http: {source: 'path'}
    },
    returns: [
      {arg: 'returnVal', type: 'object', root: true}
    ],
    http: {verb: 'get', path: '/:uuid/login/'}
  });
```",,60712558
1065,catching 401 errors,open,2017-08-31T19:31:43Z,2018-07-14T18:25:52Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

I am trying to move from a jwt-based auth system to using standard loopback auth with passport and a local strategy

Whilst the backend is working (I can log in with explorer and access the api) I'm not entirely sure how to go about integrating this into my angular4 app

So, I login, get this data back .. 

```
{
  ""id"": ""TBEauxIDQlLMlnKXsiH6ssf6FOFT4KjugoEOeQ67tfx2pK4IcoH03SwQPmmyc9eN"",
  ""ttl"": 1209600,
  ""created"": ""2017-08-31T19:09:23.189Z"",
  ""userId"": 2
}
```
how do I a) save it, and b) send it with every request ?

Another , related topic - if I am *not* logged in and the app tries to make an api call using the base .find() I (obviously) get a 401 . How can I be notified of this 401 and force a login ?",any answer ?,60712558
1066,use one common loopback-sdk-builder for both ionic and angular (for admin desktop)folders in same project.,open,2017-08-23T14:55:36Z,2017-08-23T15:14:39Z,,NONE,"#### What type of issue are you creating?
- [ ] Question


Write other if any:

I just started hybrid mobile project with ionic 2 + loopback sdk in which i will use angular 2 for admin (desktop version). There is attached screenshot of my project structure,
where client is my angular project , client-ionic is for ionic  and in same directory  path i installed my loopback-sdk under shared folder by """"build:sdk"": ""./node_modules/.bin/lb-sdk server/server.js ./shared"""". because i want to use same lb-sdk for both angular and ionic folders .
As now loopback sdk is installed out of angular(client)folder there is error in  files as it does not detect angular packages. 

**my question is** :- is it possible to  share one loopback-sdk for both ionic and angular. or i need to install differently in each ionic(by ng2web) and angular(by ngUniversal) folders. 
will it good for production if i install loopback-sdk separately in client and client-ionic folder?
what are the best practices to use in my scenario? 
Please advise me .

**Also is there any example which i can follow  for ionic 2 + loopback** similar as https://strongloop.com/strongblog/part-1-ionic-loopback-node-js-mobile/?utm_source=hashnode.com, as this example was for ionic 1 on official liioback site.

Thanks in advance !!

![loopback-sdk-issue](https://user-images.githubusercontent.com/6635819/29621889-f5e8a764-87ef-11e7-853e-041df1c675df.png)

",,60712558
1067,SDK Builder fails when hiding username from User model extension,open,2017-08-16T15:08:56Z,2017-09-11T11:05:21Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [x] 2.0.10 (Stable)
- [x] 2.1.0-rc.13
- [x] 2.1.0-rc.9

#### Please add a description for your issue:

I get an error for both 2.0.10 and 2.1.0-rc.13.4 but **not** 2.1.0-rc.9, where the SDK fails to build with the following error message:

~~~
...
Generating: ..../src/app/shared/sdk/models/Person.ts
readline.js:982
            throw err;
            ^

TypeError: ejs:5
    3| declare var Object: any;
    4| export interface <%- modelName %>Interface {
 >> 5| <%- buildModelProperties(model, true) %>
    6| }
    7|
    8| export class <%- modelName %> implements <%- modelName %>Interface {

Cannot read property 'type' of undefined
    at Object.buildModelProperties (..../node_modules/@mean-expert/loopback-sdk-builder/lib/angular2/index.js:390:40)
    at eval (eval at <anonymous> (..../node_modules/@mean-expert/loopback-sdk-builder/node_modules/ejs/lib/ejs.js:242:14), <anonymous>:30:204)
    at eval (eval at <anonymous> (..../node_modules/@mean-expert/loopback-sdk-builder/node_modules/ejs/lib/ejs.js:242:14), <anonymous>:30:2632)
...
~~~

I managed to pin down what triggers the error in my code: I extend the Loopback User model with a model called Person. If I add the line `""hidden"": [""username""]` to the model configuration, building the SDK fails, otherwise not. If I hide email instead, building the SDK succeeds.
",I have the same problem!!!!,60712558
1068,Use loopback-sdk-builder for web and ionic at same time,open,2017-08-16T01:03:35Z,2017-08-22T14:53:16Z,,NONE,"#### What type of issue are you creating?
- [ ] Question

#### What version of this module are you using?
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)

Write other if any:

#### Please add a description for your issue:
Hi everybody, 
here I send you my architecture. I plan to build an app with ionic but want to make an admin page for desktop. For that I have 2 folders client-ionic from where the sdk builder is linked, but i want to access to my back end model also on the Client folder which is an ng project. Is that possible or how you do when you need to do that kind of things?
Thank you
![questions](https://user-images.githubusercontent.com/11187383/29343124-1c2d3c8a-81fd-11e7-8419-4ecbbcdc0ef3.png)
","@favrePoupou that seems to be fine, just make sure your sdk-client is actually an angular universal environment, if this is the case then everything seems to be fine, if you are not using angular universal, well the SDK will contain a footprint of code related to universal that might not be used at all..",60712558
1069,Export SDK builder as an NPM package (à la swagger-codegen),open,2017-08-14T21:06:29Z,2017-08-22T14:28:24Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [X] Enhancement
- [ ] Question

#### What version of this module are you using?
- [X] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

First of all, thanks a lot for your work here, this SDK is saving us tons of work in our development of our website :) It surely comes handy when having to connect an Angular website to a Loopback API.

So, mostly, we have realized that even generating new versions of the SDK is easy, it makes it a bit clumpsy to manage different versions or to update the SDK in our Angular project. The problem comes from that the generated SDK is eventually a library, so it would make sense to have it in its own NPM package (or in defect use git modules, but well, why use them when we have a good package manager in node!?)

So, mostly the proposed feature able to create an NPM package with this SDK builder: thus, we could share the module in NPM and even make it as an open library for anyone wanting to use our API from an Angular site. Also, it's easier to switch versions for our developers and to archive/manage older versions, rather than having to copy the sdk folder into the project. Maybe something like they do in swagger-codegen, where you can provide the version, name, and different NPM parameters of the package would be enough for this :)

I know it's some extra work, but definitely, we are quite sure it would be great to be able to package such a library, and more if this would be integrated with the step of generating the SDK. If needed, and if I got some indications I wouldn't have any problem on working in a pull request with this feature :) Again, thanks a lot!","Hi @Sturgelose thanks for reaching out,

Hey so.. publishing the SDK would not be as easy as just adding a package.json on the root of the sdk directory.

A NPM package should not contain .ts files, we mustn't fragment the the code on NPM between JS and TS.

Said that, in order to achieve the ability to publish the SDK, we would need to add functionality to compile the result SDK into JS Files, and then it should automatically create a declaration file .d.ts and then create and configure a package.json.

As I'm saying there is a solution for that, but is not straight forward, though is possible without any refactor, is matter of adding those new functionalities and we would be able to achieve this goal.

I do think the SDK scaled so much that now it does make more sense to be a node module than part of the application, but that was not originally intended so I will keep this issue open and I will close others related in favor of this due the detailed explanation.


Cheers
Jon

",60712558
1070,SDKNodeModule has no exported member / angular issue,open,2017-08-11T14:03:18Z,2017-08-11T20:14:12Z,,NONE,"#### What type of issue are you creating?
- [ ] Question

#### What version of this module are you using?

- [ ] 2.1.0-rc.n (2.1 Release Candidate n)


Write other if any:

#### Please add a description for your issue:
Hi,
**## Those are my client configuration:**
{
  ""name"": ""hello-world"",
  ""version"": ""0.0.0"",
  ""license"": ""MIT"",
  ""scripts"": {
    ""ng"": ""ng"",
    ""start"": ""ng serve"",
    ""build"": ""ng build"",
    ""test"": ""ng test"",
    ""lint"": ""ng lint"",
    ""e2e"": ""ng e2e""
  },
  ""private"": true,
  ""dependencies"": {
    ""@angular/animations"": ""^4.0.0"",
    ""@angular/common"": ""^4.0.0"",
    ""@angular/compiler"": ""^4.0.0"",
    ""@angular/core"": ""^4.0.0"",
    ""@angular/forms"": ""^4.0.0"",
    ""@angular/http"": ""^4.3.3"",
    ""@angular/platform-browser"": ""^4.0.0"",
    ""@angular/platform-browser-dynamic"": ""^4.0.0"",
    ""@angular/router"": ""^4.0.0"",
    ""bootstrap"": ""^3.3.7"",
    ""core-js"": ""^2.4.1"",
    ""rxjs"": ""^5.4.1"",
    ""zone.js"": ""^0.8.14""
  },
  ""devDependencies"": {
    ""@angular/cli"": ""1.2.5"",
    ""@angular/compiler-cli"": ""^4.0.0"",
    ""@angular/language-service"": ""^4.0.0"",
    ""@types/jasmine"": ""~2.5.53"",
    ""@types/jasminewd2"": ""~2.0.2"",
    ""@types/node"": ""~6.0.60"",
    ""@types/socket.io-client"": ""^1.4.29"",
    ""codelyzer"": ""~3.0.1"",
    ""jasmine-core"": ""~2.6.2"",
    ""jasmine-spec-reporter"": ""~4.1.0"",
    ""karma"": ""~1.7.0"",
    ""karma-chrome-launcher"": ""~2.1.1"",
    ""karma-cli"": ""~1.0.1"",
    ""karma-coverage-istanbul-reporter"": ""^1.2.1"",
    ""karma-jasmine"": ""~1.1.0"",
    ""karma-jasmine-html-reporter"": ""^0.2.2"",
    ""protractor"": ""~5.1.2"",
    ""ts-node"": ""~3.0.4"",
    ""tslint"": ""~5.3.2"",
    ""typescript"": ""~2.3.3""
  }
}

**## My server configuration:**
{
  ""name"": ""back"",
  ""version"": ""1.0.0"",
  ""main"": ""server/server.js"",
  ""engines"": {
    ""node"": "">=4""
  },
  ""scripts"": {
    ""lint"": ""eslint ."",
    ""start"": ""node ."",
    ""posttest"": ""npm run lint && nsp check"",
    **""build:sdk"": ""./node_modules/.bin/lb-sdk server/server client/src/app/shared/sdk""**
  },
  ""dependencies"": {
    ""@angular/http"": ""^4.3.3"",
    ""@mean-expert/loopback-component-realtime"": ""^1.0.0-rc.9.4"",
    ""@mean-expert/loopback-sdk-builder"": ""^2.1.0-rc.13.2"",
    ""compression"": ""^1.0.3"",
    ""cors"": ""^2.5.2"",
    ""helmet"": ""^1.3.0"",
    ""loopback"": ""^3.0.0"",
    ""loopback-boot"": ""^2.6.5"",
    ""loopback-component-explorer"": ""^4.0.0"",
    ""loopback-connector-mongodb"": ""^1.18.1"",
    ""serve-favicon"": ""^2.0.1"",
    ""socket.io-client"": ""^2.0.3"",
    ""strong-error-handler"": ""^2.0.0""
  },
  ""devDependencies"": {
    ""eslint"": ""^3.17.1"",
    ""eslint-config-loopback"": ""^8.0.0"",
    ""nsp"": ""^2.1.0""
  },
  ""repository"": {
    ""type"": """",
    ""url"": """"
  },
  ""license"": ""UNLICENSED"",
  ""description"": ""back""
}

In my app.module.ts when i try to add 
> import { SDKNodeModule } from './shared/sdk/index';
as described in the doc, it says that it has not exported member SDKNodeModule .
When I go inside the index, there is nothong about it.
In your github repo (https://github.com/mean-expert-official/loopback-sdk-builder/blob/master/lib/angular2/shared/index.ejs) Line 71 you have it, should i mostly use yours ?

Also,  my shared/sdk was perfectly created with all the services and modules but i am not able to use my import of collection to access to it from my front side, maybe due to those issue that i was explaining or is that possible that it works fine only with the angular2 and not what i am using ( angular4 ) ?

On adding some parameters on my build:sdk in package.json ( ""build:sdk"": ""./node_modules/.bin/lb-sdk server/server client/src/app/shared/sdk **-d [ ng2web | ng2universal] -i [enabled | disabled]**""

It displays that 
![build_error](https://user-images.githubusercontent.com/11187383/29219371-d63882b8-7e85-11e7-91a2-6e976a17e1ae.png)

","Thank you very much Jon,
now i am able to import the SDKNodeModule but still have some other problem to access to my data.
I don't know if I should create another ticket for that but I ask it to you because I think it may be related again to my configuration.
My Mongo database is connected ,i used lb datasource for that (localhost). Then i created models on lb model.
I use the loopback /explorer to see what inside and also robomongo to double check
On my /common/models , I have my .js and .json file so everything is right.
I try to access from component and also back end to my data but i just can do it on event listener from back as describe in this picture

![build_error](https://user-images.githubusercontent.com/11187383/29229433-5b180f78-7eac-11e7-961f-9541c92a36b1.png)

The afterRemote is working fine, means when i add some value on /explorer to the Hello collections, the hook is retrieving the event in my common/models/hello.js and he is showing my console perfectly as the new value I've just added.
But i'm not able to do CRUD simple operation as find or create. You can see it on the picture below the hook, i put it inside a function called dede() and it is exactly executed but i have some error like this:
![build_error](https://user-images.githubusercontent.com/11187383/29229586-3605add4-7ead-11e7-9ac8-6bd671a5b7dc.png)

The same thing from my front side, I am not able to make some crud operation:

![build_error](https://user-images.githubusercontent.com/11187383/29230199-e45c6c0e-7eaf-11e7-8c0f-78a3268954c8.png)

This is my front end result:
 
![build_error](https://user-images.githubusercontent.com/11187383/29230015-18e2e60c-7eaf-11e7-8790-39d9d1b127c6.png)
",60712558
1071,Remote methods interpreted query object different,open,2017-06-28T14:48:18Z,2017-08-22T14:53:42Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ ] 2.1.0-rc.n (2.1 Release Candidate n)
- [x] Other

Write other if any:
The newest version: 2.1.0-rc12.1
#### Please add a description for your issue:

Hello, 

When I use a remote method and I send the whole query object which looks like this: 
![Image of query object ind dev. tools console](https://puu.sh/wwr8I/ea36e29aaf.png)

The query is retrieved in the LoopBack application and the object is interpreted like this: 
```
{
   ""order"": ""id ASC"",
   ""limit"": 10,
   ""skip"": ""0"",
   ""where"": {
     ""and"": [
       {
         ""status"": ""Completed"",
         ""processData.city"": ""zwolle""
       },
       {
         ""or"": [
           {
             ""[displayId][like]"": "".*a.*"",
             ""[displayId][options]"": ""i""
           },
           {
             ""[deliverTime][like]"": "".*a.*"",
             ""[deliverTime][options]"": ""i""
           }
           ....
         ]
    }]
}
```

I don't have this problem when I use base functions like `find()`

The remote method looks like this: 
```
	Order.remoteMethod(
		'getCityOrders', {
			http: {
				path: '/getCityOrders',
				verb: 'get'
			},
			description: 'Get all orders made within a certain city with a specific status',
			accepts: [
				{
					arg: 'query',
					type: 'object',
					description: 'The whole LoopBack filter object'
				},
				{
					arg: 'fields',
					type: 'object',
					description: 'The fields to retrieve'
				},
				{
					arg: 'city',
					type: 'string',
					description: 'The city of which to get the orders from'
				}
			],
			returns: {
				arg: 'orders',
				type: ['Order'],
				root: true
			}
		}
	);
```

I just want to retrieve the object like I send to the application. Can someone help me?

Kinds regards,
Meindert Romkes","@MeindertRomkes thanks for reaching out...

Hey so, that is a weird behaviour I'll need to verify... But if you say the built in find, works just fine... Then you just need to change your ""query"" parameter name to ""filter"", re-generate the SDK and should work.

````js
	Order.remoteMethod(
		'getCityOrders', {
			http: {
				path: '/getCityOrders',
				verb: 'get'
			},
			description: 'Get all orders made within a certain city with a specific status',
			accepts: [
				{
					arg: 'filter',
					type: 'object',
					description: 'The whole LoopBack filter object'
				},
				{
					arg: 'fields',
					type: 'object',
					description: 'The fields to retrieve'
				},
				{
					arg: 'city',
					type: 'string',
					description: 'The city of which to get the orders from'
				}
			],
			returns: {
				arg: 'orders',
				type: ['Order'],
				root: true
			}
		}
	);
```` 

BTW, not sure about your requirements or business logic, but usually the fields operator is part of the filter... you are setting a second parameter name fields, which I believe is unnecessary... but I'm might be wrong by ignoring the project context.

````json
{
   ""order"": ""id ASC"",
   ""limit"": 10,
   ""skip"": ""0"",
   ""fields"": [""field1"", ""field2"", ""field3""],
   ""where"": {
      ...
    }
}
````

Regards
Jon",60712558
1072,Cookies don't persist after session close.  Even if Remember Me flag set.,open,2017-06-03T17:59:04Z,2017-08-24T20:01:05Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [x ] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x ] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

#### Please add a description for your issue:

From my app, I'm calling the service User.ts `login` function, passing in the appropriate credentials, and ""true' for the rememberMe boolean value.  This does create cookies for my session, however, there is no ""expires"" key for the cookie, so the cookies aren't remembered after the browser closes.

The auth.service.ts `persist` method will pass on only two parameters (key and value) to the storage `set` value.  However, cookie.browser.ts will only set the ""expires"" key for the cookie if a third optional Date is passed into set.  Thus,  the cookies that are created, will only persist through the browser session since there is no ""expire"" flag.

Unless I'm missing something; which is possible.","@nitheshsd123 You will have to install the development branch until the next version release.
`npm install https://github.com/mean-expert-official/loopback-sdk-builder.git#development`

edit: what @jonathan-casarrubias said :)",60712558
1073,ngdocs Error,open,2017-04-27T15:28:56Z,2017-05-03T15:49:54Z,,NONE,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [X] 2.1.0-rc.10
- [ ] Other

Hello, sory for my bad English...

ngDocs return error when generating docs because some @returns doesn't have brackets : 
@returns object => @returns {object}

In ""services/custom/User.ts"" : getCurrent() for example.

Returned error :
Error: Not a valid 'returns' format: object An empty reference that will be
populated with the actual data once the response is returned",,60712558
1074,Remove references to Angular 2 in favor of Angular ,open,2017-04-08T04:29:13Z,2017-04-11T15:33:52Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [x] Enhancement

#### What version of this module are you using?
- [x] GitHub Master

#### Please add a description for your issue:

Throughout the codebase there are references to Angular 2. Since we all know that `It's just Angular` I think we should rename them.

I'm happy to send in a PR, I'd like to use this issue to make sure we're using the right references.

My suggestion is to rename the references as follows:

```
Currently       Option 1             Option 2
-------------------------------------------------
Angular 2       Angular              Angular
NG2Finder       AngularFinder        NgFinder
Ng2webPage      AngularwebPage       NgWebPage
angular2        angular              angular
ng2finder       angular-finder       ng-finder
ng2native       angular-native       ng-native
ng2native 2     angular-native       ng-native
ng2universal    angular-universal    ng-universal
ng2web          angular-web          ng-web
```

CC @jonathan-casarrubias @kattsushi Option 1 or 2?","@beeman yes these are the only public commands that might break the projects.

I believe **option 1 is going to be best**, if we add react support, it would be odd to completely write react, but a shortener for angular, same example for other frameworks.

Also, choosing the actual name is less probable that we will need to change that again in a future.

Regards
Jon
",60712558
1075, Model with hasMany/belongsTo relation to itself,open,2017-04-07T16:59:06Z,2017-06-13T20:43:11Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [x] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [ x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:
I have a model that must have a model.parent and a model.children relation: 

> {
  ""name"": ""comment"",
  ""plural"": ""comments"",
  ""base"": ""PersistedModel"",
  ""idInjection"": true,
  ""options"": {
    ""validateUpsert"": true
  },
  ""properties"": {
    ""text"": {
      ""type"": ""string"",
      ""required"": true
    }
  },
  ""validations"": [],
  ""relations"": {
    ""parent"": {
      ""type"": ""belongsTo"",
      ""model"": ""comment"",
      ""foreignKey"": ""parentId""
    },
    ""replies"": {
      ""type"": ""hasMany"",
      ""model"": ""comment"",
      ""foreignKey"": ""parentId""
    },
    ""owner"": {
      ""type"": ""belongsTo"",
      ""model"": ""member"",
      ""foreignKey"": ""memberId""
    },
    ""project"": {
      ""type"": ""belongsTo"",
      ""model"": ""project"",
      ""foreignKey"": ""projectId""
    }
  },
  ""acls"": [],
  ""methods"": {}
}

This does not compile in Angular:
ERROR in /Users/hanseilers/fundr/client/src/app/shared/sdk/models/Comment.ts (3,3): Individual declarations in merged declaration 'Comment' must be all exported or all local.
/Users/hanseilers/fundr/client/src/app/shared/sdk/models/Comment.ts (3,3): Import declaration conflicts with local declaration of 'Comment'
/Users/hanseilers/fundr/client/src/app/shared/sdk/models/Comment.ts (21,14): Individual declarations in merged declaration 'Comment' must be all exported or all local.

ERROR in /Users/hanseilers/fundr/client/src/app/shared/sdk/services/custom/Comment.ts (13,10): Duplicate identifier 'Comment'.
/Users/hanseilers/fundr/client/src/app/shared/sdk/services/custom/Comment.ts (15,10): Duplicate identifier 'Comment'.

Versions used on the server: 
    ""@mean-expert/loopback-component-realtime"": ""^1.0.0-rc.4"",
    ""@mean-expert/loopback-sdk-builder"": ""^2.1.0-rc.9"",
    ""loopback"": ""^3.2.1"",
    ""loopback-boot"": ""^2.6.5"",

Client: 
    ""@angular/common"": ""^4.0.0"",
    ""@angular/compiler"": ""^4.0.0"",
    ""@angular/core"": ""^4.0.0"",
    ""@angular/forms"": ""^4.0.0"",
    ""@angular/http"": ""^4.0.0"",
    ""@angular/platform-browser"": ""^4.0.0"",
    ""@angular/platform-browser-dynamic"": ""^4.0.0"",
    ""@angular/router"": ""^4.0.0"",
    ""core-js"": ""^2.4.1"",
    ""rxjs"": ""^5.1.0"",
    ""zone.js"": ""^0.8.4""

Any help greatly appreciated.","Wonderful, I'll verify if there is something I can do to fix the issue from this side, but I really believe you all should follow the convention for model names, which is camel cased..

I'm glad it worked, we have a clue now!!!

Cheers
Jon",60712558
1076,Add support for Ionic Storage,open,2017-03-27T14:53:07Z,2018-08-17T06:11:29Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [X] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [X] 2.1.0-rc.9 (2.1 Release Candidate n)
- [ ] Other

#### Please add a description for your issue:
In Ionic 2, it is beneficial to use [Ionic Storage](https://ionicframework.com/docs/v2/storage/) for storing the current user, since it allows for more consistent storage and does not get removed if the mobile device has low memory etc.

However, this does not seem to work with the SDK builder, since the SDK builder relies on a synchronous local storage, and Ionic Storage is asynchronous.

I have created a repo to reproduce the error:
[https://github.com/DFranch/lb-sdk-ionic-storage](https://github.com/DFranch/lb-sdk-ionic-storage)

**How to reproduce with the demo repo**
1. Run the initial setup (see [https://github.com/DFranch/lb-sdk-ionic-storage/blob/master/README.md](https://github.com/DFranch/lb-sdk-ionic-storage/blob/master/README.md))
2. Click ""Get projects""
    - Throws a 401 error
3. Click ""Login""
    - Should login and store in WebSQL storage using Ionic Storage
6. Click ""Get Projects""
    - Should give two projects
7. Refresh the page
    - 8. The info is still stored in the WebSQL
8. Click ""Get Projects""
9. **It throws 401, but should throw 200 since the user details are stored locally**

This might also be related to #378, in order to store current user in an Ionic 2 app.

Just let me know if any elaboration is needed 👍 

","Is there roadmap for adding this as part of official SDK Builder.

If not can you please?

@Strongloop Management
 Please consider this to be added particularly for LoopBack 3.0",60712558
1077,Generate Sub Interface of Nested Model,open,2017-03-25T09:41:30Z,2017-04-04T17:35:10Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [ ] Enhancement
- [* ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [*] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:
Loopback profile.json properties:
`""properties"": {
    ""gender"": {
      ""type"": ""string""
    },
    ""address"": {
      ""line1"": ""string"",
      ""line2"": ""string"",
      ""city"": ""string"",
      ""pincode"": ""number"",
      ""state"": ""string"",
      ""country"": ""string""
    }
  },`

after command ""npm run build:sdk"" generated profile.ts model file interface looks like:

`export interface ProfileInterface {
  gender?: string;
  panNumber?: string;
  address?: any;
  bank?: any;
  documents?: any;
  id?: any;
  userId?: any;
  user?: User;
}`

how can i find below type profile model:

`export interface AddressInterface {
  line1?: string;
  line2?: string;
  city?: string;
  pincode?: number;
  state?: string;
  country?: string;
}
export interface ProfileInterface {
  gender?: string;
  panNumber?: string;
  address?: AddressInterface;
  bank?: any;
  documents?: any;
  id?: any;
  userId?: any;
  user?: User;
}`

#### Please add a description for your issue:","@rajweb nested types are not supported just yet, the only way the SDK will type your properties, is either because you use a native type or because it is a relationship...

Though we might add support in a future, the Object Types are kind of a new implementation and we are moving forward to support all of these new features.

Cheers
Jon",60712558
1078,Objects & URL Params toJSON (Date Objects),open,2017-03-23T21:06:20Z,2017-09-07T15:07:46Z,,CONTRIBUTOR,"#### What type of issue are you creating?
- [X] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [X] 2.1.0-rc.9 (2.1 Release Candidate n)
- [ ] Other

#### Please add a description for your issue:

When using an object, such as a date, the system fails to convert it for usage as a query string.

I think the ideal way to handle this, is that if an object has a ""toJSON"" operator, we should call it.  The date object has this, this also allows users to use custom objects and implement their own ""toJSON"" handlers that can allow the values to be converted to a ""friendly"" format.

the Date object for example returns the string notation that is compliant with json format.

The easiest way to check for this is to change the code responsible when evaluating an object.

eg:
```ts
@Injectable()
export class JSONSearchParams {
    ...
    private _parseParam(key: string, value: any, parent: string) {
        let processedKey = parent ? parent + '[' + key + ']' : key;
        if (value && (<string>(typeof value) === 'object' || Array.isArray(value))) {
            if(<string>(typeof value) === 'object' && <string>typeof(value.toJSON) === 'function'){
                return processedKey + '=' + value.toJSON()
            } else {
                return this._JSON2URL(value, processedKey);
            }
        }
        return processedKey + '=' + value;
    }
```",Any news on this issue?,60712558
1079,Custom methods wrong parameter service function,open,2017-02-13T06:17:23Z,2017-02-24T15:43:54Z,,NONE,"#### What type of issue are you creating?
- [ ] Bug
- [X] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [X] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

I've created a custom method with two params:

1- accessToken: To be retrieved from the headers
2- projectId: To be retrieved from the body

The generated service method equivalent to that endpoint requires wrongly two parameters to be provided and send them both in the body, which is wrong.
I guess when parsing the required params, there is not discrimination over the type of parameters they are.

","I don't remember me personally working in something that allows you to pass parameters through headers decided in custom methods, nor I received a pull request for this. So I don't think this is right now supported.

What is doing now is only passing through headers the filter, if any... And does the where filter but I don't think is a good idea since led to several issues.

But right now the SDK supports query, route and body params. Adding support for custom headers won't be so straight forward as changing a line of code.

Also I don't consider this a bug, since this was introduced in LoopBack 3, originally you would not be able to map an argument to the headers.

http://loopback.io/doc/en/lb3/Remote-methods.html#http-mapping-of-input-arguments.

I will add the enhancement label instead
",60712558
1080,EmbedsOne relation generates duplicate properties and array instead of singleton,open,2017-02-02T14:13:44Z,2017-02-03T10:41:55Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.n (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue:

When using ""embedsOne"" relation in loopback. The builder generates a duplicate property in the Angular class/interface with type any. Also the correct property generated is an array instead of a single instance.

loopback json:

```
""relations"": {
    ""address"": {
      ""type"": ""embedsOne"",
      ""model"": ""Address"",
      ""property"": ""address"",
      ""options"": {
        ""validate"": true,
        ""forceId"": false
      }
    }
 }
```

generated interface and class in Angular:

```
export interface HouseInterface {
  id?: string;
  _tenant?: any;
  _address?: any;
  tenant?: Tenant[];
  address?: Address[];
}

export class House implements HouseInterface {
  id: string;
  _tenant: any;
  _address: any;
  tenant: Tenant[];
  address: Address[];
```

Not sure if this is intended but I would expect:

```
export interface HouseInterface {
  id?: string;
  tenant?: Tenant;
  address?: Address;
}

export class House implements HouseInterface {
  id: string;
  tenant: Tenant;
  address: Address;
```



",Hij @jonathan-casarrubias thanks for the update. Will keep that in mind.,60712558
1081,Feat: NGRX generator,open,2017-01-31T19:47:37Z,2017-09-11T18:58:21Z,,MEMBER,"#### What type of issue are you creating?
- [ ] Bug
- [x] Enhancement
- [ ] Question

#### Please add a description for your issue:

Enhance sdk-builder to generate ngrx actions, effects and reducers.

The idea is to keep all services as is and use effects to trigger services and trigger ""success/fail"" actions to be consumed in reducers for state change.",Your right now latest version in on ```new-ngrx``` branch. It is also the proposed branch to be merged.,60712558
1082,Type 'SDKToken' is not assignable to type 'AccessToken',open,2017-01-30T18:24:31Z,2017-02-10T22:10:43Z,,NONE,"#### What type of issue are you creating?
- [X ] Bug
- [ ] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.8 (2.1 Release Candidate n)
- [ ] Other

Write other if any:

#### Please add a description for your issue: 
i'm using the 2.1.0-rc.8  i'm getting this error when i build my typescript 

``` javascript
src/client/app/shared/sdk/services/custom/Customer.ts(2709,12):
error TS2322: Type 'SDKToken' is not assignable to type 'AccessToken'.
Property 'customer' is missing in type 'SDKToken'.
``` ",Any updates? ,60712558
1083,Property is missing in type '{}'.,open,2017-01-02T16:59:25Z,2017-01-06T23:00:02Z,,NONE,"#### What type of issue are you creating?
- [x] Bug
- [x] Enhancement
- [ ] Question

#### What version of this module are you using?
- [ ] 2.0.10 (Stable)
- [x] 2.1.0-rc.7 (2.1 Release Candidate n)
- [ ] Other

#### Please add a description for your issue:
I'm getting a Typescript type-error in some of my custom service method arguments:

![ts-3](https://cloud.githubusercontent.com/assets/8859860/21593215/e2244478-d114-11e6-9f67-39763386c33e.png)

Is it possible to maybe add a cast to the object? This seems to resolve it. Ex:
![ts-2](https://cloud.githubusercontent.com/assets/8859860/21593189/ad7016d0-d114-11e6-9d6a-085b9922ef69.png)

Thanks, Jesper.","Cool, I believe I will follow that path then, since it would also initialize default values, in the case you enabled that functionality when generating the sdk.
",60712558
1084,CurvesAlgoUpdateEndpointMultiplicity : Correct Catmull-Rom,open,2020-03-25T02:42:52Z,2020-03-25T23:15:02Z,,CONTRIBUTOR,"Catmull-Rom only needs double up endpoints, not tripled.

This also corrects handling of bezier curves while I'm at - bezier curves don't have any endpoint multiplicity.  If we want something for adding / removing tangents, that should probably be a separate function.

This fixes Carsten's overshoots, and a basic test passes.  The one more thing I should probably do is add tests that converting linear->bSpline->catmull yields the same result as linear->catmull.

If I was going to do a bit more playing with this while I'm at it, the one thing that might be worth checking into is why catmull-rom curves seem to always draw black in Gaffer ( whereas linear curves are white or use Cs ), and why gl:curvesPrimitive:ignoreBasis appears to default on?","> The one more thing I should probably do is add tests that converting linear->bSpline->catmull yields the same result as linear->catmull.

I do think this additional test would be worthwhile",10654465
1085,Usd camera support test,open,2020-02-01T11:37:53Z,2020-02-10T12:53:20Z,,NONE,"Add functions in USDScene.cpp so that SceneReader node will be able to read usdGeomCamera correctly and convert it to IECoreScene::camera into Gaffer.

### Checklist ###

- [x] I have read the [contribution guidelines](https://github.com/ImageEngine/cortex/blob/master/CONTRIBUTING.md).
- [x] I have tested my change(s) in the test suite, and added new test cases where necessary.
- [x] My code follows the Cortex project's prevailing coding style and conventions.
","Hey Naiqi, Thanks for the extra details.

> Hi, Tom This is the reason: if I only convert the output object of SceneReader to be IECore::camera into the scene, when you have the following graph for rendering, Arnold can't recognize this object as known camera, therefore it will crash if you click on the render button on ""InterativeArnoldRender"" node.

Right, cool. As John alluded to, this is actually a 'known issue we've been meaning to sort for a while. You have the same crash with alembic cameras.

It happens as at the beginning of the render Gaffer translates all of the cameras in the `__cameras` set (which is also used to populate the Viewer UI camera pickers) to the renderer. If your camera isn't in that set, then it doesn't get converted, and the crash you noted happens.  What we need to do is this:

 1. Fix the crash - it should just be an informative error. I'll sort that soon.
 2. Ensure the USD reader (and the Alembic one too) populates the `__cameras` set with all the cameras in the file that's being read.  That's a bigger change though, so probably best to tackle that in another PR.

So don't worry about the `IECoreArnoldPreview` changes for now, we'll take care of those. If you are able to address Don's comments though that would be fantastic.

Many thanks again for all the time you've spent on this!
'best
Tom

For now, you can also use the `Set` node to add your cameras to the `__cameras` set, which should stop the crash. 
",10654465
1086,MeshAlgoDistributePoints and density of 0,open,2019-08-15T18:30:33Z,2019-08-15T18:30:33Z,,CONTRIBUTOR,"I'm going through the tests and getting them to pass on Windows and I'm not sure what is the best solution for a failure with [MeshAlgoDistributePointsTest.testDensityMaskPrimVar](https://github.com/ImageEngine/cortex/blob/919dd01970db3fba9851954ae675bcb82d711243/test/IECoreScene/MeshAlgoDistributePointsTest.py#L93-L102).

It runs two tests - one with 100 points scattered and one with 1000 points scattered. The 100 point test passes, the 1000 point test fails in the `pointTest` function.

I tracked the difference between it passing on Linux and failing on Windows to the [signedDistance](https://github.com/ImageEngine/cortex/blob/919dd01970db3fba9851954ae675bcb82d711243/test/IECoreScene/MeshAlgoDistributePointsTest.py#L59) call which includes the primitive index in `result`:

`self.assertAlmostEqual( meshEvaluator.signedDistance( p, result ), 0.0, 3 )`

Small differences between floating point behavior on Linux and Windows can occasionally attribute the closest point to the mesh to different primitives on each platform. In the Windows tests when there are enough points there eventually are some points that appear to ""bleed"" over into a primitive with density of zero, but only barely and I think due to numeric precision.

I found that the calculation of the nearest point is consistent between platforms up to [triangleClosestBarycentric](https://github.com/ImageEngine/cortex/blob/a8e78bb01bdb0d83dde3999be9692dcdd4f19d8e/include/IECore/TriangleAlgo.inl#L74-L321) where it can rarely diverge (something like 1 in 10,000 odds).

I tried a number of different floating point compilation methods MSVC offers and none offered any noticeable difference (i.e. tests passing). 

Would it be reasonable to add an extra margin of error to 

`self.failUnless( abs(pointsPerFace[f] - density * mesh['faceArea'].data[f]) <= density * error )`

maybe something like:

`self.failUnless( abs(pointsPerFace[f] - density * mesh['faceArea'].data[f]) <= density * error + len(positions) * error * error )`

which gets it passing on Windows.

Thoughts?",,10654465
1087,Allow opting out of RTLD_GLOBAL,open,2019-06-05T00:23:04Z,2019-06-10T17:45:39Z,,MEMBER,"Following up on #810, I've added an environment variable to enable/disable `RTLD_GLOBAL` while importing the IECore python module and loading the IECoreMaya/IECoreHoudini c++ plugins.

Note I'm putting this up as a draft, in case anyone else wants to test it. Its not currently working at IE, the tests fail immediately as mentioned in #810, and interactive use is similar (though a slightly different error in each app).","Hmm, [this comment](https://github.com/ImageEngine/cortex/pull/672#issuecomment-355244691) implies maybe we do need c0f860e and we don't know why Travis isn't complaining about it?",10654465
1088,Add support for alembic visibility property,open,2019-04-04T04:46:57Z,2020-01-17T18:52:47Z,,NONE,"As per discussions with John on this [thread](https://groups.google.com/forum/#!topic/gaffer-dev/gXAVEh1Jcxc), support for automatically using the ""visible"" property of an xform in an alembic file can be added by updating the corresponding IECoreAlembic source files.

This is my first time touching anything in cortex so hope you are patient with me :) So far, these are the source files that I think I need to update to support this. Please correct me if  I'm wrong:

[IECoreAlembic/AlembicScene.cpp](https://github.com/ImageEngine/cortex/blob/7ecb5e7321503609f0d324cf71ec93f4365f7df1/contrib/IECoreAlembic/src/IECoreAlembic/AlembicScene.cpp)

[IECoreAlembic/AlembicScene.h](https://github.com/ImageEngine/cortex/blob/2d10fd9c8acbfe89c8f07627aa92dda55e05c904/contrib/IECoreAlembic/include/IECoreAlembic/AlembicScene.h)

The function of interest would be [readAttributeAtSample()](https://github.com/ImageEngine/cortex/blob/7ecb5e7321503609f0d324cf71ec93f4365f7df1/contrib/IECoreAlembic/src/IECoreAlembic/AlembicScene.cpp#L454) where currently it only seems to read user properties so I could add the default visible property as well if its available in the alembic. Am I on the right track?

Attaching the [sample file](https://github.com/ImageEngine/cortex/files/3041761/scene_vis_animated.tar.gz) that I'm going to use for this.

Cheers,
Sachin



",Is this something that can be added to the main Cortex build? We also have a need to automatically drive visibility in Gaffer via this Alembic Visibility attribute.,10654465
1089,USD Module loading,open,2019-03-19T16:20:53Z,2019-03-29T19:33:43Z,,CONTRIBUTOR,"I came across a curious issue with USD bindings on Windows. Currently the [IECoreUSDModule binding](https://github.com/ImageEngine/cortex/blob/master/contrib/IECoreUSD/src/IECoreUSD/bindings/IEUSDModule.cpp) doesn't have any explicit code but nevertheless it works on my Mac (and I presume Linux?). How does Boost / Cortex know to connect that module declaration to USDScene?

I ask because when building on Windows it _doesn't_ link to USDScene (and so USD doesn't work). This commit gets it working by mimicking the AlembicScene binding (most interesting parts at the bottom)
https://github.com/hypothetical-inc/cortex/commit/c5433fab68abe370fdacf3f28f4f4306872e7912#diff-47879de001ce177fea0f8628dff0d204

I'm not sure if that's the right way to bind to USDScene, if it should be included in a future PR or if I should be dropping that commit in favor of a more correct linking setup of some kind.","I just did a little searching but didn't turn up too much additional to contribute - most still point me towards the linker optimization of unused symbols still being the culprit. But that doesn't add anything to @dboogert case on Linux unfortunately.

I just about have a PR ready for this, just need to test out actually loading a USD on Linux, which means I'm finally setting up a VM with a video card to make sure it works.",10654465
1090,possible threading issue on Windows build,open,2019-02-07T16:18:52Z,2019-02-08T17:36:44Z,,CONTRIBUTOR,"I was digging into a crash problem with expanding the GafferBot hierarchy in my Windows work-in-progress build of Gaffer and it may be leading me to Cortex so I wanted to raise the issue sooner than later with the Windows Cortex PR #916 under review.

I'm a little out of my depth here but eager to learn so please bear with me if you will. Here are the steps that lead to a crash (all on Windows and I assume unique to that platform):

1. In Gaffer, load the GafferBot in a SceneReader node
2. Expand the hierarchy of the full bot -> crash
3. Expand the hierarchy of a single part -> maybe a crash
4. Expand the hierarchy of a few parts one after another -> eventually crash
5. BUT: Expand the hierarchy while the system is under near 100% load from another program -> GafferBot hierarchy expands without problems

I suspect it is a memory access issue as a result of multi-threading. At one point I was looking into the problem while my CPU was under heavy load on another program, slowing down Gaffer quite a bit, and loading the GafferBot worked great. So my theory is that it was running slowly enough that the race condition didn't cause a problem. Does that sound valid?

I'm wondering if this sparks any ideas from @johnhaddon or others who are far more steeped in the code than myself, if it sounds like a Cortex problem or Gaffer, and if you have any tips on debugging this kind of multi-threading problem. I'll continue to dig as much as I can but wanted to get some other brains involved too. Perhaps Windows is missing a data lock somewhere?

I have this stack trace from the crash. (Or here: [stack_trace.txt](https://github.com/ImageEngine/cortex/files/2841685/stack_trace.txt)) I'm working on sorting out how to get the Python calls included in the call stack and I'll post that when I can figure it out.

```
> ntdll.dll!00007ffd7571aed2()
ntdll.dll!00007ffd7572379e()
ntdll.dll!00007ffd75723aaa()
ntdll.dll!00007ffd756bebb1()
ntdll.dll!00007ffd756ccd22()
ucrtbase.dll!00007ffd71badf7b()
[Inline Frame] IECoreScene.dll!std::_Default_allocator_traits<std::allocator<std::_Tree_node<std::pair<std::basic_string<char,std::char_traits<char>,std::allocator<char> > const ,IECoreScene::PrimitiveVariable>,void *> > >::deallocate() Line 873
	at c:\program files (x86)\microsoft visual studio\2017\community\vc\tools\msvc\14.16.27023\include\xmemory0(873)
[Inline Frame] IECoreScene.dll!std::_Tree_node<std::pair<std::basic_string<char,std::char_traits<char>,std::allocator<char> > const ,IECoreScene::PrimitiveVariable>,void *>::_Freenode0() Line 414
	at c:\program files (x86)\microsoft visual studio\2017\community\vc\tools\msvc\14.16.27023\include\xtree(414)
[Inline Frame] IECoreScene.dll!std::_Tree<std::_Tmap_traits<std::basic_string<char,std::char_traits<char>,std::allocator<char> >,IECoreScene::PrimitiveVariable,std::less<std::basic_string<char,std::char_traits<char>,std::allocator<char> > >,std::allocator<std::pair<std::basic_string<char,std::char_traits<char>,std::allocator<char> > const ,IECoreScene::PrimitiveVariable> >,0> >::erase() Line 1379
	at c:\program files (x86)\microsoft visual studio\2017\community\vc\tools\msvc\14.16.27023\include\xtree(1379)
IECoreScene.dll!`anonymous namespace'::convertLegacyVariables(variables={...}) Line 327
	at m:\cortex\src\iecorescene\primitive.cpp(327)
IECoreScene.dll!IECoreScene::Primitive::load(context={...}) Line 375
	at m:\cortex\src\iecorescene\primitive.cpp(375)
IECoreScene.dll!IECoreScene::MeshPrimitive::load(context={...}) Line 254
	at m:\cortex\src\iecorescene\meshprimitive.cpp(254)
IECore.dll!IECore::Object::LoadContext::loadObject(container) Line 327
	at m:\cortex\src\iecore\object.cpp(327)
IECore.dll!IECore::Object::LoadContext::loadObjectOrReference(container=0x000001a7c913d5c0, name={...}) Line 311
	at m:\cortex\src\iecore\object.cpp(311)
IECore.dll!IECore::Object::LoadContext::load<IECore::Object>(i, name) Line 87
	at m:\cortex\include\iecore\object.inl(87)
IECore.dll!IECore::Object::load(ioInterface={...}, name={...}) Line 567
	at m:\cortex\src\iecore\object.cpp(567)
IECoreScene.dll!IECoreScene::SceneCache::ReaderImplementation::doReadObjectAtSample(key) Line 1107
	at m:\cortex\src\iecorescene\scenecache.cpp(1107)
IECoreScene.dll!boost::detail::function::function_invoker1<boost::intrusive_ptr<IECore::Object> (__cdecl*)(std::pair<IECoreScene::SceneCache::ReaderImplementation const *,unsigned __int64> const &),boost::intrusive_ptr<IECore::Object const >,std::pair<IECoreScene::SceneCache::ReaderImplementation const *,unsigned __int64> const &>::invoke(function_ptr, a0) Line 101
	at m:\gaffer_build\include\boost-1_61\boost\function\function_template.hpp(101)
[Inline Frame] IECoreScene.dll!boost::function1<boost::intrusive_ptr<IECore::Object const >,std::pair<IECoreScene::SceneCache::ReaderImplementation const *,unsigned __int64> const &>::operator()() Line 770
	at m:\gaffer_build\include\boost-1_61\boost\function\function_template.hpp(770)
IECoreScene.dll!IECore::ComputationCache<std::pair<IECoreScene::SceneCache::ReaderImplementation const *,unsigned __int64> >::get(args={...}, missingBehaviour=ComputeIfMissing) Line 103
	at m:\cortex\include\iecore\computationcache.inl(103)
IECoreScene.dll!IECoreScene::SceneCache::ReaderImplementation::SharedData::readObjectAtSample(reader=0x000001a7c87777d0, sample=0) Line 916
	at m:\cortex\src\iecorescene\scenecache.cpp(916)
[Inline Frame] IECoreScene.dll!IECoreScene::SceneCache::ReaderImplementation::readObjectAtSample() Line 587
	at m:\cortex\src\iecorescene\scenecache.cpp(587)
IECoreScene.dll!IECoreScene::SceneCache::readObjectAtSample(sampleIndex=0) Line 2466
	at m:\cortex\src\iecorescene\scenecache.cpp(2466)
IECoreScene.dll!IECoreScene::SampledSceneInterface::readObject(time) Line 161
	at m:\cortex\src\iecorescene\sampledsceneinterface.cpp(161)
GafferScene.dll!GafferScene::SceneReader::computeObject(path, context=0x000001a7c87779b0, parent=0x000001a7c95893d0) Line 334
	at m:\gaffer\src\gafferscene\scenereader.cpp(334)
GafferScene.dll!GafferScene::SceneNode::compute(output=0x000001a7c9587880, context=0x000001a7c87779b0) Line 270
	at m:\gaffer\src\gafferscene\scenenode.cpp(270)
Gaffer.dll!Gaffer::ValuePlug::ComputeProcess::ComputeProcess(plug=0x000001a7c9587880, downstream=0x0000003b59e93850) Line 383
	at m:\gaffer\src\gaffer\valueplug.cpp(383)
Gaffer.dll!Gaffer::ValuePlug::ComputeProcess::value(plug=0x000001a7c8c03000, precomputedHash=0x0000000000000000, cachedOnly) Line 304
	at m:\gaffer\src\gaffer\valueplug.cpp(304)
Gaffer.dll!Gaffer::ValuePlug::getObjectValue(precomputedHash) Line 674
	at m:\gaffer\src\gaffer\valueplug.cpp(674)
Gaffer.dll!Gaffer::TypedObjectPlug<IECore::Object>::getValue(precomputedHash) Line 101
	at m:\gaffer\include\gaffer\typedobjectplug.inl(101)
GafferScene.dll!GafferScene::DeleteObject::computeObject(path={...}, context, parent=0x000001a7b8d26850) Line 126
	at m:\gaffer\src\gafferscene\deleteobject.cpp(126)
GafferScene.dll!GafferScene::SceneNode::compute(output=0x000001a7b8d24bd0, context=0x000001a7c87779b0) Line 270
	at m:\gaffer\src\gafferscene\scenenode.cpp(270)
Gaffer.dll!Gaffer::ValuePlug::ComputeProcess::ComputeProcess(plug=0x000001a7b8d24bd0, downstream=0x0000003b59e93ca0) Line 383
	at m:\gaffer\src\gaffer\valueplug.cpp(383)
Gaffer.dll!Gaffer::ValuePlug::ComputeProcess::value(plug=0x000001a7c8c00540, precomputedHash=0x0000003b59e93de0, cachedOnly) Line 304
	at m:\gaffer\src\gaffer\valueplug.cpp(304)
Gaffer.dll!Gaffer::ValuePlug::getObjectValue(precomputedHash) Line 674
	at m:\gaffer\src\gaffer\valueplug.cpp(674)
Gaffer.dll!Gaffer::TypedObjectPlug<IECore::Object>::getValue(precomputedHash) Line 101
	at m:\gaffer\include\gaffer\typedobjectplug.inl(101)
GafferScene.dll!GafferScene::RenderController::SceneGraph::updateObject(objectPlug=0x000001a7c8c00540, type=ObjectType, renderer=0x000001a7c6774c40, globals=0x000001a7b8ffc1c0, scene=0x000001a7c8c02a10) Line 491
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(491)
GafferScene.dll!GafferScene::RenderController::SceneGraph::update(path={...}, changedGlobals, type=ObjectType, controller=0x000001a7c926c618) Line 244
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(244)
GafferScene.dll!GafferScene::RenderController::SceneGraphUpdateTask::execute() Line 748
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(748)
tbb.dll!00007ffd57c7f3ce()
[Inline Frame] GafferScene.dll!tbb::task::wait_for_all() Line 760
	at m:\gaffer_build\include\tbb\task.h(760)
GafferScene.dll!GafferScene::RenderController::SceneGraphUpdateTask::execute() Line 769
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(769)
tbb.dll!00007ffd57c7f3ce()
[Inline Frame] GafferScene.dll!tbb::task::wait_for_all() Line 760
	at m:\gaffer_build\include\tbb\task.h(760)
GafferScene.dll!GafferScene::RenderController::SceneGraphUpdateTask::execute() Line 769
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(769)
tbb.dll!00007ffd57c7f3ce()
[Inline Frame] GafferScene.dll!tbb::task::wait_for_all() Line 760
	at m:\gaffer_build\include\tbb\task.h(760)
GafferScene.dll!GafferScene::RenderController::SceneGraphUpdateTask::execute() Line 769
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(769)
tbb.dll!00007ffd57c7f3ce()
[Inline Frame] GafferScene.dll!tbb::task::wait_for_all() Line 760
	at m:\gaffer_build\include\tbb\task.h(760)
GafferScene.dll!GafferScene::RenderController::SceneGraphUpdateTask::execute() Line 769
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(769)
tbb.dll!00007ffd57c7f3ce()
[Inline Frame] GafferScene.dll!tbb::task::wait_for_all() Line 760
	at m:\gaffer_build\include\tbb\task.h(760)
GafferScene.dll!GafferScene::RenderController::SceneGraphUpdateTask::execute() Line 769
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(769)
tbb.dll!00007ffd57c7f3ce()
tbb.dll!00007ffd57c80a1f()
[Inline Frame] GafferScene.dll!tbb::task::spawn_root_and_wait() Line 749
	at m:\gaffer_build\include\tbb\task.h(749)
GafferScene.dll!GafferScene::RenderController::updateInternal(callback={...}, pathsToUpdate=0x0000000000000000) Line 1148
	at m:\gaffer\src\gafferscene\rendercontroller.cpp(1148)
[Inline Frame] Gaffer.dll!std::_Func_class<void>::operator()()
[Inline Frame] Gaffer.dll!Gaffer::ParallelAlgo::callOnBackgroundThread::__l2::<lambda_7d48a069dbe2f868092036970752470e>::operator()() Line 92
	at m:\gaffer\src\gaffer\parallelalgo.cpp(92)
[Inline Frame] Gaffer.dll!std::_Invoker_functor::_Call()
[Inline Frame] Gaffer.dll!std::invoke()
[Inline Frame] Gaffer.dll!std::_Invoker_ret<void,1>::_Call()
Gaffer.dll!std::_Func_impl_no_alloc<<lambda_7d48a069dbe2f868092036970752470e>,void,IECore::Canceller const &>::_Do_call(<_Args_0>)
[Inline Frame] Gaffer.dll!std::_Func_class<void,IECore::Canceller const &>::operator()() Line 184
	at m:\gaffer\src\gaffer\backgroundtask.cpp(184)
Gaffer.dll!Gaffer::BackgroundTask::{ctor}::__l2::<lambda>() Line 185
	at m:\gaffer\src\gaffer\backgroundtask.cpp(185)
[Inline Frame] Gaffer.dll!std::_Func_class<void>::operator()() Line 71
	at m:\gaffer\src\gaffer\backgroundtask.cpp(71)
Gaffer.dll!`anonymous namespace'::FunctionTask::execute() Line 72
	at m:\gaffer\src\gaffer\backgroundtask.cpp(72)
tbb.dll!00007ffd57c7f3ce()
tbb.dll!00007ffd57c7361d()
tbb.dll!00007ffd57c78ff4()
tbb.dll!00007ffd57c7bd2c()
tbb.dll!00007ffd57c7becd()
ucrtbase.dll!00007ffd71bc03ba()
kernel32.dll!00007ffd74917e94()
ntdll.dll!00007ffd7568a251()

```","Removing the WindowsPlatformReader did the trick! GafferBot is loading up just fine now. I force pushed an update to StreamIndexedIO with that taken out for the PR.

I also had success with a WindowsPlatformReader styled after the USD code from that link, thanks a lot for digging it up.

I'd like to do some performance testing on some different WindowsPlatformReader implementations so I'm keeping that in a separate branch for now and I figure I'll do a follow-up PR once I have a better idea of how all of this is working with multi-threading. 

I'm open to discussion of course.",10654465
1091,IECoreGL : convert glVisualiser attributes to State userAttributes.,open,2019-01-10T00:07:17Z,2019-02-15T15:31:33Z,,CONTRIBUTOR,Second attempt to copy a few attributes  so they're available in GL rendering.,"Thanks Don, this is more like what I had in mind. I hadn't realised that there would be some overhead required in the push/pop of the user attributes though - I'll need to do some testing to determine the cost for viewport rendering. In the meantime, if you could push your PR for the improved VDB visualisers depending on this, that would be great.",10654465
1092,Build Cortex error: scons: *** [src/IECore/DataConvertOp.os] Error 1,open,2018-12-18T18:45:45Z,2018-12-18T21:53:15Z,,NONE,"**Version**: Cortex 10.0.0-a44
**3rd-party modules**: List any 3rd-party modules in your configuration
OpenEXR

### Description ###
I'm trying to build CORTEX but I don't understand where I'm failing.


### Steps to Reproduce ###

Download cortex-10.0.0-a44 and untar

```
scons BOOST_LIB_PATH=/usr/lib64 BOOST_LIB_SUFFIX=
```

Centos 7 - 3.10.0-957.1.3.el7.x86_64
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Python 2.7.5
boost-1.53.0
boost-devel-1.53.0
OpenEXR 1.7.1-7.el7
OpenEXR-devel 1.7.1-7.el7
tbb 4.1-9.20130314.el7
tbb-devel 4.1-9.20130314.el7
blosc 1.6.1-1.el7
blosc-devel 1.6.1-1.el7


### Debug Log ###

<details>
<summary>Click to Expand</summary><p>

<!-- Optional: Insert debug log output below -->


```
[prismo@prismo cortex-10.0.0-a44]$ scons BOOST_LIB_PATH=/usr/lib64 BOOST_LIB_SUFFIX=
scons: Reading SConscript files ...
Checking for C++ header file boost/version.hpp... (cached) yes
Checking for C++ library boost_iostreams... (cached) yes
Checking for C++ library Iex... (cached) yes
Checking for C++ library tbb... (cached) yes
Checking for C++ library blosc... (cached) yes
Checking for C++ library freetype... (cached) yes
Checking for C++ library OpenImageIO... (cached) no
ERROR : unable to find the OpenImageIO libraries - check OIIO_INCLUDE_PATH and OIIO_LIB_PATH.
Checking for C++ library openvdb... (cached) no
WARNING : no OpenVDB library found, not building IECoreVDB - check VDB_INCLUDE_PATH, VDB_LIB_PATH and config.log.
Checking for C++ header file ndspy.h... (cached) no
WARNING : ndspy.h not found - check RMAN_ROOT.
Checking for C++ header file maya/MVectorArray.h... (cached) no
WARNING : no maya devkit found, not building IECoreMaya - check MAYA_ROOT.
Checking for C++ header file DDImage/Vector3.h... (cached) no
WARNING : no nuke devkit found, not building IECoreNuke - check NUKE_ROOT.
Checking for C++ library HoudiniGEO... (cached) no
WARNING : no houdini devkit found, not building IECoreHoudini - check HOUDINI_ROOT.
Checking for C++ library ai... (cached) no
WARNING : no ai library found, not building IECoreArnold - check ARNOLD_ROOT.
Checking for C++ library usd... (cached) no
WARNING : no USD library found, not building IECoreUSD - check USD_INCLUDE_PATH, USD_LIB_PATH and config.log.
Checking for C++ library Alembic... (cached) no
Checking for C++ library AlembicAbcGeom... (cached) no
WARNING : no Alembic library found, not building IECoreAlembic - check ALEMBIC_INCLUDE_PATH, ALEMBIC_LIB_PATH and config.log.
Checking for C++ library appleseed... (cached) no
WARNING : no appleseed library found, not building IECoreAppleseed - check APPLESEED_INCLUDE_PATH and APPLESEED_LIB_PATH.
Checking for doxygen... yes
scons: done reading SConscript files.
scons: Building targets ...
g++ -o src/IECore/DataConvertOp.os -c -isystem /usr/local/include/tbb -isystem /usr/include -isystem /usr/include/OpenEXR -isystem /usr/include/OpenEXR -isystem /usr/include -isystem /usr/include/OpenEXR/OpenEXR -isystem /usr/include/OpenEXR/OpenEXR -isystem /usr/include/freetype2 -pipe -Wall -std=c++11 -fvisibility=hidden -Werror -DNDEBUG -DBOOST_DISABLE_ASSERTS -O3 -DIECore_EXPORTS -fPIC -DIE_CORE_MAJORVERSION=10 -DIE_CORE_MINORVERSION=0 -DIE_CORE_PATCHVERSION=0 -DBOOST_FILESYSTEM_VERSION=3 -DIECORE_WITH_FREETYPE -Iinclude src/IECore/DataConvertOp.cpp
In file included from include/IECore/DespatchTypedData.h:153:0,
                 from src/IECore/DataConvertOp.cpp:38:
include/IECore/DespatchTypedData.inl:70:40: error: 'enable_if' in namespace 'boost' does not name a type
  struct Func< Enabler, typename boost::enable_if< Enabler<DataType> >::type >
                                        ^
include/IECore/DespatchTypedData.inl:70:49: error: expected template-argument before '<' token
  struct Func< Enabler, typename boost::enable_if< Enabler<DataType> >::type >
                                                 ^
include/IECore/DespatchTypedData.inl:70:49: error: expected '>' before '<' token
include/IECore/DespatchTypedData.inl:70:77: error: template argument 2 is invalid
  struct Func< Enabler, typename boost::enable_if< Enabler<DataType> >::type >
                                                                             ^
include/IECore/DespatchTypedData.inl:71:2: error: expected '::' before '{' token
  {
  ^
include/IECore/DespatchTypedData.inl:71:2: error: expected identifier before '{' token
include/IECore/DespatchTypedData.inl:71:2: error: qualified name does not name a class before '{' token
In file included from include/IECore/DespatchTypedData.h:153:0,
                 from src/IECore/DataConvertOp.cpp:38:
include/IECore/DespatchTypedData.inl:459:63: error: 'enable_if' in namespace 'boost' does not name a type
 struct TypedDataSize::TypedDataSizeHelper< T, typename boost::enable_if< TypeTraits::IsSimpleTypedData<T> >::type >
                                                               ^
include/IECore/DespatchTypedData.inl:459:72: error: expected template-argument before '<' token
 struct TypedDataSize::TypedDataSizeHelper< T, typename boost::enable_if< TypeTraits::IsSimpleTypedData<T> >::type >
                                                                        ^
include/IECore/DespatchTypedData.inl:459:72: error: expected '>' before '<' token
include/IECore/DespatchTypedData.inl:459:115: error: template argument 2 is invalid
 struct TypedDataSize::TypedDataSizeHelper< T, typename boost::enable_if< TypeTraits::IsSimpleTypedData<T> >::type >
                                                                                                                   ^
include/IECore/DespatchTypedData.inl:460:1: error: expected '::' before '{' token
 {
 ^
include/IECore/DespatchTypedData.inl:460:1: error: expected identifier before '{' token
include/IECore/DespatchTypedData.inl:460:1: error: qualified name does not name a class before '{' token
include/IECore/DespatchTypedData.inl:469:63: error: 'enable_if' in namespace 'boost' does not name a type
 struct TypedDataSize::TypedDataSizeHelper< T, typename boost::enable_if< TypeTraits::IsVectorTypedData<T> >::type >
                                                               ^
include/IECore/DespatchTypedData.inl:469:72: error: expected template-argument before '<' token
 struct TypedDataSize::TypedDataSizeHelper< T, typename boost::enable_if< TypeTraits::IsVectorTypedData<T> >::type >
                                                                        ^
include/IECore/DespatchTypedData.inl:469:72: error: expected '>' before '<' token
include/IECore/DespatchTypedData.inl:469:115: error: template argument 2 is invalid
 struct TypedDataSize::TypedDataSizeHelper< T, typename boost::enable_if< TypeTraits::IsVectorTypedData<T> >::type >
                                                                                                                   ^
include/IECore/DespatchTypedData.inl:470:1: error: expected '::' before '{' token
 {
 ^
include/IECore/DespatchTypedData.inl:470:1: error: expected identifier before '{' token
include/IECore/DespatchTypedData.inl:470:1: error: qualified name does not name a class before '{' token
include/IECore/DespatchTypedData.inl:502:69: error: 'enable_if' in namespace 'boost' does not name a type
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< TypeTraits::IsSimpleTypedData<T> >::type >
                                                                     ^
include/IECore/DespatchTypedData.inl:502:78: error: expected template-argument before '<' token
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< TypeTraits::IsSimpleTypedData<T> >::type >
                                                                              ^
include/IECore/DespatchTypedData.inl:502:78: error: expected '>' before '<' token
include/IECore/DespatchTypedData.inl:502:121: error: template argument 2 is invalid
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< TypeTraits::IsSimpleTypedData<T> >::type >
                                                                                                                         ^
include/IECore/DespatchTypedData.inl:503:1: error: expected '::' before '{' token
 {
 ^
include/IECore/DespatchTypedData.inl:503:1: error: expected identifier before '{' token
include/IECore/DespatchTypedData.inl:503:1: error: qualified name does not name a class before '{' token
include/IECore/DespatchTypedData.inl:512:69: error: 'enable_if' in namespace 'boost' does not name a type
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< boost::mpl::and_< TypeTraits::IsVectorTypedData<T>, boost::mpl::not_< boost::is_same< typename TypeTraits::VectorValueType<T>::type, bool > > > >::type >
                                                                     ^
include/IECore/DespatchTypedData.inl:512:78: error: expected template-argument before '<' token
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< boost::mpl::and_< TypeTraits::IsVectorTypedData<T>, boost::mpl::not_< boost::is_same< typename TypeTraits::VectorValueType<T>::type, bool > > > >::type >
                                                                              ^
include/IECore/DespatchTypedData.inl:512:78: error: expected '>' before '<' token
include/IECore/DespatchTypedData.inl:512:232: error: template argument 2 is invalid
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< boost::mpl::and_< TypeTraits::IsVectorTypedData<T>, boost::mpl::not_< boost::is_same< typename TypeTraits::VectorValueType<T>::type, bool > > > >::type >
                                                                                                                                                                                                                                        ^
include/IECore/DespatchTypedData.inl:513:1: error: expected '::' before '{' token
 {
 ^
include/IECore/DespatchTypedData.inl:513:1: error: expected identifier before '{' token
include/IECore/DespatchTypedData.inl:513:1: error: qualified name does not name a class before '{' token
include/IECore/DespatchTypedData.inl:522:69: error: 'enable_if' in namespace 'boost' does not name a type
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< boost::mpl::and_< TypeTraits::IsVectorTypedData<T>, boost::is_same< typename TypeTraits::VectorValueType<T>::type, bool > > >::type >
                                                                     ^
include/IECore/DespatchTypedData.inl:522:78: error: expected template-argument before '<' token
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< boost::mpl::and_< TypeTraits::IsVectorTypedData<T>, boost::is_same< typename TypeTraits::VectorValueType<T>::type, bool > > >::type >
                                                                              ^
include/IECore/DespatchTypedData.inl:522:78: error: expected '>' before '<' token
include/IECore/DespatchTypedData.inl:522:212: error: template argument 2 is invalid
 struct TypedDataAddress::TypedDataAddressHelper< T, typename boost::enable_if< boost::mpl::and_< TypeTraits::IsVectorTypedData<T>, boost::is_same< typename TypeTraits::VectorValueType<T>::type, bool > > >::type >
                                                                                                                                                                                                                    ^
include/IECore/DespatchTypedData.inl:523:1: error: expected '::' before '{' token
 {
 ^
include/IECore/DespatchTypedData.inl:523:1: error: expected identifier before '{' token
include/IECore/DespatchTypedData.inl:523:1: error: qualified name does not name a class before '{' token
scons: *** [src/IECore/DataConvertOp.os] Error 1
scons: building terminated because of errors.

```
</p>
</details>
","`boost/utility/enable_if.hpp` does exists.

```

[prismo@prismo ~]$ tree /usr/include/boost/ -P enable_if.hpp --prune
/usr/include/boost/
|-- iterator
|   `-- detail
|       `-- enable_if.hpp
|-- python
|   `-- detail
|       `-- enable_if.hpp
`-- utility
    `-- enable_if.hpp

```

But I don't care to update boost. Will come back with more information after the updates.

Thanks!",10654465
1093,Build : Implement BUILD_DIR like in Gaffer,open,2018-10-10T00:28:23Z,2018-10-10T17:05:38Z,,CONTRIBUTOR,"To build Cortex at home, users currently need to set many options; see the _Configure_ section of the [cmake instructions](https://github.com/ImageEngine/cortex/blob/master/contrib/cmake/README.md) for a list.

It could be made significantly easier if users could set a single `BUILD_DIR` variable, which would point to GafferDependencies, just like the Gaffer build process. This would mean changing most of the paths in Sconstruct to point to that variable.",,10654465
1094,Improvements to PathMatcher iterators,open,2018-09-25T21:53:40Z,2018-09-25T21:53:40Z,,MEMBER,Consider the discussion on #728 and improve the iterators to avoid the traps.,,10654465
1095,repr<float> export symbol?,open,2018-04-12T14:07:04Z,2018-04-13T21:05:19Z,,CONTRIBUTOR,"Building on the hard work by @boberfly to port Cortex and Gaffer to Windows I just about have what I think is a successful rebase of both onto the latest changes.

Cortex required almost nothing, Gaffer less so since there were a number of additions since Alex split his out. One sticky one from Gaffer is this linker error:

> SplinePlugBinding.obj : error LNK2019: unresolved external symbol ""__declspec(dllimport) class std::basic_string<char,struct std::char_traits<char>
> ,class std::allocator<char> > __cdecl IECorePython::repr<float>(float &)"" (__imp_??$repr@M@IECorePython@@YA?AV?$basic_string@DU?$char_traits@D@std@@V
> ?$allocator@D@2@@std@@AEAM@Z) referenced in function ""class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __cdecl
>  `anonymous namespace'::splineDefinitionRepr<struct Gaffer::SplineDefinition<class IECore::Spline<float,float> > >(class boost::python::api::object)""
>  (??$splineDefinitionRepr@U?$SplineDefinition@V?$Spline@MM@IECore@@@Gaffer@@@?A0xa9402e25@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@
> 2@@std@@Vobject@api@python@boost@@@Z) [M:\gaffer\_Gaffer.vcxproj]

I solved it by adding this to Cortex: https://github.com/hypotheticalinc/cortex/commit/d8801e528c1db84f4449bb8b74d82be8284f30cf

I don't have experience creating Python bindings but my solution doesn't seem quite right. It seems like an out-of-pattern solution that makes me think I'm missing something bigger or simpler.

I haven't had related linker errors yet, but should I add an IECORE_EXPORT to the str<TYPE> as well? Or is there a more correct solution within Gaffer?
","I recently got a fairly old but nimble 20-core linux workstation to do occasional builds also, and I discovered there's a windows docker with a windows backend that you can install visual studio to, so I have that as a vm that I can spin up to do builds also...",10654465
1096,Handle Traceback Failure,open,2018-03-02T18:21:27Z,2018-03-02T18:21:27Z,,CONTRIBUTOR,"If an exception is thrown during Python shutdown, Python may have already replaced the traceback module with None, and our exception handling code will crash without printing the Python exception.

This PR fixes this, but introduces other errors, and we haven't cared enough to debug it yet:
https://github.com/ImageEngine/cortex/pull/718",,10654465
1097,Crash when changing camera parameters in Appleseed interactive render,open,2018-02-26T11:28:54Z,2018-02-26T11:28:54Z,,CONTRIBUTOR,"I figured it was better to log here than in Gaffer, since I think the code best changed is here.
Repro:
* setup and kick off an interactive render using Appleseed
* change camera FOV
* crashy
The issue as I see it is that Cortex caches the asr::Frame / asf::Image being used for pixel data. For a  lot of updates, that's fine, but for camera updates a whole new one is created (destroying the old one), but the ""initialisation flag"" isn't cleared.
There's a pull request coming.",,10654465
1098,Modern Camera spec,open,2017-06-09T16:45:29Z,2019-06-18T19:56:04Z,,MEMBER,"`IECore::Camera` is fairly limited in its features, and we often have trouble fully representing DCC camera settings. We often resort to baking things down, and hence lose information. Lets update to a more modern spec that can handle the common DCC settings without baking it down to screenWindow when possible.

Related to #29 in that Alembic has a camera spec we may consider adopting or at least need to support loading.",We'll want to address this issue as well: https://github.com/ImageEngine/cortex/pull/539#issuecomment-261337070,10654465
1099,Defaults to /usr/lib* might be harmful,open,2016-10-21T23:13:43Z,2016-10-24T14:27:01Z,,NONE,"Here is the case:
If you provide custom library paths but some of the libraries are not given /usr/lib is being added as default.
However this default might mess up the linking for all other libraries if the system happens to have the same libraries.

The concrete use-case was where alembic would fail to link against hdf5 in the tests because our alembic was linked against a newer hdf.
However since a different path was not specified it defaulted to /usr/lib. The order of these variable is random and in our case the system library was being linked (and failed) before our provided hdf5 path.

This was 8.4 but I still see /usr/lib as defaults in dev.
I would suggest not to default to /usr/lib\* but instead leave the path empty.
ld always picks up /usr/lib as last resort so no action is necessary.

Cheers,
Blazej
",,10654465
1100,Disallow invalid names for SceneInterface/SceneCache/IndexedIO,open,2016-03-30T08:26:00Z,2017-05-11T18:53:21Z,,MEMBER,"This was motivated by a cache being written using """" for the name and breaking tools further down the line. We should also consider disallowing ""/"" in a name since we use it as a path separator. Need to consider carefully at which level of IO we do this - perhaps IndexedIO should be left alone?
","Just so I have mentioned this: The solution to use just alphanumerics that I have brought up before actually wouldn't work for us because we have nodes that create objects in an array-like format:

```
myObjects
\ object[0]
\ object[1]
```",10654465
1101,Investigate using blosc within IndexedIO,open,2016-03-17T16:09:48Z,2016-03-17T16:09:48Z,,MEMBER,"See https://github.com/ImageEngine/cortex/pull/420 for more details.
",,10654465
1102,Include interpretation in `repr( GeometricTypedData )`,open,2015-07-23T12:44:15Z,2015-07-23T12:44:15Z,,MEMBER,"This is needed because `repr()` is used to serialise plug values in Gaffer, and we need to maintain the geometric interpretation for V3fVectorData in order to have the correct interpretation for RenderManShader values.
",,10654465
1103,problem building 9.0.0.b5 with houdini 14.0.201.13,open,2015-04-16T04:41:52Z,2016-02-26T00:21:53Z,,NONE,"I'm getting this error:
include/IECoreHoudini/GU_CortexPrimitive.h:52: error: expected class-name before '{' token
include/IECoreHoudini/GU_CortexPrimitive.h:90: error: 'convert' declared as a 'virtual' field
include/IECoreHoudini/GU_CortexPrimitive.h:90: error: expected ';' before '(' token
include/IECoreHoudini/GU_CortexPrimitive.h:91: error: 'convertNew' declared as a 'virtual' field
include/IECoreHoudini/GU_CortexPrimitive.h:91: error: expected ';' before '(' token
include/IECoreHoudini/GU_CortexPrimitive.h:109: error: expected ';' before '(' token
scons: **\* [src/IECoreHoudini/FromHoudiniCompoundObjectConverter.os] Error 1

when building against houdini 14.0.201.13. Have you guys tested building with houdini 14 before?
cheers...
-H
","Do you want to put up a pull request, and I'll see if it compiles happily for us here?
",10654465
1104,Precompiled headers,open,2014-12-18T06:00:27Z,2017-05-09T20:34:33Z,,CONTRIBUTOR,"What I've noticed from building Cortex over and over is that it takes way too long! What I propose is having a Precompiled.h (or stdafx.h) and place includes that are commonly used through the library to speed up compile times.
MSVC:
http://msdn.microsoft.com/en-us/library/h552b3ca.aspx
GCC:
https://gcc.gnu.org/onlinedocs/gcc/Precompiled-Headers.html

Thoughts? Bringing in the Export.h took awhile and I'm somewhat reluctant to add another include into every file again, but the compile times at least on MSVC on my laptop are quite long.
","Adding this link commit as it's exactly what Pixar's USD has done for MSVC support:
https://github.com/PixarAnimationStudios/USD/commit/791bdb6102228e68b4b58d4cb1339e7c8acbfef0",10654465
1105,"Windows port, various issues",open,2014-09-20T07:15:55Z,2014-12-15T13:33:10Z,,CONTRIBUTOR,"Hi all,

Posting a bug report on a platform currently unsupported by Cortex is probably a bad idea but I am currently at a loss as to how to approach this issue. On Visual Studio 2013 x64 I am compiling Cortex with my custom branch here:

https://github.com/boberfly/cortex/tree/windows

I have recently introduced IECore/IECoreExport.h to all the includes in anticipation to support dynamic .dll's for Windows and this is a requirement to correctly export definitions without making a custom .def file.

The problem now is with boost intrusive_ptr. Currently MSVC has the following error:

Error   588 error C2664: 'void IECore::intrusive_ptr_release(const IECore::RefCounted *)' : cannot convert argument 1 from 'IECore::FileNameParameter *' to 'const IECore::RefCounted *'    C:\Users\Boberfly\Documents\Development\windows\gafferDependencies\include\boost\smart_ptr\intrusive_ptr.hpp    97  1   IECore
Error   3923    error C2664: 'void IECore::intrusive_ptr_release(const IECore::RefCounted *)' : cannot convert argument 1 from 'IECore::FileNameParameter *' to 'const IECore::RefCounted *'    C:\Users\Boberfly\Documents\Development\windows\gafferDependencies\include\boost\smart_ptr\intrusive_ptr.hpp    97  1   IECore
Error   7283    error C2664: 'void IECore::intrusive_ptr_release(const IECore::RefCounted *)' : cannot convert argument 1 from 'IECore::MatrixMultiplyOp *' to 'const IECore::RefCounted *' C:\Users\Boberfly\Documents\Development\windows\gafferDependencies\include\boost\smart_ptr\intrusive_ptr.hpp    97  1   IECore
Error   18752   error C2664: 'void IECore::intrusive_ptr_release(const IECore::RefCounted *)' : cannot convert argument 1 from 'IECore::FileNameParameter *' to 'const IECore::RefCounted *'    C:\Users\Boberfly\Documents\Development\windows\gafferDependencies\include\boost\smart_ptr\intrusive_ptr.hpp    97  1   IECore

First hint is they're not const, a first tweak was I made was taking out const in RefCounted.h :
inline void intrusive_ptr_release( IECore::RefCounted *r )
Which caused more of these issues but for constified versions of classes derived from RefCounted. So that's the only 'hint' I could come up with.

This issue looks suspiciously like an earlier attempt at porting Cortex to Windows, albeit at a time when intrusive_ptr probably had a different design implementation in Cortex:
https://code.google.com/p/cortex-vfx/issues/detail?id=49

Thanks all!
","Hey Alex, just checking in to see how it's going - is there anything I can do to help move things along?
",10654465
1106,Automatic library loading for unknown typeIds,open,2014-09-08T16:46:36Z,2014-09-08T16:46:36Z,,CONTRIBUTOR,"We often run into situations where, for example, the user imports a python module, writes out a scene cache containing an object defined in one of that python module's libraries, and is henceforth unable to read that scene cache because the data file contains an unregistered typeId (unless they remember to import the python module so the library gets loaded or whatever).

This can get annoying, so it'd be good to have some kind of mechanism for automatically loading libraries for unregistered type ids
",,10654465
1107,Remove unnecessary null pointer checks,open,2014-08-16T18:30:26Z,2014-08-16T18:30:26Z,,NONE,"[An extra null pointer check is not needed in functions](http://dietmar-kuehl.de/mirror/c++-faq/freestore-mgmt.html#faq-16.8) like the following.
- [PNGImageReader](https://github.com/ImageEngine/cortex/blob/b1ec5f5b1c81bd202177075d2b506ed5057ae4e4/src/IECore/PNGImageReader.cpp#L127)
- [PTCParticleReader::close](https://github.com/ImageEngine/cortex/blob/dde831b51c95002db3424d4086a4702522a8e45e/src/IECoreRI/PTCParticleReader.cpp#L94)
- [StreamIndexedIO::StringCache::read](https://github.com/ImageEngine/cortex/blob/dde831b51c95002db3424d4086a4702522a8e45e/src/IECore/StreamIndexedIO.cpp#L262)
",,10654465
1108,Renderers to use doubles instead of (or in addition to) floats,open,2014-06-06T01:57:02Z,2014-06-06T16:55:56Z,,MEMBER,"SceneInterface provides transforms as M44d, but the Renderers only accept M44f. I think there are other cases where we have to convert between the two all the time as well. Can we just support double now? Or both at least? Does this seem reasonable for Cortex 9 or should it wait?
","Cool - ImageEngine/gaffer#860, in the Misc Enhancements milestone for now.
",10654465
1109,LinkedScenes etc: working out what file you're actually reading,open,2014-05-14T21:51:49Z,2014-05-31T04:30:41Z,,CONTRIBUTOR,"Hello,

I've got a local version of cortex where you can query a couple of invisible attributes called ""sceneInterface:file:name"" and ""sceneInterface:file:scenePath"" from SceneCaches, which return the scene cache file name and location path respectively. This is so you can work out what file you're actually reading in a LinkedScene, or my IERendering::ParticleScene, so you can build proper hashes in gaffer scene readers where there's instancing. I realise that this probably won't make sense if we start playing with gaffer scene interfaces etc, but we need some way of working these things out... sceneInterface:objectHash, sceneInterface:attributeHash etc? What do we reckon?
","After some internal discussion, we believe that computing hashes in the SceneInterface could solve this problem and also go in the direction pointed by issue #219, which has a pull request #274 to start addressing it. The overall idea is to try providing reliable hashes from IndexedIO that the SceneInterface can use and that will also make the implementation of the SceneCache reader node in Gaffer to have a straight forward implementation.
",10654465
1110,Support MissingBehaviour argument in CompoundData and CompoundObject,open,2014-05-09T10:49:34Z,2019-06-18T19:56:44Z,,MEMBER,"Currently the CompoundData and CompoundObject member() methods take a clunky pair of ( throwExceptions, createIfMissing ) bools, rather than the nice MissingBehaviour enum we use in IndexedIO and SceneCache. Make them use a MissingBehaviour enum instead.

Should we define another enum with the same values, or move the MissingBehaviour enum to the global namespace somewhere? If so, where?
",,10654465
1111,Create tags for animatedTransform and animatedAttribute in SceneCache,open,2014-03-28T00:36:00Z,2019-06-18T19:56:44Z,,CONTRIBUTOR,"We currently have no reliable way to detect when there's animated attributes or animated transforms without bounds (no objects) at any location in the hierarchy of a SceneCache.  

Our readers in Houdini and Maya rely on the boundSamples() as a hint for that, and set their outputs as dirty only when there are animated bounding boxes. This of course fails on the two situations described above...

If SceneCache writes sceneInterface:animatedTransform and sceneInterface:animatedAttribute tags we could distinguish these cases. But this means creating two new tags on the whole hierarchy when there's animation and we should check the file size and memory consumption before doing it.
",,10654465
1112,Optimize factory function for Object::create,open,2014-03-21T18:50:37Z,2019-06-18T19:56:04Z,,CONTRIBUTOR,"This has shown in some profiles, and I believe that by converting the map to InternedStrings it could help.
This would require changing the typeName() function to return InternedString.
",,10654465
1113,Use single V2f primvar for UV coordinates in Primitives,open,2014-03-20T21:16:16Z,2019-06-18T19:56:12Z,,CONTRIBUTOR,"This is an old todo that I believe is about time to address. Will probably have a lot of repercussion. 
",,10654465
1114,Improve native bounding box drawing in IECoreGL,open,2014-03-20T21:12:13Z,2019-06-18T19:56:04Z,,CONTRIBUTOR,"We should improve this to improve visualization in large scenes.
",,10654465
1115,Package cleanup and contrib,open,2014-03-20T21:10:26Z,2019-06-18T19:56:12Z,,CONTRIBUTOR,"This is an offline discussion that aims on simplifying Cortex packages by:

A) Reassessing whether we should break IECore into sub-packages ( IECoreMath, IECoreRendering, IECoreData, IECoreAlgo, etc)

B) Moving classes to Contrib and making them optional: old stuff, optional stuff, not so well thought out stuff. Maybe we could be more flexible in terms of binary compatibility for things moved to Contrib?

C) Use pyilmbase for Imath python bindings. What do we do with Imath extensions we have?

We can discuss here about these three big changes that may be addressed separately, once we have a plan.
",,10654465
1116,Lazy computation of prim vars in IECoreGL,open,2014-03-07T01:34:50Z,2014-03-07T17:09:33Z,,CONTRIBUTOR,"I think that drawing could be greatly improved by doing lazy computation on the conversion of IECore Primitives to IECoreGL primitives or to gl buffers, not to mention reduce memory consumption. 

Ideally it should be driven by the primVars that the GL shaders see.
","Hi John, to be frank, me too. I haven't seen this for a while but wanted to leave as something to check when looking at Cortex 9 improvements. 

I believe I saw the TriangulateOp in the profile back then. So I figured that we are triangulating all the primVars before knowing which ones are actually necessary for GL view. I guess our readers could remove primVars as you suggested... for now it would work. But if we start supporting shaders in the SceneReaders than they won't necessarily know which primVars are important.

So when I said lazy conversion, it was more referring to the translation IECore.Primitive to IECoreGL.Primitive. Either make it lazy or drop this intermediate representation and do straight conversions to GL buffers. I agree that all that should only take place if improves performance...
",10654465
1117,Consider adding time variable hierarchy to SceneInterface,open,2014-03-07T01:23:32Z,2014-03-07T10:54:36Z,,CONTRIBUTOR,"Our implementation of HoudiniScene (derived from SceneInterface) has an add-hoc method to specify the time in which we want to query the hierarchy that is coming out of the Houdini nodes.

Also, we are starting to consider implementing a GafferScene (also derived from SceneInterface) where the hierarchy is also dependent on time.

Let's discuss here what would be the advantages of doing this and also the challenges.
","My gut feeling on this is that I'd really like to not complicate things any further in the SceneInterface - I like the simplicity of a hierarchy which is constant through time. I'd rather have a few special cases here and there for specific use cases in Houdini/Gaffer than I would have to make all code that ever deals with a SceneInterface able to cope with a time-varying hierarchy. If that number of special use cases grows then the balance changes and it might be preferable to deal with things everywhere, but I'm not convinced that we need to just yet.

Perhaps our internal discussions about approaches to instancing should inform this decision too. If it turns out that we're going to procedurally instance onto them at render time (which I think makes sense), then we don't have so much need to store a time varying hierarchy on disk anyway?
",10654465
1118,LRUCache with constant access time,open,2014-02-22T17:24:55Z,2019-06-18T19:56:12Z,,CONTRIBUTOR,"As we rely more on the LRUCache, I believe would be beneficial to use associative maps with constant access time for find operations. Should also pay attention to memory consumption. Consider passing the map to be used as a template parameter as well.
","Issue #205 is all about that very thing - and the protected Object::MemoryAccumulator class is already some way to being the context object you're talking about.
",10654465
1119,Consider memory deduplication in Object::load method (Cortex 9),open,2014-02-11T17:05:51Z,2019-06-18T19:56:04Z,,CONTRIBUTOR,"Currently we have in our StreamIndexedIO all the information would be required for high level Object deduplication at load time.

The Objects when saved, flush their directories into a sub-index in the StreamIndexedIO, which is deduplicated. So identical Objects are currently saved in identical Sub-index data blocks. 

I believe we could add a hash() method to IndexedIO that would uniquely identify the current location and in case of a sub-index, it would use it's offset in the file. Then we could use a ComputationCache in the Object::load method to reuse loaded objects. The main drawback I can see is that for objects that are not repetitive, we would have an additional copy() call once we get them from the cache...

Just an idea to consider. If we have that, then the cache mechanisms in SceneCache reader will be unnecessary and we would save memory when loading models with repetitive structures.
","An alternative to not affect Object::load method is to, instead, add a method to SampledSceneInterface for returning hashes of the stored IECore::Objects and then the cache mechanism would remain in the SceneCache object. We would still require a hash function in IndexedIO.
",10654465
1120,Improve ObjectPool memory tracking,open,2014-01-09T11:42:18Z,2019-06-18T19:56:44Z,,MEMBER,"The current mechanism for tracking memory usage in an ObjectPool is rather simplistic, simply adding Object::memoryUsage() to the total when adding an object and subtracting it when removing an object.

In reality, many objects share the same child objects, so we are overcounting our memory usage, and therefore removing objects from the pool in unnecessary attempt to keep below memory limits. We should fix this.

Note that when counting the memory for an individual object with Object::memoryUsage, we already have an awareness of when the same child object is referenced twice, and don't overcount there, using the Object::MemoryAccumulator class - I suspect we could use a persistent version of something like this class inside the ObjectPool.
","Note that this is related to topics discussed in #195, so we might be able to address the Houdini version of the same issue at the same time.
",10654465
1121,IECore.warning doesn't handle evaluated code,open,2013-10-24T17:12:53Z,2013-10-24T18:11:10Z,,MEMBER,"IECore.warning (and similar commands) fail when the warning is issued from an evaluated python script with the following error message:

```
File ""/software/apps/cortex/8.0.0-a20/cent6.x86_64/maya/2014/python/IECore/Log.py"", line 81, in __getCallContext
callStr = f.f_globals[""__name__""]
KeyError: '__name__'
```

Evaluated python scripts are, for example, ones that are defined in config files.
","I like the functionality of getting the current context automatically, and would like to keep it.
If most people think that this kind of functionality shouldn't be in cortex, then I'd probably add them to my own code, outside cortex.
But personally, I would vote for keeping those functions there and simply fix the bug in question.
",10654465
1122,Sphere primitive generator improvements,open,2013-09-27T21:18:47Z,2019-06-18T20:04:11Z,,CONTRIBUTOR,"Currently the sphere primitive in mesh mode is generating as quads. These do not subdiv nicely.

Also - the poles are a bit funky when subdived and the verts along the seam don't appear to be correctly merged.

cheers

(these problems manifesting in gaffer)
![screenshot](https://f.cloud.github.com/assets/3977628/1229505/5bf611c6-27ba-11e3-9bb1-14f5815e6418.png)
",,10654465
1123,Houdini Light Converters,open,2013-07-18T00:49:45Z,2019-06-18T19:56:04Z,,MEMBER,"We'd like to be able to convert IECore::Lights to and from Houdini. Once we have this, we could start storing light rigs in SceneCache files.
","This one seems like it needs plenty of thought to me. We need to decide whether or not there are common properties of lights we can represent across all packages, and how we go about representing non-common properties. We also need to decide whether lights are objects in their own right or something more like cameras or coordinate systems that happen to have light shaders assigned. The IERendering approach has been that lights are first class objects, and that's the Gaffer approach too so far, but there are a few things that need working out about that still.
",10654465
1124,Houdini Camera Converters,open,2013-07-18T00:49:11Z,2019-06-18T19:56:04Z,,MEMBER,"We'd like to be able to convert IECore::Cameras to and from Houdini. Once we have this, we could start storing cameras in SceneCache files, allowing us to ditch FBX from our pipeline completely.
",,10654465
1125,Version 1.45.0,open,2020-03-12T18:24:38Z,2020-03-12T18:24:38Z,,CONTRIBUTOR,Issue to be added to all changes in 1.45.0,,3305584
1126,error while running mothur ,open,2020-02-25T05:07:47Z,2020-03-02T17:42:53Z,,NONE,"did not complete pcr.seqs.
how to resolve this error in mothur ","Could you tell me more? 

What version of mothur are your running? 

What pcr.seqs command did you run?",3305584
1127,Add opti method to classify.seqs,open,2020-02-03T19:41:42Z,2020-02-03T19:41:49Z,,CONTRIBUTOR,"1. Assign reference sequences to OTUs based on taxonomic assignment
2. Find distance (average??) ratio for OTU - shortcut files
3. Fit query reads to reference OTUs
    - Find tp, tn, fp, fn values, based on how query read effects ref OTUs distance. 
4. Bootstrapping
    - Sample with replacement columns from alignment to confirm query assignment.
",,3305584
1128,Create a report datatype,open,2019-12-04T18:15:20Z,2020-03-12T18:26:03Z,,CONTRIBUTOR,"Mothur currently has several report file types:

align report
contains report
chimeras
summary

These files types include a header. Each row has a sequence name and related data.",,3305584
1129,"How to select the ""start"" and ""end"" positions for screen.seqs",open,2019-11-19T07:46:15Z,2019-11-19T18:04:46Z,,NONE,"Hi everyone!
I came across the fact that my start and end positions are differing in the summary.seqs table which I will mention below. I want to know how one can select the correct start & end positions for our screen.seqs command in order to eliminate unwanted sequences. I have done V3-V4 sequencing of my sample with Illumina MiSeq. 
In fact, I experimented with trying two cases for the summary.seqs table below:

```
Start	End	NBases	Ambigs	Polymer	NumSeqs
Minimum:	1044	6098	17	0	3	1
2.5%-tile:	1044	13133	453	0	4	485
25%-tile:	1044	13871	499	0	5	4848
Median: 	1044	13871	514	0	5	9696
75%-tile:	1044	13871	516	0	5	14543
97.5%-tile:	1044	14286	529	0	7	18906
Maximum:	43053	43116	531	0	8	19390
Mean:	1046	13851	505	0	5
 of Seqs:	19390
```

1. start = 1044 and end = 13871, for which at the very end of the protocol, after the classify.otu command OTU count is 1063 OTUs
2. start = 1044 and end = 14286, for which at the very end of the protocol, after the classify.otu command OTU count is 218 OTUs

How should I go about to select these positions if I am getting such large differences in this sample?
Kindly help me as soon as possible.

Regards,
Keertana","Dear Dr Schloss,
Thank you so much for the explanation. I figured as much but was waiting to
hear from the experts themselves. This will be very helpful for me.

Sincerely,
Keertana Tallapragada

MSc Molecular Microbiology
University of Hyderabad,
Hyderabad, India.
Email: *tkeertana@gmail.com <tkeertana@gmail.com>*



On Tue, Nov 19, 2019 at 10:52 PM Pat Schloss <notifications@github.com>
wrote:

> Hi,
>
> The parameters you probably want are start=1044 and end=13871. This
> probably results in a loss of 2000 to 4000 sequences. If you use the second
> set of parameters you list, you'll likely be losing about 17000 sequences
> since not many of the sequences end at or after 14286. Because of the large
> reduction in the number of sequences, the number of OTUs would also be far
> fewer than what you have with the first approach.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mothur/mothur/issues/689?email_source=notifications&email_token=AN2AYRTWPBIXVUOS3LYEQKDQUQOGTA5CNFSM4JO7GZFKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEPAH4A#issuecomment-555615216>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AN2AYRQOAFZNBLKS6D63YOLQUQOGTANCNFSM4JO7GZFA>
> .
>
",3305584
1130,Chimera searching very slow,open,2019-11-14T20:29:21Z,2019-12-02T17:08:51Z,,NONE,"Let me know if this is a question better asked in another forum. I'm using mothur to do some QC on data from a highly multiplexed amplicon sequencing panel (~135 primer pairs x 48 samples). I'm having problems with chimera.vsearch running for too many (4+ days currently and <30% finished). From looking at the log files, it appears that the checking of each combination of sample x primer pair is being run sequentially rather than any parallelization happening. I thought I recalled reading in mothur docs somewhere that vsearch did not parallelize, but that is not what I understood from reading the vsearch github description. My mothur script is short and pasted below, so please let me know if there's something I've done in the workflow that's creating a problem. Thank you so much for your help.

set.dir(input=raw_seqs, output=/scratch/mothur, tempdefault=/scratch/mothur)
make.contigs(ffastq=Undetermined_S0_L001_R1_001.fastq, rfastq=Undetermined_S0_L001_R2_001.fastq, findex=Undetermined_S0_L001_I1_001.fastq, rindex=Undetermined_S0_L001_I2_001.fastq, processors=40, format=illumina1.8+, oligos=191018.oligos, bdiffs=0, pdiffs=0, checkorient=t, insert=25, trimoverlap=f)
rename.file(fasta=current, group=current, prefix=sal)
summary.seqs()
screen.seqs(fasta=current, group=current, maxambig=0, maxlength=325)
summary.seqs()
unique.seqs(fasta=current)
summary.seqs()
chimera.vsearch(fasta=current, name=current, group=current, dereplicate=t, processors=40)
remove.seqs(fasta=current, accnos=current, name=current, group=current, dups=t)
summary.seqs()
split.groups(fasta=current, group=current)
quit()","The chimera.vsearch command is parallelized and divides the work by assigning each processor a set of the samples to process. Each process then calls the split.groups / get.seqs commands which find the names of the sequences present in each sample and selects the reads from the fasta file. This step requires reading the fasta input file. These new parsed files are sent to the vsearch program for analysis. The chimera.vsearch command then assembles the vsearch program results for you. This assembly includes editing the counts for the sequences in the count file to reflect which samples found which sequences to be chimeric.

1. The splitting of the dataset into individual samples is the source of the issue. With 10K samples mothur is reading the fasta file 10k times and writing 10K temp files for vsearch. This will use a lot of time and memory. 

2. You can run the chimera.vsearch command on the entire dataset without splitting by sample. We recommend the splitting by sample because its the more conservative approach. To run the command without parsing: 

NOTE: your count file cannot contain groups. You can remove the group columns manually or run the following to remove them:

mothur > deunique.seqs(fasta=yourFastaFile, count=yourCountFile) - create fasta file will all reads. This could be huge.
mothur > unique.seqs(format=count) - create count file without groups
mothur > chimera.vsearch(fasta=current, count=current, reference=self) - flag sequences chimeric in whole dataset
mothur > remove.seqs(fasta=current, count=yourCountFile) - remove chimeras from fasta and original count file that includes groups
 
3. Paralellizing split.groups would not improve the speed with the command. 
",3305584
1131,Add format option to merge.taxsummary,open,2019-09-19T15:09:45Z,2020-02-14T14:19:21Z,,CONTRIBUTOR,"Currently, merge.taxsummary can only process the detailed format of the summary file. 

* Add a format parameter
* Modify merge.taxsummary to enable processing simple format",,3305584
1132,Make biom read format more flexible,open,2018-10-16T13:18:42Z,2020-01-06T13:50:10Z,,CONTRIBUTOR,"Mothur expects the id field to be first in the taxonomy definition, but it should be allowed anyway in the string to make it compatible with MEGAN output.

Mothur expects something like:

{""id"":""Otu01"", ""metadata"":{""taxonomy"":[""Bacteria"", ""Bacteroidetes"", ""Bacteroidia"", ""Bacteroidales"", ""Porphyromonadaceae"", ""unclassified""], ""bootstrap"":[100, 100, 100, 100, 100, 100]}}

also allow for lines like:

{""metadata"":{""taxonomy"":[""Root"",""cellular organisms"",""Eukaryota"",""Opisthokonta"",""Fungi"",""Fungi incertae sedis"",""Mucoromycota"",""Glomeromycotina"",""Glomeromycetes"",""Glomerales"",""Glomeraceae"",""Glomus""]},""id"":""4875""}",,3305584
1133,Improve Testing Coverage,open,2018-07-31T20:01:17Z,2018-07-31T20:01:17Z,,CONTRIBUTOR,"* Add Unit Tests for existing mothur code
* Improve Integration Test and add them to github",,3305584
1134,Incorporate c++11 functions for optimization,open,2017-09-29T13:07:04Z,2018-09-06T12:59:41Z,,CONTRIBUTOR,"Math functions:
* http://en.cppreference.com/w/cpp/numeric/math

",Replaced RNG class with random number generators in standard c++11.,3305584
1135,accept interleaved fastq file format,open,2017-08-16T15:54:14Z,2017-08-31T12:54:16Z,,NONE,"Hi, since some sequencing centers provide paired-end fastq files in the interleaved, 8-line format instead of as separate forward and reverse files, it would be great if mothur could accept this format in `make.contigs` or perhaps convert to the paired files format in `fastq.info`.

Thanks!

Robin

interleaved format meaning eg:
```
@read1forward
ATGCATCG
+
qualityscores
@read1reverse
ATGCATCG
+
qualityscores
@read2forward
ATGCGCGA
+
@read2reverse
ATGCGCAG
+
qualityscores
```",This is the first I've heard of this as a format generated from a sequencing center. I think the separate fastq files would be preferred - it would be better and safer for the sequencing provider to do it than us since separate is the MiSeq's default. I'd put this on the back burner unless we see more requests for the feature.,3305584
1136,Code Cleanup ,open,2016-05-12T12:24:02Z,2019-03-21T20:04:50Z,,CONTRIBUTOR,"- [ ] Remove dependencies as much as possible
- [ ] Break apart large classes into simpler smaller classes that are easier to test
- [ ] Remove unused code
- [ ] Look for potential reuse ",Phase out name / group file in favor of count table. Will improve memory use and speed.,3305584
1137,Improve Mothur's Documentation,open,2015-11-16T15:24:41Z,2019-01-31T18:50:26Z,,CONTRIBUTOR,"Do we want to add ""Common Questions"" sections to each command page? 
- The first steps to an auto-help in a web app.
- Send a link or copy and paste to simplify a portion of user support over time.  

Your thoughts, @pschloss?
","* Add common questions function for each command within mothur. This info can be displayed using the commands help() function. For example:

mothur > align.seqs(help)

Common Questions: 


Common Issues: 

1. ...template is not aligned, aborting. What do I do?
	Mothur requires the reference file to be aligned to generate aligned sequences. You can download mothur's aligned silva references here, https://mothur.org/wiki/Silva_reference_files. For ITS sequences, see 'how to' below.

2. ...xxx of your sequences generated alignments that eliminated too many bases... What does this mean?
	By default, mothur will align the reverse compliment of your sequences when the alignment process removes more than 50% of the bases indicating the read may be flipped. This process assembles the best possible alignment, and downstream analysis will remove any poor quality reads remaining.


How To: 

1. How do I 'align' ITS sequences?
	You really can't do an alignment because there isn't positional homology. You can use the pre.cluster and pairwise.seqs commands to generate a distance matrix from unaligned sequences.

2. How do I create a custom reference for the region I am studying?
	You can tailor your reference using this method: http://blog.mothur.org/2016/07/07/Customization-for-your-region/.


The align.seqs command reads a file containing sequences and creates an alignment file and a report file.
The align.seqs command parameters are align, fasta, flip, gapextend, gapopen, inputdir, ksize, match, mismatch, outputdir, processors, reference, search, seed, threshold.
The reference and fasta parameters are required. You may leave fasta blank if you have a valid fasta file.
The search parameter allows you to specify the method to find most similar reference sequence.  Your options are: suffix, kmer and blast. The default is kmer.
The align parameter allows you to specify the alignment method to use.  Your options are: gotoh, needleman, blast and noalign. The default is needleman.
The ksize parameter allows you to specify the kmer size for finding most similar reference to a given sequence.  The default is 8.
The match parameter allows you to specify the bonus for having the same base. Default=1.0.
The mistmatch parameter allows you to specify the penalty for having different bases. Default=-1.0.
The gapopen parameter allows you to specify the penalty for opening a gap in an alignment. Default=-5.0.
The gapextend parameter allows you to specify the penalty for extending a gap in an alignment. Default=-2.0.
If the flip parameter is set to true the reverse complement of the sequence is aligned and the better alignment is reported. By default, mothur will align the reverse compliment of your sequences when the alignment process removes more than 50% of the bases indicating the read may be flipped. This process assembles the best possible alignment, and downstream analysis will remove any poor quality reads remaining.
The threshold is used to specify a cutoff at which an alignment is deemed 'bad' and the reverse complement may be tried. The default threshold is 0.50, meaning 50% of the bases are removed in the alignment.
The align.seqs command should be in the following format: align.seqs(reference=yourTemplateFile, fasta=yourUnalignedFastaFile)
Example: align.seqs(fasta=water.fasta, template=silva.v4.fasta)

* This should also be added to the command's wiki page.",3305584
1138,added typescript definition as best i could. ,open,2018-01-02T20:57:42Z,2018-01-14T13:14:10Z,,NONE,"altspace uses the THREE global so does not integrate with THREE.js as i hoped it would but it is still usable from typescript. 
the bundler adds the altspace and three.js libs to the compiled output. 
Much more to add to the definitions file.","I have had some trouble using these, i cant seem to get the scene to render in altspace when using the compiled output. i can access the api ok and the sdk appears to work ( getUser/getSpace/getEnclosure all work and resolve as they should ) but no objects appear int he scene. 

I will investigate more once i have more time on this. ",33642201
1139,HoverScale Improvements,open,2017-05-28T23:43:51Z,2017-12-01T01:21:00Z,,CONTRIBUTOR,"* Added eventListener property to HoverScale behavior to allow other objects to trigger cursor events on behalf of the object that owns the behavior.
* Improved animation accuracy when HoverScale cursor hover state is changed mid-animation.","Sorry for the delay. Finally got around to trying it out, it looks good! We'll merge it in with the next SDK push. Sound good?",33642201
1140,Implement profile and initialSerializationBufferSize options to altspace.utilities.Simulation.,open,2017-05-02T04:03:17Z,2017-12-01T01:21:00Z,,CONTRIBUTOR,* Added profile and initialSerializationBufferSize options to altspace.utilities.Simulation.,"Thanks for the PR. We intend to expose these across the board (including in a-frame), but I'm going to hold off for now because we're planning changes to the profiler.",33642201
1141,Adding linear interpolation support to Object3DSync behavior,open,2016-12-15T10:52:19Z,2018-03-10T01:51:56Z,,CONTRIBUTOR,"Updated Object3DSync behavior to support linear interpolation for position and scale updates, and spherical linear interpolation for rotation updates, which aids in smoothing out jerky object synchronization.

Interpolation is currently enabled by default, and can be explicitly enabled or disabled on creation of the behavior with config parameters.  For example:
`obj.addBehavior(Object3DSync({ position: true, rotation: true, scale: true, lerp: { position: true, rotation: true, scale: false, duration: 150 } }));`","Off by default might be best.  If the coder is doing stuff like testing object distances to detect a game event, they probably expect the objects to snap to position on clients.  I do expect most people to always use it though.  The side-effects of lerp syncing on clients is minimal.

Another useful behavior to consider is a ""lerpMove"" behavior that animates object transforms on the local PC as well, but special care must be given to make a lerpMove behavior play nice with a lerpSync behavior on the same object.",33642201
1142,Please remove the THREE.js requirement for including altspace.js,open,2015-11-19T22:40:12Z,2015-11-24T19:25:44Z,,NONE,"Currently you have to include three.js even if you don't have 3D elements.

``` html
<script src=""http://sdk.altvr.com/libs/three.js/r71/build/three.min.js""></script>
<script src=""http://sdk.altvr.com/libs/altspace.js/latest/altspace.min.js""></script>
```

Ideally you could just include altspace and make use of the firebase connection for interesting 2D applications in VR.
","That may be tricky given that a number of the utilities use three.js classes, but worth thinking about. Perhaps making it easier to use the individual utilities would be a way to go.
",33642201
1143,Traffic resolution: Pure DAIDALUS stops the drone.,open,2020-01-11T16:21:03Z,2020-03-07T13:03:36Z,,NONE,"Hi,

I've run into a new issue with the traffic module. Summoning an intruder can stop the drone dead in its tracks for no clear reason as shown in the attachment. 

![Capture d'écran de 2020-01-11 17-13-42](https://user-images.githubusercontent.com/56804233/72207157-699f2e80-3496-11ea-9e12-4b893bfb404e.png)

On this picture the intruder on the right did not trigger the traffic resolution but the one on the left did and stopped the drone even tough it wasn't on its trajectory.   

Thank you for your help !","@Fauconer For you convenience, we have updated Icarous to work with the latest version of MAVProxy. This was tested on 1.8.18. You should be able to use the SetupMavProxy.sh script with the GitHub version as usual. Alternately, you can also consider using  [WebGCS](https://github.com/nasa/webgs).

@marselomeri  I've explained why this happens in this comment [here](https://github.com/nasa/icarous/issues/62#issuecomment-582513273). The simulator will not takeoff until it acquires a 3D fix. You'll have to wait till you see the appropriate messages before sending the start command from Icarous.

",66090748
1144,Restarting Eclipse and opening Extended Configuration Editor removes configurable attribute values,open,2020-03-23T10:30:51Z,2020-03-23T13:20:20Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  `4.12`
* **FeatureIDE-Version:**  `issue_978TheSecond`
* **Operating system:** `Windows`


### Issue description
After editing the values of configurable attributes in the feature attribute view, they are persistently stored. If I close the config and reopen it, the values are still available. However, restarting the eclipse instance the vales are removed once the config is open. It makes no difference whether the config was still open from the last session or not.
Part of #978

How to reproduce:
1. Create Extended Feature Model
2. Add Feature attribute with configurable flag 
3. Create Extended Configuraion
4. Provide value for configurable attribute with the extended configuration open
5. (Optional) Close extended configuration
6. Restart eclipse instance
7. If closed, open extended configuration

Expected behavior: Added attribute values are still there.
Actual behavior: All configurable attribute values are deleted.
",,13869700
1145,"""import feature model"" can only be accessed by right-clicking a feature model. Also: Rework import feature model so it can be added to eclipse import wizards.",open,2020-03-15T16:16:51Z,2020-03-24T14:23:32Z,,COLLABORATOR,"I'm pretty sure it should be accessible under ""Import..."" like the other import wizards. Or under the FeatureIDE submenu when right-clicking a FeatureIDE project.

The import feature model action should be reworked to be more like other eclipse import wizards. Allow converting to feature model formats.",,13869700
1146,A lot of exceptions thrown when trying to import feature model,open,2020-03-15T16:12:26Z,2020-03-24T14:28:53Z,,COLLABORATOR,"This bug currently exists on the develop and release3.6 branches.

```
!ENTRY org.eclipse.ui 4 0 2020-03-15 17:01:05.824
!MESSAGE Unhandled event loop exception
!STACK 0
java.lang.NullPointerException
	at de.ovgu.featureide.fm.ui.editors.FeatureUIHelper.getGraphicalFeature(FeatureUIHelper.java:75)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshTargetDecoration(ConnectionEditPart.java:288)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshVisuals(ConnectionEditPart.java:196)
	at org.eclipse.gef.editparts.AbstractEditPart.refresh(AbstractEditPart.java:725)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:644)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.refresh(AbstractConnectionEditPart.java:226)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.addNotify(AbstractConnectionEditPart.java:100)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.setParent(AbstractConnectionEditPart.java:268)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.setSource(AbstractConnectionEditPart.java:282)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addSourceConnection(AbstractGraphicalEditPart.java:260)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refreshSourceConnections(AbstractGraphicalEditPart.java:697)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:645)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.FeatureEditPart.refresh(FeatureEditPart.java:193)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractEditPart.addChild(AbstractEditPart.java:212)
	at org.eclipse.gef.editparts.AbstractEditPart.refreshChildren(AbstractEditPart.java:781)
	at org.eclipse.gef.editparts.AbstractEditPart.refresh(AbstractEditPart.java:726)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:644)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractEditPart.addChild(AbstractEditPart.java:212)
	at org.eclipse.gef.editparts.SimpleRootEditPart.setContents(SimpleRootEditPart.java:105)
	at org.eclipse.gef.ui.parts.AbstractEditPartViewer.setContents(AbstractEditPartViewer.java:617)
	at org.eclipse.gef.ui.parts.AbstractEditPartViewer.setContents(AbstractEditPartViewer.java:626)
	at de.ovgu.featureide.fm.ui.editors.FeatureDiagramEditor$4.run(FeatureDiagramEditor.java:777)
	at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:233)
	at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:144)
	at org.eclipse.swt.widgets.Display.syncExec(Display.java:4567)
	at de.ovgu.featureide.fm.ui.editors.FeatureDiagramEditor.propertyChange(FeatureDiagramEditor.java:771)
	at de.ovgu.featureide.fm.core.base.event.DefaultEventManager.callListener(DefaultEventManager.java:68)
	at de.ovgu.featureide.fm.core.base.event.DefaultEventManager.fireEvent(DefaultEventManager.java:62)
	at de.ovgu.featureide.fm.core.io.manager.AFileManager.fireEvent(AFileManager.java:256)
	at de.ovgu.featureide.fm.core.io.manager.AFileManager.overwrite(AFileManager.java:448)
	at de.ovgu.featureide.fm.ui.editors.EclipseExternalChangeListener$1.run(EclipseExternalChangeListener.java:80)
	at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:233)
	at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:144)
	at org.eclipse.swt.widgets.Display.syncExec(Display.java:4567)
	at de.ovgu.featureide.fm.ui.editors.EclipseExternalChangeListener.doUpdate(EclipseExternalChangeListener.java:55)
	at de.ovgu.featureide.fm.core.io.ExternalChangeListener.update(ExternalChangeListener.java:35)
	at de.ovgu.featureide.fm.core.io.manager.AFileManager.read(AFileManager.java:388)
	at de.ovgu.featureide.fm.core.io.manager.EclipseFileChangeVisitor.visit(EclipseFileChangeVisitor.java:45)
	at org.eclipse.core.internal.events.ResourceDelta.accept(ResourceDelta.java:64)
	at org.eclipse.core.internal.events.ResourceDelta.accept(ResourceDelta.java:74)
	at org.eclipse.core.internal.events.ResourceDelta.accept(ResourceDelta.java:74)
	at org.eclipse.core.internal.events.ResourceDelta.accept(ResourceDelta.java:48)
	at de.ovgu.featureide.fm.ui.editors.EclipseExternalChangeListener.resourceChanged(EclipseExternalChangeListener.java:91)
	at org.eclipse.core.internal.events.NotificationManager$1.run(NotificationManager.java:297)
	at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)
	at org.eclipse.core.internal.events.NotificationManager.notify(NotificationManager.java:287)
	at org.eclipse.core.internal.events.NotificationManager.broadcastChanges(NotificationManager.java:150)
	at org.eclipse.core.internal.resources.Workspace.broadcastPostChange(Workspace.java:376)
	at org.eclipse.core.internal.resources.Workspace.endOperation(Workspace.java:1499)
	at org.eclipse.core.internal.resources.File.setContents(File.java:344)
	at org.eclipse.core.internal.resources.File.setContents(File.java:434)
	at de.ovgu.featureide.fm.core.io.EclipseFileSystem.write(EclipseFileSystem.java:83)
	at de.ovgu.featureide.fm.core.io.FileSystem.write(FileSystem.java:57)
	at de.ovgu.featureide.fm.core.io.manager.SimpleFileHandler.write(SimpleFileHandler.java:271)
	at de.ovgu.featureide.fm.core.io.manager.SimpleFileHandler.save(SimpleFileHandler.java:152)
	at de.ovgu.featureide.fm.ui.handlers.ImportHandler.singleAction(ImportHandler.java:122)
	at de.ovgu.featureide.fm.ui.handlers.base.AFileHandler.singleAction(AFileHandler.java:43)
	at de.ovgu.featureide.fm.ui.handlers.base.ASelectionHandler.execute(ASelectionHandler.java:53)
	at org.eclipse.ui.internal.handlers.HandlerProxy.execute(HandlerProxy.java:291)
	at org.eclipse.ui.internal.handlers.E4HandlerProxy.execute(E4HandlerProxy.java:93)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.e4.core.internal.di.MethodRequestor.execute(MethodRequestor.java:55)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invokeUsingClass(InjectorImpl.java:318)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invoke(InjectorImpl.java:252)
	at org.eclipse.e4.core.contexts.ContextInjectionFactory.invoke(ContextInjectionFactory.java:161)
	at org.eclipse.e4.core.commands.internal.HandlerServiceHandler.execute(HandlerServiceHandler.java:152)
	at org.eclipse.core.commands.Command.executeWithChecks(Command.java:494)
	at org.eclipse.core.commands.ParameterizedCommand.executeWithChecks(ParameterizedCommand.java:487)
	at org.eclipse.e4.core.commands.internal.HandlerServiceImpl.executeHandler(HandlerServiceImpl.java:204)
	at org.eclipse.e4.ui.workbench.renderers.swt.HandledContributionItem.executeItem(HandledContributionItem.java:433)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.handleWidgetSelection(AbstractContributionItem.java:446)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.lambda$2(AbstractContributionItem.java:472)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:86)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4118)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1052)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3931)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3534)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$5.run(PartRenderingEngine.java:1170)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1059)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)
	at org.eclipse.ui.internal.Workbench.lambda$3(Workbench.java:667)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:597)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)
	at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:152)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:656)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:592)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1498)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1471)

!ENTRY org.eclipse.e4.ui.workbench 4 0 2020-03-15 17:01:05.940
!MESSAGE 
!STACK 0
java.lang.NullPointerException
	at de.ovgu.featureide.fm.ui.editors.FeatureUIHelper.getGraphicalFeature(FeatureUIHelper.java:75)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshTargetDecoration(ConnectionEditPart.java:288)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshVisuals(ConnectionEditPart.java:196)
	at org.eclipse.gef.editparts.AbstractEditPart.refresh(AbstractEditPart.java:725)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:644)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.refresh(AbstractConnectionEditPart.java:226)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.addNotify(AbstractConnectionEditPart.java:100)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.setParent(AbstractConnectionEditPart.java:268)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.setSource(AbstractConnectionEditPart.java:282)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addSourceConnection(AbstractGraphicalEditPart.java:260)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refreshSourceConnections(AbstractGraphicalEditPart.java:697)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:645)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.FeatureEditPart.refresh(FeatureEditPart.java:193)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractEditPart.addChild(AbstractEditPart.java:212)
	at org.eclipse.gef.editparts.AbstractEditPart.refreshChildren(AbstractEditPart.java:781)
	at org.eclipse.gef.editparts.AbstractEditPart.refresh(AbstractEditPart.java:726)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:644)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractEditPart.addChild(AbstractEditPart.java:212)
	at org.eclipse.gef.editparts.SimpleRootEditPart.setContents(SimpleRootEditPart.java:105)
	at org.eclipse.gef.ui.parts.AbstractEditPartViewer.setContents(AbstractEditPartViewer.java:617)
	at org.eclipse.gef.ui.parts.AbstractEditPartViewer.setContents(AbstractEditPartViewer.java:626)
	at de.ovgu.featureide.fm.ui.editors.FeatureDiagramEditor.createPartControl(FeatureDiagramEditor.java:433)
	at org.eclipse.ui.part.MultiPageEditorPart.addPage(MultiPageEditorPart.java:241)
	at org.eclipse.ui.part.MultiPageEditorPart.addPage(MultiPageEditorPart.java:211)
	at de.ovgu.featureide.fm.ui.editors.FeatureModelEditor.addPage(FeatureModelEditor.java:451)
	at de.ovgu.featureide.fm.ui.editors.FeatureModelEditor.createPages(FeatureModelEditor.java:422)
	at org.eclipse.ui.part.MultiPageEditorPart.createPartControl(MultiPageEditorPart.java:348)
	at org.eclipse.ui.internal.e4.compatibility.CompatibilityPart.createPartControl(CompatibilityPart.java:153)
	at org.eclipse.ui.internal.e4.compatibility.CompatibilityEditor.createPartControl(CompatibilityEditor.java:99)
	at org.eclipse.ui.internal.e4.compatibility.CompatibilityPart.create(CompatibilityPart.java:364)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.e4.core.internal.di.MethodRequestor.execute(MethodRequestor.java:55)
	at org.eclipse.e4.core.internal.di.InjectorImpl.processAnnotated(InjectorImpl.java:1005)
	at org.eclipse.e4.core.internal.di.InjectorImpl.processAnnotated(InjectorImpl.java:970)
	at org.eclipse.e4.core.internal.di.InjectorImpl.internalInject(InjectorImpl.java:137)
	at org.eclipse.e4.core.internal.di.InjectorImpl.internalMake(InjectorImpl.java:412)
	at org.eclipse.e4.core.internal.di.InjectorImpl.make(InjectorImpl.java:331)
	at org.eclipse.e4.core.contexts.ContextInjectionFactory.make(ContextInjectionFactory.java:190)
	at org.eclipse.e4.ui.internal.workbench.ReflectionContributionFactory.createFromBundle(ReflectionContributionFactory.java:105)
	at org.eclipse.e4.ui.internal.workbench.ReflectionContributionFactory.doCreate(ReflectionContributionFactory.java:74)
	at org.eclipse.e4.ui.internal.workbench.ReflectionContributionFactory.create(ReflectionContributionFactory.java:56)
	at org.eclipse.e4.ui.workbench.renderers.swt.ContributedPartRenderer.createWidget(ContributedPartRenderer.java:129)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.createWidget(PartRenderingEngine.java:1012)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.safeCreateGui(PartRenderingEngine.java:672)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.safeCreateGui(PartRenderingEngine.java:778)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.access$0(PartRenderingEngine.java:749)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$2.run(PartRenderingEngine.java:743)
	at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.createGui(PartRenderingEngine.java:727)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl$1.handleEvent(PartServiceImpl.java:104)
	at org.eclipse.e4.ui.services.internal.events.UIEventHandler$1.run(UIEventHandler.java:40)
	at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:233)
	at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:144)
	at org.eclipse.swt.widgets.Display.syncExec(Display.java:4567)
	at org.eclipse.e4.ui.internal.workbench.swt.E4Application$1.syncExec(E4Application.java:212)
	at org.eclipse.e4.ui.services.internal.events.UIEventHandler.handleEvent(UIEventHandler.java:36)
	at org.eclipse.equinox.internal.event.EventHandlerWrapper.handleEvent(EventHandlerWrapper.java:201)
	at org.eclipse.equinox.internal.event.EventHandlerTracker.dispatchEvent(EventHandlerTracker.java:196)
	at org.eclipse.equinox.internal.event.EventHandlerTracker.dispatchEvent(EventHandlerTracker.java:1)
	at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230)
	at org.eclipse.osgi.framework.eventmgr.ListenerQueue.dispatchEventSynchronous(ListenerQueue.java:148)
	at org.eclipse.equinox.internal.event.EventAdminImpl.dispatchEvent(EventAdminImpl.java:135)
	at org.eclipse.equinox.internal.event.EventAdminImpl.sendEvent(EventAdminImpl.java:78)
	at org.eclipse.equinox.internal.event.EventComponent.sendEvent(EventComponent.java:39)
	at org.eclipse.e4.ui.services.internal.events.EventBroker.send(EventBroker.java:52)
	at org.eclipse.e4.ui.internal.workbench.UIEventPublisher.notifyChanged(UIEventPublisher.java:60)
	at org.eclipse.emf.common.notify.impl.BasicNotifierImpl.eNotify(BasicNotifierImpl.java:374)
	at org.eclipse.e4.ui.model.application.ui.impl.ElementContainerImpl.setSelectedElement(ElementContainerImpl.java:174)
	at org.eclipse.e4.ui.internal.workbench.ModelServiceImpl.showElementInWindow(ModelServiceImpl.java:634)
	at org.eclipse.e4.ui.internal.workbench.ModelServiceImpl.bringToTop(ModelServiceImpl.java:598)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.delegateBringToTop(PartServiceImpl.java:788)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.bringToTop(PartServiceImpl.java:401)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.showPart(PartServiceImpl.java:1238)
	at org.eclipse.ui.internal.WorkbenchPage.busyOpenEditor(WorkbenchPage.java:3277)
	at org.eclipse.ui.internal.WorkbenchPage.access$26(WorkbenchPage.java:3192)
	at org.eclipse.ui.internal.WorkbenchPage$10.run(WorkbenchPage.java:3174)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:71)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3169)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3133)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3114)
	at org.eclipse.ui.ide.IDE.openEditor(IDE.java:600)
	at de.ovgu.featureide.fm.ui.handlers.ImportHandler.openFileInEditor(ImportHandler.java:147)
	at de.ovgu.featureide.fm.ui.handlers.ImportHandler.singleAction(ImportHandler.java:124)
	at de.ovgu.featureide.fm.ui.handlers.base.AFileHandler.singleAction(AFileHandler.java:43)
	at de.ovgu.featureide.fm.ui.handlers.base.ASelectionHandler.execute(ASelectionHandler.java:53)
	at org.eclipse.ui.internal.handlers.HandlerProxy.execute(HandlerProxy.java:291)
	at org.eclipse.ui.internal.handlers.E4HandlerProxy.execute(E4HandlerProxy.java:93)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.e4.core.internal.di.MethodRequestor.execute(MethodRequestor.java:55)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invokeUsingClass(InjectorImpl.java:318)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invoke(InjectorImpl.java:252)
	at org.eclipse.e4.core.contexts.ContextInjectionFactory.invoke(ContextInjectionFactory.java:161)
	at org.eclipse.e4.core.commands.internal.HandlerServiceHandler.execute(HandlerServiceHandler.java:152)
	at org.eclipse.core.commands.Command.executeWithChecks(Command.java:494)
	at org.eclipse.core.commands.ParameterizedCommand.executeWithChecks(ParameterizedCommand.java:487)
	at org.eclipse.e4.core.commands.internal.HandlerServiceImpl.executeHandler(HandlerServiceImpl.java:204)
	at org.eclipse.e4.ui.workbench.renderers.swt.HandledContributionItem.executeItem(HandledContributionItem.java:433)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.handleWidgetSelection(AbstractContributionItem.java:446)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.lambda$2(AbstractContributionItem.java:472)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:86)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4118)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1052)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3931)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3534)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$5.run(PartRenderingEngine.java:1170)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1059)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)
	at org.eclipse.ui.internal.Workbench.lambda$3(Workbench.java:667)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:597)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)
	at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:152)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:656)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:592)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1498)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1471)

!ENTRY org.eclipse.e4.ui.workbench 4 2 2020-03-15 17:01:06.027
!MESSAGE Problems occurred when invoking code from plug-in: ""org.eclipse.e4.ui.workbench"".
!STACK 0
java.lang.ClassCastException: org.eclipse.ui.internal.ErrorEditorPart cannot be cast to de.ovgu.featureide.fm.ui.editors.FeatureModelEditor
	at de.ovgu.featureide.fm.ui.editors.featuremodel.FeatureModelEditorContributor.setActiveEditor(FeatureModelEditorContributor.java:71)
	at org.eclipse.ui.internal.EditorActionBars.partChanged(EditorActionBars.java:340)
	at org.eclipse.ui.internal.WorkbenchPage.updateActivations(WorkbenchPage.java:325)
	at org.eclipse.ui.internal.WorkbenchPage.access$18(WorkbenchPage.java:306)
	at org.eclipse.ui.internal.WorkbenchPage$E4PartListener.partActivated(WorkbenchPage.java:213)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl$3.run(PartServiceImpl.java:250)
	at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.firePartActivated(PartServiceImpl.java:247)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.activate(PartServiceImpl.java:772)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.activate(PartServiceImpl.java:681)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.activate(PartServiceImpl.java:676)
	at org.eclipse.ui.internal.WorkbenchPage.busyOpenEditor(WorkbenchPage.java:3285)
	at org.eclipse.ui.internal.WorkbenchPage.access$26(WorkbenchPage.java:3192)
	at org.eclipse.ui.internal.WorkbenchPage$10.run(WorkbenchPage.java:3174)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:71)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3169)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3133)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3114)
	at org.eclipse.ui.ide.IDE.openEditor(IDE.java:600)
	at de.ovgu.featureide.fm.ui.handlers.ImportHandler.openFileInEditor(ImportHandler.java:147)
	at de.ovgu.featureide.fm.ui.handlers.ImportHandler.singleAction(ImportHandler.java:124)
	at de.ovgu.featureide.fm.ui.handlers.base.AFileHandler.singleAction(AFileHandler.java:43)
	at de.ovgu.featureide.fm.ui.handlers.base.ASelectionHandler.execute(ASelectionHandler.java:53)
	at org.eclipse.ui.internal.handlers.HandlerProxy.execute(HandlerProxy.java:291)
	at org.eclipse.ui.internal.handlers.E4HandlerProxy.execute(E4HandlerProxy.java:93)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.e4.core.internal.di.MethodRequestor.execute(MethodRequestor.java:55)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invokeUsingClass(InjectorImpl.java:318)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invoke(InjectorImpl.java:252)
	at org.eclipse.e4.core.contexts.ContextInjectionFactory.invoke(ContextInjectionFactory.java:161)
	at org.eclipse.e4.core.commands.internal.HandlerServiceHandler.execute(HandlerServiceHandler.java:152)
	at org.eclipse.core.commands.Command.executeWithChecks(Command.java:494)
	at org.eclipse.core.commands.ParameterizedCommand.executeWithChecks(ParameterizedCommand.java:487)
	at org.eclipse.e4.core.commands.internal.HandlerServiceImpl.executeHandler(HandlerServiceImpl.java:204)
	at org.eclipse.e4.ui.workbench.renderers.swt.HandledContributionItem.executeItem(HandledContributionItem.java:433)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.handleWidgetSelection(AbstractContributionItem.java:446)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.lambda$2(AbstractContributionItem.java:472)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:86)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4118)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1052)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3931)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3534)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$5.run(PartRenderingEngine.java:1170)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1059)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)
	at org.eclipse.ui.internal.Workbench.lambda$3(Workbench.java:667)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:597)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)
	at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:152)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:656)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:592)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1498)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1471)

!ENTRY org.eclipse.e4.ui.workbench 4 0 2020-03-15 17:01:06.029
!MESSAGE An exception occurred while notifying part listeners
!STACK 0
java.lang.ClassCastException: org.eclipse.ui.internal.ErrorEditorPart cannot be cast to de.ovgu.featureide.fm.ui.editors.FeatureModelEditor
	at de.ovgu.featureide.fm.ui.editors.featuremodel.FeatureModelEditorContributor.setActiveEditor(FeatureModelEditorContributor.java:71)
	at org.eclipse.ui.internal.EditorActionBars.partChanged(EditorActionBars.java:340)
	at org.eclipse.ui.internal.WorkbenchPage.updateActivations(WorkbenchPage.java:325)
	at org.eclipse.ui.internal.WorkbenchPage.access$18(WorkbenchPage.java:306)
	at org.eclipse.ui.internal.WorkbenchPage$E4PartListener.partActivated(WorkbenchPage.java:213)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl$3.run(PartServiceImpl.java:250)
	at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.firePartActivated(PartServiceImpl.java:247)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.activate(PartServiceImpl.java:772)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.activate(PartServiceImpl.java:681)
	at org.eclipse.e4.ui.internal.workbench.PartServiceImpl.activate(PartServiceImpl.java:676)
	at org.eclipse.ui.internal.WorkbenchPage.busyOpenEditor(WorkbenchPage.java:3285)
	at org.eclipse.ui.internal.WorkbenchPage.access$26(WorkbenchPage.java:3192)
	at org.eclipse.ui.internal.WorkbenchPage$10.run(WorkbenchPage.java:3174)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:71)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3169)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3133)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:3114)
	at org.eclipse.ui.ide.IDE.openEditor(IDE.java:600)
	at de.ovgu.featureide.fm.ui.handlers.ImportHandler.openFileInEditor(ImportHandler.java:147)
	at de.ovgu.featureide.fm.ui.handlers.ImportHandler.singleAction(ImportHandler.java:124)
	at de.ovgu.featureide.fm.ui.handlers.base.AFileHandler.singleAction(AFileHandler.java:43)
	at de.ovgu.featureide.fm.ui.handlers.base.ASelectionHandler.execute(ASelectionHandler.java:53)
	at org.eclipse.ui.internal.handlers.HandlerProxy.execute(HandlerProxy.java:291)
	at org.eclipse.ui.internal.handlers.E4HandlerProxy.execute(E4HandlerProxy.java:93)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.e4.core.internal.di.MethodRequestor.execute(MethodRequestor.java:55)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invokeUsingClass(InjectorImpl.java:318)
	at org.eclipse.e4.core.internal.di.InjectorImpl.invoke(InjectorImpl.java:252)
	at org.eclipse.e4.core.contexts.ContextInjectionFactory.invoke(ContextInjectionFactory.java:161)
	at org.eclipse.e4.core.commands.internal.HandlerServiceHandler.execute(HandlerServiceHandler.java:152)
	at org.eclipse.core.commands.Command.executeWithChecks(Command.java:494)
	at org.eclipse.core.commands.ParameterizedCommand.executeWithChecks(ParameterizedCommand.java:487)
	at org.eclipse.e4.core.commands.internal.HandlerServiceImpl.executeHandler(HandlerServiceImpl.java:204)
	at org.eclipse.e4.ui.workbench.renderers.swt.HandledContributionItem.executeItem(HandledContributionItem.java:433)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.handleWidgetSelection(AbstractContributionItem.java:446)
	at org.eclipse.e4.ui.workbench.renderers.swt.AbstractContributionItem.lambda$2(AbstractContributionItem.java:472)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:86)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4118)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1052)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3931)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3534)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$5.run(PartRenderingEngine.java:1170)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1059)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)
	at org.eclipse.ui.internal.Workbench.lambda$3(Workbench.java:667)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:597)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)
	at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:152)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:656)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:592)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1498)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1471)

!ENTRY org.eclipse.ui 4 4 2020-03-15 17:01:06.202
!MESSAGE An internal error has occurred.
!STACK 0
java.lang.NullPointerException
	at de.ovgu.featureide.fm.ui.editors.FeatureUIHelper.getGraphicalFeature(FeatureUIHelper.java:75)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshTargetDecoration(ConnectionEditPart.java:288)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshVisuals(ConnectionEditPart.java:196)
	at org.eclipse.gef.editparts.AbstractEditPart.refresh(AbstractEditPart.java:725)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:644)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.refresh(AbstractConnectionEditPart.java:226)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.setTarget(AbstractConnectionEditPart.java:304)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshParent(ConnectionEditPart.java:203)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.ConnectionEditPart.refreshVisuals(ConnectionEditPart.java:195)
	at org.eclipse.gef.editparts.AbstractEditPart.refresh(AbstractEditPart.java:725)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:644)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.refresh(AbstractConnectionEditPart.java:226)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.addNotify(AbstractConnectionEditPart.java:100)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.setParent(AbstractConnectionEditPart.java:268)
	at org.eclipse.gef.editparts.AbstractConnectionEditPart.setSource(AbstractConnectionEditPart.java:282)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addSourceConnection(AbstractGraphicalEditPart.java:260)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refreshSourceConnections(AbstractGraphicalEditPart.java:697)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:645)
	at de.ovgu.featureide.fm.ui.editors.featuremodel.editparts.FeatureEditPart.refresh(FeatureEditPart.java:193)
	at org.eclipse.gef.editparts.AbstractEditPart.addNotify(AbstractEditPart.java:253)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.addNotify(AbstractGraphicalEditPart.java:223)
	at org.eclipse.gef.editparts.AbstractEditPart.addChild(AbstractEditPart.java:212)
	at org.eclipse.gef.editparts.AbstractEditPart.refreshChildren(AbstractEditPart.java:781)
	at org.eclipse.gef.editparts.AbstractEditPart.refresh(AbstractEditPart.java:726)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.refresh(AbstractGraphicalEditPart.java:644)
	at de.ovgu.featureide.fm.ui.editors.FeatureDiagramEditor$3.runInUIThread(FeatureDiagramEditor.java:571)
	at org.eclipse.ui.progress.UIJob.lambda$0(UIJob.java:95)
	at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:37)
	at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:182)
	at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:3906)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3537)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$5.run(PartRenderingEngine.java:1170)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1059)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)
	at org.eclipse.ui.internal.Workbench.lambda$3(Workbench.java:667)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:597)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)
	at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:152)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:656)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:592)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1498)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1471)

```

How to reproduce:

1. Right-click a feature model in the package or project explorer.

2. Select any feature model.

3. Lots of errors.

4. The model.xml file is replaced by the imported feature model, I'm not sure if this is the intended behaviour?

","It replaces the selected feature model, not the model.xml file.",13869700
1147,Unused Actions: CreateLayerAction and CreateCompoundAction.,open,2020-03-09T14:43:14Z,2020-03-09T18:31:18Z,,COLLABORATOR,These were replaced by CreateFeatureAboveAction and CreateFeatureBelowAction a while ago. As far as I can they're now not used in FeatureIDE anywhere and can be deleted.,,13869700
1148,Fixed #978: Fixes several issues for the feature attribute view when handling extended configurations,open,2020-03-09T14:42:03Z,2020-03-23T12:14:40Z,,COLLABORATOR,,,13869700
1149,Unsigned content warning when installing from Eclipse Marketplace,open,2020-03-05T12:58:06Z,2020-03-10T17:25:50Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  `2019-12 (4.14.0)`
* **FeatureIDE-Version:**  `Marketplace`
* **Operating system:** `5.5.6-arch1-1`
* **Java runtime used to run eclipse:** `1.8.0_242`

### Issue description
When installing FeatureIDE from Eclipse Marketplace
![image](https://user-images.githubusercontent.com/58979585/75983241-6fd6e780-5ee8-11ea-9567-877051e41b84.png)

Since it is not mentioned in the current wiki, is it intended?
","This seems to be pretty forward:
https://wiki.eclipse.org/JAR_Signing
and
https://wiki.eclipse.org/IT_Infrastructure_Doc#Sign_my_Jar.2Fplugins.2FWindows_exe.2FmacOS_App_files.3F

",13869700
1150,Auto-layouting legend does not work correctly after manually moving it.,open,2020-03-02T11:41:41Z,2020-03-09T13:08:26Z,,COLLABORATOR,"This bug is currently on the branches release3.6 and develop.

1. Move the Legend a few pixels to the right. Auto-Layout legend is now off.

![auto_layout_legend_1](https://user-images.githubusercontent.com/32126695/75673320-f7232180-5c82-11ea-9192-2c2046b32749.png)

2. Right-click Legend and click to enable Auto-Layout Legend.

3. Create a new feature that shoud change the position of the legend.

![auto_layout_legend_2](https://user-images.githubusercontent.com/32126695/75673329-fb4f3f00-5c82-11ea-94cb-a203a3195f9a.png)

The legend won't move.",Oh you also can't change it back to auto layout via the context menu.,13869700
1151,Allow slicing for a selection of multiple features,open,2020-02-24T15:29:03Z,2020-02-24T17:11:54Z,,COLLABORATOR,"### Issue description
Currently slicing is only allowed for the subtree of one selected feature in the feature model editor.
![grafik](https://user-images.githubusercontent.com/24757266/75165263-66988e80-5722-11ea-8338-3bafd2da1f5c.png)
It makes sense to also allow selecting an arbitrary number of features and create a sliced model with those.",,13869700
1152,"Generating T-wise configurations with ""Product Generator"" fails because of missing apache.commons",open,2020-02-24T15:18:39Z,2020-02-24T17:12:32Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  `4.12`
* **FeatureIDE-Version:**  `Release 3.6 pre-built version and release3.6 branch`
* **Operating system:** `Windows 10`


### Issue description
The library apache.commons.math seems to not be automatically Building t-wise configurations with any algorithm does not create any configurations and results in the following exception:

eclipse.buildId=4.12.0.I20190605-1800
java.version=1.8.0_232
java.vendor=Oracle Corporation
BootLoader constants: OS=win32, ARCH=x86_64, WS=win32, NL=de_DE
Framework arguments:  -product org.eclipse.epp.package.committers.product
Command-line arguments:  -os win32 -ws win32 -arch x86_64 -product org.eclipse.epp.package.committers.product

org.eclipse.core.jobs
Error
Mon Feb 24 16:10:07 CET 2020
An internal error occurred during: ""Create Configurations 1"".

java.lang.NoClassDefFoundError: org/apache/commons/math/util/MathUtils
	at no.sintef.ict.splcatool.CoveringArrayChvatal.generate2(CoveringArrayChvatal.java:161)
	at no.sintef.ict.splcatool.CoveringArrayChvatal.generate(CoveringArrayChvatal.java:52)
	at no.sintef.ict.splcatool.CoveringArrayChvatal.generate(CoveringArrayChvatal.java:60)
	at de.ovgu.featureide.fm.core.analysis.cnf.generator.configuration.SPLCAToolConfigurationGenerator.generate(SPLCAToolConfigurationGenerator.java:84)
	at de.ovgu.featureide.fm.core.analysis.cnf.generator.configuration.AConfigurationGenerator.analyze(AConfigurationGenerator.java:71)
	at de.ovgu.featureide.fm.core.analysis.cnf.generator.configuration.AConfigurationGenerator.analyze(AConfigurationGenerator.java:1)
	at de.ovgu.featureide.fm.core.analysis.cnf.analysis.AbstractAnalysis.execute(AbstractAnalysis.java:82)
	at de.ovgu.featureide.fm.core.job.LongRunningWrapper.runMethod(LongRunningWrapper.java:53)
	at de.ovgu.featureide.ui.actions.generator.configuration.ACNFConfigurationGenerator.execute(ACNFConfigurationGenerator.java:105)
	at de.ovgu.featureide.ui.actions.generator.configuration.ACNFConfigurationGenerator.execute(ACNFConfigurationGenerator.java:1)
	at de.ovgu.featureide.fm.core.job.Executer.execute(Executer.java:44)
	at de.ovgu.featureide.fm.core.job.LongRunningJob.work(LongRunningJob.java:48)
	at de.ovgu.featureide.fm.core.job.AbstractJob.run(AbstractJob.java:122)
	at org.eclipse.core.internal.jobs.Worker.run(Worker.java:63)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.math.util.MathUtils cannot be found by de.ovgu.featureide.fm.core_3.6.0.201908302227
	at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:512)
	at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:423)
	at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:415)
	at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:155)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 14 more

",,13869700
1153,Expand the Select Subtree action so it can be used for multiple features at once.,open,2020-02-24T14:17:52Z,2020-02-24T14:18:22Z,,COLLABORATOR,Select subtree currently extends the abstract class SingleSelectionAction. It could instead extend MultipleSelectionAction and work for multiple features at the same time.,,13869700
1154,Feature Attributes View not working as intended for Extended Configurations,open,2020-02-23T10:39:22Z,2020-03-09T13:23:30Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  `4.12`
* **FeatureIDE-Version:**  `Release3.6 Branch`
* **Operating system:** `Windows 10`


### Issue description
![grafik](https://user-images.githubusercontent.com/24757266/75110535-99ae2580-562f-11ea-84a2-ca6d61d2f665.png)
This is always shown when using the feature attribute view while working with an extended configuration.
Expected Behavior:
The attributes of some/all features with the ""Configurable""-flag are shown. 
Viable options to decide which features to display I can think of:
(A) all features
(B) all features included in the configuration
(C) only the feature marked by the last click 
",We found more problems with the attribute view. We refactored the filtering and content provider so that the usage of the configuration editors is intuitive and shows respective messages. We fixed the saving of configurable attributes in extended configurations.,13869700
1155,Prevent the creation of the FM's logical formula until it is needed,open,2020-01-27T12:22:00Z,2020-01-27T13:13:12Z,,COLLABORATOR,"### Issue description
Prevent the creation of the FM's logical formula until it is needed to improve the usability, especially for large models. Currently, the formula is constructed quite often even if it is not needed in the end. 

The performance for both FeatureModelEditor and ConstraintEditor could be improved as large models tend to not work well. The logical formula should only be computed when the automatic analyses are active.

As part of this enhancement, it should be possible that the constraint editor can be used without checking the constraints with every change. This is extremely helpful but not for the large model. As we already have a mechanism to determine whether the calculation is performed on-the-fly or on-demand it could be used for the editor as well.",,13869700
1156,"""Auto Layout Constraints"" in layout context menu should be a toggle",open,2020-01-27T11:59:32Z,2020-01-27T11:59:32Z,,COLLABORATOR,"# Issue description
The option ""Auto Layout Constraints"" is the only option in the layout context menu that is not a toggle but an action. This is not intuitive. The old behavior can still be emulated if the option is a toggle. 

![grafik](https://user-images.githubusercontent.com/24757266/73172820-28e51d80-4104-11ea-8c6c-17d346a9cac7.png)

",,13869700
1157,Wiki,open,2020-01-26T13:41:34Z,2020-02-29T13:40:47Z,,COLLABORATOR,"Multiple images, links, pages and texts are marked as _under construction_, this issue exists to document, and update their content.

## Pages
* [x] https://github.com/FeatureIDE/FeatureIDE/wiki/Background _removed missing subpages, linked to Wikipedia in the meantime_
  * [x] https://github.com/FeatureIDE/FeatureIDE/wiki/Background-Software-Product-Lines _deleted since empty_
  * [x] https://github.com/FeatureIDE/FeatureIDE/wiki/Feature-Models <s>_description missing_</s>
  * [x] https://github.com/FeatureIDE/FeatureIDE/wiki/Background-FOSD _deleted since empty_
  * [x] https://github.com/FeatureIDE/FeatureIDE/wiki/Background-FOP _deleted since empy_

* [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/FeatureIDE-Installation-and-Update _check for accordance with 3.6_
* [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/FeatureIDE-Overview _description missing_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/Plugin-List _check for accordance with 3.6_
* [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/FeatureIDE-Functions-in-Deep _description missing_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/FeatureIDE-Project _broken content_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/Feature-Model-Editor _check for accordance with 3.6_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/Collaboration-Diagram _check for accordance with 3.6_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/Statistics-View _check for accordance with 3.6_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/FeatureIDE-Outline _check for accordance with 3.6_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/Configuration-Map _check for accordance with 3.6_
  * [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/Feature%20Attributes _check for accordance with 3.6_

## Images
Only images on pages not mentioned in _Pages_ are listed.

## Text
Only texts on pages not mentioned in _Pages_ are listed.

## Links
Only links on pages not mentioned in _Pages_ are listed.

##Structural problems
* [ ] https://github.com/FeatureIDE/FeatureIDE/wiki/Getting-started _confusing (non-linear) navigation_

To be continued and edited.",,13869700
1158,"Unused classes: MoveElementsOperation, FeatureTreeDeleteOperation",open,2020-01-25T13:57:32Z,2020-01-27T13:15:55Z,,COLLABORATOR,"MoveElementsOperation <- not sure about this one 

FeatureTreeDeleteOperation <- we now have the select subtree action instead of delete subtree, which makes this redundant.

Both of these classes are currently not being used. Is there any reason not to delete them?",,13869700
1159,"""Show Hidden Features"" flag cannot be removed",open,2020-01-21T13:01:04Z,2020-01-21T13:57:25Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  `4.8 and 4.12`
* **FeatureIDE-Version:**  `Release 3.6 branch`
* **Operating system:** `Windows 10`

### Issue description
Clicking ""Show Hidden Features"" in the feature model editor context menu does nothing.
It does not seem to matter whether there is a hidden feature in the feature model.

![image](https://user-images.githubusercontent.com/24757266/72806805-3870ec00-3c56-11ea-9130-998e093927ff.png)

",We decided that this menu entry including all related code should be removed. Hiding features in the configuration should still be possible.,13869700
1160,Unexpected Constraint Resulting from Erroneous Input in Create Constraint Dialog,open,2020-01-21T12:54:13Z,2020-02-23T20:49:07Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:** `4.8 and 4.12`
* **FeatureIDE-Version:**  `Release3.6 Branch`
* **Operating system:** `Windows 10`


### Issue description


The expression not F1 not F2 results in the constraint not(not F2).

How to reproduce:
1. Open feature model editor
2. Create two features F1 & F2
3. Open ""Create Constraint Dialog""
4. Create Constraint ""not F1 not F2""

Expected behavior: Error message + constraint cannot be created
Actual behaviour: Resulting constraint is ""not not F2""


![image](https://user-images.githubusercontent.com/24757266/72806423-74578180-3c55-11ea-878a-576e1d5b6367.png)


results in:

![image](https://user-images.githubusercontent.com/24757266/72806438-7a4d6280-3c55-11ea-9807-e9314c228f21.png)





",,13869700
1161,Fast Counting of the Number of Configurations for Feature Models without Cross-Tree Constraints,open,2020-01-17T17:12:26Z,2020-01-17T17:12:26Z,,COLLABORATOR,"The current counting method does not scale well and we aim to replace it soon by a #SAT solver. Nevertheless, it is likely to be much faster to compute the number of configurations for feature models without cross-tree constraints, as the complexity is linear in the number of features.

The goal is to design and implement such an algorithm. This algorithm should then be used whenever there are no constraints available.
",,13869700
1162,"Potential layouting issue, abego left / right has overlapping edges",open,2020-01-16T13:24:10Z,2020-01-17T08:33:45Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  `4.12`
* **FeatureIDE-Version:**  `release 3.6`
* **Operating system:** `5.4.8-arch1-1`

### Issue description
Example ""BerkleyDB"":
![Screenshot_overlapping_edges](https://user-images.githubusercontent.com/58979585/72528518-7bece400-386b-11ea-9f33-488cd44292c7.png)

",,13869700
1163,Add dynamic localization,open,2020-01-15T03:29:05Z,2020-01-17T08:28:24Z,,COLLABORATOR,"Currently the localization is in [de.ovgu.featureide.fm.core.localization.StringTable](https://github.com/FeatureIDE/FeatureIDE/blob/develop/plugins/de.ovgu.featureide.fm.core/src/de/ovgu/featureide/fm/core/localization/StringTable.java) and is done by mapping final String variables to the corresponding strings.

### Issues at first glance:
- Mixed English & German strings (e.g. SUMME, KONTEXT)
- Currently no language switch possible
  - Only English is fully supported
  - Even if Strings for other languages _would_ exist, currently the strings are hardwired and thus not interchangeable
- No grouping (e.g. Strings for GUI-Elements, Messages, ...)
- hard coded leading and trailing whitespaces
- (Naming convention?)

### Cons to a change of implementation:
- Most of the code would be affected !!!!!
- Amount of work vs. benefit (does anybody want language support for another language?)
- Eclipse does not have a go to mechanism for localization
- Speed ?

### Pros to a change of implementation:
- See issues
- A more accessible localization mechanism would lower the barrier for potential translators
- (Easier GUI Testing?)

### Proposed implementation
- Move Strings to XML-file(s)
- On plugin ""activation"" load XML
- String references get replaced by `<Localization>.get(<key>)` (should be possible with refactoring based on current StringTable)

### ToDo
- [ ] Discuss, if the issue is an issue 
- [ ] Agreement on implementation",,13869700
1164,Overlapping feature boxes after introducing new defects,open,2020-01-14T13:26:05Z,2020-01-21T14:11:32Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  `4.12`
* **FeatureIDE-Version:**  `Release 3.6.0 & release3.6 branch`
* **Operating system:** `Windows 10`

### Issue description
![grafik](https://user-images.githubusercontent.com/24757266/72347394-59769180-36d8-11ea-925f-7396fdcd4c52.png)

The features are not layouted right after the defect flags are set but after another action that forces  re-layouting (e.g. introducing a new feature).

","> Did you test the issue on Eclipse `4.12`?

Tested it on `4.8` and `4.12`, CNR in both with course of action of @Subaro, updated my original comment.",13869700
1165,Collapse boxes with 10 or more children don't show the number of children.,open,2020-01-07T12:54:46Z,2020-01-07T13:26:44Z,,COLLABORATOR,"This bug is currently on the release3.6 branch.

before collapsing:

![collapsebox1](https://user-images.githubusercontent.com/32126695/71896659-ab596d80-3154-11ea-95b4-4d2694487d7f.png)

after collapsing:

![collapsebox2](https://user-images.githubusercontent.com/32126695/71896676-bb714d00-3154-11ea-94f4-7e7810c39994.png)


This bug was introduced in FeatureIDE 3.6.0","This bug occurs for me every time. Also for features with 100 or more children, while @Subaro does not seem to get the bug at all.",13869700
1166,Implicit constraints not highlighted when computing hidden dependencies,open,2020-01-07T09:42:20Z,2020-01-07T09:42:21Z,,COLLABORATOR,"Implicit constraints, dead features, and false-optional features not highlighted when computing hidden dependencies of submodels:

![image](https://user-images.githubusercontent.com/5330357/71885130-0336ab00-313a-11ea-90c1-56aac19d434c.png)

See #920 ",,13869700
1167,Features show up in feature model editor multiple times.,open,2020-01-06T14:28:08Z,2020-01-07T10:10:26Z,,COLLABORATOR,"This bug is currently in the release3.6 branch. It does not seem to be 100% reproducible but still very common.

1. Load example HelloWorld-Antenna
2. Create new feature below ""Beautiful""
3. Save changes
4. Close the feature model editor
5. Reopen the feature model editor

![doublefeature](https://user-images.githubusercontent.com/32126695/71824064-f746dc80-3098-11ea-852d-02bd51cd6b80.png)

Any change to the model will make the feature model editor display it correctly again.

This bug was introduced in FeatureIDE 3.6.0",,13869700
1168,Remove Fuji Support,open,2019-12-10T09:25:12Z,2019-12-10T09:28:02Z,,COLLABORATOR,"### Issue description
Fuji is not able to run with Java 1.8 or higher. Since FeatureIDE now requires Java 1.8 or higher to run, it is not possible to use Fuji at all. Thus, we should remove support for Fuji all together in the next version to avoid confusion and to clean up the code.
","Issues exists since version 3.6.
Related to #928.",13869700
1169,Export of configurations as LaTeX with TikZ,open,2019-12-03T13:05:54Z,2020-01-07T09:51:27Z,,COLLABORATOR,"### Issue description
Extend the configuration export as LaTeX with new template.

Template for advanced export:
![grafik](https://user-images.githubusercontent.com/6231523/70054052-a857e400-15ce-11ea-8c9e-ac0b8eed66ad.png)
","Already implemented:

![image](https://user-images.githubusercontent.com/5330357/71885857-83a9db80-313b-11ea-85a6-0843a9676d13.png)

Still not clear to me why the export is only available in the advanced editor. It should be available in every configurator tab and also in the package and project explorer.",13869700
1170,"Plug-In ""de.ovgu.featureide.visualisation"" is redundant",open,2019-12-03T13:02:32Z,2020-02-24T12:57:37Z,,COLLABORATOR,"#### Prerequisitives
* **FeatureIDE-Version:**  `3.6`

### Issue description
All classes and functionality of the Plug-In `de.ovgu.featureide.visualisation` are already present in `de.ovgu.featureide.ui`. Both add a menu entry. However, only the menu entry of the `de.ovgu.featureide.ui` works. Thus, we should remove `de.ovgu.featureide.visualisation`.",We decided to leave everything in its own plug-in. I fixed the issue that prevented the generation of graphs and removed the redundant code from the `fm.ui` plug-in.,13869700
1171,Explanation for void feature models not shown in tooltip.,open,2019-12-03T12:55:19Z,2020-02-24T15:09:43Z,,COLLABORATOR,"#### Prerequisites
* **FeatureIDE-Version:**  `3.6`
### Issue description
The explanation for void feature models is not shown in the tooltip of any feature. ","We decided that no constraint should be highlighted. Furthermore, the constraint error marker in the first picture indicates the usage of unnecessary calculations for the feature model analysis. A separate issue will be created.",13869700
1172,Multi product line example HelloWorldMPL-FH-Java does not work,open,2019-11-26T21:13:28Z,2020-02-04T08:33:03Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  see release packages
* **FeatureIDE-Version:**  v3.6.1 and earlier versions (see below)
* **Operating system:** Windows 10
* **Java runtime used to run eclipse:** Java 8 Update 201

### Issue description
The Velvet feature model cannot be opened. Also, there are some weird errors in the package explorer.

![image](https://user-images.githubusercontent.com/5330357/69673090-d6529b00-1099-11ea-869a-6439e8f5ab66.png)
","Velvet model can be opened multiple times with v3.4.3/v3.3.2/v3.2.0, but they have to be opened twice to get updated on changes to input models. The model is immediately updated in v3.1.2 and Eclipse freezes when opening it with v3.0.1.",13869700
1173,Improve intuitivity of context menu for feature models and FeatureIDE projects,open,2019-11-26T20:44:08Z,2019-11-26T20:44:08Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  see release packages
* **FeatureIDE-Version:**  v3.6.1
* **Operating system:** Windows 10
* **Java runtime used to run eclipse:** Java 8 Update 201

### Issue description
Why is action ""Build Feature Graph"" only available for the project?
Why is the export for all feature models only available for the project?
",,13869700
1174,Large example feature models cannot be opened with recent FeatureIDE versions because of the outline view,open,2019-11-26T19:18:04Z,2020-01-27T13:26:56Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  see release packages
* **FeatureIDE-Version:**  v3.6.1 and v3.5.5 (works with v3.4.3)
* **Operating system:** Windows 10
* **Java runtime used to run eclipse:** Java 8 Update 201

### Issue description
When opening Automotive02_V4 example feature model with v3.5.5 the UI freezes for a long long time and I had to kill the Eclipse after more than 10 minutes.

When opening Linux_2.6.33.3 example feature model with v3.6.1 I got an out of memory error in the error log:

```
eclipse.buildId=4.13.0.I20190916-1045
java.version=1.8.0_201
java.vendor=Oracle Corporation
BootLoader constants: OS=win32, ARCH=x86_64, WS=win32, NL=en_US
Command-line arguments:  -os win32 -ws win32 -arch x86_64

org.eclipse.equinox.event
Error
Tue Nov 26 20:00:53 CET 2019
Exception while dispatching event org.osgi.service.event.Event [topic=org/eclipse/e4/ui/model/ui/ElementContainer/selectedElement/SET] {ChangedElement=org.eclipse.e4.primaryDataStack=org.eclipse.e4.ui.model.application.ui.basic.impl.PartStackImpl@32a72c4 (tags: [org.eclipse.e4.primaryDataStack, EditorStack], contributorURI: null) (widget: CTabFolder {}, renderer: org.eclipse.e4.ui.workbench.renderers.swt.StackRenderer@5bc14211, toBeRendered: true, onTop: false, visible: true, containerData: null, accessibilityPhrase: null), Widget=CTabFolder {}, org.eclipse.e4.data={ChangedElement=org.eclipse.e4.primaryDataStack=org.eclipse.e4.ui.model.application.ui.basic.impl.PartStackImpl@32a72c4 (tags: [org.eclipse.e4.primaryDataStack, EditorStack], contributorURI: null) (widget: CTabFolder {}, renderer: org.eclipse.e4.ui.workbench.renderers.swt.StackRenderer@5bc14211, toBeRendered: true, onTop: false, visible: true, containerData: null, accessibilityPhrase: null), AttName=selectedElement, EventType=SET, Widget=CTabFolder {}, NewValue=org.eclipse.e4.ui.compatibility.editor=org.eclipse.e4.ui.model.application.ui.basic.impl.PartImpl@2b8ad0d9 (tags: [Editor, removeOnHide, de.ovgu.featureide.fm.ui.editors.FeatureModelEditor], contributorURI: null) (widget: ContributedPartRenderer$1 {}, renderer: org.eclipse.e4.ui.workbench.renderers.swt.ContributedPartRenderer@345af277, toBeRendered: true, onTop: false, visible: true, containerData: null, accessibilityPhrase: null) (contributionURI: bundleclass://org.eclipse.ui.workbench/org.eclipse.ui.internal.e4.compatibility.CompatibilityEditor, object: null, context: PartImpl (org.eclipse.e4.ui.compatibility.editor)  removeOnHide de.ovgu.featureide.fm.ui.editors.FeatureModelEditorContext, variables: [], label: null, iconURI: null, tooltip: null, dirty: false, closeable: true, description: null)}, AttName=selectedElement, NewValue=org.eclipse.e4.ui.compatibility.editor=org.eclipse.e4.ui.model.application.ui.basic.impl.PartImpl@2b8ad0d9 (tags: [Editor, removeOnHide, de.ovgu.featureide.fm.ui.editors.FeatureModelEditor], contributorURI: null) (widget: ContributedPartRenderer$1 {}, renderer: org.eclipse.e4.ui.workbench.renderers.swt.ContributedPartRenderer@345af277, toBeRendered: true, onTop: false, visible: true, containerData: null, accessibilityPhrase: null) (contributionURI: bundleclass://org.eclipse.ui.workbench/org.eclipse.ui.internal.e4.compatibility.CompatibilityEditor, object: null, context: PartImpl (org.eclipse.e4.ui.compatibility.editor)  removeOnHide de.ovgu.featureide.fm.ui.editors.FeatureModelEditorContext, variables: [], label: null, iconURI: null, tooltip: null, dirty: false, closeable: true, description: null), EventType=SET} to handler org.eclipse.e4.ui.services.internal.events.UIEventHandler@35df5961

java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.HashMap.newNode(Unknown Source)
	at java.util.HashMap.putVal(Unknown Source)
	at java.util.HashMap.put(Unknown Source)
	at java.util.HashSet.add(Unknown Source)
	at org.prop4j.Node.buildCNF_rec(Node.java:277)
	at org.prop4j.Node.buildCNF_rec(Node.java:198)
	at org.prop4j.Node.buildCNF_rec(Node.java:198)
	at org.prop4j.Node.buildCNF_rec(Node.java:198)
	at org.prop4j.Node.buildCNF_rec(Node.java:198)
	at org.prop4j.Node.buildCNF_rec(Node.java:288)
	at org.prop4j.Node.buildCNF(Node.java:137)
	at de.ovgu.featureide.fm.core.analysis.cnf.Nodes.getClauseFromNode(Nodes.java:160)
	at de.ovgu.featureide.fm.core.analysis.cnf.Nodes.convert(Nodes.java:57)
	at de.ovgu.featureide.fm.core.analysis.cnf.Nodes.convert(Nodes.java:52)
	at de.ovgu.featureide.fm.core.AnalysesCollection$AConstraintAnalysisWrapper.setClauseGroups(AnalysesCollection.java:355)
	at de.ovgu.featureide.fm.core.AnalysesCollection$CauseAnalysisWrapper.setFormula(AnalysesCollection.java:265)
	at de.ovgu.featureide.fm.core.AnalysesCollection.init(AnalysesCollection.java:456)
	at de.ovgu.featureide.fm.core.FeatureModelAnalyzer.<init>(FeatureModelAnalyzer.java:99)
	at de.ovgu.featureide.fm.core.analysis.cnf.formula.FMAnalyzerCreator.create(FMAnalyzerCreator.java:34)
	at de.ovgu.featureide.fm.core.analysis.cnf.formula.FMAnalyzerCreator.create(FMAnalyzerCreator.java:1)
	at de.ovgu.featureide.fm.core.analysis.cnf.formula.ACreator.get(ACreator.java:41)
	at de.ovgu.featureide.fm.core.analysis.cnf.formula.FeatureModelFormula.getElement(FeatureModelFormula.java:60)
	at de.ovgu.featureide.fm.core.analysis.cnf.formula.FeatureModelFormula.getAnalyzer(FeatureModelFormula.java:105)
	at de.ovgu.featureide.fm.ui.editors.FeatureModelEditor.createModelFileMarkers(FeatureModelEditor.java:541)
	at de.ovgu.featureide.fm.ui.editors.FeatureModelEditor.setInput(FeatureModelEditor.java:510)
	at org.eclipse.ui.part.MultiPageEditorPart.init(MultiPageEditorPart.java:753)
	at de.ovgu.featureide.fm.ui.editors.FeatureModelEditor.init(FeatureModelEditor.java:134)
	at org.eclipse.ui.internal.EditorReference.initialize(EditorReference.java:353)
	at org.eclipse.ui.internal.e4.compatibility.CompatibilityPart.create(CompatibilityPart.java:340)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
```

Opening Automotive02_V4 with v3.4.3 works just fine.","Closing both, the FeatureIDE outline and the Eclipse outline helped for Automotive02_V4 (but not for Linux). Then, I was able to collapse all features to get a reasonable efficiency.",13869700
1175,Opening feature models with GUIDSL does not work anymore,open,2019-11-26T18:27:59Z,2020-01-07T10:27:24Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  see release packages
* **FeatureIDE-Version:**  v3.6.1 and v3.5.5 and v3.4.3 and v3.3.2 and v3.2.0 and v3.1.2 and v3.0.1
* **Operating system:** Windows 10
* **Java runtime used to run eclipse:** Java 8 Update 201

### Issue description
Imported the Car example. Pressing the button does create a model.m file but GUIDSL does not open.

![image](https://user-images.githubusercontent.com/5330357/69660323-5cfa7e80-1080-11ea-9b72-687611e2e271.png)

",,13869700
1176,Computing the number of variants only on demand,open,2019-10-21T10:11:26Z,2019-10-21T10:11:26Z,,COLLABORATOR,"The computation of the number of variants is an expensive operation. Right now, we are performing this operation after every selection in the configurator. Instead, it should be possible to compute this number only on demand, if needed. This might help to reduce unnecessary computations.

Note that this number for a given partial configuration is typically lower than the number computed in the statistics view. Hence, it would be good to still have this additional number.",,13869700
1177,Weird behavior when creating a new project while the constraint view is closed,open,2019-10-15T12:02:08Z,2020-01-13T13:03:01Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:** 2019-03
* **Operating system:** Windows 10
* **Git branch/Commit-ID:**  release3.6 https://github.com/FeatureIDE/FeatureIDE/commit/6173d671966b5824f4beff3748b8cb7b1e306dd4

### Issue description
Closed the constraints view and tried to create a new feature modeling project. When pressing finish, there is a popup as for the newly created project the feature model is opened.

Pressing abort seems to do nothing. Pressing no seems to work fine. Pressing yes results in some weird behavior that I first need to press finish again in the project creation wizard and then need to answer the other dialog. Maybe it would help to first close the old dialog before proceed opening the feature model.","When updating an old Eclipse or when the FeatureIDE perspective is not used, this message is still needed.",13869700
1178,Refactor non-Eclipse related code into Java projects,open,2019-10-08T14:32:44Z,2019-10-08T14:32:44Z,,COLLABORATOR,"Some years ago, we started to create a Java library with the core functionality of FeatureIDE (cp. #392). A more robust solution would be to have pure Java projects for that purpose. Ideally, it would also be split into several Java projects depending on the use case. At least Prop4J and feature modeling should be separated, as Prop4J has more use cases than within FeatureIDE.

It is probably not feasible to migrate all functionality at once, such that an iterative migration should be preferred. It is likely that we will loose the history for those files in this process and could therefore also think of a re-design of the package structure. Ideally, we would accompany this iterative migration by adding test cases that achieve at least 90% coverage.",,13869700
1179,Constraints over attributes,open,2019-07-16T10:03:01Z,2019-07-16T11:20:23Z,,COLLABORATOR,"### Issue description
It should be possible to create constraints over attributes for extended feature models.
",,13869700
1180,Computation of coverage for pre-defined configurations,open,2019-06-17T12:05:29Z,2019-06-17T12:05:29Z,,COLLABORATOR,"Their is the notion of t-wise coverage. For pair-wise coverage (i.e., t=2) it means that the following pairs are covered for every pair of two features A, B:

* A and B
* A and not B
* not A and B
* not A and not B

 While some sampling algorithms ensure a certain coverage it would be nice if any list of configurations could be checked for the coverage for different values of t. A simple solution could be to take all configurations added to the configuration folder for that calculation. The computation may be costly depending on the feature model and value for t, but it could be calculated on demand in the statistics view.",,13869700
1181,Make long descriptions with linebreaks readable in Constraint View. ,open,2019-06-10T10:15:54Z,2019-06-11T12:10:50Z,,COLLABORATOR,"![linebreaks](https://user-images.githubusercontent.com/32126695/59188856-eec90a80-8b78-11e9-82bb-d6480e3251fd.png)

Right now linebreaks are replaced by whitespaces. This is fine to make the View usable with long descriptions, but there should be an option that allows you to read the whole description without having to click the constraint.

This could be achieved by adding an option to show the whole constraint description directly in the View.

There should at least be a popup text showing the whole description when you hover over the constraint description column entries with the cursor.",,13869700
1182,Allow sorting of Constraints in Constraint View by clicking the column headings.,open,2019-06-10T10:06:03Z,2019-06-11T04:37:47Z,,COLLABORATOR,"![columnheaders](https://user-images.githubusercontent.com/32126695/59188485-0ce23b00-8b78-11e9-8f00-79890b1afc6f.png)

Clicking these headers doesn't do anything right now. It should sort the columns alphabetically.",,13869700
1183,Tool support for partial configurations,open,2019-05-22T17:43:07Z,2019-05-22T17:43:07Z,,COLLABORATOR,"The ""new"" format for configuration allows to store partial configurations (i.e., configurations in which not all features have been specified). It would be nice to have better integration for partial configurations.

* A marker could help to distinguish partial from concrete configurations.
* Checks for validity could be different from those being applied to concrete configurations.
* We might need a special flag saying that a configuration is partial in the editor and in the file format, as a change in the feature model could change whether a configuration is partial or concrete. Such a change may go unnoticed otherwise.
* Partial configurations could even be build on top of each other (cf. staged configuration).
* Sampling algorithms could generate partial opposed to only concrete configurations.",,13869700
1184,Publish FeatureIDE library at the Maven Central Repository,open,2019-04-23T13:32:41Z,2019-10-31T19:30:11Z,,COLLABORATOR,The title says it all. We fixed all JavaDoc problems for that purpose (#748) but need to publish the next releases accordingly.,,13869700
1185,Replacement of RCPTT with RedDeer or SWTBot,open,2019-04-23T12:28:53Z,2019-04-23T12:28:53Z,,COLLABORATOR,"### **Possible replacements for RCPTT (GUI Test Tool):**

[**1. RedDeer:**](https://projects.eclipse.org/projects/technology.reddeer)
* ""The Eclipse RedDeer project is an extensible framework used for development of automated SWT/Eclipse tests which interacts with application’s user interface""
* Tests are programmed and not recorded:
```
@Test
	public void redDeerTestExample() {
		
		// Create Java Project
		JavaProjectWizard projectDlg = new JavaProjectWizard();
		projectDlg.open();
		NewJavaProjectWizardPageOne projectPage = new NewJavaProjectWizardPageOne(projectDlg);
		projectPage.setProjectName(""testProject"");
		projectDlg.finish();
		
		// Create Java class
		NewClassCreationWizard classDlg = new NewClassCreationWizard();
		classDlg.open();
		NewClassWizardPage classPage = new NewClassWizardPage(classDlg);
		classPage.setName(""RedDeerDemo"");
		classPage.setPackage(""org.reddeer.demo"");
		classDlg.finish();
		
		// Edit Java class
		TextEditor textEditor = new TextEditor(""RedDeerDemo.java"");
		textEditor.setText(""Written by RedDeer"");
		textEditor.save();
		
		// Check ProblemsView
		ProblemsView problemsView = new ProblemsView();
		problemsView.open();
		assertFalse(problemsView.getProblems(ProblemType.ERROR).isEmpty());
	}
```

[**2. SWTBot:**](https://projects.eclipse.org/projects/technology.swtbot)
* ""SWTBot is an open-source Java based UI/functional testing tool for testing SWT, Eclipse and GEF based applications.""
* Also programmed and not recorded:
```
@Test
    public void test() {
        // find the text after the label ""My Label""
        SWTBotText textWithLabel = bot.textWithLabel(""My Label"");
        // Set the focus and write a text into the text field
        textWithLabel.setFocus();
        assertEquals(textWithLabel.getText(), ""This is my text"");
        textWithLabel.selectAll();
        textWithLabel.typeText(""Java rules them all"");
        assertEquals(textWithLabel.getText(), ""Java rules them all"");

        // find the text with with the assigned id
        SWTBotText textWithId = bot.textWithId(""text1"");
        assertEquals(textWithId.getText(), ""This text has an ID"");

        // now lets find a view part
        SWTBotView viewById = bot.viewById(""de.vogella.swtbot.app.view"");
        assertNotNull(viewById);

        // Select the exit menu
        // bot.menu(""/File"").menu(""Exit"").click();

        assertTrue(true);
    }
```",,13869700
1186,Constraints view updated multiple times when opening a feature model,open,2019-03-25T12:10:18Z,2019-06-04T12:27:40Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:** 2019-03
* **Operating system:** Windows 10
* **Java runtime used to run eclipse:** Java 8
* **Git branch/Commit-ID:**  develop 52970006e188ae37e494688ddd1740edbe54b788
* **Java compiler used to build the FeatureIDE plugin:** Java 8

### Issue description
When opening a large feature model, the constraints view is filled with constraints multiple times. I recognized this by the scrollbar which it larger, shrink, getting larger, shrinks... The constraint view seems to be updated when there are changes in the feature diagram representation even though it is independent of those changes.

For reproduction, take a large feature model (e.g., FinancialServices01) and copy model.xml into a new file. Then open the constraints view and then the copied model. You may even try to expand all features once they have been automatically collapsed and reopen it again. I counted that the constraint view is updated 5 times before the diagram is opened and 10 times afterwards.

Also, I'm not quite sure why simply showing the constraints (i.e., a single update) takes so long. It seems that the view is updated after every constraint (otherwise the scrollbar would probably not be updated all the time).","The view still refreshes more often than neccessary, but this makes it refresh significantly less:

related: dd7af6e31026d2c94a4c74085a39c8373d06a5c6

Possibly, a timer could be implemented that limits how often the view can be refreshed (eg. every 200ms)",13869700
1187,Syntactical feature model statistics the same for all feature models,open,2019-02-10T14:49:19Z,2020-01-07T10:27:10Z,,NONE,"#### Prerequisitives
* **Eclipse Version:**  `Oxygen.3a Release (4.7.3a)`
* **FeatureIDE-Version:**  `  FeatureIDE	3.5.3.201811131854`
* **Operating system:** `Windows 10 pro`
* **Java runtime used to run eclipse:** `java version ""1.8.0_201""`
* **FeatureIDE Composer:** ``
* **Git branch/Commit-ID:**  ``
* **Java compiler used to build the FeatureIDE plugin:** ``

### Issue description
When opening a project containing multiple feature models, the syntactical feature model statistics shown in the FeatureIDE Statistics tab are the same for all feature models, no matter which one is opened. The issue was encountered with the *FinancialServices01* example contained in the FeatureIDE example suite. No matter which model of the *history* folder is opened the statistics remain the same. Moving a model from the *history* folder to *root directory* does not change anything. However, renaming the original file named *model.xml* and renaming the moved model from the history folder to *model.xml*, helps to show its statistics in the FeatureIDE Statistics tab. 

#### Example
We want to show statistics for model *2017-12-22.xml* from the history folder of FinancialServices. By simply opening it, only the statistics from the feature model named *model.xml* in the root folder are shown. A work around is to rename the feature model contained in the root folder to *model1.xml*; copying the file *2017-12-22.xml* into the root folder and renaming it to *model.xml*. Now the FeatureIDE Statistics tab shows the right syntactical statistics.
",,13869700
1188,FeatureModelEditor: collapse tree on tree-level basis,open,2019-01-15T13:08:44Z,2019-01-15T15:27:14Z,,CONTRIBUTOR,"### Issue description

I would like to ask if it is possible to implement a functionality, that collapses the tree to a certain level, starting from a selected feature or root feature. A keyboard shortcut would be nice too.

There are other tree-structure editor that have similiar functionalities. For example Mindmanager from Mindjet/Microsoft. Even though this isn't very urgent, but at least this would be useful for me and my team to inspect the feature model.
",,13869700
1189,Warning to users if font used in feature diagram is not installed,open,2019-01-04T08:08:11Z,2019-01-21T13:18:04Z,,NONE,"#### Prerequisitives
* **Eclipse Version:**  Oxygen.3a (4.7.3a)
* **FeatureIDE-Version:**  3.5.3.201811131854
* **Operating system:** Windows 10
* **Java runtime used to run eclipse:** JDK 8u121
* **FeatureIDE Composer:** 
* **Git branch/Commit-ID:**  
* **Java compiler used to build the FeatureIDE plugin:** 

### Issue description
Feature diagrams are broken in general. The screenshot is taken from a newly created FeatureIDE project.
![feature-diagram](https://user-images.githubusercontent.com/977893/50678665-13d0b480-1000-11e9-9d73-c467cdda4398.png)
This is the source code of the model.xml:
```
<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>
<featureModel>
    <properties/>
    <struct>
        <and abstract=""true"" mandatory=""true"" name=""test"">
            <feature name=""Base""/>
        </and>
    </struct>
    <constraints/>
    <calculations Auto=""true"" Constraints=""true"" Features=""true"" Redundant=""true"" Tautology=""true""/>
    <comments/>
    <featureOrder userDefined=""false""/>
</featureModel>
```


","Good to now!

Seems that we need to handle not available fonts in a better way.",13869700
1190,Group-tag functionality for constraints.,open,2018-12-16T14:42:59Z,2018-12-17T06:13:28Z,,COLLABORATOR,Allow assigning tags in the constraint view (#812) to the description of multiple constraints at the same time. Also allow the user to order constraints or to search for them using these tags.,,13869700
1191,Timeout of some calculations in the FeatureStatistics for large feature models,open,2018-12-10T12:50:23Z,2018-12-10T13:36:01Z,,COLLABORATOR,"Some calculations can be computed on demand by expanding the appropriate tree element in the view. But for some large feature models, the calculates terminated with a timeout of 1 second. Seems a little bit so low.",,13869700
1192,UI freezes and out of memory error when opening or working with large feature models,open,2018-11-29T13:55:58Z,2019-07-02T12:43:18Z,,COLLABORATOR,"#### Prerequisitives
* **Eclipse Version:**  4.7 + 4.8
* **FeatureIDE-Version:**  3.5.3 (edit: also confirmed for 3.4.3 except for the out of memory error)
* **Operating system:** Win 10

### Issue description
Import Automotive02_V4. Feature model opens rather quickly. Close feature model and remove .featureide/model.xml/model.xml.xml. Open feature model again. The UI freezes for minutes until the diagram is finally opened. Working with Eclipse while the feature model is opened is almost impossible, as the UI seems to freeze all the time.

Related to #695

","* What is the memory used for?
* Influence of views?
* Does it help to increase VM memory? (Would help to identify whether it is just large memory consumption or a memory leak.)
* Do we need an upper bound on the number of features being shown in the diagram? Rest is collapsed?
* Are analyses turned on in the example?
* How does it work without the separate model.xml.xml file?
* Do we need to introduce jobs to avoid UI freezes (e.g., when opening feature diagram)?
* Check for UI freezes in GUI tests?
* Are large alternatives groups a problem?",13869700
1193,Warning if feature models are saved in a format that does not support all properties,open,2018-11-12T13:58:48Z,2018-12-20T12:17:57Z,,COLLABORATOR,"FeatureIDE does not only provide import and export to different feature modeling languages, but it does also support editing all formats directly. As a consequence, a format may not support all properties being set in the editor.

For instance, dimacs format does not have any hierarchy for features but only constraints in conjunctive normal form. Almost any format does not support to store layout information or positions of features (as with the manual layout).

In those cases, it would be good to issue a warning for such a model when the user is attempting to save the model. It should be easily possible to store the feature model in FeatureIDE's format or to permanently ignore this message for the workspace.",see also #616,13869700
1194,Integrate SMT solver for feature model analysis,open,2018-10-30T08:20:22Z,2019-07-02T12:45:34Z,,COLLABORATOR,This has been implemented as part of a bachelor thesis (see #255) but needs to be integrated into the main development. It could be necessary to integrate this prior to #835.,,13869700
1195,Focus on all anomalies in a feature model,open,2018-10-29T10:59:23Z,2018-10-29T11:01:20Z,,COLLABORATOR,"We have a menu entry to focus on an explanation or a single constraint. In this case, all parts of the feature diagram not relevant are collapsed automatically.

Would be great to have something similar for: all dead features, all false-optional features, all redundant constraints, or all anomalies alltogether. These four options could be entries in a submenu.","Similarly, it would be great to show not only a single explanation, but to show all explanations alltogether on demand and focus on those. Here, a constraint causing numerous anomalies would be easily visible.",13869700
1196,Make context menu on feature models available outside of FeatureIDE projects,open,2018-10-29T10:47:27Z,2018-10-29T10:47:27Z,,COLLABORATOR,"For instance, export of feature models does only work if the model is within a FeatureIDE project.",,13869700
1197,Distinction of problem markers in product-line artifacts and derived products,open,2018-09-13T09:24:42Z,2018-09-13T09:24:42Z,,COLLABORATOR,"During the FeatureIDE tutorial, we noticed that if developers want to fix problems based on the problems view, they confuse product-line artifacts with derived products. Markers are useful for both: in products for inspecting the problem and in the product line for fixing it. The idea is to add the strings to the beginning of the message identifying the context:

Generic pattern
* Product line: [here is the marker message] (found in product(s) [name of one or more configurations])
* Product [name of the configuration]: [here is the marker message]

Examples
* Product line: Return statement is not reachable (found in products A and B)
* Product A: Return statement is not reachable
* Product B: Return statement is not reachable

We need to make sure that identical markers occurring in several products are only added once to the product-line artifacts. The functionality should be tested not only with compiler errors, but also with composition problems (e.g., with FeatureHouse).

Thanks to Christoph Seidl for constructive discussions and suggestions.",,13869700
1198,"Team project on ""Feature Attributes""",open,2018-09-06T18:41:06Z,2018-09-19T10:59:04Z,,COLLABORATOR,"Tentative tasks for Team 4 ""Feature Attributes""

* Add the Attributes View to the FeatureIDE Perspective if and only if the Attributes Plug-In is installed (part of #713)
* Ask users whether they want to open the Attributes View if an extended feature model or configuration is opened (part of #713)
* Add a button to the Attributes View to convert a feature model (configuration) into an extended feature model (configuration) (part of #713)
* Add a new menu entry in package explorer to convert a feature model (opposed to import and export)
* Ask users before conversion whether they aim to store a copy of the original model (automatically generated name with time stamp)
* Implement the feature model obfuscator for extended feature models #772

Related tasks

* Configuration map could be used to select the current configuration #698
* Color bars for configurations in project explorer #478
*  Make selection of a color scheme more intuitive #684 ",This topic will not be investigated this year.,13869700
1199,Automatically adjust FM to editor size when opening if no layout information is available,open,2018-09-06T16:49:35Z,2020-01-07T10:23:53Z,,COLLABORATOR,"Now that the automatic collapsing (i.e., adjusting to editor size) works (cf. #621), we can use that function if no layout information is available when opening a feature model. This happens in various cases. For instance, when creating a new feature model (but then it is typically small enough to display) but also when exporting a feature model or when sending a feature model to someone else (when not including the whole project).
","I removed this functionality 2ea424d45d46b3cc6e7eb7bb25d8f0c13367446d because it no longer worked correctly (adjusted model to editor size every time a model was opened). 

The old implementation relied on the model.xml.xml file, which is no longer being used.

Now it needs to be re-implemented with the new feature model format.",13869700
1200,Unhandled event loop exception when interacting with model editor on Ubuntu 17.10,open,2018-07-25T08:51:04Z,2018-07-26T14:11:31Z,,CONTRIBUTOR,"#### Prerequisitives
* **Eclipse Version:**  `4.7.3a`
* **FeatureIDE-Version:**  `3.5`
* **Operating system:** `Ubuntu 17.10`
* **Java runtime used to run eclipse:** `1.8.0_171`
* **FeatureIDE Composer:** ``
* **Git branch/Commit-ID:**  ``
* **Java compiler used to build the FeatureIDE plugin:** ``

### Issue description

In a completely new feature project and a completely new model.xml, I wanted to interact with the userinterface to add/insert new features to the model.xml, using the model editor view.

EDIT1: 
When clicking onto a feature, a error gets prompted (see below) and I'm not able to insert a new feature. Using the outline view of the model editor, I'm able to insert a feature, though it comes to unusual layout arrangement (top-down-order: feature below is placed in the left corner). Either way the model editor is not really usable.

Contents of the error log item:
Plugin: `org.eclipse.ui`
Message: `Unhandled event loop exception`
Exception Stack Trace: 
```
org.eclipse.swt.SWTError: No more handles
	at org.eclipse.swt.SWT.error(SWT.java:4559)
	at org.eclipse.swt.SWT.error(SWT.java:4448)
	at org.eclipse.swt.SWT.error(SWT.java:4419)
	at org.eclipse.swt.graphics.Cursor.<init>(Cursor.java:180)
	at org.eclipse.draw2d.Cursors.<clinit>(Cursors.java:195)
	at org.eclipse.gef.tools.DragEditPartsTracker.<init>(DragEditPartsTracker.java:89)
	at org.eclipse.gef.editparts.AbstractGraphicalEditPart.getDragTracker(AbstractGraphicalEditPart.java:483)
	at org.eclipse.gef.tools.SelectionTool.handleButtonDown(SelectionTool.java:207)
	at org.eclipse.gef.tools.AbstractTool.mouseDown(AbstractTool.java:1091)
	at org.eclipse.gef.tools.SelectionTool.mouseDown(SelectionTool.java:512)
	at org.eclipse.gef.EditDomain.mouseDown(EditDomain.java:245)
	at org.eclipse.gef.ui.parts.DomainEventDispatcher.dispatchMousePressed(DomainEventDispatcher.java:348)
	at org.eclipse.draw2d.LightweightSystem$EventHandler.mouseDown(LightweightSystem.java:523)
	at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:193)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:86)
	at org.eclipse.swt.widgets.Display.sendEvent(Display.java:5348)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1348)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4602)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:4183)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$5.run(PartRenderingEngine.java:1150)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1039)
	at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:153)
	at org.eclipse.ui.internal.Workbench.lambda$3(Workbench.java:680)
	at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:594)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148)
	at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:151)
	at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:653)
	at org.eclipse.equinox.launcher.Main.basicRun(Main.java:590)
	at org.eclipse.equinox.launcher.Main.run(Main.java:1499)
	at org.eclipse.equinox.launcher.Main.main(Main.java:1472)
```

Session data
```
eclipse.buildId=4.7.3.M20180330-0640
java.version=1.8.0_171
java.vendor=Oracle Corporation
BootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=de_DE
Framework arguments:  -product org.eclipse.epp.package.committers.product
Command-line arguments:  -data file:/home/cpwnd/eclipse-workspace/ -os linux -ws gtk -arch x86_64 
   -product org.eclipse.epp.package.committers.product
```
","The first setup was FeatureIDE Linux 64 bit zip from http://featureide.cs.ovgu.de/downloads/eclipse4.7.3committers-featureide3.5.0-linux64.tar.gz.
Then after the first ""crash"" I fully updated the FeatureIDE plugin via the eclipse marketplace and it crashed again. Sorry I don't know if some plugins were/are missing.

No, in the second setup with the 3.5.1 zip from the downloads it won't appear again.",13869700
1201,Feature names incomplete when zooming in the feature diagram,open,2018-07-20T08:46:12Z,2019-04-23T12:58:13Z,,COLLABORATOR,"![image2](https://user-images.githubusercontent.com/5330357/42992845-100b9772-8c0a-11e8-92e5-64229bdd32df.png)

![image](https://user-images.githubusercontent.com/5330357/42992813-f6c7547c-8c09-11e8-961e-10827860f93f.png)

Thanks to Don Batory for the report.
",Sounds like a reasonable workaround.,13869700
1202,Highlight FeatureHouse's original(),open,2018-06-28T08:11:17Z,2018-06-28T09:54:26Z,,NONE,"#### Prerequisitives
* **Eclipse Version:**  `4.7.3a`
* **FeatureIDE-Version:**  `3.5.0`
* **Operating system:** `Ubuntu 16.04 LTS`
* **Java runtime used to run eclipse:** `1.8`
* **FeatureIDE Composer:** `FeatureHouse`
* **Git branch/Commit-ID:** 
* **Java compiler used to build the FeatureIDE plugin:** 

### Issue description:
It would be nice if the call of `original()` in the feature code would be highlighted in some way. Right now it just looks like a normal method call, that is sometimes confusing.
",What is indeed easier than regular highlighting is add a colored background (annotation) to the background. That would be similar to feature colors in preprocessor-based product lines.,13869700
1203,Legend should only show entries for visible (not collapsed) model elements,open,2018-06-27T17:25:29Z,2018-06-27T17:25:29Z,,COLLABORATOR,"![temp](https://user-images.githubusercontent.com/5330357/41989505-d0c4b55c-7a3f-11e8-8a6d-3bd39b56971b.png)
",,13869700
1204,"Autocompletion in constraint dialog for features starting with """,open,2018-06-12T15:44:25Z,2018-09-06T18:16:21Z,,COLLABORATOR,"Constraints use """" for features that have spaces in their name. Example:

To use a feature called New Feature in a constraint, you have to type ""New Feature"".

How it should work:

1. Create a new project using a composer that allows spaces in feature names

2. Create a feature with a space in its name

3. Create a new constraint

4. Type a "", there should be auto complete options for features that contain a space",,13869700
1205,Feature model obfuscator for extended feature models,open,2018-05-24T09:20:48Z,2018-05-24T09:20:48Z,,COLLABORATOR,Attribute names should also be obfuscated as well as string values. Other numerical values should remain as-is.,,13869700
1206,Create readme.md for each Plug-In,open,2018-04-11T17:22:51Z,2020-01-07T10:24:17Z,,COLLABORATOR,"For each folder in the git repo that contains a readme.md GitHub displays its content in the code tab.
We should provide basic information for each plug-in using this functionality.",We decided that links to the wiki could be helpful.,13869700
1207,Vectorized graphics instead of bitmap icons in feature diagrams,open,2018-03-09T11:03:20Z,2018-03-09T11:03:20Z,,COLLABORATOR,"The icons for dead features, false-optional features, and redundant constraints look rather ugly on screen and even worse when exported to PDF. They should be drawn by means of Draw2D.",,13869700
1208,Simplified creation and handling of extended feature models,open,2018-03-06T08:12:42Z,2018-09-06T17:10:14Z,,COLLABORATOR,"There are some suggestions to improve the handling of extended feature models.

1. The feature attributes view should be part of the FeatureIDE perspective. It might be necessary to create an extension point to add further views to the FeatureIDE perspective in other plug-ins. Nevertheless, attributes should still work without FeatureIDE being installed, if possible.
2. Once the attribute view is opened and a standard FeatureIDE feature model or configuration is shown, it should be possible to convert it into an extended feature model or extended configuration, respectively. Ideally, by a dedicated button inside of the attribute view.
3. If an extended feature model or configuration is opened and the attribute view is not open, it should be opened automatically. There is a similar handling if an aspect is opened in AspectJ Development Tools.",,13869700
1209,Quickfix for unused concrete features / used abstract features.,open,2018-02-02T15:22:12Z,2018-02-02T15:22:12Z,,COLLABORATOR,"Currently, we already have a marker for each of these two problems.
There could be an addtional quickfix that set the features to abstract or concrete.",,13869700
1210,Configuration map could be used to select the current configuration,open,2018-02-02T15:19:37Z,2018-02-02T15:19:37Z,,COLLABORATOR,"Would be easier than using the nested context menu.
",,13869700
1211,Solver timeout when generating random configurations for large FM,open,2018-01-25T09:34:53Z,2018-01-25T10:06:55Z,,NONE,"#### Prerequisitives
* **Eclipse Version:**  Oxygen 4.7.0
* **FeatureIDE-Version:**  see Git branch / commit ID (seems to be release 3.4)
* **Operating system:** Windows
* **Java runtime used to run eclipse:** Java 1.8
* **FeatureIDE Composer:** none
* **Git branch/Commit-ID:**  develop, 4b6a634
* **Java compiler used to build the FeatureIDE plugin:**

### Issue description
When I want to generate random configurations of a very large feature model (see #694 #695 ) the solver always has a timeout and no configurations are generated.
Naturally, a certain timeout is sensible, but it would be nice if the user could be asked to increase this timeout manually (e.g. in a popup or something like that).
To make it work, I changed the timeout to 100000 (BasicSolver.java , line 105).
Feature Model attached (same as for #695 ).
[model.zip](https://github.com/FeatureIDE/FeatureIDE/files/1663369/model.zip)
",,13869700
1212,FeatureIDE UI very slow when having a large feature model,open,2018-01-25T09:31:26Z,2019-07-02T12:36:25Z,,NONE,"#### Prerequisitives
* **Eclipse Version:**  Oxygen 4.7.0
* **FeatureIDE-Version:**  see Git branch / commit ID (seems to be release 3.4)
* **Operating system:** Windows
* **Java runtime used to run eclipse:** Java 1.8
* **FeatureIDE Composer:** none
* **Git branch/Commit-ID:**  develop, 4b6a634
* **Java compiler used to build the FeatureIDE plugin:**

### Issue description
When importing a feature model from Dimacs (see #694 ) and the resulting feature model is very large, the UI is extremely slow and each click takes about 30 seconds to be performed.
Even when no editor or something similar is opened.
Feature Model is attached.
[model.zip](https://github.com/FeatureIDE/FeatureIDE/files/1663355/model.zip)


","Thanks for the fix, but the projects of interest did not have any accompanied source code. Hence, I guess that the fix does not help in this regard.

I think what would be most beneficial is to start reducing the number of unnecessary SAT calls even further for other parts of FeatureIDE, such as constraints in feature diagram and configuration map.",13869700
1213,New dialog when importing feature models in Dimacs format to let users choose whether slicing is applied or not,open,2018-01-25T09:28:36Z,2018-09-06T18:01:20Z,,NONE,"#### Prerequisitives
* **Eclipse Version:**  Oxygen 4.7.0
* **FeatureIDE-Version:**  see Git branch / commit ID (seems to be release 3.4)
* **Operating system:** Windows
* **Java runtime used to run eclipse:** Java 1.8
* **FeatureIDE Composer:** none
* **Git branch/Commit-ID:**  develop, 4b6a634
* **Java compiler used to build the FeatureIDE plugin:**

### Issue description
When importing a Dimacs formatted feature model (from Linux), it is very slow and takes about 30 minutes for me.
What I do:
1. Create new FeatureIDE Feature Modeling project
2. Right-click on model.xml -> FeatureIDE -> Import From Dimacs
3. Select the attached dimacs file

[dimacs.zip](https://github.com/FeatureIDE/FeatureIDE/files/1663342/dimacs.zip)

","Wow, I did not know that we can indeed slice away more than 30,000 variables. :)

Sounds like a good idea to make slicing optional. What about a message box asking about this? It could also warn users, that slicing can take some time.",13869700
1214,Make selection of a color scheme more intuitive,open,2017-12-28T17:34:53Z,2018-09-06T18:40:56Z,,COLLABORATOR,"It took me a while to understand how users are supposed to select a color scheme with the following dialog:

![color-scheme](https://user-images.githubusercontent.com/5330357/34418162-bc973f22-ebfc-11e7-8809-80f38265e216.png)

Two ideas for improvement:

1. We don't need the dialog at all, if there is only a single color scheme. It could automatically be selected then. (Would be nice to have that for the tutorial.)
2. We could remove the yellow arrow and simply consider the selection of the large box listing all schemes, as the selected scheme.

Furthermore, it took me even more time to understand how to rename an existing color scheme. Not sure how to improve that.","It was not yet the goal to revise the dialog. We decided to postpone this to a team project.

Does the following work now?

""We don't need the dialog at all, if there is only a single color scheme. It could automatically be selected then.""",13869700
1215,Check which of the interactive parts of the FeatureIDE book work with 3.3.2 and upcoming 3.4.2,open,2017-11-24T07:34:05Z,2018-09-26T08:52:14Z,,COLLABORATOR,"I tried some of the interactive sessions with the current release branch and almost nothing worked as expected! That's critical for the book and for our planned tutorial. For both, it would be feasible to use v3.3.2 or to create a new version 3.3.3. To decide whether tutorial should be based on version 3.4.x or 3.3.x, we need an overview what is working and what not.

In most cases it could be useful to **create GUI tests** for v3.3.2 and then simply replay them with the current release branch. That would also make it easier to retest the instructions in the future.

If everything works as expected, indicate that by a check mark in the following lists. If GUI tests have been created for that instruction, please add `GUI test` in that line. This way, we know what has to be done manually for future releases.

If you find any issues, please create a new issue and link it in the corresponding line. In case you find a problem with v3.3.2 it could be the case that it is already fixed since then (checkout on release branch). Please watchout issues closed since that release and link them if possible.","Tests for release3.4 branch must be revised as the currently fail. See https://travis-ci.org/FeatureIDE/FeatureIDE/builds/332406524
Fixes should be done in gui-test-in-maven-for-release3.4 branch before merging it in release. After this, we can merge the release branch in the develop branch and we should be fine with running gui tests on travis for release and develop branches.",13869700
1216,Layouting of legend should incorporate boxes for collapsed features,open,2017-11-10T13:39:25Z,2017-11-15T14:23:36Z,,COLLABORATOR,"![a](https://user-images.githubusercontent.com/5330357/32660866-ddcb1d92-c624-11e7-81fa-66cfb129e4e9.png)
",,13869700
1217,Boxes for collapsed features are crossed by feature connections,open,2017-11-10T13:37:57Z,2018-10-12T08:01:35Z,,COLLABORATOR,"The numbers for collapsed features are often located over connections. To make numbers readable, the boxes should have a white background color. This color could also be configurable or we simply take the same color as for the legend background.

![collapsed](https://user-images.githubusercontent.com/5330357/32660829-ad067f62-c624-11e7-8c3f-8d3217d46e19.png)

Legend and boxes for collapsed features should use the same color for borders as connections. If this is already configurable, we just need the same default values.","Great, this is quite helpful already. Could you also link related packages and classes here?",13869700
1218,Duplicate warning markers using Antenna,open,2017-10-26T15:50:41Z,2018-09-26T08:52:33Z,,COLLABORATOR,"Sometimes, duplicate warning markers are created when using Antenna.

Example [1]:
> Multiple markers at this line
	- This annotation causes a dead code block. The presence condition of Manual is a contradiction because: • The expression is nested within a block annotated with ¬Manual. 
	 (2/7)
	- if Gearbox if Manual elif Automatic if Manual
	- if Manual
	- if Gearbox if Manual elif Automatic if Manual
	- if Manual
	- if Gearbox if Manual elif Automatic if Manual
	- if Gearbox if Manual elif Automatic if Manual


[1] https://github.com/TimoGuenther/explaining-sat-queries-for-spls/blob/39176cd3b9e85f1b6e96d0297fdc1682d6d098b7/Documentation/data/Car/src/Car.java#L10","If it is not within the Antenna plug-in, it is most likely in the de.ovgu.featureide.ui package. There is a special abstraction for preprocessors, which is instantiated by plug-ins for Antenna, Munge, and CPP.",13869700
1219,GUI Tests for valid and invalid feature names,open,2017-10-16T13:10:45Z,2017-12-28T18:12:36Z,,COLLABORATOR,"Composers behave arbitrarily if feature names do not match supported naming conventions (e.g., contain spaces). GUI Tests should check some allowed and disallowed cases, for each composer separately.

See #594","Check also what happens for white spaces at begin and end, especially for feature modeling.",13869700
1220,Update/Fix MPL plug-in.,open,2017-10-13T14:40:54Z,2017-11-15T14:43:00Z,,CONTRIBUTOR,"Prerequisites

- Eclipse Version: Eclipse Neon
- FeatureIDE-Version: develop
- Operating system: Win 10
- Java runtime used to run eclipse: Java 1.8
- Issue Description

Issue Description

1. Run FeatureCpp composer

2. Convert to MPL Project -> Error
product generator -> Error
![mplproject](https://user-images.githubusercontent.com/26891940/31551558-3cf49c86-b035-11e7-9676-d1293a151341.png)
![productgenerator](https://user-images.githubusercontent.com/26891940/31551559-3d0f0b16-b035-11e7-82d8-7a85130e0346.png)

",This seems to be a general problem with the MPL functionality.,13869700
1221,"FMCore Composer, Error in Perform Feature Based Verification with Key",open,2017-10-13T14:38:58Z,2018-03-28T13:34:37Z,,CONTRIBUTOR,"Prerequisites

- Eclipse Version: Eclipse Neon
- FeatureIDE-Version: develop
- Operating system: Win 10
- Java runtime used to run eclipse: Java 1.8

Issue Description

1. Run FMCore Composer.

2. Perform Feature based verification with key.

![featurebasedverification](https://user-images.githubusercontent.com/26891940/31551481-f7abe9d6-b034-11e7-820f-924468cedff1.png)
",,13869700
1222,Clicking on Document doesn't generate a document,open,2017-10-13T14:36:13Z,2018-06-27T13:41:23Z,,CONTRIBUTOR,"Prerequisites

Eclipse Version: Eclipse Neon
FeatureIDE-Version: develop
Operating system: Win 10
Java runtime used to run eclipse: Java 1.8

Issue Description

Run any composer
Choose corresponding FeatureIDE Example
FeatureIDE -> Documentation -> Create Product/Meta/Context/Feature Documentation
No document gets generated.","For project with Javadoc, the generated document should look like described in here:
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.723.9006&rep=rep1&type=pdf",13869700
1223,Use Marker Type for Preprocessor Markers,open,2017-10-12T14:29:57Z,2017-11-15T14:48:20Z,,COLLABORATOR,"Currently, preprocessor markers are identified by checking if its message contains one of the pre-defined messages:

https://github.com/FeatureIDE/FeatureIDE/blob/abe44b99fd6b288ab6746bc57ab9edc68e8cfda0/plugins/de.ovgu.featureide.core/src/de/ovgu/featureide/core/builder/preprocessor/PPComposerExtensionClass.java#L383-L390

This is brittle. A marker type should be used to identify preprocessor markers.",,13869700
1224,Error markers for invalid configurations beyond FeatureIDE projects,open,2017-10-10T11:10:34Z,2017-10-10T15:20:50Z,,CONTRIBUTOR,"#### Prerequisitives
* **Eclipse Version:**  `Oxygen.1 Release (4.7.1)`
* **FeatureIDE-Version:**  `Current develop ""Latest commit b0875d0""`
* **Operating system:** `CentOS Linux 7`
* **Java runtime used to run eclipse:** `build 1.8.0_131-b11`
* **FeatureIDE Composer:** 
* **Git branch/Commit-ID:**  `Current develop ""Latest commit b0875d0""`
* **Java compiler used to build the FeatureIDE plugin:** 

### Issue description
- Create a Java Project (not a FeatureIDE project)
- Create a feature model with at least one mandatory feature
- Create a configuration.
- By removing a mandatory feature from a configuration, through the source tab and saving the configuration, no error marker is shown in the file list (left package / file list).








",Currently only available for FeatureIDE projects and not if only Feature Modeling is installed.,13869700
1225,Configure Continuous Integration,open,2017-09-26T19:58:03Z,2020-01-27T13:23:58Z,,COLLABORATOR,"Milestone 1
- [x] Compilation of all plug-ins
- [x] Compilation and execution of all test fragments (missing ahead-test, aspectj-test, munge-test, ui-test)
- [x] Revise hard-coded remote paths
- [x] Compile all branches (or release and develop) on Jenkins (e.g., with Jenkins file)
- [x] Separately compile fm.core, fm.core+fm.ui, fm.core+core, fm.core+fm.ui+core+ui, and all plug-ins
- [x] GUI tests

Milestone 2
* [x] False messages of failing builds on Jenkins (email notification correct?)
* [x] Check how email notifications work on Jenkins
* [x] Better separation of real users and users added by commits (i.e., can we have email notifications without users being added automatically?)
* [x] Fix pending status on Github from Jenkins
* [ ] New job on Jenkins: JavaDoc (including Travis, merge, Email notifications, Github status)
* [ ] Clean restart Javadoc jobs
* [ ] Consistent naming on Github/Jenkins
* [ ] Demo on Jenkins

Milestone 3
- [ ] Other projects than FeatureIDE: Kamil? Tobias R.? Michael?
- [ ] Publish results on an Update Site (see branch https://github.com/FeatureIDE/FeatureIDE/commits/tycho for first configuration steps)
- [ ] Create FeatureIDE library in CI
- [ ] New job on Jenkins: GUItests

Milestone 4
- [ ] Show in Travis: Separately compile fm.core, fm.core+fm.ui, fm.core+core, fm.core+fm.ui+core+ui, and all plug-ins
- [ ] Use different Eclipse versions 
- [ ] Use JDK1.7 instead of JDK1.8
- [ ] Use different operating systems
- [ ] Checks if coverage decreases (only needs to be configured)","* [x] Check that all new plug-ins are in maven scripts
* [x] Show on Github: Separately compile fm.core, fm.core+fm.ui, fm.core+core, fm.core+fm.ui+core+ui, and all plug-ins
* [x] Create logins for all developers
* [x] Show coverage image on Jenkins
* [x] Show on Github and in Travis: GUItests

And later:


* [x] Fix GUI tests + code (best before team project)
",13869700
1226,"Save state of advanced configuration page, when switching to normal configuration page / source page.",open,2017-09-13T15:00:18Z,2017-09-14T05:46:04Z,,COLLABORATOR,"Deselection of features is removed, when switching from the advanced configuration page to the normal one.","Alternatively, a warning that deselections are not maintained would be fine as a quick fix.",13869700
1227,Efficient caching for similar conjunctive normal forms of the feature model,open,2017-09-13T13:25:42Z,2017-12-28T18:32:39Z,,COLLABORATOR,"Various analysis methods use the feature model formula in CNF. For example, `FeatureModelAnalyzer` uses the CNF to detect dead features. The CNF is already being cached in `FeatureModelAnalyzer` due to https://github.com/FeatureIDE/FeatureIDE/issues/449, but other classes still use their own separate CNF instances. They should be cached in a single place to avoid creating the CNF more often than necessary.",,13869700
1228,Improvements for the importer,open,2017-09-13T08:53:31Z,2017-09-13T08:53:31Z,,CONTRIBUTOR,"## Importer
- Implement conversion of legacy feature modules to a FeatureIDE project (includes automatically generating a feature model)
- Implement conversion of legacy preprocessor code (Antenna, Munge, CPP) to a FeatureIDE project (includes automatically generating a feature model)

",,13869700
1229,Feature Request | Provide CMake option composer as output for the FeatureIDE,open,2017-08-22T08:24:43Z,2017-12-28T18:36:17Z,,NONE,"Hello Dear Devs,

I am thinking about a feature system where features are enabled/disabled via conditional compilation managed by the build system CMake. There each feature can be included to the build system via an option in the CMake-Generation phase.

So the build process of a feature model would like this.
1. User configures a valid product selection with help of the featureIDE based on the specified model
2. FeatureIDE creates a CMake option file.
3. CMake generates make files for your build system
4. Build

This has the advantage, that CMake does not need to hold any information about the feature model.

PS: Since I am working currently working on my master thesis in the field of SPL and FOP this implementation could be done from my side, if you think, that this would fit in the concept of the FeatureIDE.

Any feedback welcome!
",That's the data model that lies behind collaboration diagram and outline. It stores the artifacts/roles/ifdefs of features.,13869700
1230,MPL example project does not work as expected,open,2017-07-19T14:49:17Z,2017-12-28T18:36:55Z,,COLLABORATOR,See also #487 for which changes to names would be good to have an example that is consistent with our other examples.,,13869700
1231,Unnecessary SAT solver calls for constraints,open,2017-05-18T12:53:26Z,2019-07-02T12:45:27Z,,COLLABORATOR,"I am looking into the usage of the SAT solver in FeatureIDE. Here is a list of calls to the SAT solver when loading an exemplary feature model into the feature model editor:

```
FeatureModelAnalysis#updateFeatures -> checkValidity
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:65
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:72
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureFalseOptional -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:61
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:65
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:61
FeatureModelAnalysis#updateFeatures -> checkFeatureDead -> CoreDeadAnalysis#analyze:61
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant -> checkConstraintTautology -> ValidAnalysis
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant -> checkConstraintTautology -> ValidAnalysis
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant
FeatureModelAnalysis#updateConstraints -> checkConstraintRedundant
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:61
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:72
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:61
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:72
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:61
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:72
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:61
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureDead2 -> CoreDeadAnalysis#analyze:93
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:65
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:72
FeatureModelAnalysis#updateConstraints -> checkConstraintDeadAndFalseOptional -> checkFeatureFalseOptional2 -> ImplicationAnalysis#analyze:93
```

There are two sets of calls related to dead features and false-optional features; one stemming from `updateFeatures` and one from `checkConstraintDeadAndFalseOptional`. Apparently, the latter is there to let the user know that a given constraint is causing a feature to be dead or false-optional. However, this notification has since been removed as it has been replaced by explanations. Unfortunately, as seen above, the underlying calls to the SAT solver have not been removed, thus slowing down FeatureIDE.",,13869700
1232,Investigate why propagate problem markers takes more than 3 minutes for BerkeleyDB-FH-Java,open,2017-04-05T09:44:03Z,2017-09-05T15:59:36Z,,COLLABORATOR,"On my machine it takes something about four minutes to load this project into the workspace, mainly due to propagating problem markers. About 40 seconds to compose and compile all resources and the rest for propagation, whereas the latter should not take so much time.

![unbenannt](https://cloud.githubusercontent.com/assets/5330357/24699670/18026b28-19f5-11e7-9ed5-0de9b3c9375b.PNG)

Furthermore, we could improve the progress bar by considering the number of files to process as the progress. Would involve to have a single job for each project iterating over all files instead of a separate job for each file.
",,13869700
1233,Performance improvements for FSTModelBuilder for FeatureHouse,open,2017-04-03T20:53:58Z,2017-09-05T15:59:59Z,,CONTRIBUTOR,"#### Prerequisitives
* **FeatureIDE Composer:** `FeatureHouse`
* **Git branch/Commit-ID:**  `develop`

### Issue description
In the FeatureHouseModelBuilder, it appears as the FST gets also files from other projects as shown in the screenshot below. Maybe we can speed up the build process through filtering the files.

![unbenannt](https://cloud.githubusercontent.com/assets/8019776/24630585/8494eee8-18bd-11e7-8733-3af61346ef3e.PNG)
",,13869700
1234,Color bars for configurations in project explorer,open,2017-02-03T14:45:04Z,2017-04-04T17:35:58Z,,COLLABORATOR,"In FOP projects, we can show which features are contained in the product and where. However, it would also be nice to also color the folder ""src"" and the configurations similarly. The colors for the current configuration and src folder may be different, if a certain feature is not referenced in the source code (or feature module is empty).

![fop-tracing-projectexplorer-product-final](https://cloud.githubusercontent.com/assets/5330357/22595338/643033b6-ea27-11e6-82e8-12a8def09685.png)
","The later drawing problem for interfaces could be fixed by drawing the bars left of icons, but might cause similar problems for other overlays.",13869700
1235,Improve long-running computations for statistics view,open,2017-02-02T12:01:29Z,2017-04-12T12:18:27Z,,CONTRIBUTOR,"### Issue description
Related to #463, we should also make the statistics more consistent when the user can start longer running calculations.

Steps:
- Replace uncollapse to calculate through double-click
- Remove dialogs and make settings available in the properties of a project
","I'm not favoring a solution with properties, as this is hard-to-find and the timeouts might change depending on the analysis. My proposal is to take a second for computation once uncollapsed and then use double click to open the wizard for specifying a timeout.

All this would be feasible for a software project.",13869700
1236,Create a source file for specific feature,open,2017-01-27T18:52:19Z,2018-12-20T12:26:07Z,,COLLABORATOR,"* **FeatureIDE Composer:** `Antenna, Munge`

### Issue description
Antenna supports to annotate a complete file using #condition.
Thus the FeatureIDE wizard could create a new Java class already containing the selected feature.

```
//#condition Feature
public class Main {

}
```

She same would be possible for Munge as well: 
```
/*if[Feature]*/
public class Main {

}
/*end[Feature]*/
```
","You are considering to add this functionality to the FeatureIDE file wizard?

Probably very rarely used. Content assist is more likely to be used instead.",13869700
1237,[MPL] names are not right in velvet diagram,open,2016-07-20T13:19:11Z,2018-03-28T13:29:54Z,,NONE,"Tried the nightly build version:   Feature Modeling 3.0.1.201607200400
- [x] the short names are now there --> OK
- [ ] but the names are not right, see screenshot above ""Security_S7P_Repository.CSI.CSI_HARDWARE"" is now just ""Security_S7P_Repository._HARDWARE"" the substring in name ""CSI.CSI"" is not shown:
  ![image](https://cloud.githubusercontent.com/assets/95811/16986959/c4c10352-4e89-11e6-8313-5aea9fd621a7.png)
  the same for short names:
  ![image](https://cloud.githubusercontent.com/assets/95811/16987039/54e68056-4e8a-11e6-9e1c-b945c2a85a48.png)
","@skrieter Is that still an issue? If yes, how hard is it to fix?
",13869700
1238,New extension point to let other plug-ins add actions in feature diagram,open,2016-07-13T10:47:42Z,2017-09-20T11:24:22Z,,CONTRIBUTOR,"#### Prerequisitives
- **FeatureIDE-Version:**  3.0.1
### Issue description

I would like to add an action when the user right click a feature in the feature model editor. And I would like to do it in a separate plugin without modifying FeatureIDE core code. Now all the actions are hardcoded in de.ovgu.featureide.fm.ui.editors.FeatureDiagramEditor.createActions() and  I cannot find any menu id to use the Eclipse way to contribute actions or commands.
",Thanks for the fast response. Feature Relations Graph is a good use case to test the extension point.,13869700
1239,Remove dependencies to JDT from FeatureIDE and Feature Modeling,open,2016-04-11T13:56:32Z,2017-12-28T18:33:29Z,,COLLABORATOR,"#### Prerequisitives
- **Eclipse Version:**  Eclipse 4.5.2 Platform 32bit as well as 64bit
- **FeatureIDE-Version:**  FeatureIDE v2.7.5
- **Operating system:** Windows 10 
- **Java runtime used to run eclipse:** 1.8.0_77
- **FeatureIDE Composer:** 
- **Git branch/Commit-ID:**  
- **Java compiler used to build the FeatureIDE plugin:** 
### Issue description

Installed FeatureIDE using our update site, which worked well except that there is no FeatureIDE functionality visible within Eclipse. No error during installation and Eclipse even says it is installed.

To prepare the feature modeling version, I only installed Feature Modeling and FeatureIDE (no further extensions/composers).

If I remember correctly, we had similar problems also with Eclipse 4.4.2 for Win 64bit.

I guess the same will happen when we create v3.0.0 next week. Any ideas what is the problem?
","This is likely to reduce the size of the Eclipse download for feature modeling significantly.
",13869700
1240,Velvet Feature Models do not Listen to Changes of Input Models,open,2015-07-08T12:50:57Z,2016-10-13T08:47:29Z,,COLLABORATOR,"When changing a feature model used in a Velvet model one has to close and open the Velvet edtior again, which is anoying. To be more precise, the Velvet editor should listen only to changes to the actual file (similar to the configuration editor).
","We are constantly improving the support for Velvet. Many refactorings have been applied to FeatureIDE in the last year towards better support for any other format of feature models. However, we are glad for any input what is most urgent for users.

@anb0s It seems that it is easier to discuss that via Skype or so. Please contact me via email: t.thuem@tu-braunschweig.de. Thanks!
",13869700
1241,"Products returned by ""calculateExample"" of class ""ModelComparator""",open,2015-06-10T13:08:14Z,2020-01-07T10:24:46Z,,NONE,"Model

![altopt](https://cloud.githubusercontent.com/assets/12829806/8082725/8b21da6c-0f7f-11e5-8da3-d937f7a0030b.png)

is a generalization of model

![alt](https://cloud.githubusercontent.com/assets/12829806/8082729/950e7404-0f7f-11e5-809f-74f9c4b075ed.png)

In the first model, every configuration is a product, whereas in the second model only four configurations are products.

I need to obtain all the products added in the generalization. Method ""calculateExample"" of class ModelComparator seems suitable for obtaining them.
However, running the following test does not return all the added products, but only a subset. Indeed, I am expecting to retrieve 12 added products, but I get only 5 of them.

Is this the expected behaviour (i.e., I have wrongly understood the behaviour of ""calculateExample""), or should it be considered a fault?

Thank you
Best regards,
PA

``` java
@Test
public void testForFeatureIDEaddedProducts() throws FileNotFoundException, UnsupportedModelException, TimeoutException {
    FeatureModel fm = read(""alternative.xml"");
    FeatureModel fmGen = read(""optional.xml"");
    ModelComparator comparator = new ModelComparator(1000000);
    Comparison comparison = comparator.compare(fm, fmGen);
    assertEquals(Comparison.GENERALIZATION, comparison);
    Set<String> addedProducts = new HashSet<String>();
    Configuration c;
    while((c = comparator.calculateExample(true)) != null) {
        System.out.println(c);
        addedProducts.add(c.toString());
    }
    assertEquals(12, addedProducts.size());
}

private static FeatureModel read(String path) throws FileNotFoundException, UnsupportedModelException {
    FeatureModel fm = new FeatureModel();
    AbstractFeatureModelReader reader = new XmlFeatureModelReader(fm);
    reader.readFromFile(new File(path));
    return fm;
}
```
","You are right, this is an incorrect output of FeatureIDE. I was able to reproduce it with the development version and SAT4J Core 2.3.5.v201308161310. As this functionality in FeatureIDE is just a wrapper for the SAT solver, we will investigate whether the cause is wrong usage of the Sat4J or a fault in Sat4J.
",13869700
1242,Extend constraint dialog to work with Velvet models,open,2015-03-13T13:32:00Z,2017-09-20T11:26:04Z,,NONE,"I've installed nightly build 2.7.3.201503120400 and FeatureHouse.

Manually constraints in velvet files are possible and working. The graphical interface with content assist is very convenient and should be available.
",,13869700
1243,Removal of features by means of slicing,open,2015-02-06T13:12:44Z,2017-09-22T12:39:41Z,,COLLABORATOR,"When removing a feature that occurs in cross-tree constraints, it can only be removed, if there is a valid replacement (i.e., a nother feature that is true/false in exactly the same configurations):

![removal1](https://cloud.githubusercontent.com/assets/5330357/6079739/80ee6e16-ae09-11e4-9da7-5ab57996a34b.png)

However, removing a feature may include that dependencies given by the hierarchy are lost:

![removal2](https://cloud.githubusercontent.com/assets/5330357/6079740/8225e4ee-ae09-11e4-80d7-d0d2e9b287b3.png)

Hence, we need a new algorithm or procedure to handle the removal of features. It may rely on the removal of abstract/hidden features internally.

This could be the topic for an individual project or bachelor thesis, because proofs that the new algorithm is correct would be nice. I thought for several years that the current was correct. ;)
","Removing features is not quite easy and involves many decisions and an interactive process with users. Additionally, there are many bug fixes outstanding, such that I would like to postpone this to a thesis project.
",13869700
1244,Lazy loading of feature models for better performance during Eclipse start,open,2015-02-06T10:09:14Z,2017-12-28T18:32:18Z,,COLLABORATOR,"Currently, opening a workspace with all our example project takes several minutes. The reason is that all projects are build during start-up, even if probably not necessary. It may help to read the feature model from disc only when it is needed (not during start-up), as a change in the feature model requires many new analyses and potentially a rebuild of the project.

If lazy loading of the feature model does not help, try (in addition) to find out why FeatureIDE builds all projects during Eclipse start.
",,13869700
1245,Improvements for the product generation,open,2015-02-06T09:38:43Z,2018-12-20T12:26:32Z,,COLLABORATOR,"## Error markers for generated products are not updated when the source code changes

This enhancement is focusing on the generation of multiple products (e.g., sampling, exhaustive or all current configurations). When the feature modules/ifdef source code, feature model, or configuration changes, the error markers of generated source code may not be valid anymore. What about removing all generated source code and those propagated error markers once the user made such changes? Or we should find another solution that avoids confusion and does not need annoying dialogs.
## Change labels and their order for product generation strategies

The labels should be sorted by the expected computational effort (or a likely order for use, even if some are skipped for some projects):
1. All current configurations -> All [number] user-defined configuration
2. Random configurations
3. Configurations with T-wise coverage
4. All valid configurations -> All valid configurations (more than [number] configurations)
The latter should be calculated with a timeout of 100ms in a similar way as in the statistics view

![zwischenablage-5](https://cloud.githubusercontent.com/assets/5330357/18327848/a6ece528-754c-11e6-8b69-3f7cc1fc16ed.png)

## Implement generation of products in separate projects for FeatureC++ projects

merged from #21 

## Implement buildConfiguration() for AspectJ to generate products

see AspectJs? composerExtension class this class is necessary to generate products, merged from #20 ","I would just remove all markers at the next build.
",13869700
1246,Improvements for the feature model editor,open,2015-01-21T16:19:17Z,2018-09-06T13:47:32Z,,COLLABORATOR,"## FM Parser should distinguish between warnings and errors

When switching between FeatureIDE versions, it is often not possible to open the feature diagram, because of warnings. However, if just some tags are not supported in this version (colors, automated analysis) there should just be a warning that the tag is ignored. Still, the model could be parsed in these cases and opened. Also make sure that these warnings and errors are remove, once the feature model is changed/parsed again.

## Left-to-right layouts should use larger circles for alternatives and or groups to be better visible

Currently, it is often hard to distinguish or from alternative groups, or even to recognize that there is a circle at all. First try at https://github.com/Henningson/FeatureIDETeam2/tree/I3_largeCircles_2","Removed the following part, as done in [SP_MD_SoSe2018](https://github.com/FeatureIDE/FeatureIDE/tree/SP_MD_SoSe2018)

### Integrate tree layout library for feature diagram layouting (see #504)

Provide additional layouts using this library: http://treelayout.sourceforge.net/",13869700
1247,Improvements for the statistics view,open,2015-01-14T11:24:42Z,2018-09-06T17:23:15Z,,COLLABORATOR,"## Not resolved in 2016
- Determine and display LOC by file extension independent of composer
- Determine and display LOC for preprocessor projects (i.e. Antenna, Munge, CPP). Variable lines of code exclude preprocessor statements when counting.
- LOC by feature should also count nested features(*)
- Variable LOC excludes preprocessor statements when counting(*)
- Unit LOC statistics for variable and non-variable code (empty lines count in variable code)(*)
- Enable to jump-to-file for all files shown in the statistic view (similar as in collaboration diagram)
- Improve performance of statistics view by avoiding calculations when view is hidden
- Improve performance of feature model view by avoiding calculations when view is hidden


(*): extra cards made by team 2016, check validity","Not necessary anymore:

## More detailed statistics on contract-composition keywords

- Currently, the statistics view only reports which mechanism for contract composition is used. In case that method-based composition is choosen, it would be good to know which keywords are used how often. This applies only to FeatureHouse projects that use JML.",13869700
1248,Improvements for the collaboration diagram and outline,open,2015-01-14T11:20:16Z,2018-09-06T17:24:26Z,,COLLABORATOR,"## New support in collaboration diagram only:
- Develop concept for searching and filtering in collaboration diagram (e.g., filter dialog) - merged from #113
- Improve performance of collaboration diagram by avoiding calculations when view is hidden

","Already done:

## New support in collaboration outline only:
- Implement outline for configuration editor: show statistics on the currently selected, deselected, (manually, automated) feature, constraints of the currently selected feature",13869700
1249,Improvements for the constraint dialog,open,2015-01-12T15:25:44Z,2017-04-13T16:45:09Z,,CONTRIBUTOR,"## Current state

Currently below the feature diagram all constraints are listened. When clicking on an existing one the ConstraintDialog opens where the constraint can be edited. For a lot of changes in a large list of constraints this leads to select constraint - open - edit - close - select constraint - open - edit - close - ... 
## Improved ConstraintDialog workflow

In order to organize this a bit more all constraints of the model should be additionally placed in a **list** control in the left of the ConstraintDialog. Here you can then switch between different constraint, edit them on the fly or remove them **without the need of leaving the dialog** (see #176). Beside listing the existing constraints,  his list should also contain: The possibility to 
- create a new empty constraint, 
- edit existing and 
- deleting existing ones. 

All changes to this set of constraints should be _temporally_ until pressing OK/Apply button. 
## Improved User Experience

Nice optional features to my mind, which increases user experience, could be 
- deactivating of constraints (which leads to the same effect as deleting but the constraint still lives without affecting the model). Consequently activation for those constraints is necessary.
- Giving features names, a description, tags, colors or something to find a kind of grouping of constraints (let call this _tagging_ constraints). Without such a feature one can be confused for huge real world models. 
## Filtering in constraint list by features or constraint pattern

By selecting a set of feature names the list of constraints should be filtered to match that query. With this for a large set of constraints you can find all constraints affecting a given feature very easily. Moreover an alternative to the set of features could be a pattern, e.g. ""\* and FEATURE implies *"". Both could be done with RegEx and leads to more productivity for finding specific constraints. 
## Filtering in constraint list by tags

Assume the _tagging_ feature as implemented like described above.  Similar to filtering a list of constraints by a given set of features/pattern, filtering it by those tags will improve the user experience.
## Automatic merging of constraints

There is a way to merge some constraints, e.g. A => B and A => C to A => (B and C). Selecting two or more constraints from the list should be checked if merging is possible and after users request processed. Additionally with a decomposing of A => (B and C) to A => B and A => C this feature will lead to a rapid constraint structure changing workflow.
","Another addition:

- In the header replace the textbox with a label to make scaling better on small screens",13869700
1250,"Reuse New Project Wizards of the chosen Language (C++, Java, etc).",open,2013-11-13T16:45:02Z,2017-05-03T21:07:27Z,,COLLABORATOR,"When creating a new FeatureIDE Project:
After finishing the FeatureIDE new project wizard call the new project wizard of the specified language from Eclipse (e.g., call the Java new project wizard).
",,13869700
