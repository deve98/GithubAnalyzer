,Draft,Prerelease,Created_at,Published_at,Details,Id
0,False,False,2020-03-10T08:46:24Z,2020-03-10T09:09:07Z,This release drops the use of CGo-based bindings for ZeroMQ ([github.com/pebbe/zmq4](https://github.com/pebbe/zmq4)) in favor of a pure-Go package ([github.com/go-zeromq/zmq4](https://github.com/go-zeromq/zmq4)).,50202460
1,False,False,2019-12-08T18:21:50Z,2019-12-08T18:23:42Z,"use github.com/gofrs/uuid instead of github.com/satori/go.uuid
update to latest gomacro",50202460
2,False,False,2019-12-03T18:57:15Z,2019-12-03T18:59:14Z,update to latest gomacro which supports modules,50202460
3,False,True,2017-09-20T16:56:08Z,2017-09-20T16:57:27Z,,50202460
4,False,False,2016-11-25T19:32:13Z,2016-11-29T15:36:00Z,"Now gophernotes outputs both any error from compiling and running, and any content of `stderr` once a program is run.  Hopefully this gives a bit more context for things like indices out of range, etc.
",50202460
5,False,False,2016-10-03T02:49:02Z,2016-10-03T02:52:11Z,"- fix error printing weirdness on function declarations.
- update tests.
",50202460
6,False,False,2016-10-03T02:16:15Z,2016-10-03T02:19:49Z,"- new more descriptive error returns.
- fix for `interface{}` variable declarations.
- fix various issues related to error handling.
",50202460
7,False,False,2016-09-20T01:54:22Z,2016-09-20T01:59:06Z,"- Bug fixes - out of order declarations, printing
",50202460
8,False,False,2016-09-15T11:14:14Z,2016-09-15T11:20:56Z,"- fix weird printing repetition.
- code styling changes.
- update install files and docs.
",50202460
9,False,False,2016-08-17T12:17:24Z,2016-08-17T12:18:41Z,"- fix block importing of packages
",50202460
10,False,False,2016-08-10T11:20:11Z,2016-08-10T11:21:56Z,"- bug fixes for imports
- improvement to import without the special `:` character
- linting changes
",50202460
11,False,False,2016-08-01T12:26:21Z,2016-08-01T12:28:05Z,"- Updated README for installations.
- Update for Go 1.7.
- Update vendoring, dependency management.
- Refactoring of ZMQ code.
- Error handling.
",50202460
12,False,False,2019-04-19T11:55:16Z,2019-04-25T02:10:05Z,"Main update:

  * Support python DMatrix.
  * Better Windows support.",93925242
13,False,False,2019-03-25T13:17:10Z,2019-03-25T13:30:35Z,"Main Update:
    *Fix bugs in previous version
    *Provide binary python package on windows. Support Python(x64) in these versions: py2.7,py3.4,py3.5,py3.6,py3.7
",93925242
14,False,False,2019-03-12T07:38:49Z,2019-03-12T08:17:00Z,"Main update:
* Release Windows version of xLearn
",93925242
15,False,False,2019-01-30T14:02:00Z,2019-01-30T14:13:32Z,"Main update:

* More flexible data reader ",93925242
16,False,False,2018-11-22T13:45:00Z,2018-11-22T13:46:30Z,"* Fix bugs in previous version
* Add online learning for xLearn",93925242
17,False,False,2018-11-10T13:01:12Z,2018-11-10T13:01:57Z,"2018-11-10 xLearn 0.3.8 version release. Main update:

   * Fix bugs in previous version.
   * Update early-stop meachnism.",93925242
18,False,False,2018-10-29T05:10:33Z,2018-10-29T05:14:18Z,"Main Update:

* Fix bugs in 0.3.6",93925242
19,False,False,2018-10-29T05:10:33Z,2018-10-29T05:13:42Z,,93925242
20,False,False,2018-10-29T04:37:12Z,2018-10-29T04:38:10Z,"Main update:

    * Add incremental Reader, which can save 50% memory cost.",93925242
21,False,False,2018-10-22T07:10:10Z,2018-10-22T07:18:05Z,Fix bugs in 0.3.4 version.,93925242
22,False,False,2018-10-21T14:17:31Z,2018-10-21T14:20:14Z,"Main Update:

1. Fix bugs in on-disk training in previous version.
2. Support new file format.",93925242
23,False,False,2018-10-11T11:51:33Z,2018-10-14T08:33:41Z,"Main update:

1. Solve segmentation fault in prediction
2. Update Early-stop ",93925242
24,False,False,2018-09-22T11:45:54Z,2018-09-22T12:42:39Z,Fix bugs in previous version and re-design the TXT model output format. ,93925242
25,False,False,2018-03-09T06:50:04Z,2018-03-09T06:53:08Z,Fix the memory leak bug in xLearn 0.3.0,93925242
26,False,False,2018-03-08T23:34:15Z,2018-03-09T06:51:51Z,,93925242
27,False,False,2018-08-19T12:19:07Z,2018-08-19T12:21:01Z,"New Features:
* `plot_confusion_matrix` has new parameter `hide_counts` via @echan5 #90",80898688
28,False,False,2018-05-12T10:20:47Z,2018-05-12T10:28:40Z,"New features:
* `plot_precision_recall_curve` and `plot_roc_curve` have been deprecated for `plot_precision_recall` and `plot_roc`, respectively. The major difference is the deletion of the `curves` parameter and the use of `plot_macro`, `plot_micro`, and `classes_to_plot` to choose which curves should be plotted. Thanks to @lugq1990 for this change.",80898688
29,False,False,2018-02-05T13:55:56Z,2018-02-05T14:01:36Z,"New feature:

* `decomposition.plot_pca_2d_projection` now has an option to show biplots! Thanks to @ryanliwag for the change. ",80898688
30,False,False,2017-10-26T01:06:49Z,2017-10-26T01:08:14Z,Hotfix release for RTD. Use conda and readthedocs.yml,80898688
31,False,False,2017-10-25T14:52:15Z,2017-10-25T14:56:24Z,"New Features
* Gain Chart and Lift Chart added to `scikitplot.metrics` module #71 
* Updated Jupyter notebook examples for v0.3.x by @ljvmiranda921 #69 

Bugfix
* Changed deprecated `spectral` colormap to `nipy_spectral` by @emredjan #66 
",80898688
32,False,False,2017-09-17T03:24:51Z,2017-09-17T03:26:27Z,"Bugfix:

* Remove `nose` dependency preventing proper documentation build",80898688
33,False,False,2017-09-13T15:56:19Z,2017-09-13T16:01:01Z,"New features:
* `plot_learning_curve` has new parameter `scoring` to allow custom scoring functions. By @jengelman 
* New plotting function `plot_calibration_curves`

Deprecations
* The Factory API has been deprecated and will be removed in v0.4.0
* `scikitplot.plotters` has been deprecated and the functions in the Functions API have been distributed to various new modules. See documentation for more details.",80898688
34,False,False,2017-09-08T17:38:14Z,2017-09-08T17:46:13Z,"Features

* New option `hide_zeros` for `plot_confusion_matrix` by @ExcaliburZero. #39
* New option to plot only certain labels in `plot_confusion_matrix` by @ExcaliburZero. #41
* New options to set colormaps for `plot_pca_2d_projection`, `plot_silhouette`, `plot_precision_recall_curve`, `plot_roc_curve`, and `plot_confusion_matrix`. #50 

Bugfix:
* Fixed bug with nan values in confusion matrices by @ExcaliburZero  (#42) ",80898688
35,False,False,2017-07-09T18:25:21Z,2017-07-09T18:42:55Z,"Features:
* #38 adds new parameter `x_tick_rotation` to `plot_confusion_matrix` and `plot_feature_importances`",80898688
36,False,False,2017-05-17T12:14:01Z,2017-05-17T12:17:09Z,"Bugfix
* Fix for #31 ",80898688
37,False,False,2017-04-30T15:02:19Z,2017-04-30T15:07:08Z,"* Fix #13 Thanks to @david1309 for pointing out the fix
* New argument `labels` for `plot_confusion_matrix`. This also fixes #28",80898688
38,False,False,2017-04-25T11:04:20Z,2017-04-25T11:08:18Z,"* Previously, `plot_elbow_curve` calculated cost manually instead of using the built-in `score method of a clusterer instance.",80898688
39,False,False,2017-03-19T06:23:29Z,2017-03-19T06:28:26Z,"New features: 
* `plot_precision_recall_curve` and `plot_ks_statistic` now have a new `curves` argument that allows the user to choose which curves should be plotted. Thanks to @doug-friedman for this PR.
* Jupyter notebook examples are now available thanks to @lstmemery ",80898688
40,False,False,2017-02-26T17:34:29Z,2017-02-26T17:39:15Z,"New features:
- plot_pca_2d_projection function
- plot_pca_component_variance function
- plots now have a `figsize`, `title_fontsize`, and `text_fontsize` feature to allow user to customize the size of the plot. This is particularly crucial for Jupyter notebook users where the default settings come out too small. Thanks to @frankherfert for this idea.
",80898688
41,False,False,2017-02-19T05:20:47Z,2017-02-19T05:21:55Z,"Minor changes to examples repo.

Release to trigger Zenodo webhook.
",80898688
42,False,False,2017-02-18T21:01:21Z,2017-02-18T21:16:39Z,"Added Functions API
",80898688
43,False,False,2017-02-17T18:07:48Z,2017-02-17T18:12:09Z,"Welcome to the first ever release of scikit-plot. Hope you find this small library useful!
",80898688
44,False,False,2019-08-29T17:22:24Z,2019-08-29T17:25:28Z,,145148726
45,False,False,2019-08-29T17:22:24Z,2019-08-29T17:25:17Z,,145148726
46,False,False,2019-08-29T17:22:24Z,2019-08-29T17:25:10Z,,145148726
47,False,False,2019-08-29T17:22:24Z,2019-08-29T17:24:59Z,,145148726
48,False,False,2019-08-29T17:22:24Z,2019-08-29T17:24:48Z,,145148726
49,False,False,2019-08-27T18:19:38Z,2019-08-27T18:22:41Z,,145148726
50,False,False,2019-08-27T18:19:38Z,2019-08-27T18:22:33Z,,145148726
51,False,False,2019-08-27T18:19:38Z,2019-08-27T18:22:18Z,,145148726
52,False,False,2019-08-27T18:19:38Z,2019-08-27T18:22:03Z,,145148726
53,False,False,2019-08-27T16:23:40Z,2019-08-27T16:27:39Z,,145148726
54,False,False,2019-07-03T16:41:31Z,2019-07-03T18:17:02Z,,145148726
55,False,False,2019-06-12T14:09:08Z,2019-06-12T14:09:42Z,,145148726
56,False,False,2019-05-29T15:01:15Z,2019-05-29T15:01:52Z,,145148726
57,False,False,2019-05-14T20:04:09Z,2019-05-14T20:05:05Z,,145148726
58,False,False,2019-04-26T17:45:47Z,2019-04-26T17:46:11Z,,145148726
59,False,False,2019-04-22T19:40:11Z,2019-04-22T19:42:00Z,,145148726
60,False,False,2019-04-08T19:35:50Z,2019-04-08T19:36:20Z,,145148726
61,False,False,2019-03-25T19:07:09Z,2019-03-25T19:07:42Z,,145148726
62,False,False,2019-03-11T19:23:44Z,2019-03-11T19:24:11Z,,145148726
63,False,False,2019-02-25T21:12:51Z,2019-02-25T21:13:23Z,,145148726
64,False,False,2019-02-11T20:18:00Z,2019-02-11T20:18:32Z,,145148726
65,False,False,2019-01-28T23:10:20Z,2019-01-28T23:11:00Z,,145148726
66,False,False,2019-01-14T20:14:02Z,2019-01-14T20:14:36Z,,145148726
67,False,False,2018-12-20T20:43:17Z,2018-12-20T20:43:53Z,azureml-sdk-1.0.6,145148726
68,False,False,2018-12-13T16:28:02Z,2018-12-14T16:12:28Z,,145148726
69,False,True,2018-11-20T16:02:28Z,2018-11-20T16:03:37Z,Update to SDK version 0.1.80. Note azureml.widget and MachineLearningCompute changes.,145148726
70,False,True,2018-11-05T20:28:40Z,2018-11-05T20:29:19Z,,145148726
71,False,True,2018-10-12T18:44:10Z,2018-10-15T19:57:19Z,Update notebooks to match new Azure ML SDK version 0.1.68.,145148726
72,False,False,2018-12-17T21:58:45Z,2018-12-17T22:00:12Z,"This is a minor release that fixes some bug and documentation nits.

Bugfixes:
 - Fix sorting in the post index table layout (#475) [@srowen]
 - Fix rendering of months in stat plots (#474) [@srowen]
 - Fix Python 2 string handling, resulting in several bugs [@matthewwardrop]

Documentation improvements:
 - Add guidance to `kp preview` command about how to access preview when running remotely. [@matthewwardrop]
 - Add configuration guide for using SSH authentication GitHub-backed knowledge repositories (#477) [@srowen]
 - Improve rendering of options prefixed by two hyphens (e.g. `--flags`) (#476) [@srowen]",65949398
73,False,False,2018-12-12T23:42:59Z,2018-12-12T23:45:43Z,"This is a minor release fixing indexing for gunicorn deployments (which failed to start the indexing threads due to multiple instances of the Knowledge Repo web app being created, and the master uuid being assigned to an unused instance).",65949398
74,False,False,2018-10-29T21:06:12Z,2018-10-29T21:40:25Z,This is a minor release that fixes a bug introduced in v0.8.5 that prevented indexing when running the server in non-deployment scenarios via the `knowledge_repo` script.,65949398
75,False,False,2018-10-08T20:09:51Z,2018-10-08T20:29:33Z,"This is a minor release with several small improvements and bugfixes.

Features and improvements:
 - 404 pages are now shown instead of error pages if a post does not exist. (#463) [@wooddar]
 - Thumbnails of posts are stored in the database, but if they are too large, the base64 encoded images are truncated and thus corrupted. This patch causes the post thumbnail to be resized before being added to the index. (#464) [@matthewwardrop]

Bugfixes:
 - Indexing routines are now initialised at time of deployment, rather than instantiation, improving user experience with commands like `reindex` in the `knowledge_repo` script. (#465) [@matthewwardrop]
 - `kp ... preview` did not correctly disable indexing when launching the preview server [@matthewwardrop]
",65949398
76,False,False,2018-10-04T23:08:27Z,2018-10-05T19:34:53Z,"This is another minor release with a significant set of improvements noticeable for the end-user.

Features and enhancements:
- Main UI now restricts its maximum width and increases font size for better readability. [@matthewwardrop]
- Landed the new `kp` script that replaces `knowledge_repo` for contribution by users (currently in beta, will deprecate `knowledge_repo` for these use cases in future versions; as well as the new `FolderKnowledgeRepository` which serves posts from any directory (#308) [@matthewwardrop]
- Indexing stability improved by disposing of engine on child thread before performing operations. (#457) [@matthewwardrop]
- Added support for subtitle field, made the document title distinct from `h1`, and made post header submissions (optionally) interactive (#460) [@matthewwardrop]
- Added support for importing documents from Google Docs and programmatically creating proxy posts (#462) [@matthewwardrop]
- Enable downloading of the portable knowledge format used by the `kp` script [@matthewwardrop]

Miscellaneous:
- Travis was configured to run on actual target Python releases (#456) [@naoyak]
- Python 3.4 was temporarily disabled due to upstream issues in anaconda [@matthewwardrop]
- Remove troublesome (and redundant) constraints on SQL fields preventing use in MariaDB. [@matthewwardrop]",65949398
77,False,False,2018-09-27T00:19:14Z,2018-09-27T04:18:53Z,This a hotfix reverting an attempt to improve database connection reliability during indexing (#445) that broke SQLite in-memory databases.,65949398
78,False,False,2018-09-26T17:17:25Z,2018-09-26T17:32:03Z,"This is another minor release with a large number of improvements and bugfixes. This release is a composite of work from a large number of contributors, so thanks to everyone for chipping in!

Features and enhancements:
- Names of comment authors is now rendered using `format_name` (#406) [@danhper]
- Properly render in IE compatibility mode (#419) [@dorianbrown]
- Support deployments using HTTPS for both `gunicorn` and `uwsgi` (#420) [@dorianbrown]
- Properly set the viewport size for mobile browsers (#422) [@wooddar]
- Support nested folders in the cluster view (#424) [@tcbegley]
- Allow configuration of `gunicorn` via standard environment variables (#437) [@john-bodley]
- Redirect to original target page after logging in (#439) [@wooddar]
- Allow `knowledge_repo` to work with `markdown` >= 3 (#453) [@naoyak]

Bugfixes and stability enhancments:
- Database connections would sometimes fail during indexing (#445) [@CPapadim]
- Knowledge Git Repositories not deployed off the `master` branch did not reindex properly (#449) [@jihonrado]
- Multiple slashes would appear in OAuth `redirect_uri` (#407) [@danhper]
- Correctly set the `__all__` module variable for dynamically generated imports (#417) [@BioGeek]

Miscellaneous:
- Do not warn about `gunicorn` compatibility on Windows unless actually attempting to use `gunicorn` [@matthewwardrop]
- Typos and broken links (#397, #398, #414) [@notpeter, @BioGeek]",65949398
79,False,False,2018-04-11T20:38:13Z,2018-09-26T17:15:42Z,"This is a minor release with some feature enhancements and bugfixes.

Feature enhancements:
 - Flesh out header auth with support for user attributes like email, photo, etc. (#396) [@matthewwardrop]

Bugfixes:
 - Bugfix related to PostProcessor kwargs (#395) [@danfrankj]
 - Fix builds breaking in Windows due to `conda` changes and stricter `pycodestyle`. [@matthewwardrop]",65949398
80,False,False,2018-03-25T09:20:34Z,2018-03-25T21:22:17Z,"This is a new feature release that includes more than a year's worth of contributions since v0.7.6. The configuration of both repositories and servers has change significantly, and Knowledge Repo administrators are recommended to review these changes as soon as possible. In particular, repository configuration from v0.7.6 and earlier is no longer compatible, and is ignored in v0.8.0+ due to security concerns. If you need to enable compatibility for this configuration during a migration, add `required_tooling_version: ""!v0.7.6""` to a file named `.knowledge_repo_config.yml` in the root of your repository.

**Features:**
- Added support for custom server-side authentication (with various OAuth 2.0 providers) [@matthewwardrop, @zerogjoe]
- Error logs are now stored separately from pageviews [@matthewwardrop]
- Added support for HTML/Javascript cells (i.e. Plotly, Bokeh, etc) [@bmabey, @matthewwardrop]
- New `KnowledgePostProcessor` to handle extracting images from posts for use in a separate server for static content. [@aaronbiller]
- Posts can be opened in new tab by holding Alt or Command keys while clicking the post [@matthewwardrop]

**Enhancements:**
- Indexing is now much more robust and can handle multiple instances connected to the same index database across multiple servers [@matthewwardrop]
- Added index database schema downgrade functionality for when this is necessary [@NiharikaRay]
- Documentation improvements, including creation of new Sphinx documentation [@matthewwardrop, @danfrankj, @mrustl, @aaronbiller]
- Added support for user icons [@matthewwardrop]
- Knowledge Post source files are now found at /src/ instead of /orig_src/ [ @matthewwardrop ]
- Improvements to web editor flow, including directly creating a proxy-post from `/create` [@danfrankj]
- Various theming improvements including favicons, responsive UI, and styling [@matthewwardrop, @danfrankj]
- Added posts per author to stats [@ymwdalex]
- Allow specifying custom templates during post creation via the CLI [@jordan-wright]

**Security Improvements:**
- Removed two security vulnerabilities associated with arbitrary code execution from code stored in knowledge repositories on both clients and servers via knowledge repository configuration and embedded tooling. [@matthewwardrop]

And many other small bugfixes and improvements. Many thanks to everyone who contributed code and information via issues.",65949398
81,False,False,2017-02-27T04:42:28Z,2017-02-27T04:54:15Z,"This is the next in a series of minor updates for the v0.7.x series, and fixes several important bugs and introduces several cosmetic improvements. We also introduce formal compatibility with the Windows platform and add Windows to the list of platforms we continuously test against.

Interface improvements:
- Improvements to the rendering of the main index feed. (#218)
- Improved pagination controls (#221, #224)
- Code folding support (#232, #233) [thanks to @clabroy]

Bug fixes:
- Fix preview mode. (#219)
- Fix image parser to avoid skipping images in markdown files (#220)
- Fix importing and running on Windows (#225)
- Fix Rmd conversions in Windows (#228)
- Fix support for Postgresql and other databases not idiomatically similar to MySQL (#229)
",65949398
82,False,False,2017-02-07T21:36:07Z,2017-02-07T21:49:41Z,"This release does a handful of things
- Fixes MySQL timeout errors in the DBKnowledgeRepository ([PR here](https://github.com/airbnb/knowledge-repo/pull/185))
- Changes the way posts are rendered ([PR here](https://github.com/airbnb/knowledge-repo/pull/186))
- Several webeditor fixes including: 
  - Not allowing paths to be editable: ([PR here](https://github.com/airbnb/knowledge-repo/pull/188))
  - Better error messages in alerts ([PR here](https://github.com/airbnb/knowledge-repo/pull/191))
  - Adding a link to the webeditor from rendered webposts ([PR here](https://github.com/airbnb/knowledge-repo/pull/192))
- Update the URL schemas for all post-related routes: ([PR here])(https://github.com/airbnb/knowledge-repo/pull/197)

Full change list [here](https://github.com/airbnb/knowledge-repo/compare/v0.7.4...master)
",65949398
83,False,False,2016-12-20T07:32:52Z,2016-12-20T07:53:46Z,"This release fixes some small bugs that have been discovered since the last release:
- support for dir functionality in a DBKnowledgeRepository when specifying a subfolder as parent (fixes loading images from the repository)
- some lingering issues with indexing (such as occasional hanging)
- some cli issues caused by a recent patch to the chaining of the knowledge_repo command
- a dependency issue due to an upstream change to nbconvert

It also adds some simply debugging routes that can assist in diagnosing issues, and improves documentation.
",65949398
84,False,False,2016-12-08T22:43:48Z,2016-12-20T07:46:56Z,"This release is  (slightly) more than a bugfix release. It two new headers:
- `thumbnail` that allows you to choose which image to use as the feed image. It can be a normal file or web uri, or a number (in which case the nth image from the post is chosen as the feed image).
- `proxy` which allows you to specific a url which will be loaded into an iframe when the post is rendered. This can be helpful in gaining publicity for documents stored on external hosting services, like Google Docs Docs, Dropbox, etc.

It also supports using non-standard port numbers for git-ssh, improves search, fixes some CLI bugs and fixes batch tagging. 
",65949398
85,False,False,2016-11-09T23:40:25Z,2016-11-09T23:44:14Z,"This release fixes some small bugs related to reindexing, and some minor enhancements:
- DBKnowledgeRepository revisions were datetime objects rather than strings, breaking comparison
- Cleaned up time delta handling during the reindexing
- Added the last time the repositories were checked for updates as a tooltip when hovering over last index update time.
",65949398
86,False,False,2016-11-09T01:09:00Z,2016-11-09T01:11:55Z,"This is a minor bugfix which addresses the following issues:
- PostGres databases do not support `BLOB` datatypes, so we now use a generalisation.
- Revision information for DBKnowledgeRepository instances was malformed.
- MetaKnowledgeRepository revision information was not being output in the expected form.
",65949398
87,False,False,2016-11-08T18:29:52Z,2016-11-08T18:45:09Z,"This release is the next minor version in the pre-stable series.

It adds the following features and improvements:
- Automatic reindexing of knowledge repositories when they are updated (git repositories must still be externally updated, which will be addressed in a future version)
- Improved deployment logic which unifies launching the knowledge repo using the development server built into Flask, Gunicorn and uWSGI.
- Greatly simplified and improved web editor.

It also addresses the following bugs:
- Fixes setting up a DBKnowledgeRepository atop Postgres
- Fixes knitting of Rmd files on Windows

For a complete list of changes, please review the git changelog.
",65949398
88,False,False,2016-11-03T22:47:40Z,2016-11-03T22:52:56Z,"This release does a few things: 
1. Adds the knowledge version to content ([PR here](https://github.com/airbnb/knowledge-repo/pull/98))
2. Adds ""proxy posts"", where things like google docs can be added to the KR. ([PR Here](https://github.com/airbnb/knowledge-repo/pull/100))
3. Adds the ability to add post-specific permissions, using a ""private"" flag in the header, and then a list of allowed_groups. ([PR here](https://github.com/airbnb/knowledge-repo/pull/108))
",65949398
89,False,False,2016-10-31T22:24:03Z,2016-10-31T22:30:08Z,"This is another small release that:
- enhances/fixes some formatting/styling of the typeahead search dropdown
- improves the documentation by clarifying how configuration files are handled
",65949398
90,False,False,2016-10-27T21:12:55Z,2016-10-27T21:17:33Z,"This release improved the typeahead search box, by creating keywords for each post, consisting of the title, authors, tags, and tldrs. Search was then done by looking at matches in these keywords, ranking by the highest number of matches.
",65949398
91,False,False,2016-10-26T23:59:16Z,2016-10-27T00:01:32Z,"This releases some further inadvertent breakage due to the ""excluded tags"" functionality.
",65949398
92,False,False,2016-10-26T18:17:50Z,2016-10-26T18:24:59Z,"This releases fixes two small bugs:
- ""Excluded tags"" functionality causing problems when not specified.
- Fix adding Rmd and md files with images in Python 3 (ipynb files were not affected because images are treated differently).
",65949398
93,False,False,2016-10-12T19:26:44Z,2016-10-12T19:29:36Z,"This release fixes a bug whereby if server configuration was not present, or if ""EXCLUDED_TAGS"" was not defined in the server config, then the web app would crash.
",65949398
94,False,False,2016-10-12T06:27:53Z,2016-10-12T06:36:19Z,"This release adds the following enhancements:
- Addition of a `--version` option to the `knowledge_repo` script, which shows both the locally installed version and the currently active versions of the knowledge repository tooling (these can be different if using embedded tooling).
- Expansion of `~` (the user home directory) when extracting images from ipynb/Rmd/markdown source.
- Use of the https rather than ssh protocol when embedding knowledge_repo tools into git repositories.
- Disable auto-embedding of knowledge_repo tooling in new repositories, since this is mainly useful in large deployments and was causing headaches for new users.

It also fixes the following bugs:
- Initialization of embedded knowledge-repo tools fails in newly checked out repositories (introduced in v0.6.3).
",65949398
95,False,False,2016-10-07T21:43:34Z,2016-10-07T22:14:05Z,"This release adds the concept of excluded tags to the app, which allows users to exclude posts that may be sensitive.
",65949398
96,False,False,2016-09-29T23:08:50Z,2016-09-29T23:14:03Z,"This release adds support for versions of git older than ~2.5; which do not have support for extracting the remote url using:
`git remote get-url origin`

In the process it also cleans up the GitKnowledgeRepository code a little pertaining to remote repositories, as well as clarifying that the Knowledge Repository supports any git repository (including those not hosted by GitHub).
",65949398
97,False,False,2016-09-27T21:13:56Z,2016-09-27T21:15:03Z,"This release simply suppresses spurious standard error output reporting git fatal errors.
",65949398
98,False,False,2016-09-27T20:17:22Z,2016-09-27T20:25:18Z,"This release adds support for migrating the submodule url for the embedded tools inside of knowledge data repositories.

It also fixes:
- Deploying when not based on a MetaKnowledgeRepository
- A hard dependency on PyPDF2 by making it a soft dependency.
  and other small miscellaneous changes and cleanups.
",65949398
99,False,False,2016-09-27T04:16:40Z,2016-09-27T04:20:34Z,"With the release of v0.6.0, we open the Knowledge Repository up to the world. We encourage everyone to try it out, give feedback, and contribute code as we work our way toward v1.0.0. With this release, we are confident that the Knowledge Repository is already very useful, and look forward to working with you to make it even better.
",65949398
100,False,False,2019-10-07T20:03:26Z,2019-10-07T20:06:38Z,"Keras 2.3.1 is a minor bug-fix release. In particular, it fixes an issue with using Keras models across multiple threads.

## Changes

- Bug fixes
- Documentation fixes
- No API changes
- No breaking changes",33015583
101,False,False,2019-09-17T17:01:48Z,2019-09-17T17:09:50Z,"Keras 2.3.0 is the first release of multi-backend Keras that supports TensorFlow 2.0. It maintains compatibility with TensorFlow 1.14, 1.13, as well as Theano and CNTK.

**This release brings the API in sync with the [tf.keras](https://www.tensorflow.org/beta/guide/keras/) API as of TensorFlow 2.0. However note that it does not support most TensorFlow 2.0 features, in particular eager execution. If you need these features, use [tf.keras](https://www.tensorflow.org/beta/guide/keras/).**

**This is also the last major release of multi-backend Keras. Going forward, we recommend that users consider switching their Keras code to [tf.keras](https://www.tensorflow.org/beta/guide/keras/) in TensorFlow 2.0**. It implements the same Keras 2.3.0 API (so switching should be as easy as changing the Keras import statements), but it has many advantages for TensorFlow users, such as support for eager execution, distribution, TPU training, and generally far better integration between low-level TensorFlow and high-level concepts like Layer and Model. It is also better maintained.

Development will focus on tf.keras going forward. We will keep maintaining multi-backend Keras over the next 6 months, but we will only be merging bug fixes. API changes will not be ported.


# API changes

- Add `size(x)` to backend API.
- `add_metric` method added to Layer / Model (used in a similar way as `add_loss`, but for metrics), as well as the metrics `property`.
- Variables set as attributes of a Layer are now tracked in `layer.weights` (including `layer.trainable_weights` or `layer.non_trainable_weights` as appropriate).
- Layers set as attributes of a Layer are now tracked (so the weights/metrics/losses/etc of a sublayer are tracked by parent layers). This behavior already existed for Model specifically and is now extended to all Layer subclasses.
- Introduce class-based losses (inheriting from `Loss` base class). This enables losses to be parameterized via constructor arguments. Loss classes added:
  - `MeanSquaredError`
  - `MeanAbsoluteError`
  - `MeanAbsolutePercentageError`
  - `MeanSquaredLogarithmicError`
  - `BinaryCrossentropy`
  - `CategoricalCrossentropy`
  - `SparseCategoricalCrossentropy`
  - `Hinge`
  - `SquaredHinge`
  - `CategoricalHinge`
  - `Poisson`
  - `LogCosh`
  - `KLDivergence`
  - `Huber`
- Introduce class-based metrics (inheriting from `Metric` base class). This enables metrics to be stateful (e.g. required for supported AUC) and to be parameterized via constructor arguments. Metric classes added:
  - `Accuracy`
  - `MeanSquaredError`
  - `Hinge`
  - `CategoricalHinge`
  - `SquaredHinge`
  - `FalsePositives`
  - `TruePositives`
  - `FalseNegatives`
  - `TrueNegatives`
  - `BinaryAccuracy`
  - `CategoricalAccuracy`
  - `TopKCategoricalAccuracy`
  - `LogCoshError`
  - `Poisson`
  - `KLDivergence`
  - `CosineSimilarity`
  - `MeanAbsoluteError`
  - `MeanAbsolutePercentageError`
  - `MeanSquaredError`
  - `MeanSquaredLogarithmicError`
  - `RootMeanSquaredError`
  - `BinaryCrossentropy`
  - `CategoricalCrossentropy`
  - `Precision`
  - `Recall`
  - `AUC`
  - `SparseCategoricalAccuracy`
  - `SparseTopKCategoricalAccuracy`
  - `SparseCategoricalCrossentropy`
- Add `reset_metrics` argument to `train_on_batch` and `test_on_batch`. Set this to True to maintain metric state across different batches when writing lower-level training/evaluation loops. If False, the metric value reported as output of the method call will be the value for the current batch only.
- Add `model.reset_metrics()` method to Model. Use this at the start of an epoch to clear metric state when writing lower-level training/evaluation loops.
- Rename `lr` to `learning_rate` for all optimizers.
- Deprecate argument `decay` for all optimizers. For learning rate decay, use [`LearningRateSchedule`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule) objects in tf.keras.


# Breaking changes

- TensorBoard callback:
  - `batch_size` argument is deprecated (ignored)  when used with TF 2.0
  - `write_grads` is deprecated (ignored) when used with TF 2.0
  - `embeddings_freq`, `embeddings_layer_names`, `embeddings_metadata`, `embeddings_data` are deprecated (ignored) when used with TF 2.0
- Change loss aggregation mechanism to sum over batch size. This may change reported loss values if you were using sample weighting or class weighting. You can achieve the old behavior by making sure your sample weights sum to 1 for each batch.
- Metrics and losses are now reported under the exact name specified by the user (e.g. if you pass `metrics=['acc']`, your metric will be reported under the string ""acc"", not ""accuracy"", and inversely `metrics=['accuracy']` will be reported under the string ""accuracy"".
- Change default recurrent activation to `sigmoid` (from `hard_sigmoid`) in all RNN layers.
",33015583
102,False,False,2019-08-22T00:58:08Z,2019-08-22T16:43:53Z,"Keras 2.2.5 is the last release of Keras that implements the 2.2.* API. It is the last release to only support TensorFlow 1 (as well as Theano and CNTK).

The next release will be 2.3.0, which makes significant API changes and add support for TensorFlow 2.0. The 2.3.0 release will be the last major release of multi-backend Keras. Multi-backend Keras is superseded by `tf.keras`.

At this time, we recommend that Keras users who use multi-backend Keras with the TensorFlow backend switch to `tf.keras` in TensorFlow 2.0. `tf.keras` is better maintained and has better integration with TensorFlow features.

## API Changes

* Add new Applications: `ResNet101`, `ResNet152`, `ResNet50V2`, `ResNet101V2`, `ResNet152V2`.
* Callbacks: enable callbacks to be passed in `evaluate` and `predict`.
  - Add `callbacks` argument (list of callback instances) in `evaluate` and `predict`.
  - Add callback methods `on_train_batch_begin`, `on_train_batch_end`, `on_test_batch_begin`, `on_test_batch_end`, `on_predict_batch_begin`, `on_predict_batch_end`, as well as `on_test_begin`, `on_test_end`, `on_predict_begin`, `on_predict_end`. Methods `on_batch_begin` and `on_batch_end` are now aliases for `on_train_batch_begin` and `on_train_batch_end`.
* Allow file pointers in `save_model` and `load_model` (in place of the filepath)
* Add `name` argument in Sequential constructor
* Add `validation_freq` argument in `fit`, controlling the frequency of validation (e.g. setting `validation_freq=3` would run validation every 3 epochs)
* Allow Python generators (or Keras Sequence objects) to be passed in `fit`, `evaluate`, and `predict`, instead of having to use `*_generator` methods.
  - Add generator-related arguments `max_queue_size`, `workers`, `use_multiprocessing` to these methods.
* Add `dilation_rate` argument in layer `DepthwiseConv2D`.
* MaxNorm constraint: rename argument `m` to `max_value`.
* Add `dtype` argument in base layer (default dtype for layer's weights).
* Add Google Cloud Storage support for model.save_weights and model.load_weights.
* Add JSON-serialization to the `Tokenizer` class.
* Add `H5Dict` and `model_to_dot` to utils.
* Allow default Keras path to be specified at startup via environment variable KERAS_HOME.
* Add arguments `expand_nested`, `dpi` to `plot_model`.
* Add `update_sub`, `stack`, `cumsum`, `cumprod`, `foldl`, `foldr` to CNTK backend
* Add `merge_repeated` argument to `ctc_decode` in TensorFlow backend

Thanks to the 89 committers who contributed code to this release!",33015583
103,False,False,2018-10-03T20:58:20Z,2018-10-03T20:58:33Z,"This is a bugfix release, addressing two issues:

- Ability to save a model when a file with the same name already exists.
- Issue with loading legacy config files for the `Sequential` model.

[See here](https://github.com/keras-team/keras/releases/tag/2.2.3) for the changelog since 2.2.2.",33015583
104,False,False,2018-10-01T19:00:01Z,2018-10-01T23:39:39Z,"## Areas of improvement

- API completeness & usability improvements
- Bug fixes
- Documentation improvements

## API changes

- Keras models can now be safely pickled.
- Consolidate the functionality of the activation layers `ThresholdedReLU` and `LeakyReLU` into the `ReLU` layer.
- As a result, the `ReLU` layer now takes new arguments `negative_slope` and `threshold`, and the `relu` function in the backend takes a new `threshold` argument.
- Add `update_freq` argument in `TensorBoard` callback, controlling how often to write TensorBoard logs.
- Add the `exponential` function to `keras.activations`.
- Add `data_format` argument in all 4 `Pooling1D` layers.
- Add `interpolation` argument in `UpSampling2D` layer and in `resize_images` backend function, supporting modes `""nearest""` (previous behavior, and new default) and `""bilinear""` (new).
- Add `dilation_rate` argument in `Conv2DTranspose` layer and in `conv2d_transpose` backend function.
- The `LearningRateScheduler` now receives the `lr` key as part of the `logs` argument in `on_epoch_end` (current value of the learning rate).
- Make `GlobalAveragePooling1D` layer support masking.
- The the `filepath` argument `save_model` and `model.save()` can now be a `h5py.Group` instance.
- Add argument `restore_best_weights` to `EarlyStopping` callback (optionally reverts to the weights that obtained the highest monitored score value).
- Add `dtype` argument to `keras.utils.to_categorical`.
- Support `run_options` and `run_metadata` as optional session arguments in `model.compile()` for the TensorFlow backend.

## Breaking changes

- Modify the return value of `Sequential.get_config()`. Previously, the return value was a list of the config dictionaries of the layers of the model. Now, the return value is a dictionary with keys `layers`, `name`, and an optional key `build_input_shape`. The old config is equivalent to `new_config['layers']`. This makes the output of `get_config` consistent across all model classes.


## Credits

Thanks to our 38 contributors whose commits are featured in this release:

@BertrandDechoux, @ChrisGll, @Dref360, @JamesHinshelwood, @MarcoAndreaBuchmann, @ageron, @alfasst, @blue-atom, @chasebrignac, @cshubhamrao, @danFromTelAviv, @datumbox, @farizrahman4u, @fchollet, @fuzzythecat, @gabrieldemarmiesse, @hadifar, @heytitle, @hsgkim, @jankrepl, @joelthchao, @knightXun, @kouml, @linjinjin123, @lvapeab, @nikoladze, @ozabluda, @qlzh727, @roywei, @rvinas, @sriyogesh94, @tacaswell, @taehoonlee, @tedyu, @xuhdev, @yanboliang, @yongzx, @yuanxiaosc",33015583
105,False,False,2018-07-28T19:32:13Z,2018-07-28T19:34:04Z,"This is a bugfix release, fixing a significant bug in `multi_gpu_model`.

For changes since version 2.2.0, see release notes for [Keras 2.2.1](https://github.com/keras-team/keras/releases/tag/2.2.1).",33015583
106,False,False,2018-07-27T22:06:51Z,2018-07-27T22:23:54Z,"## Areas of improvement

- Bugs fixes
- Performance improvements
- Documentation improvements

## API changes

- Add `output_padding` argument in `Conv2DTranspose` (to override default padding behavior).
- Enable automatic shape inference when using Lambda layers with the CNTK backend.

## Breaking changes

No breaking changes recorded.

## Credits

Thanks to our 33 contributors whose commits are featured in this release:

@Ajk4, @Anner-deJong, @Atcold, @Dref360, @EyeBool, @ageron, @briannemsick, @cclauss, @davidtvs, @dstine, @eTomate, @ebatuhankaynak, @eliberis, @farizrahman4u, @fchollet, @fuzzythecat, @gabrieldemarmiesse, @jlopezpena, @kamil-kaczmarek, @kbattocchi, @kmader, @kvechera, @maxpumperla, @mkaze, @pavithrasv, @rvinas, @sachinruk, @seriousmac, @soumyac1999, @taehoonlee, @yanboliang, @yongzx, @yuyang-huang",33015583
107,False,False,2018-06-06T18:53:18Z,2018-06-06T22:42:23Z,"## Areas of improvements

- New model definition API: `Model` subclassing.
- New input mode: ability to call models on TensorFlow tensors directly (TensorFlow backend only).
- Improve feature coverage of Keras with the Theano and CNTK backends.
- Bug fixes and performance improvements.
- Large refactors improving code structure, code health, and reducing test time. In particular:
   * The Keras engine now follows a much more modular structure.
   * The `Sequential` model is now a plain subclass of `Model`.
   * The modules `applications` and `preprocessing` are now externalized to their own repositories ([keras-applications](https://github.com/keras-team/keras-applications) and [keras-preprocessing](https://github.com/keras-team/keras-preprocessing)).

## API changes

- Add `Model` subclassing API (details below).
- Allow symbolic tensors to be fed to models, with TensorFlow backend (details below).
- Enable CNTK and Theano support for layers `SeparableConv1D`, `SeparableConv2D`, as well as backend methods `separable_conv1d` and `separable_conv2d` (previously only available for TensorFlow).
- Enable CNTK and Theano support for applications `Xception` and `MobileNet` (previously only available for TensorFlow).
- Add `MobileNetV2` application  (available for all backends).
- Enable loading external (non built-in) backends by changing your `~/.keras.json` configuration file (e.g. PlaidML backend).
- Add `sample_weight` in `ImageDataGenerator`.
- Add `preprocessing.image.save_img` utility to write images to disk.
- Default `Flatten` layer's `data_format` argument to `None` (which defaults to global Keras config).
- `Sequential` is now a plain subclass of `Model`. The attribute `sequential.model` is deprecated.
- Add `baseline` argument in `EarlyStopping` (stop training if a given baseline isn't reached).
- Add `data_format` argument to `Conv1D`.
- Make the model returned by `multi_gpu_model` serializable.
- Support input masking in `TimeDistributed` layer.
- Add an `advanced_activation` layer `ReLU`, making the ReLU activation easier to configure while retaining easy serialization capabilities.
- Add `axis=-1` argument in backend crossentropy functions specifying the class prediction axis in the input tensor.

## New model definition API : `Model` subclassing

In addition to the `Sequential` API and the functional `Model` API, you may now define models by subclassing the `Model` class and writing your own `call` forward pass:

```python
import keras

class SimpleMLP(keras.Model):

    def __init__(self, use_bn=False, use_dp=False, num_classes=10):
        super(SimpleMLP, self).__init__(name='mlp')
        self.use_bn = use_bn
        self.use_dp = use_dp
        self.num_classes = num_classes

        self.dense1 = keras.layers.Dense(32, activation='relu')
        self.dense2 = keras.layers.Dense(num_classes, activation='softmax')
        if self.use_dp:
            self.dp = keras.layers.Dropout(0.5)
        if self.use_bn:
            self.bn = keras.layers.BatchNormalization(axis=-1)

    def call(self, inputs):
        x = self.dense1(inputs)
        if self.use_dp:
            x = self.dp(x)
        if self.use_bn:
            x = self.bn(x)
        return self.dense2(x)

model = SimpleMLP()
model.compile(...)
model.fit(...)
```

Layers are defined in `__init__(self, ...)`, and the forward pass is specified in `call(self, inputs)`. In `call`, you may specify custom losses by calling `self.add_loss(loss_tensor)` (like you would in a custom layer).

## New input mode: symbolic TensorFlow tensors

With Keras 2.2.0 and TensorFlow 1.8 or higher, you may `fit`, `evaluate` and `predict` using symbolic TensorFlow tensors (that are expected to yield data indefinitely). The API is similar to the one in use in `fit_generator` and other generator methods:

```python
iterator = training_dataset.make_one_shot_iterator()
x, y = iterator.get_next()

model.fit(x, y, steps_per_epoch=100, epochs=10)

iterator = validation_dataset.make_one_shot_iterator()
x, y = iterator.get_next()
model.evaluate(x, y, steps=50)
```

This is achieved by dynamically rewiring the TensorFlow graph to feed the input tensors to the existing model placeholders. There is no performance loss compared to building your model on top of the input tensors in the first place.


## Breaking changes

- Remove legacy `Merge` layers and associated functionality (remnant of Keras 0), which were deprecated in May 2016, with full removal initially scheduled for August 2017. Models from the Keras 0 API using these layers cannot be loaded with Keras 2.2.0 and above.
- The `truncated_normal` base initializer now returns values that are scaled by ~0.9 (resulting in correct variance value after truncation). This has a small chance of affecting initial convergence behavior on some models.


## Credits

Thanks to our 46 contributors whose commits are featured in this release:

@ASvyatkovskiy, @AmirAlavi, @Anirudh-Swaminathan, @DavidAriel, @Dref360, @JonathanCMitchell, @KuzMenachem, @PeterChe1990, @Saharkakavand, @StefanoCappellini, @ageron, @askskro, @bileschi, @bonlime, @bottydim, @brge17, @briannemsick, @bzamecnik, @christian-lanius, @clemens-tolboom, @dschwertfeger, @dynamicwebpaige, @farizrahman4u, @fchollet, @fuzzythecat, @ghostplant, @giuscri, @huyu398, @jnphilipp, @masstomato, @morenoh149, @mrTsjolder, @nittanycolonial, @r-kellerm, @reidjohnson, @roatienza, @sbebo, @stevemurr, @taehoonlee, @tiferet, @tkoivisto, @tzerrell, @vkk800, @wangkechn, @wouterdobbels, @zwang36wang",33015583
108,False,False,2018-04-23T19:43:48Z,2018-04-23T20:14:24Z,"## Areas of improvement

- Bug fixes
- Documentation improvements
- Minor usability improvements

## API changes

- In callback `ReduceLROnPlateau`, rename `epsilon` argument to `min_delta` (backwards-compatible).
- In callback `RemoteMonitor`, add argument `send_as_json`.
- In backend `softmax` function, add argument `axis`.
- In `Flatten` layer, add argument `data_format`.
- In `save_model` (`Model.save`) and `load_model` functions, allow the `filepath` argument to be a `h5py.File` object.
- In `Model.evaluate_generator`, add `verbose` argument.
- In `Bidirectional` wrapper layer, add `constants` argument.
- In `multi_gpu_model` function, add arguments `cpu_merge` and `cpu_relocation` (controlling whether to force the template model's weights to be on CPU, and whether to operate merge operations on CPU or GPU).
- In `ImageDataGenerator`, allow argument `width_shift_range` to be `int` or 1D array-like.

## Breaking changes

This release does not include any known breaking changes.

## Credits

Thanks to our 37 contributors whose commits are featured in this release:

@Dref360, @FirefoxMetzger, @Naereen, @NiharG15, @StefanoCappellini, @WindQAQ, @dmadeka, @edrogers, @eltronix, @farizrahman4u, @fchollet, @gabrieldemarmiesse, @ghostplant, @jedrekfulara, @jlherren, @joeyearsley, @johanahlqvist, @johnyf, @jsaporta, @kalkun, @lucasdavid, @masstomato, @mrlzla, @myutwo150, @nisargjhaveri, @obi1kenobi, @olegantonyan, @ozabluda, @pasky, @planck35, @sotlampr, @souptc, @srjoglekar246, @stamate, @taehoonlee, @vkk800, @xuhdev",33015583
109,False,False,2018-03-06T22:05:39Z,2018-03-06T22:07:49Z,"## Areas of improvement

- Bug fixes.
- New APIs: sequence generation API `TimeseriesGenerator`, and new layer `DepthwiseConv2D`.
- Unit tests / CI improvements.
- Documentation improvements.

## API changes

- Add new sequence generation API `keras.preprocessing.sequence.TimeseriesGenerator`.
- Add new convolutional layer `keras.layers.DepthwiseConv2D`.
- Allow weights from `keras.layers.CuDNNLSTM` to be loaded into a `keras.layers.LSTM` layer (e.g. for inference on CPU).
- Add `brightness_range` data augmentation argument in `keras.preprocessing.image.ImageDataGenerator`.
- Add `validation_split` API in `keras.preprocessing.image.ImageDataGenerator`. You can pass `validation_split` to the constructor (float), then select between training/validation subsets by passing the argument `subset='validation'` or `subset='training'` to methods `flow` and `flow_from_directory`.

## Breaking changes

- As a side effect of a refactor of `ConvLSTM2D` to a modular implementation, recurrent dropout support in Theano has been dropped for this layer.

## Credits

Thanks to our 28 contributors whose commits are featured in this release:

@DomHudson, @Dref360, @VitamintK, @abrad1212, @ahundt, @bojone, @brainnoise, @bzamecnik, @caisq, @cbensimon, @davinnovation, @farizrahman4u, @fchollet, @gabrieldemarmiesse, @khosravipasha, @ksindi, @lenjoy, @masstomato, @mewwts, @ozabluda, @paulpister, @sandpiturtle, @saralajew, @srjoglekar246, @stefangeneralao, @taehoonlee, @tiangolo, @treszkai
",33015583
110,False,False,2018-02-13T22:52:55Z,2018-02-13T23:53:22Z,"## Areas of improvement

- Bug fixes
- Performance improvements
- Improvements to example scripts

## API changes

- Allow for stateful metrics in `model.compile(..., metrics=[...])`. A stateful metric inherits from `Layer`, and implements `__call__` and `reset_states`.
- Support `constants` argument in `StackedRNNCells`.
- Enable some TensorBoard features in the `TensorBoard` callback (loss and metrics plotting) with non-TensorFlow backends.
- Add `reshape` argument in `model.load_weights()`, to optionally reshape weights being loaded to the size of the target weights in the model considered.
- Add `tif` to supported formats in `ImageDataGenerator`.
- Allow auto-GPU selection in `multi_gpu_model()` (set `gpus=None`).
- In `LearningRateScheduler` callback, the scheduling function now takes an argument: `lr`, the current learning rate.

## Breaking changes

- In `ImageDataGenerator`, change default interpolation of image transforms from nearest to bilinear. This should probably not break any users, but it is a change of behavior.

## Credits

Thanks to our 37 contributors whose commits are featured in this release:

@DalilaSal, @Dref360, @GalaxyDream, @GarrisonJ, @Max-Pol, @May4m, @MiliasV, @MrMYHuang, @N-McA, @Vijayabhaskar96, @abrad1212, @ahundt, @angeloskath, @bbabenko, @bojone, @brainnoise, @bzamecnik, @caisq, @cclauss, @dsadulla, @fchollet, @gabrieldemarmiesse, @ghostplant, @gorogoroyasu, @icyblade, @kapsl, @kevinbache, @mendesmiguel, @mikesol, @myutwo150, @ozabluda, @sadreamer, @simra, @taehoonlee, @veniversum, @yongtang, @zhangwj618",33015583
111,False,False,2018-01-16T04:55:08Z,2018-01-16T05:47:01Z,"## Areas of improvement

- Performance improvements (esp. convnets with TensorFlow backend).
- Usability improvements.
- Docs & docstrings improvements.
- New models in the `applications` module.
- Bug fixes.

## API changes

- `trainable` attribute in `BatchNormalization` now disables the updates of the batch statistics (i.e. if `trainable == False` the layer will now run 100% in inference mode).
- Add `amsgrad` argument in `Adam` optimizer.
- Add new applications: `NASNetMobile`, `NASNetLarge`, `DenseNet121`, `DenseNet169`, `DenseNet201`.
- Add `Softmax` layer (removing need to use a `Lambda` layer in order to specify the `axis` argument).
- Add `SeparableConv1D` layer.
- In `preprocessing.image.ImageDataGenerator`, allow `width_shift_range` and `height_shift_range` to take integer values (absolute number of pixels)
- Support `return_state` in `Bidirectional` applied to RNNs (`return_state` should be set on the child layer).
- The string values `""crossentropy""` and `""ce""` are now allowed in the `metrics` argument (in `model.compile()`), and are routed to either `categorical_crossentropy` or `binary_crossentropy` as needed.
- Allow `steps` argument in `predict_*` methods on the `Sequential` model.
- Add `oov_token` argument in `preprocessing.text.Tokenizer`.

## Breaking changes

- In `preprocessing.image.ImageDataGenerator`, `shear_range` has been switched to use degrees rather than radians (for consistency). This should not actually break anything (neither training nor inference), but keep this change in mind in case you see any issues with regard to your image data augmentation process.


## Credits

Thanks to our 45 contributors whose commits are featured in this release:

@Dref360, @OliPhilip, @TimZaman, @bbabenko, @bdwyer2, @berkatmaca, @caisq, @decrispell, @dmaniry, @fchollet, @fgaim, @gabrieldemarmiesse, @gklambauer, @hgaiser, @hlnull, @icyblade, @jgrnt, @kashif, @kouml, @lutzroeder, @m-mohsen, @mab4058, @manashty, @masstomato, @mihirparadkar, @myutwo150, @nickbabcock, @novotnj3, @obsproth, @ozabluda, @philferriere, @piperchester, @pstjohn, @roatienza, @souptc, @spiros, @srs70187, @sumitgouthaman, @taehoonlee, @tigerneil, @titu1994, @tobycheese, @vitaly-krumins, @yang-zhang, @ziky90",33015583
112,False,False,2017-12-01T18:12:33Z,2017-12-01T18:28:02Z,"## Areas of improvement

- Bug fixes and performance improvements.
- API improvements in Keras applications, generator methods.

## API changes

- Make `preprocess_input` in all Keras applications compatible with both Numpy arrays and symbolic tensors (previously only supported Numpy arrays).
- Allow the `weights` argument in all Keras applications to accept the path to a custom weights file to load (previously only supported the built-in `imagenet` weights file).
- `steps_per_epoch` behavior change in generator training/evaluation methods:
    - If specified, the specified value will be used (previously, in the case of generator of type `Sequence`, the specified value was overridden by the `Sequence` length)
    - If unspecified and if the generator passed is a `Sequence`, we set it to the `Sequence` length.
- Allow `workers=0` in generator training/evaluation methods (will run the generator in the main process, in a blocking way).
- Add `interpolation` argument in `ImageDataGenerator.flow_from_directory`, allowing a custom interpolation method for image resizing.
- Allow `gpus` argument in `multi_gpu_model` to be a list of specific GPU ids.

## Breaking changes

- The change in `steps_per_epoch` behavior (described above) may affect some users.

## Credits

Thanks to our 26 contributors whose commits are featured in this release:

@Alex1729, @alsrgv, @apisarek, @asos-saul, @athundt, @cherryunix, @dansbecker, @datumbox, @de-vri-es, @drauh, @evhub, @fchollet, @heath730, @hgaiser, @icyblade, @jjallaire, @knaveofdiamonds, @lance6716, @luoch, @mjacquem1, @myutwo150, @ozabluda, @raviksharma, @rh314, @yang-zhang, @zach-nervana
",33015583
113,False,False,2017-11-14T21:40:18Z,2017-11-14T21:41:22Z,This release amends release 2.1.0 to include a fix for an erroneous breaking change introduced in #8419.,33015583
114,False,False,2017-11-13T19:52:31Z,2017-11-13T20:46:20Z,"This is a small release that fixes outstanding bugs that were reported since the previous release.

## Areas of improvement

- Bug fixes (in particular, Keras no longer allocates devices at startup time with the TensorFlow backend. This was causing issues with Horovod.)
- Documentation and docstring improvements.
- Better CIFAR10 ResNet example script and improvements to example scripts code style.

## API changes

- Add `go_backwards` to cuDNN RNNs (enables `Bidirectional` wrapper on cuDNN RNNs).
- Add ability to pass `fetches` to `K.Function()` with the TensorFlow backend.
- Add `steps_per_epoch` and `validation_steps` arguments in `Sequential.fit()` (to sync it with `Model.fit()`).

## Breaking changes

None.

## Credits

Thanks to our 14 contributors whose commits are featured in this release:

@Dref360, @LawnboyMax, @anj-s, @bzamecnik, @datumbox, @diogoff, @farizrahman4u, @fchollet, @frexvahi, @jjallaire, @nsuh, @ozabluda, @roatienza, @yakigac

",33015583
115,False,False,2017-11-01T20:03:25Z,2017-11-01T21:01:43Z,"## Areas of improvement

- RNN improvements:
    - Refactor RNN layers to rely on atomic RNN cells. This makes the creation of custom RNN very simple and user-friendly, via the `RNN` base class.
    - Add ability to create new RNN cells by stacking a list of cells, allowing for efficient stacked RNNs.
   - Add `CuDNNLSTM` and `CuDNNGRU` layers, backend by NVIDIA's cuDNN library for fast GPU training & inference.
   - Add RNN Sequence-to-sequence example script.
   - Add `constants` argument in `RNN`'s `call` method, making RNN attention easier to implement.
- Easier multi-GPU data parallelism via `keras.utils.multi_gpu_model`.
- Bug fixes & performance improvements (in particular, native support for NCHW data layout in TensorFlow).
- Documentation improvements and examples improvements.



## API changes

- Add ""fashion mnist"" dataset as `keras.datasets.fashion_mnist.load_data()`
- Add `Minimum` merge layer as `keras.layers.Minimum` (class) and `keras.layers.minimum(inputs)` (function)
- Add `InceptionResNetV2` to `keras.applications`.
- Support `bool` variables in TensorFlow backend.
- Add `dilation` to `SeparableConv2D`.
- Add support for dynamic `noise_shape` in `Dropout`
- Add `keras.layers.RNN()` base class for batch-level RNNs (used to implement custom RNN layers from a cell class).
- Add `keras.layers.StackedRNNCells()` layer wrapper, used to stack a list of RNN cells into a single cell.
- Add `CuDNNLSTM` and `CuDNNGRU` layers.
- Deprecate `implementation=0` for RNN layers.
- The Keras progbar now reports time taken for each past epoch, and average time per step.
- Add option to specific resampling method in `keras.preprocessing.image.load_img()`.
- Add `keras.utils.multi_gpu_model` for easy multi-GPU data parallelism.
- Add `constants` argument in `RNN`'s `call` method, used to pass a list of constant tensors to the underlying RNN cell.

## Breaking changes

- Implementation change in `keras.losses.cosine_proximity` results in a different (correct) scaling behavior.
- Implementation change for samplewise normalization in `ImageDataGenerator` results in a different normalization behavior.

## Credits

Thanks to our 59 contributors whose commits are featured in this release!

@Alok, @Danielhiversen, @Dref360, @HelgeS, @JakeBecker, @MPiecuch, @MartinXPN, @RitwikGupta, @TimZaman, @adammenges, @aeftimia, @ahojnnes, @akshaychawla, @alanyee, @aldenks, @andhus, @apbard, @aronj, @bangbangbear, @bchu, @bdwyer2, @bzamecnik, @cclauss, @colllin, @datumbox, @deltheil, @dhaval067, @durana, @ericwu09, @facaiy, @farizrahman4u, @fchollet, @flomlo, @fran6co, @grzesir, @hgaiser, @icyblade, @jsaporta, @julienr, @jussihuotari, @kashif, @lucashu1, @mangerlahn, @myutwo150, @nicolewhite, @noahstier, @nzw0301, @olalonde, @ozabluda, @patrikerdes, @podhrmic, @qin, @raelg, @roatienza, @shadiakiki1986, @smgt, @souptc, @taehoonlee, @y0z
",33015583
116,False,False,2017-08-25T19:01:46Z,2017-08-25T19:21:07Z,"The primary purpose of this release is to address an incompatibility between Keras 2.0.7 and the next version of TensorFlow (1.4). TensorFlow 1.4 isn't due until a while, but the sooner the PyPI release has the fix, the fewer people will be affected when upgrading to the next TensorFlow version when it gets released.

No API changes for this release. A few bug fixes.",33015583
117,False,False,2017-08-21T22:13:50Z,2017-08-21T23:31:42Z,"## Areas of improvement

- Bug fixes.
- Performance improvements.
- Documentation improvements.
- Better support for training models from data tensors in TensorFlow (e.g. Datasets, TFRecords). Add a related example script.
- Improve TensorBoard UX with better grouping of ops into name scopes.
- Improve test coverage.

## API changes

- Add `clone_model` method, enabling to construct a new model, given an existing model to use as a template. Works even in a TensorFlow graph different from that of the original model.
-  Add `target_tensors` argument in `compile`, enabling to use custom tensors or placeholders as model targets.
- Add `steps_per_epoch` argument in `fit`, enabling to train a model from data tensors in a way that is consistent with training from Numpy arrays.
- Similarly, add `steps` argument in `predict` and `evaluate`.
- Add `Subtract` merge layer, and associated layer function `subtract`.
- Add `weighted_metrics` argument in `compile` to specify metric functions meant to take into account `sample_weight` or `class_weight`.
- Make the `stop_gradients` backend function consistent across backends.
- Allow dynamic shapes in `repeat_elements` backend function.
- Enable stateful RNNs with CNTK.

## Breaking changes

- The backend methods `categorical_crossentropy`, `sparse_categorical_crossentropy`, `binary_crossentropy` had the order of their positional arguments (`y_true`, `y_pred`) inverted. This change does not affect the `losses` API. This change was done to achieve API consistency between the `losses` API and the backend API.
- Move constraint management to be based on variable attributes. Remove the now-unused `constraints` attribute on layers and models (not expected to affect any user).

## Credits

Thanks to our 47 contributors whose commits are featured in this release!

@5ke, @Alok, @Danielhiversen, @Dref360, @NeilRon, @abnera, @acburigo, @airalcorn2, @angeloskath, @athundt, @brettkoonce, @cclauss, @denfromufa, @enkait, @erg, @ericwu09, @farizrahman4u, @fchollet, @georgwiese, @ghisvail, @gokceneraslan, @hgaiser, @inexxt, @joeyearsley, @jorgecarleitao, @kennyjacob, @keunwoochoi, @krizp, @lukedeo, @milani, @n17r4m, @nicolewhite, @nigeljyng, @nyghtowl, @nzw0301, @rapatel0, @souptc, @srinivasreddy, @staticfloat, @taehoonlee, @td2014, @titu1994, @tleeuwenburg, @udibr, @waleedka, @wassname, @yashk2810
",33015583
118,False,False,2017-07-07T20:48:29Z,2017-07-07T20:59:28Z,"## Areas of improvement

- Improve generator methods (`predict_generator`, `fit_generator`, `evaluate_generator`) and add data enqueuing utilities.
- Bug fixes and performance improvements.
- New features: new `Conv3DTranspose` layer, new `MobileNet` application, self-normalizing networks.

## API changes

- Self-normalizing networks: add `selu` activation function, `AlphaDropout` layer, `lecun_normal` initializer.
- Data enqueuing: add `Sequence`, `SequenceEnqueuer`, `GeneratorEnqueuer` to `utils`.
- Generator methods: rename arguments `pickle_safe` (replaced with `use_multiprocessing`) and `max_q_size ` (replaced with `max_queue_size`).
- Add `MobileNet` to the applications module.
- Add `Conv3DTranspose` layer.
- Allow custom print functions for model's `summary` method (argument `print_fn`).
",33015583
119,False,False,2017-06-12T18:46:21Z,2017-06-12T18:52:05Z,"- Add beta CNTK backend.
- TensorBoard improvements.
- Documentation improvements.
- Bug fixes and performance improvements.
- Improve style transfer example script.

## API changes:

- Add `return_state` constructor argument to RNNs.
- Add `skip_compile` option to `load_model`.
- Add `categorical_hinge` loss function.
- Add `sparse_top_k_categorical_accuracy` metric.
- Add new options to `TensorBoard` callback.
- Add `TerminateOnNaN` callback.
- Generalize the `Embedding` layer to N (>=2) input dimensions.
",33015583
120,False,False,2017-03-14T15:34:11Z,2017-05-05T03:11:30Z,"# Keras 2 release notes

This document details changes, in particular API changes, occurring from Keras 1 to Keras 2.

## Training

- The `nb_epoch` argument has been renamed `epochs` everywhere.
- The methods `fit_generator`, `evaluate_generator` and `predict_generator` now work by drawing a number of *batches* from a generator (number of training steps), rather than a number of samples.
    - `samples_per_epoch` was renamed `steps_per_epoch` in `fit_generator`.
    - `nb_val_samples` was renamed `validation_steps` in `fit_generator`.
    - `val_samples` was renamed `steps` in `evaluate_generator` and `predict_generator`.
- It is now possible to manually add a loss to a model by calling `model.add_loss(loss_tensor)`. The loss is added to the other losses of the model and minimized during training.
- It is also possible to *not* apply any loss to a specific model output. If you pass `None` as the `loss` argument for an output (e.g. in compile, `loss={'output_1': None, 'output_2': 'mse'}`, the model will expect no Numpy arrays to be fed for this output when using `fit`, `train_on_batch`, or `fit_generator`. The output values are still returned as usual when using `predict`.
- In TensorFlow, models can now be trained using `fit` if some of their inputs (or even all) are TensorFlow queues or variables, rather than placeholders. See [this test](https://github.com/fchollet/keras/blob/master/tests/keras/engine/test_training.py#L252) for specific examples.


## Losses & metrics

- The `objectives` module has been renamed `losses`.
- Several legacy metric functions have been removed, namely `matthews_correlation`, `precision`, `recall`, `fbeta_score`, `fmeasure`.
- Custom metric functions can no longer return a dict, they must return a single tensor.


## Models

- Constructor arguments for `Model` have been renamed:
    - `input` -> `inputs`
    - `output` -> `outputs`
- The `Sequential` model not longer supports the `set_input` method.
- For any model saved with Keras 2.0 or higher, weights trained with backend X will be converted to work with backend Y without any manual conversion step.


## Layers

### Removals

Deprecated layers `MaxoutDense`, `Highway` and `TimedistributedDense` have been removed.


### Call method

- All layers that use the learning phase now support a `training` argument in `call` (Python boolean or symbolic tensor), allowing to specify the learning phase on a layer-by-layer basis. E.g. by calling a `Dropout` instance as `dropout(inputs, training=True)` you obtain a layer that will always apply dropout, regardless of the current global learning phase. The `training` argument defaults to the global Keras learning phase everywhere.
- The `call` method of layers can now take arbitrary keyword arguments, e.g. you can define a custom layer with a call signature like `call(inputs, alpha=0.5)`, and then pass a `alpha` keyword argument when calling the layer (only with the functional API, naturally).
- `__call__` now makes use of TensorFlow `name_scope`, so that your TensorFlow graphs will look pretty and well-structured in TensorBoard.

### All layers taking a legacy `dim_ordering` argument

`dim_ordering` has been renamed `data_format`. It now takes two values: `""channels_first""` (formerly `""th""`) and `""channels_last""` (formerly `""tf""`).

### Dense layer

Changed interface:

- `output_dim` -> `units`
- `init` -> `kernel_initializer`
- added `bias_initializer` argument
- `W_regularizer` -> `kernel_regularizer`
- `b_regularizer` -> `bias_regularizer`
- `b_constraint` -> `bias_constraint`
- `bias` -> `use_bias`

### Dropout, SpatialDropout*D, GaussianDropout

Changed interface:

- `p` -> `rate`

### Embedding

### Convolutional layers

- The `AtrousConvolution1D` and `AtrousConvolution2D` layer have been deprecated. Their functionality is instead supported via the `dilation_rate` argument in `Convolution1D` and `Convolution2D` layers.
- `Convolution*` layers are renamed `Conv*`.
- The `Deconvolution2D` layer is renamed `Conv2DTranspose`.
- The `Conv2DTranspose` layer no longer requires an `output_shape` argument, making its use much easier.

Interface changes common to all convolutional layers:

- `nb_filter` -> `filters`
- float kernel dimension arguments become a single tuple argument, `kernel` size. E.g. a legacy call `Conv2D(10, 3, 3)` becomes `Conv2D(10, (3, 3))`
- `kernel_size` can be set to an integer instead of a tuple, e.g. `Conv2D(10, 3)` is equivalent to `Conv2D(10, (3, 3))`.
- `subsample` -> `strides`. Can also be set to an integer.
- `border_mode` -> `padding`
- `init` -> `kernel_initializer`
- added `bias_initializer` argument
- `W_regularizer` -> `kernel_regularizer`
- `b_regularizer` -> `bias_regularizer`
- `b_constraint` -> `bias_constraint`
- `bias` -> `use_bias`
- `dim_ordering` -> `data_format`
- In the `SeparableConv2D` layers, `init` is split into `depthwise_initializer` and `pointwise_initializer`.
- Added `dilation_rate` argument in `Conv2D` and `Conv1D`.
- 1D convolution kernels are now saved as a 3D tensor (instead of 4D as before).
- 2D and 3D convolution kernels are now saved in format `spatial_dims + (input_depth, depth))`, even with `data_format=""channels_first""`.


### Pooling1D

- `pool_length` -> `pool_size`
- `stride` -> `strides`
- `border_mode` -> `padding`

### Pooling2D, 3D

- `border_mode` -> `padding`
- `dim_ordering` -> `data_format`


### ZeroPadding layers

The `padding` argument of the `ZeroPadding2D` and `ZeroPadding3D` layers must be a tuple of length 2 and 3 respectively. Each entry `i` contains by how much to pad the spatial dimension `i`. If it's an integer, symmetric padding is applied. If it's a tuple of integers, asymmetric padding is applied.

### Upsampling1D

- `length` -> `size`

### BatchNormalization

The `mode` argument of `BatchNormalization` has been removed; BatchNorm now only supports mode 0 (use batch metrics for feature-wise normalization during training, and use moving metrics for feature-wise normalization during testing).

- `beta_init` -> `beta_initializer`
- `gamma_init` -> `gamma_initializer`
- added arguments `center`, `scale` (booleans, whether to use a `beta` and `gamma` respectively)
- added arguments `moving_mean_initializer`, `moving_variance_initializer`
- added arguments `beta_regularizer`, `gamma_regularizer`
- added arguments `beta_constraint`, `gamma_constraint`
- attribute `running_mean` is renamed `moving_mean`
- attribute `running_std` is renamed `moving_variance` (it *is* in fact a variance with the current implementation).


### ConvLSTM2D

Same changes as for convolutional layers and recurrent layers apply.

### PReLU

- `init` -> `alpha_initializer`

### GaussianNoise

- `sigma` -> `stddev`

### Recurrent layers

- `output_dim` -> `units`
- `init` -> `kernel_initializer`
- `inner_init` -> `recurrent_initializer`
- added argument `bias_initializer`
- `W_regularizer` -> `kernel_regularizer`
- `b_regularizer` -> `bias_regularizer`
- added arguments `kernel_constraint`, `recurrent_constraint`, `bias_constraint`
- `dropout_W` -> `dropout`
- `dropout_U` -> `recurrent_dropout`
- `consume_less` -> `implementation`. String values have been replaced with integers: implementation 0 (default), 1 or 2.
- LSTM only: the argument `forget_bias_init` has been removed. Instead there is a boolean argument `unit_forget_bias`, defaulting to `True`.


### Lambda

The `Lambda` layer now supports a `mask` argument.


## Utilities

Utilities should now be imported from `keras.utils` rather than from specific submodules (e.g. no more `keras.utils.np_utils...`).


## Backend

### random_normal and truncated_normal
- `std` -> `stddev`

## Misc

- In the backend, `set_image_ordering` and `image_ordering` are now `set_data_format` and `data_format`.
- Any arguments (other than `nb_epoch`) prefixed with `nb_` has been renamed to be prefixed with `num_` instead. This affects two datasets and one preprocessing utility.",33015583
121,False,False,2017-04-29T23:18:54Z,2017-04-29T23:19:34Z,"- Documentation improvements.
- Docstring improvements.
- Update some examples scripts (in particular, new deep dream example).
- Bug fixes and performance improvements.

## API changes:

- Add `logsumexp` and `identity` to backend.
- Add `logcosh` loss.
- New signature for `add_weight` in `Layer`.
- `get_initial_states` in `Recurrent` is now `get_initial_state`.
",33015583
122,False,False,2020-03-12T10:30:41Z,2020-03-12T13:40:56Z,"## ✨ New features and improvements

* **NEW:** Add `Span.char_span` method.
* **NEW:** Base language support for [Yoruba](spacy/lang/yo) and [Basque](spacy/lang/eu).
* **NEW:** Add `--tag-map-path` argument to `debug-data` and `train` commands.
* **NEW** Add `add_lemma` option to `displacy` dependency visualizer.
* Add `IDX` as an attribute available via `Doc.to_array`.
* Improve speed of adding large number of patterns to `EntityRuler`.
* Replace `python-mecab3` with [`fugashi`](https://github.com/polm/fugashi) for Japanese.
* Improve language data for [Norwegian](spacy/lang/nb), [Luxembourgish](spacy/lang/lb), [Finnish](spacy/lang/fi), [Slovak](spacy/lang/sk), [Romanian](spacy/lang/ro), [Greek](spacy/lang/el) and [German](spacy/lang/de).

## 🔴 Bug fixes

* Fix issue #3979, #4819, #4871: Add `tok2vec` parameters to `train` command.
* Fix issue #4009: Fix use of pretrained vectors in text classifier.
* Fix issue #4342: Improve CLI training with base model.
* Fix issue #4432: Add destructors for states in `TransitionSystem`.
* Fix issue #4440: Require `HEAD` for `is_parsed` in `Doc.from_array`. 
* Fix issue #4615: Update `SHAPE` docs and examples.
* Fix issue #4665: Allow `HEAD` field in CoNLL-U format to be an underscore.
* Fix issue #4673: Ensure correct array module is used when returning a vector via `Vocab`.
* Fix issue #4674: Make `set_entities` in the `KnowledgeBase` more robust.
* Fix issue #4677: Add missing tags to tag maps for `el`, `es` and `pt`.
* Fix issue #4688: Iterate over `lr_edges` until `Doc.sents` are correct.
* Fix issue #4703, #4823: Facilitate large training files.
* Fix issue #4707: Auto-exclude `disabled` when calling `from_disk` during load.
* Fix issue #4717: Fix int value handling in `Matcher`.
* Fix issue #4719: Add message when cli train script throws exception.
* Fix issue #4723: Update `EntityLinker` example.
* Fix issue #4725: Take care of global vectors in multiprocessing.
* Fix issue #4770: Include `Doc.cats` in serialization of `Doc` and `DocBin`.
* Fix issue #4772: Fix bug in `EntityLinker.predict`.
* Fix issue #4777: Fix link to user hooks in documentation.
* Fix issue #4829: Update build dependencies in `pyproject.toml`.
* Fix issue #4830: Warn for punctuation in entities when training with noise.
* Fix issue #4833: Make example scripts work with transformer starter models.
* Fix issue #4849: Fix serialization of `ENT_ID`.
* Fix issue #4862: Fix and improve URL pattern.
* Fix issue #4868: Include `.pyx` and `.pxd` files in the distribution.
* Fix issue #4876: Add friendlier error to entity linking example script.
* Fix issue #4903: Fix handling of custom underscore attributes during multiprocessing.
* Fix issue #4924: Fix handling of empty docs or golds in `Language.evaluate`.
* Fix issue #4934: Prevent updating component config if the `Model` was already defined.
* Fix issue #4935: Fix `Sentencizer.pipe` for empty `Doc`.
* Fix issue #4961: Remove old docs section links.
* Fix issue #4965: Sync `Span.__eq__` and `Span.__hash__`.
* Fix issue #4975: Adjust `srsly` pin.
* Fix issue #5048: Fix behavior of `get_doc` test utility.
* Fix issue #5073: Normalize `IS_SENT_START` to `SENT_START` for `Matcher`. 
* Fix issue #5075: Make it impossible to create invalid heads with `Doc.from_array`.
* Fix issue #5082: Correctly set vector of merged span in `merge_entities`.
* Fix issue #5115: Ensure paths in `Tokenizer.to_disk` and `Tokenizer.from_disk`.
* Fix issue #5117: Clarify behavior of `Doc.is_` flags for empty `Doc`s.

## 📖 Documentation and examples

* Fix various typos and inconsistencies.
* Add new projects to the [spaCy Universe](https://spacy.io/universe).

## 👥 Contributors

Thanks to @polm, @mmaybeno, @jarib, @questoph, @aajanki, @mr-bjerre, @Tclack88, @thiagola92, @tamuhey, @Olamyy, @AlJohri, @iechevarria, @iurshina, @lineality, @pbadeer, @BramVanroy, @kabirkhan, @ceteri, @omri374, @maknotavailable, @onlyanegg,  @drndos, @ju-sh, @nlptechbook, @chkoar, @Jan-711, @MisterKeefe, @bryant1410, @mirfan899, @dhpollack and @mabraham for the pull requests and contributions!",21467110
123,False,False,2019-11-21T17:19:47Z,2019-11-21T18:21:03Z,"## ✨ New features and improvements

* **NEW:** `Tokenizer.explain` method to see which rule or pattern was matched.
  ```python
  tok_exp = nlp.tokenizer.explain(""(don't)"")
  assert [t[0] for t in tok_exp] == [""PREFIX"", ""SPECIAL-1"", ""SPECIAL-2"", ""SUFFIX""]
  assert [t[1] for t in tok_exp] == [""("", ""do"", ""n't"", "")""]
  ```
* **NEW:** Official Python 3.8 wheels for spaCy and its dependencies.
* Base language support for [Korean](spacy/lang/ko).
* Add `Scorer.las_per_type` (labelled depdencency scores per label).
* Rework [Chinese](spacy/lang/zh) language initialization and tokenization 
* Improve language data for [Luxembourgish](spacy/lang/lb).

## 🔴 Bug fixes

* Fix issue #4573, #4645: Improve tokenizer usage docs.
* Fix issue #4575: Add error in `debug-data` if no dev docs are available.
* Fix issue #4582: Make `as_tuples=True` in `Language.pipe` work with multiprocessing.
* Fix issue #4590: Correctly call `on_match` in `DependencyMatcher`.
* Fix issue #4593: Build wheels for Python 3.8.
* Fix issue #4604: Fix realloc in `Retokenizer.split`.
* Fix issue #4656: Fix `conllu2json` converter when `-n` > 1.
* Fix issue #4662: Fix `Language.evaluate` for components without `.pipe` method.
* Fix issue #4670: Ensure `EntityRuler` is deserialized correctly from disk.
* Fix issue #4680: Raise error if non-string labels are added to `Tagger` or `TextCategorizer`.
* Fix issue #4691: Make `Vectors.find` return keys in correct order.

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @yash1994, @walterhenry, @prilopes, @f11r, @questoph, @erip, @richardpaulhudson and @GuiGel for the pull requests and contributions.",21467110
124,False,False,2019-10-28T15:17:02Z,2019-10-28T16:22:20Z,"> This is a small maintenance update that backports a bug fix for a memory leak that'd occur in long-running parsing processes. It's intended for users who can't or don't yet want to upgrade to spaCy v2.2 (e.g. because it requires retraining all the models). If you're able to upgrade, you shouldn't use this version and instead install the latest v2.2.

## 🔴 Bug fixes

* Fix issue #3618: Fix memory leak for long-running parsing processes.
* Fix issue #4538: Backport memory leak fix to v2.1.x branch.",21467110
125,False,False,2019-10-31T14:53:31Z,2019-10-31T16:34:36Z,"## ✨ New features and improvements

* **NEW:** Support multiprocessing in `nlp.pipe` via the `n_process` argument (Python 3 only).
* Base language support for [Luxembourgish](spacy/lang/lb).
* Add noun chunks iterator for [Swedish](spacy/lang/sv).
* Retrained models for [Greek](https://spacy.io/models/el), [Norwegian Bokmål](https://spacy.io/models/nb) and [Lithuanian](https://spacy.io/models/lt) that now correctly support parser-based sentence segmentation.
* Repackaged models for [Greek](https://spacy.io/models/el) and [German](https://spacy.io/models/de) with improved lookup tables via [`spacy-lookups-data`](https://github.com/explosion/spacy-lookups-data).
* Add warning in `debug-data` for low sentences per doc ratio.
* Improve checks and errors related to ill-formed IOB input in `convert` and `debug-data` CLI.
* Support training dict format as JSONL.
* Make `EntityRuler` ID resolution 2&times; faster and support `""id""` in patterns to set `Token.ent_id`.
* Improve rendering of named entity spans in `displacy` for RTL languages.
* Update [Thinc](https://github.com/explosion/thinc) to ditch `thinc_gpu_ops` for simpler GPU install.
* Support [Mish](https://github.com/digantamisra98/Mish) activation in `spacy pretrain`.
* Add forwards-compatible support for new `Language.disable_pipes` API, which will become
the default in the future. The method can now also take a list of component names as its first argument (instead of a variable number of arguments).
  ```diff
  - disabled = nlp.disable_pipes(""tagger"", ""parser"")
  + disabled = nlp.disable_pipes([""tagger"", ""parser""])
  ```
* Add forwards-compatible support for new `Matcher.add` and `PhraseMatcher.add` API, which will become the default in the future. The patterns are now the second argument and a list (instead of a variable number of arguments). The `on_match` callback becomes an optional keyword argument.
  ```diff
  patterns = [[{""TEXT"": ""Google""}, {""TEXT"": ""Now""}], [{""TEXT"": ""GoogleNow""}]]
  - matcher.add(""GoogleNow"", None, *patterns)
  + matcher.add(""GoogleNow"", patterns)
  - matcher.add(""GoogleNow"", on_match, *patterns)
  + matcher.add(""GoogleNow"", patterns, on_match=on_match)
  ```
* Add new and improved tokenization alignment in `gold.align` behind a feature flag. The new alignment may produce backwards-incompatible results, so it won't be enabled by default before v3.0.
  ```python
  import spacy.gold
  spacy.gold.USE_NEW_ALIGN = True
  ```

## 🔴 Bug fixes

* Fix issue #1303: Support multiprocessing in `nlp.pipe`.
* Fix issue #1745: Ditch `thinc_gpu_ops` for simpler GPU install.
* Fix issue #2411: Update Thinc to fix compilation on cygwin.
* Fix issue #3412: Prevent division by zero in `Vectors.most_similar`.
* Fix issue #3618: Fix memory leak for long-running parsing processes.
* Fix issue #4241: Update Greek lookups in `spacy-lookups-data`.
* Fix issue #4269: Extend unicode character block for Sinhala.
* Fix issue #4362: Improve `URL_PATTERN` and handling in tokenizer.
* Fix issue #4373: Make `PhraseMatcher.vocab` consistent with `Matcher.vocab`.
* Fix issue #4377: Clarify serialization of extension attributes.
* Fix issue #4382: Improve usage of `pkg_resources` and handling of entry points.
* Fix issue #4386: Consider `batch_size` when sorting similar vectors.
* Fix issue #4389: Fix `ner_jsonl2json` converter.  
* Fix issue #4397: Ensure `on_match` callback is executed in `PhraseMatcher`.
* Fix issue #4401, #4408: Fix sentence segmentation in Greek, Norwegian and Lithuanian models.
* Fix issue #4402: Fix issue with how training data was passed through the pipeline.
* Fix issue #4406: Correct spelling in lemmatizer API docs.
* Fix issue #4418, #4438: Improve knowledge base and Wikidata parsing.
* Fix issue #4435: Fix `PhraseMatcher.remove` for overlapping patterns.
* Fix issue #4443: Fix bug in `Vectors.most_similar`.
* Fix issue #4452: Fix `gold.docs_to_json` documentation.
* Fix issue #4463: Add missing `cats` to `GoldParse.from_annot_tuples` in `Scorer`.
* Fix issue #4470: Suppress convert output if writing to `stdout`.
* Fix issue #4475: Correct mistake in docs example.
* Fix issue #4485: Update tag maps and docs for English and German.
* Fix issue #4493: Update information in spaCy Universe.
* Fix issue #4496: Improve docs of `PhraseMatcher.add` arguments.
* Fix issue #4506: Ensure `Vectors.most_similar` returns `1.0` for identical vectors.
* Fix issue #4509: Fix `None` iteration error in entity linking script.
* Fix issue #4524: Fix typo in `Parser` sample construction of `GoldParse`.
* Fix issue #4528: Fix serialization of extension attribute values in `DocBin`.
* Fix issue #4529: Ensure `GoldParse` is initialized correctly with misaligned tokens.
* Fix issue #4538: Backport memory leak fix to v2.1.x branch and release [v2.1.9](https://github.com/explosion/spaCy/releases/tag/v2.1.9). 

## ⚠️ Backwards incompatibilities

* The unused attributes `lemma_rules`, `lemma_index`, `lemma_exc` and `lemma_lookup` of the `Language.Defaults` have now been removed to prevent confusion (e.g. if users add rules that then have no effect). The only place lemmatization tables are stored and can be modified at runtime is via `nlp.vocab.lookups`.
  ```diff
  - nlp.Defaults.lemma_lookup[""spaCies""] = ""spaCy""
  + lemma_lookup = nlp.vocab.lookups.get_table(""lemma_lookup"")
  + lemma_lookup[""spaCies""] = ""spaCy""
  ```

## 📖 Documentation and examples

* Fix various typos and inconsistencies.
* Add more projects to the [spaCy Universe](https://spacy.io/universe).

## 👥 Contributors

Thanks to @tamuhey, @PeterGilles, @akornilo, @danielkingai2, @ghollah, @pberba, @gustavengstrom, @ju-sh, @kabirkhan, @ZhuoruLin, @nipunsadvilkar and @neelkamath for the pull requests and contributions.",21467110
126,False,False,2019-10-03T12:50:39Z,2019-10-03T14:22:47Z,"## ✨ New features and improvements

* Make `Vectors.most_similar` return the top most similar vectors instead of only one.

## 🔴 Bug fixes

* Fix issue #4365: Fix tag map in Dutch model.
* Fix issue #4368: Fix initialization of `DocBin` with attributes.

## 📖 Documentation and examples

* Add API docs for [`Vectors.most_similar`](https://spacy.io/api/vectors#most_similar).

## 👥 Contributors

Thanks to @bintay and @svlandeg for the pull requests and contributuons.",21467110
127,False,False,2019-10-02T12:40:06Z,2019-10-02T14:47:34Z,"> ⚠️ This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions. If you've been training **your own models**, you'll need to **retrain them** with the new version.

## ✨ New features and improvements

* **NEW:** Pretrained **core models** for [Norwegian](https://spacy.io/models/no) (MIT) and [Lithuanian](https://spacy.io/models/lt) (CC BY-SA).
* **NEW:** Better pre-trained [Dutch](https://spacy.io/models/nl) NER using custom labelled UD corpus instead of WikiNER.
* **NEW:** Make spaCy roughly **5-10&times; smaller on disk** (depending on your platform) by compressing and moving lookups to a [separate package](https://github.com/explosion/spacy-lookups-data).
* **NEW:** `EntityLinker` and `KnowledgeBase` API to train and access entity linking models, plus scripts to train your own Wikidata models.
* **NEW:** 10&times; faster `PhraseMatcher` and improved phrase matching algorithm.
* **NEW:** `DocBin` class to efficiently serialize collections of `Doc` objects.
* **NEW:** Train text classification models on the command line with `spacy train` and get `textcat` results via the `Scorer`.
* **NEW:** [`debug-data`](https://spacy.io/api/cli#debug-data) command to validate your training and development data, get useful stats, and find problems like invalid entity annotations, cyclic dependencies, low data labels and more.
* **NEW:** Efficient `Lookups` class using Bloom filters that allows storing, accessing and serializing large dictionaries via `vocab.lookups`.
* Data augmentation in `spacy train` via the `--orth-variant-level` flag, which defines the percentage of occurrences of some tokens subject to replacement during training.
* Add `nlp.pipe_labels` (labels assigned by pipeline components) and include `""labels""` in `nlp.meta`.
* Support `spacy_displacy_colors` entry point to allow packages to add entity colors to `displacy`.
* Allow `template` config option in `displacy` to customize entity HTML template.
* Improve match pattern validation and handling of unsupported attributes.
* Add lookup lemmatization data for [Croatian](spacy/lang/hr) and [Serbian](spacy/lang/sr).
* Update and improve language data for [Chinese](spacy/lang/zh), [Croatian](spacy/lang/hr), [Thai](spacy/lang/th), [Romanian](spacy/lang/ro), [Hindi](spacy/lang/hi) and [English](spacy/lang/en).

## 🔴 Bug fixes

* Fix issue #3258: Reduce package size on disk by moving and compressing large dictionaries.
* Fix issue #3540: Update lemma and vector information after splitting a token.
* Fix issue #3687: Automatically skip duplicates in `Doc.retokenize`.
* Fix issue #3830: Retrain German model and fix `subtok` errors.
* Fix issue #3850: Allow customizing entity HTML template in displaCy.
* Fix issue #3879, #3951, #4154: Fix bug in `Matcher` retry loop that'd cause problems with `?` operator.
* Fix issue #3917: Raise error for negative token indices in `displacy`.
* Fix issue #3922: Add `PhraseMatcher.remove` method.
* Fix issue #3959, #4133: Make sure both `pos` and `tag` are correctly serialized.
* Fix issue #3972: Ensure `PhraseMatcher` returns multiple matches for identical rules.
* Fix issue #4020: Raise error for overlapping entities in `biluo_tags_from_offsets`.
* Fix issue #4051: Ensure retokenizer sets POS tags correctly on merge.
* Fix issue #4070: Improve token pattern checking without validation.
* Fix issue #4096: Add checks for cycles in `debug-data`.
* Fix issue #4100: Improve docs on phrase pattern attributes.
* Fix issue #4102: Correct mistakes in English lookup lemmatizer data.
* Fix issue #4104: Make visualized NER examples in docs more clear.
* Fix issue #4107: Automatically set span root attributes on merging.
* Fix issue #4111, #4170: Improve NER/IOB converters.
* Fix issue #4120: Correctly handle `?` operator at the end of pattern.
* Fix issue #4123: Provide more details in cycle error message `E069`.
* Fix issue #4138: Correctly open `.html` files as UTF-8 in `evaluate` command.
* Fix issue #4139: Make emoticon data a raw string.
* Fix issue #4148: Add missing API docs for `force` flag on `set_extension`.
* Fix issue #4155: Correct language code for Serbian.
* Fix issue #4165: Add more attributes to matcher validation schema.
* Fix issue #4190: Fix caching issue that'd cause tokenizer to not be deserialized correctly.
* Fix issue #4200: Work around `tqdm` bug that'd remove text color from terminal output.
* Fix issue #4229: Fix handling of pre-set entities.
* Fix issue #4238: Flush tokenizer cache when affixes, token_match, or special cases are modified.
* Fix issue #4242: Make `.pos`/`.tag` distinction more clear in the docs.
* Fix issue #4245: Fix bug that occurred when processing empty string in Korean.
* Fix issue #4262: Fix handling of spaces in Japanese.
* Fix issue #4269: Tokenize punctuation correctly in Kannada, Tamil, and Telugu and add unicode characters to default sentencizer config.
* Fix issue #4270: Fix `--vectors-loc` documentation.
* Fix issue #4302: Remove duplicate `Parser.tok2vec` property.
* Fix issue #4303: Correctly support `as_tuples` and `return_matches` in `Matcher.pipe`.
* Fix issue #4307: Ensure that pre-set entities are preserved and allow overwriting unset tokens.
* Fix issue #4308: Fix bug that could cause `PhraseMatcher` with very large lists to miss matches.   
* Fix issue #4348: Ensure training doesn't crash with empty batches.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* The lemmatization tables have been moved to their own package, [`spacy-lookups-data`](https://github.com/explosion/spacy-lookups-data), which is not installed by default. If you're using pre-trained models, **nothing changes**, because the tables are now included in the model packages. If you want to use the lemmatizer for other languages that don't yet have pre-trained models (e.g. Turkish or Croatian) or start off with a blank model that contains lookup data (e.g. `spacy.blank(""en"")`), you'll need to **explicitly install spaCy plus data** via `pip install spacy[lookups]`. The data will be registered automatically via entry points.
* Lemmatization tables (rules, exceptions, index and lookups) are now part of the `Vocab` and serialized with it. This means that serialized objects (`nlp`, pipeline components, vocab) will now include additional data, and models written to disk will include additional files.
* The `Lemmatizer` class is now initialized with an instance of `Lookups` containing the rules and tables, instead of dicts as separate arguments. This makes it easier to share data tables and modify them at runtime. This is mostly internals, but if you've been implementing a custom `Lemmatizer`, you'll need to update your code.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* The Dutch model has been trained on a new NER corpus (custom labelled UD instead of WikiNER), so their predictions may be very different compared to the previous version. The results should be significantly better and more generalizable, though. 
* The `spacy download` command does **not** set the `--no-deps` pip argument anymore by default, meaning that model package dependencies (if available) will now be also downloaded and installed. If spaCy (which is also a model dependency) is not installed in the current environment, e.g. if a user has built from source, `--no-deps` is added back automatically to prevent spaCy from being downloaded and installed again from pip.
* The built-in `biluo_tags_from_offsets` converter is now stricter and will raise an error if entities are overlapping (instead of silently skipping them). If your data contains invalid entity annotations, make sure to clean it and resolve conflicts. You can now also use the new `debug-data` command to find problems in your data.
* Pipeline components can now overwrite IOB tags of tokens that are not yet part of an entity. Once a token has an `ent_iob` value set, it won't be reset to an ""unset"" state and will always have at least `O` assigned. `list(doc.ents)` now actually keeps the annotations on the token level consistent, instead of resetting `O` to an empty string.
* The default punctuation in the `Sentencizer` has been extended and now includes more characters common in various languages. This also means that the results it produces may change, depending on your text. If you want the previous behaviour with limited characters, set `punct_chars=[""."", ""!"", ""?""]` on initialization. 
* The `PhraseMatcher` algorithm was rewritten from scratch and it's now 10&times; faster. The rewrite also resolved a few subtle bugs with very large terminology lists. So if you were matching large lists, you may see slightly different results – however, the results should now be fully correct. See #4309 for details on this change.
* The `Serbian` language class (introduced in v2.1.8) incorrectly used the language code `rs` instead of `sr`. This has now been fixed, so `Serbian` is now available via `spacy.lang.sr`.
* The `""sources""` in the `meta.json` have changed from a list of strings to a list of dicts. This is mostly internals, but if your code used `nlp.meta[""sources""]`, you might have to update it.

## 📈 Benchmarks

| Model               | Language   | Version |   UAS |   LAS |   POS | NER F | Vec |   Size |
| ------------------- | ---------- | ------: | ----: | ----: | ----: | ----: | :-: | -----: |
| [`en_core_web_sm`]  | English    |   2.2.0 | 91.61 | 89.71 | 97.03 | 85.07 |  𐄂  |  11 MB |
| [`en_core_web_md`]  | English    |   2.2.0 | 91.65 | 89.77 | 97.14 | 86.10 |  ✓  |  91 MB |
| [`en_core_web_lg`]  | English    |   2.2.0 | 91.98 | 90.16 | 97.21 | 86.30 |  ✓  | 789 MB |
| [`de_core_news_sm`] | German     |   2.2.0 | 90.75 | 88.63 | 96.29 | 83.11 |  𐄂  |  14 MB |
| [`de_core_news_md`] | German     |   2.2.0 | 91.26 | 89.36 | 96.44 | 83.42 |  ✓  | 214 MB |
| [`es_core_news_sm`] | Spanish    |   2.2.0 | 90.20 | 87.05 | 96.79 | 89.45 |  𐄂  |  15 MB |
| [`es_core_news_md`] | Spanish    |   2.2.0 | 90.89 | 87.94 | 97.03 | 89.86 |  ✓  |  74 MB |
| [`pt_core_news_sm`] | Portuguese |   2.2.0 | 89.53 | 86.07 | 79.96 | 87.97 |  𐄂  |  20 MB |
| [`fr_core_news_sm`] | French     |   2.2.0 | 87.27 | 84.28 | 94.38 | 82.77 |  𐄂  |  14 MB |
| [`fr_core_news_md`] | French     |   2.2.0 | 88.82 | 86.07 | 95.15 | 82.82 |  ✓  |  84 MB |
| [`it_core_news_sm`] | Italian    |   2.2.0 | 90.79 | 86.94 | 96.06 | 86.29 |  𐄂  |  13 MB |
| [`nl_core_news_sm`] | Dutch      |   2.2.0 | 76.79 | 69.53 | 90.10 | 68.79 |  𐄂  |  14 MB |
| [`el_core_news_sm`] | Greek      |   2.2.0 | 84.40 | 80.98 | 94.41 | 71.88 |  𐄂  |  10 MB |
| [`el_core_news_md`] | Greek      |   2.2.0 | 87.96 | 84.88 | 96.38 | 77.59 |  ✓  | 126 MB |
| [`nb_core_news_sm`] | Norwegian  |   2.2.0 | 89.02 | 86.49 | 95.72 | 83.99 |  𐄂  |  12 MB |
| [`lt_core_news_sm`] | Lithuanian |   2.2.0 | 59.87 | 48.00 | 74.02 | 76.58 |  𐄂  |  12 MB |
| [`xx_ent_wiki_sm`]  | Multi      |   2.2.0 |     - |     - |     - | 79.88 |  𐄂  |   3 MB |

[`en_core_web_sm`]: https://github.com/explosion/spacy-models/releases/tag/en_core_web_sm-2.2.0
[`en_core_web_md`]: https://github.com/explosion/spacy-models/releases/tag/en_core_web_md-2.2.0
[`en_core_web_lg`]: https://github.com/explosion/spacy-models/releases/tag/en_core_web_lg-2.2.0
[`de_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/de_core_news_sm-2.2.0
[`de_core_news_md`]: https://github.com/explosion/spacy-models/releases/tag/de_core_news_md-2.2.0
[`es_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/es_core_news_sm-2.2.0
[`es_core_news_md`]: https://github.com/explosion/spacy-models/releases/tag/es_core_news_md-2.2.0
[`pt_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/pt_core_news_sm-2.2.0
[`fr_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/fr_core_news_sm-2.2.0
[`fr_core_news_md`]: https://github.com/explosion/spacy-models/releases/tag/fr_core_news_md-2.2.0
[`it_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/it_core_news_sm-2.2.0
[`nl_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/nl_core_news_sm-2.2.0
[`el_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/el_core_news_sm-2.2.0
[`el_core_news_md`]: https://github.com/explosion/spacy-models/releases/tag/el_core_news_md-2.2.0
[`nb_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/nb_core_news_sm-2.2.0
[`lt_core_news_sm`]: https://github.com/explosion/spacy-models/releases/tag/lt_core_news_sm-2.2.0
[`xx_ent_wiki_sm`]: https://github.com/explosion/spacy-models/releases/tag/xx_ent_wiki_sm-2.2.0

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Add ""label scheme"" section to all models in the [models directory](https://spacy.io/models) that lists the labels assigned by the different components.
* Extend the `sources` listed in the `meta.json` of pre-trained models with more details on the training corpora and include more information in the [models directory](https://spacy.io/models).
* Add more examples of [matching regular expressions](https://spacy.io/usage/rule-based-matching#regex).
* Add instructions for [training an entity linking model](https://spacy.io/usage/training#entity-linker).
* Add API docs for new [`debug-data`](https://spacy.io/api/cli#debug-data), [`EntityLinker`](https://spacy.io/api/entitylinker), [`KnowledgeBase`](https://spacy.io/api/knowledgebase) and [`Lookups`](https://spacy.io/api/lookups).
* Add new projects to the [spaCy Universe](https://spacy.io/universe).
* Add [example for interactive model visualizer](examples/streamlit_spacy.py) with Streamlit.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @ICLRandD, @phiedulxp, @ajrader, @RyanZHe, @jenojp, @yanaiela, @isaric, @mrdbourke, @avramandrei, @Pavle992, @chkoar, @wannaphongcom, @BreakBB, @b1uec0in, @mihaigliga21, @tamuhey, @euand, @Hazoom, @SeanBE, @esemeniuc, @zqianem, @ajkl, @jaydeepborkar, @EarlGreyT and @er-raoniz for the pull requests and contributions.

Special thanks to our spaCy team @svlandeg and @adrianeboyd for the bug fixes and new features, @polm for the Bloom filters implementation and data compression and @yvespeirsman, @lemontheme, @jarib, @miktoki and @rokasramas for the help and resources for the new models.",21467110
128,False,False,2019-08-07T11:53:58Z,2019-08-08T09:20:39Z,"## ✨ New features and improvements

* **NEW:** Alpha tokenization support for [Serbian](spacy/lang/rs)
* Improve language data for [Urdu](spacy/lang/ur).
* Support installing and loading model packages in the same session.

## 🔴 Bug fixes

* Fix issue #4002: Make `PhraseMatcher` work as expected for `NORM` attribute.
* Fix issue #4063: Improve docs on `Matcher` attributes.
* Fix issue #4068: Make Korean work as expected on Python 2.7.
* Fix issue #4069: Add `validate` option to `EntityRuler`.
* Fix issue #4074: Raise error if annotation dict in simple training style has unexpected keys.
* Fix issue #4081: Fix typo in `pyproject.toml`.
* Fix handling of keyword arguments in `Language.evaluate`.

## 📖 Documentation and examples

* Improve [`Matcher` attribute](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes) docs.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @akornilo, @mirfan899, @veer-bains, @seppeljordan, @Pavle992, @svlandeg, @jenojp and @adrianeboyd for the pull requests and contributions.",21467110
129,False,False,2019-08-01T16:30:50Z,2019-08-01T17:43:04Z,"## ✨ New features and improvements

* Add `Token.tensor` and `Span.tensor` attributes.
* Support simple training format of `(text, annotations)` instead of only `(doc, gold)` for `nlp.evaluate`.
* Add support for `""lang_factory""` setting in model `meta.json` (see #4031).
* Also support `""requirements""` in `meta.json` to define packages for setup's `install_requires`.
* Improve `Pipe` base class methods and make them less presumptuous.
* Improve [Danish](spacy/lang/da) and [Korean](spacy/lang/ko) tokenization.
* Improve error messages when deserializing model fails.

## 🔴 Bug fixes

* Fix issue #3669, #3962: Fix dependency copy in `Span.as_doc` that could cause segfault.
* Fix issue #3968: Fix bug in per-entity scores. 
* Fix issue #4000: Improve entity linking API.
* Fix issue #4022: Fix error when Korean text contains special characters.
* Fix issue #4030: Handle edge case when calling `TextCategorizer.predict` with empty `Doc`. 
* Fix issue #4045: Correct `Span.sent` docs.
* Fix issue #4048: Fix `init-model` command if there's no vocab. 
* Fix issue #4052: Improve per-type scoring of NER.
* Fix issue #4054: Ensure the `lang` of `nlp` and `nlp.vocab` stay consistent.
* Fix bugs in `Token.similarity` and `Span.similarity` when called via hook.

## 📖 Documentation and examples

* Add documentation for [`gold.align` helper](https://spacy.io/api/goldparse#align).
* Add more explicit section on [processing text](https://spacy.io/usage/processing-pipelines#processing).
* Improve documentation on [disabling pipeline components](https://spacy.io/usage/processing-pipelines#disabling).
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @sorenlind, @pmbaumgartner, @svlandeg, @FallakAsad, @BreakBB, @adrianeboyd, @polm, @b1uec0in, @mdaudali and @ejarkm for the pull requests and contributions.",21467110
130,False,False,2019-07-12T15:59:47Z,2019-07-12T16:18:15Z,"## 🔴 Bug fixes

* Fix issue #3958: Fix order of symbols that caused tag maps to be out-of-sync.",21467110
131,False,False,2019-07-12T11:26:12Z,2019-07-12T12:31:09Z,"## ✨ New features and improvements

* **NEW:** Base language data for [Marathi](spacy/lang/mr) and [Korean](spacy/lang/ko) (via [`mecab-ko`](https://bitbucket.org/eunjeon/mecab-ko/src/master/README.md), [`mecab-ko-dic`](https://bitbucket.org/eunjeon/mecab-ko-dic) and [`natto-py`](https://natto-py.readthedocs.io)).
* Improve language data for Lithuanian, Spanish, Kannada, French, Norwegian and Hindi.
* Add evaluation metrics per entity type.
* Add resume logic to `spacy pretrain`.
* Add optional `id` property to EntityRuler patterns.
* Better introspection and IDE automcomplete for custom extension attributes.
* Make `Doc.is_sentenced` always return `True` for single-token docs.

## 🔴 Bug fixes

* Fix issue #3490: Add evaluation metrics per entity type to `Scorer`.
* Fix issue #3526: Serialize `EntityRuler` settings correctly.
* Fix issue #3558: Improve `E024` error message for incorrect `GoldParse`.
* Fix issue #3611: Fix bug when setting `ngram` parameter in text classifier.
* Fix issue #3625: Improve default punctuation rules for Hindi.
* Fix issue #3707: Improve introspection of custom attributes.
* Fix issue #3737: Check if component is callable in `Language.replace_pipe`.
* Fix issue #3743: Fix documentation of `lex_id`.
* Fix issue #3749: Change vector training script to work with latest Gensim.
* Fix issue #3762, #3934: Make `Doc.is_sentenced` default to `True` for single-token `Doc`s.
* Fix issue #3802: Fix typo in docs example.
* Fix issue #3811: Fix type of `--seed` option in `spacy pretrain`.
* Fix issue #3822: Allow passing `PhraseMatcher` arguments to `EntityRuler`.
* Fix issue #3839: Ensure the `Matcher` returns correct match IDs when used with operators.
* Fix issue #3840: Improve error messages in `spacy pretrain`.
* Fix issue #3853: Rename vectors if multiple models are loaded to prevent clashes.
* Fix issue #3859: Update `pretrain` to prevent unintended overwriting of weight files.
* Fix issue #3862: Fix matcher callback example.
* Fix issue #3868: Add `""v.s.""` to English tokenizer exceptions.
* Fix issue #3869: Make `Doc.count_by` work as expected.
* Fix issue #3880: Fix unflatten padding in Thinc when last element is empty.
* Fix issue #3882: Exclude `user_data` when copying doc in displaCy.
* Fix issue #3892: Update `Tokenizer` initialization docs.
* Fix issue #3912: Make text classifier raise more friendly errors.

## 📖 Documentation and examples

* Add documentation for [`Scorer`](https://spacy.io/api/scorer), [`Language.evaluate`](https://spacy.io/api/language#evaluate) and [`gold.docs_to_json`](https://spacy.io/api/goldparse#docs_to_json).
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @BreakBB, @ujwal-narayan, @estr4ng7d, @maknotavailable, @ramananbalakrishnan, @nipunsadvilkar, @NirantK, @munozbravo, @intrafindBreno, @Azagh3l, @jarib, @tokestermw, @polm, @skrcode, @kabirkhan, @demongolem, @elbaulp, @clarus, @BramVanroy, @rokasramas, @askhogan, @khellan, @kognate, @cedar101 and @yash1994 for the pull requests and contributions.",21467110
132,False,False,2019-05-11T20:57:53Z,2019-05-11T22:08:02Z,"## ✨ New features and improvements

* **NEW:** `util.filter_spans` helper to filter duplicates and overlaps from a list of `Span` objects.
* Improve language data for Thai, Japanese, Indonesian and Dutch.
* Add `--n-save-every` to `spacy pretrain` and rename `--nr-iter` to `--n-iter` for consistency.
* Add `--return-scores` flag to `spacy evaluate` to return a dict.
* Add `--n-early-stopping` option to `spacy train` to define maximum number of iterations without dev accuracy improvements.

## 🔴 Bug fixes

* Fix issue #3307: Fix symlink creation to show error on Windows.
* Fix issue #3473: Fix GPU training for text classification.
* Fix issue #3475: Change favicon.
* Fix issue #3482: Add Estonian base support to documentation.
* Fix issue #3484: Ensure lemmatization is always consistent between sessions.
* Fix issue #3521: Add variations of contractions to English stop words.
* Fix issue #3523: Make `spacy convert` correctly default to `json`.
* Fix issue #3525, #3551, #3572: Fix problem that'd cause lemmas to not be lowercase.
* Fix issue #3531: Don't make `""settings""` or `""title""` required in displaCy data.
* Fix issue #3533: Remove non-existent example from docs.
* Fix issue #3546: Make sure path in  `GoldParse.__del__` is a string.
* Fix issue #3549: Ensure match pattern error isn't raised on empty errors list.
* Fix issue #3561: Fix `DependencyParser.predict` docs.
* Fix issue #3598: Allow `jupyter=False` to override Jupyter mode in `displacy`.
* Fix issue #3620: Fix bug in `.iob` converter.
* Fix issue #3628: Relax `jsonschema` pin.
* Fix issue #3667: Fix offset bug in loading pre-trained word2vec.
* Fix issue #3679: Update glossary to include missing labels in `spacy.explain`.
* Fix issue #3680: Re-add missing universe README.
* Fix issue #3681: Rewrite information extraction example to use `Doc.retokenize`.
* Fix issue #3692: Fix return value in `Language.update` docs.
* Fix issue #3694: Make `""text""` in `spacy pretrain` optional when `""tokens""` is provided.
* Fix issue #3701: Improve `Token.prob` and `Lexeme.prob` docs. 
* Fix issue #3708: Fix error in regex matcher examples.
* Fix issue #3713: Call `rmtree` and `copytree` with strings in `spacy train`.
* Fix issue #3720: Add version tag to `--base-model` argument in `spacy train` docs.

## 📖 Documentation and examples

* Add [free interactive spaCy course](https://course.spacy.io).
* Fix various typos and inconsistencies.
* Add new projects to the [spaCy universe](https://spacy.io/universe).

## 👥 Contributors

Thanks to @svlandeg, @wannaphongcom, @Bharat123rox, @DuyguA, @SamuelLKane, @graus, @HiromuHota, @jeannefukumaru, @ivigamberdiev, @socool, @yvespeirsman, @lemontheme, @Dobita21, @w4nderlust, @pierremonico, @bryant1410, @celikomer, @xssChauhan, @kowaalczyk, @BreakBB, @fizban99, @tokestermw, @bjascob, @pickfire, @yaph, @amitness, @henry860916, @d5555, @BramVanroy, @F0rge1cE, @richardpaulhudson, @ldorigo, @aaronkub and @devforfu for the pull requests and contributions.",21467110
133,False,False,2019-03-23T15:47:57Z,2019-03-23T17:07:26Z,"## ✨ New features and improvements

* Allow customizing punctuation characters in sentencizer and make it serializable.
* Add new `""bow""` architecture for `TextCategorizer`, to do faster bag-of-words text classification.

## 🔴 Bug fixes

* Fix issue #3433, #3458: Fix mismatch of classes in parser after serialization.
* Fix issue #3464: Fix training loop in `train_textcat.py` example.
* Fix issue #3468: Make sentencizer set `Token.is_sent_start` correctly.
* Fix bug in the `""ensemble""` `TextClassifier` architecture that prevented the unigram bag-of-words submodel from working properly.

## 👥 Contributors

Thanks to @chkoar for the pull request!",21467110
134,False,False,2019-03-22T12:44:47Z,2019-03-22T13:46:16Z,"## 🔴 Bug fixes

* Fix issue #3356: Fix handling of unicode ranges in regular expressions on Python 2.
* Fix issue #3432: Update `wasabi` to better handle non-UTF-8 terminals.
* Fix issue #3445: Update docs on `label` argument in `Span.__init__`.
* Fix issue #3455: Bring English `tag_map` in line with UD Treebank.

## 📖 Documentation and examples

* Add `--init-tok2vec` argument to [`train_textcat.py`](examples/training/train_textcat.py) example.
* Fix various typos and inconsistencies.",21467110
135,False,False,2019-03-20T11:19:52Z,2019-03-20T12:13:46Z,"## ✨ New features and improvements

* Raise error if user is running a narrow unicode build.
* Move `ud_train`, `ud_evaluate` and other UD scripts from CLI to `/bin` in repo only.
* Improve accuracy of `spacy pretrain` by implementing cosine loss.

## 🔴 Bug fixes

* Fix issue #3421: Update docs and raise error for narrow unicode builds.
* Fix issue #3427: Correct mistake in French lemmatizer.
* Fix issue #3431: Make `Doc.vector` and `Doc.vector_norm` work as expected on GPU.
* Fix issue #3437: Fix installation problem on GPU.
* Fix issue #3439, #3446: Don't include UD scripts in `spacy.cli`.

## 👥 Contributors

Thanks to @mhham and @Bharat123Rox for the pull requests!",21467110
136,False,False,2019-03-17T21:42:58Z,2019-03-18T15:07:15Z,"> ⚠️ This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions. If you've been training **your own models**, you'll need to **retrain them** with the new version.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Add simpler, GPU-friendly option to `TextCategorizer`, and allow setting `exclusive_classes` and `architecture` arguments on initialization.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.
* Add `Vocab.writing_system` (populated via the language data) to expose settings like writing direction.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #795: Fix behaviour of `Token.conjuncts.`
* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Add simpler GPU-friendly option to `TextCategorizer`.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2091: Fix `displacy` support for RTL languages.
* Fix issue #2203, #3268: Prevent bad interaction of lemmatizer and tokenizer exceptions.
* Fix issue #2329: Correct `TextCategorizer` and `GoldParse` API docs.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2390: Support setting lexical attributes during retokenization.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2512, #2153: Fix issue with deserialization into non-empty vocab.
* Fix issue #2603: Improve handling of missing NER tags.
* Fix issue #2644: Add table explaining training metrics to docs.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2728: Fix HTML escaping in `displacy` NER visualization and correct API docs.
* Fix issue #2740: Add ability to pass additional arguments to pipeline components.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2869: Make `doc[0].is_sent_start == True`.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3036: Support mutable default arguments in extension attributes.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix issue #3112: Make sure entity types are added correctly on GPU.
* Fix issue #3191: Fix pickling of `Japanese`.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3274: Make `Token.sent` work as expected without the parser.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix issue #3346: Expose Japanese stop words in language class.
* Fix issue #3357: Update displaCy examples in docs to correctly show `Token.pos_`.
* Fix issue #3345: Fix NER when preset entities cross-sentence boundaries.
* Fix issue #3348: Don't use `numpy` directly for similarity.
* Fix issue #3366: Improve converters, training data formats and docs.
* Fix issue #3369: Fix `#egg` fragments in direct downloads.
* Fix issue #3382: Make `Doc.from_array` consistent with `Doc.to_array`.
* Fix issue #3398: Don't set extension attributes in language classes.
* Fix issue #3373: Merge and improve `conllu` converters.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, v2.1.x currently **doesn't work on Python 2.7 on Windows**. We expect this to be corrected in the future.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
- The deprecated `Doc.merge` and `Span.merge` methods still work, but you may notice that they now run slower when merging many objects in a row. That's because the merging engine was rewritten to be more reliable and to support more efficient merging **in bulk**. To take advantage of this, you should rewrite your logic to use the `Doc.retokenize` context manager and perform as many merges as possible together in the `with` block.
```diff
- doc[1:5].merge()
- doc[6:8].merge()
+ with doc.retokenize() as retokenizer:
+     retokenizer.merge(doc[1:5])
+     retokenizer.merge(doc[6:8])
```
* The serialization methods `to_disk`, `from_disk`, `to_bytes` and `from_bytes` now support a single `exclude` argument to provide a list of string names to exclude. The docs have been updated to list the available serialization fields for each class. The `disable` argument on the `Language` serialization methods has been renamed to `exclude` for consistency.
```diff
- nlp.to_disk(""/path"", disable=[""parser"", ""ner""])
+ nlp.to_disk(""/path"", exclude=[""parser"", ""ner""])
- data = nlp.tokenizer.to_bytes(vocab=False)
+ data = nlp.tokenizer.to_bytes(exclude=[""vocab""])
```
* The `.pos` value for several common English words has changed, due to corrections to long-standing mistakes in the English tag map (see #593, #3311).
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The keyword argument `n_threads` on the `.pipe` methods is now deprecated, as the v2.x models cannot release the global interpreter lock. (Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.)
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `is_sent_start` attribute of the first token in a `Doc` now correctly defaults to `True`. It previously defaulted to `None`.
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0 | 91.5 | 89.7 | 96.8 | 85.9 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0 | 91.8 | 90.0 | 96.9 | 86.6 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0 | 91.8 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0 | 90.7 | 88.6 | 96.3 | 83.1 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0 | 91.2 | 89.4 | 96.6 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0 | 90.4 | 87.3 | 96.9 | 89.5 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0 | 91.0 | 88.2 | 97.2 | 89.7 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0 | 89.1 | 85.9 | 80.4 | 88.9 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0 | 87.6 | 84.7 | 94.5 | 82.6 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0 | 89.1 | 86.4 | 95.3 | 83.1 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0 | 91.0 | 87.3 | 95.8 | 86.1 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0 | 83.7 | 77.6 | 91.6 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0 | 84.4 | 80.6 | 94.6 | 71.6 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0 | 88.3 | 85.0 | 96.6 | 81.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0 | - | - | - | 81.3 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

Although it looks pretty much the same, we've rebuilt the entire documentation using [Gatsby](https://www.gatsbyjs.org/) and [MDX](https://mdxjs.com/). It's now an even faster progressive web app and allows us to write all content entirely **in Markdown**, without having to compromise on easy-to-use custom UI components. We're hoping that the Markdown source will make it even easier to contribute to the documentation. For more details, check out the [styleguide](https://spacy.io/styleguide) and [source](https://github.com/explosion/spaCy/tree/develop/website). 

While converting the pages to Markdown, we've also fixed a bunch of typos, improved the existing pages and added some new content:

* **Usage Guide:** [Rule-based Matching](https://spacy.io/usage/rule-based-matching). How to use the `Matcher`, `PhraseMatcher` and the new `EntityRuler`, and write powerful components to combine statistical models and rules.
* **Usage Guide:** [Saving and Loading](https://spacy.io/usage/saving-loading). Everything you need to know about serialization, and how to save and load pipeline components, package your spaCy models as Python modules and use entry points.
* **Usage Guide:** [Merging and Splitting](https://spacy.io/usage/linguistic-features#retokenization). How to retokenize a `Doc` using the new `retokenize` context manager and merge spans into single tokens and split single tokens into multiple.
* **Universe:** [Videos](https://spacy.io/universe/category/videos) and [Podcasts](https://spacy.io/universe/category/podcasts)
* **API:** [`EntityRuler`](https://spacy.io/api/entityruler)
* **API:** [`SentenceSegmenter`](https://spacy.io/api/sentencesegmenter)
* **API:** [Pipeline functions](https://spacy.io/api/pipeline-functions)

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825, @grivaz, @roshni-b, @mpuig, @mikelibg, @danielkingai2, @adrienball and @Poluglottos for the pull requests and contributions.",21467110
137,False,True,2019-03-12T14:14:06Z,2019-03-12T14:49:22Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use. [See here for the updated nightly docs.](https://spacy.netlify.com/)**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ This nightly release currently doesn't work on Python 2.7 on Windows, due to difficulties compiling our new matrix multiplication dependency [`blis`](https://github.com/explosion/cython-blis) in that environment. We expect this can be corrected in future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Add simpler, GPU-friendly option to `TextCategorizer`, and allow setting `exclusive_classes` and `architecture` arguments on initialization.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.
* Add `Vocab.writing_system` (populated via the language data) to expose settings like writing direction.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #795: Fix behaviour of `Token.conjuncts.`
* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Add simpler GPU-friendly option to `TextCategorizer`.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2091: Fix `displacy` support for RTL languages.
* Fix issue #2203, #3268: Prevent bad interaction of lemmatizer and tokenizer exceptions.
* Fix issue #2329: Correct `TextCategorizer` and `GoldParse` API docs.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2390: Support setting lexical attributes during retokenization.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2512, #2153: Fix issue with deserialization into non-empty vocab.
* Fix issue #2603: Improve handling of missing NER tags.
* Fix issue #2644: Add table explaining training metrics to docs.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2728: Fix HTML escaping in `displacy` NER visualization and correct API docs.
* Fix issue #2740: Add ability to pass additional arguments to pipeline components.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2869: Make `doc[0].is_sent_start == True`.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3036: Support mutable default arguments in extension attributes.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix issue #3112: Make sure entity types are added correctly on GPU.
* Fix issue #3191: Fix pickling of `Japanese`.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3274: Make `Token.sent` work as expected without the parser.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix issue #3346: Expose Japanese stop words in language class.
* Fix issue #3357: Update displaCy examples in docs to correctly show `Token.pos_`.
* Fix issue #3345: Fix NER when preset entities cross-sentence boundaries.
* Fix issue #3348: Don't use `numpy` directly for similarity.
* Fix issue #3366: Improve converters, training data formats and docs.
* Fix issue #3369: Fix `#egg` fragments in direct downloads.
* Fix issue #3382: Make `Doc.from_array` consistent with `Doc.to_array`.
* Fix issue #3398: Don't set extension attributes in language classes. 
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, v2.1.x currently **doesn't work on Python 2.7 on Windows**. We expect this to be corrected in the future.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
- The deprecated `Doc.merge` and `Span.merge` methods still work, but you may notice that they now run slower when merging many objects in a row. That's because the merging engine was rewritten to be more reliable and to support more efficient merging **in bulk**. To take advantage of this, you should rewrite your logic to use the `Doc.retokenize` context manager and perform as many merges as possible together in the `with` block.
```diff
- doc[1:5].merge()
- doc[6:8].merge()
+ with doc.retokenize() as retokenizer:
+     retokenizer.merge(doc[1:5])
+     retokenizer.merge(doc[6:8])
```
* The serialization methods `to_disk`, `from_disk`, `to_bytes` and `from_bytes` now support a single `exclude` argument to provide a list of string names to exclude. The docs have been updated to list the available serialization fields for each class. The `disable` argument on the `Language` serialization methods has been renamed to `exclude` for consistency.
```diff
- nlp.to_disk(""/path"", disable=[""parser"", ""ner""])
+ nlp.to_disk(""/path"", exclude=[""parser"", ""ner""])
- data = nlp.tokenizer.to_bytes(vocab=False)
+ data = nlp.tokenizer.to_bytes(exclude=[""vocab""])
```
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The keyword argument `n_threads` on the `.pipe` methods is now deprecated, as the v2.x models cannot release the global interpreter lock. (Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.)
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `is_sent_start` attribute of the first token in a `Doc` now correctly defaults to `True`. It previously defaulted to `None`.
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a7 | 91.6 | 89.7 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a7 | 91.8 | 90.0 | 96.9 | 86.3 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a7 | 91.9 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a7 | 91.7 | 89.5 | 97.3 | 83.4 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a7 | 92.3 | 90.4 | 97.4 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a7 | 90.2 | 87.1 | 97.0 | 89.1 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a7 | 91.2 | 88.4 | 97.2 | 89.4 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a7 | 89.5 | 86.2 | 80.1 | 89.0 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a7 | 87.3 | 84.4 | 94.7 | 83.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a7 | 89.1 | 86.2 | 95.3 | 83.3 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a7 | 91.1 | 87.2 | 96.0 | 86.3 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a7 | 83.9 | 77.6 | 91.5 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a7 | 85.1 | 81.5 | 94.5 | 73.3 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a7 | 88.2 | 85.1 | 96.7 | 78.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a7 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

Although it looks pretty much the same, we've rebuilt the entire documentation using [Gatsby](https://www.gatsbyjs.org/) and [MDX](https://mdxjs.com/). It's now an even faster progressive web app and allows us to write all content entirely **in Markdown**, without having to compromise on easy-to-use custom UI components. We're hoping that the Markdown source will make it even easier to contribute to the documentation. For more details, check out the [styleguide](https://spacy.netlify.com/styleguide) and [source](https://github.com/explosion/spaCy/tree/develop/website). 

While converting the pages to Markdown, we've also fixed a bunch of typos, improved the existing pages and added some new content:

* **Usage Guide:** [Rule-based Matching](https://spacy.netlify.com/usage/rule-based-matching). How to use the `Matcher`, `PhraseMatcher` and the new `EntityRuler`, and write powerful components to combine statistical models and rules.
* **Usage Guide:** [Saving and Loading](https://spacy.netlify.com/usage/saving-loading). Everything you need to know about serialization, and how to save and load pipeline components, package your spaCy models as Python modules and use entry points.
* **Usage Guide:** [Merging and Splitting](https://spacy.netlify.com/usage/linguistic-features#retokenization). How to retokenize a `Doc` using the new `retokenize` context manager and merge spans into single tokens and split single tokens into multiple.
* **Universe:** [Videos](https://spacy.netlify.com/universe/category/videos) and [Podcasts](https://spacy.netlify.com/universe/category/podcasts)
* **API:** [`EntityRuler`](https://spacy.netlify.com/api/entityruler)
* **API:** [`SentenceSegmenter`](https://spacy.netlify.com/api/sentencesegmenter)
* **API:** [Pipeline functions](https://spacy.netlify.com/api/pipeline-functions)

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825, @grivaz, @roshni-b, @mpuig, @mikelibg, @danielkingai2 and @adrienball for the pull requests and contributions.",21467110
138,False,True,2019-03-11T21:27:10Z,2019-03-11T23:07:47Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use. [See here for the updated nightly docs.](https://spacy.netlify.com/)**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Add simpler, GPU-friendly option to `TextCategorizer`, and allow setting `exclusive_classes` and `architecture` arguments on initialization.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.
* Add `Vocab.writing_system` (populated via the language data) to expose settings like writing direction.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #795: Fix behaviour of `Token.conjuncts.`
* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Add simpler GPU-friendly option to `TextCategorizer`.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2091: Fix `displacy` support for RTL languages.
* Fix issue #2203, #3268: Prevent bad interaction of lemmatizer and tokenizer exceptions.
* Fix issue #2329: Correct `TextCategorizer` and `GoldParse` API docs.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2390: Support setting lexical attributes during retokenization.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2512, #2153: Fix issue with deserialization into non-empty vocab.
* Fix issue #2603: Improve handling of missing NER tags.
* Fix issue #2644: Add table explaining training metrics to docs.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2728: Fix HTML escaping in `displacy` NER visualization and correct API docs.
* Fix issue #2740: Add ability to pass additional arguments to pipeline components.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2869: Make `doc[0].is_sent_start == True`.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3036: Support mutable default arguments in extension attributes.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix issue #3112: Make sure entity types are added correctly on GPU.
* Fix issue #3191: Fix pickling of `Japanese`.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3274: Make `Token.sent` work as expected without the parser.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix issue #3346: Expose Japanese stop words in language class.
* Fix issue #3357: Update displaCy examples in docs to correctly show `Token.pos_`.
* Fix issue #3345: Fix NER when preset entities cross-sentence boundaries.
* Fix issue #3348: Don't use `numpy` directly for similarity.
* Fix issue #3366: Improve converters, training data formats and docs.
* Fix issue #3369: Fix `#egg` fragments in direct downloads.
* Fix issue #3382: Make `Doc.from_array` consistent with `Doc.to_array`.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, v2.1.x currently **doesn't work on Python 2.7 on Windows**. We expect this to be corrected in the future.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
- The deprecated `Doc.merge` and `Span.merge` methods still work, but you may notice that they now run slower when merging many objects in a row. That's because the merging engine was rewritten to be more reliable and to support more efficient merging **in bulk**. To take advantage of this, you should rewrite your logic to use the `Doc.retokenize` context manager and perform as many merges as possible together in the `with` block.
```diff
- doc[1:5].merge()
- doc[6:8].merge()
+ with doc.retokenize() as retokenizer:
+     retokenizer.merge(doc[1:5])
+     retokenizer.merge(doc[6:8])
```
* The serialization methods `to_disk`, `from_disk`, `to_bytes` and `from_bytes` now support a single `exclude` argument to provide a list of string names to exclude. The docs have been updated to list the available serialization fields for each class. The `disable` argument on the `Language` serialization methods has been renamed to `exclude` for consistency.
```diff
- nlp.to_disk(""/path"", disable=[""parser"", ""ner""])
+ nlp.to_disk(""/path"", exclude=[""parser"", ""ner""])
- data = nlp.tokenizer.to_bytes(vocab=False)
+ data = nlp.tokenizer.to_bytes(exclude=[""vocab""])
```
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The keyword argument `n_threads` on the `.pipe` methods is now deprecated, as the v2.x models cannot release the global interpreter lock. (Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.)
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `is_sent_start` attribute of the first token in a `Doc` now correctly defaults to `True`. It previously defaulted to `None`.
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a7 | 91.6 | 89.7 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a7 | 91.8 | 90.0 | 96.9 | 86.3 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a7 | 91.9 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a7 | 91.7 | 89.5 | 97.3 | 83.4 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a7 | 92.3 | 90.4 | 97.4 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a7 | 90.2 | 87.1 | 97.0 | 89.1 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a7 | 91.2 | 88.4 | 97.2 | 89.4 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a7 | 89.5 | 86.2 | 80.1 | 89.0 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a7 | 87.3 | 84.4 | 94.7 | 83.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a7 | 89.1 | 86.2 | 95.3 | 83.3 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a7 | 91.1 | 87.2 | 96.0 | 86.3 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a7 | 83.9 | 77.6 | 91.5 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a7 | 85.1 | 81.5 | 94.5 | 73.3 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a7 | 88.2 | 85.1 | 96.7 | 78.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a7 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

Although it looks pretty much the same, we've rebuilt the entire documentation using [Gatsby](https://www.gatsbyjs.org/) and [MDX](https://mdxjs.com/). It's now an even faster progressive web app and allows us to write all content entirely **in Markdown**, without having to compromise on easy-to-use custom UI components. We're hoping that the Markdown source will make it even easier to contribute to the documentation. For more details, check out the [styleguide](https://spacy.netlify.com/styleguide) and [source](https://github.com/explosion/spaCy/tree/develop/website). 

While converting the pages to Markdown, we've also fixed a bunch of typos, improved the existing pages and added some new content:

* **Usage Guide:** [Rule-based Matching](https://spacy.netlify.com/usage/rule-based-matching). How to use the `Matcher`, `PhraseMatcher` and the new `EntityRuler`, and write powerful components to combine statistical models and rules.
* **Usage Guide:** [Saving and Loading](https://spacy.netlify.com/usage/saving-loading). Everything you need to know about serialization, and how to save and load pipeline components, package your spaCy models as Python modules and use entry points.
* **Usage Guide:** [Merging and Splitting](https://spacy.netlify.com/usage/linguistic-features#retokenization). How to retokenize a `Doc` using the new `retokenize` context manager and merge spans into single tokens and split single tokens into multiple.
* **Universe:** [Videos](https://spacy.netlify.com/universe/category/videos) and [Podcasts](https://spacy.netlify.com/universe/category/podcasts)
* **API:** [`EntityRuler`](https://spacy.netlify.com/api/entityruler)
* **API:** [`SentenceSegmenter`](https://spacy.netlify.com/api/sentencesegmenter)
* **API:** [Pipeline functions](https://spacy.netlify.com/api/pipeline-functions)

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825, @grivaz, @roshni-b, @mpuig, @mikelibg, @danielkingai2 and @adrienball for the pull requests and contributions.",21467110
139,False,True,2019-03-11T09:45:06Z,2019-03-11T14:05:15Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use. [See here for the updated nightly docs.](https://spacy.netlify.com/)**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Add simpler, GPU-friendly option to `TextCategorizer`, and allow setting `exclusive_classes` and `architecture` arguments on initialization.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Add simpler GPU-friendly option to `TextCategorizer`.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2203, #3268: Prevent bad interaction of lemmatizer and tokenizer exceptions.
* Fix issue #2329: Correct `TextCategorizer` and `GoldParse` API docs.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2390: Support setting lexical attributes during retokenization.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2512, #2153: Fix issue with deserialization into non-empty vocab.
* Fix issue #2603: Improve handling of missing NER tags.
* Fix issue #2644: Add table explaining training metrics to docs.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2728: Fix HTML escaping in `displacy` NER visualization and correct API docs.
* Fix issue #2740: Add ability to pass additional arguments to pipeline components.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2869: Make `doc[0].is_sent_start == True`.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix issue #3112: Make sure entity types are added correctly on GPU.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3274: Make `Token.sent` work as expected without the parser.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix issue #3346: Expose Japanese stop words in language class.
* Fix issue #3357: Update displaCy examples in docs to correctly show `Token.pos_`.
* Fix issue #3345: Fix NER when preset entities cross-sentence boundaries.
* Fix issue #3348: Don't use `numpy` directly for similarity.
* Fix issue #3366: Improve converters, training data formats and docs.
* Fix issue #3369: Fix `#egg` fragments in direct downloads.
* Fix issue #3382: Make `Doc.from_array` consistent with `Doc.to_array`.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, v2.1.x currently **doesn't work on Python 2.7 on Windows**. We expect this to be corrected in the future.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
- The deprecated `Doc.merge` and `Span.merge` methods still work, but you may notice that they now run slower when merging many objects in a row. That's because the merging engine was rewritten to be more reliable and to support more efficient merging **in bulk**. To take advantage of this, you should rewrite your logic to use the `Doc.retokenize` context manager and perform as many merges as possible together in the `with` block.
```diff
- doc[1:5].merge()
- doc[6:8].merge()
+ with doc.retokenize() as retokenizer:
+     retokenizer.merge(doc[1:5])
+     retokenizer.merge(doc[6:8])
```
* The serialization methods `to_disk`, `from_disk`, `to_bytes` and `from_bytes` now support a single `exclude` argument to provide a list of string names to exclude. The docs have been updated to list the available serialization fields for each class. The `disable` argument on the `Language` serialization methods has been renamed to `exclude` for consistency.
```diff
- nlp.to_disk(""/path"", disable=[""parser"", ""ner""])
+ nlp.to_disk(""/path"", exclude=[""parser"", ""ner""])
- data = nlp.tokenizer.to_bytes(vocab=False)
+ data = nlp.tokenizer.to_bytes(exclude=[""vocab""])
```
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The keyword argument `n_threads` on the `.pipe` methods is now deprecated, as the v2.x models cannot release the global interpreter lock. (Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.)
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `is_sent_start` attribute of the first token in a `Doc` now correctly defaults to `True`. It previously defaulted to `None`.
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a7 | 91.6 | 89.7 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a7 | 91.8 | 90.0 | 96.9 | 86.3 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a7 | 91.9 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a7 | 91.7 | 89.5 | 97.3 | 83.4 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a7 | 92.3 | 90.4 | 97.4 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a7 | 90.2 | 87.1 | 97.0 | 89.1 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a7 | 91.2 | 88.4 | 97.2 | 89.4 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a7 | 89.5 | 86.2 | 80.1 | 89.0 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a7 | 87.3 | 84.4 | 94.7 | 83.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a7 | 89.1 | 86.2 | 95.3 | 83.3 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a7 | 91.1 | 87.2 | 96.0 | 86.3 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a7 | 83.9 | 77.6 | 91.5 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a7 | 85.1 | 81.5 | 94.5 | 73.3 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a7 | 88.2 | 85.1 | 96.7 | 78.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a7 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

Although it looks pretty much the same, we've rebuilt the entire documentation using [Gatsby](https://www.gatsbyjs.org/) and [MDX](https://mdxjs.com/). It's now an even faster progressive web app and allows us to write all content entirely **in Markdown**, without having to compromise on easy-to-use custom UI components. We're hoping that the Markdown source will make it even easier to contribute to the documentation. For more details, check out the [styleguide](https://spacy.netlify.com/styleguide) and [source](https://github.com/explosion/spaCy/tree/develop/website). 

While converting the pages to Markdown, we've also fixed a bunch of typos, improved the existing pages and added some new content:

* **Usage Guide:** [Rule-based Matching](https://spacy.netlify.com/usage/rule-based-matching). How to use the `Matcher`, `PhraseMatcher` and the new `EntityRuler`, and write powerful components to combine statistical models and rules.
* **Usage Guide:** [Saving and Loading](https://spacy.netlify.com/usage/saving-loading). Everything you need to know about serialization, and how to save and load pipeline components, package your spaCy models as Python modules and use entry points.
* **Usage Guide:** [Merging and Splitting](https://spacy.netlify.com/usage/linguistic-features#retokenization). How to retokenize a `Doc` using the new `retokenize` context manager and merge spans into single tokens and split single tokens into multiple.
* **Universe:** [Videos](https://spacy.netlify.com/universe/category/videos) and [Podcasts](https://spacy.netlify.com/universe/category/podcasts)
* **API:** [`EntityRuler`](https://spacy.netlify.com/api/entityruler)
* **API:** [`SentenceSegmenter`](https://spacy.netlify.com/api/sentencesegmenter)
* **API:** [Pipeline functions](https://spacy.netlify.com/api/pipeline-functions)

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825, @grivaz, @roshni-b, @mpuig, @mikelibg, @danielkingai2 and @adrienball for the pull requests and contributions.",21467110
140,False,True,2019-02-27T11:26:13Z,2019-02-27T15:23:49Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use. [See here for the updated nightly docs.](https://spacy.netlify.com/)**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Add simpler, GPU-friendly option to `TextCategorizer`, and allow setting `exclusive_classes` and `architecture` arguments on initialization.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Add simpler GPU-friendly option to `TextCategorizer`.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2329: Correct `TextCategorizer` and `GoldParse` API docs.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2390: Support setting lexical attributes during retokenization.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2603: Improve handling of missing NER tags.
* Fix issue #2644: Add table explaining training metrics to docs.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2728: Fix HTML escaping in `displacy` NER visualization and correct API docs.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2869: Make `doc[0].is_sent_start == True`.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix issue #3112: Make sure entity types are added correctly on GPU.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3274: Make `Token.sent` work as expected without the parser.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, v2.1.x currently **doesn't work on Python 2.7 on Windows**. We expect this to be corrected in the future.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
- The deprecated `Doc.merge` and `Span.merge` methods still work, but you may notice that they now run slower when merging many objects in a row. That's because the merging engine was rewritten to be more reliable and to support more efficient merging **in bulk**. To take advantage of this, you should rewrite your logic to use the `Doc.retokenize` context manager and perform as many merges as possible together in the `with` block.
```diff
- doc[1:5].merge()
- doc[6:8].merge()
+ with doc.retokenize() as retokenizer:
+     retokenizer.merge(doc[1:5])
+     retokenizer.merge(doc[6:8])
```
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The keyword argument `n_threads` on the `.pipe` methods is now deprecated, as the v2.x models cannot release the global interpreter lock. (Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.)
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `is_sent_start` attribute of the first token in a `Doc` now correctly defaults to `True`. It previously defaulted to `None`.
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a7 | 91.6 | 89.7 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a7 | 91.8 | 90.0 | 96.9 | 86.3 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a7 | 91.9 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a7 | 91.7 | 89.5 | 97.3 | 83.4 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a7 | 92.3 | 90.4 | 97.4 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a7 | 90.2 | 87.1 | 97.0 | 89.1 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a7 | 91.2 | 88.4 | 97.2 | 89.4 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a7 | 89.5 | 86.2 | 80.1 | 89.0 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a7 | 87.3 | 84.4 | 94.7 | 83.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a7 | 89.1 | 86.2 | 95.3 | 83.3 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a7 | 91.1 | 87.2 | 96.0 | 86.3 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a7 | 83.9 | 77.6 | 91.5 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a7 | 85.1 | 81.5 | 94.5 | 73.3 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a7 | 88.2 | 85.1 | 96.7 | 78.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a7 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

Although it looks pretty much the same, we've rebuilt the entire documentation using [Gatsby](https://www.gatsbyjs.org/) and [MDX](https://mdxjs.com/). It's now an even faster progressive web app and allows us to write all content entirely **in Markdown**, without having to compromise on easy-to-use custom UI components. We're hoping that the Markdown source will make it even easier to contribute to the documentation. For more details, check out the [styleguide](https://spacy.netlify.com/styleguide) and [source](https://github.com/explosion/spaCy/tree/develop/website). 

While converting the pages to Markdown, we've also fixed a bunch of typos, improved the existing pages and added some new content:

* **Usage Guide:** [Rule-based Matching](https://spacy.netlify.com/usage/rule-based-matching). How to use the `Matcher`, `PhraseMatcher` and the new `EntityRuler`, and write powerful components to combine statistical models and rules.
* **Usage Guide:** [Saving and Loading](https://spacy.netlify.com/usage/saving-loading). Everything you need to know about serialization, and how to save and load pipeline components, package your spaCy models as Python modules and use entry points.
* **Usage Guide:** [Merging and Splitting](https://spacy.netlify.com/usage/linguistic-features#retokenization). How to retokenize a `Doc` using the new `retokenize` context manager and merge spans into single tokens and split single tokens into multiple.
* **Universe:** [Videos](https://spacy.netlify.com/universe/category/videos) and [Podcasts](https://spacy.netlify.com/universe/category/podcasts)
* **API:** [`EntityRuler`](https://spacy.netlify.com/api/entityruler)
* **API:** [`SentenceSegmenter`](https://spacy.netlify.com/api/sentencesegmenter)
* **API:** [Pipeline functions](https://spacy.netlify.com/api/pipeline-functions)

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825, @grivaz, @roshni-b, @mpuig and @mikelibg for the pull requests and contributions.",21467110
141,False,True,2019-02-25T20:55:43Z,2019-02-25T21:23:04Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use. [See here for the updated nightly docs.](https://spacy.netlify.com/)**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Add simpler, GPU-friendly option to `TextCategorizer`, and allow setting `exclusive_classes` and `architecture` arguments on initialization.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Add simpler GPU-friendly option to `TextCategorizer`.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2329: Correct `TextCategorizer` and `GoldParse` API docs.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2390: Support setting lexical attributes during retokenization.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2644: Add table explaining training metrics to docs.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2728: Fix HTML escaping in `displacy` NER visualization and correct API docs.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix issue #3112: Make sure entity types are added correctly on GPU.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, v2.1.x currently **doesn't work on Python 2.7 on Windows**. We expect this to be corrected in the future.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
- The deprecated `Doc.merge` and `Span.merge` methods still work, but you may notice that they now run slower when merging many objects in a row. That's because the merging engine was rewritten to be more reliable and to support more efficient merging **in bulk**. To take advantage of this, you should rewrite your logic to use the `Doc.retokenize` context manager and perform as many merges as possible together in the `with` block.
```diff
- doc[1:5].merge()
- doc[6:8].merge()
+ with doc.retokenize() as retokenizer:
+     retokenizer.merge(doc[1:5])
+     retokenizer.merge(doc[6:8])
```
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The keyword argument `n_threads` on the `.pipe` methods is now deprecated, as the v2.x models cannot release the global interpreter lock. (Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.)
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a7 | 91.6 | 89.7 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a7 | 91.8 | 90.0 | 96.9 | 86.3 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a7 | 91.9 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a7 | 91.7 | 89.5 | 97.3 | 83.4 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a7 | 92.3 | 90.4 | 97.4 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a7 | 90.2 | 87.1 | 97.0 | 89.1 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a7 | 91.2 | 88.4 | 97.2 | 89.4 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a7 | 89.5 | 86.2 | 80.1 | 89.0 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a7 | 87.3 | 84.4 | 94.7 | 83.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a7 | 89.1 | 86.2 | 95.3 | 83.3 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a7 | 91.1 | 87.2 | 96.0 | 86.3 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a7 | 83.9 | 77.6 | 91.5 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a7 | 85.1 | 81.5 | 94.5 | 73.3 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a7 | 88.2 | 85.1 | 96.7 | 78.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a7 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

Although it looks pretty much the same, we've rebuilt the entire documentation using [Gatsby](https://www.gatsbyjs.org/) and [MDX](https://mdxjs.com/). It's now an even faster progressive web app and allows us to write all content entirely **in Markdown**, without having to compromise on easy-to-use custom UI components. We're hoping that the Markdown source will make it even easier to contribute to the documentation. For more details, check out the [styleguide](https://spacy.netlify.com/styleguide) and [source](https://github.com/explosion/spaCy/tree/develop/website). 

While converting the pages to Markdown, we've also fixed a bunch of typos, improved the existing pages and added some new content:

* **Usage Guide:** [Rule-based Matching](https://spacy.netlify.com/usage/rule-based-matching). How to use the `Matcher`, `PhraseMatcher` and the new `EntityRuler`, and write powerful components to combine statistical models and rules.
* **Usage Guide:** [Saving and Loading](https://spacy.netlify.com/usage/saving-loading). Everything you need to know about serialization, and how to save and load pipeline components, package your spaCy models as Python modules and use entry points.
* **Usage Guide:** [Merging and Splitting](https://spacy.netlify.com/usage/linguistic-features#retokenization). How to retokenize a `Doc` using the new `retokenize` context manager and merge spans into single tokens and split single tokens into multiple.
* **Universe:** [Videos](https://spacy.netlify.com/universe/category/videos) and [Podcasts](https://spacy.netlify.com/universe/category/podcasts)
* **API:** [`EntityRuler`](https://spacy.netlify.com/api/entityruler)
* **API:** [`SentenceSegmenter`](https://spacy.netlify.com/api/sentencesegmenter)
* **API:** [Pipeline functions](https://spacy.netlify.com/api/pipeline-functions)

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825, @grivaz, @roshni-b, @mpuig and @mikelibg for the pull requests and contributions.",21467110
142,False,True,2019-02-21T11:09:34Z,2019-02-21T11:34:31Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use. [See here for the updated nightly docs.](https://spacy.netlify.com/)**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this problem to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Refactor CLI and add `debug-data` command to validate training data (see #2932).
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
- The deprecated `Doc.merge` and `Span.merge` methods still work, but you may notice that they now run slower when merging many objects in a row. That's because the merging engine was rewritten to be more reliable and to support more efficient merging **in bulk**. To take advantage of this, you should rewrite your logic to use the `Doc.retokenize` context manager and perform as many merges as possible together in the `with` block.
```diff
- doc[1:5].merge()
- doc[6:8].merge()
+ with doc.retokenize() as retokenizer:
+     retokenizer.merge(doc[1:5])
+     retokenizer.merge(doc[6:8])
```
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The keyword argument `n_threads` on the `.pipe` methods is now deprecated, as the v2.x models cannot release the global interpreter lock. (Future versions may introduce a `n_process` argument for parallel inference via multiprocessing.)
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a7 | 91.6 | 89.7 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a7 | 91.8 | 90.0 | 96.9 | 86.3 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a7 | 91.9 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a7 | 91.7 | 89.5 | 97.3 | 83.4 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a7 | 92.3 | 90.4 | 97.4 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a7 | 90.2 | 87.1 | 97.0 | 89.1 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a7 | 91.2 | 88.4 | 97.2 | 89.4 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a7 | 89.5 | 86.2 | 80.1 | 89.0 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a7 | 87.3 | 84.4 | 94.7 | 83.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a7 | 89.1 | 86.2 | 95.3 | 83.3 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a7 | 91.1 | 87.2 | 96.0 | 86.3 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a7 | 83.9 | 77.6 | 91.5 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a7 | 85.1 | 81.5 | 94.5 | 73.3 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a7 | 88.2 | 85.1 | 96.7 | 78.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a7 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

Although it looks pretty much the same, we've rebuilt the entire documentation using [Gatsby](https://www.gatsbyjs.org/) and [MDX](https://mdxjs.com/). It's now an even faster progressive web app and allows us to write all content entirely **in Markdown**, without having to compromise on easy-to-use custom UI components. We're hoping that the Markdown source will make it even easier to contribute to the documentation. For more details, check out the [styleguide](https://spacy.netlify.com/styleguide) and [source](https://github.com/explosion/spaCy/tree/develop/website). 

While converting the pages to Markdown, we've also fixed a bunch of typos, improved the existing pages and added some new content:

* **Usage Guide:** [Rule-based Matching](https://spacy.netlify.com/usage/rule-based-matching). How to use the `Matcher`, `PhraseMatcher` and the new `EntityRuler`, and write powerful components to combine statistical models and rules.
* **Usage Guide:** [Saving and Loading](https://spacy.netlify.com/usage/saving-loading). Everything you need to know about serialization, and how to save and load pipeline components, package your spaCy models as Python modules and use entry points.
* **Usage Guide:** [Merging and Splitting](https://spacy.netlify.com/usage/linguistic-features#retokenization). How to retokenize a `Doc` using the new `retokenize` context manager and merge spans into single tokens and split single tokens into multiple.
* **Universe:** [Videos](https://spacy.netlify.com/universe/category/videos) and [Podcasts](https://spacy.netlify.com/universe/category/podcasts)
* **API:** [`EntityRuler`](https://spacy.netlify.com/api/entityruler)
* **API:** [`SentenceSegmenter`](https://spacy.netlify.com/api/sentencesegmenter)
* **API:** [Pipeline functions](https://spacy.netlify.com/api/pipeline-functions)

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825, @grivaz, @roshni-b, @mpuig and @mikelibg for the pull requests and contributions.",21467110
143,False,True,2019-02-16T16:48:34Z,2019-02-17T12:24:19Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use.**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this problem to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** 2-3 times faster tokenization across all languages at the same accuracy!
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* **NEW:** Alpha support for [Tamil](spacy/lang/ta), [Ukrainian](spacy/lang/uk) and [Kannada](spacy/lang/kn), and base language classes for [Afrikaans](spacy/lang/af), [Bulgarian](spacy/lang/bg), [Czech](spacy/lang/cs), [Icelandic](spacy/lang/is), [Lithuanian](spacy/lang/lt), [Latvian](spacy/lang/lv), [Slovak](spacy/lang/sk), [Slovenian](spacy/lang/sl) and [Albanian](spacy/lang/sq).
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging and splitting tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* **NEW:** `gold.spans_from_biluo_tags` helper that returns `Span` objects, e.g. to overwrite the `doc.ents`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Refactor CLI and add `debug-data` command to validate training data (see #2932).
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1642: Replace `regex` with `re` and speed up tokenization.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2833: Raise better error if `Token` or `Span` are pickled.
* Fix issue #2838: Add `Retokenizer.split` method to split one token into several.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #2901: Fix issue with first call of `nlp` in Japanese (MeCab).
* Fix issue #2924: Make IDs of displaCy arcs more unique to avoid clashes.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix issue #3122: Correct docs of `Token.subtree` and `Span.subtree`.
* Fix issue #3128: Improve error handling in converters.
* Fix issue #3248: Fix `PhraseMatcher` pickling and make `__len__` consistent.
* Fix issue #3277: Add en/em dash to tokenizer prefixes and suffixes.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
* For better compatibility with the Universal Dependencies data, the lemmatizer now preserves capitalization, e.g. for proper nouns (see #3256).
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
- The `spacy init-model` command now uses a `--jsonl-loc` argument to pass in a a newline-delimited JSON (JSONL) file containing one lexical entry per line instead of a separate `--freqs-loc` and `--clusters-loc`.
```diff
- $ spacy init-model en ./model --freqs-loc ./freqs.txt --clusters-loc ./clusters.txt
+ $ spacy init-model en ./model --jsonl-loc ./vocab.jsonl
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a7 | 91.6 | 89.7 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a7 | 91.8 | 90.0 | 96.9 | 86.3 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a7 | 91.9 | 90.1 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a7 | 91.7 | 89.5 | 97.3 | 83.4 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a7 | 92.3 | 90.4 | 97.4 | 83.8 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a7 | 90.2 | 87.1 | 97.0 | 89.1 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a7 | 91.2 | 88.4 | 97.2 | 89.4 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a7 | 89.5 | 86.2 | 80.1 | 89.0 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a7 | 87.3 | 84.4 | 94.7 | 83.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a7 | 89.1 | 86.2 | 95.3 | 83.3 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a7 | 91.1 | 87.2 | 96.0 | 86.3 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a7 | 83.9 | 77.6 | 91.5 | 87.0 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a7 | 85.1 | 81.5 | 94.5 | 73.3 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a7 | 88.2 | 85.1 | 96.7 | 78.1 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a7 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin, @moreymat, @mirfan899, @ozcankasal, @willprice, @alvations, @amperinet, @retnuh, @Loghijiaha, @DeNeutoy, @gavrieltal, @boena, @BramVanroy, @pganssle, @foufaster, @adrianeboyd, @maknotavailable, @pierremonico, @lauraBaakman, @juliamakogon, @Gizzio, @Abhijit-2592, @akki2825 and @grivaz for the pull requests and contributions.",21467110
144,False,True,2019-01-21T17:32:34Z,2019-01-21T17:46:09Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use.**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this problem to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** Enhanced pattern API for rule-based `Matcher` (see #1971).
* **NEW:** `Doc.retokenize` context manager for merging tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Refactor CLI and add `debug-data` command to validate training data (see #2932).
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

> ### 🚧 Under construction
>
> This section includes new features and improvements that are planned for the stable `v2.1.x` release, but aren't included in the nightly yet.
>
> * Improve tokenizer performance (see #1642).
> * Allow retokenizer to update `Lexeme` attributes on merge (see #2390).
> * `md` and `lg` models and new, pre-trained word vectors for German, French, Spanish, Italian, Portuguese and Dutch.
> * Improved JSON(L) format for training (see #2928, #2932).

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1537: Make `Span.as_doc` return a copy, not a view.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Fix issue #1773: Prevent tokenizer exceptions from setting `POS` but not `TAG`.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #1963: Resize `Doc.tensor` when merging spans.
* Fix issue #1971: Update `Matcher` engine to support regex, extension attributes and rich comparison.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2396: Fix `Doc.get_lca_matrix`.
* Fix issue #2464, #3009: Fix behaviour of `Matcher`'s `?` quantifier.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #3012: Fix clobber of `Doc.is_tagged` in `Doc.from_array`.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix issue #3064: Allow single string attributes in `Doc.to_array`.
* Fix issue #3093, #3067: Set `vectors.name` correctly when exporting model via CLI.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a6 | 91.5 | 89.6 | 96.8 | 85.5 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a6 | 91.9 | 90.2 | 97.0 | 86.4 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a6 | 92.0 | 90.2 | 97.0 | 86.6 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a6 | 91.6 | 89.6 | 97.2 | 83.3 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a6 | 92.2 | 90.3 | 97.5 | 83.9 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a6 | 90.3 | 87.3 | 97.0 | 89.0 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a6 | 90.9 | 88.1 | 97.2 | 89.3 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a6 | 89.4 | 86.0 | 80.4 | 89.1 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a6 | 87.7 | 84.8 | 94.5 | 82.9 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a6 | 89.1 | 86.5 | 95.1 | 83.4 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a6 | 90.9 | 87.2 | 95.9 | 86.4 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a6 | 83.7 | 77.6 | 91.5 | 87.1 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a6 | 85.0 | 81.5 | 94.8 | 73.1 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a6 | 88.4 | 85.2 | 96.6 | 81.0 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a6 | - | - | - | 81.6 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal, @svlandeg, @jarib, @alvaroabascar, @kbulygin and @moreymat for the pull requests and contributions.",21467110
145,False,True,2018-12-20T23:26:39Z,2019-01-05T13:18:47Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use.**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this problem to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** `Doc.retokenize` context manager for merging tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Refactor CLI and add `debug-data` command to validate training data (see #2932).
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

> ### 🚧 Under construction
>
> This section includes new features and improvements that are planned for the stable `v2.1.x` release, but aren't included in the nightly yet.
>
> * Enhanced pattern API for rule-based `Matcher` (see #1971).
> * Improve tokenizer performance (see #1642).
> * Allow retokenizer to update `Lexeme` attributes on merge (see #2390).
> * `md` and `lg` models and new, pre-trained word vectors for German, French, Spanish, Italian, Portuguese and Dutch.
> * Improved JSON(L) format for training (see #2928, #2932).

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1585: Prevent parser from predicting unseen classes.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1816: Allow custom `Language` subclasses via entry points.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2779: Fix handling of pre-set entities.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix issue #3048: Raise better errors for uninitialized pipeline components.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a5 | 91.2 | 89.3 | 96.9 | 85.6 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a5 | 91.4 | 89.5 | 96.9 | 85.9 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a5 | 91.5 | 89.7 | 97.0 | 86.3 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a5 | 91.3 | 89.0 | 97.1 | 82.2 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a5 | 92.0 | 90.0 | 97.4 | 82.7 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a5 | 89.9 | 86.7 | 96.6 | 87.3 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a5 | 90.6 | 87.7 | 97.0 | 88.0 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a5 | 89.3 | 86.0 | 78.5 | 87.8 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a5 | 87.3 | 84.4 | 94.4 | 81.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a5 | 88.8 | 86.1 | 94.9 | 82.2 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a5 | 90.8 | 87.0 | 95.7 | 84.8 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a5 | 83.7 | 77.4 | 90.9 | 85.4 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a5 | 85.5 | 81.8 | 94.7 | 75.9 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a5 | 88.5 | 85.2 | 96.8 | 80.01 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a5 | - | - | - | 82.8 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal and @svlandeg for the pull requests and contributions.",21467110
146,False,True,2018-12-18T18:19:26Z,2018-12-18T21:42:18Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use.**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this problem to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser, NER and Text Categorizer

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.
* Improve loading time of `French` by ~30%.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** `Doc.retokenize` context manager for merging tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* **NEW:** Replace `ujson`, `msgpack`, `msgpack-numpy`, `pickle`, `cloudpickle` and `dill` with our own package [`srsly`](https://github.com/explosion/srsly) to centralise dependencies and allow binary wheels.
* **NEW:** `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
* **NEW:** Built-in `EntityRuler` component to make it easier to build rule-based NER and combinations of statistical and rule-based systems.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.
* Accept `""TEXT""` as an alternative to `""ORTH""` in `Matcher` patterns.
* Refactor CLI and add `debug-data` command to validate training data (see #2932).
* Use [`black`](https://github.com/ambv/black) for auto-formatting `.py` source and optimse codebase using [`flake8`](http://flake8.pycqa.org/en/latest/). You can now run `flake8 spacy` and it should return no errors or warnings. See [`CONTRIBUTING.md`](CONTRIBUTING.md#code-conventions) for details. 

> ### 🚧 Under construction
>
> This section includes new features and improvements that are planned for the stable `v2.1.x` release, but aren't included in the nightly yet.
>
> * Enhanced pattern API for rule-based `Matcher` (see #1971).
> * Improve tokenizer performance (see #1642).
> * Allow retokenizer to update `Lexeme` attributes on merge (see #2390).
> * `md` and `lg` models and new, pre-trained word vectors for German, French, Spanish, Italian, Portuguese and Dutch.
> * Improved JSON(L) format for training (see #2928, #2932).

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1748, #1798, #2756, #2934: Make `TextCategorizer` default to a simpler, GPU-friendly model.
* Fix issue #1782, #2343: Fix training on GPU.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2648: Fix `KeyError` in `Vectors.most_similar`.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2693: Only use `'sentencizer'` as built-in sentence boundary component name.
* Fix issue #2754, #3028: Make `NORM` a `Token` attribute instead of a `Lexeme` attribute to allow setting context-specific norms in tokenizer exceptions.
* Fix issue #2769: Fix issue that'd cause segmentation fault when calling `EntityRecognizer.add_label`.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix issue #2870: Make it illegal for the entity recognizer to predict whitespace tokens as `B`, `L` or `U`.
* Fix issue #2871: Fix vectors for reserved words.
* Fix issue #3027: Allow `Span` to take unicode value for `label` argument.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
* The `Doc.print_tree` method is not deprecated in favour of a unified `Doc.to_json` method, which outputs data in the same format as the expected JSON training data.
* The built-in rule-based sentence boundary detector is now only called `'sentencizer'` – the name `'sbd'` is deprecated.
```diff
- sentence_splitter = nlp.create_pipe('sbd')
+ sentence_splitter = nlp.create_pipe('sentencizer')
``` 
* The `spacy train` command now lets you specify a comma-separated list of pipeline component names, instead of separate flags like `--no-parser` to disable components. This is more flexible and also handles custom components out-of-the-box.
```diff
- $ spacy train en /output train_data.json dev_data.json --no-parser
+ $ spacy train en /output train_data.json dev_data.json --pipeline tagger,ner
```
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a5 | 91.2 | 89.3 | 96.9 | 85.6 | 𐄂 | 10 MB |
| `en_core_web_md` | English | 2.1.0a5 | 91.4 | 89.5 | 96.9 | 85.9 | ✓ | 90 MB |
| `en_core_web_lg` | English | 2.1.0a5 | 91.5 | 89.7 | 97.0 | 86.3 | ✓ | 788 MB |
| `de_core_news_sm` | German | 2.1.0a5 | 91.3 | 89.0 | 97.1 | 82.2 | 𐄂 | 10 MB |
| `de_core_news_md` | German | 2.1.0a5 | 92.0 | 90.0 | 97.4 | 82.7 | ✓ | 210 MB |
| `es_core_news_sm` | Spanish | 2.1.0a5 | 89.9 | 86.7 | 96.6 | 87.3 | 𐄂 | 10 MB |
| `es_core_news_md` | Spanish | 2.1.0a5 | 90.6 | 87.7 | 97.0 | 88.0 | ✓ | 69 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a5 | 89.3 | 86.0 | 78.5 | 87.8 | 𐄂 | 12 MB |
| `fr_core_news_sm` | French | 2.1.0a5 | 87.3 | 84.4 | 94.4 | 81.0 | 𐄂 | 14 MB |
| `fr_core_news_md` | French | 2.1.0a5 | 88.8 | 86.1 | 94.9 | 82.2 | ✓ | 82 MB |
| `it_core_news_sm` | Italian | 2.1.0a5 | 90.8 | 87.0 | 95.7 | 84.8 | 𐄂 | 10 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a5 | 83.7 | 77.4 | 90.9 | 85.4 | 𐄂 | 10 MB |
| `el_core_news_sm` | Greek | 2.1.0a5 | 85.5 | 81.8 | 94.7 | 75.9 | 𐄂 | 10 MB |
| `el_core_news_md` | Greek | 2.1.0a5 | 88.5 | 85.2 | 96.8 | 80.01 | ✓ | 126 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a5 | - | - | - | 82.8 | 𐄂 | 3 MB |

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas, @skrcode, @gavrieltal and @svlandeg for the pull requests and contributions.",21467110
147,False,True,2018-11-28T18:07:24Z,2018-11-28T20:45:04Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use.**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

> ⚠️ Due to difficulties linking our new [`blis`](https://github.com/explosion/cython-blis) for faster platform-independent matrix multiplication, this nightly release currently doesn't work on Python 2.7 on Windows. We expect this problem to be corrected in the future.

## ✨ New features and improvements

### Tagger, Parser & NER

* **NEW:** Experimental ULMFit/BERT/Elmo-like pretraining (see #2931) via the new `spacy pretrain` command. This pre-trains the CNN using BERT's cloze task. A new trick we're calling *Language Modelling with Approximate Outputs* is used to apply the pre-training to smaller models. The pre-training outputs CNN and embedding weights that can be used in `spacy train`, using the new `-t2v` argument.
* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Add `EntityRecognizer.labels` property.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v7.0](https://github.com/explosion/thinc/releases), which defaults to single-thread with fast [`blis`](https://github.com/explosion/cython-blis) kernel for matrix multiplication. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data

* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.

### CLI

* **NEW:** `pretrain` command for ULMFit/BERT/Elmo-like pretraining (see #2931).
* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** `Doc.retokenize` context manager for merging tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* **NEW:** Allow `PhraseMatcher` to match on token attributes other than `ORTH`, e.g. `LOWER` (for case-insensitive matching) or even `POS` or `TAG`.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.

> ### 🚧 Under construction
>
> This section includes new features and improvements that are planned for the stable `v2.1.x` release, but aren't included in the nightly yet.
>
> * Enhanced pattern API for rule-based `Matcher` (see #1971).
> * Improve tokenizer performance (see #1642).
> * Allow retokenizer to update `Lexeme` attributes on merge (see #2390).
> * `md` and `lg` models and new, pre-trained word vectors for German, French, Spanish, Italian, Portuguese and Dutch.
> * Improved JSON(L) format for training (see #2928, #2932).
> * `Doc.to_json()` method which outputs data in spaCy's training format. This will be the only place where the format is hard-coded (see #2932).
> * Refactor CLI and add `debug-data` command to validate training data (see #2932).

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2482: Fix serialization when parser model is empty.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns.
* Fix issue #2772: Fix bug in sentence starts for non-projective parses.
* Fix issue #2782: Make `like_num` work with prefixed numbers.
* Fix serialization of custom tokenizer if not all functions are defined.
* Fix bugs in beam-search training objective.
* Fix problems with model pickling.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a4 | 91.7 | 89.8 | 96.8 | 85.7 | 𐄂 | 12 MB |
| `en_core_web_md` | English | 2.1.0a4 | 92.0 | 90.1 | 97.0 | 86.2 | ✓ | 93 MB |
| `en_core_web_lg` | English | 2.1.0a4 | 92.1 | 90.3 | 97.0 | 86.5 | ✓ | 780 MB |
| `de_core_news_sm` | German | 2.1.0a4 | 91.9 | 89.8 | 97.2 | 83.4 | 𐄂 | 12 MB |
| `de_core_news_md` | German | 2.1.0a4 | 91.3 | 90.5 | 97.4 | 83.6 | ✓ | 212 MB |
| `es_core_news_sm` | Spanish | 2.1.0a4 | 90.1 | 87.1 | 96.8 | 89.3 | 𐄂 | 12 MB |
| `es_core_news_md` | Spanish | 2.1.0a4 | 90.7 | 87.8 | 97.1 | 89.4 | ✓ | 72 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a4 | 89.2 | 85.8 | 79.8 | 82.4 | 𐄂 | 14 MB |
| `fr_core_news_sm` | French | 2.1.0a4 | 87.2 | 84.0 | 94.4 | 67.0 <sup>1</sup> | 𐄂 | 16 MB |
| `fr_core_news_md` | French | 2.1.0a4 | 88.8 | 86.0 | 94.9 | 70.0 <sup>1</sup> | ✓ | 84 MB |
| `it_core_news_sm` | Italian | 2.1.0a4 | 90.6 | 87.0 | 96.0 | 81.7 | 𐄂 | 12 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a4 | 83.1 | 77.2 | 91.3 | 87.3 | 𐄂 | 12 MB |
| `el_core_news_sm` | Greek | 2.1.0a4 | 84.2 | 80.4 | 94.6 | 71.5 | 𐄂 | 12 MB |
| `el_core_news_md` | Greek | 2.1.0a4 | 87.5 | 84.1 | 96.4 | 78.3 | ✓ | 128 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a4 | - | - | - | 83.2 | 𐄂 | 4 MB |

1) We're currently investigating this, as the results are anomalously low.

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos, @louridas and @skrcode for the pull requests and contributions.",21467110
148,False,False,2018-12-01T02:35:09Z,2018-12-01T03:00:22Z,"## ✨ New features and improvements

* **NEW:** Alpha tokenization support for [Catalan](spacy/lang/ca).
* Improve [French](spacy/lang/fr) tokenization.
* Fix `regex` pin to harmonise dependencies with conda.
* Fix `msgpack` pin.
* Update tests for `pytest` 4.0.

## 🔴 Bug fixes

* Fix issue #2933: Correct mistake in `is_ascii` documentation.
* Fix issue #2976: Fix bug where `Vocab.prune_vectors` did not use `batch_size`.
* Fix issue #2986: Correctly document when `Span.ents` was added.
* Fix issue #2995, #2996: Fix `msgpack` pin.

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @mpuig, @ALSchwalm, @bpben, @svlandeg and @wxv for the pull requests and contributions.",21467110
149,False,False,2018-11-24T14:34:23Z,2018-11-26T12:31:26Z,"## ✨ New features and improvements

* Make `max_length` of input text inclusive.
* Raise error when setting overlapping entities as `doc.ents`.
* Improve French lemmatization and check if a word is in one of the regular lists specific to each part-of-speech tag.

## 🔴 Bug fixes

* Fix issue #1581, #1969, #1986: Fix out-of-bounds access in NER training that'd cause segmentation fault.
* Fix issue #2924: Prevent problem where `displacy` arcs would receive the same IDs in Jupyter notebooks, causing weirdly positioned arc labels.
* Fix issue #2948: Fix problem with symlink creation on Windows.

## 📖 Documentation and examples

* Fix various typos and inconsistencies.
* Update [spaCy Universe](https://spacy.io/universe) with new projects.
* Add [example script](examples/pipeline/fix_space_entities.py) showing a fix-up rule for whitespace entities like `'\n'`.

## 👥 Contributors

Thanks to @digest0r, @BramVanroy, @grivaz, @wannaphongcom, @mikelibg, @danielhers, @frascuchon, @mauryaland and @cicorias for the pull requests and contributions.",21467110
150,False,False,2018-10-15T12:39:25Z,2018-10-15T13:04:33Z,"## 🔴 Bug fixes

* Fix `msgpack-numpy` pin, which could affect serialization on Python 2.7.",21467110
151,False,False,2018-10-14T23:40:44Z,2018-10-15T12:01:33Z,"## ✨ New features and improvements

* Improve version compatibility to support wheels for all spaCy dependencies maintained by us: [`thinc`](https://github.com/explosion/thinc), [`cymem`](https://github.com/explosion/cymem), [`preshed`](https://github.com/explosion/preshed) and [`murmurhash`](https://github.com/explosion/murmurhash).
* Support GPU installation by specifying `spacy[cuda]`, `spacy[cuda90]`, `spacy[cuda91]`, `spacy[cuda92]` or `spacy[cuda10]`, which will install `cupy` and [`thinc_gpu_ops`](https://github.com/explosion/thinc_gpu_ops).
* Add `spacy.prefer_gpu()` and `spacy.require_gpu()` functions.

## 📖 Documentation and examples

* Update GPU installation and usage docs.",21467110
152,False,False,2018-10-13T17:42:16Z,2018-10-13T21:48:53Z,"## ✨ New features and improvements

* **NEW:** Pre-built wheels and up to 10 times faster installation! This release starts the journey towards pre-built wheels for all of spaCy's dependencies. Once that's completed, you won't even need a local compiler anymore to install the library. For more details on our wheels process, see [`explosion/wheelwright`](https://github.com/explosion/wheelwright).
* **NEW:** Alpha support for [Telugu](spacy/lang/te) and [Sinhala](spacy/lang/si).
* **NEW:** Rule-based lemmatization for [Greek](spacy/lang/el) and [French](spacy/lang/fr).
* Port over Chinese support (#1210) from v1.x.
* Improve language data for [Persian](spacy/lang/fa), [Greek](spacy/lang/el), [Swedish](spacy/lang/sv), [Bengali](spacy/lang/bn), [Polish](spacy/lang/pl), [Portuguese](spacy/lang/pt), [Indonesian](spacy/lang/id), [French](spacy/lang/fr), [German](spacy/lang/de) and [Russian](spacy/lang/ru).
* Add `Span.ents` property for consistency with `Doc.ents`.
* Add `--verbose` option to `spacy train` to output more details for debugging.

## 🔴 Bug fixes

* Fix issue #653: Introduce bulk merge function.
* Fix issue #1445, #1917, #2209, #2362, #2371, #2383, #2501, #2743, #2758: Fix Keras examples.
* Fix issue #2261, #2800: Fix bug that could cause a crash with too many entity types. 
* Fix issue #2540: Improve French stop words.
* Fix issue #2582, #2640, #2645, #2657, #2705, #2784, #2815, #2841, #2845: Fix typos and inconsistencies in documentation.
* Fix issue #2593: Prevent `numpy` warning.
* Fix issue #2706: Add missing label `FAC` to `spacy.explain` glossary.
* Fix issue #2709: Pass default option when calling `getoption()` in `conftest.py`.

## 📖 Documentation and examples

* Improve Keras examples.
* Update [training examples](examples/training) to use minibatching.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DimaBryuhanov, @kororo, @AndriyMulyar, @katarkor, @giannisdaras, @bphi, @vikaskyadav, @sammous, @EmilStenstrom, @howl-anderson, @ohenrik, @aashishg, @aryaprabhudesai, @steve-prod, @njsmith, @aniruddha-adhikary, @pzelasko, @mbkupfer, @sainathadapa, @tyburam, @grivaz, @filipecaixeta, @aongko, @free-variation, @mauryaland, @pmj642, @keshan, @darindf, @charlax, @phojnacki, @skrcode, @jacopofar, @Cinnamy and @JKhakpour for the pull requests and contributions!",21467110
153,False,True,2018-08-16T14:54:50Z,2018-08-16T16:25:39Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use.**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

## ✨ New features and improvements

### Tagger, Parser & NER

* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Fix bugs in beam-search training objective.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v6.11](https://github.com/explosion/thinc/releases/tag/v6.11.1), which defaults to single-thread with fast OpenBLAS kernel. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.
* **NEW:** Statistical models for Greek.

### CLI

* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.
* Add support for multi-task objectives to `train` command.
* Add support for data-augmentation to `train` command.

### Other

* **NEW:** `Doc.retokenize` context manager for merging tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* **NEW:** Built-in rule-based NER component to add entities based on match patterns (see #2513).
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.

> ### 🚧 Under construction
>
> This section includes new features and improvements that are planned for the stable `v2.1.x` release, but aren't included in the nightly yet.
>
> * Enhanced pattern API for rule-based `Matcher` (see #1971).
> * Improve tokenizer performance (see #1642).
> * Allow retokenizer to update `Lexeme` attributes on merge (see #2390).
> * `md` and `lg` models and new, pre-trained word vectors for German, French, Spanish, Italian, Portuguese and Dutch.

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix issue #2671, #2675: Fix incorrect match ID on some patterns. 
* Fix serialization of custom tokenizer if not all functions are defined.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Language | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | English | 2.1.0a0 | 91.8 | 90.0 | 96.8 | 85.6 | 𐄂 | 28 MB |
| `en_core_web_md` | English | 2.1.0a0 | 92.0 | 90.2 | 97.0 | 86.2 | ✓ | 107 MB |
| `en_core_web_lg` | English | 2.1.0a0 | 92.1 | 90.3 | 97.0 | 86.2 | ✓ | 805 MB |
| `de_core_news_sm` | German | 2.1.0a0 | 92.0 | 90.1 | 97.2 | 83.8 | 𐄂 | 26 MB |
| `de_core_news_md` | German | 2.1.0a0 | 92.4 | 90.7 | 97.4 | 84.2 | ✓ | 228 MB |
| `es_core_news_sm` | Spanish | 2.1.0a0 | 90.1 | 87.2 | 96.9 | 89.4 | 𐄂 | 28 MB |
| `es_core_news_md` | Spanish | 2.1.0a0 | 90.7 | 88.0 | 97.2 | 89.5 | ✓ | 88 MB |
| `pt_core_news_sm` | Portuguese | 2.1.0a0 | 89.4 | 86.3 | 80.1 | 82.7 | 𐄂 | 29 MB |
| `fr_core_news_sm` | French | 2.1.0a0 | 88.8 | 85.7 | 94.4 | 67.3 <sup>1</sup> | 𐄂 | 32 MB |
| `fr_core_news_md` | French | 2.1.0a0 | 88.7 | 86.0 | 95.0 | 70.4 <sup>1</sup> | ✓ | 100 MB |
| `it_core_news_sm` | Italian | 2.1.0a0 | 90.7 | 87.1 | 96.1 | 81.3 | 𐄂 | 27 MB |
| `nl_core_news_sm` | Dutch | 2.1.0a0 | 83.5 | 77.6 | 91.5 | 87.3 | 𐄂 | 27 MB |
| `el_core_news_sm` | Greek | 2.1.0a0 | 84.5 | 81.0 | 95.0 | 73.5 | 𐄂 | 27 MB |
| `el_core_news_md` | Greek | 2.1.0a0 | 87.7 | 84.7 | 96.3 | 80.2 | ✓ | 143 MB |
| `xx_ent_wiki_sm` | Multi | 2.1.0a0 | - | - | - | 83.8 | 𐄂 | 9 MB |

1) We're currently investigating this, as the results are anomalously low.

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DuyguA, @giannisdaras, @mgogoulos and @louridas for the pull requests and contributions.",21467110
154,False,False,2018-07-21T13:57:18Z,2018-07-21T15:18:40Z,"We had to release another update to the `v2.0.x` branch of spaCy to resolve a dependency issue, so we decided to also include and/or backport a bunch of features and fixes that were originally intended for `v2.1.0` ([see here](https://github.com/explosion/spaCy/releases/tag/v2.1.0a0) for the nightly version).

## ✨ New features and improvements

* **NEW:** Alpha tokenization and language data for [Arabic](spacy/lang/ar), [Urdu](spacy/lang/ur), [Tatar](spacy/lang/tt) and [Greek](spacy/lang/el).
* **NEW:** Mecab-based [Japanese](spacy/lang/ja) tokenization and lemmatization.
* **NEW:** Add [Norwegian](spacy/lang/no) rule-based and lookup lemmatization.
* **NEW:** Add [Danish](spacy/lang/da) lookup lemmatization based on the *Den store danske SprogTeknologiske Ordbase, STO* dataset, courtesy of The University of Copenhagen.
* **NEW:** [Romanian](spacy/lang/ro) lookup lemmatization.
* Improve language data for [Polish](spacy/lang/pl), [Turkish](spacy/lang/tr), [French](spacy/lang/fr), [Romanian](spacy/lang/ro), [Swedish](spacy/lang/sv) and [Japanese](spacy/lang/ja).
* Improve case-sensitive lookup lemmatization in [German](spacy/lang/de).
* Add `Token.sent` property that returns the sentence `Span` the token is part of.
* Add `remove_extension` method on `Doc`, `Token` and `Span`.
* Add `Doc.is_sentenced` property that returns `True` if sentence boundaries have been applied.
* Allow ignoring warning by code via the `SPACY_WARNING_IGNORE` environment variable.
* Add `--silent` option to `info` command.

## 🔴 Bug fixes

* Fix issue #1456: Pass additional arguments of `download` command to `pip` and check if model is already installed before downloading it.
* Fix issue #2191: Update `README` section on tests and dependencies.
* Fix issue #2194: Ensure that `Doc.noun_chunks_iterator` isn't `None` before calling it.
* Fix issue #2196: Return data in `cli.info` and add `silent` option.
* Fix issue #2200: Correct typo in `spacy package` command message.
* Fix issue #2210: Fix bug in Spanish noun chunks.
* Fix issue #2211, #2320: Resolve problem in `download` command and use `requests` library again.
* Fix issue #2219: Fix token similarity of single-letter tokens.
* Fix issue #2222, #2223: Fix typos in documentation and docstrings.
* Fix issue #2226: Use correct, non-deprecated merge syntax in `merge_ents`.
* Fix issue #2228: Fix deserialization when using `tensor=False` or `sentiment=False`.
* Fix issue #2238: Correct Swedish lookup lemmatization.
* Fix issue #2242: Add `remove_extension` method on `Doc`, `Token` and `Span`.
* Fix issue #2266: Add `collapse_phrases` option to displaCy visualizer.
* Fix issue #2269: Fix `KeyError` by renaming `SP` to `_SP`.
* Fix issue #2304: Don't require `attrs` argument in `Doc.retokenize` and allow ints/unicode.
* Fix issue #2361: Escape HTML tags in `displacy.render`.
* Fix issue #2376: Improve `Matcher` examples and add section on using pipeline components.
* Fix issue #2385: Handle multi-word entities correctly in IOB to BILUO conversion.
* Fix issue #2452: Fix bug that would cause `displacy` arrows to only point in one direction.
* Fix issue #2477: Also allow `Span` objects in `displacy.render`.
* Fix issue #2490: Update Thinc's dependencies for Python 3.7 compatibility.
* Fix issue #2495: Fix loading tokenizer with custom prefix search.
* Fix issue #2514: Switch from `msgpack-python` to `msgpack` to hopefully prevent conda from downloading a two-year-old spaCy version when installing with latest the Anaconda distribution. 
* Ensure that `Doc.is_tagged` is set correctly when using `Language.pipe`.
* Fix bug in `merge_noun_chunks` factory that would return `None` if `Doc` wasn't parsed.
* Explicitly require `pathlib` backport on Python 2 only.

## 📖 Documentation and examples

* **NEW:** Edit and execute code examples in your browser – all across the [documentation](https://spacy.io)!
* **NEW:** The [spaCy Universe](https://spacy.io/universe), a collection of plugins, extensions and other resources for spaCy.
* **NEW:** Experimental [rule-based `Matcher` Explorer demo](https://explosion.ai/demos/matcher) – create token patterns interactively, test them against your text and copy-paste the Python pattern code.
* **NEW:** Document [Cython API](https://spacy.io/api/cython).
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @mollerhoj, @howl-anderson, @pktippa, @skrcode, @miroli, @ivyleavedtoadflax, @5hirish, @therealronnie, @alexvy86, @mn3mos, @polm, @knoxdw, @bellabie, @mauryaland, @LRAbbade, @janimo, @vishnumenon, @tzano, @cclauss, @armsp, @aristorinjuang, @BigstickCarpet, @idealley, @ansgar-t, @mpszumowski, @91ns, @msklvsk, @himkt, @DanielRuf, @nathanathan, @GolanLevy, @nipunsadvilkar, @cjhurst, @aliiae, @mirfan899, @ohenrik, @btrungchi, @kleinay, @DuyguA, @stefan-it, @Eleni170, @datascouting, @tjkemp, @x-ji, @giannisdaras, @kororo and @katarkor for the pull requests and contributions.",21467110
155,False,False,2018-04-04T09:19:11Z,2018-04-04T09:52:00Z,"### [📊 Help us improve spaCy and take the User Survey 2018!](https://survey.spacy.io/)

---

## ✨ New features and improvements

* **NEW:** Alpha [Vietnamese](spacy/lang/vi) support with tokenization via [Pyvi](https://github.com/trungtv/pyvi).
* **NEW:** Improved system for error messages and warnings. Errors now have unique error codes and are referenced in one place, and all unspecified `assert`s have been replaced with descriptive errors. See #2163 for implementation details, and let us know if you have any suggestions for errors and warnings in #2164!
* Improve language data for [Polish](spacy/lang/pl).
* Tidy up dependencies and drop `six`, `html5lib`, `ftfy` and `requests`.
* Improve efficiency (and potentially accuracy) of beam-search training, by randomly using greedy updates for some sentences. This can be controlled by changing the `beam_update_prob` entry in `nlp.parser.cfg`. The default value is 0.5, so 50% of beam updates will be done as greedy updates. 

## 🔴 Bug fixes

* Fix issue #1554, #1752, #2159: Fix `Token.ent_iob` after `Doc.merge()`, and ensure consistency in `Doc.ents`.
* Fix issue #1660: Fix loading of multiple vector models.
* Fix issue #1967: Allow entity types with dashes.
* Fix issue #2032: Fix accidentally quadratic runtime in `Vocab.set_vector`.
* Fix issue #2050: Correct mistakes in Italian lemmatizer data.
* Fix issue #2073: Make `Token.set_extension` work as expected.
* Fix issue #2100, #2151, #2181: Drop `six` and `html5lib` and prevent dependency conflict with TensorFlow / Keras.
* Fix issue #2101: Improve error message if token text is empty string.
* Fix issue #2121: Fix `Language.to_bytes` and pickling in Thinc.
* Fix issue #2156: Fix hashtag example in `Matcher` docs. 
* Fix issue #2177: Don't raise error in `set_extension` if `getter` and `setter` are specified or if `default=None`, and add error if `setter` is specified with no `getter`.

## 📖 Documentation and examples

* Add [example for TensorBoard's standalone embedding projector](examples/vectors_tensorboard_standalone.py).
* Improve [example for training a new entity type](examples/training/train_new_entity_type.py).
* Add formal [`CITATION`](CITATION) for [assigning a DOI](https://guides.github.com/activities/citable-code/) via Zenodo.

## 👥 Contributors

Thanks to @jimregan, @justindujardin, @trungtv, @katrinleinweber and @skrcode for the pull requests and contributions.",21467110
156,False,False,2018-03-23T21:00:23Z,2018-03-23T22:48:06Z,"## 🔴 Bug fixes

* Fix issue #2112: Avoid `import pip` to ensure compatibility with pip v9.0.2 which deprecated this usage. See pypa/pip#5081 for more details.

## 👥 Contributors

Thanks to @mdcclv for the pull request!",21467110
157,False,False,2018-03-24T17:09:03Z,2018-03-24T18:03:47Z,"### [📊 Help us improve spaCy and take the User Survey 2018!](https://survey.spacy.io/)

---

## ✨ New features and improvements

* Improve language data for [Turkish](spacy/lang/tr) and [Croatian](spacy/lang/hr).
* Add built-in factories for `merge_entities` and `merge_noun_chunks` to allow models to specify those components as part of their pipeline.

```python
merge_entities = nlp.create_pipe('merge_entities')
nlp.add_pipe(merge_entities, after='ner')
```

## 🔴 Bug fixes

* Fix issue #2012: Fix Spanish `noun_chunks` failure caused by typo.
* Fix issue #2040: Make sure `Token.lemma` always returns a hash value.
* Fix issue #2063: Correct typo in English lookup lemmatization table.
* Fix issue #2103: Correct typo in documentation.
* Fix pickling of `Vectors` class.

## 📖 Documentation and examples

* [Add example](examples/vectors_tensorboard.py) for visualizing spaCy vectors with the TensorBoard Embedding Projector.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @thomasopsomer, @alldefector, @DuyguA, @dejanmarich, @justindujardin, @calumcalder, @SebastinSanty, @iann0036, @doug-descombaz and @willismonroe for the pull requests and contributions.",21467110
158,False,False,2018-02-22T16:07:53Z,2018-02-22T17:32:59Z,"### [📊 Help us improve spaCy and take the User Survey 2018!](https://survey.spacy.io/)

---

## 🔴 Bug fixes

* Fix issue #2015: Pin `msgpack-python` to `0.5.4` to avoid conflict with new `msgpack` release.",21467110
159,False,True,2018-07-10T11:51:45Z,2018-07-21T14:14:18Z,"**🌙 This is an alpha pre-release of spaCy v2.1.0 and available on pip as [`spacy-nightly`](https://pypi.python.org/pypi/spacy-nightly). It's not intended for production use.**

```bash
pip install -U spacy-nightly
```

If you want to test the new version, we recommend using a new virtual environment. Also make sure to download the new models – see below for details and benchmarks.

## ✨ New features and improvements

### Tagger, Parser & NER

* **NEW:** Allow parser to do joint word segmentation and parsing. If you pass in data where the tokenizer over-segments, the parser now learns to merge the tokens.
* Make parser, tagger and NER faster, through better hyperparameters.
* Fix bugs in beam-search training objective.
* Remove document length limit during training, by implementing faster Levenshtein alignment.
* Use [Thinc v6.11](https://github.com/explosion/thinc/releases/tag/v6.11.1), which defaults to single-thread with fast OpenBLAS kernel. Parallelisation should be performed at the task level, e.g. by running more containers.

### Models & Language Data
* **NEW:** Small accuracy improvements for parsing, tagging and NER for 6+ languages.
* **NEW:** The English and German models are now available under the MIT license.

### CLI

* **NEW:** New `ud-train` command, to train and evaluate using the CoNLL 2017 shared task data.
* Check if model is already installed before downloading it via `spacy download`.
* Pass additional arguments of `download` command to `pip` to customise installation.
* Improve `train` command by letting `GoldCorpus` stream data, instead of loading into memory.
* Improve `init-model` command, including support for lexical attributes and word-vectors, using a variety of formats. This replaces the `spacy vocab` command, which is now deprecated.

### Other

* **NEW:** `Doc.retokenize` context manager for merging tokens more efficiently.
* **NEW:** Add support for custom pipeline component factories via entry points (#2348).
* **NEW:** Implement [fastText](https://fasttext.cc/) vectors with subword features.
* Add warnings if `.similarity` method is called with empty vectors or without word vectors.
* Improve rule-based `Matcher` and add `return_matches` keyword argument to `Matcher.pipe` to yield `(doc, matches)` tuples instead of only `Doc` objects, and `as_tuples` to add context to the `Doc` objects.
* Make stop words via `Token.is_stop` and `Lexeme.is_stop` case-insensitive.

> ### 🚧 Under construction
>
> This section includes new features and improvements that are planned for the stable `v2.1.x` release, but aren't included in the nightly yet.
>
> * Enhanced pattern API for rule-based `Matcher` (see #1971).
> * Built-in rule-based NER component to add entities based on match patterns (see #2513).
> * Improve tokenizer performance (see #1642).
> * Allow retokenizer to update `Lexeme` attributes on merge (see #2390).
> * `md` and `lg` models and new, pre-trained word vectors for German, French, Spanish, Italian, Portuguese and Dutch.

## 🔴 Bug fixes

* Fix issue #1487: Add `Doc.retokenize()` context manager.
* Fix issue #1574: Make sure stop words are available in medium and large English models.
* Fix issue #1665: Correct typos in symbol `Animacy_inan` and add `Animacy_nhum`.
* Fix issue #1865: Correct licensing of `it_core_news_sm` model.
* Fix issue #1889: Make stop words case-insensitive.
* Fix issue #1903: Add `relcl` dependency label to symbols.
* Fix issue #2014: Make `Token.pos_` writeable.
* Fix issue #2369: Respect pre-defined warning filters.
* Fix serialization of custom tokenizer if not all functions are defined.

## ⚠️ Backwards incompatibilities

* This version of spaCy requires downloading **new models**. You can use the [`spacy validate`](https://spacy.io/api/cli#validate) command to find out which models need updating, and print update instructions.
* If you've been training **your own models**, you'll need to **retrain them** with the new version.
* While the `Matcher` API is fully backwards compatible, its algorithm has changed to fix a number of bugs and performance issues. This means that the `Matcher` in `v2.1.x` may produce different results compared to the `Matcher` in `v2.0.x`.
* Also note that some of the model licenses have changed: `it_core_news_sm` is now correctly licensed under CC BY-NC-SA 3.0, and all English and German models are now published under the MIT license.

## 📈 Benchmarks

| Model | Version | UAS | LAS | POS | NER F | Vec | Size |
| --- | ---: | ---: | ---: | ---: | ---: | :---: | ---: |
| `en_core_web_sm` | 2.1.0a0 | 91.8 | 90.0 | 96.8 | 85.6 | 𐄂 | 28 MB |
| `en_core_web_md` | 2.1.0a0 | 92.0 | 90.2 | 97.0 | 86.2 | ✓ | 107 MB |
| `en_core_web_lg` | 2.1.0a0 | 92.1 | 90.3 | 97.0 | 86.2 | ✓ | 805 MB |
| `de_core_news_sm` | 2.1.0a0 | 92.0 | 90.1 | 97.2 | 83.8 | 𐄂 | 26 MB |
| `de_core_news_md` | 2.1.0a0 | 92.4 | 90.7 | 97.4 | 84.2 | ✓ | 228 MB |
| `es_core_news_sm` | 2.1.0a0 | 90.1 | 87.2 | 96.9 | 89.4 | 𐄂 | 28 MB |
| `es_core_news_md` | 2.1.0a0 | 90.7 | 88.0 | 97.2 | 89.5 | ✓ | 88 MB |
| `pt_core_news_sm` | 2.1.0a0 | 89.4 | 86.3 | 80.1 | 82.7 | 𐄂 | 29 MB |
| `fr_core_news_sm` | 2.1.0a0 | 88.8 | 85.7 | 94.4 | 67.3 <sup>1</sup> | 𐄂 | 32 MB |
| `fr_core_news_md` | 2.1.0a0 | 88.7 | 86.0 | 95.0 | 70.4 <sup>1</sup> | ✓ | 100 MB |
| `it_core_news_sm` | 2.1.0a0 | 90.7 | 87.1 | 96.1 | 81.3 | 𐄂 | 27 MB |
| `nl_core_news_sm` | 2.1.0a0 | 83.5 | 77.6 | 91.5 | 87.3 | 𐄂 | 27 MB |
| `xx_ent_wiki_sm` | 2.1.0a0 | - | - | - | 83.8 | 𐄂 | 9 MB |

1) We're currently investigating this, as the results are anomalously low.

> 💬 **UAS:** Unlabelled dependencies (parser). **LAS:** Labelled dependencies (parser). **POS:** Part-of-speech tags (fine-grained tags, i.e. `Token.tag_`). **NER F:** Named entities (F-score). **Vec:** Model contains word vectors. **Size:** Model file size (zipped archive).

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @DuyguA for the pull requests and contributions.",21467110
160,False,False,2018-02-18T11:16:31Z,2018-02-18T12:25:51Z,"### [📊 Help us improve spaCy and take the User Survey 2018!](https://survey.spacy.io/)

---

## ✨ New features and improvements

* **NEW**: Lexical attribute `IS_CURRENCY` via `Token.is_currency` for currency symbols.
* Add `noun_chunks` syntax iterator for Norwegian.
* Add `get_beam_parse` method in `ArcEager`.
* Revert changes to the `Matcher` in favour of the new and improved API (#1971) coming in v2.1.0.

## 🔴 Bug fixes

* Fix issue #1706: Ensure files opened in `from_disk` are closed.
* Fix issue #1733: Make model loading from package compatible with Python 3.4.
* Fix issue #1832, #1928: Fix vector handling in `init_model` command.
* Fix issue #1915: Pass in hyperparameters correctly during `begin_training`.
* Fix issue #1924: Require `html5lib` in `setup.py` to prevent `six` error.
* Fix issue #1929: Correctly handle NER with pre-set sentence boundaries.
* Fix issue #1941: Improve documentation around model symlink on Windows.
* Fix issue #1949: Correct `Matcher` docs to only include `ORTH` and `LOWER`.
* Fix issue #1950: Fix bug in regex `Matcher` example.
* Fix issue #1959: Execute custom pipeline component when using `Language.pipe`.
* Fix issue #1964: Correct typo in glossary.
* Fix issue #1974: Don't set `random.seed` globally in CLI commands.
* Fix issue #1989: Correct documentation of `match_id` and improve example.

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @ohenrik, @tokestermw, @azarezade, @piratos, @mhaddy, @pktippa, @mdcclv, @oxinabox, @SThomasP, @DuyguA, @emulbreh, @ursachec and @enerrio for the pull requests and contributions.",21467110
161,False,False,2018-02-02T02:39:16Z,2018-02-02T02:58:04Z,"## 🔴 Bug fixes

* Fix issue #1919: Fix missing config property in parser when resuming training.",21467110
162,False,False,2018-02-01T01:57:52Z,2018-02-01T03:47:09Z,"## ✨ New features and improvements

* Alpha tokenization support for [Persian](spacy/lang/fa).
* Add lookup lemmatizer for [Turkish](spacy/lang/tr).
* Add lookup lemmatizer and tag map for [Norwegian](spacy/lang/nb) and improve tokenizer exceptions.
* Improve model downloading and linking and use proper exit codes in CLI commands.

## 🔴 Bug fixes

* Fix issue #1503: Fix `Matcher` bugs and behaviour of `*` and `+` operators. 
* Fix issue #1539: Fix `Vectors.resize` on Python 3.
* Fix issue #1591: Fix compiler flags and remove `march=native`.
* Fix issue #1606, #1698: Ensure `LIKE_URL` doesn't return `True` for email addresses.
* Fix issue #1622: Use `nlp.to_disk` in `spacy train` command.
* Fix issue #1633: Add missing `Span.vocab` property.
* Fix issue #1640:  Fix infinite recursion in `token.sent_start`.
* Fix issue #1663, #1721, #1761, #1780: Download models with `--no-deps` to avoid conda errors.
* Fix issue #1712, #1813: Don't raise deprecation warning in property.
* Fix issue #1714: Make sure `download` and `validate` commands exit correctly.
* Fix issue #1727: Dont overwrite `pretrained_dims` setting from cfg.
* Fix issue #1728: Correct `TextCategorizer` documentation.
* Fix issue #1750: Remove non-breaking spaces from Hindi examples.
* Fix issue #1757: Fix rich comparison against `None` objects.
* Fix issue #1758: Add English tokenizer exception for ""would've"".
* Fix issue #1769: Make `LIKE_NUM` case-insensitive.
* Fix issue #1774: Allow pickling of `Chinese` language class.
* Fix issue #1781: Add missing dev dependency.
* Fix issue #1799: Set `l_edge` and `r_edge` correctly for non-projective parses.
* Fix issue #1807: Make `set_vector` add word to vocab.
* Fix issue #1820: Correct documentation of `Matcher` operators.
* Fix issue #1831: Allow vector loading to work on 1d data files.
* Fix issue #1834: Fix sentence boundaries serialization.
* Fix issue #1838: Clarify hyperparameters and alias usage in `spacy train`.
* Fix issue #1851: Fix typo and use better serialization example.
* Fix issue #1868: Make `Vocab.__contains__` work with ints.
* Fix issue #1883: Fix unpickling of `Matcher`.
* Fix issue #1911: Improve error handling if pipeline component is not callable.
* Fix issues with `spacy init_model` command.

## 📖 Documentation and examples

* Update list of community [plugins and extensions](https://spacy.io/usage/resources#extensions).
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @cbilgili, @melanuria, @mpuels, @IsaacHaze, @sorenlind, @Bri-Will, @d99kris, @mdda, @kimfalk, @benjaminp, @zqhZY, @avinashrubird, @nirdesh37, @kwhumphreys, @fucking-signup, @wrathagom, @pbnsilva, @savkov, @matatusko, @GregDubbin, @avadhpatel, @azarezade, @ohenrik, @azarezade, @thomasopsomer, @Kimahriman and @hassanshamim for the pull requests and contributions.",21467110
163,False,False,2017-12-07T09:39:32Z,2017-12-07T10:01:35Z,"## ✨ New features and improvements

* Add `spacy init-model` command to create a model directory from raw data (similar to the `spacy model` command in v1.x).

## 🔴 Bug fixes

* Fix an issue with the vector pickling that would cause vectors to be set to `None`.

## 📖 Documentation and examples

* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @mpuels and @GreenRiverRUS for the pull requests and contributions.",21467110
164,False,False,2017-12-06T12:24:02Z,2017-12-06T12:39:42Z,"## ✨ New features and improvements

* Alpha support for [Russian](spacy/lang/ru) via [pymorphy2](https://github.com/kmike/pymorphy2).
* Improve language data for [Danish](spacy/lang/da), [Italian](spacy/lang/it) and [Dutch](spacy/lang/nl).
* Add `offsets_from_biluo_tags` helper to convert BILUO notation to entity offsets.
* Use `POS` instead of `TAG` by default in displaCy, to prevent visualisation issues in languages with long combined tags (e.g. Italian or Dutch).
* Drop support for EOL Python 2.6 and 3.3.

## 🔴 Bug fixes

* Fix issue #1207: Fix `Span.noun_chunks`.
* Fix issue #1494: Handle sequential infixes in tokenizer rules.
* Fix issue #1587: Add note on attribute extension default arguments in docs.
* Fix issue #1599: Fix typo in documentation.
* Fix issue #1612: Ensure that `Span.orth_ == Span.text`.
* Fix issue #1617: Make `entity_relations.py` example Python 2 compatible and fix French test.
* Fix issue #1654: Fix off-by-one error in `nlp.add_pipe` when using `after`.
* Fix issue #1674: Set correct requirement string in `spacy package`.
* Fix issue with `StringStore` cleanup.

## 📖 Documentation and examples

* Update resources page with new [spaCy extensions](https://spacy.io/usage/resources#extensions).
* Add ""Unknown locale"" error to [troubleshooting guide](https://spacy.io/usage/#unknown-locale).
* Always use `python -m spacy` for CLI commands again to prevent issues on Windows etc.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @ligser, @pavillet, @yuukos, @GreenRiverRUS, @MartinoMensio, @raphael0202, @tokestermw, @fsonntag, @cclauss, @bdewilde, @markulrich, @sorenlind, @hugovk, @atomobianco, @twerkmeister, @mkdynamic and @jimregan for the pull requests and contributions.",21467110
165,False,False,2017-11-15T15:14:46Z,2017-11-15T15:50:58Z,"## ✨ New features and improvements

* Require [Thinc](https://github.com/explosion/thinc) `v6.10.1` to fix GPU installation fix and beam parsing.
* Improve Turkish stop words. 
* Improve Hindi stop words.

## 🔴 Bug fixes

* Fix issue #1248: Update English tokenizer and norm exceptions for ""-in"" and ""-in'"" verbs.
* Fix issue #1506: Fix `KeyError` from cleaning up strings during `Language.pipe` (work in progress).
* Fix issue #1521: Ensure path in `Doc.to_disk` and `Doc.from_disk`.
* Fix issue #1525, #1582: Update [fastText example](examples/vectors_fast_text.py) to accommodate whitespace.
* Fix issue #1541: Remove broken link from documentation.
* Fix issue #1546: Add missing import to make `util.minibatch` work correctly.
* Fix issue #1557: Add dummy serialization methods to Japanese tokenizer to allow saving and loading models.
* Fix caching in `Tokenizer` (partially addresses performance regression in #1371 and #1508).

## 📖 Documentation and examples

* Add [""Videos"" section](https://spacy.io/usage/resources#videos) to resources.
* Update [training tips and advice](https://spacy.io/usage/training#tips) section.
* Re-add `python -m` to CLI commands to ensure cross-platform compatibility.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @MathiasDesch, @mcsalgado, @Wahib, @ligser, @abhi18av, @DuyguA, @KMLDS and @yogendrasoni  for the pull requests and contributions.",21467110
166,False,False,2017-11-08T21:39:39Z,2017-11-08T22:15:58Z,"## ✨ New features and improvements

* Add text examples for Hindi.

## 🔴 Bug fixes

* Fix issue #1507, #1512, #1513, #1514, #1516: Improve new documentation and list of backwards incompatibilities.
* Fix issue #1515: Correct print statement in [`train_textcat.py`](examples/training/train_textcat.py) example.
* Fix issue #1518: Make `Vectors.resize` work as expected.
* Fix conda build.

## 👥 Contributors

Thanks to @danielhers and @abhi18av  for the pull requests.",21467110
167,False,False,2017-11-08T02:01:16Z,2017-11-08T02:29:13Z,"## 🔴 Bug fixes

* Fix syntax error in language data examples that prevented conda build.",21467110
168,False,False,2017-11-07T21:41:54Z,2017-11-07T22:14:40Z,"We're very excited to finally introduce **[spaCy v2.0](https://spacy.io/usage/v2)**. The new version gets spaCy up to date with the latest deep learning technologies and makes it much easier to run spaCy in scalable cloud computing workflows. We've fixed over **60 bugs** (*every* open bug!), including several long-standing issues, trained **13 neural network models** for **7+ languages** and added alpha tokenization support for **8 new languages**. We also re-wrote almost all of the **usage guides, API docs and code examples**.

```bash
pip install -U spacy
```

```bash
conda install -c conda-forge spacy
```

## ✨ Major features and improvements

* **NEW:** Convolutional neural network models for [English](https://spacy.io/models/en), [German](https://spacy.io/models/de), [Spanish](https://spacy.io/models/es), [Portuguese](https://spacy.io/models/pt), [French](https://spacy.io/models/fr), [Italian](https://spacy.io/models/it), [Dutch](https://spacy.io/models/nl) and [multi-language](https://spacy.io/models/xx) NER. Substantial improvements in accuracy over the v1.x models.
* **NEW:** `Vectors` class for [managing word vectors](https://spacy.io/usage/vectors-similarity#custom), plus trainable document vectors and contextual similarity via convolutional neural networks.
* **NEW:** Custom [processing pipeline components](https://spacy.io/usage/processing-pipelines#custom-components) and extension attributes on the `Doc`, `Token` and `Span` via `Doc._`, `Token._` and `Span._`.
* **NEW:** Built-in, trainable [text classification](https://spacy.io/usage/training#textcat) pipeline component.
* **NEW:** Built-in [displaCy visualizers](https://spacy.io/usage/visualizers) for dependencies and entities, with Jupyter notebook support.
* **NEW:** Alpha tokenization for [Danish](spacy/lang/da), [Polish](spacy/lang/pl), [Indonesian](spacy/lang/id), [Thai](spacy/lang/th), [Hindi](spacy/lang/hi), [Irish](spacy/lang/ga), [Turkish](spacy/lang/tr), [Croatian](spacy/lang/hr) and [Romanian](spacy/lang/ro).
* Improved language data, support for lazy loading and simple, [lookup-based lemmatization](https://spacy.io/usage/adding-languages#lemmatizer) for English, German, French, Spanish, Italian, Hungarian, Portuguese and Swedish.
* Support for [multi-language](https://spacy.io/usage/models#multi-language) models and new `MultiLanguage` class (`xx`).
* Strings are now resolved to [hash values](https://spacy.io/usage/spacy-101#vocab), instead of mapped to integer IDs. This means that the string-to-int mapping no longer depends on the vocabulary state.
* Improved and consistent saving, loading and serialization across objects, plus Pickle support.
* `PhraseMatcher` for [matching large terminology lists](https://spacy.io/usage/linguistic-features#adding-phrase-patterns) as `Doc` objects, plus revised `Matcher` API.
* New CLI commands [`validate`](https://spacy.io/api/cli#validate), [`vocab`](https://spacy.io/api/cli#vocab) and [`evaluate`](https://spacy.io/api/cli#evaluate), plus entry point for `spacy` command to use instead of `python -m spacy`.
* Experimental GPU support via [Chainer](http://chainer.org)'s CuPy module.

## 🔮 Models

spaCy v2.0 comes with **13 new** convolutional neural network models for **7+ languages**. The models have been designed and implemented from scratch specifically for  spaCy. A novel bloom embedding strategy with subword features is used to support huge vocabularies in tiny tables.

All `core` models include **part-of-speech tags**, **dependency labels** and **named entities**. Small models include only context-specific token vectors, while medium-sized and large models ship with word vectors. For more details, see the [models directory](https://spacy.io/models) or try our new [model comparison tool](https://spacy.io/models/comparison).

| Name | Language | Features | Size |
| --- | --- | --- | ---: |
| [`en_core_web_sm`](https://spacy.io/models/en#en_core_web_sm) | English | Tagger, parser, entities | 35 MB |
| [`en_core_web_md`](https://spacy.io/models/en#en_core_web_md) | English | Tagger, parser, entities, vectors | 115 MB |
| [`en_core_web_lg`](https://spacy.io/models/en#en_core_web_lg) | English | Tagger, parser, entities, vectors | 812 MB |
| [`en_vectors_web_lg`](https://spacy.io/models/en#en_vectors_web_lg) | English | Vectors | 627 MB |
| [`de_core_news_sm`](https://spacy.io/models/de#de_core_news_sm) | German | Tagger, parser, entities | 36 MB |
| [`es_core_news_sm`](https://spacy.io/models/es#es_core_news_sm) | Spanish | Tagger, parser, entities | 35 MB |
| [`es_core_news_md`](https://spacy.io/models/es#es_core_news_md) | Spanish | Tagger, parser, entities, vectors | 93 MB |
| [`pt_core_news_sm`](https://spacy.io/models/pt#pt_core_news_sm) | Portuguese | Tagger, parser, entities | 36 MB |
| [`fr_core_news_sm`](https://spacy.io/models/fr#fr_core_news_sm) | French | Tagger, parser, entities | 37 MB |
| [`fr_core_news_md`](https://spacy.io/models/fr#fr_core_news_md) | French | Tagger, parser, entities, vectors | 106 MB |
| [`it_core_news_sm`](https://spacy.io/models/it#it_core_news_sm) | Italian | Tagger, parser, entities | 34 MB |
| [`nl_core_news_sm`](https://spacy.io/models/nl#nl_core_news_sm) | Dutch | Tagger, parser, entities | 34 MB |
| [`xx_ent_wiki_sm`](https://spacy.io/models/xx#xx_ent_wiki_sm) | Multi-language | Entities | 33MB |

You can download a model by using its name or shortcut. To load a model, use `spacy.load()`, or import it as a module and call its `load()` method:

```bash
spacy download en_core_web_sm
```

```python
import spacy
nlp = spacy.load('en_core_web_sm')

import en_core_web_sm
nlp = en_core_web_sm.load()
```

## 📈 Benchmarks

spaCy v2.0's new neural network models bring significant improvements in accuracy, especially for English Named Entity Recognition. The new [`en_core_web_lg`](https://spacy.io/models/en#en_core_web_lg) model makes about **25% fewer mistakes** than the corresponding v1.x model and is within **1% of the current state-of-the-art** ([Strubell et al., 2017](https://arxiv.org/pdf/1702.02098.pdf)). The v2.0 models are also cheaper to run at scale, as they require **under 1 GB of memory** per process.

### English

| Model | spaCy | Type | UAS | LAS | NER F | POS | Size |
| --- | ---: | :---: | ---: | ---: | ---: | ---: | ---: |
| `en_core_web_sm-2.0.0` | v2.x | neural | 91.7 | 89.8 | 85.3 | 97.0 | **35MB** |
| `en_core_web_md-2.0.0` | v2.x | neural | 91.7 | 89.8 | **85.9** | 97.1 | 115MB |
| `en_core_web_lg-2.0.0` | v2.x | neural | **91.9** | **90.1** | **85.9** | **97.2** | 812MB |
| `en_core_web_sm-1.1.0` | v1.x | linear | 86.6 | 83.8	| 78.5 | 96.6 | 50MB |
| `en_core_web_md-1.2.1` | v1.x | linear | 90.6 | 88.5 | 81.4 | 96.7 | 1GB |

### Spanish

| Model | spaCy | Type | UAS | LAS | NER F | POS | Size |
| --- | ---: | :---: | ---: | ---: | ---: | ---: | ---: |
| `es_core_news_sm-2.0.0` | v2.x | neural | 89.8 | 86.8 | 88.7 | **96.9** | **35MB** |
| `es_core_news_md-2.0.0` | v2.x | neural | **90.2** | 87.2 | 89.0 | 97.8 | 93MB |
| `es_core_web_md-1.1.0` | v1.x | linear | 87.5 | *n/a* | **94.2** | 96.7 | 377MB |

For more details of the other models, see the [models directory](https://spacy.io/models) and [model comparison tool](https://spacy.io/models/comparison).

## 🔴 Bug fixes

* Fix issue #125, #228, #299, #377, #460, #606, #930: Add full Pickle support.
* Fix issue #152, #264, #322, #343, #437, #514, #636, #785, #927, #985, #992, #1011: Fix and improve serialization and deserialization of `Doc` objects.
* Fix issue #285, #1225: Fix memory growth problem when streaming data.
* Fix issue #512: Improve parser to prevent it from returning two `ROOT` objects.
* Fix issue #519, #611, #725: Retrain German model with better tokenized input.
* Fix issue #524: Improve parser and handling of noun chunks.
* Fix issue #621: Prevent double spaces from changing the parser result.
* Fix issue #664, #999, #1026: Fix bugs that would prevent loading trained NER models.
* Fix issue #671, #809, #856: Fix importing and loading of word vectors.
* Fix issue #683, #1052, #1442: Don't require tag maps to provide `SP` tag.
* Fix issue #753: Resolve bug that would tag OOV items as personal pronouns.
* Fix issue #860, #956, #1085, #1381: Allow custom attribute extensions on `Doc`, `Token` and `Span`.
* Fix issue #905, #954, #1021, #1040, #1042: Improve parsing model and allow faster accuracy updates.
* Fix issue #933, #977, #1406: Update [online demos](https://demos.explosion.ai).
* Fix issue #995: Improve punctuation rules for Hebrew and other non-latin languages.
* Fix issue #1008: `train` command finally works correctly if used without `dev_data`.
* Fix issue #1012: Improve word vectors documentation.
* Fix issue #1043: Improve NER models and allow faster accuracy updates.
* Fix issue #1044: Fix bugs in French model and improve performance.
* Fix issue #1051: Improve error messages if functionality needs a model to be installed.
* Fix issue #1071: Correct typo of ""whereve"" in English tokenizer exceptions.
* Fix issue #1088: Emoji are now split into separate tokens wherever possible.
* Fix issue #1240: Allow merging `Span`s without keyword arguments.
* Fix issue #1243: Resolve undefined names in deprecated functions.
* Fix issue #1250: Fix caching bug that would cause tokenizer to ignore special case rules after first parse.
* Fix issue #1257: Ensure the compare operator `==` works as expected on tokens.
* Fix issue #1291: Improve documentation of training format.
* Fix issue #1336: Fix bug that caused inconsistencies in NER results.
* Fix issue #1375: Make sure `Token.nbor` raises `IndexError` correctly.
* Fix issue #1450: Fix error when OP quantifier `""*""` ends the match pattern.
* Fix issue #1452: Fix bug that would mutate the original text.

## 📖 Documentation and examples

* **NEW:** Completely rewritten, reorganised and redesigned [usage](https://spacy.io/usage) and [API](https://spacy.io/api) docs, plus [models directory](https://spacy.io/models) and [model comparison tool](https://spacy.io/models/comparison).
* **NEW:** [spacy 101 guide](https://spacy.io/usage/spacy-101) with simple explanations and illustrations of the most important concepts and an overview of spaCy's features and capabilities.
* Documentation on [custom processing pipelines](https://spacy.io/usage/processing-pipelines), [visualizers](https://spacy.io/usage/visualizers), detailed [training tutorials](https://spacy.io/usage/training) and improved guides on [word vectors](https://spacy.io/usage/vectors-similarity) and [rule-based matching](https://spacy.io/usage/linguistic-features#section-rule-based-matching).
* Updated [code examples](spacy/examples) for training, information extraction and pipeline management.

## ⚠️ Backwards incompatibilities
For the complete table and more details, see the guide on [what's new in v2.0](https://spacy.io/usage/v2).

**Note that the old v1.x models are not compatible with spaCy v2.0.0.** If you've trained your own models, you'll have to **re-train them** to be able to use them with the new version. For a full overview of changes in v2.0, see the [documentation](https://spacy.io/usage/v2) and guide on [migrating from spaCy 1.x](https://spacy.io/usage/v2#migrating).

### Document processing

The `Language.pipe` method allows spaCy to batch documents, which brings a **significant performance advantage** in v2.0. The new neural networks introduce some overhead per batch, so if you're processing a number of documents in a row, you should use `nlp.pipe` and process the texts as a stream.

```python
docs = nlp.pipe(texts)
# BAD: docs = (nlp(text) for text in texts)
```

To make usage easier, there's now a boolean `as_tuples` keyword argument, that lets you pass in an iterator of `(text, context)` pairs, so you can get back an iterator of `(doc, context)` tuples.

### Loading models

[`spacy.load()`](https://spacy.io/api/top-level#spacy) is now **only intended for loading models** – if you need an empty language class, import it directly instead, e.g. `from spacy.lang.en import English`. If the model you're loading is a shortcut link or package name, spaCy will expect it to be a **model package**, import it and call its `load()` method. If you supply a path, spaCy will expect it to be a **model data directory** and use the meta.json to initialise a language class and call `nlp.from_disk()` with the data path.

```python
nlp = spacy.load('en')
nlp = spacy.load('en_core_web_sm')
nlp = spacy.load('/model-data')
nlp = English().from.disk('/model-data')
# OLD: nlp = spacy.load('en', path='/model-data')
```

### Training

All built-in pipeline components are now subclasses of `Pipe`, fully [trainable](https://spacy.io/usage/training) and serializable, and follow the same API. Instead of updating the model and telling spaCy when to *stop*, you can now explicitly call `begin_training`, which returns an optimizer you can pass into the `update` function. While `update` still accepts sequences of `Doc` and `GoldParse` objects, you can now also pass in a list of strings and dictionaries describing the annotations. This is the recommended usage, as it removes one layer of abstraction from the training.

```python
optimizer = nlp.begin_training()
for itn in range(1000):
    for texts, annotations in train_data:
        nlp.update(texts, annotations, sgd=optimizer)
nlp.to_disk('/model')
```

### Serialization

spaCy's [serialization API](https://spacy.io/usage/training#saving-loading) is now consistent across objects. All containers and pipeline components have `.to_disk()`, `.from_disk()`, `.to_bytes()` and `.from_bytes()` methods.

```python
nlp.to_disk('/model')
nlp.vocab.to_disk('/vocab')
# OLD: nlp.save_to_directory('/model')
```

### Processing pipelines and attribute extensions

Models can now define their own [processing pipelines](https://spacy.io/usage/processing-pipelines) as a list of strings, mapping to component names. Components receive a `Doc`, modify it and return it to be processed by the next component in the pipeline. You can add custom components to `nlp.pipeline` and create extensions to add custom attributes, properties and methods to the `Doc`, `Token` and `Span` objects.

```python
nlp = spacy.load('en')
my_component = MyComponent()
nlp.add_pipe(my_component, before='tagger')

Doc.set_extension('my_attr', default=True)
doc = nlp(u""This is a text."")
assert doc._.my_attr
```

## 👥 Contributors

This release is brought to you by @honnibal and @ines. Thanks to @Gregory-Howard, @luvogels, @Ferdous-Al-Imran, @uetchy, @akYoung, @kengz, @raphael0202, @ardeego, @yuvalpinter, @dvsrepo, @frascuchon, @oroszgy, @v3t3a, @Tpt, @thinline72, @jarle, @jimregan, @nkruglikov, @delirious-lettuce, @geovedi, @wannaphongcom, @h4iku, @IamJeffG, @binishkaspar, @ramananbalakrishnan, @jerbob92, @mayukh18, @abhi18av and @uwol for the pull requests and contributions. Also thanks to everyone who submitted bug reports and took the spaCy user survey – your feedback made a big difference!
",21467110
169,False,False,2017-11-07T11:11:08Z,2017-11-07T11:41:45Z,"> ⚠️ **Important note:** This is a bridge release that gets the current state of the v1.x branch published. Stay tuned for v2.0.

## ✨ Major features and improvements

* **NEW:** Alpha tokenization support for [Thai](spacy/lang/th) and [Russian](spacy/lang/ru).
* **NEW:** Alpha support for Japanese part-of-speech tagging.
* **NEW:** Dependency pattern-matching algorithm (see #1120).
* Add support for getting a lowest common ancestor matrix via `Doc.get_lca_matrix()`.
* Improve capturing of English noun chunks.


## 🔴 Bug fixes

* Fix issue #1078: Simplify URL pattern.
* Fix issue #1174: Fix NER model loading bug and make sure JSON keys are loaded as strings.
* Fix issue #1291: Document correct JSON format for training.
* Fix issue #1292: Fix error when adding custom infix rules.
* Fix issue #1387: Ensure that lemmatizer respects exception rules.
* Fix issue #1410: Support single value for attribute list in `Doc.to_scalar` and `Doc.to_array`.

## 📖 Documentation and examples

* Document correct JSON format for training.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @raphael0202, @gideonite, @delirious-lettuce, @polm, @kevinmarsh, @IamJeffG, @Vimos, @ericzhao28, @galaxyh, @hscspring, @wannaphongcom, @Wellan89, @kokes, @mdcclv, @ameyuuno, @ramananbalakrishnan, @Demfier, @johnhaley81, @mayukh18 and @jnothman for the pull requests and contributions.",21467110
170,False,False,2017-07-22T14:20:19Z,2017-07-22T16:28:50Z,"**Thanks to all of you for 5,000 stars on GitHub, the valuable feedback in the user survey and testing [spaCy v2.0 alpha](https://alpha.spacy.io/docs/usage/v2).** We're working hard on getting the new version ready and can't wait to release it. In the meantime, here's a new release for the 1.x branch that fixes a variety of outstanding bugs and adds capabilities for new languages.

💌 **P.S.:** If you haven't gotten your hands on a [set of spaCy stickers yet](https://twitter.com/i/moments/888736232112574464), you can still do so – send us a DM with your address on Twitter or Gitter, and we'll mail you some!


---

## ✨ Major features and improvements

* **NEW:** The first [official Spanish model](https://github.com/explosion/spacy-models/releases/tag/es_core_web_md-1.0.0) (377 MB) including vocab, syntax, entities and word vectors. Thanks to the amazing folks at [recogn.ai](http://recogn.ai) for the collaboration!

```bash
python -m spacy download es
```

```python
nlp = spacy.load('es')
doc = nlp(u'Esto es una frase.')
```

* **NEW:** Alpha tokenization for [Norwegian Bokmål](spacy/nb) and [Japanese](spacy/jp) (via [Janome](https://github.com/mocobeta/janome)).
* **NEW:** Allow dropout training for `Parser` and `EntityRecognizer`, using the `drop` keyword argument to the `update()` method.
* **NEW:** Glossary for POS, dependency and NER annotation scheme via `spacy.explain()`. For example, `spacy.explain('NORP')` will return ""Nationalities or religious or political groups"".
* Improve language data for [Dutch](spacy/nl), [French](spacy/fr) and [Spanish](spacy/es).
* Add `Language.parse_tree` method to generate POS tree for all sentences in a `Doc`.


## 🔴 Bug fixes

* Fix issue #1031: Close gaps in `Lexeme` API.
* Fix issue #1034: Add annotation scheme glossary and `spacy.explain()`.
* Fix issue #1051: Improved error messaging when trying to load non-existing model.
* Fix issue #1052: Add missing `SP` symbol to tag map.
* Fix issue #1061: Add `flush_cache` method to tokenizer.
* Fix issue #1069: Fix `Doc.sents` iterator when customised with generator.
* Fix issue ##1099, #1143: Improve documentation on models in `requirements.txt`.
* Fix issue #1137: Use lower min version for `requests` dependency.
* Fix issue #1207: Fix `Span.noun_chunks`.
* Fix issue with `six` and its dependencies that occasionally caused spaCy to fail.
* Fix typo in `package` command that caused error when printing error messages.

## 📖 Documentation and examples

* Fix various typos and inconsistencies.
* **NEW:** [spaCy 101 guide](https://alpha.spacy.io/docs/usage/spacy-101) for v2.0: all important concepts, explained with examples and illustrations. Note that some of the behaviour and examples are specific to v2.0+ – but the NLP basics are relevant independent of the spaCy version you're using.

## 👥 Contributors

Thanks to @kengz, @luvogels, @Ferdous-Al-Imran, @uetchy, @akYoung, @pasupulaphani, @dvsrepo, @raphael0202, @yuvalpinter, @frascuchon, @kootenpv, @oroszgy, @bartbroere, @ianmobbs, @garfieldnate, @polm, @callumkift, @swierh, @val314159, @lgenerknol and @jsparedes for the contributions!",21467110
171,False,True,2017-06-05T18:41:30Z,2017-06-05T19:05:12Z,"### [![PyPi](https://img.shields.io/pypi/v/spacy-nightly.svg?style=flat-square)](https://pypi.python.org/pypi/spacy-nightly) **Last update:** `2.0.0rc2`, 2017-11-07

**This is an alpha pre-release of spaCy v2.0.0 and available on pip as `spacy-nightly`. It's not intended for production use. The alpha documentation is available at [alpha.spacy.io](https://alpha.spacy.io/docs). Please note that the docs reflect the library's intended state on release, not the current state of the implementation. For bug reports, feedback and questions, see the [spaCy v2.0.0 alpha thread](https://github.com/explosion/spacy/issues/1105).**

Before installing v2.0.0 alpha, we recommend setting up a clean environment.

```bash
pip install spacy-nightly
```

[The models](https://github.com/explosion/spacy-models/releases) are still under development and will keep improving. For more details, see the benchmarks below. There will also be additional models for German, French and Spanish.

| Name | Lang | Capabilities | Size | spaCy | Info |
| --- | --- | --- | ---: | --- | :---: |
| `en_core_web_sm-2.0.0a4` | en | Parser, Tagger, NER | 42MB | `>=2.0.0a14` | [ℹ️](https://github.com/explosion/spacy-models/releases/en_core_web_sm-2.0.0-alpha4) |
| `en_vectors_web_lg-2.0.0a0` | en | Vectors ([GloVe](https://nlp.stanford.edu/projects/glove/)) | 627MB |  `>=2.0.0a10` | [ℹ️](https://github.com/explosion/spacy-models/releases/en_vectors_web_lg-2.0.0-alpha) |
| `xx_ent_wiki_sm-2.0.0a0` | multi | NER | 12MB | `<=2.0.0a9` | [ℹ️](https://github.com/explosion/spacy-models/releases/xx_ent_wiki_sm-2.0.0-alpha) |

You can download a model by using its name or shortcut. To load a model, use spaCy's loader, e.g. `nlp = spacy.load('en_core_web_sm') `, or import it as a module (`import en_core_web_sm`) and call its `load()` method, e.g `nlp = en_core_web_sm.load()`.

```bash
python -m spacy download en_core_web_sm
```

## 📈 Benchmarks

The evaluation was conducted on raw text with no gold standard information. Speed and accuracy are currently comparable to the v1.x models: speed on CPU is slightly lower, while accuracy is slightly higher. We expect performance to improve quickly between now and the release date, as we run more experiments and optimise the implementation.

| Model | spaCy | Type | UAS | LAS | NER F | POS | Words/s |
| --- | ---: | :---: | ---: | ---: | ---: | ---: | ---: |
| `en_core_web_sm-2.0.0a4` | v2.x | neural | **91.9** | **90.0** | 85.0 | **97.1** | 10,000 |
| `en_core_web_sm-2.0.0a3` | v2.x | neural | 91.2 | 89.2 | **85.3** | 96.9 | 10,000 |
| `en_core_web_sm-2.0.0a2` | v2.x | neural | 91.5 | 89.5 | 84.7 | 96.9 | 10,000 |
| `en_core_web_sm-1.1.0` | v1.x | linear | 86.6 | 83.8	| 78.5 | 96.6 | **25,700** |
| `en_core_web_md-1.2.1` | v1.x | linear | 90.6 | 88.5 | 81.4 | 96.7 | 18,800 |

## ✨ Major features and improvements

* **NEW:** Neural network model for English (comparable performance to the >1GB v1.x models) and multi-language NER (still experimental).
* **NEW:** GPU support via [Chainer](http://chainer.org)'s CuPy module.
* **NEW:** Strings are now resolved to hash values, instead of mapped to integer IDs. This means that the string-to-int mapping no longer depends on the vocabulary state.
* **NEW:** Trainable document vectors and contextual similarity via convolutional neural networks.
* **NEW:** Built-in text classification component.
* **NEW:** Built-in displaCy visualizers with Jupyter notebook support.
* **NEW:** Alpha tokenization for [Danish](spacy/lang/da), [Polish](spacy/lang/pl) and [Indonesian](spacy/lang/id).
* Improved language data, support for lazy loading and simple, lookup-based lemmatization for English, German, French, Spanish, Italian, Hungarian, Portuguese and Swedish.
* Improved language processing pipelines and support for custom, model-specific components.
* Improved and consistent saving, loading and serialization across objects, plus Pickle support.
* Revised matcher API to make it easier to add and manage patterns and callbacks in one step.
* Support for multi-language models and new `MultiLanguage` class (`xx`).
* Entry point for `spacy` command to use instead of `python -m spacy`.

> ### 🚧 Work in progress (not yet implemented)
> * **NEW:** Neural network models for German, French and Spanish.
> * **NEW:** `Binder`, a container class for serializing collections of `Doc` objects.

## 🔴 Bug fixes

* Fix issue #125, #228, #299, #377, #460, #606, #930: Add full Pickle support.
* Fix issue #152, #264, #322, #343, #437, #514, #636, #785, #927, #985, #992, #1011: Fix and improve serialization and deserialization of `Doc` objects. 
* Fix issue #512: Improve parser to prevent it from returning two `ROOT` objects.
* Fix issue #524: Improve parser and handling of noun chunks.
* Fix issue #621: Prevent double spaces from changing the parser result.
* Fix issue #664, #999, #1026: Fix bugs that would prevent loading trained NER models.
* Fix issue #671, #809, #856: Fix importing and loading of word vectors. 
* Fix issue #753: Resolve bug that would tag OOV items as personal pronouns.
* Fix issue #905, #1021, #1042: Improve parsing model and allow faster accuracy updates.
* Fix issue #995: Improve punctuation rules for Hebrew and other non-latin languages.
* Fix issue #1008: `train` command finally works correctly if used without `dev_data`.
* Fix issue #1012: Improve documentation on model saving and loading.
* Fix issue #1043: Improve NER models and allow faster accuracy updates.
* Fix issue #1051: Improve error messages if functionality needs a model to be installed.
* Fix issue #1071: Correct typo of ""whereve"" in English tokenizer exceptions.
* Fix issue #1088: Emoji are now split into separate tokens wherever possible.

> ### 🚧 Work in progress (not yet implemented)
> * Fix issue #519, #611, #725: Retrain German model with better tokenized input.
> * Fix issue #933, #954, #977, #1040: Improve accuracy and update [online demos](https://demos.explosion.ai).
> * Fix issue #1044: Fix bugs in French model and improve performance.


## 📖 Documentation and examples

* **NEW:** [spacy 101 guide](https://alpha.spacy.io/docs/usage/spacy-101) with simple explanations and illustrations of the most important concepts and an overview of spaCy's features and capabilities.
* **NEW:** [Visualizing spaCy](https://alpha.spacy.io/docs/usage/visualizers) guide on how to use the built-in [`displacy`](https://alpha.spacy.io/docs/api/displacy) module.
* **NEW:** API docs for [top-level functions](https://alpha.spacy.io/docs/api/spacy), [`spacy.displacy`](https://alpha.spacy.io/docs/api/displacy), [`spacy.util`](https://alpha.spacy.io/docs/api/util), [`spacy.gold.GoldCorpus`](https://alpha.spacy.io/docs/api/goldcorpus).
* **NEW:** Full code example for [text classification](examples/training/train_textcat.py) (sentiment analysis).
* Improved [rule-based matching](https://alpha.spacy.io/docs/usage/rule-based-matching) guide with examples for matching entities and phone numbers, and social media analysis.
* Improved [processing pipelines](https://alpha.spacy.io/docs/usage/language-processing-pipeline) guide with examples for custom sentence segmentation logic and hooking in a sentiment analysis model.
* Re-wrote all API and usage docs and added more examples.

> ### 🚧 Work in progress (not yet implemented)
> * **NEW:** Usage guide on [scaling spaCy for production](https://alpha.spacy.io/docs/usage/production-use).
> * **NEW:** Usage guide on [text classification](https://alpha.spacy.io/docs/usage/text-classification).
> * **NEW:** API docs for [`spacy.pipeline.TextCategorizer`](https://alpha.spacy.io/docs/api/textcategorizer), [`spacy.pipeline.Tensorizer`](https://alpha.spacy.io/docs/api/tensorizer), [`spacy.tokens.binder.Binder`](https://alpha.spacy.io/docs/api/binder) and [`spacy.vectors.Vectors`](https://alpha.spacy.io/docs/api/vectors).
> * Improved  [training](https://alpha.spacy.io/docs/usage/training), [NER training](https://alpha.spacy.io/docs/usage/training-ner) and [deep learning](https://alpha.spacy.io/docs/usage/deep-learning) usage guides with examples.

## ⚠️ Backwards incompatibilities

**Note that the old v1.x models are not compatible with spaCy v2.0.0.** If you've trained your own models, you'll have to **re-train them** to be able to use them with the new version. For a full overview of changes in v2.0, see the [alpha documentation](https://alpha.spacy.io/docs/usage/v2) and guide on [migrating from spaCy 1.x](https://alpha.spacy.io/docs/usage/v2#migrating).

### Loading models

[`spacy.load()`](https://alpha.spacy.io/docs/api/spacy) is now **only intended for loading models** – if you need an empty language class, import it directly instead, e.g. `from spacy.lang.en import English`. If the model you're loading is a shortcut link or package name, spaCy will expect it to be a **model package**, import it and call its `load()` method. If you supply a path, spaCy will expect it to be a **model data directory** and use the meta.json to initialise a language class and call `nlp.from_disk()` with the data path.

```python
nlp = spacy.load('en')
nlp = spacy.load('en_core_web_sm')
nlp = spacy.load('/model-data')
nlp = English().from.disk('/model-data')
# OLD: nlp = spacy.load('en', path='/model-data')
```

### Hash values instead of integer IDs

The `StringStore` now resolves all strings to hash values instead of integer IDs. This means that the string-to-int mapping **no longer depends on the vocabulary state**, making a lot of workflows much simpler, especially during training. However, you still need to make sure all objects have access to the same `Vocab`. Otherwise, spaCy won't be able to resolve hashes back to their string values.

```python
nlp.vocab.strings[u'coffee']       # 3197928453018144401
other_nlp.vocab.strings[u'coffee'] # 3197928453018144401
```

### Serialization

spaCy's [serialization API](https://alpha.spacy.io/docs/usage/saving-loading) is now consistent across objects. All containers and pipeline components have `.to_disk()`, `.from_disk()`, `.to_bytes()` and `.from_bytes()` methods.
 
```python
nlp.to_disk('/model')
nlp.vocab.to_disk('/vocab')
# OLD: nlp.save_to_directory('/model')
```

### Processing pipelines

Models can now define their own [processing pipelines](https://alpha.spacy.io/docs/usage/language-processing-pipeline) as a list of strings, mapping to component names. Components receive a `Doc`, modify it and return it to be processed by the next component in the pipeline. You can add custom components to `nlp.pipeline`, and disable components by adding their name to the `disable` keyword argument. The tokenizer can simply be overwritten with a custom function.

```python
nlp = spacy.load('en', disable=['tagger', 'ner'])
nlp.tokenizer = my_custom_tokenizer
nlp.pipeline.append(my_custom_component)
doc = nlp(u""I don't want parsed"", disable=['parser'])
```

### Comparison table

For the complete table and more details, see the alpha guide on [what's new in v2.0](https://alpha.spacy.io/docs/usage/v2).

| Old | New | Notes |
| --- | --- | -- |
| `spacy.en`, `spacy.de`, ... | `spacy.lang.en`, ... | Language data moved to `lang`. |
| `.save_to_directory`, `.dump`, `.dump_vectors` | `.to_disk `, `to_bytes` | Consistent serialization. |
| `.load`, `.load_lexemes`, `.load_vectors`, `.load_vectors_from_bin_loc` | `.from_disk`, `.from_bytes` |  Consistent serialization. |
| `Language.create_make_doc` | `Language.tokenizer` | Tokenizer can now be replaced via `nlp.tokenizer`. |
| `Matcher.add_pattern`, `Matcher.add_entity` | `Matcher.add` | Simplified API. |
| `Matcher.get_entity`, `Matcher.has_entity` | `Matcher.get`, `Matcher.__contains__` | Simplified API. |
| `Doc.read_bytes` | `Binder` | Consistent API. |
| `Token.is_ancestor_of` | `Token.is_ancestor ` | Duplicate method. |

## 👥 Contributors

This release is brought to you by @honnibal and @ines. Thanks to @Gregory-Howard, @luvogels, @Ferdous-Al-Imran, @uetchy, @akYoung, @kengz, @raphael0202, @ardeego, @yuvalpinter, @dvsrepo, @frascuchon, @oroszgy, @v3t3a, @Tpt, @thinline72, @jarle, @jimregan, @nkruglikov, @delirious-lettuce and @geovedi for the pull requests and contributions. Also thanks to everyone who submitted bug reports and took the [spaCy user survey](https://survey.spacy.io) – your feedback made a big difference!",21467110
172,False,False,2017-04-26T18:50:27Z,2017-04-26T18:51:24Z,"We've been delighted to see spaCy growing so much over the last few months. Before the v1.0 release, we asked for your feedback, which has been incredibly helpful in improving the library. As we're getting closer to v2.0 we hope you'll take a few minutes to fill out the survey, to help us understand how you're using the library, and how it can be better.

### [📊 Take the survey!](https://survey.spacy.io/)

---

## ✨ Major features and improvements

* Move model shortcuts to [`shortcuts.json`](https://github.com/explosion/spacy-models/blob/master/shortcuts.json) to allow adding new ones without updating spaCy.
* **NEW:** The first official [French model](https://github.com/explosion/spacy-models/releases/tag/fr_depvec_web_lg-1.0.0) (~1.3 GB) including vocab, syntax and word vectors.

```bash
python -m spacy download fr_depvec_web_lg
```

```python
import fr_depvec_web_lg

nlp = fr_depvec_web_lg.load()
doc = nlp(u'Parlez-vous Français?')
```

## 🔴 Bug fixes

* Fix reporting if `train` command is used without `dev_data`.
* Fix issue #1019: Make `Span` hashable.

## 📖 Documentation and examples

* Update [list of available models](https://spacy.io/docs/usage/models#available) with more information (capabilities, license).
* Update [adding languages workflow](https://spacy.io/docs/usage/adding-languages) with data examples and details on training.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @raphael0202 and @julien-c for the contributions!",21467110
173,False,False,2017-04-23T19:25:07Z,2017-04-23T20:00:09Z,"We've been delighted to see spaCy growing so much over the last few months. Before the v1.0 release, we asked for your feedback, which has been incredibly helpful in improving the library. As we're getting closer to v2.0 we hope you'll take a few minutes to fill out the survey, to help us understand how you're using the library, and how it can be better.

### [📊 Take the survey!](https://survey.spacy.io/)

---

## 🔴 Bug fixes

* Fix issue #988: Ensure noun chunks can't be nested.
* Fix issue #991: `convert` command now uses Python 2/3 compatible `json.dumps`.
* Fix issue #995: Use `regex` library for non-latin characters to simplify [punctuation rules](https://github.com/explosion/spaCy/blob/master/spacy/language_data/punctuation.py).
* Fix issue #999: Fix parser and NER model saving and loading.
* Fix issue #1001: Add `SPACE` to Spanish tag map.
* Fix issue #1008: `train` command now works correctly if used without `dev_data`.
* Fix issue #1009: `Language.save_to_directory()` now converts strings to pathlib paths.

## 📖 Documentation and examples

* Fix issue #889, #967: Correct typos in lightning tour and [`pos_tag.py`](https://github.com/explosion/spaCy/blob/master/examples/pos_tag.py) examples.
* Add [`Language.save_to_directory()` method](https://spacy.io/docs/api/language#save_to_directory) to API docs.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @dvsrepo, @beneyal and @oroszgy for the pull requests!",21467110
174,False,False,2017-04-16T21:23:59Z,2017-04-16T21:33:59Z,"We've been delighted to see spaCy growing so much over the last few months. Before the v1.0 release, we asked for your feedback, which has been incredibly helpful in improving the library. As we're getting closer to v2.0 we hope you'll take a few minutes to fill out the survey, to help us understand how you're using the library, and how it can be better.

### [📊 Take the survey!](https://survey.spacy.io/)

---

## ✨ Major features and improvements

* **NEW:** Add experimental `Language.save_to_directory()` method to make it easier to save user-trained models.
* Add `spacy.compat` module to handle platform and Python version compatibility.
* Update `package` command to read from existing `meta.json` and supply custom location to meta file.
* Fix various compatibility issues and improve error messages in `spacy.cli`.

## 🔴 Bug fixes

* Fix issue #701, #822, #937, #959: Updated docs for [NER training](https://spacy.io/docs/usage/training-ner) and [saving/loading](https://spacy.io/docs/usage/saving-loading).
* Fix issue #968: `spacy.load()` now prints warning if no model is found.
* Fix issue #970, #978: Use correct unicode paths for symlinks on Python 2 / Windows.
* Fix issue #973: Make `token.lemma` and `token.lemma_` attributes writeable.
* Fix issue #983: Add `spacy.compat` to handle compatibility.

## 📖 Documentation and examples

* **NEW:** Example for [training a new entity type](https://github.com/explosion/spaCy/blob/master/examples/training/train_new_entity_type.py).
* **NEW:** Workflow for [training the Named Entity Recognizer](https://spacy.io/docs/usage/training-ner).
* **NEW:** Workflow for [saving and loading models](https://spacy.io/docs/usage/saving-loading).
* Update [Contributing Guidelines](https://github.com/explosion/spaCy/blob/master/CONTRIBUTING.md) with [code conventions](https://github.com/explosion/spaCy/blob/master/CONTRIBUTING.md#code-conventions) for Python and Cython.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @tsohil and @oroszgy for the pull requests!",21467110
175,False,False,2017-04-07T16:51:48Z,2017-04-07T17:02:06Z,"We've been delighted to see spaCy growing so much over the last few months. Before the v1.0 release, we asked for your feedback, which has been incredibly helpful in improving the library. As we're getting closer to v2.0 we hope you'll take a few minutes to fill out the survey, to help us understand how you're using the library, and how it can be better.

### [📊 Take the survey!](https://survey.spacy.io/)

---

## ✨ Major features and improvements

* **NEW**: Experimental `convert` and `model` [commands](https://spacy.io/docs/usage/cli) to convert files to spaCy's JSON format for training, and initialise a new model and its data directory.
* Updated language data for [Spanish](spacy/es) and [Portuguese](spacy/pt).

## 🔴 Bug fixes

* Error messages now show the new download commands if no model is loaded.
* The `package` command now works correctly and doesn't fail when creating files.
* Fix issue #693: Improve rules for detecting noun chunks.
* Fix issue #758: Adding labels now doesn't cause `EntityRecognizer` transition bug.
* Fix issue #862: `label` keyword argument is now handled correctly in `doc.merge()`.
* Fix issue #891: Tokens containing `/` infixes are now split by the tokenizer.
* Fix issue #898: Dependencies are now deprojectivized correctly.
* Fix issue #910: NER models with new labels now saved correctly, preventing memory errors.
* Fix issue #934, #946: Symlink paths are now handled correctly on Windows, preventing `invalid switch` error.
* Fix issue #947: Hebrew module is now added to `setup.py` and `__init__.py`.
* Fix issue #948: Contractions are now lemmatized correctly.
* Fix issue #957: Use `regex` module to avoid back-tracking on URL regex.

## 📖 Documentation and examples

* Documentation for new [`convert` and `model` commands](https://spacy.io/docs/usage/cli).
* Update [troubleshooting guide](https://spacy.io/docs/usage/troubleshooting) with `--no-cache-dir` error resulting from outdated pip version and file name shadowing model problem.
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @ericzhao28, @Gregory-Howard, @kinow, @jreeter, @mamoit, @kumaranvpl and @dvsrepo for the pull requests!",21467110
176,False,False,2017-03-26T14:46:00Z,2017-03-26T15:08:13Z,"## ✨ Major features and improvements

* **NEW:** Alpha tokenization for [Hebrew](spacy/he).
* **NEW:** Experimental `train` and `package` [commands](https://spacy.io/docs/usage/cli) to train a model and convert it to a Python package.
* Enable experimental support for L1-regularized regression loss in dependency parser and named entity recognizer. Should improve fine-tuning of existing models.
* Fix high memory usage in `download` command.

## 🔴 Bug fixes

* Fix issue #903, #912: Base forms are now correctly protected from lemmatization.
* Fix issue #909, #925: Use `mlink` to create symlinks in Python 2 on Windows.
* Fix issue #910: Update config when adding label to pre-trained model.
* Fix issue #911: Delete old training scripts.
* Fix issue #918: Use `--no-cache-dir` when downloading models via pip.
* Fixed infinite recursion in `spacy.info`.
* Fix initialisation of languages when no model is available.


## 📖 Documentation and examples

* [Troubleshooting guide](https://spacy.io/docs/usage/troubleshooting) for most common issues and usage problems.
* Documentation for new [`package` and `train` commands](https://spacy.io/docs/usage/cli).
* Documentation for spaCy's [JSON format for training data](https://spacy.io/docs/api/annotation#json-input).
* Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @raphael0202, @pavlin99th, @iddoberger and @solresol for the pull requests!",21467110
177,False,False,2017-03-20T12:20:26Z,2017-03-20T12:37:49Z,"## 🔴 Bug fixes

* Success message in `link` is now displayed correctly when using local paths.
* Decrease beam density and fix Python 3 problem in `beam_parser`.
* Fix issue #894: Model packages now install and compile paths correctly on Windows.

## 📖 Documentation and examples

* [Standalone NER training](examples/train_ner_standalone.py) example.
* Fix various typos and inconsistencies.",21467110
178,False,False,2017-03-19T00:44:43Z,2017-03-19T10:42:22Z,"## 🔴 Bug fixes

* Fix issue #892: Data now downloads and installs correctly on system Python.",21467110
179,False,False,2017-03-18T19:04:22Z,2017-03-18T19:24:19Z,"## ✨ Major features and improvements

* **NEW:** Improved English model.
* **NEW:** Additional smaller English model (50 MB, only 2% less accurate than larger model).
* **NEW:** Command line interface to download and link models, view debugging info and print Markdown info for easy copy-pasting to GitHub.
* **NEW:** Alpha support for [Finnish](spacy/fi) and [Bengali](spacy/bn).
* Updated language data for [Swedish](spacy/sv) and [French](spacy/fr).
* Simplified import of lemmatizer data to make it easier to add lemmatization for other languages.

### Improved model download and installation

To increase transparency and make it easier to use spaCy with your own models, all data is now available as direct downloads, organised in [individual releases](https://github.com/explosion/spacy-models/releases). spaCy v1.7 also supports installing and loading models as **Python packages**. You can now choose how and where you want to keep the data files, and set up ""shortcut links"" to load models by name from within spaCy. For more info on this, see the new [models documentation](https://spacy.io/docs/usage/models). 

```bash
# out-of-the-box: download best-matching default model
python -m spacy download en

# download best-matching version of specific model for your spaCy installation
python -m spacy download en_core_web_md

# pip install .tar.gz archive from path or URL
pip install /Users/you/en_core_web_md-1.2.0.tar.gz
pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-1.2.0/en_core_web_md-1.2.0.tar.gz

# set up shortcut link to load installed package as ""en_default""
python -m spacy link en_core_web_md en_default

# set up shortcut link to load local model as ""my_amazing_model""
python -m spacy link /Users/you/data my_amazing_model
```

```python
nlp1 = spacy.load('en')
nlp2 = spacy.load('en_core_web_md')
nlp3 = spacy.load('my_amazing_model')
```

## ⚠️ Backwards incompatibilities

* **IMPORTANT:** Due to fixes to the lemmatizer, the previous English model (v1.1.0) is not compatible with spaCy v1.7.0. When upgrading to this version, you need to download the new model (`en_core_web_md` v1.2.0). The German model is still valid and will be linked to the `de` shortcut automatically.
* spaCy's package manger `sputnik` is now deprecated. For now, we will keep maintaining our download server to support the `python -m spacy.{en|de}.download all` command in older versions, but it will soon re-route to download the models from GitHub instead.
* English lemmatizer data is now stored in Python files in [`spacy/en`](spacy/en) and the WordNet data previously stored in `corpora/en` has been removed. This should not affect your code, unless you have added functionality that relies on these data files.

This will be the last major release before v2.0, which will introduce a few breaking changes to allow native deep learning integration. If you're using spaCy in production, don't forget to **pin your dependencies**:

```python
# requirements.txt
spacy>=1.7.0,<2.0.0

# setup.py
install_requires=['spacy>=1.7.0,<2.0.0']
```

## 🔴 Bug fixes

* Fix issue #401: Contractions with `'s` are now lemmatized correctly.
* Fix issue #507, #711, #798: Models are now available as direct downloads.
* Fix issue #669: `Span` class now has `lower_` and `upper_` properties.
* Fix issue #686: Pronouns now lemmatize to `-PRON-`.
* Fix issue #704: Sentence boundary detection improved with new English model.
* Fix issue #717: Contracted verbs now have the correct lemma.
* Fix issue #730, #763, #880, #890: A smaller English model (`en_core_web_sm`) is now available.
* Fix issue #755: Add missing import to prevent exception using `--force`.
* Fix issue #759: All available `NUM_WORDS` are now recognised correctly as `like_number`.
* Fix issue #766: Add operator to `matcher` and make sure open patterns are closed at doc end.
* Fix issue #768: Allow zero-width infix tokens in tokenizer exceptions.
* Fix issue #771: Version numbers for `ujson` and `plac` are now specified correctly.
* Fix issue #775: ""Shell"" and ""shell"" are now excluded from English tokenizer exceptions.
* Fix issue #778: spaCy is now [available on conda](https://anaconda.org/conda-forge/spacy) via `conda-forge`.
* Fix issue #781: Lemmatizer is now correctly applied to OOV words.
* Fix issue #791: Environment variables are now passed to subprocess calls in `cythonize`.
* Fix issue #792: Trailing whitespace is now handled correctly by the tokenizer.
* Fix issue #801: Update global infix rules to prevent attached punctuation in complex cases.
* Fix issue #805: Swedish tokenizer exceptions are now imported correctly.
* Fix issue #834: `load_vectors()` now accepts arbitrary space characters as word tokens.
* Fix issue #840: Use better regex for matching URL patterns in tokenizer exceptions.
* Fix issue #847: ""Shed"" and ""shed"" are now excluded from English tokenizer exceptions.
* Fix issue #856: Vocab now adds missing words when importing vectors.
* Fix issue #859: Prevent extra spaces from being added after applying `token_match` regex.
* Fix issue #868: Model data can now be downloaded to any directory.
* Fix issue #886: `token.idx` now matches original index when text contains newlines.

## 📖 Documentation and examples

* **NEW:**  [Models usage](https://spacy.io/docs/usage/models) documentation.
* **NEW:** [Command line interface](https://spacy.io/docs/usage/cli) documentation.
* **NEW:** [`spacy-models`](https://github.com/explosion/spacy-models), including the latest model releases.
* **NEW:** [Linear model feature scheme](https://spacy.io/docs/api/features) API docs.
* Add [`help wanted (easy)`](https://github.com/explosion/spaCy/labels/help%20wanted%20%28easy%29) issue label for contribution requests suitable for beginners.
* Update [installation docs](https://spacy.io/docs/usage/) with more details on model download and building spaCy from source.
* Fix various typos and inconsistencies.

## 👥 Contributors

This release is brought to you by @honnibal and @ines. Thanks to @magnusburton, @jktong, @JasonKessler, @sudowork, @oiwah, @raphael0202, @latkins, @ematvey, @Tpt, @wallinm1, @knub, @wehlutyk, @vaulttech, @nycmonkey, @jondoughty, @aniruddha-adhikary, @badbye, @shuvanon, @rappdw, @ericzhao28, @juanmirocks and @rominf for the pull requests!",21467110
180,False,False,2017-01-16T13:02:12Z,2017-01-16T13:14:30Z,"## ✨ Major features and improvements
- Updated token exception handling mechanism to allow the usage of arbitrary functions as token exception matchers.
- Improve how tokenizer exceptions for English contractions and punctuations are generated.
- Update language data for [Hungarian](spacy/hu) and [Swedish](spacy/sv) tokenization.
- Update to use [Thinc v6](https://github.com/explosion/thinc/) to prepare for [spaCy v2.0](https://github.com/explosion/spaCy/projects/3).

## 🔴 Bug fixes
- Fix issue #326: Tokenizer is now more consistent and handles abbreviations correctly.
- Fix issue #344: Tokenizer now handles URLs correctly.
- Fix issue #483: Period after two or more uppercase letters is split off in tokenizer exceptions.
- Fix issue #631: Add `richcmp` method to `Token`.
- Fix issue #718: Contractions with `She` are now handled correctly.
- Fix issue #736: Times are now tokenized with correct string values.
- Fix issue #743: `Token` is now hashable.
- Fix issue #744: `were` and `Were` are now excluded correctly  from contractions.

## 📋 Tests
- Modernise and reorganise all tests and remove model dependencies where possible.
- Improve test speed to ~20s for basic tests (from previously >80s) and ~100s including models (from previously >200s).
- Add fixtures for spaCy components and test utilities, e.g. to create `Doc` object manually.
- Add [documentation for tests](spacy/tests) to explain conventions and organisation.

## 👥 Contributors

Thanks to @oroszgy, @magnusburton, @guyrosin and @danielhers  and  for the pull requests!
",21467110
181,False,False,2016-12-27T21:19:19Z,2016-12-27T21:20:03Z,"## ✨ Major features and improvements
- **NEW:** Alpha support for [Swedish](spacy/sv) tokenization.
- **NEW:** Alpha support for [Hungarian](spacy/hu) tokenization.
- Update language data for [Spanish](spacy/es) tokenization.
- Speed up tokenization when no data is preloaded by caching the first 10,000 vocabulary items seen.

## 🔴 Bug fixes
- List the `language_data` package in the [`setup.py`](setup.py).
- Fix missing `vec_path` declaration that was failing if `add_vectors` was set.
- Allow `Vocab` to load without `serializer_freqs`.

## 📖 Documentation and examples
- **NEW:** [spaCy Jupyter notebooks](https://github.com/explosion/spacy-notebooks) repo: ongoing collection of easy-to-run spaCy examples and tutorials.
- Fix issue #657: Generalise dependency parsing [annotation specs](https://spacy.io/docs/api/annotation) beyond English.
- Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @oroszgy, @magnusburton, @jmizgajski, @aikramer2, @fnorf and @bhargavvader for the pull requests!
",21467110
182,False,False,2016-12-18T22:54:39Z,2016-12-18T23:02:40Z,"## ✨ Major features and improvements
- **NEW:** Alpha support for [Dutch](spacy/nl) tokenization.
- Reorganise and improve format of language data.
- Add [shared](spacy/language_data) tag map, entity rules, emoticons and punctuation to language data.
- Convert entity rules, morphological rules and lemmatization rules from JSON to Python.
- Update language data for [English](spacy/en), [German](spacy/de), [Spanish](spacy/es), [French](spacy/fr), [Italian](spacy/it) and [Portuguese](spacy/pt).

## 🔴 Bug fixes
- Fix issue #649: Update and reorganise stop lists.
- Fix issue #672: Make `token.ent_iob_` return unicode.
- Fix issue #674: Add missing lemmas for contracted forms of ""be"" to `TOKENIZER_EXCEPTIONS`.
- Fix issue #683: `Morphology` class now supplies tag map value for the special space tag if it's missing. 
- Fix issue #684: Ensure `spacy.en.English()` loads the Glove vector data if available. Previously was inconsistent with behaviour of `spacy.load('en')`.
- Fix issue #685: Expand `TOKENIZER_EXCEPTIONS` with unicode apostrophe (`’`).
- Fix issue #689: Correct typo in `STOP_WORDS`.
- Fix issue #691: Add tokenizer exceptions for ""gonna"" and ""Gonna"".

## ⚠️  Backwards incompatibilities

No changes to the public, documented API, but the previously undocumented language data and model initialisation processes have been refactored and reorganised. If you were relying on the `bin/init_model.py` script, see the new [spaCy Developer Resources](https://github.com/explosion/spacy-dev-resources) repo. Code that references internals of the `spacy.en` or `spacy.de` packages should also be reviewed before updating to this version.

## 📖  Documentation and examples
- **NEW:** [""Adding languages""](https://spacy.io/docs/usage/adding-languages) workflow.
- **NEW:** [""Part-of-speech tagging""](https://spacy.io/docs/usage/pos-tagging) workflow.
- **NEW:** [spaCy Developer Resources](https://github.com/explosion/spacy-dev-resources) repo – scripts, tools and resources for developing spaCy.
- Fix various typos and inconsistencies.

## 👥 Contributors

Thanks to @dafnevk, @jvdzwaan, @RvanNieuwpoort, @wrvhage, @jaspb, @savvopoulos and @davedwards for the pull requests!
",21467110
183,False,False,2016-12-03T10:55:22Z,2016-12-03T10:56:08Z,"## ✨ Major features and improvements

- Add `Span.sentiment` attribute.
- #658: Add `Span.noun_chunks` iterator (thanks @pokey).
- #642: Let `--data-path` be specified when running download.py scripts (thanks @ExplodingCabbage).
- #638: Add German stopwords (thanks @souravsingh).
- #614: Fix `PhraseMatcher` to work with new `Matcher` (thanks @sadovnychyi).

## 🔴  Bug fixes
- Fix issue #605: `accept` argument to `Matcher` now rejects matches as expected.
- Fix issue #617: `Vocab.load()` now works with string paths, as well as `Path` objects.
- Fix issue #639: Stop words in `Language` class now used as expected.
- Fix issues #656, #624: `Tokenizer` special-case rules now support arbitrary token attributes.

## 📖 Documentation and examples
- Add [""Customizing the tokenizer""](https://spacy.io/docs/usage/customizing-tokenizer) workflow.
- Add [""Training the tagger, parser and entity recognizer""](https://spacy.io/docs/usage/training) workflow.
- Add [""Entity recognition""](https://spacy.io/docs/usage/entity-recognition) workflow.
- Fix various typos and inconsistencies.

## 👥  Contributors

Thanks to @pokey, @ExplodingCabbage, @souravsingh, @sadovnychyi, @manojsakhwar, @TiagoMRodrigues, @savkov, @pspiegelhalter, @chenb67, @kylepjohnson, @YanhaoYang, @tjrileywisc, @dechov, @wjt, @jsmootiv and @blarghmatey for the pull requests!
",21467110
184,False,False,2016-11-05T01:35:37Z,2016-11-05T01:35:55Z,"## ✨ Major features and improvements
- **NEW:** Support Chinese tokenization, via [Jieba](https://github.com/fxsjy/jieba).
- **NEW:** Alpha support for French, Spanish, Italian and Portuguese tokenization.

## 🔴  Bug fixes
- Fix issue #376: POS tags for ""and/or"" are now correct.
- Fix issue #578: `--force` argument on download command now operates correctly.
- Fix issue #595: Lemmatization corrected for some base forms.
- Fix issue #588: `Matcher` now rejects empty patterns.
- Fix issue #592: Added exception rule for tokenization of ""Ph.D.""
- Fix issue #599: Empty documents now considered tagged and parsed.
- Fix issue #600: Add missing `token.tag` and `token.tag_` setters.
- Fix issue #596: Added missing unicode import when compiling regexes that led to incorrect tokenization.
- Fix issue #587: Resolved bug that caused `Matcher` to sometimes segfault.
- Fix issue #429: Ensure missing entity types are added to the entity recognizer.
",21467110
185,False,False,2016-10-23T16:53:34Z,2016-10-23T16:54:12Z,"## ✨ Major features and improvements
- Rename new `pipeline` keyword argument of `spacy.load()` to `create_pipeline`.
- Rename new `vectors` keyword argument of `spacy.load()` to `add_vectors`.

## 🔴 Bug fixes
- Fix issue #544: Add `vocab.resize_vectors()` method, to support changing to vectors of different dimensionality.
- Fix issue #536: Default probability was incorrect for OOV words.
- Fix issue #539: Unspecified encoding when opening some JSON files.
- Fix issue #541: GloVe vectors were being loaded incorrectly.
- Fix issue #522: Similarities and vector norms were calculated incorrectly.
- Fix issue #461: `ent_iob` attribute was incorrect after setting entities via `doc.ents`
- Fix issue #459: Deserialiser failed on empty doc
- Fix issue #514: Serialization failed after adding a new entity label.
",21467110
186,False,False,2016-10-18T23:24:22Z,2016-10-19T00:29:19Z,"## ✨ Major features and improvements
- **NEW:** [custom processing pipelines](https://spacy.io/docs/usage/customizing-pipeline), to support deep learning workflows
- **NEW:** [Rule matcher](https://spacy.io/docs/usage/rule-based-matching) now supports entity IDs and attributes
- **NEW:** Official/documented [training APIs](https://github.com/explosion/spaCy/tree/master/examples/training) and `GoldParse` class
- Download and use GloVe vectors by default
- Make it easier to load and unload word vectors
- Improved rule matching functionality
- Move basic data into the code, rather than the json files. This makes it simpler to use the tokenizer without the models installed, and makes adding new languages much easier.
- Replace file-system strings with `Path` objects. You can now load resources over your network, or do similar trickery, by passing any object that supports the `Path` protocol.

## ⚠️  Backwards incompatibilities
- The data_dir keyword argument of `Language.__init__` (and its subclasses `English.__init__` and `German.__init__`) has been renamed to `path`.
- Details of how the Language base-class and its sub-classes are loaded, and how defaults are accessed, have been heavily changed. If you have your own subclasses, you should review the changes.
- The deprecated `token.repvec` name has been removed.
- The `.train()` method of Tagger and Parser has been renamed to `.update()`
- The previously undocumented `GoldParse` class has a new `__init__()` method. The old method has been preserved in `GoldParse.from_annot_tuples()`.
- Previously undocumented details of the `Parser` class have changed.
- The previously undocumented `get_package` and `get_package_by_name` helper functions have been moved into a new module, `spacy.deprecated`, in case you still need them while you update.

## 🔴  Bug fixes
- Fix `get_lang_class` bug when GloVe vectors are used.
- Fix Issue #411: `doc.sents` raised IndexError on empty string.
- Fix Issue #455: Correct lemmatization logic
- Fix Issue #371: Make `Lexeme` objects hashable
- Fix Issue #469: Make `noun_chunks` detect root NPs

## 👥  Contributors

Thanks to @daylen, @RahulKulhari, @stared, @adamhadani, @izeye and @crawfordcomeaux for the pull requests!
",21467110
187,False,True,2020-02-11T20:01:05Z,2020-02-11T23:47:03Z,"Please note that this is not (yet) intended to be a release candidate. Rather, we're publishing this document so that users of master or our new nightly releases have additional context on the changes.

### Breaking changes:
* WordSplitter has been replaced by Tokenizer. See #3361. (this also requires a config file change; see below)
* Pretrained models are now available from `allennlp-hub`. See #3478.
* `Model.decode()` was renamed to `Model.make_output_human_readable()`
* `trainer.cuda_device` no longer takes a list, use `distributed.cuda_devices`. See #3529.
* TODO: As of #3529 dataset readers used in the distributed setting need to shard instances to separate processes internally. We should fix this before releasing.
* Dataset caching is now handled entirely with a parameter passed to the dataset reader, not with command-line arguments.  If you used the caching arguments to `allennlp train`, instead just add a `""cache_directory""` key to your dataset reader parameters.
* Sorting keys in the bucket iterator have changed; now you just give a field name that you want to sort by, and that's it.  We also implemented a heuristic to figure out what the right sorting key is, so in almost all cases you can just remove the `sorting_keys` parameter from your config file and our code will do the right thing.  Some cases where our heuristic might get it wrong are if you have a `ListField[TextField]` and you want the size of the list to be the padding key, or if you have an `ArrayField` with a long but constant dimension that shouldn't be considered in sorting.
* The argument order to `Embedding()` changed (because we made an argument optional and had to move it; pretty unfortunate, sorry).  It used to be `Embedding(num_embeddings, embedding_dim)`.  Now it's `Embedding(embedding_dim, num_embeddings)`.


### Config file changes:
In 1.0, we made some significant simplifications to how `FromParams` works, so you basically never see it in your code and don't ever have to think about adding custom `from_params` methods.  We just follow argument annotations and have the config file always exactly match the argument names in the constructors that are called.

This meant that we needed to remove cases where we previously allowed mismatches between argument names and keys that show up in config files.  There are a number of places that were affected by this:

* The way Vocabulary options are specified in config files has changed. See #3550. If you want to load a vocabulary from files, you should specify `""type"": ""from_files""`, and use the key `""directory""` instead of `""directory_path""`.
* When instantiating a `BasicTextFieldEmbedder` `from_params`, you used to be able to have embedder names be top-level keys in the config file (e.g., `""embedder"": {""elmo"": ELMO_PARAMS, ""tokens"": TOKEN_PARAMS}`).  We changed this a long time ago to prefer wrapping them in a `""token_embedders""` key, and this is now required (e.g., `""embedder"": {""token_embedders"": {""elmo"": ELMO_PARAMS, ""tokens"": TOKEN_PARAMS}}`).
* The `TokenCharactersEncoder` now requires you to specify the `vocab_namespace` for the underlying embedder.  It used to default to `""token_characters""`, matching the `TokenCharactersIndexer` default, but making that work required some custom magic that wasn't worth the complexity.  So instead of `""token_characters"": {""type"": ""character_encoding"", ""embedding"": {""embedding_dim"": 25}, ""encoder"": {...}}`, you need to change this to: `""token_characters"": {""type"": ""character_encoding"", ""embedding"": {""embedding_dim"": 25, ""vocab_namespace"": ""token_characters""}, ""encoder"": {...}}`
* Regularization now needs another key in a config file.  Instead of specifying regularization as `""regularizer"": [[regex1, regularizer_params], [regex2, regularizer_params]]`, it now must be specified as `""regularizer"": {""regexes"": [[regex1, regularizer_params], [regex2, regularizer_params]]}`.
* Initialization was changed in a similar way to regularization.  Instead of specifying initialization as `""initializer"": [[regex1, initializer_params], [regex2, initializer_params]]`, it now must be specified as `""initializer"": {""regexes"": [[regex1, initializer_params], [regex2, initializer_params]]}`.  Also, you used to be able to have `initializer_params` be `""prevent""`, to prevent initialization of matching parameters.  This is now done with a separate key passed to the initializer: `""initializer"": {""regexes"": [..], ""prevent_regexes"": [regex1, regex2]}.
* `num_serialized_models_to_keep` and `keep_serialized_model_every_num_seconds` used to be able to be passed as top-level parameters to the `trainer`, but now they must always be passed to the `checkpointer` instead.  For example, if you had `""trainer"": {""num_serialized_models_to_keep"": 1}`, it now needs to be `""trainer"": {""checkpointer"": {""num_serialized_models_to_keep"": 1}}`.
* Tokenizer specification changed because of #3361.  Instead of something like `""tokenizer"": {""word_splitter"": {""type"": ""spacy""}}`, you now just do `""tokenizer"": {""type"": ""spacy""}` (more technically: the `WordTokenizer` has now been removed, with the things we used to call `WordSplitters` now just moved up to be top-level `Tokenizers` themselves).
* The `namespace_to_cache` argument to `ElmoTokenEmbedder` has been removed as a config file option.  You can still pass `vocab_to_cache` to the constructor of this class, but this functionality is no longer available from a config file.  If you used this and are really put out by this change, let us know, and we'll see what we can do.


### Changes:
* `allennlp make-vocab` and `allennlp dry-run` are deprecated, replaced with a `--dry-run` flag which can be passed to `allennlp train`. We did this so that people might find it easier to actually use the dry run features, as they don't require any config changes etc.
* When constructing objects using our `FromParams` pipeline, we now inspect superclass constructors when the concrete class has a `**kwargs` argument, adding arguments from the superclass.  This means, e.g., that we can add parameters to the base `DatasetReader` class that are immediately accessible to all subclasses, without code changes.  All that this requires is that you take a `**kwargs` argument in your constructor, and you call `super().__init__(**kwargs)`.  See #3633.
* The order of the `num_embeddings` and `embedding_dim` constructor arguments for `Embedding` has changed. Additionally, passing a `pretrained_file` now initializes the embedding regardless of whether it was constructed from a config file, or directly instantiated in code. see #3763  
* Our default logging behavior is now much less verbose.

### Notable bug fixes
There are far too many small fixes to be listed here, but these are some notable fixes:
* NER interpretations have never actually reproduced the result in the original AllenNLP Interpret paper.  This version finds and fixes that problem, which was that the loss masking code to make the model compute correct gradients for a single span prediction was not checked in. See #3971.


# Upgrading Guide


## Iterators -> DataLoaders
Allennlp now uses Pytorch's API for data iteration, rather than our own custom one. This means that `train_data`, `validation_data`, `iterator` and `validation_iterator` arguments to the `Trainer` are now deprecated, having been replaced with `data_loader` and `validation_dataloader`.

*Previous config files which looked like:*
```
{
  ""iterator"": {
    ""type"": ""bucket"",
    ""sorting_keys"": [[""tokens""], [""num_tokens""]],
	""padding_noise"": 0.1
    ...
  }
}
```
*Now become:*

```
{
  ""data_loader"": {
	""batch_sampler"" {
		""type"": ""bucket"",
		// sorting keys are no longer required! They can be inferred automatically.
		""padding_noise"": 0.1
	}
}
```



## Multi-GPU

Allennlp now uses `DistributedDataParallel` for parallel training, rather than `DataParallel`. With `DistributedDataParallel`, each worker (GPU) runs in it's own process. As such, each process also has its own `Trainer`, which now takes a single GPU ID only.

*Previous config files which looked like:*
```
{
  ""trainer"": {
    ""cuda_device"": [0, 1, 2, 3],
    ""num_epochs"": 20,
    ...
  }
}
```
*Now become:*

```
{
  ""distributed"": {
    ""cuda_devices"": [0, 1, 2, 3],
  },
  ""trainer"": {
    ""num_epochs"": 20,
    ...
  }
}
```
In addition, if it is important that your dataset is correctly sharded such that one epoch strictly corresponds to one pass over the data, your dataset reader should contain the following logic to read instances on a per-worker basis:

```python
rank = torch.distributed.get_rank()
world_size = torch.distributed.get_world_size()
for idx, inputs in enumerate(data_file):
	if idx % world_size == rank:
		yield self.text_to_instance(inputs)
	
```
",91356408
188,False,False,2019-09-25T13:47:34Z,2019-09-25T14:34:32Z,"## Main features

- [AllenNLP Interpret](https://allennlp.org/interpret).  This lets you interpret the predictions of any AllenNLP model, using gradient-based visualization and attack techniques.  You can (1) explore existing interpretations for models that we have implemented at [demo.allennlp.org](https://demo.allennlp.org); (2) easily add interpretations for your own model, either programmatically or in a live demo; and (3) easily add new interpretation methods that can be used with any AllenNLP model.
- Compatibility with `pytorch-transformers`, so you can use RoBERTa or whatever else as your base encoder.

## Also of note

- A new, more flexible seq2seq abstraction is available (though, honestly, I think we all agree that fairseq or OpenNMT are better for seq2seq models still).
- When specifying types for registrable items, you can now use a fully-qualified path, like `""my_package.models.my_new_fancy_classifier""`, instead of needing to pass `--include-package` everywhere.

## Complete commit list

052353ed (tag: v0.9.0) bump version number to v0.9.0
ff0d44a5 (origin/master, origin/HEAD) reversing NER for interpet UI (#3283)
3b220112 Composed Sequence to Sequence Abstraction (#2913)
b85f29c6 Fix F1Measure returning true positives, false positives, et al. only for the first class (#3279)
64143c41 upgrade to latest pylint (#3266)
d09042e4 Fix crash when hotflip gets OOV input (#3277)
2a950223 Revert batching for input reduction (#3276)
052e8d32 Reduce number of samples in smoothgrad (#3273)
76d248f8 Reduce hotflip vocab size, batch input reduction beam search (#3270)
9a67546e fix empty sequence bug (#3271)
87fb294e Update question.md (#3267)
daed8359 Fix wrong partition to types in DROP evaluation (#3263)
41a47767 Unidirectional LM doesn't return backward loss. (#3256)
3e0bad4a Minor fixes for interpret code (#3260)
05be16a8 allow implicit package imports (#3253)
48de8667 Assorted fixes for run_with_beaker.py (#3248)
c732cbf1 Add additive attention & unittest (#3238)
07364c67 Make Instance in charge of when to re-index (#3239)
7b50b69f Replace staticmethods with classmethods (#3229)
7cfaab47 Add ERROR callback event (#2983)
ce504073 Revert ""Use an NVIDIA base image. (#3177)"" (#3222)
b1caa9e5 Use an NVIDIA base image. (#3177)
4625a9d2 Improve check_links.py CI script (#3141)
5e2206df Add a reference to Joe Barrow's blog
27ebcf6b added infer_type_and_cast flags (#3209)
bbaf1fc0 Benchmark iterator, avoid redundant queue, remove managers. (#3119)
78ee3d85 Targeted hotflip attacks and beam search for input reduction (#3206)
f2824fdc Predictors for demo LMs, update for coref predictor (#3202)
d78ac70a Language model classes for making predictions (both masked LM and next token LM) (#3201)
8c06c4b2 Adding a LanguageModelHead abstraction (#3200)
370d5126 Dataset readers for masked language modeling and next-token-language-modeling (#3147)
1eaa1ff9 Link to Discourse in README
030e28c9 Revert ""Revert ""Merge branch 'matt-gardner-transformer-embedder'""""
6e1e3713 Revert ""Merge branch 'matt-gardner-transformer-embedder'""
4c7fa737 Merge branch 'matt-gardner-transformer-embedder'
07bdc4ae Merge branch 'transformer-embedder' of https://github.com/matt-gardner/allennlp into matt-gardner-transformer-embedder
993034f0 Minor fixes so PretrainedTransformerIndexer works with roberta (#3203)
70e92e85 doc
ed93e523 pylint
195bf0c3 override method
6ec74aaf Added a TokenEmbedder for use with pytorch-transformers
fb9a9718 code for mixed bert embedding layers (#3199)
0e872a0d Clarify that scalar_mix_parameters takes unnormalized weights (#3198)
23efadd9 upgrade to pytorch 1.2 (#3182)
155a94e5 Add DropEmAndF1 metric to __init__.py (#3191)
7738cb58 Add exist_ok parameter to registrable.register decorator. (#3190)
ce6dc726 Add example of initializing weights from pretrained model to doc (#3188)
817814bf Update documentation for bert_pooler.py (#3181)
112d8d0b Bump version numbers to v0.9.0-unreleased",91356408
189,False,False,2019-08-21T17:17:34Z,2019-08-21T18:10:25Z,"This is (almost certainly) the last release to support versions of PyTorch earlier than 1.2.0. PyTorch 1.2.0 introduces some breaking changes that require changes to the allennlp library (as well as some new features that will allow us to make allennlp better), and so you should expect that the next release will require `torch>=1.2.0`

This introduces some changes to the `CallbackTrainer`, which moves much of the ancillary training behavior into configurable Callbacks. Its API should still be considered somewhat experimental; in particular, we are open to feedback on its design decisions. There are no current plans to get rid of the classic `Trainer`, although it is likely to get more and more unwieldy as we add new training functionality to the library.

This also includes the ""srl_bert"" model as featured in the allennlp demo, as well as many other fixes.

Full list of commits:

c8d73270 (tag: v0.8.5) bump version number to v0.8.5
9d8d36af quoref metric and evaluator (#3153)
7bacfad5 Set pytorch-transformer to 1.1.0 (#3171)
18daa298 Fix pearson correlation.py (#3101)
e641543e Add a test for the subcommands docstring help outputs (#3172)
b6af6ebf bug fix for default tokenization of knowledge graph entities (#3170)
0f6b3b89 Make SrlBert model use SrlEvalMetric (#3168)
adad1bc3 Switch SemanticRoleLabeler metric to SrlEvalScorer. (#3164)
8fffd831 Add missing train command cache options (#3160)
770791a2 switch for DataIterators whether smaller batches should be skipped (#3140)
111db19d Create method to save instances to cache file. (#3131)
dac486ef Fixing NaN warning with single element tensors (#3158)
6bbf82ef Move matplotlib import into function (#3157)
3ef43c96 Upgrade minimum spacy to 2.1.0 (#3152)
1d6e1667 Fixing Conda download and install link on Readme (#3151)
f111d8a7 Pretrained transformer indexer (#3146)
fa1ff674 Add support for running preemptible workloads on beaker (#3143)
0bd33194 Add regularization parameter to Models (#3120)
bf968c69 add keep_as_dict option to Params.pop, use in Vocab and automat… (#3075)
217022f4 Adding a PretrainedTransformerTokenizer (#3145)
f9e2029f Update HTTP links to HTTPS where possible (#3142)
9093f475 Add dropout option for BERT Pooler (#3109)
23a089c8 pin pytorch away from 1.2 until we fix the tests (#3128)
0be4b488 fix UpdateMovingAverage.from_params (#3126)
9db00422 Upgrade conllu from 0.11 to 1.3.1 (#3115)
6746d12c pass cache_directory and cache_prefix to non-default trainers (#3077)
031bbf95 allenNLP broken link (#3086)
0caf3640 Adding cached_path to input file of the predictor (#3098)
417a7572 Adding ability to choose validation DatasetReader with ""predict"" (#3033)
30c4271f Close tensorboard's event files properly at the end of the training (#3085)
428c1511 fix MetadataField.batch_tensors (#3084)
88a61e13 [Embedding] Forward given padding_index param to embedding() (#2504)
9ed9e2c8 remove executable permission for submods (#3080)
a1476c04 add equality check for index field; allennlp interpret (#3073)
5014d022 remove deprecated function call in hotflip (#3074)
014fe318 Improve dict missing key code (#3071)
9166c184 AllenNLP Interpret Basic Version (#3032)
7728b12f Minor WTQ ERM model and  dataset reader fixes for demo (#3068)
ec30c902 remove dropout from test fixtures (#2889)
1cd21937 Revert ""Lr scheduler bug"" (#3065)
083f3430 Lr scheduler bug (#2905)
5c64f9d0 warn about truncation only once (#3052)
ebe91139 Add options for focal loss (#3036)
c22ed57a Spacy token indexer (#3040)
a33436db Multilabel bug (#3021)
dd3476f1 simplify callback trainer (#3029)
0663e0bb Fixes to ERM decoding script (#3041)
64d16acf fix shape comments (#3025)
354a19b4 Update documents to sentence_splitter.py (#3023)
427996d4 Fix forward in EndpointSpanExtractor (#3042)
38a10735 Update README.md
715422c7 Fix error in BooleanAccuracy when total count is 0 (#2991)
9e52e0f6 Remove separate start type prediction in state machines (#3030)
c2c4b64d Remove awscli from dependencies (#3024)
ae72049f Make per-batch logging quieter. (#3020)
57870f5a removing unnecessary data iteration (#3027)
e71618de Allow option to only reset some states in _EncoderBase (#2967)
15a9cbe5 PassThroughIterator (#3015)
70fa4aac Typo in initializers.py (#3016)
c85dcfcf fix behavior when num_serialized_models_to_keep is 0 (#2880)
2cce412e fix type in vocab config (#2977)
7943b2fb Expose the spacy language model for the word splitter in the se… (#3008)
9b929b28 Fixes inconsistent resetting of metrics with Validate and TrackMetrics callbacks  (issue #3001) (#3002)
0a267397 Modified ActionSpaceWalker to use DomainLanguage (#3006)
9a13ab57 (vikigenius/master) do not evaluate after training if non-default trainer (#2997)
30ffaa54 Removed target_token_indexers documentation (#2990)
7b465c69 Clarify docs for CosineWithRestarts (#2953)
fb878721 Add never_split signature (#2463)
b6a2abbf correct the wrong parameter note(target_namespace) (#2987)
cf247c6a Add model parameters / modules inspection helper. (#2466)
0fbd1ca8 WTQ dataset reader and models moved from iterative-search-semparse (#2764)
7e08298e Fix wordpiece indexer truncation (#2931)
03aa838e fix incorrect logging in viterbi decode (#2982)
51b74b1a use starting offsets in the srl model so output is wellformed (#2972)
bcd10700 Add cuda_device to Predictor.from_path (#2974)
459633c9 rename callbacks (#2966)
0f1bc3b9 DeprecationWarning removed for op-level token_embedders (#2955)
a655ad52 experimental: add backoff (#2968)
2a59be3a (epwalsh/master) Change registered names of scheduler callbacks (#2964)
2a884501 update sphinx version (#2959)
165b282b Bert srl model (#2961)
3dc99a77 Add missing param in CallbackTrainer.__init__ docstring (#2960)
9e6e0af6 callback based trainer (#2817)
1b656dd7 Allowing for bulk adding of tokens to vocab (#2948)
c9eb2d0e Replace current default stopword list with spaCy's. (#2940)
6a3d3a8d ensure regularizers are only computed for parameters requiring gradients (#2887)
acfbb8c0 Replace s3 path style to virtual host style (#2873)
ac72c888 Fix Model.load fail if model_params is str (#2805)
e7b00130 Linear assignment depricated fix (#2950)
01602c86 Link to Wikitables and ATIS data. (#2947)
eaebe02f Update issue templates to request full stacktrace (#2876)
da16ad13 Multilingual parser and Cross-lingual ELMo (#2628)
92ee4215 Fix for cyclic import problems (issue #2935) (#2938)
5e3c4cdd token_type_ids fix for window reshaping (#2942)
44ba4900 Use unsigned s3 requests when missing credentials (#2939)
c0f44f74 Fixed minor error while calculating span accuracy (#2923)
8e180cb9 Pad coreference model input to 5 (#2933)
9a0e01fa fix trainable and requires_grad kwargs (#2932)
5f377834 Bert srl (#2854)
5b2066bd Fix Invalid Index Reference for labels in Vocabulary (#2926)
c629093b CopyNet: replace in-place tensor operation with out-of-place equivalent (#2925)
89700de2 Change image to docker_image (#2918)
53938826 Change blueprint to image in run_with_beaker (#2903)
6afba9a2 Fix TextField padding when there are no tokens (#2843)
954a02f9 (vikigenius/release-v0.8.4, upstream/release-v0.8.4) Bump version numbers to v0.8.5-unreleased
",91356408
190,False,False,2019-05-30T19:52:44Z,2019-05-30T22:14:32Z,"This is a minor release to distribute the numerous small improvements and bugfixes to our users.

# List of Commits

030ef755 bump version number to v0.8.4
fbc28cef Fix typo in Model.extend_embedder_vocab docstring (#2806)
26ac3499 fix dependency conflicts (by removing moto + disabled tests that use it) (#2902)
69c1c9fc Shift extra_weight for embedding extension to right device (#2896)
d6bb6c87 Make DROP EM and F1 calculation length aware (#2866)
d800e823 truncate type ids (#2875)
c2609453 updated links for pretrained NER models (#2872)
20844259 Add ability to generate BERT embeddings using a sliding window (#2493) (#2537)
093847a7 updated fine-grained-ner-model-elmo URL (#2868)
93e86a96 Add output path to drop eval (#2860)
b6693107 Log random seeds to disk. (#2859)
b20c12ba Use optimal matching for the drop eval and add appropriate tests. (#2853)
c59a3a8b Update auc.py (#2775)
7bdd575c Remove multiple GPU warning (#2837)
8e0953ab Fix typo in tagger README file (#2836)
e3febb99 Fix test evaluation after training in the general case (#2835)
aa1524ee Fix typo in a comment (#2826)
7c4311b1 Unwrap masks to tensors as well in AUC metric (#2813)
2452492f fix batched_index_select (#2765)
425f2af3 add `token_min_padding_length` to `TokenIndexer` (#2615)
e70eb7bb Link pretrained model in tutorial. (#2814)
48f46ea9 Number predictions. (#2709)
aeafe1c5 Bert for classification (#2787)
63be47a2 Improve handling of empty ListFields. (#2697)
30460e61 Use a hash function that is constant across program invocations. (#2802)
16c40ec5 Delete .DS_Store (#2803)
24f90a82 Adding NamedTuple case for Tensors to be moved to GPU. (#2799)
a701a0ae Fix out-of-bound checking in BidirectionalEndpointSpanExtractor for empty sequences. (#2763)
9fc6f9eb Add SrlEvalMetric (#2743)
42ada05d fixing regression in drop script and adding a test case for the same (#2796)
d9baa6f7 Changing model name in config file to match registered name (#2794)
6acfc6ca Repro for #2776 and backwards compatible fix. (#2784)
648a36f7 Increase max_runs for NumericallyAugmentedQaNetTest. (#2778)
3170f6f3 Make FBetaMeasure work with batch size of 1. (#2777)
b97bca02 Make _replace_none properly handle ""None"" in parameter lists (#2774)
7c0d5d53 Fix bug in QaNetEncoder, update pretrained model (#2773)
95b439da Remove misleading dropout from training configs where RNN has only one layer (#2768)
c059b151 Remove misleading dropout from bidaf.jsonnet (#2767)
3c226042 Extras checks (#2754)
c6ddb9d3 Update comment on ELMo NER model to match current configuration (#2761)
979817dd add print-results command (#2744)
282f12ae fix abstract type hint (#2753)
90839d0b Dummy commit to test Google Cloud Build removal.
b6453dc1 Directly capture output in EVALB metric (#2755)
20772152 Use numpy's shuffle for reproducibility. (#2729)
53b3d37b Text Classification Predictor (#2745)
12cee922 lowercase stopword set in word filter (#2749)
f8d2ec5b Moving WTQ language updates from iterative-search-semparse (#2637)
b9072218 Add caching functionality to the base DatasetReader class (#2726)
75f7992c Document interaction between UNK token and max_vocab_size (#2740)
7e2e592d Allow FromParams to construct Union types (#2734)
016ea34e Fixing typo in ElmoTokenEmbedder documentation (#2741)
57956e78 Enable span-level F1 metric in SimpleTagger (#2735)
00e95b8b Added NAQANet to pretrained.py and DEFAULT_PREDICTORS (#2731)
9dec0202 [Feature Enhanced] Generalize F1-measure to FBeta-measure (#2275)
e2d153f8 Add perplexity metric to LanguageModel (#2548)
4422d53d QaNetEncoder Multi-GPU (#2692)
4c98095b Fix example in RegularizerApplicator.from_params docstring (#2733)
deae1db2 Add coref_resolved method to CorefPredictor (#2296)
7d34ca3b Fix to include day count in training duration for metrics.json  (#2718)
58f386c5 clarify that seq2vecencoder is required for basic classifier (#2712)
74634e34 Add missing docstring for Embedding.pretrained_file (#2710)
08d66bf2 Fix typo in output parameter name in docstring (#2708)
79e2cf7b Fix ArrayField.to_tensor's dtype when it's a scalar (#2676)
48294831 Fix tagger tutorial (#2705)
a9d957b7 Update pylint to 1.9.4 (#2698)
73bc049b Adding NAQANET training config and fixing test format in evaluation (#2695)
e5adfd73 Ignore 2 root node types in PTB parsing reader (#2675)
53a46ab7 call parse_cuda_device inside check_for_gpu (#2646)
1bca7f60 Correct The Pearson Correlation Formula In Docs (#2683)
0f417503 Catch some references to old library versions. (#2672)
efdc9f3c unpin msgpack, pin spacy to > 2.0.18 (#2671)",91356408
191,False,False,2019-03-29T20:31:43Z,2019-03-29T23:44:27Z,"# Highlighted Changes

* This release includes code for working with the DROP dataset, including the official evaluation script, a `DatasetReader`, and the `NAQANet` model. (#2559, #2556 and #2560)
* We added a no-op trainer that allows you to create AllenNLP model archives for programmatic baselines, alternatively trained models, etc. (#2610)

# Breaking Changes

1. In #2607 we changed the (default) SpacyWordSplitter to return allennlp `Token`s (which are compact, efficient `NamedTuple`s) rather than `spacy.tokens.Token`s. This was done primarily to decrease memory usage for large datasets; secondarily to play nicer with the multiprocess dataset reader. 

This is a breaking change in two ways, neither of which should affect most users:

* in theory everyone should be programming to the `Token` abstraction that's shared between both implementations, but it's possible that someone could be relying on having the actual spacy token, in which case they would need need to configure their word splitter with `keep_spacy_tokens=True`.

* a NamedTuple can't have different constructor parameters and field names. Our previous Token implementation used e.g. pos as the name of the constructor argument but then pos_ as the name of the field. Converting this to a namedtuple meant that the constructor argument now also has to be pos_. If you were for some reason generating your own tokens manually (which the wikitables dataset reader was doing) you would need to make the corresponding changes to that code; if you were only creating Tokens using our `Tokenizer`s, then there's no difference to you.

It's quite likely that neither of these changes will affect even a single user, but in theory they *could*.

# List of Commits

baef9537 bump version number to v0.8.3
0abefe25 Fix docstrings after inspection (#2655)
a80aac7e Move register to typical location. (#2662)
e1d70bb7 Add missing paren (#2661)
2bf0779f Fixed ELMO command's lack of encoding specification when reading from… (#2614)
e138d6cb TextCat Reader skip_label_indexing Fix (#2653)
6e1ee2e1 config_allennlp.py uses open(file_path) where file_path is a URL (#2654)
263d3401 Upgrade Dockerfile to stretch. (#2647)
fab4b15e Fix quarel explanations (#2648)
37a078af make things backward compatible with spacy 2.0 (#2644)
e79b713d add dependency parser config (#2639)
305bd35c final_state_tuple is a Tuple (#2645)
a4a43066 Checkpointer should check in case user deleted a serialized model (#2531)
3c889cae Update outdated doc (#2641)
12626ac4 fix sampled softmax tests (#2061)
c06e9045 add option ""-k"" to limit tests in test-install command (#2635)
1357c7e8 Remove reference to install_requirements.sh from the README (#2633)
0bbd359f Add workaround for missing linking in spacy 2.1, remove install_requirements.sh (#2632)
1b07b481 Bump up spacy version pin to 2.1 (#2626)
e3038a3f bug fixes in drop evaluation and more test cases (#2594)
f8b10a94 Add a no-op trainer. (#2610)
9e72ee03 Fix TextClassificationJsonReader handling of unlabeled instances (#2621)
01065364 Add text classification model (#2591)
43b384d4 Move some scripts to `allennlp/allennlp/tools` (#2584)
fe80f9fb Fix 'cuda_device' docstring in Trainer.__init__ (#2613)
f19c0ee2 Enable Pruner class to keep different number of items for different entries in minibatch. (#2511)
3cdb7e21 Ensure contiguous initial state tensors in `_EncoderBase(stateful=True)` (#2451)
ca998b26 Feature Request: Add a `dtype` parameter to `ArrayField` (#2609)
ff908456 change pins to bounds (#2490)
0fffb9b0 Allow the transition from M to M in the BMES constraint type (#2611)
0542c5a6 make spacy word splitter return allennlp Tokens (now NamedTuples) by default (#2607)
9e3f4052 Only log the keys in the ""extras"" dictionary when instantiating objects from_params (#2608)
720d306b Handle edge cases in beam search (#2557)
79936e5e Re-use .allennlp when running Docker commands (#2593)
55458f51 fix bugs in naqanet (#2604)
c163b638 Fixed memory error in `make_vocab` on big dataset. (#2606)
b61d511d context manager that allows predictor to capture model internals (#2581)
3e0fcf0b Update README.md (#2601)
18312a0c Seq2seq dataset reader improvements (#2599)
1adb3e8a Interactive beam search (#2513)
0f7bcf52 Add support for overriding list elements (#2585)
9437b614 disable tutorial test (#2580)
6ea273ef Allow checkpointer to be initialized from params (#2491)
b0ea7ab6 Make tutorial use GPU if available. (#2570)
41174daa Fix unit test to work with GPUs. (#2574)
32defc3b fix a bug in augmented_lstm.py (#2534)
cdbac6db Fix min padding length in pretrained NER predictors (#2541)
d0f7170b Make `load_archive` operate on serialization directories. (#2554)
31af01e0 Add missing requirement to setup.py (#2564)
c54fcc62 Add NAQANet model for DROP (#2560)
97f3578b add initializer to copynet (#2558)
bbb67e9f Add dataset reader for DROP (#2556)
4d5eadee Add official DROP evaluation script (#2559)
3d5560fa missing `=overrides` argument when instantiate Params despite a second time (#2553)
64a8e130 Scope DeprecationWarning errors to just allennlp-internal stuff (#2549)
321cf915 Clarify `data_parallel` implementation. (#2488)
540ebac7 Propose a deprecation policy. (#2424)
6d8da973 make archival take an optional output path (#2510)
fefc4390 Restore tensorboard epoch metrics to pre-refactoring behavior (#2532)
0205c26f Bump version numbers to v0.8.3-unreleased
",91356408
192,False,False,2019-02-19T15:41:09Z,2019-02-19T16:59:36Z,"# List of Commits

4bac9b55 bump version number to v0.8.2
3a5373fd upgrade huggingface pretrained bert (#2524)
2f2b481c Adding bag_of_embeddings as an alternate name for the boe encoder (Issue #2268) (#2521)
9f87aa56 fix typo (#2508)
751d2e1e Remove extended_vocab argument from extend_embedder_vocab API. (#2505)
cf6eff22 Allow vocab+embedding extension in evaluate command. (#2501)
39413f22 Add necessary implicit embedding extension for transfer-modules api and vocab extension (#2431)
47feb35e remove notebooks and juptyer dependency (#2499)
56c11e53 Revert ""Less restrictive token characters indexer (#2494)"" (#2497)
89056f1e Less restrictive token characters indexer (#2494)
43dc4cb4 upgrade pytorch-pretrained-bert (#2495)
b9a40036 Add momentum schedulers to trainer (#2469)
19d0f592 Add support to transfer submodules, and in different modes. (#2471)
ce83cb41 Variational dropout in Augmented LSTM (#2344)
2e7acb05 Mark QaNet test as flaky (#2481)
23ea5908 Add support for pretrained embedding extension in fine-tuning. (#2395)
dbd70851 WIP: Make warnings errors and filter library warnings from pytest (#2479)
234fb18f make bag_of_word_counts token embedder ignore padding and UNK tokens (#2432)
e5a74abc [Feature Enhanced] Support sentence pair in BERT (#2279)
6f5f5657 Fix CORS error for react in config explorer (#2476)
08a8c5e5 Add QaNet model (#2446)
e4174868 Fixes unnecessary parameter clone in moving average. (#2468)
9a2f1982 Add support to kwargs in TimeDistributed (#2439)
9a5ea1a2 Ten times faster than before in GPU get_best_span of bidaf (#2465)
84eb4d1a More help info for `archive_surgery.py` (#2327)
a8e0f15f Make `mask` in `PassThroughEncoder` work (#2448)
2b52492e Fix path issue for certain cases when using --include-package (#2464)
35f7f169 Update `Running AllenNLP` in README.md (#2447)
dddcbf24 Cleanup global logging after training (#2458)
5560466e [Feature Enhanced]Add FeedforwardEncoder for Sequences (#2444)
5ff923c5 Generalize LR scheduler (#2345)
508cb730 Instantiate the class `Activation` properly when testing FeedForward. (#2443)
dc901a6a rename test case (#2441)
00c877b9 Fix edgecase of potentially missing best-val-metrics in metrics.json on training recovery (#2352)
4465a6e4 Support exponential moving average in the default trainer. (#2406)
b6cc9d39 Optimizing the memory usage in `multi_head_self_attention` and `masked_softmax` (#2405)
90f39f91 Mark Atis Parser tests as flaky. Fix pylint. (#2430)
8b07c42a Improve error message for ""undocumented modules"" (#2427)
585c19e4 Fixing BERT mask size (#2429)
b7d56ae0 Fix typo when loading train state (#2425)
cb9651a4 Add AUC metric. (#2358)
9b01d4ca fix params duplicate bug (#2421)
c1aace7e Get rid of hardcoded Vocabulary class name. (#2418)
55b9bd08 serialization in the tutorial (#2412)
d6e3140f Replace scripts with entry_points.console_scripts (#2232)
3baec620 Remove outdated reference to custom extensions (#2401)
012e42dd Ensure vocab is popped off params (#2409)
a9b34750 Fix docstring for PretrainedBertIndexer's pretrained_model param (#2399)
11d83278 Fix typing for python 3.7 (#2393)
7525c610 Remove scattering for multi-GPU training. (#2200)
d0a5a40a Remove unnecessary line (#2385)
9719b5c7 Allow embedding extension to load from pre-trained embeddings file. (#2387)
174f5395 enable pickling for vocabulary (#2391)
2d29736b Add support for extending Embeddings/Embedders with Extended Vocabulary. (#2374)
7cc8ba04 Rollback PR #2308 ""Check train/dev/test-file-path"" (#2386)
4fe8fa0d move model to cuda in tests, add comment (#2384)
8eb2d75c Text classification JSON dataset reader (#2366)
e9b0acac Make DomainLanguage handle executing action sequences directly, with side arguments (#2375)
122a21a5 changed log-to-console flags (#2381)
385e66e8 pieces for multitask learning (#2369)
ae63a2ae New WikiTables language (#2350)
fc91f3e6 Sparse Gradient Clipping (#2312)
7da19bc8 Disable requires_grad for Transformer ELMo parser. (#2336)
e9287d4d Bag of words token embedder (#2365)
e75b19b8 Use f-string (#2370)
e2af6b44 Install package in dockerfile (#2305)
9649f3a2 fix a typo (#2367)
e08ade81 trainer refactor (#2304)
be57ecc3 Add snippet for using `LanguageModelTokenEmbedder`. (#2359)
abc10ed9 Update create_a_configuration.md howto by removing old allennlp configure (#2330)
083f49ea Bump up pytorch-pretrained-bert to v0.4.0 (#2349)
aa8ed3b7 Added StackedBiDirectional to list of encoders (#2339)
51ac8142 Add optional additional tokens to ELMo character indexer (#2364)
6bd59751 sanitize environment variables that can't be unicode encoded (#2357)
0f6796aa Fix very minor docstring typo in elmo.py (#2361)
0409371e New NLVR language (#2319)
632b14ce Warn default value of min_padding_length (#2309)
4c5de577 adjust call to lisp_to_nested_expression (#2347)
43ea97cc QuaRel Domain Language (#2321)
23687601 Remove pylint ignores for backslashes. (#2331)
e6ad6e9a Evaluate on a token-weighted basis. (#2183)
71ebcd84 add infer_and_cast (#2324)
059b0572 remove custom extensions (#2332)
5f9fb419 Stacked Bi-Directional LSTM to be compatible with the Seq2Vec wrapper (#2318)
93250f05 Skip Custom Highway LSTM tests, since they're broken (#2307)
7ecf772d Fix backslash exceptions. (#2322)
5bce1d54 Display default values in help message for allennlp command (#2323)
36d74006 Added links for some tutorials and organized the How-to alphabetically. (#2315)
f1600591 Add raw prefix to avoid warnings from regex (#2310)
8a7f808b Check train/dev/test-file-path before process (#2308)
7d3b130e Masked Flip (#2299)
b0e29566 Add CopyNet seq2seq model (#2237)
a4670adb Grammar induction from a python executor (#2281)
088f0bb6 Turn BidirectionalLM into a more-general LanguageModel class (#2264)
f76dc70b Bump version numbers to v0.8.2-unreleased
",91356408
193,False,False,2019-01-07T23:40:17Z,2019-01-08T17:29:13Z,"# Highlighted changes

* We now include a script to easily update pre-existing model archives (#2223).
* We fixed an issue that caused issues using AllenNLP from within iPython (#2257).

# List of Commits

b0191969 Don't deprecate bidirectional-language-model name (#2297)
01913fb4 Update the base image in the Dockerfiles. (#2298)
1bec3f96 Add __repr__ to Vocabulary (#2293)
73f0e5b9 Update the `find-lr` subcommand help text. (#2289)
e13aae41 fix #2285 (#2286)
2f662cf4 Fix spelling in tutorial README (#2283)
e6b0f213 script for doing archive surgery (#2223)
259ce322 Add a Contributions section to README.md (#2277)
e394b7a9 Fix type annotation for .forward(...) in tutorial (#2122)
cf6a7d7d Fix bug in uniform_unit_scaling #2239 (#2273)
511c846c Deprecate bidirectional-language-model for bidirectional_language_model (#2253)
b5141b23 fix doc (#2213)
0d54a7a3 Add a quick README for training transformer ELMo. (#2231)
07d193ee clarify the ""num_output_representations"" more clear (#2256)
ee02ed0f Fix multiGPU peak gpu memory test (#2254)
fb587833 Check for existing vocabulary before creating a new one (#2240) (#2261)
3cff7d35 Remove deprecated SpanPruner (#2248)
a98481c8 Remove deprecated batch_average argument to sequence ce with logits (#2247)
cf671280 Remove EpochTrackingBucketIterator (#2249)
2f56765b fix get_output_dim() for ElmoTokenEmbedder (#2234)
42e0815e Fix circular dependency. (#2257)
b5b9b401 add some docstrings about parameter `force` (#2226)
e53b4f45 Allow loading model from path with ~ HOME (#2215)
3f0953d1 change mislabeled variable in description (#2242)
1938a5af fix completely masked case in BooleanAccuracy (#2230)
fe626580 Corrected documentation (#2229)
e2f66c0d Simplifies Subsequent Mask  (#2224)
ce060bad Bidirectional LM Embedder (#2138)",91356408
194,False,False,2018-12-19T17:49:23Z,2018-12-20T00:14:13Z,"# Major New Features

* PyTorch 1.0 support

# List of Commits

e142042c Update pretrained.py
4cc4b6b6 Remove constraint_type parameter from CRF Tagger (#2208)
eff25a30 Adding metadata and debug info for the NLVR demo (#2214)
050b7671 Update predicting_paper_venues_pt2.md
bb000a01 Allow NLVR predictor to handle string inputs for the structured representation (#2209)
6aaf76ae Adding DatasetReader for the bAbI tasks and Qangaroo (#2194)
3fd224fc fix lowercase-ization in bert indexer (#2205)
a2084fd3 Remove last_dim_softmax as it's deprecated and scheduled for removal. (#2207)
d1bae5ce Remove deprecated dataset_readers.{nlvr, wikitables} components. (#2206)
06637629 Fix (most?) warnings from BasicTextFieldEmbedder (#2117)
c6663579 Adding an initializer to initialize a model to pretrained weights (#2043)
30612985 Fix loaded model not taken to cuda device (#2190)
7e22b861 add CPU/GPU usage in metrics.json (#2136)
12d32972 Make bz2 and lzma optional dependencies (#2196)
a558f7f4 minor spelling tweaks (#2192)
89cef2f0 Clean up temporary archive directory at exit (#2184)
0ae699a5 empty time stamp should be a str instead of int 0 (#2153)
8e861e75 (upstream/add_memory_usage_into_metricsA) pytorch 1.0 (#2165)
d0d6310b add default argument for SpacyWordSplitter (#2174)
a89aebae Minor fixes to help evaluate ELMo port. (#2172)
da761e8f pre commit hook to verify file sizes (#2151)
41c71960 instantiate multiprocessing.log_to_stderr lazily (#2166)
021471a9 Transformer ELMo (#2119)
6c33005c fix bert input order (#2145)
a8adc6c1 Fixes broken link and rephrasing visualizing_model_internals.md (#2162)
140c3ec5 make max dialog length configurable through json file (#2160)
2e412e33 fix mismatches (#2157)
a75cb0a9 Update the elmo command help text. (#2143)
7dbd7d34 add [CLS] and [SEP] tags to bert indexer (#2142)
411b5a2f upgrade pytorch-pretrained-bert + fix kwarg (#2130)",91356408
195,False,False,2018-12-03T18:54:13Z,2018-12-03T21:37:05Z,"# Major New Features

* You can now run `allennlp configure` to launch a GUI tool that helps you build a model configuration.
* You can now use a BERT embedder within you model.

# List of Commits

ca7e3cf3 release config explorer (#2118)
27830443 pin msgpack (#2125)
3eecd1aa more informative message for BasicTextFieldEmbedder mismatched keys (#2124)
3a7e0659 fix epoch tracking (#2121)
db0096f1 Fix more BasicTextFieldEmbedder warnings (#2114)
f757f7a0 Fix epoch tracking bucket iterator warnings. (#2108)
44269a1d Rename DATASET_CACHE to CACHE_DIRECTORY. (#2000)
3842820c Fix span pruner warning. (#2113)
92c71a17 Upgrade flask to remove werkzeug warning. (#2107)
240974fc Pack batches more tightly with maximum_samples_per_batch. (#2111)
42d076ee modify BERT embedder to deal with higher order inputs (#2104)
dcd1d25e Resolve some of the token_embedders warnings. (#2100)
2648d952 Add BLEU metric to simple_seq2seq (#2063)
582d0e4f add BERT token embedder  (#2067)
d78daa44 Fix EVALB compilation by cd to directory path instead of binary path (#2090)
6b16222b calypso transformer (#2049)
5890111b Separate calculation of num_tokens per TokenIndexer (#2080)
193bb04d Specify path at which to compile evalb. (#2027)
af902a3f Add support of tokenized input for coref and srl predictors (#2076)
e3e8e1cb Fix typo in IntraSentenceAttentionEncoder docstring (#2072)
d5040896 Add wikitables predicator to the default predicators (#2071)
2a2d9c94 Improve server_simple by adding predict_batch and adding GPU option (#2064)
19c784fa Add BLEU metric (#2001)
6ecd1932 Fix logging statement so it has the proper scope. (#2059)
888c11a3 add flaky decorator + increase tolerance (#2060)
86da8809 add sampled softmax loss (#2042)
07b57491 Enable multi-gpu training in find_learning_rate.py (#2045)
43243acf Update issue templates
de7c013e Sentence splitter (#2036)
0701dbdc Dynamic stopwords (#2037)
aa1b774e Test sql decoding (#2030)
a5c2d9eb Catch nan loss in training loop (#2029)
82bbee7d (warnings) Add link to EMNLP tutorial from tutorial README.
68cbfb80 modify training_configs related issue #1954 (#1997)
481c1817 Fix ArrayField.to_tensor not working with a scalar (#2008)
be36374e change stopping factor default (#2021)
b919f5ae Add logging statement when EVALB is compiled. (#2018)
3ca69420 Support stdin for prediction jsonl. (#2003)
bae77581 Change log level to clean up allennlp command. (#2004)
1406a856 Added default predictor for bimpm model (#2014)
77517992 Ignore hidden files in vocabulary/ (#2002)
6af83e7c Prevent inspect_cache from swallowing exception. (#1999)
e4f9131c Untyped grammar (#1986)
a4b885cd Add scalar_mix_parameters to Elmo.from_params (#1992)
1f782d33 Add --force option to find-lr command (#1991)
021f8bb1 use wordsplit with taggers (#1981)
c262ef5a Match vocab generation in currently online Event2Mind model. (#1978)
bc97ce87 combine_tensors_and_multiply_with_batch_size_one_and_seq_len_one (#1980)
5aa1c8f0 Fix for import_submodules (#1976)
02317e12 add min_padding_length to TokenCharactersIndexer (#1954) (#1967)
39e16c41 delete swp file (#1975)
ad729e37 Link tutorial site from tutorials/README.md. (#1972)
2a8bd638 Extend GPU fixes from vidurj and MaxMotovilov (#1944)
",91356408
196,False,False,2018-10-25T22:12:07Z,2018-11-12T16:24:56Z,"This is a minor release.

# List of Commits

5512a8fb Add config for non-elmo constituency parser, rename existing parser config (#1965)
dedc4cef Try compiling EVALB in metric if it doesn't exist (#1964)
26f09cff Disable tqdm when there isn't a TTY (#1927)
9a3e4b6b Add Windows support info to README.md (#1962)
a3bd4759 Update elmo.md
19d106e7 minor bug fix in get_agenda (#1959)
4e440970 Add scalar_mix_parameters to ElmoTokenEmbedder.from_params (#1956)
02640024 Add scalar_mix_parameters to ElmoTokenEmbedder (#1955)
ce0bc55b Add training config for bidaf with elmo (#1953)
c6fb86d2 Various fixes related to the variable free wikitables world (#1917)
aeb2fc30 Fix small typo (#1939)
d089d52f Add a dimension check to DialogQA, fix example configuration (#1934)
3e2d7959 Remove the report from pylint. (#1932)
53a555c4 Update training_and_evaluating.md (#1837)
afc36eb1 Add a --force command to train (#1913)
947bd165 make api more pythonic (#1926)
0e82106c clean up simple_seq2seq tests (#1928)
b529f6df Generalize beam search, improve simple_seq2seq (#1841)
b0ade1bf add matplotlib to setup.py (#1919)
188e06d7 Passing the 'stateful' parameter to the 'PytorchSeq2SeqWrapper' (#1925)
360c3e10 Text2sql model (#1905)
f29839e0 fix BiMPM url in MODEL.md (#1923)
404b5296 Enable setting scalar mix parameters for ScalarMix and Elmo (#1921)
9fcc7956 Learning Rate Finder (#1776)
63836c42 Adding support for list, tuple, and set in from_params (#1914)
f224c628 Agenda improvements (#1897)
2ec52a5d Uptick cffi to 1.11.5 (#1846)
0e47d160 bidirectional LM + cnn highway encoder + gated cnn encoder (#1787)
158a29c1 Tentative port of `LMDatatsetReader` (#1881)
ae7b9a73 Move 'What is AllenNLP' from README to docs. (#1909)
a94a23eb More closely emulate original Event2Mind implementation. (#1903)
d3a8f4f6 Track dev loss in ATIS model (#1907)
c4505659 Update README.md
3753b0b2 Multilayer decoder for semantic parsing framework (#1902)
7a707ea2 Make `SlantedTriangular` a little more robust (#1751)
4a22c292 # added optimizer parameter (#1766)
27fab848 Add more configuration options for ATIS semantic parser (#1821)
dc66c8f9 Fix QuaRel reference (#1899)
ae9c9c83 try to do some type inference on variables (#1898)
1691cb3a Run ActionSpaceWalker on the new variable free language for WikiTables (#1860)
0d9ad655 Var free grammar (#1893)
24e5547b feature-enhancement: make trainer registrable (#1884)
91bfb4c0 Global grammar values (#1888)
ffab3201 strings in sql/prelinked entities (#1876)
043ff07c allow Model to use custom Vocabulary subclasses
c1dcd0ff Reflects the updated code (#1873)
371fd807 input_size of phrase_layer: 1144 -> 1124 (#1875)",91356408
197,False,False,2018-10-05T21:58:33Z,2018-10-05T23:01:59Z,"# Major new features

- A [new framework](https://github.com/allenai/allennlp/blob/master/tutorials/getting_started/semantic_parsing.md) for training state-machine-based models, and several examples of using this for semantic parsing.  This still has a few rough edges, but we've successfully used it for enough models now that we're comfortable releasing it.
- A [model](http://demo.allennlp.org/open-information-extraction) for neural open information extraction
- A [re-implementation](https://github.com/allenai/allennlp/blob/master/allennlp/models/graph_parser.py) of a [graph-based semantic dependency parser](https://www.semanticscholar.org/paper/Simpler-but-More-Accurate-Semantic-Dependency-Dozat-Manning/03c3070e0d39513bb8d324d9f0ca602f7d827d6a).
- A [MultiProcessDataIterator](https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/multiprocess_iterator.py) for loading data on multiple threads on the CPU (we haven't actually used this much, though - if you have trouble with it, let us know).

# Breaking Changes

1. Previously if you were working on a GPU, you would specify a `cuda_device` at the time you called `instance.as_tensor_dict()`, and the tensors would be generated on the GPU initially. As we started to develop code for generating instances in parallel across multiple processes, we became concerned that over-generation of instances could potentially exhaust the GPU memory. 

Accordingly, now `instance.as_tensor_dict()` (and all the `field.as_tensor` operations that underlie it) always return tensors on the CPU, and then the `Trainer` (or the evaluation loop, or whoever) moves them to the GPU right before sending them to the model.

Most likely this won't affect you (other than making your training loop a tiny bit slower), but if you've been creating your own custom `Field`s or `Iterator`s, they'll require small changes as in #1731 

# List of commits

7ddc7f1 Automatically map function names to aliases for NLTK's logic parser (#1870)
3989000 Bug fix binary expression in updates to grammar (#1869)
3d78e46 Tutorial for the semantic parsing framework (#1853)
c530fde Update MODELS.md for Event2Mind. (#1866)
8ff8324 Add QuaRel semantic parser (#1857)
8236624 Compile and fix warning for regex in SQL action seq formatting (#1864)
5172c85 Create a markdown file that enumerates available models (#1802)
2111428 Use test-install rather than verify.py (#1849)
c635bc4 Graph parser for semantic dependencies (#1743)
c728951 Integrate new table context in variable free world (#1832)
3de6943 Avoid deprecation warnings (#1861)
a7da2ab Fast grammar generation (#1852)
d8b13e0 Simplified GrammarStatelet, made a new LambdaGrammarStatelet class for WikiTables (#1829)
1d50292 Use current_log_probs instead of log_probs in debug_info (#1855)
0934512 move ftfy to right section, fix req. check script (#1858)
6183c90 Remove wget in wikitables tests by using requests (#1854)
358c36b Raise RuntimeError if java is not available (#1856)
99308f6 Structured sql data (#1845)
53b166e Executor for WikiTables variable free language (#1762)
38c87e0 fix network issue (#1844)
0b852fb Add Open AI tokenizer, and ability to add special tokens to token indexer (#1836)
f7c4195 Faster data loading for SQL Context (#1838)
a1ec53d initial text2sql grammar with unconstrained context (#1834)
a6b4c30 Add per node beam size option to beam search (#1835)
63ba3fb make some sql context code more generic (#1831)
e84e496 Support adding to vocabulary from pretrained embeddings (#1822)
9c7d0d0 sql data updates (#1827)
b1db1c9 ATIS Predictor (#1818)
53bba3d SQL Executor (#1815)
8be358e Seq2Seq Test Cleanup (#1814)
02e2930 Model can store extra pretained embeddings (#1817)
f65ced5 Add an example of using ELMo interactively (#1771)
0459261 Atis model action refactored (#1792)
546242f Fixes for seq2seq model (#1808)
63fcada Make num_start_types optional in transition functions (#1811)
7833447 Load the pre-trained embeddings for all NER tokens (#1806)
c78bb36 Add a correctness test for Open AI transformer (#1801)
e64373c Update README.md
01d2906 Add tags_to_spans_function param to SpanBasedF1Measure. (#1783)
3906981 Moving the WikiTables executor into semparse.executors (#1786)
7647de8 Fixing the table format for the WikiTables executor (#1785)
6039ac0 SQL Coverage script (#1750)
0b44bce Rename SOURCE_COMMIT to ALLENNLP_SOURCE_COMMIT. (#1784)
9306e97 Add minimal configuration to existing models. (#1770)
ae72f79 Better multi-word predicates in Open IE predictors (#1759)
cca99b9 Add a predictor for Event2Mind. (#1779)
63dbdf1 one tutorial to rule them all (#1613)
8759ea3 Event2Mind (#1679)
c5501c7 fix trainer initialization (#1761)
898cfed BiattentiveClassificationNetwork with ELMo and without GloVe (#1767)
421f9a4 add simplest possible pretrained model interface (#1768)
b9cbfd6 Add an example of how to read ELMo embeddings with h5py (#1772)
e4f41e7 use managers for queues (#1769)
64f253f Add a requirements check to scripts/verify.py (#1699)
b5087e7 multiprocess dataset reader and iterator (#1760)
1761684 Fixed bug in _get_combination_and_multiply for batch size equal to 1 (#1764)
ffe037d Update README.md (#1763)
606a61a output metrics.json every epoch (#1755)
49f43ec Remove large openie model file (#1756)
609babe Add logging of learning rates to tensorboard (#1745)
eda2ba5 Set up `SlantedTriangular` for first batch (#1744)
1d81d8b Grammar for a variable free language for WikiTableQuestions (#1709)
4674b01 Make bmes_tags_to_spans support ill-formed spans. (#1710)
4c99f8e Text2sql reader (#1738)
8867f2f create tensors on cpu, move them to gpu later (#1731)
0664893 Discriminative fine-tuning, gradual unfreezing, slanted triangular learning rates (ULMFiT) (#1636)
1532886 Rename and organize tutorials (#1741)
72f7b4b Remove bucket iterator shuffle warning. (#1742)
8bbde0d Fix index_with bug in basic iterator (#1715)
3f54fc8 make openai transformer byte pair indexer add to the vocab (#1705)
7bf930f Add Open Information Extraction (#1726)
6c1607e bump gevent to 1.3.6 (#1732)
934ee17 Update training_and_evaluating.md (#1721)
72c9e98 Sql text utils (#1717)
ec25acd Update README.md
647e53e Removing contents of requirements.txt file (#1729)
a585994 Update configuration.md (#1722)
a61aa67 Moving allennlp.nn.decoding to allennlp.state_machines (#1714)
0b7bb20 Fixes and updates to README.md (#1718)
c47318b Add configs for tasks in ELMo paper, with and without ELMo (#1626)
f2884ad require torch 0.4.1 (#1708)
ef72e2e Save learning rate scheduler to training state (#1650)
6cb7005 Add average parameter to sequence cross entropy (#1702)
5e68d04 Rename SpanPruner -> Pruner, remove -infs (#1703)
",91356408
198,False,False,2018-08-30T23:07:53Z,2018-08-31T00:19:25Z,"This release includes a new dependency parser model, a QUAC model, and a new NLI model, as well as many bugfixes and small improvements.

4920249 bump version number to v0.6.1
ec2d5a1 skip moto tests, unpin dependencies (#1697)
863ded8 Add option to keep sentence boundaries in Elmo (#1695)
e027478 Upgrade Flask to 0.12.4 (fixes bug) (#1694)
335d899 Make SpanBasedF1Measure support BMES  (#1692)
d16f6c0 Add a default predictor for biaffine-parser. (#1677)
4b6f8d1 Remove inplace modification in Covariance (#1691)
a0506a7 remove print statement (#1690)
89729e0 Add BMES constrain to is_transition_allowed function (#1688)
3df54c8 Removing last_dim_*softmax (#1687)
d1f6748 minor memory improvements in _joint_likelihood() of ConditionalRandomField with advanced indexing (#1686)
2a45f44 Add Covariance and PearsonCorrelation metrics (#1684)
1b31320 Add MeanAbsoluteError metric (#1683)
e9710c8 Fix links in docs and improve check_links.py (#1680)
cbeef92 Predictor for QUAC models (#1674)
279f325 SQL semantic parser entity improvements (#1658)
45e6a0f pin boto3 + awscli (#1671)
fcdbbd3 require Python 3.6.1 (#1667)
5a305e3 improve API, update tests (#1664)
6c7c807 Adding decoder to bimpm and improve demo server. (#1665)
9caac66 Fix lazy dataset reader bug in ModelTestCase (#1668)
0b3ebcf Reading comprehension model for QUAC dataset (#1625)
994b996 Make CrfTagger work with non-BIO tagging tasks (#1661)
c31d5f9 Fix conll2000 data reading (#1657)
abfb32d Refactoring how actions are handled in the semantic parsing code (#1294)
75abebb Standardize tagging datasets (#1656)
362060a add back sniff test for parser (#1654)
5e13d24 Fix Conll2003 reader docs to reflect true label namespace names (#1655)
fea0d0a Upgrade flask to avoid security vulnerability. (#1653)
d27770a Make replace_masked_values more efficient by using masked_fill (#1651)
4ade6e4 Fix module docstring for training.learning_rate_schedulers (#1649)
301f2d6 Implement cosine with restarts (#1647)
681a9cf make pos selection an option in dataset reader, use in predictor (#1648)
bca6c2a make max_vocab_size default to None for a given namespace in Vocabulary._extend (#1643)
1d43188 Add learning rate to logs (#1641)
b70e026 Make LinearAttention and LinearMatrixAttention memory-efficient (#1632)
be76b5c Add missing --recover flag to train docs (#1640)
2e47ac4 typing is part of standard library from python3.6 (gives errors on python3.7) (#1638)
4df4638 Data reader for QUAC (#1624)
bf75c9b Allow configurable label namespaces (#1621)
4c6731b Pip install the library in editable mode (-e) (#1592)
14aee14 fix calculation of estimated time remaining (#1631)
8c89b08 Parser decoding fix 2 (#1619)
7a9975e Fix bimpm config file for names num_perspective(s). (#1627)
0a5aea7 atis dataset reader (#1577)
659bf25 Allow files to be downloaded from S3 (#1620)
76a65a8 BiMPM model (#1594)
58119c0 make fine-tune not expand vocabulary by default (#1623)
3107a0c Don't error if fine-tune serialization dir already exists (#1622)
82686c1 Add IOB1 as allowed CRF constraint (#1615)
59132d2 Avoid divide by zero in CategoricalAccuracy (#1617)",91356408
199,False,False,2018-08-15T16:29:47Z,2018-08-15T17:56:03Z,"AllenNLP v.0.6.0 has been upgraded to use PyTorch 0.4.1. Accordingly, it should now run on Python 3.7.

It contains a handful of breaking changes, most of which probably won't affect you.

# Breaking changes:

## 1. HOCON -> Jsonnet for Configuration files
Although our experiment configurations look like JSON, they were technically [HOCON](https://github.com/lightbend/config/blob/master/HOCON.md) (which was a superset of JSON). In this release we changed the format to [Jsonnet](https://jsonnet.org/), which is a *different* superset of JSON.

If your configuration files are ""JSON with comments"", this change should not affect you. Your configuration files are valid jsonnet and will work fine as is. We believe this described 99+% of people using allennlp.

If you are using advanced features of HOCON, then these changes will be breaking for you. Probably the two most common issues will be

### unquoted strings

JSON requires strings to be quoted. HOCON doesn't. Jsonnet does. So in the off chance that you have not been putting your strings in quotes, you'll need to start putting them in quotes.

### environment variables

HOCON allows you to substitute in environment variables, like

```
    ""root_directory"": ${HOME}
```

Jsonnet only allows substitution of explicit variables, using a syntax like

```
    ""root_directory"": std.extVar(""HOME"")
```

these are in fact variables fed to the Jsonnet parser (not environment variables); however, the allennlp code will read all the environment variables and feed them to the parser

### the elimination of `ConfigTree`

(you probably don't care about this)

previously the AllenNLP `Params` object was a wrapper around a `pyhocon` `ConfigTree`, which is basically a fancy `dict`. After this change, `Params.params` is just a plain `dict` instead of a `ConfigTree`, so if you have code that relies on it being a `ConfigTree`, that code will break. This is very unlikely to affect you.

### why did we make this change?

There is a bug in the Python HOCON parser that incorrectly handles backslashes in strings. This created issues involving initializer regexes being serialized and deserialized incorrectly. Once we determined that the bug was not simple enough for us to easily fix, we chose this as the next best solution.

(in addition, jsonnet has some nice features involving templates that you might find useful in your experiments)

## 2. Change to the `Predictor API`

The API for the `_json_to_instance` method of the `Predictor` used to be `(json: JsonDict) -> Tuple[Instance, JsonDict]`, where the returned JsonDict contained information from the input which you wanted to be returned in the predictor. This is now not allowed, and the `_json_to_instance` method returns only an `Instance`, meaning any additional information must be routed through your model via the use of `MetadataFields`. This change was to make `Predictors` agnostic of where `Instances` they process come from, allowing us to generate predictions from an original dataset using a `DatasetReader` to generate instances.

This means you can now do:
`allennlp predict /path/to/original/dataset --use-dataset-reader`, rather than having to format your data as .jsonl files.

## 3. Automatic implementation of `from_params`

It used to be the case that if you implemented your own `Model` or `DatasetReader` or whatever, you were required to implement a `from_params` classmethod that unpacked a `Params` object and called the constructor with the relevant values. In most cases this method was just boilerplate that didn't do anything interesting -- it popped off strings and strings and ints and ints and so on. And it opened you up to a class of subtle bugs if your `from_params` popped parameters with a different default value than the constructor used.

In the latest version, any class that inherits from `FromParams` (which automatically includes all `Registrable` classes) gets for free a `from_params` method that does the ""right thing"". If you need complex logic to instantiate your class from a JSON config, you'll still have to write your own method, but in most cases you won't need to.

There are some `from_params` methods that take additional parameters; for example, every `Model` constructor requires a `Vocabulary`, which will need to be supplied by its `from_params` method. To support this, the automatic `from_params` allows extra *keyword-only* arguments.  That is, if you are calling the `from_params` method yourself (which you probably aren't), you have to do

```
YourModel.from_params(params, vocab=vocab)
```

if you try to supply the extra arguments positionally (which you could when all of the from_params were defined explicitly), you will get an error. This is the ""breaking"" component of the change.

## 4. changes to `TokenIndexers`

previously the interface for `TokenIndexer` was

```
TokenIndexer.token_to_indices(self, token: Token, vocabulary: Vocabulary) -> TokenType:
```

this assumption (one token) -> (one or more indices) turned out to be not general enough. there are cases where you want to generate indices that depend on multiple tokens, and where you want to generate multiple sets of (related) indices from one input text.  accordingly, we changed the API to

```
TokenIndexer.tokens_to_indices(self, tokens: List[Token], vocabulary: Vocabulary, index_name: str) -> Dict[str, List[TokenType]]:
```

this is some real library-innards stuff, and it is unlikely to affect you or your code unless you have been writing your own `TokenIndexer` subclasses or `Field` subclasses (which is not most users). If this does describe you, look at the changes to `TextField` to see how to update your code.

--------

other changes:

95401255 Tree decoding fix (#1606)
4eaeff72 Fix use of scalar tensors in ConllCorefScores (#1604)
982ceddf Small typo fixes in tutorial (#1603)
45fff838 use empty list for no package not empty string (#1602)
e0e5f4a8 revert conllu changes (#1600)
49626cc1 filter out numpy 'size changed' warnings (#1601)
4fca0287 (include-package-fix) Log number of parameters in optimizers (#1598)
b79d5001 Add file friendly logging for elmo. (#1593)
152b590c Output details when running check-links. (#1569)
068407e3 make --include-package include all submodules (#1586)
12b74e5a Add some debugging echo commands to pip. (#1579)
9194b30b copy bin/ into image (#1587)
bf760b04 be friendlier to windows users (#1572)
4fa4dc23 fix and pin conllu dependency == 1.0 (#1581)
6b37dd2b Turn off shuffling during evaluation (#1578)
07bfc312 Demo features for the dependency parser (#1560)
025b5e7c Remove a step from verify. (#1565)
d2c02742 Don't use a hard-coded temp directory. (#1564)
15e36458 openai transformer LM embedder (#1525)
87b32bb3 Expose iterator shuffling through Trainer config (#1557)
52f44e24 Add parsimonious for SQL parsing to setup.py (#1558)
089d16dc SQL action sequences and Atis World (#1524)
6f0fec13 make passing different feedforward modules more flexible (#1555)
dcba726a WIP: Skip tests that require Java in test-install (#1551)
8438f91f Remove the unused NltkWordSplitter and punkt model. (#1548)
09c2cc56 Dependency parser predictor (#1538)
c2e70ca7 upgrade to pytorch 0.4.1 + make work with python 3.7 (but still 3.6 also) (#1543)
c000ae22 made checklist updates more efficient (#1552)
2ec4c5c2 re-work dependency parser to use HEAD sentinel inside model (#1544)
10ac9ede Update install_requirements.sh
1c2a0deb Remove requirements_test.txt (merge into requirements.txt) (#1541)
2154e726 Allow server start without field-names. (#1523)
e32f4865 fix BasicTextFieldEmbedder.from_params to reflect the constructor (#1474)
dc1ff363 Fix the reported broken links. (#1533)
e049afc0 fix ud reader in case of implicit references (#1529)
ad265f85 Add output-file option in evaluate to save the computed metrics (#1512)
c37ff2ca update config files to jsonnet format (#1479)
f3fce4c9 Move cache breaker to the end. (#1527)
c9385e78 Fixed broken link (#1508)
8cf893e7 Add a scirpt to report broken links in all markdowns. (#1522)
be69e52a Parser improvements (#1515)
e4b86b0e Show warning before ignoring key with unseparable batches from model.forward. (#1520)
2c9abf9a Minor change of a comment (#1500)
0722d7f1 DenseSparseAdam + CRF Feedforward layer (#1519)
1402b7c0 Add to_file method in Params and default preference ordering. (#1517)
e0581b61 Preserve best metrics (#1504)
de0d3f73 Dependency parser (#1465)
be0f0c25 Remove extra .params (#1513)
7df8275e Text field updates to support multiple arrays in TokenIndexer (#1506)
88c381a1 Make usage of make-vocab, dry-run consistent with train and allow 'extend' to be used by both (#1487)
34a92d0d Update using_as_a_library_pt1.md (#1509)
8e5ee656 fix dumb domain filtering (#1505)
8a208203 Ensure Contiguous Hidden State Tensors in Encoders  (#1493)
66b2c1c3 Bio to bioul (#1497)
f4eef6ee [for discussion] change token_to_indices -> tokens_to_indices (in preparation for byte pair encoding) (#1499)
9ec3aa64 Fix start of tqdm logging in training. (#1492)
ee003d24 Fix SpanBasedF1Measure allowed label encodings comment (#1501)
d307a253 Add IOB1 support to SpanBasedF1Metric (#1494)
9c21696d fixing a bug in trainer for histograms (#1498)
5f2f539a Add option to have tie breaking in Categorical Accuracy (#1485)
74577103 Update elmo.py (#1496)
5fc7a00d Fix SpanBasedF1Measure for tags without conll labels (#1491)
01ddd126 make tables nice in validation summary (#1490)
ba6f3451 Crf ner tweaks (#1488)
f5bbe592 Move param import (#1484)
e50b1027 fine grained ner reader (#1483)
d9e98610 don't call create_kwargs  for a class that has no constructor (#1481)
52c08355 instantiate default activation functions in constructor (#1478)
580dc8b0 (mostly) remove from_params (#1191)
ff41dda4 Implementation of ESIM model (#1469)
e2edc9b2 unwrap tensors in avg metric (#1463)
77298a97 Fix logging of no-grad parameters. (#1448)
bef52ed7 Fix call to vocab.token_from_index -> self.label_namespace (#1459)
7cc3db13 fix Vocabulary.from_params to accept a dict for max_vocab_size (#1460)
59ecd3b7 Fix conll2003.from_params incorrect default (#1453)
f09ff87e Allow to use a different validation iterator from training iterator (#1455)
a56fa40f remove RegistrableVocabulary (#1454)
f136ae00 Fix a typo in embedding_tokens notebook. (#1449)
d4ee5db1 Make bucket iterator respect maximum_samples_per_batch (#1446)
f0ed1d45 Few feature additions (#1438)
74a30d08 update the look and feel of the config explorer (#1412)
fa34344b refactor iterators (#1157)
43fc89ee Enables Predict to use dataset readers from models (#1434)
d2e3035f enable mypy on tests (#1437)
7664b121 Add support for selective finetune (freeze parameters by regex from config file) (#1427)
8855042f eliminate or make private most of the new Vocabulary methods (#1436)
a0c368a7 Fix an edge case for incompatible vocabulary extension. (#1435)
18d4fee3 remove adaptive iterator (#1433)
0312b16e Add support for configurable vocabulary extension (#1416)
5d382821 Avoid non-model state in predictors (#1422)
eaf5b7e1 Call  before logging to tensorboard (#1423)
872acf94 Make evaluation tqdm description ignore metrics starting with _ (#1430)
36d91fd1 Make tqdm description ignore metrics starting with _ (#1425)
70d4d3c3 use sensible default for num_serialised_models_to_keep (#1420)
9dbba338 Fix chdir in ModelTestCase breaking downstream models (#1418)
1031815a duplicate config in Predictor.from_archive (#1413)
2bf1e28b fix a minor typo in docstring causing wrong api usage docs of vocabulary config. (#1415)
e16a6b5b Split off function to find latest checkpoint in Trainer (#1414)
70b4ffb0 (jonborchardt/master) replace hocon with jsonnet (#1409)
8a314940 (upstream/ratecalculus, jonborchardt/ratecalculus) Add --include-sentence-indices flag to ELMo command (#1404)
4bd8e7f2 Add support for prevention of parameter initialization which match the given regexes (#1405)
76deabb5 Remove frontend (#1407)
6800d76a fix elmo command to use line indices and disallow empty lines (#1397)
e9030189 Fix multiple GPU training after upgrading to pytorch 0.4 (#1401)
db519aff Update README.md with ./allennlp/run.py (#1395)
3dff9c7a remove demo (#1338)
6da17d67 Adds support for reading pretrained embeddings (text format) from uncompressed files and archives (#1364)
5e38a081 Update Dockerfile.pip
da429d6d Update Dockerfile.pip
2b32a867 Update Dockerfile.pip
bb08b065 Add a Dockerfile for downstream usage of AllenNLP. (#1389)
bab565a0 Update elmo.py (#1388)
3aa81e71 In get_from_cache(), allow redirections in head requests (#1387)
f4d8d073 Output answers in wikitables predictor when inputs are batched (#1384)
a8072394 create ccgbank dataset reader (#1381)",91356408
200,False,False,2018-06-13T23:56:40Z,2018-06-14T00:23:07Z,"`numpydocs` was left out of requirements.txt and setup.py, so that `pip install allennlp` wouldn't install it and allennlp wouldn't work (unless you installed it manually). This fixes that.",91356408
201,False,False,2018-05-24T20:39:36Z,2018-05-25T01:42:09Z,"This is primarily a bugfix release as well as the final release on PyTorch 0.3.

* Fixes the [TQDM bug](https://github.com/allenai/allennlp/pull/1168/files) that was causing jobs to hang in our internal job execution framework (Beaker).

* [Moves tests](https://github.com/allenai/allennlp/issues/1217) into the source distribution, which a user needed to create a conda installation.

Here is a full list of commits:

66da4eed Update version numbers referred to in tutorials.
1c8b1492 (upstream/master, master) Fix crash when validation metric is 0 (#1274)
b4c9fe41 (release-v0.4.2) Migrate gevent's wsgi to pywsgi (#1272)
6b5b0172 `allennlp train` should fail faster if trainer.cuda_device >= 0 (#1196)
40691d3f Fix LR scheduler and test usage inside Trainer (#1255)
ed3697c3 Remove most mentions of python -m allennlp.run (#1264)
7b9d6a25 Consolidate installation instructions (#1261)
622ea1bf (origin/master, origin/HEAD) Tutorial cleanup (#1260)
c2b61c60 make evalb use unique temporary directories per process (#1254)
906b26f1 make it OK if serialization_dir exists but is empty (#1251)
5ebe103d Add missing close brace, standardize indentation in ELMo howto (#1252)
eabb37fc Output predictions in CSV format for official eval (#1249)
d1c36de9 Constituency Parser Demo Reference Update (#1248)
4f2db42f Replace slicing with chunk along the last dim (#1244)
a4f2fb8f Cache remote datasets with fixed-length filenames (#1230)
9ef013d3 Fix Constituency Parser / EVALB for pip-installed allennlp (#1233)
3dcde323 Add custom extensions to distribution and install (#1229)
229361c6 In train_model(), load the best weights at the end so that: (#1234)
76a5a80a changed checklist cost computation (#1231)
d0bd42d5 edit project root test (#1227)
356829d9 Add allennlp test-install command (#1213)
820cbfba gitignore EVALB generated files (#1214)
3a8fdb01 Include tests in source distribution (#1208)
10ea3b36 Add the attention visualization to the textual entailment demo (#1219)
b71ef434 Fix for https://github.com/allenai/allennlp/issues/203 (#1210)
f246da73 Add missing import to setup.py (#1215)
70862e09 Make pytest_runner a conditional requirement in setup.py (#1203)
10e7e99e Remove argparse from requirements (#1202)
e1fdad6e Added a ConstrainedBeamSearch, switched MML to use it (#1189)
7bd52cb7 Use README.md for PyPI long description (#1201)
2dda95be Changed how checklist balance is used in action prediction (#1204)
1554fb03 Update test requirements in setup.py, remove pytest-pythonpath (#1207)
a8f7adae Added dropout to the NLVR parser (#1205)
b5af3e47 Prune finished states in ERM (#1187)
77b33fb7 Add compute model number to Compile custom LSTM for Tesla V100 (#1198)
63f2108e Update ELMo command help docstring (#1195)
8ba58675 Added coverage to WikiTables ERM parser (#1181)
69ae074e Rename tutorials so they're clearly connected. (#1186)
65aecdd7 Add a tutorial for using the pre-trained models. (#1182)
3add61da check for zero grads only if grad is not none (#1188)
7142962d ERM parser for wikitables (#1159)
c369502a Add missing --all flag to ELMo howto (#1183)
ea2e431c Update using_in_your_repo.md
7cc4f72c Update using_in_your_repo.md
19980b52 Add shebang to bin/allennlp (#1179)
58f90337 Clarify the ELMo readme (#1167)
4f8834c7 fix comment (#1171)
af283d16 hack to stop tqdm hanging (#1168)
a6d4b1b7 Merge branch 'release-v0.4.2'
15f61028 bump version numbers in README
60e03e3d remove spaces in SpacyWordSplitter.batch_tokenize (#1156)",91356408
202,False,False,2018-06-13T17:33:49Z,2018-06-13T18:26:49Z,"Breaking changes:

- Starting with v0.5.0, AllenNLP is based on PyTorch 0.4. This version of PyTorch contains [many substantial changes from earlier releases](https://pytorch.org/2018/04/22/0_4_0-migration-guide.html) and the internals of AllenNLP required corresponding changes. It is possible that this may break some of your custom models.

- The prior `Attention` and `MatrixAttention` modules have been renamed `LegacyAttention` and `LegacyMatrixAttention`, and have been replaced with `Registrable` classes that allow for much more efficient attention implementations.  The minimal change to upgrade if you were using these previously is to just change where you have `Attention` to be `LegacyAttention`.  Though, it'll probably speed up your code and/or reduce memory usage if you switch to using the new `Attention`.

Large new features:

- We have added a Configuration Wizard that makes it easier to create configuration files for your experiments. Its use is detailed [in a new how-to](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/create_a_configuration.md).

Full list of changes:

7128324 (tag: v0.5.0) bump version number to v0.5.0
e17cbd1 fix bug (#1363)
691af4e address PR comments (#1362)
d844a9a fancy version of the configuration wizard (#1344)
6739c31 Make test_trainer_respects_keep_serialized_model_every_num_seconds more patient (#1358)
ac2e0b9 Make optional args actually optional. (#1357)
a08e7fd Move serve functionality out of allennlp command. (#1317)
97484fb Faster Elmo (#1347)
ca4d262 Remove norm from question / table similarity computation (#1354)
2cddc69 Add ability to add tokens to vocabulary namespaces (#1352)
b556e53 Format pytest logging correctly (#1351)
6aaeb70 Add bilinear attention (#1349)
f6d9ba3 Remove what appears to be outdated line (#1348)
6c87ff5 Make vocab (#1339)
0c2d5c7 config explorer webapp (#1329)
b6b8955 Fix link to demo.allennlp.org page (#1336)
4326b59 Fix link to installation instructions (#1335)
03d6fad (initializers-regularizers) command-line configuration explorer (#1309)
b0d0d94 LabelField.as_tensor returns 0-tensor (#1320)
765dc20 Add logging for the original path in load_archive. (#1323)
8eb358b Convert run_with_beaker.py to use Blueprints. (#1199)
427a319 Add version to AllenNLP command. (#1322)
2456983 Add option to keep Viterbi scores when predicting (#1314)
62f701e Remove default arguments from the simple server. (#1319)
50fcb0c how to for debugging using pycharm (#1312)
cebf719 SRL elmo 5b (#1310)
e37a68e Add ""Citing"" section to README.md (#1305)
0db4bc5 Add ELMo to BCN (#1308)
097ccd7 Update torch and tensorboard versions in setup.py (#1311)
26e7f41 add user contributed models blurb (#1306)
5352a19 make predictors more discoverable (#1302)
4849589 Script for generating logical forms from ERM model for wikitables (#1247)
504964b allow sanitize to work on custom classes (#1307)
200b27e A new model is only considered the best if it is better than others and not simply better or equal (#1246)
ed63b7e upgrade to pytorch 0.4.0 (#1126)
b26031d Ignore tests in coverage metrics (#1293)
986cf17 Improve performance of attention modules (#1235)
69b9af3 In Trainer, require ""patience"" to be a positive integer or None (meaning ""no early stopping""). Set patience=None by default. (#1271)
9cb0ea3 Add LICENSE to source distribution (#1291)
c26a513 Noam lr schedule (#1258)
59a0e5a Fix test-install by moving tests into module (#1232)
c0afe31 Insteall psycopg2-binary (#1286)
1f8125c (cli-params) Update the version of twine. (#1285)
5c06914 Use full version in docs. (#1283)
20da3fd Set long_description_content_type to markdown in setup.py. (#1284)
7e1080e Uptick version to unreleased. (#1281)
3c623c5 Fix links to the allennlp-as-a-library tutorials (#1279)",91356408
203,False,False,2018-05-01T17:04:52Z,2018-05-01T18:03:29Z,"The most immediate change is that now PyTorch is installed via `pip`, and you don't have to do it separately.   We also have new code to support a state-of-the-art NER model.

Here's the full list of commits:

d4b286c Mattp/ner (#1162)
d05673a Add a default cuda_device to model. (#1151)
281d032 Added two feature extractors that were in PNP and not in our version (#1155)
f8d64ef add stacked bilm (#1154)
f2257a6 Use separate action embeddings for prediction vs. input feeding (#1153)
cc510fa Allow ablation where linking features are removed (#1145)
121d3e8 unidecode in setup (#1148)
55b0411 Adding ReLUs after linear projections (#1150)
645379e Allow default predictors when calling programatically (#1112)
6d15d17 Allow to restart with optimizers on CUDA (#1144)
c684216 Streamlining the docker build a little bit (#1140)
bfff55f bug fix for empty decoder outputs (#1141)
b9630e6 Fix state scores in WikiTablesDecoderStep (#1129)
a869e0b Move imports to inside of CACHE_MODELS=true condition (#1133)
53ae735 clean EVALB via make, add to Dockerfile (#1132)
812dfcf Added a script to generate data from an ERM trained model (#1115)
2b81da7 Remove the KeyError catch block in the server (#1130)
960f913 Adding WikiTables and NLVR predictors (#1118)
7627a09 Use xavier_uniform for initializing embedding weights (#1120)
0df8978 Adding the wikitables parser (#1114)
f7b736c increase metrics logging precision (#1113)
7dfc342 Adding NLVR model (#1108)
bc8ac1a Adding WikiTables dataset reader (#1106)
cbe5897 Adding NLVR dataset reader (#1105)
f7924bc Adding KnowledgeGraphField and ProductionRuleField (#1104)
245a9af add name argument to run_with_beaker.py (#1103)
2e6f2dd Adding the type system / logical form parsing code from the wikitables branch (#1087)
eb81ac9 Update elmo.md (#1092)
1655f22 Adding the decoding framework from the wikitables branch (#1086)
3ea82b1 Moving over modifications to common / util modules (#1085)
f7b736c increase metrics logging precision (#1113)
7dfc342 Adding NLVR model (#1108)
bc8ac1a Adding WikiTables dataset reader (#1106)
cbe5897 Adding NLVR dataset reader (#1105)
f7924bc Adding KnowledgeGraphField and ProductionRuleField (#1104)
245a9af add name argument to run_with_beaker.py (#1103)
2e6f2dd Adding the type system / logical form parsing code from the wikitables branch (#1087)
eb81ac9 Update elmo.md (#1092)
1655f22 Adding the decoding framework from the wikitables branch (#1086)
3ea82b1 Moving over modifications to common / util modules (#1085)
78dc1df Data cleanup and additions from the wikitables branch (#1084)
6829edb Move the top nav bar to the left pane. (#1082)
14bb4e3 Revert ""Top menu -> Left menu (#1074)"" (#1081)
a92bf48 Top menu -> Left menu (#1074)
b72c838 Adding an optional projection layer to ElmoTokenEmbedder (#1076)
4c02d92 Reading glove embeddings: strip() --> rstrip() (#1056)
0a918aa read vocab params in model test when available (#1071)
8ddc8cb initial dry run command (#1063)
da1e6f4 Update setup.py
e8e2499 install pytorch via pip (#1062)
bcbc12e don't use mutable sys.stdout for both logs (#1060)
ebf25ea One line update in file_utiles.py (#1059)
9299131 Add a multilabel field (#1054)
db44a25 Add a get_final_encoder_states function that handles bidirectional encoders (#1048)
77da425 don't allow U tags in BIO to spans, use BIOUL in SpanF1Measure (#1045)
e444216 Add an ensemble model for BiDAF (#1000)
a5a827e Add Biattentive Classification Network (#1038)
78aa071 proper configuration of all dropout in self attention (#1042)
d0bb3d2 CoNLL dataset reader that allows BIOLU tags (#1041)
d57717e srl model tweaks (#1040)
1700db4 Minor enhancements to seq2seq data reader (#1037)
2b55bfb re-jig readme (#1034)
395646a Add Stanford Sentiment Treebank dataset reader (#1032)",91356408
204,False,False,2018-03-23T22:12:36Z,2018-03-23T22:40:12Z,"496867ca add an initial string representation to fields and instances (#1021)
008ceb26 Break up AWS login command in two to catch failures. (#1022)
a0ced895 reset meteric when done evaluation (#1020)
3ea3e64d fix logging error (#1017)
ab3bd0f5 add optional exclusive start indices flag to Enpoint Extractor (#1005)
f37bc6cc add some new optimisers and a cosine LR schedule (#1012)
a327d03c make srl predictor more robust (#1011)
5f722fcd Add .pytest_cache folder to gitignore (#1006)
31f4f604 better error for gradient check (#1010)
f06d62f5 readme: add port publishing for docker (#1009)
760853c5 Winobias reader (#968)
3c8e299a fix predictor issue for constituency parser (#1004)
d351ac7e Fix simple tagger link in creating a model tutorial (#1003)
e28415ca remove PREDICTOR_OVERRIDES and MODEL_OVERRIDES (#999)
1d68f889 (michael/master) add allennlp command (#987)
0c532d50 use correct PTB results on demo page (#990)
dc7a9d68 make hierplane div overflow so it's scrollable (#989)
565b95cf (matt/master) Constituency parser demo (#985)
eb794288 Change input name from ""source_string"" to ""source"" in Seq2SeqPredictor (#984)
7b2e09db Fix issue #973 and add predictor for SimpleSeq2Seq (#976)
40d337ea Keyboard interrupt + training admin (#983)
c7a4e6d4 don't require that EVALB is compiled on instantiation (#980)
5c663c45 fix span construction (#975)
3d100d31 Fix max_vocab_size bug (#964) (#966)
18eb4218 fix sentence encoder from params (#963)
9121eed6 Move --include-packages flag up to top level (#962)
cc2756db Add a link to the span representations tutorial (#959)
0ef211da fix online metric calculation for EVALB (#956)
c84c714c use biased estimator for layernorm, fix some views in multi head attention (#953)
71c80e39 Install nltk the normal way. (#932)
6044cced Allow to provide a custom `Module` in `Elmo` class (#945)
e6573532 add label smoothing to loss (#942)
f81e27a5 get the dimensions correct for the transformer (#941)
c12d4356 Automatically install spacy models, if missing (#933)
cdfe9aed add ImportError to lstm import (#938)
c66fac02 pos -> tag (#935)
dcd6487e More parser improvements (#934)
acf21a53 Fix #928 - Minor naming inconsistency in tutorial json files (#929)
0cb2f606 speed up metrics (#927)
394c26d8 add try except block with helpful message (#923)
97bc7a2d Combined recovery logic, made it not crash on beaker (#925)
de5df629 Fix random hash that's appened to git SHA (#924)
b7a9784e Nested constituents (#920)
085a7509 use gold pos tags for tree evaluation (#921)
8b706e42 Constituency js (#916)
740f4fbb Constituency Parser Predictor and tests (#914)
6a108577 Constituency training pr (#913)
6ad7d5bc Migrating to 0.4.0 (#909)
bca992ef Fix span masking (#905)
6f4de853 Update TextualEntailment text to highlight ELMo. (#906)
b891d374 (log-learning-rate) Merge branch 'release-v0.4.0'
5756ff6c Span tutorial (#903)",91356408
205,False,False,2018-02-20T19:43:09Z,2018-02-20T21:54:32Z,"**New features:**

* A major feature in the 0.4 release is the inclusion of ELMo which produces contextualized word embeddings that greatly improve model performance.  You can read more in our [ELMo HowTo](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md).
* Support for [lazy datasets](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/laziness.md), so you can stream data through the trainer with a lower memory footprint.  This is a breaking change for some parts of the API; if you've written a `DatasetReader`, you will probably need to change a little bit of code.  The `Dataset` class is now gone.
* First-class support for models that operate on [_spans_ instead of on _tokens_](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/span_representations.md).
* Support for [programmatically importing additional dependencies](https://github.com/allenai/allennlp/pull/727) so you don't need to write your own `run.py` script.
* A simple server to [create a stand-alone web demo](https://github.com/allenai/allennlp/blob/master/tutorials/getting_started/making_predictions_and_creating_a_demo.md) for your model.
* Added [constrained decoding](https://github.com/allenai/allennlp/pull/818) to the `ConditionalRandomField` module (and to the corresponding [NER tagger](https://github.com/allenai/allennlp/blob/master/allennlp/models/crf_tagger.py) model)

**Additional [tutorials](http://allennlp.org/tutorials):**

* A tutorial on [writing `Predictors`](https://github.com/allenai/allennlp/blob/master/tutorials/getting_started/making_predictions_and_creating_a_demo.md) for using `python -m allennlp.run predict` and for creating demos.
* Instructions for how to [visualize model internals](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/visualizing_model_internals.md) in a live demo of your model, for gaining better insights about what your model is doing.
* A tutorial on [how laziness works](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/laziness.md) in AllenNLP.

**Additional models / dataset readers:**
* A [span-based constituency parser](https://github.com/allenai/allennlp/blob/master/allennlp/models/constituency_parser.py) that independently predicts a non-terminal label for each span in an input sentence, along with a [Penn treebank dataset reader](https://github.com/allenai/allennlp/blob/master/allennlp/data/dataset_readers/penn_tree_bank.py) that reads data for this model.  Trained model and demo coming soon.

**Minor bugfixes and features:**
* This release is compatible with pytorch 0.3.1 (and still compatible with pytorch 0.3.0).
* Made it possible to do batch tokenization with spacy inside a `DatasetReader`.
* Added a `make-vocab` command to precompute a vocabulary for a dataset.
* Added a `fine-tune` command to fine-tune a trained model on a new dataset.
* Unified handling of Ontonotes-based datasets, so it is now easier to write new `DatasetReaders` that use Ontonotes.
* `Predictors` now support non-json formats for bulk prediction.
* More flexible batching code, and bug fixes when batching / padding using `ListFields`.
* Added ability to handle different data reading configurations at train and test time.

**Breaking Changes**

This release contains several breaking changes. Please see [the migration guide](https://github.com/allenai/allennlp/blob/master/tutorials/misc/migrating-to-0.4.0.md) if you have pre-0.4.0 code you need to update.",91356408
206,False,False,2017-12-14T21:58:07Z,2017-12-15T16:26:27Z,"We updated our key dependencies to Spacy 2.0 and PyTorch 0.3, and we have a few additional models and many new features since our 0.2 release.

**Additional models**.  More details for our models are available at http://allennlp.org/models and you can use them interactively online at http://demo.allennlp.org/.

* The baseline NER model from [Semi-supervised Sequence Tagging with Bidirectional Language Models](https://www.semanticscholar.org/paper/Semi-supervised-sequence-tagging-with-bidirectiona-Peters-Ammar/73e59cb556351961d1bdd4ab68cbbefc5662a9fc).
* A coreference model, based on the publication [End-to-end Neural Coreference Resolution](https://www.semanticscholar.org/paper/End-to-end-Neural-Coreference-Resolution-Lee-He/3f2114893dc44eacac951f148fbff142ca200e83), which achieved state-of-the-art performance in early 2017.

**Additional examples and tutorials**.  Find them at http://allennlp.org/tutorials/installation.

* A tutorial on u[sing AllenNLP in your project](http://allennlp.org/tutorials/using-in-your-repo) as a pip dependency.
* Example code for[ training a seq2seq model](https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/simple_seq2seq.py).

**New features**.

* Improved SRL visualization on the demo.
* `ListField` padding fixes.",91356408
207,False,False,2017-12-07T01:31:57Z,2017-12-06T19:05:30Z,"- Fixes bugs in stateful versions of `Seq2XXXEncoders`.
- Adds an `ArrayField` for array inputs to models.
- Uses an up to date stand-alone version of tensorboard such that you can use it inside a single environment.
- Adds the ability to read hdf5 formatted embedding matrices.
- Adds a flag to specify what `Datasets` should be used to build vocabularies in `train`.
",91356408
208,False,False,2017-09-06T18:45:48Z,2017-09-08T13:57:04Z,"The first release of AllenNLP using PyTorch.

This release of AllenNLP includes three models:

* Semantic Role Labeling (78.9 dev F1, 78.9 test F1, CoNLL 2012)
* Machine Comprehension (68.7 EM, SQuAD)
* Textual Entailment (84.7 test accuracy, SNLI)",91356408
209,False,False,2017-06-18T01:56:30Z,2017-06-18T01:58:39Z,"Major changes:
- TensorFlow 1.2.0 support

Minor changes:
- GAN and DCGAN examples
- SELU activation
- Weighted Cross-Entropy
- Various bug fix",55147386
210,False,False,2017-05-18T17:34:18Z,2017-05-18T17:45:26Z,"Minor changes:
- Grouped Convolution support (depthwise conv).
- VAE and ResNeXt Examples.
- New optimizers.
- New activation functions.
- Various bug fix.",55147386
211,False,False,2017-02-20T17:06:34Z,2017-02-20T17:09:58Z,"Major changes:
- TensorFlow 1.0 compatibility

Minor changes:
- Documents refactoring.
- Inception-ResNet-v2 Example.
- CIFAR-100 Dataset.
- Added time monitoring.
- Various bug fix.
",55147386
212,False,False,2016-08-11T03:36:33Z,2016-08-11T03:37:49Z,"- Support for 3D conv ops
- New layers: time_distributed, l2_normalize
- RNNs support for batch norm
- Added an option to save the best model
- Seq2seq and Reinforcement learning examples
- Beginner tutorial
- Others minor changes
- Various bug fix
",55147386
213,False,False,2016-06-10T05:49:31Z,2016-06-10T05:50:50Z,"- Various bug fix
- State of the art result for Residual Networks
- FCN objective & Upscore layer
",55147386
214,False,False,2016-04-14T15:08:25Z,2016-05-31T08:03:06Z,"Initial release
",55147386
215,False,False,2016-05-31T07:54:51Z,2016-05-31T08:02:04Z,"Major changes:
- DataFlow: A data pipeline for faster computing.
- Data Augmentation and data preprocessing support.
- Layers now support any custom function as parameter.
- Basic tests.
- Highway network architecture.
- AUC objective function.
- New examples.

Minor changes:
- Residual net fix.
- Notebook display issues fix.
- Datasets fix.
- Various other bugs fix.
- More exceptions.
",55147386
216,False,False,2019-11-27T20:26:57Z,2019-11-27T20:28:34Z,"Improvements:

* Updated default yaml loader to move off of
  deprecated method (Thanks @vh920!)
* Updated legend handling to adjust for deprecated methods
  in recent versions of Bokeh (Thanks for reporting @jpkoc)
* Updated license in setup.py (Thanks for reporting @jsignell)
* Bump base Pillow dependency to avoid insecure version.
* Update MANIFEST to include missing files (Thanks @toddrme2178!)",149135719
217,False,False,2019-08-15T19:27:50Z,2019-08-15T19:28:31Z,"Bugfixes:

- Moved package requirements and fixed bug that occured with latest version of Bokeh (Thanks @emschuch & @mollymzhu!)
- Fixed bug in README while generating docs (Thanks @Bharat123rox!)",149135719
218,False,False,2019-03-08T22:28:57Z,2019-03-08T22:30:43Z,"Improvements:
- Allows users to plot colors on bar charts that aren't contained in the categorical axis.

Bugfixes:
- Fixed bug that caused float types to break when plotted with categorical text plots (Thanks for finding @danela!)
- Fixed broken readme links.",149135719
219,False,False,2019-02-17T20:27:50Z,2019-02-17T20:28:55Z,"Improvements:

* Added Radar Chart",149135719
220,False,False,2019-02-16T23:03:36Z,2019-02-16T23:05:20Z,"Improvements:

* Added second Y axis plotting.
* Removed Bokeh loading notification on import (Thanks @canavandl!)
* Added support for custom Bokeh resource loading (Thanks @canavandl!)
* Added example for Chart.save() method (Thanks @david30907d!)

Bugfixes:

* Updated documentation for saving and showing svgs.
* Fixed bug that broke plots with no difference between min and max
  points. (Thanks for finding @fabioconcina!)",149135719
221,False,False,2018-11-21T19:07:40Z,2018-11-21T19:09:05Z,"Improvements:

- Updated docstrings (Thanks @gregorybchris @ItsPugle!)
- Added SVG output options to Chart.show() and Chart.save() (Thanks for the suggestion @jdmendoza!)

Bugfixes:

- Fixed bug that caused source label to overlap with xaxis labels.
- Fixed bug that prevented x axis orientation changes with datetime axes (Thanks for finding @simonwongwong!)
- Fixed bug that caused subtitle to disappear with outside_top legend location (Thanks for finding @simonwongwong!)
- Line segment callout properties will work correctly. (Thanks @gregorybchris!)",149135719
222,False,False,2018-11-16T15:49:03Z,2018-11-16T20:18:24Z,,149135719
223,False,False,2018-10-24T20:28:15Z,2018-10-24T20:30:13Z,To allow for use of Pillow 5.0+,149135719
224,False,False,2018-10-18T22:24:33Z,2018-10-18T22:26:53Z,"* Added scatter plots with a single categorical axis.
![image](https://user-images.githubusercontent.com/1086968/47187844-a1efa580-d303-11e8-989f-5e2288633868.png)

* Stacked bar and area order now matches default vertical legend order.
* Added method for shifting color palettes.
* Fixed bug with text_stacked that occurred with multiple categorical levels.",149135719
225,False,False,2018-09-27T19:06:56Z,2018-09-27T19:10:10Z,"* Fix scatter plot bug that can occur when nested data types (dicts, lists) are contained in the data frame.",149135719
226,False,False,2018-09-27T01:44:18Z,2018-09-27T01:56:42Z,"* Added hexbin plot type.
* More control over grouped axis label orientation.
* Added alpha control to scatter, line, and parallel plots.
* Added control over marker style to scatter plot.
* Added ability to create custom color palettes.
* Changed default accent color.
* Visual tweaks to lollipop plot.
* Bar plots with a few number of series will have better widths.",149135719
227,False,False,2018-09-17T17:51:15Z,2018-09-17T18:28:33Z,,149135719
228,False,False,2020-03-25T22:24:48Z,2020-03-25T22:25:10Z,"#### 0.24.3 - 2020-03-25

##### New features
 - new `logx` kwarg in plotting curves
 - PH models have `compute_followup_hazard_ratios` for simulating what the hazard ratio would be at previous times. This is useful because the final hazard ratio is some weighted average of these.

##### Bug fixes
 - Fixed error in HTML printer that was hiding concordance index information.

",12420595
229,False,False,2020-03-15T16:09:39Z,2020-03-15T16:11:38Z,"
#### 0.24.2 - 2020-03-15

##### Bug fixes
 - Fixed bug when no covariates were passed into `CoxPHFitter`. See #975
 - Fixed error in `StatisticalResult` where the test name was not displayed correctly.
 - Fixed a keyword bug in `plot_covariate_groups` for parametric models.

",12420595
230,False,False,2020-03-06T00:13:23Z,2020-03-06T00:14:34Z,"#### 0.24.1 - 2020-03-05

##### New features
 - Stability improvements for GeneralizedGammaRegressionFitter and CoxPHFitter with spline estimation.

##### Bug fixes
 - Fixed bug with plotting hazards in NelsonAalenFitter.
",12420595
231,False,False,2020-02-20T15:50:45Z,2020-02-20T15:51:11Z,"#### 0.24.0 - 2020-02-20

This version and future versions of lifelines no longer support py35. Pandas 1.0 is fully supported, along with previous version. Minimum Scipy has been bumped to 1.2.0

##### New features
 - `CoxPHFitter` and `CoxTimeVaryingFitter` has support for an elastic net penalty, which includes L1 and L2 regression.
 - `CoxPHFitter` has new baseline survival estimation methods. Specifically, `spline` now estimates the coefficients and baseline survival using splines. The traditional method, `breslow`, is still the default however.
 - Regression models have a new `score` method that will score your model against a dataset (ex: a testing or validation dataset). The default is to evaluate the log-likelihood, but also the concordance index can be chose.
 - New `MixtureCureFitter` for quickly creating univariate mixture models.
 - Univariate parametric models have a `plot_density`, `density_at_times`, and property `density_` that computes the probability density function estimates.
 - new dataset for interval regression involving C. Botulinum.
 - new `lifelines.fitters.mixins.ProportionalHazardMixin` that implements proportional hazard checks.

##### API Changes
 - Models' prediction method that return a single array now return a Series (use to return a DataFrame). This includes `predict_median`, `predict_percentile`, `predict_expectation`, `predict_log_partial_hazard`, and possibly others.
 - The penalty in Cox models is now scaled by the number of observations. This makes it invariant to changing sample sizes. This change also make the penalty magnitude behave the same as any parametric regression model.
 - `score_` on models has been renamed `concordance_index_`
 - models' `.variance_matrix_` is now a DataFrame.
 - `CoxTimeVaryingFitter` no longer requires an `id_col`. It's optional, and some checks may be done for integrity if provided.
 - Significant changes to `utils.k_fold_cross_validation`.
 - removed automatically adding `inf` from `PiecewiseExponentialRegressionFitter.breakpoints` and `PiecewiseExponentialFitter.breakpoints`
 - `tie_method` was dropped from Cox models (it was always Efron anyways...)
 - Mixins are moved to `lifelines.fitters.mixins`
 - `find_best_parametric_model` `evaluation` kwarg has been changed to `scoring_method`.
 - removed `_score_` and `path` from Cox model.

##### Bug fixes
 - Fixed `show_censors` with `KaplanMeierFitter.plot_cumulative_density` see issue #940.
 - Fixed error in `""BIC""` code path in `find_best_parametric_model`
 - Fixed a bug where left censoring in AFT models was not converging well
 - Cox models now incorporate any penalizers in their `log_likelihood_`

",12420595
232,False,False,2020-01-28T13:52:05Z,2020-01-28T13:52:36Z,"#### 0.23.9 - 2020-01-28

##### Bug fixes
 - fixed important error when a parametric regression model would not assign the correct labels to fitted
parameters' variances. See more here: https://github.com/CamDavidsonPilon/lifelines/issues/931. Users of `GeneralizedGammaRegressionFitter` and any custom regression models should update their code as soon as possible.
",12420595
233,False,False,2020-01-21T22:45:22Z,2020-01-21T22:46:38Z,"##### Bug fixes
 - fixed important error when a parametric regression model would not assign the correct labels to fitted parameters. See more here: https://github.com/CamDavidsonPilon/lifelines/issues/931. Users of `GeneralizedGammaRegressionFitter` and any custom regression models should update their code as soon as possible.",12420595
234,False,False,2020-01-14T22:37:47Z,2020-01-14T22:39:42Z,"Bug fixes for py3.5. This will be the last version of lifelines that supports Python 3.5.
",12420595
235,False,False,2020-01-07T15:36:35Z,2020-01-07T15:37:05Z,"#### 0.23.6 - 2020-01-07

##### New features
 - New univariate model, `SplineFitter`, that uses cubic splines to model the cumulative hazard.
 - To aid users with selecting the best parametric model, there is a new `lifelines.utils.find_best_parametric_model` function that will iterate through the models and return the model with the lowest AIC (by default).
 - custom parametric regression models can now do left and interval censoring.
",12420595
236,False,False,2020-01-05T22:13:01Z,2020-01-05T22:13:51Z,"#### 0.23.5 - 2020-01-05

##### New features
 - New `predict_hazard` for parametric regression models.
 - New lymph node cancer dataset, originally from *H.F. for the German Breast Cancer Study Group (GBSG) (1994)*

##### Bug fixes
 - fixes error thrown when converge of regression models fails.
 - `kwargs` is now used in `plot_covariate_groups`
 - fixed bug where large exponential numbers in `print_summary` were not being suppressed correctly.
",12420595
237,False,False,2019-12-15T15:15:44Z,2019-12-15T15:20:18Z,Bugfix for PyPI,12420595
238,False,False,2019-12-11T17:27:38Z,2019-12-11T17:28:12Z,"
#### 0.23.2

##### New features
 - `StatisticalResult.print_summary` supports html output.

##### Bug fixes
 - fix import in `printer.py`
 - fix html printing with Univariate models.
",12420595
239,False,False,2019-12-07T17:39:15Z,2019-12-07T17:39:52Z,"#### 0.23.2

##### New features
 - new `lifelines.plotting.rmst_plot` for pretty figures of survival curves and RMSTs.
 - new variance calculations for `lifelines.utils.resticted_mean_survival_time`
 - performance improvements on regression models' preprocessing. Should make datasets with
 high number of columns more performant.

##### Bug fixes
 - fixed `print_summary` for AAF class.
 - fixed repr for `sklearn_adapter` classes.
 - fixed `conditional_after` in Cox model with strata was used.
",12420595
240,False,False,2019-11-28T03:29:48Z,2019-11-28T03:30:52Z,"#### 0.23.1

##### New features
 - new `print_summary` option `style` to print HTML, LaTeX or ASCII output
 - performance improvements for `CoxPHFitter` - up to 30% performance improvements for some datasets.

##### Bug fixes
 - fixed bug where computed statistics were not being shown in `print_summary` for HTML output.
 - fixed bug where ""None"" was displayed in models' `__repr__`
 - fixed bug in `StatisticalResult.print_summary`
 - fixed bug when using `print_summary` with left censored models.
 - lots of minor bug fixes.",12420595
241,False,False,2019-11-17T14:15:58Z,2019-11-17T15:20:00Z,"#### 0.23.0

##### New features
 - new `print_summary` abstraction that allows HTML printing in Jupyter notebooks!
 - silenced some warnings.

##### Bug fixes
 - The ""comparison"" value of some parametric univariate models wasn't standard, so the null hypothesis p-value may have been wrong. This is now fixed.
 - fixed a NaN error in confidence intervals for KaplanMeierFitter

##### API Changes

 - To align values across models, the column names for the confidence intervals in parametric univariate models `summary` have changed.
 - Fixed typo in `ParametricUnivariateFitter` name.
 - `median_` has been removed in favour of `median_survival_time_`.
 - `left_censorship` in `fit` has been removed in favour of `fit_left_censoring`.
",12420595
242,False,False,2019-11-08T14:20:19Z,2019-11-08T14:21:19Z,"
#### 0.22.10

The tests were re-factored to be shipped with the package. Let me know if this causes problems.


##### Bug fixes
 - fixed error in plotting models with ""lower"" or ""upper"" was in the label name.
 - fixed bug in plot_covariate_groups for AFT models when >1d arrays were used for values arg.
",12420595
243,False,False,2019-10-30T15:39:35Z,2019-10-30T16:08:16Z,"
#### 0.22.9 - 2019-10-30


##### Bug fixes
 - fixed `predict_` methods in AFT models when `timeline` was not specified.
 - fixed error in `qq_plot`
 - fixed error when submitting a model in `qth_survival_time`
 - `CoxPHFitter` now displays correct columns values when changing alpha param.

",12420595
244,False,False,2019-10-06T13:29:35Z,2019-10-06T13:31:11Z,"#### 0.22.8

##### New features
 - Serializing lifelines is better supported. Packages like joblib and pickle are now supported. Thanks @AbdealiJK!
 - `conditional_after` now available in `CoxPHFitter.predict_median`
 - Suppressed some unimportant warnings.

##### Bug fixes
 - fixed initial_point being ignored in AFT models.
",12420595
245,False,False,2019-09-30T00:41:50Z,2019-09-30T00:43:04Z,"## Changelog

#### 0.22.7

##### New features
 - new `ApproximationWarning` to tell you if the package is making an potentially bad approximation.

##### Bug fixes
 - fixed a bug in parametric prediction for interval censored data.
 - realigned values in `print_summary`.
 - fixed bug in `survival_difference_at_fixed_point_in_time_test`

##### API Changes

 - `utils.qth_survival_time` no longer takes a `cdf` argument - users should take the compliment (1-cdf).
 - Some previous `StatisticalWarnings` have been replaced by `ApproximationWarning`
",12420595
246,False,False,2019-09-25T18:59:51Z,2019-09-25T19:00:37Z,"#### 0.22.6

##### New features
 - `conditional_after` works for `CoxPHFitter` prediction models 😅

##### Bug fixes

##### API Changes
 - `CoxPHFitter.baseline_cumulative_hazard_`'s column is renamed `""baseline cumulative hazard""` - previously it was `""baseline hazard""`. (Only applies if the model has no strata.)
 - `utils.dataframe_interpolate_at_times` renamed to `utils.interpolate_at_times_and_return_pandas`.

",12420595
247,False,False,2019-09-20T15:35:07Z,2019-09-20T15:36:00Z,"#### 0.22.5 - 2019-09-20

##### New features
 - Improvements to the __repr__ of models that takes into accounts weights.
 - Better support for predicting on Pandas Series

##### Bug fixes
 - Fixed issue where `fit_interval_censoring` wouldn't accept lists.
 - Fixed an issue with `AalenJohansenFitter` failing to plot confidence intervals.

##### API Changes
 - `_get_initial_value` in parametric univariate models is renamed `_create_initial_point`
",12420595
248,False,False,2019-09-04T16:48:01Z,2019-09-04T16:49:43Z,"#### 0.22.4 - 2019-09-04

##### New features
 - Some performance improvements to regression models.
 - lifelines will avoid penalizing the intercept (aka bias) variables in regression models.
 - new `utils.restricted_mean_survival_time` that approximates the RMST using numerical integration against survival functions.

##### API changes
 - `KaplanMeierFitter.survival_function_`'s' index is no longer given the name ""timeline"".

##### Bug fixes
 - Fixed issue where `concordance_index` would never exit if NaNs in dataset.
",12420595
249,False,False,2019-08-06T12:54:12Z,2019-08-08T21:00:27Z,"#### 0.22.3

##### New features
 - model's now expose a `log_likelihood_` property.
 - new `conditional_after` argument on `predict_*` methods that make prediction on censored subjects easier.
 - new `lifelines.utils.safe_exp` to make `exp` overflows easier to handle.
 - smarter initial conditions for parametric regression models.
 - New regression model: `GeneralizedGammaRegressionFitter`

##### API changes
 - removed `lifelines.utils.gamma` - use `autograd_gamma` library instead.
 - removed bottleneck as a dependency. It offered slight performance gains only in Cox models, and only a small fraction of the API was being used.

##### Bug fixes
 - AFT log-likelihood ratio test was not using weights correctly.
 - corrected (by bumping) scipy and autograd dependencies
 - convergence is improved for most models, and many `exp` overflow warnings have been eliminated.
 - Fixed an error in the `predict_percentile` of `LogLogisticAFTFitter`. New tests have been added around this.
",12420595
250,False,False,2019-07-26T00:10:47Z,2019-07-26T00:12:01Z,"#### 0.22.2

##### New features
 - lifelines is now compatible with scipy>=1.3.0

##### Bug fixes
 - fixed printing error when using robust=True in regression models
 - `GeneralizedGammaFitter` is more stable, maybe.
 - lifelines was allowing old version of numpy (1.6), but this caused errors when using the library. The correctly numpy has been pinned (to 1.14.0+)

",12420595
251,False,False,2019-07-14T19:45:47Z,2019-07-14T19:46:28Z,"### 0.22.1

##### New features
 - New univariate model, `GeneralizedGammaFitter`. This model contains many sub-models, so it is a good model to check fits.
 - added a warning when a time-varying dataset had instantaneous deaths.
 - added a `initial_point` option in univariate parametric fitters.
 - `initial_point` kwarg is present in parametric univariate fitters `.fit`
 - `event_table` is now an attribute on all univariate fitters (if right censoring)
 - improvements to `lifelines.utils.gamma`

##### API changes
 - In AFT models, the column names in `confidence_intervals_` has changed to include the alpha value.
 - In AFT models, some column names in `.summary` and `.print_summary` has changed to include the alpha value.
 - In AFT models, some column names in `.summary` and `.print_summary` includes confidence intervals for the exponential of the value.

##### Bug fixes
 - when using `censors_show` in plotting functions, the censor ticks are now reactive to the estimate being shown.
 - fixed an overflow bug in `KaplanMeierFitter` confidence intervals
 - improvements in data validation for `CoxTimeVaryingFitter`
",12420595
252,False,False,2019-07-03T19:21:48Z,2019-07-03T19:24:26Z,"##### New features
 - Ability to create custom parametric regression models by specifying the cumulative hazard. This enables new and extensions of AFT models.
 - `percentile(p)` method added to univariate models that solves the equation `p = S(t)` for `t`
 - for parametric univariate models, the `conditional_time_to_event_` is now exact instead of an approximation.

##### API changes
 - In Cox models, the attribute `hazards_` has been renamed to `params_`. This aligns better with the other regression models, and is more clear (what is a hazard anyways?)
 - In Cox models, a new `hazard_ratios_` attribute is available which is the exponentiation of `params_`.
 - In regression models, the column names in `confidence_intervals_` has changed to include the alpha value.
 - In regression models, some column names in `.summary` and `.print_summary` has changed to include the alpha value.
 - In regression models, some column names in `.summary` and `.print_summary` includes confidence intervals for the exponential of the value.
 - Significant changes to internal AFT code.
 - A change to how `fit_intercept` works in AFT models. Previously one could set `fit_intercept` to False and not have to set `ancillary_df` - now one must specify a DataFrame.

##### Bug fixes
 - for parametric univariate models, the `conditional_time_to_event_` is now exact instead of an approximation.
",12420595
253,False,False,2019-06-06T16:22:36Z,2019-06-06T16:23:22Z,"#### 0.21.3 - 2019-06-04

##### New features
 - include in lifelines is a scikit-learn adapter so lifeline's models can be used with scikit-learn's API. See [documentation here](https://lifelines.readthedocs.io/en/latest/Compatibility%20with%20scikit-learn.html).
 - `CoxPHFitter.plot` now accepts a `hazard_ratios` (boolean) parameter that will plot the hazard ratios (and CIs) instead of the log-hazard ratios.
 - `CoxPHFitter.check_assumptions` now accepts a `columns` parameter to specify only checking a subset of columns.

##### Bug fixes
 - `covariates_from_event_matrix` handle nulls better",12420595
254,False,False,2019-05-16T12:36:53Z,2019-05-16T12:37:12Z,"#### 0.21.2 - 2019-05-16

##### New features
 - New regression model: `PiecewiseExponentialRegressionFitter` is available. See blog post here: https://dataorigami.net/blogs/napkin-folding/churn
 - Regression models have a new method `log_likelihood_ratio_test` that computes, you guessed it, the log-likelihood ratio test. Previously this was an internal API that is being exposed.

##### API changes
 - The default behavior of the `predict` method on non-parametric estimators (`KaplanMeierFitter`, etc.) has changed from (previous) linear interpolation to (new) return last value. Linear interpolation is still possible with the `interpolate` flag.
 - removing `_compute_likelihood_ratio_test` on regression models. Use `log_likelihood_ratio_test` now.
",12420595
255,False,False,2019-04-26T21:57:37Z,2019-04-26T21:58:20Z,"
#### 0.21.1 - 2019-04-26

##### New features
 - users can provided their own start and stop column names in `add_covariate_to_timeline`
 - PiecewiseExponentialFitter now allows numpy arrays as breakpoints

##### API changes
 - output of `survival_table_from_events` when collapsing rows to intervals now removes the ""aggregate"" column multi-index.

##### Bug fixes
 - fixed bug in CoxTimeVaryingFitter when ax is provided, thanks @j-i-l!
",12420595
256,False,False,2019-04-12T16:52:16Z,2019-04-12T16:53:13Z,"#### 0.21.0

##### New features
 - `weights` is now a optional kwarg for parametric univariate models.
 - all univariate and multivariate parametric models now have ability to handle left, right and interval censored data (the former two being special cases of the latter). Users can use the `fit_right_censoring` (which is an alias for `fit`), `fit_left_censoring` and `fit_interval_censoring`.
 - a new interval censored dataset is available under `lifelines.datasets.load_diabetes`

##### API changes
 - `left_censorship` on all univariate fitters has been deprecated. Please use the new
 api `model.fit_left_censoring(...)`.
 - `invert_y_axis` in `model.plot(...` has been removed.
 - `entries` property in multivariate parametric models has a new Series name: `entry`

##### Bug fixes
 - lifelines was silently converting any NaNs in the event vector to True. An error is now thrown instead.
 - Fixed an error that didn't let users use Numpy arrays in prediction for AFT models
",12420595
257,False,False,2019-04-08T15:22:29Z,2019-04-08T15:23:32Z,"#### 0.20.5 - 2019-04-08

##### New features
 - performance improvements for `print_summary`.

##### API changes
 - `utils.survival_events_from_table` returns an integer weight vector as well as durations and censoring vector.
 - in `AalenJohansenFitter`, the `variance` parameter is renamed to `variance_` to align with the usual lifelines convention.

##### Bug fixes
 - Fixed an error in the `CoxTimeVaryingFitter`'s likelihood ratio test when using strata.
 - Fixed some plotting bugs with `AalenJohansenFitter`
",12420595
258,False,False,2019-03-27T15:24:52Z,2019-03-27T15:25:36Z,"#### 0.20.4

##### New features
 - left-truncation support in AFT models, using the `entry_col` kwarg in `fit()`
 - `generate_datasets.piecewise_exponential_survival_data` for generating piecewise exp. data
 - Faster `print_summary` for AFT models.

##### API changes
 - Pandas is now correctly pinned to >= 0.23.0. This was always the case, but not specified in setup.py correctly.

##### Bug fixes
 - Better handling for extremely large numbers in `print_summary`
 - `PiecewiseExponentialFitter` is available with `from lifelines import *`.

",12420595
259,False,False,2019-03-23T13:33:06Z,2019-03-23T13:34:09Z,"#### 0.20.3

##### New features
 - Now `cumulative_density_` & `survival_function_` are _always_ present on a fitted `KaplanMeierFitter`.
 - New attributes/methods on `KaplanMeierFitter`: `plot_cumulative_density()`, `confidence_interval_cumulative_density_`, `plot_survival_function` and `confidence_interval_survival_function_`.
",12420595
260,False,False,2019-03-21T16:34:34Z,2019-03-21T16:35:14Z,"
#### 0.20.2

##### New features
 - Left censoring is now supported in univariate parametric models: `.fit(..., left_censorship=True)`. Examples are in the docs.
 - new dataset: `lifelines.datasets.load_nh4()`
 - Univariate parametric models now include, by default, support for the cumulative density function: `.cumulative_density_`, `.confidence_interval_cumulative_density_`, `plot_cumulative_density()`, `cumulative_density_at_times(t)`.
 -  add a `lifelines.plotting.qq_plot` for univariate parametric models that handles censored data.

##### API changes
 - `plot_lifetimes` no longer reverses the order when plotting. Thanks @vpolimenov!
 - The `C` column in `load_lcd` dataset is renamed to `E`.

##### Bug fixes
 - fixed a naming error in `KaplanMeierFitter` when `left_censorship` was set to True, `plot_cumulative_density_()` is now `plot_cumulative_density()`.
 - added some error handling when passing in timedeltas. Ideally, users don't pass in timedeltas, as the scale is ambiguous. However, the error message before was not obvious, so we do some conversion, warn the user, and pass it through.
 - `qth_survival_times` for a truncated CDF would return `np.inf` if the q parameter was below the truncation limit. This should have been `-np.inf`
",12420595
261,False,False,2019-03-16T14:15:19Z,2019-03-16T14:15:53Z,"#### 0.20.1
 - Some performance improvements to `CoxPHFitter` (about 30%). I know it may seem silly, but we are now about the same or slighty faster than the Cox model in R's `survival` package (for some testing datasets and some configurations). This is a big deal, because 1) lifelines does more error checking prior, 2) R's cox model is written in C, and we are still pure Python/NumPy, 3) R's cox model has decades of development.
 - suppressed unimportant warnings

##### API changes
 - Previously, lifelines _always_ added a 0 row to `cph.baseline_hazard_`, even if there were no event at this time. This is no longer the case. A 0 will still be added if there is a duration (observed or not) at 0 occurs however.
",12420595
262,False,False,2019-03-06T03:48:52Z,2019-03-06T03:49:59Z,"### Changelog

#### 0.20.0
 - Starting with 0.20.0, only Python3 will be supported. Over 75% of recent installs where Py3.
 - Updated minimum dependencies, specifically Matplotlib and Pandas.

##### New features
 -  smarter initialization for AFT models which should improve convergence.

##### API changes
 - `inital_beta` in Cox model's `.fit` is now `initial_point`.
 - `initial_point` is now available in AFT models and `CoxTimeVaryingFitter`
 - the DataFrame `confidence_intervals_` for univariate models is transposed now (previous parameters where columns, now parameters are rows).

##### Bug fixes
 - Fixed a bug with plotting and `check_assumptions`.

",12420595
263,False,False,2019-02-26T19:30:38Z,2019-02-26T19:31:31Z,"#### 0.19.5

##### New features
 -  `plot_covariate_group` can accept multiple covariates to plot. This is useful for columns that have implicit correlation like polynomial features or categorical variables.
 - Convergence improvements for AFT models.",12420595
264,False,False,2019-02-26T01:20:55Z,2019-02-26T01:22:35Z,"#### 0.19.4

##### Bug fixes
 - remove some bad print statements in `CoxPHFitter`.
",12420595
265,False,False,2019-02-25T20:35:56Z,2019-02-25T20:36:29Z,"
#### 0.19.3

##### New features
 - new AFT models: `LogNormalAFTFitter` and `LogLogisticAFTFitter`.
 - AFT models now accept a `weights_col` argument to `fit`.
 - Robust errors (sandwich errors) are now avilable in AFT models using the `robust=True` kwarg in `fit`.
 - Performance increase to `print_summary` in the `CoxPHFitter` and `CoxTimeVaryingFitter` model.
",12420595
266,False,False,2019-02-22T18:03:38Z,2019-02-22T18:04:31Z,"#### 0.19.2

##### New features
 - `ParametricUnivariateFitters`, like `WeibullFitter`, have smoothed plots when plotting (vs stepped plots)

##### Bug fixes
 - The `ExponentialFitter` log likelihood _value_ was incorrect - inference was correct however.
 - Univariate fitters are more flexiable and can allow 2-d and DataFrames as inputs.
",12420595
267,False,False,2019-02-21T16:21:43Z,2019-02-21T16:22:29Z,"#### 0.19.1

##### New features
 - improved stability of `LogNormalFitter`
 - Matplotlib for Python3 users are not longer forced to use 2.x.

##### API changes
 - **Important**: we changed the parameterization of the `PiecewiseExponential` to the same as `ExponentialFitter` (from `\lambda * t` to `t / \lambda`).
",12420595
268,False,False,2019-02-20T21:02:46Z,2019-02-20T21:04:49Z,"#### 0.19.0

##### New features
 - New regression model `WeibullAFTFitter` for fitting accelerated failure time models. Docs have been added to our [documentation](https://lifelines.readthedocs.io/) about how to use `WeibullAFTFitter` (spoiler: it's API is similar to the other regression models) and how to interpret the output.
 - `CoxPHFitter` performance improvements (about 10%)
 - `CoxTimeVaryingFitter` performance improvements (about 10%)


##### API changes
 - **Important**: we changed the `.hazards_` and `.standard_errors_` on Cox models to be pandas Series (instead of Dataframes). This felt like a more natural representation of them. You may need to update your code to reflect this. See notes here: https://github.com/CamDavidsonPilon/lifelines/issues/636
 - **Important**: we changed the `.confidence_intervals_` on Cox models to be transposed. This felt like a more natural representation of them. You may need to update your code to reflect this. See notes here: https://github.com/CamDavidsonPilon/lifelines/issues/636
 - **Important**: we changed the parameterization of the `WeibullFitter` and `ExponentialFitter` from `\lambda * t` to `t / \lambda`. This was for a few reasons: 1) it is a more common parameterization in literature, 2) it helps in convergence.
 - **Important**: in models where we add an intercept (currently only `AalenAdditiveModel`), the name of the added column has been changed from `baseline` to `_intercept`
 - **Important**: the meaning of `alpha` in all fitters has changed to be the standard interpretation of alpha in confidence intervals. That means that the _default_ for alpha is set to 0.05 in the latest lifelines, instead of 0.95 in previous versions.

##### Bug Fixes
 - Fixed a bug in the `_log_likelihood_` property of `ParametericUnivariateFitter` models. It was showing the ""average"" log-likelihood (i.e. scaled by 1/n) instead of the total. It now displays the total.
 - In model `print_summary`s, correct a label erroring. Instead of ""Likelihood test"", it should have read ""Log-likelihood test"".
 - Fixed a bug that was too frequently rejecting the dtype of `event` columns.
 - Fixed a calculation bug in the concordance index for stratified Cox models. Thanks @airanmehr!
 - Fixed some Pandas <0.24 bugs.",12420595
269,False,False,2019-02-14T02:59:01Z,2019-02-14T02:59:48Z,"
#### 0.18.6
 - some improvements to the output of `check_assumptions`. `show_plots` is turned to `False` by default now. It only shows `rank` and `km` p-values now.
 - some performance improvements to `qth_survival_time`.
",12420595
270,False,False,2019-02-11T20:28:22Z,2019-02-11T20:38:28Z,"### 0.18.5
 - added new plotting methods to parametric univariate models: `plot_survival_function`, `plot_hazard` and `plot_cumulative_hazard`. The last one is an alias for `plot`.
 - added new properties to parametric univarite models: `confidence_interval_survival_function_`, `confidence_interval_hazard_`, `confidence_interval_cumulative_hazard_`. The last one is an alias for `confidence_interval_`.
 - Fixed some overflow issues with `AalenJohansenFitter`'s variance calculations when using large datasets.
 - Fixed an edgecase in `AalenJohansenFitter` that causing some datasets with to be jittered too often.
 - Add a new kwarg to  `AalenJohansenFitter`, `calculate_variance` that can be used to turn off variance calculations since this can take a long time for large datasets. Thanks @pzivich!
",12420595
271,False,False,2019-02-10T19:42:16Z,2019-02-10T19:43:33Z,"### 0.18.4
 - fixed confidence intervals in cumulative hazards for parametric univarite models. They were previously 
   serverly depressed. 
 - adding left-truncation support to parametric univarite models with the `entry` kwarg in `.fit`
",12420595
272,False,False,2019-02-07T16:44:20Z,2019-02-07T16:45:02Z,"### 0.18.3 
 - Some performance improvements to parametric univariate models.
 - Suppressing some irrelevant NumPy and autograd warnings, so lifeline warnings are more noticeable. 
 - Improved some warning and error messages. ",12420595
273,False,False,2019-02-05T18:45:43Z,2019-02-05T18:46:14Z,"### 0.18.2
 - New univariate fitter `PiecewiseExponentialFitter` for creating a stepwise hazard model. See docs online.
 - Ability to create novel parametric univariate models using the new `ParametericUnivariateFitter` super class. See docs online for how to do this. 
 - Unfortunately, parametric univariate fitters are not serializable with `pickle`. The library `dill` is still useable. 
 - Complete overhaul of all internals for parametric univariate fitters. Moved them all (most) to use `autograd`.
 - `LogNormalFitter` no longer models `log_sigma`.
",12420595
274,False,False,2019-02-02T15:57:39Z,2019-02-02T16:01:37Z,"### 0.18.1
 - bug fixes in `LogNormalFitter` variance estimates
 - improve convergence of `LogNormalFitter`. We now model the log of sigma internally, but still expose sigma externally. 
 - use the `autograd` lib to help with gradients.
 - New `LogLogisticFitter` univariate fitter available. ",12420595
275,False,False,2019-02-01T01:10:01Z,2019-02-01T01:11:45Z,"
### 0.18.0
 - `LogNormalFitter` is a new univariate fitter you can use.
 - `WeibullFitter` now correctly returns the confidence intervals (previously returned only NaNs)
 - `WeibullFitter.print_summary()` displays p-values associated with its parameters not equal to 1.0 - previously this was (implicitly) comparing against 0, which is trivially always true (the parameters must be greater than 0)
 - `ExponentialFitter.print_summary()` displays p-values associated with its parameters not equal to 1.0 - previously this was (implicitly) comparing against 0, which is trivially always true (the parameters must be greater than 0)
 - `ExponentialFitter.plot` now displays the cumulative hazard, instead of the survival function. This is to make it easier to compare to `WeibullFitter` and `LogNormalFitter`
 - Univariate fitters' `cumulative_hazard_at_times`, `hazard_at_times`, `survival_function_at_times` return pandas Series now (use to be numpy arrays)
 - remove `alpha` keyword from all statistical functions. This was never being used. 
 - Gone are astericks and dots in `print_summary` functions that represent signficance thresholds. 
 - In models' `summary` (including `print_summary`), the `log(p)` term has changed to `-log2(p)`. This is known as the s-value. See https://lesslikely.com/statistics/s-values/
 - introduce new statistical tests between univariate datasets: `survival_difference_at_fixed_point_in_time_test`,...
 - new warning message when Cox models detects possible non-unique solutions to maximum likelihood. 
 - Generally: clean up lifelines exception handling. Ex: catch `LinAlgError: Matrix is singular.` and report back to the user advice. 
",12420595
276,False,False,2019-01-25T16:46:00Z,2019-01-25T16:46:41Z,"### 0.17.5
 - more bugs in `plot_covariate_groups` fixed when using non-numeric strata.
",12420595
277,False,False,2019-01-25T14:49:42Z,2019-01-25T14:50:15Z,"#### 0.17.4
 - Fix bug in `plot_covariate_groups` that wasn't allowing for strata to be used. 
 - change name of `multicenter_aids_cohort_study` to `load_multicenter_aids_cohort_study`",12420595
278,False,False,2019-01-24T20:53:10Z,2019-01-24T20:53:55Z,"#### 0.17.3
 - Fix in `compute_residuals` when using `schoenfeld` and the minumum duration has only censored subjects. 
",12420595
279,False,False,2019-01-22T20:33:36Z,2019-01-22T21:21:28Z,"### v0.17.2
 - Another round of serious performance improvements for the Cox models. Up to 2x faster for CoxPHFitter and CoxTimeVaryingFitter. This was mostly the result of using NumPy's `einsum` to simplify a previous `for` loop. The downside is the code is more esoteric now. ",12420595
280,False,False,2019-01-20T19:24:54Z,2019-01-20T19:25:56Z,"
#### 0.17.1
 - adding bottleneck as a dependency. This library is highly-recommended by Pandas, and in lifelines we see some nice performance improvements with it too. (~15% for `CoxPHFitter`)
 - There was a small bug in `CoxPHFitter` when using `batch_mode` that was causing coefficients to deviate from their MLE value. This bug eluded tests, which means that it's discrepancy was less than 0.0001 difference. It's fixed now, and even more accurate tests are added. 
 - Faster `CoxPHFitter._compute_likelihood_ratio_test()`
 - Fixes a Pandas performance warning in `CoxTimeVaryingFitter`.
 - Performances improvements to `CoxTimeVaryingFitter`. 
",12420595
281,False,False,2019-01-11T21:43:16Z,2019-01-11T21:43:53Z,"#### 0.17.0
 - corrected behaviour in `CoxPHFitter` where `score_` was not being refreshed on every new `fit`.
 - Reimplentation of `AalenAdditiveFitter`. There were significant changes to it:
   - implementation is at least 10x faster, and possibly up to 100x faster for some datasets.
   - memory consumption is way down
   - removed the time-varying component from `AalenAdditiveFitter`. This will return in a future release.
   - new `print_summary`
   - `weights_col` is added
   - `nn_cumulative_hazard` is removed (may add back)
 - new dataset add: `multicenter_aids_cohort_study` from Cole SR, Hudgens MG. Survival analysis in infectious disease research: describing events in time. AIDS. 2010;24(16):2423-31.",12420595
282,False,False,2019-01-03T13:30:56Z,2019-01-03T13:34:12Z,"#### 0.16.3
 - More `CoxPHFitter` performance improvements. Up to a 40% reduction vs 0.16.2 for some datasets. 
",12420595
283,False,False,2019-01-02T21:40:11Z,2019-01-02T21:40:56Z,"#### 0.16.2
 - Fixed `CoxTimeVaryingFitter` to allow more than one variable to be stratafied
 - Significant performance improvements for `CoxPHFitter` with dataset has lots of duplicate times. See https://github.com/CamDavidsonPilon/lifelines/issues/591",12420595
284,False,False,2019-01-02T00:04:59Z,2019-01-02T00:08:11Z,"#### 0.16.1
 - Fixed py2 division error in `concordance` method.
",12420595
285,False,False,2019-01-01T18:33:38Z,2019-01-01T18:38:41Z,"#### 0.16.0
 - Drop Python 3.4 support. 
 - introduction of residual calculations in `CoxPHFitter.compute_residuals`. Residuals include ""schoenfeld"", ""score"", ""delta_beta"", ""deviance"", ""martingale"", and ""scaled_schoenfeld"".
 - removes `estimation` namespace for fitters. Should be using `from lifelines import xFitter` now. Thanks @usmanatron
 - removes `predict_log_hazard_relative_to_mean` from Cox model. Thanks @usmanatron
 - `StatisticalResult` has be generalized to allow for multiple results (ex: from pairwise comparisons). This means a slightly changed API that is mostly backwards compatible. See doc string for how to use it. 
 - `statistics.pairwise_logrank_test` now returns a `StatisticalResult` object instead of a nasty NxN DataFrame 💗
 - Display log(p-values) as well as p-values in `print_summary`. Also, p-values below thesholds will be truncated. The orignal p-values are still recoverable using `.summary`.
 - Floats `print_summary` is now displayed to 2 decimal points. This can be changed using the `decimal` kwarg. 
 - removed `standardized` from `Cox` model plotting. It was confusing. 
 - visual improvements to Cox models `.plot`
 - `print_summary` methods accepts kwargs to also be displayed.
 - `CoxPHFitter` has a new human-readable method, `check_assumptions`, to check the assumptions of your Cox proportional hazard model. 
 - A new helper util to ""expand"" static datasets into long-form: `lifelines.utils.to_episodic_format`. 
 - `CoxTimeVaryingFitter` now accepts `strata`. ",12420595
286,False,False,2018-12-18T19:31:27Z,2018-12-19T12:28:38Z,"#### 0.15.3
 - Only allow matplotlib less than 3.0.

#### 0.15.2
 - API changes to `plotting.plot_lifetimes`
 - `cluster_col` and `strata` can be used together in `CoxPHFitter`
 - removed `entry` from `ExponentialFitter` and `WeibullFitter` as it was doing nothing.
",12420595
287,False,False,2018-11-23T16:31:05Z,2018-11-23T16:31:30Z,"## 0.15.1
 - Bug fixes for v0.15.0
 - Raise NotImplementedError if the `robust` flag is used in `CoxTimeVaryingFitter` - that's not ready yet.",12420595
288,False,False,2018-11-22T21:51:43Z,2018-11-22T21:57:09Z," - adding `robust` params to `CoxPHFitter`'s `fit`. This enables atleast i) using non-integer weights in the model (these could be sampling weights like IPTW), and ii) mis-specified models (ex: non-proportional hazards). Under the hood it's a sandwich estimator. This does not handle ties, so if there are high number of ties, results may significantly differ from other software.
 - `standard_errors_` is now a property on fitted `CoxPHFitter` which describes the standard errors of the coefficients.
 - `variance_matrix_` is now a property on fitted `CoxPHFitter` which describes the variance matrix of the coefficients.
 - new criteria for convergence of `CoxPHFitter` and `CoxTimeVaryingFitter` called the Newton-decrement. Tests show it is as accurate (w.r.t to previous coefficients) and typically shaves off a single step, resulting in generally faster convergence. See https://www.cs.cmu.edu/~pradeepr/convexopt/Lecture_Slides/Newton_methods.pdf. Details about the Newton-decrement are added to the `show_progress` statements.
 - Minimum suppport for scipy is 1.0
 - Convergence errors in models that use Newton-Rhapson methods now throw a `ConvergenceError`, instead of a `ValueError` (the former is a subclass of the latter, however).
 - `AalenAdditiveModel` raises `ConvergenceWarning` instead of printing a warning.
 - `KaplanMeierFitter` now has a cumulative plot option. Example `kmf.plot(invert_y_axis=True)`
 - a `weights_col` option has been added to `CoxTimeVaryingFitter` that allows for time-varying weights. 
 - `WeibullFitter` has a new `show_progress` param and additional information if the convergence fails. 
 - `CoxPHFitter`, `ExponentialFitter`, `WeibullFitter` and `CoxTimeVaryFitter` method `print_summary` is updated with new fields. 
 - `WeibullFitter` has renamed the incorrect `_jacobian` to `_hessian_`. 
 - `variance_matrix_` is now a property on fitted `WeibullFitter` which describes the variance matrix of the parameters.
 - The default `WeibullFitter().timeline` has changed from integers between the min and max duration to _n_ floats between the max and min durations, where _n_ is the number of observations. 
 - Performance improvements for `CoxPHFitter` (~20% faster)
 - Performance improvements for `CoxTimeVaryingFitter` (~100% faster)
 - In Python3, Univariate models are now serialisable with `pickle`. Thanks @dwilson1988 for the contribution. For Python2, `dill` is still the preferred method.
 - `baseline_cumulative_hazard_` (and derivatives of that) on `CoxPHFitter` now correctly incorporate the `weights_col`. 
 - Fixed a bug in `KaplanMeierFitter` when late entry times lined up with death events. Thanks @pzivich
 - Adding `cluster_col` argument to `CoxPHFitter` so users can specify groups of subjects/rows that may be correlated. 
 - Shifting the ""signficance codes"" for p-values down an order of magnitude. (Example, p-values between 0.1 and 0.05 are not noted at all and p-values between 0.05 and 0.1 are noted with `.`, etc.). This deviates with how they are presented in other software. There is an argument to be made to remove p-values from lifelines altogether (_become the changes you want to see in the world_ lol), but I worry that people could compute the p-values by hand incorrectly, a worse outcome I think. So, this is my stance. P-values between 0.1 and 0.05 offer _very_ little information, so they are removed. There is a growing movement in statistics to shift ""signficant"" findings to p-values less than 0.01 anyways. 
 - New fitter for cumulative incidence of multiple risks `AalenJohansenFitter`. Thanks @pzivich! See ""Methodologic Issues When Estimating Risks in Pharmacoepidemiology"" for a nice overview of the model. ",12420595
289,False,False,2018-07-02T17:14:13Z,2018-07-02T17:14:36Z,"#### 0.14.6
 - fix for n > 2 groups in `multivariate_logrank_test` (again).
 - fix bug for when `event_observed` column was not boolean. 
",12420595
290,False,False,2018-06-30T01:26:37Z,2018-06-30T01:27:06Z,"#### 0.14.5
 - fix for n > 2 groups in `multivariate_logrank_test`
 - fix weights in KaplanMeierFitter when using a pandas Series. 
",12420595
291,False,False,2018-06-14T19:42:39Z,2018-06-14T19:43:15Z,"#### 0.14.4
 - Adds `baseline_cumulative_hazard_` and `baseline_survival_` to `CoxTimeVaryingFitter`. Because of this, new prediction methods are available. 
 - fixed a bug in `add_covariate_to_timeline` when using `cumulative_sum` with multiple columns.
 - Added `Likelihood ratio test` to `CoxPHFitter.print_summary` and `CoxTimeVaryingFitter.print_summary`
 - New checks in `CoxTimeVaryingFitter` that check for immediate deaths and redundant rows. 
 - New `delay` parameter in `add_covariate_to_timeline`
 - removed `two_sided_z_test` from `statistics`",12420595
292,False,False,2018-05-24T15:23:36Z,2018-05-24T15:24:12Z,"#### 0.14.3 
 - fixes a bug when subtracting or dividing two `UnivariateFitters` with labels. 
 - fixes an import error with using `CoxTimeVaryingFitter` predict methods.
 - adds a `column` argument to `CoxTimeVaryingFitter` and `CoxPHFitter` `plot` method to plot only a subset of columns.
",12420595
293,False,False,2018-05-19T03:11:26Z,2018-05-19T03:12:08Z,Some quality of life improvements,12420595
294,False,False,2018-04-01T13:35:03Z,2018-04-01T13:36:11Z,"#### 0.14.1

 - fixed bug with using weights and strata in `CoxPHFitter`
 - fixed bug in using non-integer weights in `KaplanMeierFitter`
 - Performance optimizations in `CoxPHFitter` for up to 40% faster completion of `fit`.
    - even smarter `step_size` calculations for iterative optimizations. 
    - simple code optimizations & cleanup in specific hot spots.
 - Performance optimizations in `AalenAdditiveFitter` for up to 50% faster completion of `fit` for large dataframes, and up to 10% faster for small dataframes. ",12420595
295,False,False,2018-03-04T00:07:47Z,2018-03-04T00:08:20Z," - adding `plot_covariate_groups` to `CoxPHFitter` to visualize what happens to survival as we vary a covariate, all else being equal.
 - `utils` functions like `qth_survival_times` and `median_survival_times` now return the transpose of the DataFrame compared to previous version of lifelines. The reason for this is that we often treat survival curves as columns in DataFrames, and functions of the survival curve as index (ex: KaplanMeierFitter.survival_function_ returns a survival curve _at_ time _t_).
 - `KaplanMeierFitter.fit` and `NelsonAalenFitter.fit` accept a `weights` vector that can be used for pre-aggregated datasets. See this [issue](https://github.com/CamDavidsonPilon/lifelines/issues/396).
 - Convergence errors now return a custom `ConvergenceWarning` instead of a `RuntimeWarning`
 - New checks for complete separation in the dataset for regressions.",12420595
296,False,False,2017-12-22T21:37:35Z,2017-12-22T21:44:51Z,"### 0.13.0

 - Implements a new fitter `CoxTimeVaryingFitter` available under the `lifelines` namespace. This model implements the Cox model for time-varying covariates.
 - Utils for creating time varying datasets available in `utils`.
 - `CoxPHFitter.fit` now has accepts a `weight_col` kwarg so one can pass in weights per observation. This is very useful if you have many subjects, and the space of covariates is not large. Thus you can group the same subjects together and give that observation a weight equal to the count. Altogether, this means a much faster regression.
 - removes `is_significant` and `test_result` from `StatisticalResult`. Users can instead choose their significance level by comparing to `p_value`. The string representation of this class has changed aswell.
 - `CoxPHFitter` and `AalenAdditiveFitter` now have a `score_` property that is the concordance-index of the dataset to the fitted model.
 - `CoxPHFitter` has a slightly more intelligent (barely...) way to pick a step size, so convergence should generally be faster.
 - `CoxPHFitter` and `AalenAdditiveFitter` no longer have the `data` property. It was an _almost_ duplicate of the training data, but was causing the model to be very large when serialized.
 - less noisy check for complete separation.
 - removed `datasets` namespace from the main `lifelines` namespace",12420595
297,False,False,2017-06-22T13:12:48Z,2017-06-22T13:13:20Z,"#### 0.11.1
 - Python3 fix for `CoxPHFitter.plot`.",12420595
298,False,False,2017-06-22T03:45:54Z,2017-06-22T03:44:34Z,"#### 0.11.0
 - fixes regression in `KaplanMeierFitter.plot` when using Seaborn and lifelines.
 - introduce a new `.plot` function to a fitted `CoxPHFitter` instance. This plots the hazard coefficients and their confidence intervals. 
 - in all plot methods, the `ix` kwarg has been deprecated in favour of a new `loc` kwarg. This is to align with Pandas deprecating `ix`",12420595
299,False,False,2017-06-06T03:04:59Z,2017-06-11T20:02:39Z,"#### 0.10.1
 - fix in internal normalization for `CoxPHFitter` predict methods.

#### 0.10.0
 - corrected bug that was returning the wrong baseline survival and hazard values in `CoxPHFitter` when `normalize=True`. 
 - removed  `normalize` kwarg in `CoxPHFitter`. This was causing lots of confusion for users, and added code complexity. It's really nice to be able to remove it.
 - correcting column name in `CoxPHFitter.baseline_survival_`
 - `CoxPHFitter.baseline_cumulative_hazard_` is always centered, to mimic R's `basehaz` API.
 - new `predict_log_partial_hazards` to `CoxPHFitter`",12420595
300,False,False,2015-08-01T17:57:16Z,2015-08-01T18:01:51Z,"- reorganized lifelines directories: 
  - moved test files out of main directory. 
  - moved `utils.py` into it's down directory.
  - moved all estimators `fitters` directory.
- added a `at_risk` column to the output of `group_survival_table_from_events` and `survival_table_from_events`
- added sample size and power calculations for statistical tests. See `lifeline.statistics. sample_size_necessary_under_cph` and `lifelines.statistics. power_under_cph`. 
- fixed a bug when using KaplanMeierFitter for left-censored data. 
",12420595
301,False,False,2015-03-01T22:30:56Z,2015-03-01T22:31:23Z,"#### 0.7.0
- allow for multiple fitters to be passed into `k_fold_cross_validation`. 
- statistical tests in `lifelines.statstics`. now return a `StatisticalResult` object with properties like `p_value`, `test_results`, and `summary`.  
- fixed a bug in how log-rank statistical tests are performed. The covariance matrix was not being correctly calculated. This resulted in slightly different p-values. 
- `WeibullFitter`, `ExponentialFitter`, `KaplanMeierFitter` and `BreslowFlemingHarringtonFitter` all have a `conditional_time_to_event_` property that measures  the median duration remaining until the death event, given survival up until time t.
",12420595
302,False,False,2015-02-04T14:49:27Z,2015-02-06T04:00:33Z,"#### 0.6.0
- Inclusion of the univariate fitters `WeibullFitter` and `ExponentialFitter`. 
- Removing `BayesianFitter` from lifelines.
- Added new penalization scheme to AalenAdditiveFitter. You can now add a smoothing penalizer
  that will try to keep subsequent values of a hazard curve close together. The penalizing coefficient
  is `smoothing_penalizer`. 
- Changed `penalizer` keyword arg to `coef_penalizer` in AalenAdditiveFitter.
- new `ridge_regression` function in `utils.py` to perform linear regression with l2 penalizer terms.
- Matplotlib is no longer a mandatory dependency. 
- `.predict(time)` method on univariate fitters can now accept a scalar (and returns a scalar) and an iterable (and returns a numpy array)
- In `KaplanMeierFitter`, `epsilon` has been renamed to `precision`. 
",12420595
303,False,False,2015-02-06T04:00:03Z,2015-02-06T03:56:59Z,,12420595
304,False,False,2014-12-24T18:50:37Z,2014-12-24T18:52:32Z,"- New API for `CoxPHFitter` and `AalenAdditiveFitter`: the default arguments for `event_col` and `duration_col`. `duration_col` is now mandatory, and `event_col` now accepts a column, or by default, `None`, which assumes all events are observed (non-censored).
- Fix statistical tests
- Allow negative durations in Fitters
- New API in `survival_table_from_events`: `min_observations` is replaced by `birth_times` (default `None`).
- New API in `CoxPHFitter` for summary: `summary` will return a dataframe with statistics, `print_summary()` will print the dataframe (plus some other statistics) in a pretty manner.
- Adding ""At Risk"" counts option to univariate fitter `plot` methods, `.plot(at_risk_counts=True)`. 
- Fix Epanechnikov kernel.  
",12420595
305,False,False,2014-12-07T22:06:53Z,2014-12-07T22:08:43Z,"- move testing to py.test
- refactor tests into smaller files
- make `test_pairwise_logrank_test_with_identical_data_returns_inconclusive` a better test
- add test for summary()
- Alternate metrics can be used for `k_fold_cross_validation`.
",12420595
306,False,False,2014-12-05T04:10:24Z,2014-12-05T04:12:25Z,"- Makes column ordering explicit. 
",12420595
307,False,False,2014-11-27T14:06:01Z,2014-11-27T17:20:10Z,"- Lots of improvements to numerical stability (but something things still need work)
- Additions to `summary` in CoxPHFitter.
- Make all prediction methods output a DataFrame
- Fixes bug in 1-d input not returning in CoxPHFitter
- Lots of new tests. 
",12420595
308,False,False,2014-07-24T00:19:40Z,2014-07-24T00:58:15Z,"- refactoring of `qth_survival_times`: it can now accept an iterable (or a scalar still) of probabilities in the q argument, and will return a DataFrame with these as columns. If len(q)==1 and a single survival function is given, will return a scalar, not a DataFrame. Also some good speed improvements.
- KaplanMeierFitter and NelsonAalenFitter now have a `_label` property that is passed in during the fit.
- KaplanMeierFitter/NelsonAalenFitter's inital `alpha` value is overwritten if a new `alpha` value is passed
  in during the `fit`.
- New method for KaplanMeierFitter: `conditional_time_to`. This returns a DataFrame of the estimate:
  med(S(t | T>s)) - s, human readable: the estimated time left of living, given an individual is aged s.
- Adds option `include_likelihood` to CoxPHFitter fit method to save the final log-likelihood value.
",12420595
309,False,False,2014-06-19T13:03:17Z,2014-06-19T13:13:07Z,"#### 0.4.2
- Massive speed improvements to CoxPHFitter. 
- Additional prediction method: `predict_percentile` is available on CoxPHFitter and AalenAdditiveFitter. Given a percentile, p, this function returns the value t such that _S(t | x) = p_. It is a generalization of `predict_median`. 
- Additional kwargs in `k_fold_cross_validation` that will accept different prediction methods (default is `predict_median`). 
- Bug fix in CoxPHFitter `predict_expectation` function. 
- Correct spelling mistake in newton-rhapson algorithm.
- `datasets` now contains functions for generating the respective datasets, ex: `generate_waltons_dataset`.
- Bumping up the number of samples in statistical tests to prevent them from failing so often (this a stop-gap)
- pep8 everything
",12420595
310,False,False,2014-06-11T12:06:00Z,2014-06-11T12:07:12Z,"- `CoxFitter` is now known as `CoxPHFitter`
- refactoring some tests that used redundant data from `lifelines.datasets`. 
- Adding cross validation: in `utils` is a new `k_fold_cross_validation` for model selection in regression problems.
- Change CoxPHFitter's fit method's `display_output` to `False`.
- fixing bug in CoxPHFitter's `_compute_baseline_hazard` that errored when sending Series objects to
  `survival_table_from_events`.
- CoxPHFitter's `fit` now looks to columns with too low variance, and halts NR algorithm if a NaN is found.
- Adding a Changelog.
- more sanitizing for the statistical tests =)
",12420595
311,False,False,2020-02-16T11:10:31Z,2020-02-16T11:15:15Z,"This is a bug-fix release to resolve some issues regarding the handling the input and the output format of the arrays.

Changelog
-------------

* Allow column vectors to be passed as targets. #673 by @chkoar.
* Better input/output handling for pandas, numpy and plain lists. #681 by @chkoar.
",23011147
312,False,False,2019-12-07T17:48:49Z,2019-12-07T17:57:44Z,"This is a bug-fix release to primarily resolve some packaging issues in version 0.6.0. It also includes minor documentation improvements and some bug fixes.

Changelog
--------------

Bug fixes
------------

- Fix a bug in :class:`imblearn.ensemble.BalancedRandomForestClassifier` leading to a wrong number of samples used during fitting due max_samples and therefore a bad computation of the OOB score. :pr:`656` by :user:`Guillaume Lemaitre <glemaitre>`.
",23011147
313,False,False,2019-12-05T14:03:23Z,2019-12-05T14:24:36Z,"Changelog
---------

Changed models
..............

The following models might give some different sampling due to changes in
scikit-learn:

- :class:`imblearn.under_sampling.ClusterCentroids`
- :class:`imblearn.under_sampling.InstanceHardnessThreshold`

The following samplers will give different results due to change linked to
the random state internal usage:

- :class:`imblearn.over_sampling.SMOTENC`

Bug fixes
.........

- :class:`imblearn.under_sampling.InstanceHardnessThreshold` now take into
  account the `random_state` and will give deterministic results. In addition,
  `cross_val_predict` is used to take advantage of the parallelism.
  :pr:`599` by :user:`Shihab Shahriar Khan <Shihab-Shahriar>`.

- Fix a bug in :class:`imblearn.ensemble.BalancedRandomForestClassifier`
  leading to a wrong computation of the OOB score.
  :pr:`656` by :user:`Guillaume Lemaitre <glemaitre>`.

Maintenance
...........

- Update imports from scikit-learn after that some modules have been privatize.
  The following import have been changed:
  :class:`sklearn.ensemble._base._set_random_states`,
  :class:`sklearn.ensemble._forest._parallel_build_trees`,
  :class:`sklearn.metrics._classification._check_targets`,
  :class:`sklearn.metrics._classification._prf_divide`,
  :class:`sklearn.utils.Bunch`,
  :class:`sklearn.utils._safe_indexing`,
  :class:`sklearn.utils._testing.assert_allclose`,
  :class:`sklearn.utils._testing.assert_array_equal`,
  :class:`sklearn.utils._testing.SkipTest`.
  :pr:`617` by :user:`Guillaume Lemaitre <glemaitre>`.

- Synchronize :mod:`imblearn.pipeline` with :mod:`sklearn.pipeline`.
  :pr:`620` by :user:`Guillaume Lemaitre <glemaitre>`.

- Synchronize :class:`imblearn.ensemble.BalancedRandomForestClassifier` and add
  parameters `max_samples` and `ccp_alpha`.
  :pr:`621` by :user:`Guillaume Lemaitre <glemaitre>`.

Enhancement
...........

- :class:`imblearn.under_sampling.RandomUnderSampling`,
  :class:`imblearn.over_sampling.RandomOverSampling`,
  :class:`imblearn.datasets.make_imbalance` accepts Pandas DataFrame in and
  will output Pandas DataFrame. Similarly, it will accepts Pandas Series in and
  will output Pandas Series.
  :pr:`636` by :user:`Guillaume Lemaitre <glemaitre>`.

- :class:`imblearn.FunctionSampler` accepts a parameter ``validate`` allowing
  to check or not the input ``X`` and ``y``.
  :pr:`637` by :user:`Guillaume Lemaitre <glemaitre>`.

- :class:`imblearn.under_sampling.RandomUnderSampler`,
  :class:`imblearn.over_sampling.RandomOverSampler` can resample when non
  finite values are present in ``X``.
  :pr:`643` by :user:`Guillaume Lemaitre <glemaitre>`.

- All samplers will output a Pandas DataFrame if a Pandas DataFrame was given
  as an input.
  :pr:`644` by :user:`Guillaume Lemaitre <glemaitre>`.

- The samples generation in
  :class:`imblearn.over_sampling.SMOTE`,
  :class:`imblearn.over_sampling.BorderlineSMOTE`,
  :class:`imblearn.over_sampling.SVMSMOTE`,
  :class:`imblearn.over_sampling.KMeansSMOTE`,
  :class:`imblearn.over_sampling.SMOTENC` is now vectorize with giving
  an additional speed-up when `X` in sparse.
  :pr:`596` by :user:`Matt Eding <MattEding>`.

Deprecation
...........

- The following classes have been removed after 2 deprecation cycles:
  `ensemble.BalanceCascade` and `ensemble.EasyEnsemble`.
  :pr:`617` by :user:`Guillaume Lemaitre <glemaitre>`.

- The following functions have been removed after 2 deprecation cycles:
  `utils.check_ratio`.
  :pr:`617` by :user:`Guillaume Lemaitre <glemaitre>`.

- The parameter `ratio` and `return_indices` has been removed from all
  samplers.
  :pr:`617` by :user:`Guillaume Lemaitre <glemaitre>`.

- The parameters `m_neighbors`, `out_step`, `kind`, `svm_estimator`
  have been removed from the :class:`imblearn.over_sampling.SMOTE`.
  :pr:`617` by :user:`Guillaume Lemaitre <glemaitre>`.
",23011147
314,False,False,2019-06-28T14:18:10Z,2019-06-28T14:19:36Z,"Version 0.5.0
=============

Changed models
---

The following models or function might give different results even if the
same data ``X`` and ``y`` are the same.

* :class:`imblearn.ensemble.RUSBoostClassifier` default estimator changed from
  :class:`sklearn.tree.DecisionTreeClassifier` with full depth to a decision
  stump (i.e., tree with ``max_depth=1``).

Documentation
---

- Correct the definition of the ratio when using a ``float`` in sampling
  strategy for the over-sampling and under-sampling.
  :issue:`525` by :user:`Ariel Rossanigo <arielrossanigo>`.

- Add :class:`imblearn.over_sampling.BorderlineSMOTE` and
  :class:`imblearn.over_sampling.SVMSMOTE` in the API documenation.
  :issue:`530` by :user:`Guillaume Lemaitre <glemaitre>`.

Enhancement
---
- Add Parallelisation for SMOTEENN and SMOTETomek.
  :pr:`547` by :user:`Michael Hsieh <Microsheep>`.

- Add :class:`imblearn.utils._show_versions`. Updated the contribution guide
  and issue template showing how to print system and dependency information
  from the command line. :pr:`557` by :user:`Alexander L. Hayes <batflyer>`.

- Add :class:`imblearn.over_sampling.KMeansSMOTE` which is an over-sampler
  clustering points before to apply SMOTE.
  :pr:`435` by :user:`Stephan Heijl <StephanHeijl>`.

Maintenance
---

- Make it possible to ``import imblearn`` and access submodule.
  :pr:`500` by :user:`Guillaume Lemaitre <glemaitre>`.

- Remove support for Python 2, remove deprecation warning from
  scikit-learn 0.21.
  :pr:`576` by :user:`Guillaume Lemaitre <glemaitre>`.

Bug
---

- Fix wrong usage of :class:`keras.layers.BatchNormalization` in
  ``porto_seguro_keras_under_sampling.py`` example. The batch normalization
  was moved before the activation function and the bias was removed from the
  dense layer.
  :pr:`531` by :user:`Guillaume Lemaitre <glemaitre>`.

- Fix bug which converting to COO format sparse when stacking the matrices in
  :class:`imblearn.over_sampling.SMOTENC`. This bug was only old scipy version.
  :pr:`539` by :user:`Guillaume Lemaitre <glemaitre>`.

- Fix bug in :class:`imblearn.pipeline.Pipeline` where None could be the final
  estimator.
  :pr:`554` by :user:`Oliver Rausch <orausch>`.

- Fix bug in :class:`imblearn.over_sampling.SVMSMOTE` and
  :class:`imblearn.over_sampling.BorderlineSMOTE` where the default parameter
  of ``n_neighbors`` was not set properly.
  :pr:`578` by :user:`Guillaume Lemaitre <glemaitre>`.

- Fix bug by changing the default depth in
  :class:`imblearn.ensemble.RUSBoostClassifier` to get a decision stump as a
  weak learner as in the original paper.
  :pr:`545` by :user:`Christos Aridas <chkoar>`.

- Allow to import ``keras`` directly from ``tensorflow`` in the
  :mod:`imblearn.keras`.
  :pr:`531` by :user:`Guillaume Lemaitre <glemaitre>`.
",23011147
315,False,False,2018-11-06T17:23:46Z,2018-11-06T17:25:49Z,Mainly bugfix in SMOTE NC,23011147
316,False,False,2018-10-21T12:49:18Z,2018-10-21T12:51:04Z,"Version 0.4.2

Bug fixes

* Fix a bug in imblearn.over_sampling.SMOTENC in which the the median of the standard deviation instead of half of the median of the standard deviation. By Guillaume Lemaitre in #491.
* Raise an error when passing target which is not supported, i.e. regression target or multilabel targets. Imbalanced-learn does not support this case. By Guillaume Lemaitre in #490.

",23011147
317,False,False,2018-10-12T16:04:22Z,2018-10-12T16:05:06Z,"Version 0.4
===========

October, 2018

Version 0.4 is the last version of imbalanced-learn to support Python 2.7
and Python 3.4. Imbalanced-learn 0.5 will require Python 3.5 or higher.

Highlights
----------

This release brings its set of new feature as well as some API changes to
strengthen the foundation of imbalanced-learn.

As new feature, 2 new modules `imblearn.keras` and
`imblearn.tensorflow` have been added in which imbalanced-learn samplers
can be used to generate balanced mini-batches.

The module `imblearn.ensemble` has been consolidated with new classifier:
`imblearn.ensemble.BalancedRandomForestClassifier`,
`imblearn.ensemble.EasyEnsembleClassifier`,
`imblearn.ensemble.RUSBoostClassifier`.

Support for string has been added in
`imblearn.over_sampling.RandomOverSampler` and
`imblearn.under_sampling.RandomUnderSampler`. In addition, a new class
`imblearn.over_sampling.SMOTENC` allows to generate sample with data
sets containing both continuous and categorical features.

The `imblearn.over_sampling.SMOTE` has been simplified and break down
to 2 additional classes:
`imblearn.over_sampling.SVMSMOTE` and
`imblearn.over_sampling.BorderlineSMOTE`.

There is also some changes regarding the API:
the parameter ``sampling_strategy`` has been introduced to replace the
``ratio`` parameter. In addition, the ``return_indices`` argument has been
deprecated and all samplers will exposed a ``sample_indices_`` whenever this is
possible.",23011147
318,False,False,2018-10-12T15:23:58Z,2018-10-12T15:27:58Z,"Version 0.4
===========

**October, 2018**

.. warning::

    Version 0.4 is the last version of imbalanced-learn to support Python 2.7
    and Python 3.4. Imbalanced-learn 0.5 will require Python 3.5 or higher.

Highlights
----------

This release brings its set of new feature as well as some API changes to
strengthen the foundation of imbalanced-learn.

As new feature, 2 new modules `imblearn.keras` and
`imblearn.tensorflow` have been added in which imbalanced-learn samplers
can be used to generate balanced mini-batches.

The module `imblearn.ensemble` has been consolidated with new classifier:
`imblearn.ensemble.BalancedRandomForestClassifier`,
`imblearn.ensemble.EasyEnsembleClassifier`,
`imblearn.ensemble.RUSBoostClassifier`.

Support for string has been added in
`imblearn.over_sampling.RandomOverSampler` and
`imblearn.under_sampling.RandomUnderSampler`. In addition, a new class
`imblearn.over_sampling.SMOTENC` allows to generate sample with data
sets containing both continuous and categorical features.

The `imblearn.over_sampling.SMOTE` has been simplified and break down
to 2 additional classes:
`imblearn.over_sampling.SVMSMOTE` and
`imblearn.over_sampling.BorderlineSMOTE`.

There is also some changes regarding the API:
the parameter ``sampling_strategy`` has been introduced to replace the
``ratio`` parameter. In addition, the ``return_indices`` argument has been
deprecated and all samplers will exposed a ``sample_indices_`` whenever this is
possible.",23011147
319,False,False,2018-09-07T13:44:48Z,2018-09-07T13:56:21Z,Just for switching documentation,23011147
320,False,False,2018-02-22T13:49:45Z,2018-02-22T13:50:45Z,Bug fix in the classification report,23011147
321,False,False,2017-12-07T22:55:35Z,2017-12-07T23:01:44Z,,23011147
322,False,False,2017-10-09T14:17:46Z,2017-10-09T14:18:34Z,Minor documentation revisions,23011147
323,False,False,2017-10-09T13:37:10Z,2017-10-09T13:39:35Z,"# What's new in version 0.3.0

## Testing

- Pytest is used instead of nosetests. :issue:`321` by `Joan Massich`_.

## Documentation

- Added a User Guide and extended some examples. :issue:`295` by `Guillaume Lemaitre`_.

# Bug fixes

- Fixed a bug in :func:`utils.check_ratio` such that an error is raised when
  the number of samples required is negative. :issue:`312` by `Guillaume Lemaitre`_.

- Fixed a bug in :class:`under_sampling.NearMiss` version 3. The
  indices returned were wrong. :issue:`312` by `Guillaume Lemaitre`_.

- Fixed bug for :class:`ensemble.BalanceCascade` and :class:`combine.SMOTEENN`
  and :class:`SMOTETomek`. :issue:`295` by `Guillaume Lemaitre`_.`

- Fixed bug for `check_ratio` to be able to pass arguments when `ratio` is a
  callable. :issue:`307` by `Guillaume Lemaitre`_.`

## New features

- Turn off steps in :class:`pipeline.Pipeline` using the `None`
  object. By `Christos Aridas`_.

- Add a fetching function :func:`datasets.fetch_datasets` in order to get some
  imbalanced datasets useful for benchmarking. :issue:`249` by `Guillaume Lemaitre`_.

## Enhancement

- All samplers accepts sparse matrices with defaulting on CSR type. :issue:`316` by
  `Guillaume Lemaitre`_.

- :func:`datasets.make_imbalance` take a ratio similarly to other samplers. It
  supports multiclass. :issue:`312` by `Guillaume Lemaitre`_.

- All the unit tests have been factorized and a :func:`utils.check_estimators`
  has been derived from scikit-learn. By `Guillaume Lemaitre`_.

- Script for automatic build of conda packages and uploading. :issue:`242` by
  `Guillaume Lemaitre`_

- Remove seaborn dependence and improve the examples. :issue:`264` by `Guillaume
  Lemaitre`_.

- adapt all classes to multi-class resampling. :issue:`290` by `Guillaume Lemaitre`_

## API changes summary

- `__init__` has been removed from the :class:`base.SamplerMixin` to
  create a real mixin class. :issue:`242` by `Guillaume Lemaitre`_.

- creation of a module :mod:`exceptions` to handle consistant raising of
  errors. :issue:`242` by `Guillaume Lemaitre`_.

- creation of a module ``utils.validation`` to make checking of
  recurrent patterns. :issue:`242` by `Guillaume Lemaitre`_.

- move the under-sampling methods in ``prototype_selection`` and
  ``prototype_generation`` submodule to make a clearer dinstinction. :issue:`277` by
  `Guillaume Lemaitre`_.

- change ``ratio`` such that it can adapt to multiple class problems. :issue:`290` by
  `Guillaume Lemaitre`_.

## Deprecation

- Deprecation of the use of ``min_c_`` in :func:`datasets.make_imbalance`. :issue:`312` by
  `Guillaume Lemaitre`_

- Deprecation of the use of float in :func:`datasets.make_imbalance` for the
  ratio parameter. :issue:`290` by `Guillaume Lemaitre`_.

- deprecate the use of float as ratio in favor of dictionary, string, or
  callable. :issue:`290` by `Guillaume Lemaitre`_.

",23011147
324,False,False,2017-01-01T15:41:47Z,2017-01-01T15:44:33Z,,23011147
325,False,False,2016-12-31T16:49:57Z,2016-12-31T16:51:36Z,"Release 0.2.0
",23011147
326,False,False,2016-12-26T13:10:10Z,2016-12-26T13:11:52Z,,23011147
327,False,False,2016-09-07T12:49:15Z,2016-09-07T12:50:04Z,,23011147
328,False,False,2016-08-31T15:15:48Z,2016-09-01T10:19:41Z,,23011147
329,False,False,2016-08-31T08:37:06Z,2016-08-31T08:51:15Z,,23011147
330,False,False,2016-07-31T23:15:35Z,2016-08-09T08:32:14Z,"Bug fix for NearMiss 3
",23011147
331,False,False,2016-07-31T23:15:35Z,2016-07-31T23:17:04Z,"Release 0.1.5
",23011147
332,False,False,2016-07-31T23:01:39Z,2016-07-31T23:03:53Z,"Release 0.1.4
Bug fix for EasyEnsemble method
",23011147
333,False,False,2016-07-19T14:05:08Z,2016-07-19T14:13:30Z,"Solve an issue with ADASYN
",23011147
334,False,False,2016-07-19T12:21:54Z,2016-07-19T12:25:07Z,"Release created after transferring the repository to `scikit-learn-contrib`.
",23011147
335,False,False,2016-07-09T10:10:11Z,2016-07-09T10:11:11Z,,23011147
336,False,False,2020-01-17T09:52:58Z,2020-01-17T10:08:37Z,Release 3.24.1,8357227
337,False,False,2019-10-03T11:59:56Z,2020-01-10T09:49:47Z,Release 3.23.1,8357227
338,False,False,2019-12-20T11:28:07Z,2020-01-10T09:49:11Z,Release 3.24.0,8357227
339,False,False,2019-06-26T13:43:15Z,2019-07-09T08:55:53Z,,8357227
340,False,False,2019-02-01T11:25:41Z,2019-02-01T12:45:23Z,,8357227
341,False,False,2018-12-11T13:40:33Z,2018-12-11T14:14:30Z,,8357227
342,False,False,2018-11-13T13:49:20Z,2018-11-13T15:21:19Z,,8357227
343,False,False,2018-10-26T13:49:17Z,2018-10-29T09:48:13Z,,8357227
344,False,False,2018-08-06T12:22:29Z,2018-08-06T15:34:28Z,Release 3.15.0,8357227
345,False,False,2018-07-04T09:31:35Z,2018-07-04T15:01:18Z,Release 3.14.0,8357227
346,False,False,2018-04-06T12:39:24Z,2018-04-09T08:30:25Z,Release 3.12.0,8357227
347,False,False,2018-02-19T10:05:19Z,2018-02-19T11:24:41Z,Release 3.10.0,8357227
348,False,False,2018-02-02T12:53:23Z,2018-02-02T14:27:43Z,Release 3.9.1,8357227
349,False,False,2018-01-19T09:27:57Z,2018-01-22T08:46:09Z,Release 3.9.0,8357227
350,False,False,2017-12-01T12:59:13Z,2017-12-04T09:51:10Z,,8357227
351,False,False,2017-09-04T11:57:30Z,2017-11-17T13:55:30Z,,8357227
352,False,False,2017-09-29T13:29:46Z,2017-11-17T13:55:13Z,,8357227
353,False,False,2017-10-27T12:36:57Z,2017-11-17T13:54:51Z,,8357227
354,False,False,2017-11-17T10:50:22Z,2017-11-17T13:54:29Z,,8357227
355,False,False,2017-07-27T21:46:19Z,2017-07-27T22:56:24Z,,8357227
356,False,False,2017-06-16T15:06:16Z,2017-06-16T19:26:24Z,Release 3.4.4,8357227
357,False,False,2017-06-03T13:29:45Z,2017-06-04T17:18:51Z,,8357227
358,False,False,2017-04-19T06:53:30Z,2017-05-03T12:14:02Z,,8357227
359,False,False,2016-06-24T15:30:59Z,2016-06-24T15:34:44Z,,8357227
360,False,False,2016-06-01T07:56:00Z,2016-06-03T07:50:52Z,,8357227
361,False,False,2014-11-10T13:55:56Z,2014-11-10T14:31:00Z,,8357227
362,False,False,2020-02-04T17:53:03Z,2020-02-04T18:08:15Z,"## Dash and Dash-Renderer
### Fixed
- [#1080](https://github.com/plotly/dash/pull/1080) Handle case where dash fails to load when used inside an iframe with a sandbox attribute that only has allow-scripts

## Dash-Core-Components
### Changed
- [#743](https://github.com/plotly/dash-core-components/pull/743) Location component now emits an event on URL path update from Link component
- [#739](https://github.com/plotly/dash-core-components/pull/739) Async Slider and RangeSlider
- [#729](https://github.com/plotly/dash-core-components/pull/729) Handle case where dcc fails to load when used inside an iframe with a sandbox attribute that only has allow-scripts

### Fixed
- [#730](https://github.com/plotly/dash-core-components/pull/730) Fixed bug in which input components with type `number` did not correctly update their values.
- [#731](https://github.com/plotly/dash-core-components/pull/731) Fixed bug where non-clearable dropdowns could still be cleared by typing backspace

### Updated
- [#747](https://github.com/plotly/dash-core-components/pull/747)
  - Upgrade plotly.js to [1.52.2](https://github.com/plotly/plotly.js/releases/tag/v1.52.2)",33702544
363,False,False,2020-01-14T18:34:21Z,2020-01-14T18:37:09Z,"## Dash and Dash-Renderer
### Added
- [#1073](https://github.com/plotly/dash/pull/1073) Two new functions to simplify usage handling URLs and pathnames: `app.get_relative_path` & `app.trim_relative_path`.
These functions are particularly useful for apps deployed on Dash Enterprise where the apps served under a URL prefix (the app name) which is unlike apps served on localhost:8050.
    - `app.get_relative_path` returns a path with the config setting `requests_pathname_prefix` prefixed. Use `app.get_relative_path` anywhere you would provide a relative pathname, like `dcc.Link(href=app.relative_path('/page-2'))` or even as an alternative to `app.get_asset_url` with e.g. `html.Img(src=app.get_relative_path('/assets/logo.png'))`.
    - `app.trim_relative_path` a path with `requests_pathname_prefix` and leading & trailing
    slashes stripped from it. Use this function in callbacks that deal with `dcc.Location` `pathname`
    routing.
    Example usage:
    ```python
    app.layout = html.Div([
        dcc.Location(id='url'),
        html.Div(id='content')
    ])
    @app.callback(Output('content', 'children'), [Input('url', 'pathname')])
    def display_content(path):
        page_name = app.strip_relative_path(path)
        if not page_name:  # None or ''
            return html.Div([
                html.Img(src=app.get_relative_path('/assets/logo.png')),
                dcc.Link(href=app.get_relative_path('/page-1')),
                dcc.Link(href=app.get_relative_path('/page-2')),
            ])
        elif page_name == 'page-1':
            return chapters.page_1
        if page_name == ""page-2"":
            return chapters.page_2
    ```

### Changed
- [#1035](https://github.com/plotly/dash/pull/1035) Simplify our build process.
- [#1074](https://github.com/plotly/dash/pull/1045) Error messages when providing an incorrect property to a component have been improved: they now specify the component type, library, version, and ID (if available).

### Fixed
- [#1037](https://github.com/plotly/dash/pull/1037) Fix no_update test to allow copies, such as those stored and retrieved from a cache.


## Dash-Core-Components
### Added
- [#711](https://github.com/plotly/dash-core-components/pull/711) Added support for `dcc.Link` (dccLink) and nested `dcc.Markdown` (dccMarkdown) react components inside of `dcc.Markdown`
- [#706](https://github.com/plotly/dash-core-components/pull/706)
  - Added new `responsive` property that overrides the underlying Plotly.js graph responsiveness from Dash-land
  - Added responsiveness on graph parent element resize (previously only worked on window.resize)
  - Added new `dash-graph--pending` class to dcc.Graph, present while resizing, (re-)rendering, loading

### Changed
- [#723](https://github.com/plotly/dash-core-components/pull/723) Changed npm package content to allow source code inclusion from other projects
- [#725](https://github.com/plotly/dash-core-components/pull/725) Improve async graph performance by parallelizing resource fetching instead of fetching sequentially
- [#720](https://github.com/plotly/dash-core-components/pull/720) `highlight.js` is now bundled into the package, and no longer sets the `window.hljs` variable. Similarly to how `plotly.js` is handled, it is overridden by a user-provided version if one exists.

### Updated
- [#732](https://github.com/plotly/dash-core-components/pull/732)
  - Upgraded plotly.js to [1.52.1](https://github.com/plotly/plotly.js/releases/tag/v1.52.1)
  - [Feature release 1.52.0](https://github.com/plotly/plotly.js/releases/tag/v1.52.0) which contains:
    - Enable loading locale bundles before plotly.js bundles [#4453](https://github.com/plotly/plotly.js/pull/4453)
    - `ko` localization [#4315](https://github.com/plotly/plotly.js/pull/4315)
  - Patch release [1.52.1](https://github.com/plotly/plotly.js/releases/tag/v1.52.1) containing several bug fixes.
- [#706](https://github.com/plotly/dash-core-components/pull/706)
  - Upgraded plotly.js to [1.51.3](https://github.com/plotly/plotly.js/releases/tag/v1.51.3)

## Dash-Table
### Added
- [#606](https://github.com/plotly/dash-table/pull/606) Add markdown support for table cells. Cells will be rendered as markdown if the column `presentation` is specified as `markdown`.
    - Add highlight.js for syntax highlighting. If `window.hljs` is specified, that will be used for highlighting instead.

### Fixed
- [#670](https://github.com/plotly/dash-table/pull/670) Fix a bug where `derived_filter_query_structure` was not getting updated properly
- [#677](https://github.com/plotly/dash-table/pull/677) Fix a bug where the table fails to load when used inside an iframe with a sandbox attribute that only has allow-scripts
- [#665](https://github.com/plotly/dash-table/pull/665) Fix a bug in Firefox where the dropdown cells height is incorrect",33702544
364,False,False,2019-11-27T20:54:41Z,2019-11-27T20:57:05Z,"## Dash and Dash-Renderer
### Added
- [#967](https://github.com/plotly/dash/pull/967) Add support for defining
clientside JavaScript callbacks via inline strings.
- [#1020](https://github.com/plotly/dash/pull/1020) Allow `visit_and_snapshot` API in `dash.testing.browser`  to stay on the page so you can run other checks.

### Changed
- [#1026](https://github.com/plotly/dash/pull/1026) Better error message when you forget to wrap multiple `children` in an array, and they get passed to other props.

### Fixed
- [#1018](https://github.com/plotly/dash/pull/1006) Fix the `dash.testing` **stop** API with process application runner in Python2. Use `kill()` instead of `communicate()` to avoid hanging.
- [#1027](https://github.com/plotly/dash/pull/1027) Fix bug with renderer callback lock never resolving with non-rendered async component using the asyncDecorator

## Dash-Core-Components
### Updated
- Upgraded plotly.js to 1.51.2 [#708](https://github.com/plotly/dash-core-components/pull/708)
  - Patch release [1.51.2](https://github.com/plotly/plotly.js/releases/tag/v1.51.2) containing several bug fixes.

### Changed
- [#695](https://github.com/plotly/dash-core-components/pull/695) Improvements to Slider and RangeSlider
  - Marks outside of the range specified by `min` and `max` are now omitted when the slider renders.
  - Padding is now dependent on the orientation (vertical or horizontal), and whether or not tooltips are always displayed.
  - The whitespace is now preserved for `marks` labels.

### Added
- [#695](https://github.com/plotly/dash-core-components/pull/695) Added new property `verticalHeight` to Slider and RangeSlider, to allow the user to specify the height (in px) of vertical sliders. This defaults to `400`.
",33702544
365,False,False,2019-11-14T20:55:11Z,2019-11-14T20:56:10Z,"## Dash
### Fixed
- [#1006](https://github.com/plotly/dash/pull/1006) Fix IE11 / ES5 compatibility and validation issues
- [#1006](https://github.com/plotly/dash/pull/1006) Fix bug with renderer wrapper component TreeContainer to prevent useless re-renders
- [#1001](https://github.com/plotly/dash/pull/1001)
  - Fix and improve the `clear_input()` API in `dash.testing`, so it's more robust handling react `input`.
  - make the `percy_snapshot()` API more robust, and the timeout of `wait_for_callbacks` (if set to True) will not fail the snapshot execution, but logged as potential error.

## Dash-Core-Components
### Fixed
- [#696](https://github.com/plotly/dash-core-components/pull/696) Fix IE11 compatibility issues and ES5 compatibility and validation

### Changed
- [#687](https://github.com/plotly/dash-core-components/pull/687/) Use `start_date`, `min_date_allowed`, `end_date`, or `max_date_allowed` for the initial visible month if the value of the parameter `initial_visible_month` is not supplied.

## Dash-Html-Components
### Fixed
- [#143](https://github.com/plotly/dash-html-components/pull/143) Fix IE11 compatibility issues and ES5 compatibility and validation

## Dash-Table
### Fixed
- [#637](https://github.com/plotly/dash-table/pull/637) Fix multiple issues
  - Fix IE11 compatibility issues and add ES5 compatibility and validation
  - Fix a bug with `loading_state` being handled incorrectly, causing the table to steal focus",33702544
366,False,False,2019-11-04T21:13:47Z,2019-11-04T21:15:27Z,"## Dash
### Fixed
- [#999](https://github.com/plotly/dash/pull/999) Fix fingerprint for component suites with `metadata` in version.
- [#983](https://github.com/plotly/dash/pull/983) Fix the assets loading issues when dashR application runner is handling with an app defined by string chunk.

## Dash-Core-Components
### Added
- [#692](https://github.com/plotly/dash-core-components/pull/692) Async DatePickerSingle, DatePickerRange, Dropdown, Markdown, Upload components",33702544
367,False,False,2019-10-30T01:34:29Z,2019-10-30T01:35:57Z,"## Dash and Dash-Renderer
### Fixed
- [#987](https://github.com/plotly/dash/pull/987) Fix cache string handling for component suites with nested folders in their packages.
- [#986](https://github.com/plotly/dash/pull/986) Fix a bug with evaluation of `_force_eager_loading` when application is loaded with gunicorn",33702544
368,False,False,2019-10-29T17:01:17Z,2019-10-29T17:12:36Z,"## Dash and Dash-Renderer
### Added
- [#964](https://github.com/plotly/dash/pull/964) Adds support for preventing updates in clientside functions.
  - Reject all updates with `throw window.dash_clientside.PreventUpdate;`
  - Reject a single output by returning `window.dash_clientside.no_update`
- [#899](https://github.com/plotly/dash/pull/899) Add support for async dependencies and components
- [#973](https://github.com/plotly/dash/pull/973) Adds support for resource caching and adds a fallback caching mechanism through etag

## Dash-Core-Components
### Added
- [#616](https://github.com/plotly/dash-core-components/pull/616) Async Graph and Plotly.js

## Dash-Table
### Changed
- [#554](https://github.com/plotly/dash-table/pull/554) Async loading of `xlsx` library on export",33702544
369,False,False,2019-10-17T13:58:50Z,2019-10-17T14:02:45Z,"## Dash and Dash-Renderer
### Fixed
- [#969](https://github.com/plotly/dash/pull/969) Fix warnings emitted by react devtools coming from our own devtools components.

## Dash-Core-Components
### Updated
- Upgraded plotly.js to 1.50.1 [#681](https://github.com/plotly/dash-core-components/issues/681)
  - Patch release [1.50.1](https://github.com/plotly/plotly.js/releases/tag/v1.50.1) containing several bug fixes.

### Fixed
- [#681](https://github.com/plotly/dash-core-components/issues/681) Fix a bug with the dcc.Graph component logging errors in certain circumstances when nested inside a dcc.Loading component

## Dash-Table
### Fixed
- [#618](https://github.com/plotly/dash-table/issues/618) Fix a bug with keyboard navigation not working correctly in certain circumstances when the table contains `readonly` columns.
- [#206](https://github.com/plotly/dash-table/issues/206) Fix a bug with copy/paste to and from column filters not working.
- [#561](https://github.com/plotly/dash-table/issues/561) Fix an incorrect React PureComponent usage causing warnings in DevTools.
- [#611](https://github.com/plotly/dash-table/issues/611) Fix a bug with copy/paste causing hidden columns to be removed from the table",33702544
370,False,False,2019-10-08T19:39:31Z,2019-10-08T19:43:17Z,"## Dash and Dash-Renderer

### Added
- [#948](https://github.com/plotly/dash/pull/948) Support setting working directory for R apps run using the `dashr` fixture, primarily useful for tests with assets. `dashr.start_server` supports a `cwd` argument to set an explicit working directory, and has smarter defaults when it's omitted: if `app` is a path to an R script, uses the directory of that path; if `app` is a string, uses the directory the test file itself is in.
- [#944](https://github.com/plotly/dash/pull/944)
  - Relevant `dash.testing` methods can now be called with either an element or a CSS selector: `select_dcc_dropdown`, `multiple_click`, `clear_input`, `zoom_in_graph_by_ratio`, `click_at_coord_fractions`.
  - Three new `dash.testing` methods: `clear_local_storage`, `clear_session_storage`, and `clear_storage` (to clear both together)
- [#937](https://github.com/plotly/dash/pull/937) `dash.testing` adds two APIs `zoom_in_graph_by_ratio` and `click_at_coord_fractions` about advanced interactions using mouse `ActionChain`
- [#938](https://github.com/plotly/dash/issues/938) Add debugging traces to dash backend about serving component suites, to verify the installed packages whenever in doubt.

### Fixed
- [#944](https://github.com/plotly/dash/pull/944) Fix a bug with persistence being toggled on/off on an existing component.

## Dash-Table
### Added
[#546](https://github.com/plotly/dash-table/issues/546)
- New prop `export_columns` that takes values `all` or `visible` (default). This prop controls the columns used during export

[#597](https://github.com/plotly/dash-table/issues/597)
- Add `is blank` unary operator. Returns true for `undefined`, `null` and `''`.

[#299](https://github.com/plotly/dash-table/issues/299)
- New prop `page_count` that sets the maximum number of pages that are
  accessible via the pagination menu when using backend pagination.

### Changed
[#598](https://github.com/plotly/dash-table/issues/598)
- Allow values with whitespaces in column filters

[#580](https://github.com/plotly/dash-table/issues/580)
- Change pagination menu button UI to use arrow icons instead of plain
  buttons
- Move pagination menu to bottom-right of table
- Include go-to-first and go-to-last buttons
- Include current-page and total-pages display in pagination menu
- Include input box for user to navigate directly to a page

### Fixed

[#460](https://github.com/plotly/dash-table/issues/460)
- The `datestartswith` relational operator now supports number comparison
- Fixed a bug where the implicit operator for columns was `equal` instead of the expected default for the column type

[#546](https://github.com/plotly/dash-table/issues/546)
- Visible columns are used correctly for both header and data rows

[#563](https://github.com/plotly/dash-table/issues/563)
- Fixed a bug where any string beginning with a relational operator was being interpreted as that operator being applied to the rest of the string (e.g., ""lens"" was interpreted as ""<=ns"")

[#591](https://github.com/plotly/dash-table/issues/591)
- Fixed row and column selection when multiple tables are present

[#600](https://github.com/plotly/dash-table/issues/600)
- Fixed reconciliation when validation default value is `0` (number)
- Apply reconciliation value when deleting cells, if possible

## Dash-Core-Components
### Added
- Added `search_value` prop to `Dropdown`, for server-side options loading/filtering. [#660](https://github.com/plotly/dash-core-components/pull/660)

### Updated
- Upgraded plotly.js to 1.50.0 [#675](https://github.com/plotly/dash-core-components/pull/675)
  - [Feature release 1.50.0](https://github.com/plotly/plotly.js/releases/tag/v1.50.0) which contains:
    - A new `treemap` trace type for display of hierarchical data.
    - `texttemplate` support for all traces with on-graph text, and custom date formatting for templated on-graph and hover text.
    - Transitions (animation) for `bar` charts.
    - Numerous other performance improvements, features, and bug fixes.
  - Patch release [1.49.5](https://github.com/plotly/plotly.js/releases/tag/v1.49.5) containing several bug fixes.",33702544
371,False,False,2019-09-19T13:48:26Z,2019-09-19T14:17:05Z,"##dash-core-components
### Fixed
- Fix regression in DatePickerRange, DatePickerSingle, Input
[#652](https://github.com/plotly/dash-core-components/issues/652)",33702544
372,False,False,2019-09-17T18:44:43Z,2019-09-17T18:50:35Z,"## dash
### Added
- [#923](https://github.com/plotly/dash/pull/923) Adds one configuration `--percy-assets` in `pytest` to specify extra application assets path if needed
- [#918](https://github.com/plotly/dash/pull/918) Adds `wait_for_element_by_id` and `visit_and_snapshot` APIs in browser, adds `raw_command` option (it also has higher priority than
the default waitress one) and optional `start_timeout` argument to handle large application within process runner

## dash-core-components
### Added
- Added support for persistence of user-edited props to value-input components: `Checklist`, `DatePickerRange`, `DatePickerSingle`, `Dropdown`, `Input`, `RadioItems`, `RangeSlider`, `Slider`, `Tabs`, and `Textarea`. New props are `persistence`, `persistence_type`, and `persisted_props`. Set `persistence` to a truthy value to enable, the other two modify persistence behavior. See [plotly/dash#903](https://github.com/plotly/dash/pull/903) for more details. [#646](https://github.com/plotly/dash-core-components/pull/646)

### Fixed
- Fixed `Slider` and `RangeSlider` components with `tooltip.always_visible` [#640](https://github.com/plotly/dash-core-components/issues/640)
- Fixed an infinite loop problem when `Graph` is wrapped by `Loading` component [#608](https://github.com/plotly/dash-core-components/issues/608)

## dash-renderer
### Added
- [#903](https://github.com/plotly/dash/pull/903) enables props edited by the user to persist across recreating the component or reloading the page. Components need to define three new props: `persistence`, `persisted_props`, and `persistence_type` as described in the lead comment of `src/persistence.js`. App developers then enable this behavior by, in the simplest case, setting `persistence: true` on the component. First use case is table, see [dash-table#566](https://github.com/plotly/dash-table/pull/566)

### Fixed
- Reduced about 55% of the dash-renderer packages size on **PyPI** by removing the source maps. To do more advanced debugging, the source maps needs to be generated from source code with `npm run build:local` and pip install in editable mode, i.e. `pip install -e .` [#910](https://github.com/plotly/dash/pull/910)

## dash-table
### Added
[#566](https://github.com/plotly/dash-table/pull/566)
- Support persisting user edits when the component or the page is reloaded. New props are `persistence`, `persistence_type`, and `persisted_props`. Set `persistence` to a truthy value to enable, the other two modify persistence behavior. See [plotly/dash#903](https://github.com/plotly/dash/pull/903) for more details.
[#319](https://github.com/plotly/dash-table/issues/319)
- New 'loading_state' prop that contains information about which prop, if any, is being computed.
- Table no longer allows for editing while the `data` prop is loading.

### Fixed
[#578](https://github.com/plotly/dash-table/pull/578)
- Fix [#576](https://github.com/plotly/dash-table/issues/576), editing column names or deleting columns while other columns are hidden causing the hidden columns to be lost.
- Fix an unreported bug that clicking ""Cancel"" at the column name edit prompt would clear the name, rather than leaving it unchanged as it should.
[#569](https://github.com/plotly/dash-table/issues/569), [#544](https://github.com/plotly/dash-table/issues/544)
- Allow empty strings in all `filter_query` (e.g filter_query: '{colA} eq """"')
[#567](https://github.com/plotly/dash-table/issues/567)
- Add support for missing `border-radius` in style_** props
- Fix table's inner vs. outer container styling
[#18](https://github.com/plotly/dash-table/issues/18)
- Fix row selection vertical and horizontal alignment
[#103](https://github.com/plotly/dash-table/issues/103)
- Simplify usage for multi-line cells and ellipsis. The cell's content now inherits the value of
`white-space`, `overflow` and `text-overflow` from its parent, making it possible to style
multi-line & ellipsis with `style_data` and other style props.
[#583](https://github.com/plotly/dash-table/issues/583)
- Fix regression when editing the content of a cell in a scrolled virtualized table",33702544
373,False,False,2019-08-27T20:42:06Z,2019-08-28T13:10:35Z,"## dash
### Added
- [#860](https://github.com/plotly/dash/pull/860) Adds a new arg `dev_tools_prune_errors` to `app.run_server` and `app.enable_dev_tools`. Default `True`, tracebacks only include user code and below. Set it to `False` for the previous behavior showing all the Dash and Flask parts of the stack.

## dash-core-components
### Fixed
- Fixed problems with `Graph` components leaking events and being recreated multiple times if declared with no ID [#604](https://github.com/plotly/dash-core-components/pull/604)

- Fixed problem with `DatePickerRange` component about `clearable` not working [#614](https://github.com/plotly/dash-core-components/issues/614) and [#594](https://github.com/plotly/dash-core-components/issues/594)

### Updated
- Upgraded plotly.js to 1.49.4 [#612](https://github.com/plotly/dash-core-components/issues/612)
  - Patch releases [1.49.4](https://github.com/plotly/plotly.js/releases/tag/v1.49.4), [1.49.3](https://github.com/plotly/plotly.js/releases/tag/v1.49.3), [1.49.2](https://github.com/plotly/plotly.js/releases/tag/v1.49.2)

## dash-html-components
### Updated
- Generated documentation

## dash-renderer
### Changed
- Clean all the binary assets in dash-renderer repo, add tool to build all the required bundles from fresh source code to avoid confusion of the assets and improve the release process. [#874](https://github.com/plotly/dash/pull/874)

## dash-table
### Added
[#317](https://github.com/plotly/dash-table/issues/317)
- New `column.selectable` nested prop that displays a selection checkbox or radio button in the column.
- New `column_selectable` prop to choose whether columns can be selected or not, and whether a single or
    multiple selections can be in effect at the same time.
- New `selected_columns` prop that contains the list of visible and hidden columns that are currently selected
- New `derived_viewport_selected_columns` that contains the list of visible columns that are currently selected
    This prop is read-only. Use `selected_columns` in callbacks instead.

### Fixed
[#533](https://github.com/plotly/dash-table/issues/533)
- Fixed problem clearing one column shifting everything to the left and
leaving the last column blank
- Add merge_duplicate_headers prop to correct `export_format: display` behavior.
[#549](https://github.com/plotly/dash-table/issues/549)
- Fixed renaming of single-row headers in the GUI",33702544
374,False,False,2019-08-06T23:07:01Z,2019-08-06T23:08:50Z,"## dash-core-components
### Changed
- Upgraded plotly.js to 1.49.1 [#595](https://github.com/plotly/dash-core-components/issues/595)",33702544
375,False,False,2019-08-05T19:11:44Z,2019-08-05T19:34:24Z,"## dash
### Added
- [#827](https://github.com/plotly/dash/pull/827) Adds support for dashR testing using pytest framework

## dash-core-components
### Changed
- Fixed inconsistent behavior of `input` with `type=number` [#580](https://github.com/plotly/dash-core-components/pull/580)

### Updated
- Upgraded plotly.js to 1.49.0 [#589](https://github.com/plotly/dash-core-components/pull/589)
  - [Feature release 1.49.0](https://github.com/plotly/plotly.js/releases/tag/v1.49.0) which contains:
    - New `indicator` trace type for gauge and KPI displays.
    - Lots of tile map improvements: `choroplethmapbox` and `densitymapbox` trace types, numerous `style` options for `mapbox` subplots that do not require a Mapbox access token, and more.
    - Various bug fixes and smaller improvements.

## dash-table
### Added
[#314](https://github.com/plotly/dash-table/issues/314) 
- New `column.hideable` flag that displays an ""eye"" action icon in the column
    Accepts a boolean, array of booleans, 'last' or 'first'. Clicking on the ""eye"" will add the column to the `hidden_columns` prop.
    `hidden_columns` can be added back through the Columns toggle menu whether they are hideable or not.
- New accepted values for `column.clearable`, `column.deletable` and `column.renamable`
    These props now also accept 'last' and 'first'.
    - 'last' will display the action only on the last row of the headers
    - 'first' will display the action only on the first row of the headers

[#313](https://github.com/plotly/dash-table/issues/313) Ability to export table as csv or xlsx file.

[#497](https://github.com/plotly/dash-table/pull/497)
- New `column.clearable` flag that displays a ""eraser"" action in the column
    Accepts a boolean or array of booleans for multi-line headers.
    Clicking a merged column's ""eraser"" will clear all related columns.

    - Clearing column(s) will remove the appropriate data props from each datum
    row of `data`.
    - Additionally clearing the column will reset the filter for the affected column(s)

[#318](https://github.com/plotly/dash-table/issues/318) Headers are included when copying from the table to different
tabs and elsewhere. They are ignored when copying from the table onto itself and
between two tables within the same tab.

### Changed
[#497](https://github.com/plotly/dash-table/pull/497) Like for clearing above, deleting through the ""trash"" action will also
reset the filter for the affected column(s)

### Fixed
[#524](https://github.com/plotly/dash-table/issues/524) Fixed readonly dropdown cells content (display label, not value)

[#259](https://github.com/plotly/dash-table/issues/259) Fixed columns `sticky` on Safari

[#491](https://github.com/plotly/dash-table/issues/491) Fixed inconsistent behaviors when editing cell headers

[#521](https://github.com/plotly/dash-table/pull/521) Fixed white line artifacts when rendering the table with browser zoom different from 100%",33702544
376,False,False,2020-03-18T02:40:04Z,2020-03-18T02:41:06Z,"## :tada: Features and Enhancements

- improve README (add [useful external packages section](https://github.com/nteract/hydrogen#useful-external-packages))
- more menus

## :bug: Bugs

- introduce a config option for #1790, and turn off it by default (#1892)

## :construction_worker: Internal Improvements

- update to the latest `@nteract` dependencies (#1853, #1877)
- update to the latest `uuid` dependency (#1884)
- update flow and fixes #1784
",35395056
377,False,False,2020-02-13T09:58:30Z,2020-02-13T09:58:58Z,"## :tada: Features and Enhancements

- show more detailed kernel information: #1879
- center screen on cursor on `run[-cell]-and-move-down` command: #1790 
- replace unmaintained react-rangeslider and roll our own: #1796

## :bug: Bugs and fixes

- temporal fix for #1854: #1876

## :construction_worker: Internal Improvements

- improved loggings for development: #1842
- update dependencies: #1861, #1857, #1856, #1839, #1825, #1809, #1798
",35395056
378,False,False,2019-10-29T03:14:32Z,2019-10-29T03:16:48Z,"## :bug: Bugs

- Fixes an issue of mathjax renderings within markdown results: #1669

## :construction_worker: Internal Improvements

- Updated dependencies: #1798",35395056
379,False,False,2019-10-20T18:19:16Z,2019-10-20T18:25:08Z,"## :tada: Features and Enhancements

- Added the ability to import result from jupyter notebooks #1715 
   - This is enabled by default but can be turned off in the settings under 'Enable Import of Notebook Results'


## :construction_worker: Internal Improvements

- Updated dependencies: #1786
- Clean up code: #1789
",35395056
380,False,False,2019-09-28T16:43:05Z,2019-09-28T16:45:17Z,"## :bug: Bugs

- Fix an issue with kernel commands  not working: #1781 

## :construction_worker: Internal Improvements

- Updated dependencies: #1716 ",35395056
381,False,False,2019-08-30T19:27:03Z,2019-08-30T19:27:58Z,"## :tada: Features and Enhancements

- Added syntax highlighting and autocomplete inside Watches #1701
- Add supports for newer versions of Vega #1724
   * vega-lite v3, vegav4/v5 mime-types are now supported: see [here](https://github.com/nteract/nteract/pull/4442) for more details
- **Experimental** Autocompletion descriptions: #1727
   * With this feature, you can see kernel inspections in a description of autocompletions: e.g.:
      + > example in IJulia:
      + ![image](https://user-images.githubusercontent.com/40514306/64019077-1f618480-cb69-11e9-9206-a9c2d24b0986.png)
   * :warning: Since this feature can slow down the completion performance, you must enable this via the config setting `Enable Autocomplete description (Experimental)` by yourself.
- :warning: Autocompletion priority has change to a number rather than a checkbox: #1727
   * If you had this box unchecked in 2.10.0 or lower, then you may want to set the config setting `Autocomple Suggestion Priority` to an number lower than `1`. Setting the number higher will show Hydrogen results higher up in the suggestion list.


## :bug: Bugs

- Fix an issue with plotly screenshots not working: #1703
- Fixed an issue with multiline startup commands for kernels not running both lines: #1713
- Fixed a Panda DataFrame style where border had brightened from 2.9.0 to 2.10.0: #1725


## :construction_worker: Internal Improvements

- Updated dependencies: #1631, #1724
- Clean up code: #1706, #1712, #1714


## :book: Documentations

- Add [documentation for ""Cell""](https://nteract.gitbooks.io/hydrogen/docs/Usage/Cells.html): #1745
- Fix Dockerfile Example: #1717
- Added Cell Seperator Plugin
",35395056
382,False,False,2019-07-03T12:19:56Z,2019-07-03T12:21:41Z,"## :bug: Bugs

- Fixed async stream output update issues: #1687
- :warning: Revert the ""output-wrapping"" setting introduced in v2.10.0, and instead introduce the config setting for it: #1688
    * If you like the wrapping setting between v2.10.0 and v2.10.2, please check `Enable Soft Wrap for Output` in Hydrogen's settings
",35395056
383,False,False,2019-06-28T16:44:52Z,2019-06-28T16:45:38Z,"## :bug: Bugs
- Fixed ""cursor freezing"" when closing multiline results #1682

## :construction_worker: Internal Improvements
- Updated dependencies #1523, #1683

## :book: Documentation
- Added new Cell Navigation Plugin #1676",35395056
384,False,False,2019-06-22T20:07:28Z,2019-06-22T20:09:42Z,"## :tada: Features and Enhancements

- Thanks to [@wadethestealth](https://github.com/wadethestealth), `Hydrogen:Run-Cell` now can render markdown texts !: #1628
    * Since this feature is still in early stage, you might come across some issues (there are known issues like #1633, #1669, #1672). If you find the other issues, please report them to us ! :pray:
- [Kernel-Monitor](https://nteract.gitbooks.io/hydrogen/docs/Usage/GettingStarted.html#hydrogen-toggle-kernel-monitor) got enhanced so much !: #1601
    * Within the Kernel-Monitor, you can:
        + manage kernels: Interrupt / Restart / Shutdown
        + _monitor_ various information about kernels: Kernel spec / Status / Execution count / Last execution time
        + jump to files connected to a kernel on click

> Example: Putting them together

![ezgif com-video-to-gif](https://user-images.githubusercontent.com/40514306/59971904-ce10a400-95bf-11e9-93ad-6e32ee0a78e9.gif)

- Kernel-Monitor is not focused after toggling by `Hydrogen:Toggle-Kernel-Monitor`: #1661
- Selection-based copying is enabled within results: #1652
- You can now make _jump-click_ within sliders: #1616
- `Output Area` and `Watches` panes are now automatically shown if it's not activated: #1615


## :bug: Bugs

- `Hydrogen:Fold-Current-Cell` now works correctly when  the next cell marker is on the following line without an empty line: #1659
- Cursor positions for non-BMP characters got fixed: #1658
- Fixed Horizontal scrolling within result views: #1647
- Long results are now correctly wrapped: #1594


## :construction_worker: Internal Improvements

- A callback for file deletion event is added to clean up related information in store: #1662
- :up: Update output components to [@nteract/outputs](https://www.npmjs.com/package/@nteract/outputs): #1663
- `Hydrogen:Export-Notebook` is registered as activation command: #1657
- Update flow type definition of `lodash`: #1657
- Fixed package spec on Windows: #1626
- Regex for cell detection is now more forgiving: #1621
- Fixed `npm run prettier` command on Windows: #1614


## :book: Documentation

- Fixed dead links in the contributions and installation guides: #1627, #1624
- Typo in style customization documentation is fixed: #1593


## :fire: Dropped support

- `Hydrogen:Restart-Kernel-And-Re-Evaluate-Bubbles` is removed:
    * Please refer to #1642 for the rationale
    * **_If you want to recover this feature, please volunteer to maintain it_**
",35395056
385,False,False,2019-04-08T03:33:32Z,2019-04-08T03:52:02Z,"## :tada: Features
- Support running kernels in unsaved editors (#1540)
- Import notebook from treeview context menu (#1566)

![right click to import demo](https://user-images.githubusercontent.com/10860657/53927584-9861a280-4044-11e9-88eb-7e47dcdd6d8d.gif)


## :bug: Bugs
- Officially require atom `>=1.28` (#1553)
 
## :construction_worker: Internal Improvements
- Bump flow version
- Associate `MarkerStore` with specific editor (#1547)",35395056
386,False,False,2019-02-06T06:49:46Z,2019-02-06T07:06:59Z,"## :tada: Features

- Support exporting markdown cells to notebook file #1498
- Import Jupyter Notebook files into Atom #1501
- Auto-import Jupyter Notebook files #1515

## :bug: Bugs

- Fix toggling hydrogen output mode #1494
- Don't trim text put on clipboard #1511 
- Fix package repo URL link #1518
- Fix cell boundaries when regex matches outside comment #1520

## :construction_worker: Internal Improvements

- Provide ordering to configuration settings #1530
- Remove initial empty cell from `codeManager.getCells` #1505

## :memo: Documentation

- Remove duplicated data explorer docs example #1490
",35395056
387,False,False,2018-12-09T02:36:57Z,2018-12-09T02:40:30Z,"## :tada: Features
- Add code cell folding #1458
![gif showing code cell folding](https://user-images.githubusercontent.com/15164633/47398574-a1d81700-d702-11e8-815f-aeeeedfb258f.gif)
- Hide autocomplete suggestions in run and runCell #1454
- Allow Hydrogen's autocompletions to be listed first #1455
- kernel-manager.js: clarify 'no kernel found' error description #1421

## :bug: Bugs
- Run startup code on kernel restart, #1414
- Use monospace font in output area (fixes several formatting issues), #1424

## :construction_worker: Internal Improvements
- Add a spec for ResultViewComponent #1440
- Cleanup flow defs, #1437
- Update prettier and remove travis prettifications, #1438
- Switch from greenkeeper to renovate, #1442
- Cleanup mobx usage, #1450 
- Add new grammars to list of markupGrammars #1487
- Prompt for installed plugins in bug report template [\#1480](https://github.com/nteract/hydrogen/pull/1480)

## :memo: Documentation
- Update altair example in docs #1481
- Update contributing guide #1423
",35395056
388,False,False,2018-09-11T23:43:26Z,2018-09-11T23:45:25Z,"## :tada: Features

- Don't trim code selection before sending to kernel, #1363
- Add MagicPython language mapping by default. #1368
- Add class to status bar item, #1389

## :electric_plug: New Hydrogen Plugins!

- [abjadcompile](https://atom.io/packages/abjadcompile) - in-editor illustration of Abjad objects in dedicated panes
- [data explorer](https://atom.io/packages/data-explorer) - Automatic visualization of pandas dataframes
- [hydrogen python](https://atom.io/packages/hydrogen-python) - Python specific enhancements for hydrogen!

## :bug: Bugs

- Change isSingleLine to support null or undefined text, #1384
- Fix error: `Uncaught Error: Cannot find module '@babel/runtime-corejs2/helpers/interopRequireWildcard'`, #1407

## :construction_worker: Internal Improvements

- Update to mobx 5, #1381
- Remove unnecessary .slice() calls, #1382
- Remove unused references to `controlSocket`, #1360
- Upgrade flow, #1385
- Update spawnteract, #1339, and related fix: #1380
",35395056
389,False,False,2018-04-14T12:22:38Z,2018-04-14T12:28:23Z,"## :bug: Bugs
- #1293 fix output stream results not updating
- #1292 fix multi-language kernel",35395056
390,False,False,2018-04-12T02:20:24Z,2018-04-12T02:27:59Z,"## Features

Vega 3 + Vega-lite 2 support! With the coming Altair 2.0 you'll have full interactive charts. 🎉 

![hydro-altair](https://user-images.githubusercontent.com/836375/38653195-69f9bce0-3dbe-11e8-960a-39ad7f96053c.gif)
",35395056
391,False,False,2018-03-05T23:08:41Z,2018-03-06T11:26:09Z,"## :tada: Features
- Update Plugin API #1179, #862, #64 
  This allows plugins to intercept or issue kernel commands.
  Checkout [`hydrogen-python`](https://github.com/nikitakit/hydrogen-python) which uses this to improve whitespace handling for Python and adds a variable explorer.

## :bug: Bugs
- Fix session name display in WSKernelPicker #1247, #1245

## :memo: Documentation
- Mention [`hydrogen-python`](https://github.com/nikitakit/hydrogen-python) in README.md #1249

## :construction_worker: Internal Improvements
- Update dependencies #1201, #1234",35395056
392,False,False,2018-02-19T16:48:32Z,2018-03-06T11:19:20Z,"## :bug: Bugs
- Fix move down in Atom 1.24.0 #1231, #1229
- Handle filename changes #1217, #1191
- Set undefined for onClick instead of false #1211

## :construction_worker: Internal Improvements
- Update `flow-bin` to the latest version #1202, #1228
",35395056
393,False,False,2018-01-12T16:57:48Z,2018-01-12T17:00:12Z,"## 🐛 Bugs
- Fix `plotly` 3D plots #1187, #1128 

## :memo: Documentation
- Fix typo in Getting Started doc #1178

## 👷 Internal Improvements
- Update `flow-bin` and flow definitions to the latest version #1182",35395056
394,False,False,2018-01-02T13:31:40Z,2018-01-02T13:33:11Z,"## 🐛 Bugs
- Add message when startup cancels due to unsaved file #1161

## 👷 Internal Improvements
- ⬆️ @nteract/ packages and flow #1174",35395056
395,False,False,2017-12-18T21:03:14Z,2017-12-25T14:36:13Z,"## :tada: Features
- Remote kernels: Prompt to authenticate with token or cookie #1110

## :bug: Bugs
- Add padding for big outputs #1144
- Fix compatibility with Atom 1.24 and `.flowconfig` #1147


## :memo: Documentation
- Add a note for installation from console #1138

## :construction_worker: Internal Improvements
- Remove usage of private refs to upgrade `@nteract/` packages #1143
- Update dependencies #1130,  #1131, #1132
",35395056
396,False,False,2017-11-25T19:58:48Z,2017-11-25T20:02:05Z,"## 🐛Bugs
- Pin `display-area` to fix #1118 ",35395056
397,False,False,2017-11-18T04:05:46Z,2017-11-18T04:19:49Z,"## :tada: Features
- Create a Jupyter notebook from a text file #1047
    - To try it out, use the new command `hydrogen:export-notebook`
- Use autocomplete-plus config for minimum word length #1054
- Add option to disable status bar component #1058
- Navigate output/watch history with your keyboard #1062 :
![gif showing focused slider moving around with keyboard](https://user-images.githubusercontent.com/10860657/31919485-60ea9e24-b828-11e7-8272-1399e0bcdcd3.gif)
- Improve ""no kernels"" error message #1046 
- Clear output pane with clear results command #1072
- Improve error message if kernelspec isn't correctly setup #1108


## :bug: Bugs
- Fix output copy feature #1083
- Fix duplicate output panes #1085
- Fix compatibility issues with Atom 1.23 #1093

## :memo: Documentation
- Document output area #1050
- Add troubleshooting info for windows paths #1056
- Add Matplotlib interactive plots #1095

## :construction_worker: Internal Improvements
- Add specs for history slider #1053
- Set up specs with a mock global store #1070 
",35395056
398,False,False,2017-10-16T22:15:59Z,2017-10-16T22:17:19Z,"## 🐛 Bugs
- Fix history css slider issues #1049, #1030 
  <img width=""418"" alt=""bildschirmfoto 2017-10-17 um 00 07 45"" src=""https://user-images.githubusercontent.com/13285808/31637506-50128e62-b2cf-11e7-959b-95ae373ee8c8.png"">",35395056
399,False,False,2017-10-15T19:21:17Z,2017-10-15T19:21:52Z,"## :warning: Breaking Changes
### Support multiple independent kernels #1008, #40
**Three commands to start a new kernel:**
- ""Start Local Kernel"" (default when executing code in a new file)
- ""Connect to Existing Kernel"" (replaces ""Switch Kernel"")
- ""Connect to Remote Kernel""

**Main Changes:**
- Kernels are indexed by file path
- By default a new ZMQ kernel is started when users runs code in a new file
- Users can connect multiple files to the same kernel via ""Connect to Existing Kernel"". This also supports remote kernels
- ""Switch Kernel"" command is removed since it's now obsolete
- ""Select Kernel"" command is renamed to ""Start Local Kernel""
- New ""Kernel Monitor"" panel to manage all running kernels (open with ""Toggle Kernel Monitor"") :
  <img width=""802"" alt=""monitor"" src=""https://user-images.githubusercontent.com/13285808/30815792-7b685b8a-a214-11e7-863e-f334f03eef0f.png"">

### Don't rely on jupyter to discover kernel specs #1031, #1039, #1046
This removes `jupyter` as a dependency and will significantly decrease startup time.

**Main Changes:**
- Remove Kernelspec setting. This setting was introduced because we ran into some issues where `jupyter` was not available from Atom. Editing this setting is a horrible user experience and everything can be achived by properly installing the kernels too.
- Remove support for old python installations, relying on deprecated `ipython` kernel directories.
- The default Python installation won't be discovered anymore. The IPython kernel needs to be installed with:
  ```bash
  python -m pip install ipykernel
  python -m ipykernel install --user
  ```

## :tada: Features
- Make text in panes (inspector, output, watch) copyable #1017, #1029
- Add setting to view output in dock by default #1022, #995

## :bug: Bugs
- Refactor ws kernel picker to remove UI flickering #1011 
- Fix watch pane not scrollable #1037, #1032
- Fix compatibility with Atom 1.22 #1036, #1034

## :memo: Documentation
- Add `kotlin-jupyter` to the list of supported kernels #1019

## :construction_worker: Internal Improvements
- Update `prettier` to the latest version #1015, #1016, #1020, #1027
- Update `flow-bin` to the latest version #1018
- Update to React 16 #1028
- Test panes and kernel manager #1041
- Remove `requirejs` dependency #1009
- Upgrade `@jupyterlab/services@0.50.0` #1043",35395056
400,False,False,2017-09-21T20:08:31Z,2017-09-21T20:15:57Z,"## :tada: Features
- Add support for Vega mime type #939, #560
![altair](https://user-images.githubusercontent.com/13285808/30343455-f85f5b00-97fd-11e7-9bd6-478280c50c0e.png)
- Add margins between items in output area #997, #993
- Add run cell commands to menu #1005
<img width=""528"" alt=""bildschirmfoto 2017-09-21 um 20 50 40"" src=""https://user-images.githubusercontent.com/13285808/30713137-95fff11e-9f0e-11e7-83b3-1a3330e8305c.png"">

## :bug: Bugs
- Don't set default Inspector font size to 0px #991, #996, #1004 
- Use px units for inline container styling #1003, #999 

## :construction_worker: Internal Improvements
- Update `prettier` to the latest version #992
- Update `flow-bin` to the latest version #1002

",35395056
401,False,False,2017-09-12T18:41:54Z,2017-09-12T18:48:27Z,"## :tada: Features
- New scrolling list view in external output area #978
![scroll](https://user-images.githubusercontent.com/13285808/30063620-9de1e71e-924f-11e7-8345-8a3291f0e0aa.gif)
- Added copy to clipboard button to external output area #954, #983
- Add config option for fontsize in panels #977, #980, #971


## :bug: Bugs
- Support characters width non default width #975, #930 
<img width=""513"" alt=""chinese"" src=""https://user-images.githubusercontent.com/13285808/30030394-48b47472-918d-11e7-93fa-11c3534bfe98.png"">

## :memo: Documentation
- Update description and author #974
<img width=""407"" alt=""screen shot 2017-09-03 at 4 39 49 pm"" src=""https://user-images.githubusercontent.com/836375/30007571-8c5c6224-90c6-11e7-8341-fcf314b879b6.png"">

## :construction_worker: Internal Improvements
- Fix devtools error #973
- Update `atom-select-list` to the latest version #979
",35395056
402,False,False,2017-09-03T18:00:34Z,2017-09-03T18:05:53Z,"## :bug: Bugs
- Fix issues with watch component #972, #963, #936",35395056
403,False,False,2017-09-03T13:29:00Z,2017-09-03T13:39:58Z,"## :tada: Features
- Support for the new `VDOM` mime type. For more information take a look at [this notebook](https://github.com/nteract/nteract/blob/master/example-notebooks/vdom.ipynb).
- Only show copy button if there is text to copy #943

![no-copy-if-no-innertext](https://user-images.githubusercontent.com/10860657/29253709-e0ee52c0-804a-11e7-8b3b-7676424ff19c.png) | ![close-button-tooltip](https://user-images.githubusercontent.com/10860657/29253781-e6bbbf16-804b-11e7-9a08-affb78480eb8.png)
--- | ---

- Add support for `language-weave` LaTex and reStructuredText: http://mpastell.com/pweave/editors.html#atom #953
![](https://pbs.twimg.com/media/DIOsMnJWsAAMovo.png)

- Plugin API: Export [`getCurrentCellRange`](https://nteract.gitbooks.io/hydrogen/docs/PluginAPI.html#getcellrange) #957

## :bug: Bugs
- Fix issue breaking remove-watch when called from command palette #964

## :memo: Documentation
- Add guide on how to set environment variables on Windows #962, #967

## :construction_worker: Internal Improvements
- Update `prettier` to version 1.6.1 #960
- Don't include stack trace in log messages #966
- Upgrade `flow` and `@nteract/*` packages #965
",35395056
404,False,False,2017-08-14T00:57:52Z,2017-08-14T01:26:11Z,"
## :warning: Deprecations
- Connecting to existing ZMQ kernels via a connection.json file feature now fully removed #919
  - Deprecated in favor of [kernel gateways](https://nteract.gitbooks.io/hydrogen/docs/Usage/RemoteKernelConnection.html)


## :tada: Features
- Use ctrl/cmd+click to open in editor (removes need for open in editor button) #941, #942
![example open in editor](https://user-images.githubusercontent.com/10860657/29197641-aa08a868-7e02-11e7-9346-f6802421d673.gif)
- Enable hydrogen debug output toggling without reloading atom #925, #927


## :memo: Documentation

- [Simplify plotly - matplotlib example](https://nteract.gitbooks.io/hydrogen/docs/Usage/Examples.html#interactive-plots-using-plotly) #916

## :construction_worker: Internal Improvements
- Use mutable data structures to work better with mobx #917
",35395056
405,False,False,2017-07-04T12:28:51Z,2017-07-04T12:35:35Z,"## :tada: Features
- Hide expand button if nothing to expand #859
- Add config for auto hiding external output area #893

## :bug: Bugs
- Only focus output area if necessary #900

## :construction_worker: Internal Improvements
- Refactor markers handling #888
- Update dev dependencies to the latest version #889, #897",35395056
406,False,False,2017-06-22T09:58:59Z,2017-06-22T10:03:57Z,"## :tada: Features
- Add toggle-result-bubble command #875


## :bug: Bugs
- Multiple fixes for restarting kernels #883, #887
- Prevent duplicate kernel startup #876

## :construction_worker: Internal Improvements

- Add hot-reload-package command to boost dev-workflow #885
- Update lint-staged to the latest version #882",35395056
407,False,False,2017-06-16T23:11:38Z,2017-06-16T23:14:13Z,"## :bug: Bugfixes:
- Properly restart kernels #877, #863",35395056
408,False,False,2017-06-16T00:49:54Z,2017-06-16T00:51:34Z,"<!-- https://github.com/nteract/hydrogen/pulls?&q=is%3Apr%20is%3Aclosed%20merged%3A%3E${yyyy}-${mm}-${dd} -->

## :warning: Deprecations:
-  Connecting to existing ZMQ kernels via a connection.json file #855
    - Deprecated in favor of [kernel gateways](https://nteract.gitbooks.io/hydrogen/docs/Usage/RemoteKernelConnection.html)
    - See issue #858 for questions or feedback

## :tada: Features

- Add `restart-kernel-and-re-evaluate-bubbles` command
    - Cleanly evaluate code from top to bottom and update existing bubbles
  ![refresh result bubbles](https://user-images.githubusercontent.com/155205/26867118-fba72b72-4b9e-11e7-8275-cbcdc5eff68b.gif)


- Make use of all available space in external output area #860
- Add empty message to output view when nothing to display #857, #871

## :bug: Bugs

- Kernelspec user config is ignored on update-kernels #856
- ZMQ kernel should call restart-callback on light-restart #857


<!-- ## :book: Documentation

- Explain #REF
    - detail -->

## :construction_worker: Internal Improvements

- Remove ESLINT and pin prettier #865
- Suppress logs in dev mode when logs disabled #872",35395056
409,False,False,2017-06-05T16:16:02Z,2017-06-05T16:27:12Z,"## Features

- Result view will now autoscroll per default #835
- Improved kernel restart #853
  - Don't clear the result bubbles on restart
  - Don't hide external output area on restart
  - Only spawn a new kernel process and keep the ZMQ sockets open
- Add support for upcoming IPython completer API with rich type information (requires [ipykernel](https://github.com/ipython/ipykernel) v4.7) #826 
![completer](https://cloud.githubusercontent.com/assets/13285808/26584587/96caaebe-4549-11e7-9784-6c3ee7219ea5.png)

## Documentation
- Link to documentation near the top #839
- Mention Node.js development dependency #838
- Update required Atom version #842 
- Add example of using plotly in R #852


## Internal Improvements
- Improved test coverage #837, #844
- Improve flow coverage #832
- Remove slider resize hack #843
",35395056
410,False,False,2017-06-01T08:11:27Z,2017-06-01T08:32:23Z,"Starting with this release we require Atom `1.17.0+`

## New Features
### Use docks for all of our panels #818 #819

![](https://cloud.githubusercontent.com/assets/13285808/26639587/8c4d6b02-4625-11e7-9e37-1ed635b420a2.gif)

### Add External output area #825 
![](https://cloud.githubusercontent.com/assets/13285808/26563237/488115c4-44cf-11e7-8871-b97f500758b4.gif)

## Internal improvements
- Update `spawnteract` to the latest version #830
- Bump React dependencies #831 
",35395056
411,False,False,2017-05-29T18:30:08Z,2017-05-29T18:36:11Z,"**Bugfixes:**
- Fix output lag when displaying long or nested output #817 
- Fix code folding at row zero #815 #809 ",35395056
412,False,False,2017-05-23T23:21:44Z,2017-05-23T23:22:21Z,"**Bugfixes:**
- Set icon height to 100% #810",35395056
413,False,False,2017-05-22T23:44:12Z,2017-05-22T23:45:13Z,"## Features
### Rewrite result view
PRs: #772, #800, #806
![](https://cloud.githubusercontent.com/assets/13285808/25996069/984e55a2-3715-11e7-9a34-8c32fbaa26f4.png)
- Correctly determine if outputs fits inline: Fixes #744
![fit](https://cloud.githubusercontent.com/assets/13285808/26085094/dbc8c01e-39e1-11e7-81b6-1284923f9756.gif)
- Support carriage return symbol: Fixes #466
![progress](https://cloud.githubusercontent.com/assets/13285808/26085088/c67963c6-39e1-11e7-80d2-87e10353dd60.gif)
- Highlight `stderr` output: Fixes #46 ![](https://cloud.githubusercontent.com/assets/13285808/26037955/6b40be7a-38fe-11e7-9b77-da7a4a848511.png)
- Cleanup CSS: Fixes #252
- Add button to expand result: Fixes #632 
### Rewrite watch views #794

v1.13.0 | v1.14.0
--------|--------
![1 13 0](https://cloud.githubusercontent.com/assets/13285808/26279414/6be119e2-3db3-11e7-99e7-70d043893ffb.gif) | ![pr](https://cloud.githubusercontent.com/assets/13285808/26279415/6be2e006-3db3-11e7-8396-3ffeb8183253.gif)

## Bugfixes
- Fix watches scrollbar #779

## Documentation
- Add example on how to render matplotlib interactively with plotly #804
- Add link to required `language-r` package #803
- Add style customization docs page #799
- Add link to examples #805
- Add path argument to `atom --dev .` example #775
- Add instructions on how to build docs #788 

## Internal improvements
- Add flow to `watch-sidebar.js` #798
- Add flow to `plugin-api/` #790
- Simplify variable assignment of kernel start direcotry #773
- CI: Switch to trusty dist to fix Atom 1.18 builds #784",35395056
414,False,False,2017-05-13T13:47:24Z,2017-05-13T14:17:55Z,"**Features:**
- New options for kernel start directory (#771)
  - The **new default** is for a kernel to start in the project root instead of the just the open file's directory
  - You can also choose to start the kernel:
    - in the project directory relative to the file
    - in the current file's directory (the previous default)
  - See `Directory to start kernel in` under atom package settings > Hydrogen

**Internals:**
- Completed removal of `atom-space-pen-views` using [`atom-select-list`](https://github.com/atom/atom-select-list) instead (#764)
  - See also: #657, #758, #749, #742",35395056
415,False,False,2017-04-28T13:49:15Z,2017-04-28T13:51:46Z,"**Bugfixes:**
- ResultView: Guard against undefined mimeType (#746)

**Documentation:**
- Add ability to link to chapter (#755)

**Internals:**
- Refactor kernel picker to remove `atom-space-pen-views` (#749)",35395056
416,False,False,2017-04-25T15:44:51Z,2017-04-25T16:17:11Z,"**Bugfixes:**
- Fix issue with multiple language mappings (#722, #739, #740)
- Fix kernel picker issue with multiple languages  (#722)
- Fix status bar not displaying `idle` message on startup (#722)
- Don't allow language mappings change while kernels are running (#732)

**Documentation:**
- Restructure docs using gitbooks: https://nteract.gitbooks.io/hydrogen/ (#736)
- Add contribuing guide (#733)

**Internal Improvement:**
- Include stack trace in logs (#741)
- Refactor watch sidebar to remove space pen views (#742)
",35395056
417,False,False,2017-04-15T10:31:21Z,2017-04-15T10:32:31Z,"**Bugfixes:**
- Fix inline output detection (#676, #716)
- Unmount React if result bubble is destroyed (#717)",35395056
418,False,False,2017-04-13T15:34:51Z,2017-04-13T15:36:25Z,"**Bugfixes:**
- Sequential output was not displayed (#708, #709)
",35395056
419,False,False,2017-04-12T19:52:28Z,2017-04-12T20:02:28Z,"**Features:**

- Use [`@nteract/transforms`](https://github.com/nteract/nteract/tree/master/packages/transforms) to support rich JSON output (#655)

![transforms](https://cloud.githubusercontent.com/assets/13285808/24886344/3270935a-1e54-11e7-9a48-2454fa4f8cc7.gif)

- Add support for [plotly](https://plot.ly/javascript/) (#705, #706)

![plotly-transform](https://cloud.githubusercontent.com/assets/13285808/24976830/430f0fe8-1fcb-11e7-8f78-e13790be4309.gif)

**Documentation:**
- Add table of contents (#703)
",35395056
420,False,False,2017-04-05T14:31:10Z,2017-04-05T14:33:01Z,"**Bugfixes:**
- Fix language detection for upper case languages (#696, #698)",35395056
421,False,False,2017-04-03T23:50:12Z,2017-04-04T00:18:15Z,"**Features:**
- Support for Weave (#687, #684)

**Docs**
- Better documentation for language mappings

**Bugfixes:**
- Fix deprecation warnings (#688, #685 )

**Developer**
- Add types to input-view (#690)
- Add mobx-react-devtools (#693)
- Refactor code-manager functions (#672, #686)",35395056
422,False,False,2017-03-31T23:35:56Z,2017-03-31T23:55:29Z,"**Features:**
- Run cell for [multi-language grammars](https://medium.com/nteract/hydrogen-introducing-rich-multi-language-documents-b5057ff34efc)

**Bugfixes:**
- Fix startup issues with IJavascript (#591)
- Fix high CPU usage (#646)",35395056
423,False,False,2017-03-27T21:41:33Z,2017-03-27T21:48:28Z,"**Features:**
- Multi kernel support for:
  - [markdown](https://github.com/burodepeper/language-markdown) (#665)
  - [gfm](https://github.com/atom/language-gfm) (already shipped with 1.7.0)
  - [asciidoc](https://github.com/asciidoctor/atom-language-asciidoc) (#661)
  - [reStructuredText](https://github.com/Lukasa/language-restructuredtext) (#662)
  - [knitr](https://github.com/christophergandrud/language-knitr/) (#663)

**Bugfixes:**
- Listen for grammar changes of the editor (#667)
- Disable commands if in mini text editor (#670)
- Ignore commands when no active text editor (#671, #669)

**Documentation:**
- Add CHANGELOG.md with link to release page
- Document multi kernel workflow (#673)",35395056
424,False,False,2017-03-23T18:31:22Z,2017-03-23T18:35:34Z,"**Features:**
- Added support for multiple kernels per markdown file (#566, #637) ![multilang](https://cloud.githubusercontent.com/assets/13285808/23930485/deae06f8-092c-11e7-9456-650c30ff3616.gif)
- Inspector stores height and plays well with multiple kernels (#645)
- Added debug option to enable debug messages on
a running session (#626)
- Added a Code of Conduct (#642)


**Internal Improvement:**
- We are now using [React](https://facebook.github.io/react/) and [MobX](https://mobx.js.org/) which will allow us to make use of nteract's components in the future and support more output formats. This resulted in a lot of refactoring to make the codebase better maintainable, testable and ultimately more stable (#627, #636, #641, #644, #652)
- Added unit tests for all new React code (#648, #656, #658)
- Added flow typings (#650, #660)
- Updated `@jupyterlab/services` to the latest version (#631)
",35395056
425,False,False,2017-03-01T09:27:36Z,2017-03-01T09:32:34Z,"**Improvements:**
- Prevent image downscaling (#609, #607, #600, #250)
- Replace kernel notification RegExp with boolean (#625)

**Bugfixes:**
- Fix cell magics (#621)
- Always handle stderr of kernel process (#622)
- Fix scroll bar cropping text (#623)

**Other Improvements:**
- Update `@jupyterlab/services` to the latest version (#620)
",35395056
426,False,False,2017-02-04T20:44:30Z,2017-02-04T20:46:37Z,"**Bugfixes:**
- Determine status bar style from theme (#604, #605)

**Documentation:**
- Update Slack inviter URL (#603)

**Other Improvements:**
- Update `ws` to the latest version (#602)
",35395056
427,False,False,2017-01-27T15:07:52Z,2017-01-27T15:11:10Z,"**Bugfixes:**
- Fix exception if no code is selected to inspect (#599)
- Disable kernel interrupt on windows (#593, #592)
- WatchSidebar: Don't scroll past end in text editor (#588, #596)

**Documentation:**
- Add debugging guide and issue template for bug reports (#587)

**Other Improvements:**
- WatchSidebar: Remove usage of jQuery (#590)
- Update dependencies and enable Greenkeeper (#589)
",35395056
428,False,False,2017-01-11T08:04:30Z,2017-01-11T08:07:33Z,"**Bugfixes:**
- Fix styling issue with Atom material theme (#575, #578)
- Remove unnecessary CSS causing deprecation warning in Atom 1.13 (#579)
- Fix autocomplete when using non default grammars like MagicPython (#581)
",35395056
429,False,False,2017-01-09T12:26:53Z,2017-01-09T12:29:34Z,"**Bugfixes:**
- Fix excessive trim of output (#573, #564)

**Documentation:**
- Improve kernel connection docs (#569, #528)
",35395056
430,False,False,2016-12-29T18:16:56Z,2016-12-29T18:19:10Z,"**Bugfixes:**
- Don't block autocomplete if kernel is busy (#567)
- Only log to console if atom is in dev mode (#568)

**Documentation:**
- Mention nteract/nteract in README (#563)
",35395056
431,False,False,2016-12-28T00:16:27Z,2016-12-28T00:22:51Z,"**Improvements:**
- Allow text/markdown code inspect results (#562)

**Readme:**
- Improve documentation for remote kernels (#552, #553)

**Bugfixes:**
- Don't override `ctrl-backspace` on Windows. It is now replaced with `ctrl-shift-backspace` (#559)
",35395056
432,False,False,2016-12-16T16:03:31Z,2016-12-16T16:04:28Z,"**Improvements:**
- Allow token-based authentication for remote kernels (#542)
- Use passive wheel event to improve scroll performance (#545)
- Better scoping of keybindings (#550)
- Readme: Add link to [Medium blog post](https://medium.com/nteract/hydrogen-interactive-computing-in-atom-89d291bcc4dd) (#546)
",35395056
433,False,False,2016-12-10T16:26:07Z,2016-12-10T16:29:15Z,"**Improvements:**
- Limit result view width (#535)
- Don't block editor scrolling in result views (#536)
- Increase maximum output height (#540)

**Bugfixes:**
- Spinner disappears on `execution_count` message (#537)
- Action panel is squashed if space is limited (#538)
",35395056
434,False,False,2016-12-06T11:43:31Z,2016-12-06T12:08:05Z,"**Improvements:**
- We are now able to provide prebuilt binaries of [`zeromq`](https://github.com/zeromq/zeromq.js) for the usage in Atom/Electron. This means we don't need to build ØMQ during the install of Hydrogen.
  Hydrogen can now be installed without any external dependencies. This leads to significantly reduced installation times. (#531)
- Add _Connect to Remote Kernel_ to menus (#530)
",35395056
435,False,False,2016-12-01T16:46:16Z,2016-12-04T19:25:55Z,"**Features:**
- Use `commonmark` for Markdown rendering (#521)
- Improve installation and package size (#519, #526, #520)

**Readme:**
- Add Kernel Gateway instructions for Docker (#524)
- Add name to License (#514)
- Fix Typos (#517)

**Internals:**
- Move code to ES6 (#503)
- Refactor input view (#513)
",35395056
436,False,False,2016-11-19T09:13:06Z,2016-11-28T21:31:54Z,"**Bugfixes:**
- Faster installation by only rebuilding zeromq (#510)

**Readme:**
- Better GIFs (#505)
- Add Scala to supported kernels (#509)
",35395056
437,False,False,2016-11-16T16:24:21Z,2016-11-16T16:38:20Z,"# Hydrogen 1.0.0 is out! 🎉

**Major changes:**
- Hydrogen now bundles [ØMQ](http://zeromq.org/). You no longer need to install it separately.
  This really simplifies the installation. Take a look at our updated [installation guide](https://github.com/nteract/hydrogen#dependencies).
- The default keybindings changed to make them consistent with [nteract](https://nteract.io/) and [jupyter](http://jupyter.org/) notebook. Use the command pallet in Atom (`cmd-shift-P`) to find the new keybinding for your favorite command.

**All changes:**
- Bundle ØMQ (#476, #487, #489, #493)
- Update Keybindings (#488)
- Display execution counts for result bubbles (#472)
- General improvements to the watch sidebar (#496, #502, #492)
- Move ""Copy Connection File"" to [Hydrogen-Launcher](https://github.com/lgeiger/hydrogen-launcher) (#490)
- Update docker guide (#486)
- Add documentation for Plugin API (#495)
- Fix error messages (#483)
- Fix exception caused by to large buffer (#491)
",35395056
438,False,False,2016-10-18T12:56:06Z,2016-10-18T13:08:39Z,"**Fixes:**
- Fix a issue while connecting to an existing kernel (#436)
- Ensure unix style line endings before sending code to kernels (#312)
- Fix a issue while executing code cells (#470)
- Correctly support carriage return symbol (#474)
- Fix a error when file doesn't end with a new line (#477)
- Revert to original behavior of ""Run and Move Down"" (#479)

**Features:**
- Initial implementation of a plugin API used in [`hydrogen-launcher`](https://atom.io/packages/hydrogen-launcher) (#446, #471)
- Improve documentation (#444, #448, #450, #462)
",35395056
439,False,False,2016-09-04T21:54:58Z,2016-09-04T22:11:48Z,"**Remote Kernels:**
- Documentation added (PR #423)
- Command to disconnect from a kernel added (PR #421)
- Remote kernels are now filtered by language (PR #422)
- Session paths are displayed shorter (PR #424)
- Sessions can be renamed now (PR #425)

**Other Changes:**
- Improvements to move down functionality (PR #433)
- Improved compatibility with old versions of iTorch (PR #435)
- Fixed incompatibility with Atom version `1.11.0+` (PR #430)
- More small improvements (PRs #427, #431, #432)
",35395056
440,False,False,2016-08-23T08:42:04Z,2016-08-23T08:51:51Z,"- New command to copy the path for the connection file (PR #416)
- Improvements to atom notifications (PR #412)
- 🐛 Fix an error that happened when no project folder was present (Issue #413, PR #414)

**Remote kernels**:
- Support watches (PR #408)
- Support kernel shutdown (PR #409)
- Support STDIN (PR #410)
- Throw better notifications if no gateway is setup (PR #411)
",35395056
441,False,False,2016-08-17T08:10:15Z,2016-08-17T08:23:07Z,"⬆️ Bump [spawnteract](https://github.com/nteract/spawnteract) to respect `env` in kernelspec (Issue #404, PR #406, PR [spawnteract/15](https://github.com/nteract/spawnteract/pull/15)).
🐛 Fix an error that would occur when connecting to remote kernels (PR #407).
",35395056
442,False,False,2016-08-15T11:52:57Z,2016-08-15T11:56:20Z,"🐛 Pass the environment in for spawnOptions (Issue #404)
",35395056
443,False,False,2016-08-10T19:59:20Z,2016-08-10T20:12:19Z,"🐛 Fix uncaught reference  when running code cell (Issue #401)
",35395056
444,False,False,2016-08-09T21:51:30Z,2016-08-09T21:54:03Z,"Fix importing modules from same dir (Issue #398)
",35395056
445,False,False,2016-08-07T12:56:33Z,2016-08-07T13:18:58Z,"- Removed the `kernelMappings` setting. Instead, users will be prompted to make a choice (PR #351)
- Added support for STDIN (PR #364)
- Documentation updates
  - Added [TROUBLESHOOTING.md](TROUBLESHOOTING.md) (PR #372)
  - Documented the code cell functionality (PR #379)
  - Other: #363, #373, #376
- Bug fixes: #359, #366, #370, #378, #384, #387, #381, #391, #393, #395, #396
- And paying back some of our technical debt: #385, #388, #386

## Preliminary support for the Kernel Gateway (#330).

Kernel gateways are an alpha feature, please try them out:

``````
1. Run in the command line: `python -m notebook --NotebookApp.allow_origin=""127.0.0.1""`
2. Add the kernel gateway to Hydrogen's settings:
```
[{
    ""name"": ""Local gateway"",
    ""options"": {
        ""baseUrl"": ""http://127.0.0.1:8888""
    }
}]
```
3. Invoke the command `hydrogen:connect-to-remote-kernel`
``````
",35395056
446,False,False,2016-07-18T20:25:49Z,2016-07-18T20:28:20Z,"- Add support for code cells (#328, #333 )
- Improvements to the statusbar (#297, #322, #323, #334, #343)
- Toggle Inspector if invoked a second time at the same location (#338)
- Accept html inspection result (#347)
- Don't save kernel specs to setting (#337, #348)
- Fix kernel interrupt (#320)
- Fix run-and-move-down command on last line (#327)
- Code refactoring (#302, #335, #329, #341, #339 #340, #345, #346)
",35395056
447,False,False,2016-06-15T20:20:09Z,2016-06-15T20:30:19Z,"- Use existing kernel connections (#295)
- Replaced command `hydrogen:show-kernel-commands` by commands `hydrogen:select-kernel`, `hydrogen:interrupt-kernel` and `hydrogen:restart-kernel` (#270, #289).
- Added tests and set up Travis.
",35395056
448,False,False,2016-05-14T17:52:39Z,2016-05-14T17:57:29Z,"- Fix bug removing result bubbles (#265)
",35395056
449,False,False,2016-04-20T06:52:42Z,2016-04-20T07:00:57Z,"- Clean up kernel and language usage #260 
- PDF support #259 
- 🐛 fixes
",35395056
450,False,False,2016-04-15T20:44:21Z,2016-04-15T20:43:40Z,"- Support LaTeX via MathJax :symbols: https://github.com/nteract/hydrogen/pull/257
",35395056
451,False,False,2016-04-10T13:35:20Z,2016-04-10T13:46:10Z,"- Support markdown output 📝 #247 
- Upgrade `transformime-jupyter-transformers` to support more ANSI color codes 🎨  [#16](https://github.com/nteract/transformime-jupyter-transformers/pull/16)
- Don't obstruct editor content with result bubble #254 
",35395056
452,False,False,2016-04-01T21:31:20Z,2016-04-01T21:33:27Z,"- Downscale images to fit :arrow_down: https://github.com/nteract/hydrogen/pull/242
- Reposition and restyle close button :heavy_multiplication_x: https://github.com/nteract/hydrogen/pull/241
- Fix bug for ZMQ monitoring :chart_with_downwards_trend:  https://github.com/nteract/hydrogen/pull/249 
- Action panel for html output! :tram: https://github.com/nteract/hydrogen/pull/232
",35395056
453,False,False,2016-03-29T23:31:57Z,2016-03-29T23:33:44Z,"- Better styling of images! :star:
- Fix scrollbar :scroll: 
- More GIFs in our README :camera: 
",35395056
454,False,False,2016-03-25T20:46:26Z,2016-03-25T20:48:38Z,"- handles more mimetypes (mmmmm rich display!)
- inline outputs (whoa!)
- :bug: fixes
",35395056
455,False,False,2020-03-04T03:47:45Z,2020-03-04T05:03:50Z,"## Flux v0.10.3

[Diff since v0.10.2](https://github.com/FluxML/Flux.jl/compare/v0.10.2...v0.10.3)


**Closed issues:**
- Conv layer don't work on with CuArray (#809)

**Merged pull requests:**
- Common questions answered in docs (#1028) (@dhairyagandhi96)
- Added Some Loss functions with some doc improvements (#1053) (@AdarshKumar712)
- Make really good clear examples and explination of @functor  in docs (#1059) (@findmyway)
- update documenter (#1065) (@CarloLucibello)
- Updated activation functions in NNlib doc (#1069) (@AdarshKumar712)
- Prevent breakage due to new `active` field in normalise layers (#1070) (@ianshmean)",55262614
456,False,False,2020-03-03T07:20:03Z,2020-03-03T10:04:45Z,"## Flux v0.10.2

[Diff since v0.10.1](https://github.com/FluxML/Flux.jl/compare/v0.10.1...v0.10.2)


**Closed issues:**
- Training pipeline inappropriate for large datasets (#278)
- Iterators for batches and epochs (#317)
- Implicit to Explicit Parameterization of Flux Models (#742)
- crossentropy is broken with CUDA due to log (#889)
- MethodError: no method matching CuArrays.CuArray{Float32,N} where N(::Float32) (#908)
- Limitation of `Flux.istraining()` (#909)
- Error with regularization using norm() and Zygote (#930)
- Zygote error on moving array to GPU (#947)
- update! not working (#951)
- Gradients of Chain including leakyrelu function (#963)
- Is there a way to have layers (esp. a Conv) without biases?  (#966)
- Zygote error (#967)
- Why run MNIST example is vary slow? (#968)
- model-zoo Cifar10.jl is generating ""Loss is NaN"" (#970)
- Handling imbalanced data (#972)
- BatchNorm is broken (#976)
- Some activation functions change type when backpropagating and pooling layers doesn't like it (#979)
- Conv layers with CPU backend randomly mixes up batch dimensions (#982)
- destructure/restructure is doing scalar indexing on GPU in back pass (#989)
- Flux pins down Colors (#995)
- Suggestion:  Bounds for stochastic gradient descent loss fluctuations (#1000)
- How to keep weights of parts of a model fixed under Flux.train! (#1001)
- Support Colors.jl v0.10 and v0.11 (#1002)
- Typo in Flux home page description? Gougle? (#1004)
- Taking the package description (not too) seriously (#1007)
- `le_float` not differentiable: implementing reverse huber loss (#1011)
- Do you support or have any materials about optimizing with nonlinear constraints? (#1014)
- Loopinfo expression error with onecold (#1020)
- Type Promotion often Unwieldy and day Ruining (#1026)
- LoadError: MethodError: no method matching softmax(::Float32; dims=1) (#1029)
- Flux compat with Juno? (#1036)
- Failed to precompile Flux (#1045)
- train!() hasn't been export in Flux.jl (#1048)
- error with Conv (#1055)
- The most basic Conv layer fails to compute gradients (#1060)

**Merged pull requests:**
- Added new loss functions. (#680) (@thebhatman)
- Added utility function outdims to compute output dimensions of a layer (#960) (@darsnack)
- Adding CompatHelper (#984) (@aminya)
- Add custom training loops to docs (#994) (@oxinabox)
- test restructure on the GPU (#998) (@ChrisRackauckas)
- Remove unused imports. (#1008) (@maleadt)
- Adapt to GPUArrays/CuArrays changes (#1013) (@maleadt)
- nograd for onecold, onehot, onehotbatch (#1021) (@CarloLucibello)
- Feature: Added Boston Housing Dataset (#1023) (@pranjaldatta)
- Install TagBot as a GitHub Action (#1030) (@JuliaTagBot)
- Remove outdated reference to truncate! (#1032) (@mcognetta)
- Remove get! macro (#1035) (@matsueushi)
- update compat to Juno 0.8 (#1037) (@heliosdrm)
- add NNlib docs + misc docs improvements (#1041) (@CarloLucibello)
- Add testmode! back for normalization layers (#1044) (@darsnack)
- Bump Colors compat to include 0.10, 0.11 (#1046) (@ianshmean)
- Edit description of convolutional layer (#1047) (@MotJuMi)
- add DataLoader (#1051) (@CarloLucibello)
- update docs and export update! (#1052) (@CarloLucibello)
- add Julia ecosystem doc section (#1057) (@CarloLucibello)
- fix a few typos in docstrings (#1061) (@visr)
- docstring ensure signature code formatting (#1062) (@visr)
- Include cuda/cuda.jl during precompilation? (#1064) (@ianshmean)
- fix travis for documentation build (#1066) (@johnnychen94)",55262614
457,False,False,2020-01-13T13:22:05Z,2020-01-13T13:22:08Z,"## [v0.10.1](https://github.com/FluxML/Flux.jl/tree/v0.10.1) (2020-01-13)

[Diff since v0.10.0](https://github.com/FluxML/Flux.jl/compare/v0.10.0...v0.10.1)

**Closed issues:**

- destructure then restructure fails  (#988)
- ConvTranspose produces nonsense results for 3D \(aka 5D\) inputs (#978)
- Missing Tracker dependency causes DiffEqFlux v0.4.0 and DifferentialEquations v6.6.0 fail to pre-compile  in \(J V1.3\) (#975)
- UndefVarError: @functor not defined (#974)
- A problem with the first example (#959)
- Error when compiling model in GPU (#956)
- Gradient on a Neural Network (#955)
- Why the result of Flux.jl is totally different from tf.Keras \(with the same simple MLP\) (#953)
- CuArrays failed to initialize (#949)

**Merged pull requests:**

- Compat bounds for a couple more packages (#992) ([dhairyagandhi96](https://github.com/dhairyagandhi96))
- Update CuArrays + Zygote deps  (#991) ([dhairyagandhi96](https://github.com/dhairyagandhi96))
- Destructure/restructure for models (#986) ([MikeInnes](https://github.com/MikeInnes))
- Give `NNPACK` a bit of numerical leeway (#973) ([staticfloat](https://github.com/staticfloat))
- \[WIP\] Decaydocs (#954) ([baggepinnen](https://github.com/baggepinnen))",55262614
458,False,False,2019-11-29T13:47:47Z,2019-11-29T13:47:50Z,"## [v0.10.0](https://github.com/FluxML/Flux.jl/tree/v0.10.0) (2019-11-29)

[Diff since v0.9.0](https://github.com/FluxML/Flux.jl/compare/v0.9.0...v0.10.0)

**Closed issues:**

- filtering a subset of parameters (#939)
- import Flux fails with errors about libcublas (#933)
- UndefVarError: project not defined (#931)
- Warning on fresh Flux install (#929)
- Looking for libcuda and failing on a device without CUDA (#928)
- Spurious RNN failure with CUDNN (#923)
- `train!` method for `Chain` (#921)
- LoadError: LoadError: UndefVarError: libcudnn not defined (#918)
- Failed to precompile Flux (#917)
- Zygote: add adjoint for onehotbatch (#912)
- How to convert Tracked Number in Number? (#905)
- ConvTranspose gradient error: no method matching iterate\(::Nothing\) (#900)
- Gradient Through Trebuchet.jl Error (#897)
- Jacobian for Conv layers (#896)
- t (#895)
- can't find MNIST (#894)
- Regularisation docs missing norm\(\) definition (#892)
- Flux master does not precompile (#881)
- circshift breaks Tracker.gradient, but manual shifting works (#872)
- Convolution without bias (#868)
- Github stars in pkg.julialang.org (#867)
- Typo in Optimisers Doc (#862)
- Can't use Flux.Tracker (#859)
-  CUBLASError\(code 13, the GPU program failed to execute\) on seemingly simple applychain\(\) (#858)
- Should one\(::TrackedArray\) and zero\(::TrackedArray\) return TrackedArrays, instead of normal arrays? (#855)
- Flux fails its own tests when run with CuArrays (#854)
- Gradient does not converge on simple dataset (#849)
- MethodError when taking gradient of Flux.mse on GPU (#848)
- RAdam Optimizer (#841)
- Optimiser interface is not documented (#836)
- Flux\#zygote: conv\_transpose\_dims mutates arrays. (#820)
- LinearAlgebra.Transpose{Float64,Array{Float64,2}} multiplied by Tracked 2-element Array{Float64,1} doesn't work (#743)
- Glorot initialization not correctly implemented (#442)
- RNN test failures with CUDNN (#267)
- OpenCL support (#173)

**Merged pull requests:**

- compat, pkg up (#946) ([MikeInnes](https://github.com/MikeInnes))
- RNN failure hackaround (#944) ([MikeInnes](https://github.com/MikeInnes))
- Fixes \#900 (#943) ([dhairyagandhi96](https://github.com/dhairyagandhi96))
- Don't include the CUDA module during precompilation. (#941) ([maleadt](https://github.com/maleadt))
- Fix logitbinarycrossentropy on CuArrays (#940) ([matsueushi](https://github.com/matsueushi))
- Fix Glorot initialization, add He initialization (#937) ([Sleort](https://github.com/Sleort))
- Avoid unnecessary conversion (#936) ([baggepinnen](https://github.com/baggepinnen))
- Fix AMSGrad on GPU (#935) ([baggepinnen](https://github.com/baggepinnen))
- Travis: test on 1.0 (#932) ([MikeInnes](https://github.com/MikeInnes))
- Extend docs about `train!` (#927) ([heliosdrm](https://github.com/heliosdrm))
- Fix binarycrossentropy on CuArrays (#926) ([janEbert](https://github.com/janEbert))
- CUDA package initialization improvements (#924) ([maleadt](https://github.com/maleadt))
- Restore Julia 1.0 compatibility. (#922) ([maleadt](https://github.com/maleadt))
- use release versions of packages (#920) ([MikeInnes](https://github.com/MikeInnes))
- Check for CUDA availability at run time. (#916) ([maleadt](https://github.com/maleadt))
- Change `gate` function to `view` instead of copy (#907) ([janEbert](https://github.com/janEbert))
- Backticks and examples for normalise (#902) ([kshyatt](https://github.com/kshyatt))
- Fix problem in crossentropy breaking GPU compilation (#898) ([kshyatt](https://github.com/kshyatt))
- Check if CUDA availability changed during init. (#882) ([maleadt](https://github.com/maleadt))
- Fix functor's `params!` to work with complex numbers (#877) ([PhilipVinc](https://github.com/PhilipVinc))
- Move CUDNN wrappers to CuArrays (#874) ([MikeInnes](https://github.com/MikeInnes))
- Fix printing of SkipConnection (#870) ([mcabbott](https://github.com/mcabbott))
- Functor (#865) ([MikeInnes](https://github.com/MikeInnes))
- removed extra parenthesis (#863) ([Naba7](https://github.com/Naba7))
- GPU CI maintainance  (#861) ([dhairyagandhi96](https://github.com/dhairyagandhi96))
- Activations (#860) ([dsweber2](https://github.com/dsweber2))
- Restore purity (#857) ([giordano](https://github.com/giordano))
- Add RADAM optimizer (#842) ([baggepinnen](https://github.com/baggepinnen))
- using Zygote (#669) ([MikeInnes](https://github.com/MikeInnes))",55262614
459,False,False,2019-08-30T09:32:57Z,2019-08-30T09:33:00Z,"## [v0.9.0](https://github.com/FluxML/Flux.jl/tree/v0.9.0) (2019-08-29)

[Diff since v0.8.3](https://github.com/FluxML/Flux.jl/compare/v0.8.3...v0.9.0)

**Closed issues:**

- CuArrays.CUDNN.libcudnn not defined (#846)
- Flux.onecold gives incorrect result with CuArrays. (#839)
- Forward differentiation causes stackoverflow (#831)
- Layer initialization with predefined weights (#830)
- RNN behavior under different input shapes (#811)
- prefor does not update seen (#803)
- Flux is not training model (#798)
- How to Detrack the variables (#792)
- Optimisers not work for real number (#790)
- apply! in NADAM not correct (#789)
- How to onehot encode a vector (#788)
- ERROR: UndefVarError: Conv2D not defined (#786)
- Difference between params\(\) and Params\(\) (#781)
- Slowdown with Conv on CPU in newer versions of Flux+NNlib: forward pass doesn't use all available threads anymore (#771)
- CUDNN BatchNorm with relu doesn't apply relu \(when using CuArrays\)  (#760)
- back! calculates gradient incorrectly for two layer perceptron with relu (#744)
- Split out Tracker and create a Zygote branch (#664)
- ForwardDiff derivative on chain gives stackoverflow (#645)
- Calling a gpu model with a cpu array crashes julia (#581)

**Merged pull requests:**

- RFC: Replace Requires with direct CuArrays dependency. (#852) ([maleadt](https://github.com/maleadt))
- Fix CuArrays.libcudnn imports (#847) ([janEbert](https://github.com/janEbert))
- Use `CuArrays.ones` instead `cuones` which is deprecated (#837) ([mimame](https://github.com/mimame))
- Fix  cuzeros deprecation (#835) ([Moelf](https://github.com/Moelf))
- Momentum doesn't need params (#827) ([ChrisRackauckas](https://github.com/ChrisRackauckas))
- Fix for \#803 (#805) ([DrChainsaw](https://github.com/DrChainsaw))
- Fix lack of x (#801) ([quatrejuin](https://github.com/quatrejuin))
- Pick beta from the state - NADAM (#796) ([dhairyagandhi96](https://github.com/dhairyagandhi96))
- Two minor typos in docs (#793) ([amellnik](https://github.com/amellnik))
- typo of comvolutional in NEWS.md (#774) ([zsz00](https://github.com/zsz00))
- delete redundant section (#772) ([johnnychen94](https://github.com/johnnychen94))
- Some cleanup on performance tips docs (#767) ([oxinabox](https://github.com/oxinabox))
- CrossCor layer (#762) ([ayush-1506](https://github.com/ayush-1506))
- Fixes \#760 (#761) ([avik-pal](https://github.com/avik-pal))
- bump version to v0.8.3 (#759) ([dhairyagandhi96](https://github.com/dhairyagandhi96))
- Change `DepthwiseConv\(\)` to use `in=\>out` instead of `in=\>mult`. (#756) ([staticfloat](https://github.com/staticfloat))
- Fixed ExpDecay (#733) ([thebhatman](https://github.com/thebhatman))
- add broken test for \#700 (#701) ([jw3126](https://github.com/jw3126))
- Fixes OneHotMatrix/Vector GPU Performance (#612) ([dhairyagandhi96](https://github.com/dhairyagandhi96))
- noise shape for dropout (#563) ([chengchingwen](https://github.com/chengchingwen))
- Added the SkipConnection layer and constructor (#446) ([bhvieira](https://github.com/bhvieira))",55262614
460,False,False,2019-04-29T16:31:46Z,2019-05-01T15:37:48Z,,55262614
461,False,False,2019-04-05T14:48:24Z,2019-04-05T15:35:08Z,,55262614
462,False,False,2019-03-22T18:06:24Z,2019-03-22T18:33:51Z,,55262614
463,False,False,2019-03-22T16:38:16Z,2019-03-22T17:06:21Z,,55262614
464,False,False,2019-02-05T13:21:02Z,2019-02-06T14:45:24Z,,55262614
465,False,False,2019-01-29T08:37:30Z,2019-01-29T09:00:14Z,,55262614
466,False,False,2019-01-22T10:07:42Z,2019-01-22T10:22:17Z,,55262614
467,False,False,2019-01-16T10:31:53Z,2019-01-16T14:28:37Z,,55262614
468,False,False,2018-12-19T11:08:56Z,2018-12-19T11:13:19Z,,55262614
469,False,False,2018-11-14T13:59:29Z,2018-11-14T14:19:41Z,,55262614
470,False,False,2018-10-23T10:30:37Z,2018-10-23T10:31:22Z,,55262614
471,False,False,2018-09-06T14:28:15Z,2018-09-06T14:35:46Z,,55262614
472,False,False,2018-08-28T10:02:38Z,2018-08-28T10:17:55Z,,55262614
473,False,False,2018-08-24T13:30:39Z,2018-08-24T13:33:11Z,,55262614
474,False,False,2018-08-23T14:52:06Z,2018-08-23T15:08:30Z,,55262614
475,False,False,2018-08-20T15:09:02Z,2018-08-20T15:10:51Z,,55262614
476,False,False,2018-08-20T10:27:49Z,2018-08-20T11:30:56Z,,55262614
477,False,False,2018-08-16T16:28:53Z,2018-08-16T16:30:19Z,,55262614
478,False,False,2018-08-03T15:22:54Z,2018-08-03T15:32:55Z,,55262614
479,False,False,2018-07-30T19:08:44Z,2018-08-03T11:13:59Z,,55262614
480,False,False,2018-07-02T12:19:13Z,2018-07-05T11:28:00Z,,55262614
481,False,False,2018-05-07T15:14:25Z,2018-05-31T15:39:27Z,,55262614
482,False,False,2018-03-06T16:56:01Z,2018-03-06T16:57:00Z,,55262614
483,False,False,2018-03-06T03:12:42Z,2018-03-06T08:58:40Z,,55262614
484,False,False,2018-01-17T16:39:55Z,2018-01-17T17:03:31Z,,55262614
485,False,False,2017-12-18T18:18:14Z,2017-12-18T18:35:35Z,,55262614
486,False,False,2017-10-31T16:37:41Z,2017-11-01T14:29:56Z,,55262614
487,False,False,2017-10-19T16:21:08Z,2017-10-20T12:00:25Z,,55262614
488,False,False,2017-09-28T10:11:11Z,2017-09-28T10:29:10Z,,55262614
489,False,False,2017-09-12T13:11:03Z,2017-09-12T13:16:08Z,,55262614
490,False,False,2017-09-11T13:10:12Z,2017-09-11T13:22:41Z,,55262614
491,False,False,2017-08-17T23:31:24Z,2017-08-18T09:28:21Z,,55262614
492,False,False,2017-05-04T16:20:10Z,2017-05-04T16:22:53Z,,55262614
493,False,False,2017-05-02T12:55:43Z,2017-05-02T12:56:59Z,,55262614
494,False,False,2017-03-08T21:41:13Z,2017-03-09T00:11:22Z,,55262614
495,False,False,2017-03-01T12:33:37Z,2017-03-01T12:35:22Z,,55262614
496,False,False,2020-01-31T17:53:07Z,2020-01-31T18:05:21Z,"This is the final release for OpenRefine 3.3. Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features

* A new menu for joining (concatenating) columns has been added ([#2109](https://github.com/OpenRefine/OpenRefine/issues/2109))
* Commonly used fields in dialogs now have autofocus ([#2130](https://github.com/OpenRefine/OpenRefine/issues/2130))
* The Wikidata extension now supports adding dates with custom calendars ([#2136](https://github.com/OpenRefine/OpenRefine/issues/2136))
* Calling reconciliation services via CORS is now supported ([#2260](https://github.com/OpenRefine/OpenRefine/issues/2260))
* All columns can be blanked down or filled down at once ([#2280](https://github.com/OpenRefine/OpenRefine/issues/2280))
* New ""Blank values per column"" and ""Blank records per column"" facets were added ([#2220](https://github.com/OpenRefine/OpenRefine/issues/2220))


## Vulnerabilities fixed
* A cross-site scripting vulnerability in the database extension was fixed ([#2151](https://github.com/OpenRefine/OpenRefine/pull/2151))
* [Cross-Site Request Forgery (CSRF)](https://en.wikipedia.org/wiki/Cross-site_request_forgery) protection was added to POST API endpoints. If you rely on OpenRefine's server API you will need to adapt your calls accordingly ([#2164](https://github.com/OpenRefine/OpenRefine/issues/2164))

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/wiki/Changes-for-3.3).",6220644
497,False,True,2020-01-06T12:31:16Z,2020-01-06T14:07:06Z,"This is the first release candidate for OpenRefine 3.3. Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features

* A new menu for joining (concatenating) columns has been added ([#2109](https://github.com/OpenRefine/OpenRefine/issues/2109))
* Commonly used fields in dialogs now have autofocus ([#2130](https://github.com/OpenRefine/OpenRefine/issues/2130))
* The Wikidata extension now supports adding dates with custom calendars ([#2136](https://github.com/OpenRefine/OpenRefine/issues/2136))
* Calling reconciliation services via CORS is now supported ([#2260](https://github.com/OpenRefine/OpenRefine/issues/2260))


## Vulnerabilities fixed
* A cross-site scripting vulnerability in the database extension was fixed ([#2151](https://github.com/OpenRefine/OpenRefine/pull/2151))
* [Cross-Site Request Forgery (CSRF)](https://en.wikipedia.org/wiki/Cross-site_request_forgery) protection was added to POST API endpoints. If you rely on OpenRefine's server API you will need to adapt your calls accordingly ([#2164](https://github.com/OpenRefine/OpenRefine/issues/2164))

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/wiki/Changes-for-3.3).",6220644
498,False,True,2019-10-21T09:58:37Z,2019-10-21T10:02:29Z,"This is the first beta release of OpenRefine 3.3. Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features

* A new menu for joining (concatenating) columns has been added ([#2109](https://github.com/OpenRefine/OpenRefine/issues/2109))
* Commonly used fields in dialogs now have autofocus ([#2130](https://github.com/OpenRefine/OpenRefine/issues/2130))
* The Wikidata extension now supports adding dates with custom calendars ([#2136](https://github.com/OpenRefine/OpenRefine/issues/2136))

## Vulnerabilities
* A cross-site scripting vulnerability in the database extension was fixed ([#2151](https://github.com/OpenRefine/OpenRefine/pull/2151))
* [Cross-Site Request Forgery (CSRF)](https://en.wikipedia.org/wiki/Cross-site_request_forgery) protection was added to POST API endpoints. If you rely on OpenRefine's server API you will need to adapt your calls accordingly ([#2164](https://github.com/OpenRefine/OpenRefine/issues/2164))

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/wiki/Changes-for-3.3).",6220644
499,False,False,2019-07-26T14:33:02Z,2019-07-26T14:57:08Z,"This is the final release of OpenRefine 3.2. Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features
* New action to replace smart quotes to their ASCII equivalent ([#1676](https://github.com/OpenRefine/OpenRefine/issues/1676))
* New phonetic clustering methods are available: Beider-Morse ([#926](https://github.com/OpenRefine/OpenRefine/issues/926)) and Daitch-Mokotoff ([#927](https://github.com/OpenRefine/OpenRefine/issues/927))
* The ""Uses values as identifiers"" operation now accepts cells with RDF uris instead of just identifiers, using the `identifierSpace` declared by the reconciliation service ([#1953](https://github.com/OpenRefine/OpenRefine/issues/1953))
* References in the Wikidata schema can be copied across statements and items ([#1912](https://github.com/OpenRefine/OpenRefine/issues/1912))
* Items suggested by auto-complete can now be clicked with the middle button, which opens their URL in a new tab ([#1934](https://github.com/OpenRefine/OpenRefine/issues/1934))
* Reconciliation previews are now shown when hovering the candidate (no click is needed). Clicking the candidate opens its page in a new tab. It is possible to disable this feature for matched cells by adding `cell-ui.previewMatchedCells=false` in the preferences. ([#1943](https://github.com/OpenRefine/OpenRefine/issues/1943))

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/wiki/Changes-for-3.2).",6220644
500,False,True,2019-03-01T10:55:49Z,2019-03-01T11:22:18Z,"This is the beta release of OpenRefine 3.2. Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features
* New action to replace smart quotes to their ASCII equivalent ([#1676](https://github.com/OpenRefine/OpenRefine/issues/1676))
* New phonetic clustering methods are available: Beider-Morse ([#926](https://github.com/OpenRefine/OpenRefine/issues/926)) and Daitch-Mokotoff ([#927](https://github.com/OpenRefine/OpenRefine/issues/927))
* The ""Uses values as identifiers"" operation now accepts cells with RDF uris instead of just identifiers, using the `identifierSpace` declared by the reconciliation service ([#1953](https://github.com/OpenRefine/OpenRefine/issues/1953))
* References in the Wikidata schema can be copied across statements and items ([#1912](https://github.com/OpenRefine/OpenRefine/issues/1912))
* Items suggested by auto-complete can now be clicked with the middle button, which opens their URL in a new tab ([#1934](https://github.com/OpenRefine/OpenRefine/issues/1934))
* Reconciliation previews are now shown when hovering the candidate (no click is needed). Clicking the candidate opens its page in a new tab. It is possible to disable this feature for matched cells by adding `cell-ui.previewMatchedCells=false` in the preferences. ([#1943](https://github.com/OpenRefine/OpenRefine/issues/1943))

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/wiki/Changes-for-3.2).",6220644
501,False,False,2018-11-29T01:45:08Z,2018-11-29T02:58:37Z,"This is the final release of OpenRefine 3.1. Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features
* Importing n-triples, ttl, and JSON-LD files is now possible ([#1758](https://github.com/OpenRefine/OpenRefine/issues/1758))
* The `smartSplit` function now supports any string, not just a single character. ([#1761](https://github.com/OpenRefine/OpenRefine/issues/1761))
* A new menu to search and replace was added ([#1742](https://github.com/OpenRefine/OpenRefine/issues/1742))
* A field to specify custom column names was added in the CSV/TSV importer 
* It is now possible to import and export a Wikidata schema in JSON ([#1776](https://github.com/OpenRefine/OpenRefine/issues/1776))
* Strings are now automatically trimmed in Wikidata schemas. The corresponding issues have been removed. ([#1781](https://github.com/OpenRefine/OpenRefine/issues/1781))
* Browser-based autocomplete has been enabled for Wikidata edit summaries. ([#1596](https://github.com/OpenRefine/OpenRefine/issues/1596))
* It is now possible to mark a column of identifiers as reconciled without calling the reconciliation service ([#1778](https://github.com/OpenRefine/OpenRefine/issues/1778))
* The GREL function `parseXml` was added ([#1818](https://github.com/OpenRefine/OpenRefine/issues/1818))
* The way text facets handle non-text values was changed. If you rely on this, make sure you add `.toString()` to the expressions used for text facets in your workflows. ([#1662](https://github.com/OpenRefine/OpenRefine/issues/1662))

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/wiki/Changes-for-3.1).

OpenRefine is funded by the [Google News Initiative](https://newsinitiative.withgoogle.com/).",6220644
502,False,True,2018-11-07T12:46:44Z,2018-11-07T13:51:04Z,"This is the beta release of OpenRefine 3.1. Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features
* Importing n-triples, ttl, and JSON-LD files is now possible ([#1758](https://github.com/OpenRefine/OpenRefine/issues/1758))
* The `smartSplit` function now supports any string, not just a single character ([#1761](https://github.com/OpenRefine/OpenRefine/issues/1761))
* A new menu to search and replace was added ([#1742](https://github.com/OpenRefine/OpenRefine/issues/1742))
* A field to specify custom column names was added in the CSV/TSV importer 
* It is now possible to import and export a Wikidata schema in JSON ([#1776](https://github.com/OpenRefine/OpenRefine/issues/1776))
* Strings are now automatically trimmed in Wikidata schemas. The corresponding issues have been removed. ([#1781](https://github.com/OpenRefine/OpenRefine/issues/1781))
* Browser-based autocomplete has been enabled for Wikidata edit summaries. ([#1596](https://github.com/OpenRefine/OpenRefine/issues/1596))
* It is now possible to mark a column of identifiers as reconciled without calling the reconciliation service. ([#1778](https://github.com/OpenRefine/OpenRefine/issues/1778))

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/wiki/Changes-for-3.1).

OpenRefine is funded by the [Google News Initiative](https://newsinitiative.withgoogle.com/).",6220644
503,False,False,2018-09-16T15:59:49Z,2018-09-16T17:38:57Z,"This is the release of OpenRefine 3.0.  Please **backup your workspace directory** before installing and report any problems that you encounter.

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/issues?q=is%3Aissue+milestone%3A3.0+is%3Aclosed).

OpenRefine is funded by [Google News Initiative](https://newsinitiative.withgoogle.com/)",6220644
504,False,True,2018-07-15T21:22:19Z,2018-07-17T03:05:46Z,"This is the RC release of OpenRefine 3.0.  Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features:
- Wikidata extension
- Data package metadata
- Tag system
- Google drive API 
- OpenRefine Database Import Extension 
- Add coalesce function 
- Implement ""Facet by null"" and ""Facet by empty string"" and add to customized facets menu 
- Feature Request: Export SqlDump 
- Migrate from JRDF to JENA library
- Added option to toggle show/hide null values in cells in data-table 
- Unify the internal date type
- Update OpenRefine logo 
- Set http req headers 
- Add find function
- Some bug fixes

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/issues?q=is%3Aissue+milestone%3A3.0+is%3Aclosed).

OpenRefine is funded by [Google News Initiative](https://newsinitiative.withgoogle.com/)",6220644
505,False,True,2018-05-27T06:03:08Z,2018-05-27T14:20:38Z,"This is the beta release of OpenRefine 3.0.  Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features:
- Wikidata extension
- Data package metadata
- Tag system
- Google drive API 
- OpenRefine Database Import Extension 
- Add coalesce function 
- Implement ""Facet by null"" and ""Facet by empty string"" and add to customized facets menu 
- Feature Request: Export SqlDump 
- Migrate from JRDF to JENA library
- Added option to toggle show/hide null values in cells in data-table 
- Unify the internal date type
- Update OpenRefine logo 
- Set http req headers 
- Add find function
- Some bug fixes

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/issues?q=is%3Aissue+milestone%3A3.0+is%3Aclosed).

OpenRefine is funded by [Google News Initiative](https://newsinitiative.withgoogle.com/)",6220644
506,False,False,2017-11-19T04:03:43Z,2017-11-19T04:14:11Z,"This is the official release of OpenRefine 2.8.  Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features:
- Project metadata support
- Enhancement of the reconciliation API 
- Support split multivalued-cells by regex/special characters 
- Text filter exclude 
- Add free memory detection and Notification to user
- Improved UI for better usability
- New importer for Wikitables
- Some bug fixes

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/issues?utf8=%E2%9C%93&q=milestone%3A2.8%20).

OpenRefine is funded by [Google News Initiative](https://newsinitiative.withgoogle.com/)",6220644
507,False,False,2017-06-18T03:25:02Z,2017-06-18T03:43:53Z,"This is the official release of OpenRefine 2.7.  Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features:
- Wikidata Reconcile (replaced old Freebase Reconcile service) and hosted by Wikimedia Foundation.
- Export Clusters button on Clustering dialog.
- Japanese translation
- Support multiple ""logical and"" and ""logical or"" instead of just 2
- ""Transform All"" support to apply the operations to multiple columns
- Some bug fixes

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/issues?utf8=%E2%9C%93&q=milestone%3A2.7%20).
",6220644
508,False,True,2017-03-03T01:30:54Z,2017-03-03T01:48:59Z,"This is the 2nd beta release of OpenRefine 2.7.  Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features:
- Upgrade the Jython library to 2.7
",6220644
509,False,True,2017-02-11T00:47:17Z,2017-02-16T13:33:16Z,"This is the first beta release of OpenRefine 2.7.  Please **backup your workspace directory** before installing and report any problems that you encounter.

## New features:
- Wikidata Reconcile (replaced old Freebase Reconcile service) and hosted by Wikimedia Foundation.
- Export Clusters button on Clustering dialog.
- Japanese translation

See the full [list of changes](https://github.com/OpenRefine/OpenRefine/issues?utf8=%E2%9C%93&q=milestone%3A2.7%20).
",6220644
510,False,True,2015-10-13T22:48:46Z,2015-10-14T17:05:24Z,"**NOTE:**  Release candidate for OpenRefine v2.6. Hopefully no major changes are required except the final versioning and some minor improvoment. Please file issues if found any! **USE AT YOUR OWN RISK**
",6220644
511,False,True,2015-04-30T03:26:40Z,2015-04-30T03:28:43Z,"**NOTE:** This isn't a real release candidate at this point, but rather a trial build for the development team to check out how many loose ends are left to clean up. Please continue to use the v2.6 beta 1 release for now.  **USE AT YOUR OWN RISK**
",6220644
512,False,True,2013-08-27T15:39:12Z,2013-09-02T19:35:21Z,"This is the first beta release of OpenRefine 2.6.  It is for **testing purposes only** and is **_not_** intended for production work.  Please **backup your workspace directory** before testing and report any problems that you encounter.

**Testing** - _please especially keep an eye out for strings/labels in the UI which are missing or rendered as `undefined`_

## New features:
- shiny new OpenRefine branding
- internationalized UI available in both Italian and English
- a number of small of localization improvements such as support for locale in the toDate() function #729
  (if you'd like to help translating for your language, contact us)
- better data fidelity for import - it's now possible to turn off all automatic conversions 
- improved CSV support, including support for multi-character field separators
- support for the new Freebase v1 APIs released by Google as well as the latest Freebase Suggest 4.3
- better feedback on memory usage and low memory situations when creating projects
- shorter more friendly column names for JSON imports #524 
- sorting of large data sets is orders of magnitude faster #738
- almost one hundred bug fixes including fixes for some of the persistently annoying ones like cross() failures #432 
- more robust project saving and project recovery -- if you have projects in your workspace which have been renamed .project.corrupted, you may be able to recover some of the data if you rename them back to the standard .project extension

A [full list of bugs fixed](https://github.com/OpenRefine/OpenRefine/issues?direction=desc&labels=bug&milestone=1&sort=updated&state=closed) in this release is available. 

## INCOMPATIBLE CHANGE WITH GOOGLE REFINE 2.5:
- data directory has been renamed from ./Google/Refine to ./OpenRefine #777 

If you run both versions, add a property a definition for refine.data_dir using a line like this in the refine.ini for your Google Refine 2.5 installation

`JAVA_OPTIONS=-Drefine.data_dir=/path/to/data/dir`

## MAC OS X Version Requirement

The Mac kit bundles Java 7 which [requires](http://www.java.com/en/download/mac_sysreq-sm.jsp) Mac OS X 10.7.3 (Lion) or later.  The files are compiled for Java 6 compatibility, so it may be possible to run it by hand using Java 6 from Apple's Software Update, but this is unsupported and not recommended.
",6220644
513,False,True,2013-08-15T21:06:31Z,2013-08-15T21:53:27Z,"This is the first wide release of 2.6 is for **testing purposes only** and is **_not_** intended for production work.  Please **backup your workspace directory** before testing and report any problems that you encounter.

New features:
- shiny new OpenRefine branding
- internationalized UI available in both Italian and English
  (if you'd like to help translating for your language, contact us)
- better data fidelity for import - it's now possible to turn off all automatic conversions 
- improved CSV support, including support for multi-character field separators
- support for the new Freebase v1 APIs released by Google as well as the latest Freebase Suggest
- better feedback on memory usage and low memory situations when creating projects
- shorter more friendly column names for JSON imports #524 
- sorting of large data sets is orders of magnitude faster #738
- almost one hundred bug fixes including fixes for some of the persistently annoying ones like cross() failueres #432 

Things to keep an eye out for:
- missing UI strings displayed as ""undefined"" or strings with HTML code in them

INCOMPATIBLE CHANGE WITH GOOGLE REFINE 2.5:
- data directory has been renamed from ./Google/Refine to ./OpenRefine #777 

If you run both versions, add a property a definition for refine.data_dir using a line like this in the refine.ini for your Google Refine 2.5 installation

`JAVA_OPTIONS=-Drefine.data_dir=/path/to/data/dir`

Other changes since alpha1:
- browser window is opened automatically on all platforms #773
- bundled extensions now work on all operating systems #781
- various missing internationalization cleanups #766, #775, #767 
- updated to Freebase Suggest 4.3 #762 
- more robust (hopefully) workspace saving code #528 
- support for multi-character separators in CSV files #658 
- support for locale in toDate() #729 
",6220644
514,False,False,2010-11-10T23:18:41Z,2013-07-24T19:20:43Z,"## Major Changes
- New extension architecture.
- Generalized reconciliation framework that allows plugging in standard reconciliation services.
- Support for QA on data loads into Freebase.

## Features
- New commands:
  - Fill Down
  - Blank Down
  - Transpose Cells in Columns into Rows
  - Transpose Cells in Rows into Columns (Issue #82)
  - Move Column to Beginning, Move Column to End, Move Column Left, Move Column Right, Reorder Columns
  - Add Column by Fetching URLs
  - Recon commands:
  - Clear recon data for all matching rows
  - Clear recon data for one cell
  - Clear recon data for similar cells
  - Copy recon judgments across columns
- Google Refine Expression Language (GREL):
  - JSON support
  - New functions: smartSplit, escape, parseJson, hasField, uniques
  - New controls: forEachIndex, forRange, filter
  - New parameters:
    - preserveAllTokens on split function
  - Regexp groups capturing GEL function
- Importers
  - New: Json importer
  - CSV and TSV importers: added support for ignoring quotation marks
  - Added support for creating a project by pointing to a data file URL.
- Text facet's choice count limit is now configurable through preference page
- Select All and Unselect All buttons in History Extract dialog
- Schema aligment skeleton: support for multiple cells per cell-as nodes, and for conditional links

## Bug Fixes

TSV/CSV exporter bug: Gridworks crashed when there were empty cells.
 Issue #29 : Delievered ""Collapse whitespace"" transformation does not work
 Issue #69 : ControlFunctionRegistry? now correctly registers Chomp expression as ""chomp"" key.
 Issue #66 : Records not excluded with inverted text facet
 Issue #86 : Parse cells after splitting columns
 Issue #99 : Diff for dates fails with ""unknown error"" always
 Issue #110 : Import of single column text file with Postal Codes shows only 1 row with lots of � chars (?)
 Issue #113 : Export filtered rows as tsv or csv fails; html and excel OK
 Issue #116 : CSV/TSV export data includes blank fields for deleted columns
 Issue #121 : Importing attached file strips backslashes
 Issue #122 : Exporting to Excel on attached project raises server exception
 Issue #126 : Large integers formatted in scientific notation in formulas
 Issue #135 : Hangs when setting cell value to large JSON string
 Issue #138 : Numbers should be right-justified
 Issue #146 : In ""Cluster and Edit Column"", clicking on entry value to set ""Merge?"" checkbox does not reflect the final value of operation

List of all [changes](https://github.com/OpenRefine/OpenRefine/issues?milestone=5&state=closed)
",6220644
515,False,False,2011-07-10T22:44:00Z,2013-07-24T19:12:51Z,"Google Refine 2.1 is a maintenance release primarily focused on bug fixes.

## New Features
- JSoup-based HTML parsing ( issue 220  &  issue 338 ) - new functions: parseHtml, select, htmlAttr, htmlText, innerHtml, ownText
  New codec & clustering options: Metaphone3 (American English) and Cologne Phonetic (German -  issue 399 )
- Google Fusion Table import support
- new facet for exact duplicates ( issue 398 )
- save favorite (starred) transforms ( issue 222 )
- new math functions ( issue 224 ) - acos, asin, atan, atan2, cos, cosh, sin, sinh, tan, tanh, even, odd, abs, fact, factn, combin, degrees, radian, gcd (greatest common denominator), lcm (least common mulitple), multinomial, quotient
- new operator: modulo (%)
- new constant: PI
- update to Apache POI 3.7 (Excel library)
- update to Apache Commons Codec 1.5

## Bug Fixes
- issue 415  - Operand evaluation order wrong for + and - operators
- issue 404  - Character set incorrectly detected during project create
- issue 401  - Export error reporting masks real error
- issue 374  - INC function doesn't work for dates
- issue 351  - unable to export to Excel for projects with more than 256 columns
- issue 334  - Fusion Table CSV import causes NPE
- issue 294  - Export date value in CSV/TSV
- issue 263  - & character parsed incorrectly in XML import
- issue 358  - attempts to compare two values with all stop words returns NaN
- issue 276  - Character encoding issue with project create
- issue 228  - partial fix?
- issue 202  - sort text with accents
- issue 197  - date wraparound at year boundary
- issue 196  - removing columns causes error and disables undo
- issue 185  - Same reconciliation candidate for multiple cells causes problems
- issue 184  - date.toString() doesn't work
- issue 107  - non-ASCII characters don't display correctly during reconciliation
- issue 61  - multi-line text literals don't work in XML importer

Full list of [changes](https://github.com/OpenRefine/OpenRefine/issues?milestone=6&state=closed)
",6220644
516,False,True,2013-07-31T04:52:10Z,2013-07-30T15:08:58Z,"This is the first alpha release of OpenRefine 2.6 with the new branding.  This kit is primarily for developers testing.  Use AT YOUR OWN RISK and be sure to BACK UP YOUR DATA before testing it.
",6220644
517,False,False,2011-12-11T22:07:36Z,2013-07-24T18:59:09Z,"# Google Refine 2.5

Google Refine 2.5 was released December 2011 and was the last version released under the Google branding.  It features a completely revamped user interface for project creation.

**[Scroll down for kits]**

## New Features
- Completely new user interface for project creation, including:
  - Live preview with interactive settings before creating project 
  - Fixed-width importer that allows for specifying column widths by clicking (Issue #85)
  - XML and JSON importers that allow for interactive selection of elements to import
  - Direct access to Google Spreadsheets (issue #278) and Google Fusion Tables (Issue #279)
  - Import and export to private Google Spreadsheets & Fusion Tables for logged-in users
  - Import using results of Google spreadsheet visualisation API query (Issue #375)
  - Sheet selection for import from Excel (Issue #280) & Google Spreadsheets (Issue #281)
  - Support for directly selecting files within zip/archive file without unpacking them first (Issue #131)
  - Support for creating a project using contents of the paste buffer (Issue #84)
  - Better progress feedback during upload & processing (Issue #179)
- Custom tabular exporter that allows for selecting and configuring columns to export, and direct  upload to Google Spreadsheets and Fusion Tables
- Support for IE8 and IE9 through Google Chrome Frame
- New command ""Key/value Columnize"" (see explanation)
- New importer for PC-Axis file format.

## Enhancements

 #31 : Maximum number of facet values should be configurable.
 #38 : Wishlist? Fix the table header so that it's always visible when scrolling a long page
 #97 : Exporting CSV should allow for optional columns
 #447 : Extend toTitlecase() function with support for custom delimiters
- Operation ""Transpose columns into rows"" now supports an additional mode of generating 2 key and value columns (rather than generating just one combined column); it also has an option for filling in other columns.
- reinterpret() now supports optionally specifying a source encoding to be used instead of the project encoding - reinterpret(""target encoding"", ""source encoding"")

## Bug Fixes

 Issue #149 : rows button stays strike-through when clicking on it
 Issue #349 : Clustering not finding duplicates when facet is showing groupings
 Issue #394 : Add a reset button to Text filter
 Issue #419 : Values with Characters like é split across several lines
 Issue #424 : Duplicate column names don't allow user to recover
 Issue #426 : filter with custom facet adds zero lines choice
 Issue #428 : Excel import sometimes drops last row of data
 Issue #433 : Usability: use HTML label (e.g., for checkboxes)
 Issue #440 : Fetch URLs aborts while saving/loading/computing facets
 Issue #441 : onError - ""keep-original"" / ""store-blank"" working oddly for value.toDate()
 Issue #442 : Two column transforms to date on the same column turns the cells blank
 Issue #449 : Uncaught exception from Excel importer
 issue #502  - Fetch URLs does not return a correct HTTP response

## Miscellaneous

 Issue #233 : 404 Error upon Launch
 Issue #362 : Augmentation screencast (#3) is now missing/private
 Issue #410 : Convert line-endings to DOS format
 Issue #435 : refine sh script only checks for java 1.6, not > 1.6
 Issue #444 : Patch for /trunk/main/webapp/modules/core/scripts/dialogs/custom-tabular-exporter-dialog.html
 Issue #445 : Patch for /trunk/main/webapp/modules/core/scripts/dialogs/custom-tabular-exporter-dialog.html
 Issue #453 : Patch for /trunk/main/tests/server/src/com/google/refine/tests/importers/JsonImporterTests?.java
",6220644
518,False,False,2017-07-23T13:11:04Z,2017-07-23T14:44:02Z,"like [v0.8.2](https://github.com/spark-notebook/spark-notebook/releases/tag/v0.8.2), just with a fix for Docker and Debian builds",23715842
519,False,False,2017-07-04T09:46:45Z,2017-06-28T09:24:15Z,"
> Note: for `Spark < 2.0`, see [v0.7.0-pre2](https://github.com/andypetrella/spark-notebook/releases/tag/v0.7.0-pre2)

> This is (likely) the last release which supports `Scala 2.10`.

**Various fixes and improvements**, among others:
  - redesigned UI to be more user-friendly (minimalistic UX, cell context menu, improve sidebar)
  - better `Scala 2.11` support (code autocompletion; fixed kernel failures; improved `customDeps` fetching)
  - Use `coursier` for faster deps resolving during the build
  - code cleanup and other stability fixes
  - ease usage of Mesos in Spark 2.1: it now includes the `spark-mesos` lib by default (added `-Dwith.mesos=true` build option)

**New features:**
 - SBT project generation from a notebook (experimental)
 - Notebook edit versioning, and storage on Git (experimental)
 - Viewer-only mode - a build option which makes notebooks not editable

**Removed:**
- removed `:dp, :cp, :local-repo, :remote-repo` commands (use `Edit -> Notebook metadata` instead)
- removed old plotting libs: `Rickshawts` , `TauChart` , `LinePlot` , `Bokeh` (all superseeded by Plotly)
",23715842
520,False,False,2016-10-31T13:43:59Z,2016-10-31T14:09:05Z,"**THIS IS FOR SPARK PRE 2**

Based on  [v0.7.0](https://github.com/andypetrella/spark-notebook/releases/tag/v0.7.0), it uses its fixes, optimization and most new features unless spark 2 specific (`SparkSession` for instance).
",23715842
521,False,False,2016-10-31T13:39:33Z,2016-10-31T14:06:06Z,"> Note: for `Spark < 2.0`, see [v0.7.0-pre2](https://github.com/andypetrella/spark-notebook/releases/tag/v0.7.0-pre2)
- Add spark 2 support
- Many fixes for better stability (more lenient for user input, avoid kernels crash)
- Lot of optimization for the viz, also replaced most Dimple with C3.
- Introducing Plotly.js wrappers
- Better debian support
- Greater download as Markdown as zip with charts rendered as PNG referred in a images folder
- Better doc available at all time in the `doc` folder
- Cell dirtiness detection based on variables dependency graph
- New default port to 9001 to avoid conflict with HDFS
- Removed Wisp and Highcharts (in favor of plotly.js)
- Code cleanup
",23715842
522,False,False,2016-10-05T11:31:13Z,2016-10-06T06:02:42Z,"for `spark <=1.6`, use this release or the [stale/spark-1.6-and-older](https://github.com/andypetrella/spark-notebook/tree/stale/spark-1.6-and-older) branch
",23715842
523,False,False,2016-03-11T07:33:21Z,2016-03-11T07:53:04Z,"Aside the stabilization with the all the bugs fixed, new features are:
- improvement of the PivotChart
- improvement of completion with type args and more
- better sampling for automatic/default plots
- added tests and travis
- spark jobs are tracked by cells, cells have now ids
- hardened the observables init
- improved scala 2.11 support
- improve Flow widget, added Custom box taking scala code directly as logic
- job for a cell can be cancelled
- read_only mode
- notebooks are now sync wrt cell output (including reactive), but not cell add/dels and cell'content changes
- panels have landed: 
  - general spark monitor
  - defined variables and types
  - chat room
- cleaner docker build
- added taucharts viz lib support
- added `-Dguava.version` to support integration tools like cassandra connector from 1.5+

Again, we'd like to thank the community for their work and their support!
YOU'RE ALL AWESOME!
",23715842
524,False,False,2015-12-15T18:42:41Z,2015-12-15T18:44:46Z,"- build information in the UI
- better https support for web socket connections
- use the presentation compiler for completion
- fix restart kernel
- log the server/spark forwarded to the browser's console
- chart are plotting 25 entries by default (extendable using maxPoints) but this cap is changeable using a reactive HTML input
- spark jobs' monitor/progress bar is now always live (still in progress, needs some UI hardening and enhancements)
- graph plots are reactive
- table chart using dynatable
- HTTP proxy support for dependency managements
- **generic spark version** support in a best effort way for any new spark versions (including nightly builds)
- nightly build repos can be **detected** and injected with the `spark.resolver.search` jvm property set to `true`
- presentation mode added, including UI tuning via 
- **variables environment** support in metadata: loca repo, vm arguments and spark configuration
- Better `DataFrame` viz support
- `PivotChart` tuning, including viz and state managment
- support `%%` in the deps definition to take care of the used scala version
- support the **current spark** version in the deps definition using `_` like `""org.apache.spark %% spark-streaming-kafka % _""`
- added `user_custom.css` for users' extensions or redefinings of the CSS
- report the **Spark UI** link on the left hand side of the notebook
- URL Query parameter `action=recompute_now` to automatically recompute everything at loading time
- default logging less verbose
- added CSV downloader from DataFrame capability (directly in HDFS using spark-csv)!
- **new C3** based widgets
- **new GeoChart** widget -- support for JTS geometries, GeoJSON and String
- **new Flow** for visual flow management using boxes and arrows (needs hardening and improvements)
- UI cleaning (menubars, ...)
- kernel auto starts can be disabled (useful for view only mode like presentation): `autostartOnNotebookOpen` in conf
- UI shows when kernel isn't ready
- died kernel are now reported throughout the UI too
- added `manager.notebooks.override` to override and merge default values with metadata provided before starting a notebook
- new examples notebooks: 
  - Machine Learning 
  - C3
  - Geospatial
  - Flow
- more documentation (not enough...)

Special thanks to @vidma for his amazing work on many new and killing features! :clap: :clap: :clap: 
",23715842
525,False,False,2015-09-10T23:46:22Z,2015-09-11T00:04:09Z,"- ADD_JARS support (add jars to context)
- NB metadata saved at ok
- fix 2.11 :dp and :cp
- hide tachyon ui
- YARN_CONF_DIR support
- customArgs in metadata (application.conf, ...) → adding JVM arguments to spawned process for a notebook
- spark 1.5.0 support
- tachyon 0.7.1 integration for spark 1.5.0
- added reactive slider + example in `misc`
- old X and Y renaming of tuples' field name discarded, back to _1, _2
- example of cassandra connector (@maasg)
- reactive `widgets.PivotChart` support for simpler analysis of scala data
- fixes fixes fixes
",23715842
526,False,False,2015-07-23T01:58:14Z,2015-07-23T02:00:10Z,"- a loooooot of fixes \o/
- a loooooot of documentation including on how to install and run the spark notebook on distros and clusters (yarn, mapr, EMR, ...)
- support for HADOOP_CONF_DIR and EXTRA_CLASSPATH to include spark cluster specific classpath entries, like hadoop conf dir, but also lzo jar and 
  so on. This updates both the classpath of the notebook server and the notebooks processes.
- the custom repos specified in the metadata or application.conf have an higher priority
- support for spark 1.4.1
- mesos is added to the docker distro
- code is now run asynchronously, allowing the introduction of the **flame button**, that can cancel all running spark jobs
- added many new notebooks, included @Data-Fellas ML and ADAM examples or anomaly detection by @radek1st 
- LOGO :-D
- added **:markdown**, **:javascript**, **:jpeg**, **:png**, **:latex**, **:svg**, **:pdf**, **:html**, **:plain**, **:pdf** that support **interpolation** (using scala variables)
- clusters can be deleted from the ui
- spark packages repo is available by default
- spark package format is now supported : `groupId:artifactId:version`
- added `with.parquet` modifier to include parquet deps
- `spark.app.name` uses the name of the notebook by default (easier to track in clusters)
- **Dynamic table** renderer for `DataFrame`
- Added a users sections in the README
- Tachyon can be disabled by setting `manager.tachyon.enabled` to `false`
- support for printing from the browser (**CTRL+P**)
- added `:ldp` for **local** dependency definitions (so not added to spark context)
- Graph (nodes-edges) can be plotted easily using the `Node` and `Edge` types → see `viz/Graph Plots.snb`
- Geo data viz added using latlon data → see `viz/Geo Data (Map).snb`
- Enhanced the twitter stream example to show tweets in a map
- Enhanced the **WISP** examples including Histogram, BoxPot. Wisp plots can now be build using the lower api for Highchart
- Adding the commons lib in the spark context to enable extended viz using spark jobs
",23715842
527,False,False,2015-05-16T21:16:38Z,2015-05-16T21:24:00Z,"# Main

Besides quite some fixes, this version brings two major features:

## Session

When opening a notebook, a session is created allowing anybody to join it. 

But mostly, the user can now close the tab and get back to the analysis later by reopening the notebook.
Very helpful, f.i., when long processes are launched.

## Tachyon

The tachyon support has been integrated with several functionalities:
- connecting to a provided (configuration) tachyon cluster
- starting a tachyon local embed cluster if none is available in the config 
- a small-ish UI-ish on the right hand side of the notebook panel that allows the user to browse the content hence, the persisted computations or even simply files

In the first and second points, all notebooks will be automatically configured (read the `SparkContext`) to use the available tachyon cluster without requiring any action from the user

# Others

There are other stuffs that are worth mentioning:
- the notebooks directory by default is now under the root folder anymore
- the parquet deps have been discarded which could have been a pain with previous releases
- the logs are now per session/notebook, so it's now even easier to track the job
- the background logger (the yellow box on the left) has been removed since it didn't brought much info, but was interacting badly in some cases with the closure serializer...
- support for `https`
- more information is provided when errors occur, specially when the code is not complete (missing parenthesis)
- execution time is now included in each result block
- scala 2.10 now uses SBT to download deps, scala 2.11 is still using aether at the moment
- `HADOOP_CONF_DIR` has to be used to pass the hadoop conf dir when using Yarn
",23715842
528,False,False,2015-04-17T17:48:50Z,2015-04-17T17:50:25Z,"This minor patches v0.4.1 that broke scala 2.11 due to usage of sbt.
",23715842
529,False,False,2015-04-13T14:45:04Z,2015-04-14T19:53:49Z,"- fix click on logo goes to `/`
- fix launching `spark-notebook` from `bin` folder
- fix `:dp` and  `:cp` for spark 1.3 and scala 2.10
- fix rendering of list of string ouput
- output stream toggle (shortcut `t`)
",23715842
530,False,False,2015-03-30T00:39:12Z,2015-03-30T00:40:55Z,"- Adds the **auto plotting** for sequence data returned in a block (using reflection)
- The auto plotting components are also available as such (`Chart`) and provide a simple way to present data whatever the type is. Chek also the ``
- inputs can be hidden using the keystroke `i` (like `o` for the output) and according menu entries have been added
- Support for spark 1.3.0 → becomes the **default** version
- Wizard for the ""cluster"" definition, which has to be renamed ""configuration template""
- repos, deps and import are now a list of string in the metadata
- some fixes here and there.

Aknowledgments:
- @axlpado for the plots and reflection
- @virtualirfan for the ideas, time,... and the yarn support
- @minyk for the yarn support 
- @marcinjurek for the mesos support
- @lucaventurini for the yarn support
- @huitseeker for the kind words :-D
- @pkerpedjiev for the docker support (on mac for instance)
- @xtordoir for everything you did
- @mandubian for the PR
- all 245 stargazers so far!
",23715842
531,False,False,2015-02-28T15:31:06Z,2015-02-28T17:33:59Z,"- notebook can now declare metadata for deps, repos, and specially **cluster**
- spark 1.2.1 support has been added
- scala 2.11 support added
- notebooks can be arranged in folders
- a logging panel has been added to display background tasks
- duplicate, rename and delete have been fixed

WIP and KI
- creation of a folder misses some UI to name it
- move notebooks is not possible yet
- cluster profiles (notebook metadata) aren't reusable easily
",23715842
532,False,False,2015-01-10T01:45:58Z,2015-01-10T10:50:29Z,"This version cleans further the subprocesses for the REPL, that is enables remote akka in order to deploy everything unrelated to the web app to it.

The classloading and serialization problems are now gone when running the spark notebook in `play run`.

Check out the S3 repo or docker repo for available releases:
- [S3](https://s3.eu-central-1.amazonaws.com/spark-notebook/)
- [docker](https://registry.hub.docker.com/u/andypetrella/spark-notebook/tags/manage/#)
",23715842
533,False,False,2015-01-05T06:52:30Z,2015-01-05T07:01:42Z,"This new version integrates new distributions, for different hadoop versions:
- 1.0.4 (default)
- 2.0.0-cdh4.2.0 (helpful when using ec2 scripts with hadoop version 2 enabled)

So the version concatenates (sep by `_`)
- the notebook version
- the spark version
- the hadoop version

New features are:
- display datatables for sequences of type having a Codec defined for.
- `:sh` scope to execute simple shell commands

Releases are available:
- on S3: https://s3.eu-central-1.amazonaws.com/spark-notebook/
- on Docker: andypetrella/spark-notebook
",23715842
534,False,True,2014-12-27T00:59:05Z,2014-12-27T01:33:35Z,"Fixes #52 

Fixes the reload (CTRL+R, F5, ...) of notebooks containing space in the name.

The zip file can be found [here](https://s3.eu-central-1.amazonaws.com/spark-notebook/spark-notebook-0.1.1.zip).

Or the docker image can be used as well, check [this](https://registry.hub.docker.com/u/andypetrella/spark-notebook).
",23715842
535,False,True,2014-12-23T01:18:48Z,2014-12-23T06:07:06Z,"This version is the very first one allowing binary distribution, thanks to play framework!

Check the README.md for information about its features.

## Use

```
wget https://s3.eu-central-1.amazonaws.com/spark-notebook/spark-notebook-0.1.zip
unzip spark-notebook-0.1.zip
cd spark-notebook-0.1
./bin.spark-notebook
```

The default configuration will start the server on `http://localhost:9000`
",23715842
536,False,False,2018-01-22T06:01:10Z,2018-01-22T06:03:37Z,"+ Added automatic posterior approximations in variational inference (#775).
+ Added use of `tf.GraphKeys.REGULARIZATION_LOSSES` to variational inference (#813).
+ Added multinomial classification metrics (#743).
+ Added utility function to assess conditional independence (#791).
+ Added custom metrics in evaluate.py (#809).
+ Minor bug fixes, including automatic transformations (#808); ratio inside `ed.MetropolisHastings` (#806).

## Acknowledgements

+ Thanks go to Baris Kayalibay (@bkayalibay), Christopher Lovell (@christopherlovell), David Moore (@davmre), Kris Sankaran (@krisrs1128), Manuel Haussmann (@manuelhaussmann), Matt Hoffman (@matthewdhoffman), Siddharth Agrawal (@siddharth-agrawal), William Wolf (@cavaunpeu), @gfeldman.

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.",51468412
537,False,False,2017-09-28T02:33:10Z,2017-09-28T02:34:50Z,"This version release comes with several new features, alongside a significant push for better documentation, examples, and unit testing.

+ `ed.KLqp`'s score function gradient now does more intelligent (automatic) Rao-Blackwellization for variance reduction.
+ Automated transformations are enabled for all inference algorithms that benefit from it [[tutorial]](http://edwardlib.org/tutorials/automated-transformations).
+ Added Wake-Sleep algorithm ([`ed.WakeSleep`](http://edwardlib.org/api/ed/WakeSleep)).
+ Many minor bug fixes.

## Examples

+ All Edward examples now rely on the [Observations](https://github.com/edwardlib/observations) library for data loading (no ""official"" public release yet; still in alpha).
+ Added LSTM language model for text8. ([`examples/lstm.py`](https://github.com/blei-lab/edward/blob/2402498511588d61c82c6c1648b63252da85ff8b/examples/lstm.py))
+ Added deep exponential family for modeling topics in NIPS articles. ([`examples/deep_exponential_family.py`](https://github.com/blei-lab/edward/blob/2402498511588d61c82c6c1648b63252da85ff8b/examples/deep_exponential_family.py))
+ Added sigmoid belief network for Caltech-101 silhouettes. ([`examples/sigmoid_belief_network.py`](https://github.com/blei-lab/edward/blob/2402498511588d61c82c6c1648b63252da85ff8b/examples/sigmoid_belief_network.py))
+ Added stochastic blockmodel on Karate club. ([`examples/stochastic_block_model.py`](https://github.com/blei-lab/edward/blob/2402498511588d61c82c6c1648b63252da85ff8b/examples/stochastic_block_model.py))
+ Added Cox process on synthetic spatial data. ([`examples/cox_process.py`](https://github.com/blei-lab/edward/blob/2402498511588d61c82c6c1648b63252da85ff8b/examples/cox_process.py))

## Documentation & Testing

+ Sealed all undocumented functions and modules in Edward.
+ Parser and BibTeX to auto-generate API docs.
+ Added unit testing to (most) all Jupyter notebooks.

## Acknowledgements

+ Thanks go to Matthew Feickert (@matthewfeickert), Alp Kucukelbir (@akucukelbir), Romain Lopez (@romain-lopez), Emile Mathieu (@emilemathieu), Stephen Ra (@stephenra), Kashif Rasul (@kashif), Philippe Rémy (@philipperemy), Charles Shenton (@cshenton), Yuto Yamaguchi (@yamaguchiyuto), @evahlis, @samnolen, @seiyab.

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.",51468412
538,False,False,2017-06-16T07:41:31Z,2017-06-16T07:46:46Z,"+ Edward is updated to require a TensorFlow version of at least 1.2.0rc0.
+ Miscellaneous bug fixes and revisions.

## Acknowledgements

+ Thanks go to Joshua Engelman (@jengelman), Matt Hoffman (@matthewdhoffman), Kashif Rasul (@kashif).

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.",51468412
539,False,False,2017-05-30T16:47:48Z,2017-05-30T16:55:52Z,"+ More TensorBoard support, including default summaries. See the [tutorial](http://edwardlib.org/tutorials/tensorboard) (#598, #654, #653).
+ A [batch training tutorial](http://edwardlib.org/tutorials/batch-training) is added.
+ Improved training of Wasserstein GANs via penalty (#626).
+ Fixed error in sampling for `DirichletProcess` (#652).
+ Miscellaneous bug fixes, documentation, and speed ups.

## Acknowledgements

+ Thanks go to Janek Berger (@janekberger), Ian Dewancker (@iandewancker) Patrick Foley (@patrickeganfoley), Nitish Joshi (@nitishjoshi25), Akshay Khatri (@akshaykhatri639), Sean Kruzel (@closedLoop), Fritz Obermeyer (@fritzo), Lyndon Ollar (@lbollar), Olivier Verdier (@olivierverdier), @KonstantinLukaschenko, @meta-inf.

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.",51468412
540,False,False,2017-04-27T09:02:03Z,2017-04-30T10:21:58Z,+ Fixed error in 1.3.0 when importing conjugacy submodule.,51468412
541,False,False,2017-04-27T04:55:01Z,2017-04-27T04:58:55Z,"Edward requires a TensorFlow version of at least 1.1.0rc0. This includes several breaking API changes:
+ All Edward random variables use English keyword arguments instead of Greek.  For example, `Normal(loc=0.0, scale=1.0)` replaces the older syntax of `Normal(mu=0.0, sigma=1.0)`.
+ `MultivariateNormalCholesky` is renamed to `MultivariateNormalTriL`.
+ `MultivariateNormalFull` is removed.
+ `rv.get_batch_shape()` is renamed to `rv.batch_shape`.
+ `rv.get_event_shape()` is renamed to `rv.event_shape`.

## Model

+ Random variables accept an optional `sample_shape` argument. This lets its associated tensor to represent more than a single sample (#591).
+ Added a `ParamMixture` random variable. It is a mixture of random variables where each component has the same distribution (#592).
+ `DirichletProcess` has persistent states across calls to `sample()` (#565, #575, #583).

## Inference

+ Added conjugacy & symbolic algebra. This includes a `ed.complete_conditional` function (#588, #605, #613). See [a Beta-Bernoulli](https://github.com/blei-lab/edward/blob/ec45bad40312683df46ead36cd6076b02fb887cf/examples/beta_bernoulli_conjugate.py) example.
+ Added Gibbs sampling (#607). See the [unsupervised learning tutorial](http://edwardlib.org/tutorials/unsupervised) for a demo.
+ Added `BiGANInference` for adversarial feature learning (#597).
+ `Inference`, `MonteCarlo`, `VariationalInference` are abstract classes, preventing instantiation (#582).

## Miscellaneous

+ A more informative message appears if the TensorFlow version is not supported (#572).
+ Added a `shape` property to random variables. It is the same as `get_shape()`.
+ Added `collections` argument  to random variables(#609).
+ Added `ed.get_blanket` to get Markov blanket of a random variable (#590).
+ `ed.get_dims` and `ed.multivariate_rbf` utility functions are removed.
+ Miscellaneous bug fixes and speed ups (e.g., #567, #596, #616).

## Acknowledgements

+ Thanks go to Robert DiPietro (@rdipietro), Alex Lewandowski (@AlexLewandowski), Konstantin Lukaschenko (@KonstantinLukaschenko) Matt Hoffman (@matthewdhoffman), Jan-Matthis Lückmann (@jan-matthis), Shubhanshu Mishra (@napsternxg), Lyndon Ollar (@lbollar), John Reid (@johnreid), @Phdntom.

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.",51468412
542,False,False,2017-03-20T05:14:19Z,2017-03-20T05:16:37Z,"+ Added DirichletProcess random variable (#555)
+ Added progress bar for inference (#546).
+ Improved type support and error messages (#561, #563).
+ Miscellaneous bug fixes.

## Documentation

+ Added Edward Forum (https://discourse.edwardlib.org)
+ Added Jupyter notebook for all tutorials (#520).
+ Added tutorial on linear mixed effects models (#539).
+ Added example of probabilistic matrix factorization (#557).
+ Improved API styling and reference page (#536, #548, #549).
+ Updated website sidebar, including a community page (#533, #551).

## Acknowledgements
+ Thanks go to Mayank Agrawal (@timshell), Siddharth Agrawal (@siddharth-agrawal), Lyndon Ollar (@lbollar), Christopher Prohm (@chmp), Maja Rudolph (@mariru).

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.",51468412
543,False,False,2017-03-08T12:05:21Z,2017-03-08T12:07:19Z,"+ Version release in sync with the published paper version, ""[Deep Probabilistic Programming](https://arxiv.org/abs/1701.03757)"". A companion webpage is available [here](http://edwardlib.org/iclr2017) (#510).

## Models
+ All support is removed for model wrappers (#514, #517).
+ Direct fetching (`sess.run()` and `eval()`) is enabled for `RandomVariable` (#503).
+ Index, iterator, and boolean operators are overloaded for `RandomVariable` (#515).

## Inference
+ Variational inference is added for implicit probabilistic models (#491).
+ Laplace approximation uses multivariate normal approximating families (#506).
+ Removed need for manually specifying Keras session during inference (#490).
+ Recursive graphs are properly handled during inference (#500).

## Documentation & Examples
+ Probabilistic PCA tutorial is added (#499).
+ Dirichlet process with base distribution example is added (#508).
+ Bayesian logistic regression example is added (#509).

## Miscellanea
+ Dockerfile is added (#494).
+ Replace some utility functions with TensorFlow's (#504, #507).
+ A number of miscellaneous revisions and improvements (e.g., #422, #493, #495).

## Acknowledgements
- Thanks go to Mayank Agrawal (@timshell), Paweł Biernat (@pwl), Tom Diethe (@tdiethe), Christopher Prohm (@chmp), Maja Rudolph (@mariru), @SnowMasaya.

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.",51468412
544,False,False,2017-02-28T16:08:49Z,2017-02-28T16:10:31Z,"## Models
- Operators are overloaded for `RandomVariable`. For example, this enables `x + y` (#445).
- Keras' neural net layers can now be applied directly to `RandomVariable` (#483).

## Inference
- Generative adversarial networks are implemented, available as `GANInference`. There's a [tutorial](http://edwardlib.org/tutorials/gan) (#310).
- Wasserstein GANs are implemented, available as `WGANInference` (#448).
- Several integration tests are implemented (#487).
- The scale factor argument for `VariationalInference` is generalized to be a tensor (#467).
- `Inference` can now work with `tf.Tensor` latent variables and observed variables (#488).

## Criticism
- A number of miscellaneous improvements are made to `ed.evaluate` and `ed.ppc`. This includes support for checking implicit models and proper Monte Carlo estimates for the posterior predictive density (#485).

## Documentation & Examples
- [Edward tutorials](http://edwardlib.org/tutorials/) are reorganized in the style of a flattened list (#455).
- Mixture density network tutorial is updated to use native modeling language (#459).
- Mixed effects model examples are added (#461).
- Dirichlet-Categorical example is added (#466).
- Inverse Gamma-Normal example is added (#475).
- Minor fixes have been made to documentation (#437, #438, #440, #441, #454).
- Minor fixes have been made to examples (#434).

## Miscellanea
- To support both `tensorflow` and `tensorflow-gpu`, TensorFlow is no longer an explicit dependency (#482).
- The `ed.tile` utility function is removed (#484).
- Minor fixes have been made in the code base (#433, #479, #486).

## Acknowledgements
- Thanks go to Janek Berger (@janekberger), Nick Foti (@nfoti), Patrick Foley (@patrickeganfoley), Alp Kucukelbir (@akucukelbir), Alberto Quirós (@bertini36), Ramakrishna Vedantam (@vrama91), Robert Winslow (@rw).

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.
",51468412
545,False,False,2017-01-30T16:02:01Z,2017-01-30T16:06:20Z,"- Edward is compatible with [TensorFlow 1.0](https://www.tensorflow.org/versions/r1.0/). This provides significantly more distribution support. In addition, Edward now requires TensorFlow 1.0.0-alpha or above (#374, #426).

## Inference
- Stochastic gradient Hamiltonian Monte Carlo is implemented (#415).
- Leapfrog calculation is streamlined in HMC, providing speedups in the algorithm (#414).
- Inference now accepts `int` and `float` data types (#421).
- Order mismatch of latent variables during MCMC updates is fixed (#413).

## Documentation & Examples
- Rasch model example is added (#410).
- Collapsed mixture model example is added (#350).
- Importance weighted variational inference example is updated to use native modeling language.
- Lots of minor improvements to code and documentation (e.g., #409, #418).

## Acknowledgements
- Thanks go to Gökçen Eraslan (@gokceneraslan), Jeremy Kerfs (@jkerfs), Matt Hoffman (@matthewdhoffman), Nick Foti (@nfoti), Daniel Wadden (@dwadden), Shijie Wu (@shijie-wu).

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.
",51468412
546,False,False,2017-01-16T12:38:59Z,2017-01-16T12:59:31Z,"- Version released in sync with release of the preprint, ""[Deep Probabilistic Programming](https://arxiv.org/abs/1701.03757)"".

## Documentation
- Website documentation and API is improved (#381, #382, #383).
- [Gitter channel](https://gitter.im/blei-lab/edward) is added (#400).
- Added docstrings to random variables (#394).

## Miscellaneous
- `copy` is disabled for Queue operations (#384).
- All `VariationalInference` methods must use build_loss_and_gradients (#385).
- Logging is improved for `VariationalInference` (#337).
- Fixed logging issue during inference (#391).
- Fixed `copy` function to work with lists of `RandomVariable` (#401).
- Fixed bug with Theano `NameError` during inference (#395).

## Acknowledgements
- Thanks go to Gilles Boulianne (@bouliagi), Nick Foti (@nfoti), Jeremy Kerfs (@jkerfs), Alp Kucukelbir (@akucukelbir), John Pearson (@jmxpearson), and @redst4r.

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.
",51468412
547,False,False,2016-12-13T06:22:30Z,2016-12-13T06:24:34Z,"- TensorFlow v0.12.0rc0 and v0.12.0rc1 broke compatibility with Edward (see #315 for more details). For now, users are recommended to use v0.11.0.
- A bug with `KLqp` using the score function gradient estimator is fixed (#373).
",51468412
548,False,False,2016-11-16T03:21:01Z,2016-11-16T03:25:43Z,"## Models
- `RandomVariable`s now accept an optional `value` argument, enabling use of random variables that don't currently have sampling such as `Poisson` (#326).
- Documentation on model compositionality is added. [[Webpage]](http://edwardlib.org/api/model-compositionality)

## Inference
- Inference compositionality is added, enabling algorithms such as Expectation-Maximization and message passing (#330). [[Webpage]](http://edwardlib.org/api/inference-compositionality)
- Data subsampling is added, enabling proper local and global variable scaling for stochastic optimization (#327). [[Webpage]](http://edwardlib.org/api/inference-data-subsampling)
- Documentation on inference classes is added. [[Webpage]](http://edwardlib.org/api/inference-compositionality)
- `VariationalInference` has new defaults for a TensorFlow variable list as argument (#336).
- Type and shape checking is improved during `__init__` of `Inference`.

## Miscellaneous
- Fixed an issue where a new Div node is created every Monte Carlo update (#318).
- Travis build is now functioning properly (#324).
- Coveralls is now functioning properly (#342).
- `tf.placeholder` can now be used instead of `ed.placeholder`.
- Website tutorials, documentation, and API are generally more polished.
- Fixed an issue where computation was incorrectly shared among inferences (#348).
- `scipy` is now an optional rather than mandatory dependency (#344). 

## Deprecated Features

**NOTE**: Several features in Edward are now deprecated (#344):
- model wrappers, including `PythonModel`, `PyMC3Model`, and `StanModel`—in favor of Edward's native language;
- the `edward.stats` module—in favor of random variables in `edward.models`;
- `MFVI`—in favor of `KLqp`;
- `ed.placeholder`—in favor of TensorFlow's `tf.placeholder`.

Edward will continue their support for one or two more versions. They will be removed in some future release.

## Acknowledgements
- Thanks go to Alp Kucukelbir (@akucukelbir), Dawen Liang (@dawenl), John Pearson (@jmxpearson), Hayate Iso (@isohyt), Marmaduke Woodman (@maedoc), and Matthew Hoffman (@matthewdhoffman).

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.
",51468412
549,False,False,2016-11-02T15:05:54Z,2016-11-07T03:20:56Z,"- Small miscellaneous bug fixes.
- Website's API and documentation pages are overhauled.
- A white paper for Edward is released [[arXiv:1610.09787]](https://arxiv.org/abs/1610.09787).
",51468412
550,False,False,2016-10-03T03:57:55Z,2016-10-03T03:58:55Z,"## Models
- New random variables and methods are added (#256, #274). For example, random variables such as  `Mixture`, `QuantizedDistribution`, `WishartCholesky`, and methods such as `survival_function()`.
- Random variables and methods are now automatically generated from `tf.contrib.distributions` (#276). Edward random variables are minimal and adapt to the TensorFlow version.

## Inference

**Inference**
- The API is generalized to enable more fine-grained control (#253, #259, #260).

**Monte Carlo**
- Significant infrastructure for Monte Carlo is added (#254, #255). This makes it easy to develop new Monte Carlo methods.
- Metropolis-Hastings is implemented (#255)
- Hamiltonian Monte Carlo is implemented (#269).
- Stochastic gradient Langevin dynamics is implemented (#272).

**Variational inference**
- Black box-style methods are refactored internally (#249).

## Documentation
- The website tutorials are placed in a directory and have clean links (#263, #264).
- Initial progress is made on iPython notebook versions of the tutorials (#261).
- The website API is revamped (#268). Everything is now LaTeX-sourced, and the Delving In page is moved to the frontpage of the API.

## Miscellaneous
- Printing behavior of random variables is changed (#276).
- `edward.criticisms` is its own subpackage (#258).
- The TensorFlow dependency is now `>=0.11.0rc0` (#274).

## Acknowledgements
- Thanks go to Alp Kucukelbir (@akucukelbir), Bhargav Srinivasa (@bhargavvader), and Justin Bayer (@bayerj).

We are also grateful to all who filed issues or helped resolve them, asked and answered questions, and were part of inspiring discussions.
",51468412
551,False,False,2016-09-23T23:11:54Z,2016-09-23T23:14:33Z,"## Functionality
- A new modeling language is added, which exposes model structure to the user. This enables development of both model-specific and generic inference algorithms (#239).
- All of inference and criticism is updated to support the new language and also be backward-compatible with the model wrappers (#239).

## Documentation
- All of the website is updated to reflect the new modeling language (#252).
- Several existing tutorials now use the modeling language instead of a model wrapper (#252).

## Examples
- The [`examples/`](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/) directory is restructured (#251).
- Many examples with the modeling language are added:
  - [Bayesian linear regression](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/bayesian_linear_regression.py)
  - [Bayesian linear regression with TensorBoard visualization](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/bayesian_linear_regression_tensorboard.py)
  - [Bayesian neural network](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/bayesian_nn.py)
  - [Beta-Bernoulli](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/beta_bernoulli.py)
  - [Normal Normal](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/normal_normal.py)
  - [Variational auto-encoder](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/vae.py)
- Toy demonstrations of several probabilistic programming concepts are
  added:
  - [Dirichlet process](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/pp_dirichlet_process.py)
  - [Persistent randomness](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/pp_persistent_randomness.py)
  - [Stochastic control flow](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/pp_stochastic_control_flow.py)
  - [Stochastic recursion](https://github.com/blei-lab/edward/tree/f3fc5400230d9531af339bb442cd6c8f085657da/examples/pp_stochastic_recursion.py)

## Miscellaneous
- The TensorFlow dependency is now `>=0.10.0`.
- Momentum optimizer argument is fixed (#246).
",51468412
552,False,False,2016-08-30T02:12:36Z,2016-08-30T02:13:05Z,"## Functionality
- The API for inference and criticism is changed. It is a more intuitive interface that allows for multiple sets of latent variables (#192).
- The API for variational models is changed (#237). The user must explicitly define the parameters that he or she wishes to train; this allows for more flexibility in how to initialize and train variational parameters.
- `edward.models` is refactored to incorporate all random variables in [`tf.contrib.distributions`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distributions/python/ops) (#237). This speeds up computation, is more robust, and supports additional distributions and distribution methods.
-  `edward.stats` is refactored to have its main internals reside in [`tf.contrib.distributions`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distributions/python/ops) (#238). This speeds up computation, is more robust, and supports additional distributions and distribution methods.

## Documentation
- All of the website is updated to reflect the new API changes.
- The [contributing page](http://edwardlib.org/contributing) is revamped.

## Examples
- An [inference networks tutorial](http://edwardlib.org/tut_inference_networks) is added.
- A [mixture density networks tutorial](http://edwardlib.org/tut_mixture_density_network) is added.

## Testing
- [`py.test`](http://pytest.org) is now the testing tool of choice.
- Code now follows all of PEP8, with the exception of two-space indenting following [TensorFlow's style guide](https://www.tensorflow.org/versions/master/how_tos/style_guide.html) (#214, #215, #216, #217, #218, #219, #220, #221, #223, #225, #227, #228, #229, #230).
- Travis automates checking for PEP8.
- (minimal) Tensorboard support is added. Specifically, one can now visualize the computational graph used during inference.

## Miscellaneous
- The TensorFlow dependency is now `>=0.10.0rc0`.
- `ed.__version__` displays Edward's version.
- `ed.set_seed()` is more robust, checking to see if any random ops were created prior to setting the seed.
",51468412
553,False,False,2016-07-18T07:31:07Z,2016-07-18T07:41:51Z,"## Functionality
- Three ways to read data are supported, enabling the range from storing data in memory within TensorFlow's computational graph to manually feeding data to reading data from files. (see #170)
- Support for Python 3 is added.
- The naming scheme for various attributes is made consistent. (see https://github.com/blei-lab/edward/pull/162#issuecomment-232517072)

## Documentation
- The [website](http://edwardlib.org) is given a complete overhaul, now with getting started and delving in pages, in-depth tutorials, and an API describing the design of Edward and autogenerated doc for each function in Edward. (see #149)

## Examples
- [Importance-weighted variational inference](examples/iwvi.py) is added.
- [Latent space model](examples/latent_space_model.py) is added.
",51468412
554,False,False,2016-07-10T00:11:55Z,2016-07-10T00:24:25Z,"- There is now one data object to rule them all: a Python dictionary. (see #156)
- Distribution objects can be of arbitrary shape. For example, a 5 x 2 matrix of Normal random variables is declared with `x = Normal([5, 2])`. (see #138)

## Documentation
- All of Edward is documented. (see #148)
- Edward now follows [TensorFlow style guidelines](https://www.tensorflow.org/versions/r0.9/how_tos/style_guide.html).
- A tutorial on black box variational inference is available. (see #153)

## Miscellaneous
- We now use the special functions and their automatic differentation available in TensorFlow, e.g., `tf.lgamma`, `tf.digamma`, `tf.lbeta`.
- Sampling via NumPy/SciPy is done using a `tf.py_func` wrapper, speeding up sampling and avoiding internal overhead from the previous solution. (see #160)
- Sampling via reparameterizable distributions now follows the convention of `tf.contrib.distributions`. (see #161)
- Fixed bug where a class copy of the `layers` object in `Variational` is done (see #119)
",51468412
555,False,False,2016-06-26T05:54:03Z,2016-06-26T05:59:31Z,"- distributions can now be specified with parameters, simplifying use of inference networks, alternative parameterizations, and much of the internals for developing new inference algorithms; see #126
- TensorFlow session is now a global variable and can simply be accessed with `get_session()`; see #117
- added Laplace approximation
- added utility function to calculate hessian of TensorFlow tensors
",51468412
556,False,False,2016-06-05T01:35:58Z,2016-06-05T01:36:32Z,"- hotfix to get `from . import models` working
",51468412
557,False,False,2016-06-04T09:48:43Z,2016-06-04T09:51:33Z,"- website with revamped documentation: http://edwardlib.org. See details in #108
- criticism of probabilistic models with  `ed.evaluate()` and `ed.ppc()`. See details in #107
",51468412
558,False,False,2016-05-24T22:36:32Z,2016-05-24T22:38:22Z,"- enabled Keras as neural network specification
- samples in variational model can now leverage TensorFlow-based
  samplers and not only SciPy-based samplers
- let user optionally specify `sess` when using `inference`
- mean-field variational inference can now take advantage of analytically tractable KL terms for standard normal priors
- data can additionally be a list of `np.ndarray`s or list of
  `tf.placeholder`s
- added mixture density network as example
- enabled dimensions of distribution output to match with input dimensions
- renamed `log_gamma`, `log_beta`, `multivariate_log_beta` to `lgamma`
  and `lbeta` to follow convention in TensorFlow API
- let `PointMass` be a variational factor
- fixed `Multinomial` variational factor
- added continuous integration for unit tests
",51468412
559,False,False,2016-05-14T14:45:09Z,2016-05-14T14:47:16Z,"- interface-wise, you now import models (probability models or variational models) using

```
from edward.models import PythonModel, Variational, Normal
```

By default you can also do something like `ed.StanModel(model_file=model_file)`.
- variational distributions now default to initializing with only one factor
",51468412
560,False,False,2016-05-14T04:11:13Z,2016-05-14T04:13:38Z,"- generalized internals of variational distributions to use multivariate factors
- vectorized all distributions and with unit tests
- added additional distributions: `binom`, `chi2`, `geom`, `lognorm`, `nbinom`, `uniform`
- vectorized log density calls in variational distributions
- vectorized log density calls in model examples
",51468412
561,False,False,2016-05-09T20:56:25Z,2016-05-09T20:58:57Z,"- fixed bug in adding mean-field factorizations in `Variational()`
- support for PyMC3
",51468412
562,False,False,2016-05-07T14:18:29Z,2016-05-07T14:24:06Z,"- some distribution fixes
- mixture model of gaussians example
- variational model interface
",51468412
563,False,False,2016-05-03T03:47:36Z,2016-05-03T03:48:53Z,"Edward is a Python library for probabilistic modeling, inference, and criticism. It enables black box inference for models with discrete and continuous latent variables, neural network parameterizations, and infinite dimensional parameter spaces. Edward serves as a fusion of three fields: Bayesian statistics and machine learning, deep learning, and probabilistic programming.
",51468412
564,False,False,2018-11-25T18:25:54Z,2018-11-25T19:48:40Z,,71822014
565,False,False,2017-06-28T06:06:03Z,2017-06-28T13:16:09Z,,71822014
566,False,False,2017-05-29T15:07:02Z,2017-05-29T15:38:19Z,,71822014
567,False,False,2017-04-18T04:18:23Z,2017-04-18T04:18:48Z,,71822014
568,False,False,2017-04-12T14:49:06Z,2017-04-12T14:49:50Z,,71822014
569,False,False,2017-04-10T01:47:56Z,2017-04-10T02:25:10Z,,71822014
570,False,False,2017-04-05T15:02:53Z,2017-04-05T15:09:41Z,,71822014
571,False,False,2017-03-27T05:27:51Z,2017-03-27T05:39:13Z,,71822014
572,False,False,2017-03-26T18:21:55Z,2017-03-26T18:22:08Z,,71822014
573,False,False,2019-09-23T09:19:37Z,2019-09-26T05:35:28Z,"## 3.8.1, 2019-09-23

### :red_circle: Bug fixes

* Fix usage of base_dir instead of BASE_DIR in _load_info in downloader. (__[movb](https://github.com/movb)__, [#2605](https://github.com/RaRe-Technologies/gensim/pull/2605))
* Update the version of smart_open in the setup.py file (__[AMR-KELEG](https://github.com/AMR-KELEG)__, [#2582](https://github.com/RaRe-Technologies/gensim/pull/2582))
* Properly handle unicode_errors arg parameter when loading a vocab file (__[wmtzk](https://github.com/wmtzk)__, [#2570](https://github.com/RaRe-Technologies/gensim/pull/2570))
* Catch loading older TfidfModels without smartirs (__[bnomis](https://github.com/bnomis)__, [#2559](https://github.com/RaRe-Technologies/gensim/pull/2559))
* Fix bug where a module import set up logging, pin doctools for Py2 (__[piskvorky](https://github.com/piskvorky)__, [#2552](https://github.com/RaRe-Technologies/gensim/pull/2552))

### :books: Tutorial and doc improvements

* Fix usage example in phrases.py (__[piskvorky](https://github.com/piskvorky)__, [#2575](https://github.com/RaRe-Technologies/gensim/pull/2575))

### :+1: Improvements

* Optimize Poincare model training (__[koiizukag](https://github.com/koiizukag)__, [#2589](https://github.com/RaRe-Technologies/gensim/pull/2589))

### :warning: Deprecations (will be removed in the next major release)

* Remove
    - `gensim.models.FastText.load_fasttext_format`: use load_facebook_vectors to load embeddings only (faster, less CPU/memory usage, does not support training continuation) and load_facebook_model to load full model (slower, more CPU/memory intensive, supports training continuation)
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`",1349775
574,False,False,2019-07-09T00:36:19Z,2019-07-09T07:51:06Z,"## 3.8.0, 2019-07-08

## :warning: 3.8.x will be the last Gensim version to support Py2.7. Starting with 4.0.0, Gensim will only support Py3.5 and above

### :star2: New Features

* Enable online training of Poincare models (__[koiizukag](https://github.com/koiizukag)__, [#2505](https://github.com/RaRe-Technologies/gensim/pull/2505))
* Make BM25 more scalable by adding support for generator inputs (__[saraswatmks](https://github.com/saraswatmks)__, [#2479](https://github.com/RaRe-Technologies/gensim/pull/2479))
* Allow the Gensim dataset / pre-trained model downloader `gensim.downloader` to run offline, by introducing a local file cache (__[mpenkov](https://github.com/mpenkov)__, [#2545](https://github.com/RaRe-Technologies/gensim/pull/2545))
* Make the `gensim.downloader` target directory configurable (__[mpenkov](https://github.com/mpenkov)__, [#2456](https://github.com/RaRe-Technologies/gensim/pull/2456))
* Support fast kNN document similarity search using [NMSLIB](https://github.com/nmslib/nmslib) (__[masa3141](https://github.com/masa3141)__, [#2417](https://github.com/RaRe-Technologies/gensim/pull/2417))

### :red_circle: Bug fixes

* Fix `smart_open` deprecation warning globally (__[itayB](https://github.com/itayB)__, [#2530](https://github.com/RaRe-Technologies/gensim/pull/2530))
* Fix AppVeyor issues with Windows and Py2 (__[mpenkov](https://github.com/mpenkov)__, [#2546](https://github.com/RaRe-Technologies/gensim/pull/2546))
* Fix `topn=0` versus `topn=None` bug in `most_similar`, accept `topn` of any integer type (__[Witiko](https://github.com/Witiko)__, [#2497](https://github.com/RaRe-Technologies/gensim/pull/2497))
* Fix Python version check (__[charsyam](https://github.com/charsyam)__, [#2547](https://github.com/RaRe-Technologies/gensim/pull/2547))
* Fix typo in FastText documentation (__[Guitaricet](https://github.com/Guitaricet)__, [#2518](https://github.com/RaRe-Technologies/gensim/pull/2518))
* Fix ""Market Matrix"" to ""Matrix Market"" typo. (__[Shooter23](https://github.com/Shooter23)__, [#2513](https://github.com/RaRe-Technologies/gensim/pull/2513))
* Fix auto-generated hyperlinks in `CHANGELOG.md` (__[mpenkov](https://github.com/mpenkov)__, [#2482](https://github.com/RaRe-Technologies/gensim/pull/2482))

### :books: Tutorial and doc improvements

* Generate documentation for the `gensim.similarities.termsim` module (__[Witiko](https://github.com/Witiko)__, [#2485](https://github.com/RaRe-Technologies/gensim/pull/2485))
* Simplify the `Support` section in README (__[piskvorky](https://github.com/piskvorky)__, [#2542](https://github.com/RaRe-Technologies/gensim/pull/2542))

### :+1: Improvements

* Pin sklearn version for Py2, because sklearn dropped py2 support (__[mpenkov](https://github.com/mpenkov)__, [#2510](https://github.com/RaRe-Technologies/gensim/pull/2510))


### :warning: Deprecations (will be removed in the next major release)

* Remove
    - `gensim.models.FastText.load_fasttext_format`: use load_facebook_vectors to load embeddings only (faster, less CPU/memory usage, does not support training continuation) and load_facebook_model to load full model (slower, more CPU/memory intensive, supports training continuation)
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`",1349775
575,False,False,2019-05-06T06:13:27Z,2019-05-08T03:07:49Z,"## 3.7.3, 2019-05-06

### :red_circle: Bug fixes

* Fix fasttext model loading from gzip files (__[mpenkov](https://github.com/mpenkov)__, [#2476](https://github.com/RaRe-Technologies/gensim/pull/2476))
* Clean up FastText Cython code, fix division by zero (__[mpenkov](https://github.com/mpenkov)__, [#2382](https://github.com/RaRe-Technologies/gensim/pull/2382))
* Update legacy model loading (__[mpenkov](https://github.com/mpenkov)__, [#2454](https://github.com/RaRe-Technologies/gensim/pull/2454), [#2457](https://github.com/RaRe-Technologies/gensim/pull/2457))
* NMF bugfix (__[mpenkov](https://github.com/mpenkov)__, [#2466](https://github.com/RaRe-Technologies/gensim/pull/2466))
* Fix `WordEmbeddingsKeyedVectors.most_similar` (__[Witiko](https://github.com/Witiko)__, [#2461](https://github.com/RaRe-Technologies/gensim/pull/2461))
* Fix LdaSequence model by updating to num_documents (__[Bharat123rox](https://github.com/Bharat123rox)__, [#2410](https://github.com/RaRe-Technologies/gensim/pull/2410))
* Make termsim matrix positive definite even with negative similarities (__[Witiko](https://github.com/Witiko)__, [#2397](https://github.com/RaRe-Technologies/gensim/pull/2397))
* Fix the off-by-one bug in the TFIDF model. (__[AMR-KELEG](https://github.com/AMR-KELEG)__, [#2392](https://github.com/RaRe-Technologies/gensim/pull/2392))
* Make `matutils.unitvec` always return float norm when requested (__[Witiko](https://github.com/Witiko)__, [#2419](https://github.com/RaRe-Technologies/gensim/pull/2419))
* Fix misleading `Doc2Vec.docvecs` comment (__[gojomo](https://github.com/gojomo)__, [#2472](https://github.com/RaRe-Technologies/gensim/pull/2472))

### :books: Tutorial and doc improvements

* Update word2vec.ipynb (__[asyabo](https://github.com/asyabo)__, [#2423](https://github.com/RaRe-Technologies/gensim/pull/2423))

### :+1: Improvements

* Adding type check for corpus_file argument (__[saraswatmks](https://github.com/saraswatmks)__, [#2469](https://github.com/RaRe-Technologies/gensim/pull/2469))

### :warning: Deprecations (will be removed in the next major release)

* Remove
    - `gensim.models.FastText.load_fasttext_format`: use load_facebook_vectors to load embeddings only (faster, less CPU/memory usage, does not support training continuation) and load_facebook_model to load full model (slower, more CPU/memory intensive, supports training continuation)
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`",1349775
576,False,False,2019-04-06T12:08:45Z,2019-04-10T14:22:33Z,"## 3.7.2, 2019-04-06

### :star2: New Features

- `gensim.models.fasttext.load_facebook_model` function: load full model (slower, more CPU/memory intensive, supports training continuation)
  ```python
  >>> from gensim.test.utils import datapath
  >>>
  >>> cap_path = datapath(""crime-and-punishment.bin"")
  >>> fb_model = load_facebook_model(cap_path)
  >>>
  >>> 'landlord' in fb_model.wv.vocab  # Word is out of vocabulary
  False
  >>> oov_term = fb_model.wv['landlord']
  >>>
  >>> 'landlady' in fb_model.wv.vocab  # Word is in the vocabulary
  True
  >>> iv_term = fb_model.wv['landlady']
  >>>
  >>> new_sent = [['lord', 'of', 'the', 'rings'], ['lord', 'of', 'the', 'flies']]
  >>> fb_model.build_vocab(new_sent, update=True)
  >>> fb_model.train(sentences=new_sent, total_examples=len(new_sent), epochs=5)  
  ```

- `gensim.models.fasttext.load_facebook_vectors` function: load embeddings only (faster, less CPU/memory usage, does not support training continuation)
  ```python
  >>> fbkv = load_facebook_vectors(cap_path)
  >>>
  >>> 'landlord' in fbkv.vocab  # Word is out of vocabulary
  False
  >>> oov_vector = fbkv['landlord']
  >>>
  >>> 'landlady' in fbkv.vocab  # Word is in the vocabulary
  True
  >>> iv_vector = fbkv['landlady']
  ```

### :red_circle: Bug fixes

* Fix unicode error when loading FastText vocabulary (__[@mpenkov](https://github.com/mpenkov)__, [#2390](https://github.com/RaRe-Technologies/gensim/pull/2390))
* Avoid division by zero in fasttext_inner.pyx (__[@mpenkov](https://github.com/mpenkov)__, [#2404](https://github.com/RaRe-Technologies/gensim/pull/2404))
* Avoid incorrect filename inference when loading model (__[@mpenkov](https://github.com/mpenkov)__, [#2408](https://github.com/RaRe-Technologies/gensim/pull/2408))
* Handle invalid unicode when loading native FastText models (__[@mpenkov](https://github.com/mpenkov)__, [#2411](https://github.com/RaRe-Technologies/gensim/pull/2411))
* Avoid divide by zero when calculating vectors for terms with no ngrams (__[@mpenkov](https://github.com/mpenkov)__, [#2411](https://github.com/RaRe-Technologies/gensim/pull/2411))

### :books: Tutorial and doc improvements

* Add link to bindr (__[rogueleaderr](https://github.com/rogueleaderr)__, [#2387](https://github.com/RaRe-Technologies/gensim/pull/2387))

### :+1: Improvements

* Undo the hash2index optimization (__[mpenkov](https://github.com/mpenkov)__, [#2370](https://github.com/RaRe-Technologies/gensim/pull/2387))

### :warning: Changes in FastText behavior

#### Out-of-vocab word handling

To achieve consistency with the reference implementation from Facebook,
a `FastText` model will now always report any word, out-of-vocabulary or 
not, as being in the model,  and always return some vector for any word 
looked-up. Specifically:

1. `'any_word' in ft_model` will always return `True`.  Previously, it 
returned `True` only if the full word was in the vocabulary. (To test if a 
full word is in the known vocabulary, you can consult the `wv.vocab` 
property: `'any_word' in ft_model.wv.vocab` will return `False` if the full 
word wasn't learned during model training.)
2. `ft_model['any_word']` will always return a vector.  Previously, it 
raised `KeyError` for OOV words when the model had no vectors 
for **any** ngrams of the word.
3. If no ngrams from the term are present in the model,
or when no ngrams could be extracted from the term, a vector pointing
to the origin will be returned.  Previously, a vector of NaN (not a number)
was returned as a consequence of a divide-by-zero problem.
4. Models may use more more memory, or take longer for word-vector
lookup, especially after training on smaller corpuses where the previous 
non-compliant behavior discarded some ngrams from consideration.

#### Loading models in Facebook .bin format

The `gensim.models.FastText.load_fasttext_format` function (deprecated) now loads the entire model contained in the .bin file, including the shallow neural network that enables training continuation.
Loading this NN requires more CPU and RAM than previously required.

Since this function is deprecated, consider using one of its alternatives (see below).

Furthermore, you must now pass the full path to the file to load, **including the file extension.**
Previously, if you specified a model path that ends with anything other than .bin, the code automatically appended .bin to the path before loading the model.
This behavior was [confusing](https://github.com/RaRe-Technologies/gensim/issues/2407), so we removed it.
	
### :warning: Deprecations (will be removed in the next major release)

* Remove
    - `gensim.models.FastText.load_fasttext_format`: use load_facebook_vectors to load embeddings only (faster, less CPU/memory usage, does not support training continuation) and load_facebook_model to load full model (slower, more CPU/memory intensive, supports training continuation)
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`",1349775
577,False,False,2019-01-31T04:20:42Z,2019-01-31T17:00:11Z,"## 3.7.1, 2019-01-31

### :+1: Improvements

* NMF optimization & documentation (__[@anotherbugmaster](https://github.com/anotherbugmaster)__, [#2361](https://github.com/RaRe-Technologies/gensim/pull/2361))
* Optimize `FastText.load_fasttext_model` (__[@mpenkov](https://github.com/mpenkov)__, [#2340](https://github.com/RaRe-Technologies/gensim/pull/2340))
* Add warning when string is used as argument to `Doc2Vec.infer_vector` (__[@tobycheese](https://github.com/tobycheese)__, [#2347](https://github.com/RaRe-Technologies/gensim/pull/2347))
* Fix light linting issues in `LdaSeqModel` (__[@horpto](https://github.com/horpto)__, [#2360](https://github.com/RaRe-Technologies/gensim/pull/2360))
* Move out `process_result_queue` from cycle in `LdaMulticore` (__[@horpto](https://github.com/horpto)__, [#2358](https://github.com/RaRe-Technologies/gensim/pull/2358))


### :red_circle: Bug fixes

* Fix infinite diff in `LdaModel.do_mstep` (__[@horpto](https://github.com/horpto)__, [#2344](https://github.com/RaRe-Technologies/gensim/pull/2344))
* Fix backward compatibility issue: loading `FastTextKeyedVectors` using `KeyedVectors` (missing attribute `compatible_hash`) (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2349](https://github.com/RaRe-Technologies/gensim/pull/2349))
* Fix logging issue (conda-forge related) (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2339](https://github.com/RaRe-Technologies/gensim/pull/2339))
* Fix `WordEmbeddingsKeyedVectors.most_similar` (__[@Witiko](https://github.com/Witiko)__, [#2356](https://github.com/RaRe-Technologies/gensim/pull/2356))
* Fix issues of `flake8==3.7.1` (__[@horpto](https://github.com/horpto)__, [#2365](https://github.com/RaRe-Technologies/gensim/pull/2365))


### :books: Tutorial and doc improvements

* Improve `FastText` documentation (__[@mpenkov](https://github.com/mpenkov)__, [#2353](https://github.com/RaRe-Technologies/gensim/pull/2353))
* Minor corrections and improvements in `Any*Vec` docstrings (__[@tobycheese](https://github.com/tobycheese)__, [#2345](https://github.com/RaRe-Technologies/gensim/pull/2345))
* Fix the example code for SparseTermSimilarityMatrix (__[@Witiko](https://github.com/Witiko)__, [#2359](https://github.com/RaRe-Technologies/gensim/pull/2359))
* Update `poincare` documentation to indicate the relation format (__[@AMR-KELEG](https://github.com/AMR-KELEG)__, [#2357](https://github.com/RaRe-Technologies/gensim/pull/2357))


### :warning: Deprecations (will be removed in the next major release)

* Remove
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`
",1349775
578,False,False,2019-01-18T06:32:37Z,2019-01-18T20:16:12Z,"## 3.7.0, 2019-01-18

### :star2: New features

* Fast Online NMF (__[@anotherbugmaster](https://github.com/anotherbugmaster)__, [#2007](https://github.com/RaRe-Technologies/gensim/pull/2007))
    - Benchmark `wiki-english-20171001`

      | Model | Perplexity | Coherence | L2 norm | Train time (minutes) |
      |-------|------------|-----------|---------|----------------------|
      | LDA | 4727.07 | -2.514 | 7.372 | 138 |
      | NMF | **975.74** | -2.814 | **7.265** | **73** |
      | NMF (with regularization) | 985.57 | **-2.436** | 7.269 | 441 |

    - Simple to use (same interface as `LdaModel`)
      ```python
      from gensim.models.nmf import Nmf
      from gensim.corpora import Dictionary
      import gensim.downloader as api

      text8 = api.load('text8')

      dictionary = Dictionary(text8)
      dictionary.filter_extremes()

      corpus = [
          dictionary.doc2bow(doc) for doc in text8
      ]

      nmf = Nmf(
          corpus=corpus,
          num_topics=5,
          id2word=dictionary,
          chunksize=2000,
          passes=5,
          random_state=42,
      )

      nmf.show_topics()
      """"""
      [(0, '0.007*""km"" + 0.006*""est"" + 0.006*""islands"" + 0.004*""league"" + 0.004*""rate"" + 0.004*""female"" + 0.004*""economy"" + 0.003*""male"" + 0.003*""team"" + 0.003*""elections""'),
       (1, '0.006*""actor"" + 0.006*""player"" + 0.004*""bwv"" + 0.004*""writer"" + 0.004*""actress"" + 0.004*""singer"" + 0.003*""emperor"" + 0.003*""jewish"" + 0.003*""italian"" + 0.003*""prize""'),
       (2, '0.036*""college"" + 0.007*""institute"" + 0.004*""jewish"" + 0.004*""universidad"" + 0.003*""engineering"" + 0.003*""colleges"" + 0.003*""connecticut"" + 0.003*""technical"" + 0.003*""jews"" + 0.003*""universities""'),
       (3, '0.016*""import"" + 0.008*""insubstantial"" + 0.007*""y"" + 0.006*""soviet"" + 0.004*""energy"" + 0.004*""info"" + 0.003*""duplicate"" + 0.003*""function"" + 0.003*""z"" + 0.003*""jargon""'),
       (4, '0.005*""software"" + 0.004*""games"" + 0.004*""windows"" + 0.003*""microsoft"" + 0.003*""films"" + 0.003*""apple"" + 0.003*""video"" + 0.002*""album"" + 0.002*""fiction"" + 0.002*""characters""')]
      """"""
      ```
    - See also:
      - [NMF tutorial](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/nmf_tutorial.ipynb)
      - [Full NMF Benchmark](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/nmf_wikipedia.ipynb)

* Massive improvement of `FastText` compatibilities (__[@mpenkov](https://github.com/mpenkov)__, [#2313](https://github.com/RaRe-Technologies/gensim/pull/2313))
    ```python
    from gensim.models import FastText

    # 'cc.ru.300.bin' - Russian Facebook FT model trained on Common Crawl
    # Can be downloaded from https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.ru.300.bin.gz

    model = FastText.load_fasttext_format(""cc.ru.300.bin"")

    # Fixed hash-function allow to produce same output as FB FastText & works correctly for non-latin languages (for example, Russian)
    assert ""мяу"" in m.wv.vocab  # 'мяу' - vocab word
    model.wv.most_similar(""мяу"")
    """"""
    [('Мяу', 0.6820122003555298),
     ('МЯУ', 0.6373013257980347),
     ('мяу-мяу', 0.593108594417572),
     ('кис-кис', 0.5899622440338135),
     ('гав', 0.5866007804870605),
     ('Кис-кис', 0.5798211097717285),
     ('Кис-кис-кис', 0.5742273330688477),
     ('Мяу-мяу', 0.5699705481529236),
     ('хрю-хрю', 0.5508339405059814),
     ('ав-ав', 0.5479759573936462)]
    """"""

    assert ""котогород"" not in m.wv.vocab  # 'котогород' - out-of-vocab word
    model.wv.most_similar(""котогород"", topn=3)
    """"""
    [('автогород', 0.5463314652442932),
     ('ТагилНовокузнецкНовомосковскНовороссийскНовосибирскНовотроицкНовочеркасскНовошахтинскНовый',
      0.5423436164855957),
     ('областьНовосибирскБарабинскБердскБолотноеИскитимКарасукКаргатКуйбышевКупиноОбьТатарскТогучинЧерепаново',
      0.5377570390701294)]
    """"""

    # Now we load full model, for this reason, we can continue an training

    from gensim.test.utils import datapath
    from smart_open import smart_open

    with smart_open(datapath(""crime-and-punishment.txt""), encoding=""utf-8"") as infile:  # russian text
        corpus = [line.strip().split() for line in infile]

    model.train(corpus, total_examples=len(corpus), epochs=5)
    ```

* Similarity search improvements (__[@Witiko](https://github.com/Witiko)__, [#2016](https://github.com/RaRe-Technologies/gensim/pull/2016))
    - Add similarity search using the Levenshtein distance in `gensim.similarities.LevenshteinSimilarityIndex`
    - Performance optimizations to `gensim.similarities.SoftCosineSimilarity` ([full benchmark](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_benchmark.ipynb))

      | dictionary size | corpus size | speed         |
      |-----------------|-------------|--------------:|
      | 1000            | 100         | 1.0×          |
      | 1000            | 1000        | **53.4×**     |
      | 1000            | 100000      | **156784.8×** |
      | 100000          | 100         | **3.8×**      |
      | 100000          | 1000        | **405.8×**    |
      | 100000          | 100000      | **66262.0×**  |

    - See [updated soft-cosine tutorial](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb) for more information and usage examples

* Add `python3.7` support (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2211](https://github.com/RaRe-Technologies/gensim/pull/2211))
    - Wheels for Window, OSX and Linux platforms (__[@menshikh-iv](https://github.com/menshikh-iv)__, [MacPython/gensim-wheels/#12](https://github.com/MacPython/gensim-wheels/pull/12))
    - Faster installation


### :+1: Improvements

##### Optimizations
* Reduce `Phraser` memory usage (drop frequencies) (__[@jenishah](https://github.com/jenishah)__, [#2208](https://github.com/RaRe-Technologies/gensim/pull/2208))
* Reduce memory consumption of summarizer (__[@horpto](https://github.com/horpto)__, [#2298](https://github.com/RaRe-Technologies/gensim/pull/2298))
* Replace inline slow equivalent of mean_absolute_difference with fast (__[@horpto](https://github.com/horpto)__, [#2284](https://github.com/RaRe-Technologies/gensim/pull/2284))
* Reuse precalculated updated prior in `ldamodel.update_dir_prior` (__[@horpto](https://github.com/horpto)__, [#2274](https://github.com/RaRe-Technologies/gensim/pull/2274))
* Improve `KeyedVector.wmdistance` (__[@horpto](https://github.com/horpto)__, [#2326](https://github.com/RaRe-Technologies/gensim/pull/2326))
* Optimize `remove_unreachable_nodes` in `gensim.summarization` (__[@horpto](https://github.com/horpto)__, [#2263](https://github.com/RaRe-Technologies/gensim/pull/2263))
* Optimize `mz_entropy` from `gensim.summarization` (__[@horpto](https://github.com/horpto)__, [#2267](https://github.com/RaRe-Technologies/gensim/pull/2267))
* Improve `filter_extremes` methods in `Dictionary` and `HashDictionary` (__[@horpto](https://github.com/horpto)__, [#2303](https://github.com/RaRe-Technologies/gensim/pull/2303))

##### Additions
* Add `KeyedVectors.relative_cosine_similarity` (__[@rsdel2007](https://github.com/rsdel2007)__, [#2307](https://github.com/RaRe-Technologies/gensim/pull/2307))
* Add `random_seed` to `LdaMallet` (__[@Zohaggie](https://github.com/Zohaggie)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#2153](https://github.com/RaRe-Technologies/gensim/pull/2153))
* Add `common_terms` parameter to `sklearn_api.PhrasesTransformer` (__[@pmlk](https://github.com/pmlk)__, [#2074](https://github.com/RaRe-Technologies/gensim/pull/2074))
* Add method for patch `corpora.Dictionary` based on special tokens (__[@Froskekongen](https://github.com/Froskekongen)__, [#2200](https://github.com/RaRe-Technologies/gensim/pull/2200))

##### Cleanup
* Improve `six` usage (`xrange`, `map`, `zip`) (__[@horpto](https://github.com/horpto)__, [#2264](https://github.com/RaRe-Technologies/gensim/pull/2264))
* Refactor `line2doc` methods of `LowCorpus` and `MalletCorpus` (__[@horpto](https://github.com/horpto)__, [#2269](https://github.com/RaRe-Technologies/gensim/pull/2269))
* Get rid most of warnings in testing (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2191](https://github.com/RaRe-Technologies/gensim/pull/2191))
* Fix non-deterministic test failures (pin `PYTHONHASHSEED`) (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2196](https://github.com/RaRe-Technologies/gensim/pull/2196))
* Fix ""aliasing chunkize to chunkize_serial"" warning on Windows (__[@aquatiko](https://github.com/aquatiko)__, [#2202](https://github.com/RaRe-Technologies/gensim/pull/2202))
* Remove `__getitem__` code duplication in `gensim.models.phrases` (__[@jenishah](https://github.com/jenishah)__, [#2206](https://github.com/RaRe-Technologies/gensim/pull/2206))
* Add `flake8-rst` for docstring code examples (__[@kataev](https://github.com/kataev)__, [#2192](https://github.com/RaRe-Technologies/gensim/pull/2192))
* Get rid `py26` stuff (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2214](https://github.com/RaRe-Technologies/gensim/pull/2214))
* Use `itertools.chain` instead of `sum` to concatenate lists (__[@Stigjb](https://github.com/Stigjb)__, [#2212](https://github.com/RaRe-Technologies/gensim/pull/2212))
* Fix flake8 warnings W605, W504 (__[@horpto](https://github.com/horpto)__, [#2256](https://github.com/RaRe-Technologies/gensim/pull/2256))
* Remove unnecessary creations of lists at all (__[@horpto](https://github.com/horpto)__, [#2261](https://github.com/RaRe-Technologies/gensim/pull/2261))
* Fix extra list creation in `utils.get_max_id` (__[@horpto](https://github.com/horpto)__, [#2254](https://github.com/RaRe-Technologies/gensim/pull/2254))
* Fix deprecation warning `np.sum(generator)` (__[@rsdel2007](https://github.com/rsdel2007)__, [#2296](https://github.com/RaRe-Technologies/gensim/pull/2296))
* Refactor `BM25` (__[@horpto](https://github.com/horpto)__, [#2275](https://github.com/RaRe-Technologies/gensim/pull/2275))
* Fix pyemd import (__[@ramprakash-94](https://github.com/ramprakash-94)__, [#2240](https://github.com/RaRe-Technologies/gensim/pull/2240))
* Set `metadata=True` for `make_wikicorpus` script by default (__[@Xinyi2016](https://github.com/Xinyi2016)__, [#2245](https://github.com/RaRe-Technologies/gensim/pull/2245))
* Remove unimportant warning from `Phrases` (__[@rsdel2007](https://github.com/rsdel2007)__, [#2331](https://github.com/RaRe-Technologies/gensim/pull/2331))
* Replace `open()` by `smart_open()` in `gensim.models.fasttext._load_fasttext_format` (__[@rsdel2007](https://github.com/rsdel2007)__, [#2335](https://github.com/RaRe-Technologies/gensim/pull/2335))


### :red_circle: Bug fixes
* Fix overflow error for `*Vec` corpusfile-based training (__[@bm371613](https://github.com/bm371613)__, [#2239](https://github.com/RaRe-Technologies/gensim/pull/2239))
* Fix `malletmodel2ldamodel` conversion (__[@horpto](https://github.com/horpto)__, [#2288](https://github.com/RaRe-Technologies/gensim/pull/2288))
* Replace custom epsilons with numpy equivalent in `LdaModel` (__[@horpto](https://github.com/horpto)__, [#2308](https://github.com/RaRe-Technologies/gensim/pull/2308))
* Add missing content to tarball (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2194](https://github.com/RaRe-Technologies/gensim/pull/2194))
* Fixes divided by zero when w_star_count==0 (__[@allenyllee](https://github.com/allenyllee)__, [#2259](https://github.com/RaRe-Technologies/gensim/pull/2259))
* Fix check for callbacks (__[@allenyllee](https://github.com/allenyllee)__, [#2251](https://github.com/RaRe-Technologies/gensim/pull/2251))
* Fix `SvmLightCorpus.serialize` if `labels` instance of numpy.ndarray (__[@aquatiko](https://github.com/aquatiko)__, [#2243](https://github.com/RaRe-Technologies/gensim/pull/2243))
* Fix poincate viz incompatibility with `plotly>=3.0.0` (__[@jenishah](https://github.com/jenishah)__, [#2226](https://github.com/RaRe-Technologies/gensim/pull/2226))
* Fix `keep_n` behavior for `Dictionary.filter_extremes` (__[@johann-petrak](https://github.com/johann-petrak)__, [#2232](https://github.com/RaRe-Technologies/gensim/pull/2232))
* Fix for `sphinx==1.8.1` (last r (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#None](https://github.com/RaRe-Technologies/gensim/pull/None))
* Fix `np.issubdtype` warnings (__[@marioyc](https://github.com/marioyc)__, [#2210](https://github.com/RaRe-Technologies/gensim/pull/2210))
* Drop wrong key `-c` from `gensim.downloader` description (__[@horpto](https://github.com/horpto)__, [#2262](https://github.com/RaRe-Technologies/gensim/pull/2262))
* Fix gensim build (docs & pyemd issues) (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2318](https://github.com/RaRe-Technologies/gensim/pull/2318))
* Limit visdom version (avoid py2 issue from the latest visdom release) (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2334](https://github.com/RaRe-Technologies/gensim/pull/2334))
* Fix visdom integration (using `viz.line()` instead of `viz.updatetrace()`) (__[@allenyllee](https://github.com/allenyllee)__, [#2252](https://github.com/RaRe-Technologies/gensim/pull/2252))


### :books: Tutorial and doc improvements

* Add gensim-data repo to `gensim.downloader` & fix rendering of code examples (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2327](https://github.com/RaRe-Technologies/gensim/pull/2327))
* Fix typos in `gensim.models` (__[@rsdel2007](https://github.com/rsdel2007)__, [#2323](https://github.com/RaRe-Technologies/gensim/pull/2323))
* Fixed typos in notebooks (__[@rsdel2007](https://github.com/rsdel2007)__, [#2322](https://github.com/RaRe-Technologies/gensim/pull/2322))
* Update `Doc2Vec` documentation: how tags are assigned in `corpus_file` mode (__[@persiyanov](https://github.com/persiyanov)__, [#2320](https://github.com/RaRe-Technologies/gensim/pull/2320))
* Fix typos in `gensim/models/keyedvectors.py` (__[@rsdel2007](https://github.com/rsdel2007)__, [#2290](https://github.com/RaRe-Technologies/gensim/pull/2290))
* Add documentation about ranges to scoring functions for `Phrases` (__[@jenishah](https://github.com/jenishah)__, [#2242](https://github.com/RaRe-Technologies/gensim/pull/2242))
* Update return sections for `KeyedVectors.evaluate_word_*` (__[@Stigjb](https://github.com/Stigjb)__, [#2205](https://github.com/RaRe-Technologies/gensim/pull/2205))
* Fix return type in `KeyedVector.evaluate_word_analogies` (__[@Stigjb](https://github.com/Stigjb)__, [#2207](https://github.com/RaRe-Technologies/gensim/pull/2207))
* Fix `WmdSimilarity` documentation (__[@jagmoreira](https://github.com/jagmoreira)__, [#2217](https://github.com/RaRe-Technologies/gensim/pull/2217))
* Replace `fify -> fifty` in `gensim.parsing.preprocessing.STOPWORDS` (__[@coderwassananmol](https://github.com/coderwassananmol)__, [#2220](https://github.com/RaRe-Technologies/gensim/pull/2220))
* Remove `alpha=""auto""` from `LdaMulticore` (not supported yet) (__[@johann-petrak](https://github.com/johann-petrak)__, [#2225](https://github.com/RaRe-Technologies/gensim/pull/2225))
* Update Adopters in README (__[@piskvorky](https://github.com/piskvorky)__, [#2234](https://github.com/RaRe-Technologies/gensim/pull/2234))
* Fix broken link in `tutorials.md` (__[@rsdel2007](https://github.com/rsdel2007)__, [#2302](https://github.com/RaRe-Technologies/gensim/pull/2302))


### :warning: Deprecations (will be removed in the next major release)

* Remove
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`
",1349775
579,False,False,2018-09-20T12:13:38Z,2018-09-20T18:34:40Z,"## 3.6.0, 2018-09-20

### :star2: New features
* File-based training for `*2Vec` models (__[@persiyanov](https://github.com/persiyanov)__, [#2127](https://github.com/RaRe-Technologies/gensim/pull/2127) & [#2078](https://github.com/RaRe-Technologies/gensim/pull/2078) & [#2048](https://github.com/RaRe-Technologies/gensim/pull/2048))

  [Blog post / Jupyter tutorial](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Any2Vec_Filebased.ipynb). 

  New training mode for `*2Vec` models (word2vec, doc2vec, fasttext) that allows model training to **scale linearly with the number of cores** (full GIL elimination). The result of our Google Summer of Code 2018 project by Dmitry Persiyanov.

  **Benchmark** on the full English Wikipedia, Intel(R) Xeon(R) CPU @ 2.30GHz 32 cores (GCE cloud), MKL BLAS:

  | Model | Queue-based version [sec] | File-based version [sec] | speed up | Accuracy (queue-based) | Accuracy (file-based) |
  |-------|------------|--------------------|----------|----------------|-----------------------|
  | Word2Vec | 9230 | **2437** | **3.79x** | 0.754 (± 0.003) | 0.750 (± 0.001) |
  | Doc2Vec | 18264 | **2889** | **6.32x** | 0.721 (± 0.002) | 0.683 (± 0.003) |
  | FastText | 16361 | **10625** | **1.54x** | 0.642 (± 0.002) | 0.660 (± 0.001) |

  Usage:

  ```python
  import gensim.downloader as api
  from multiprocessing import cpu_count
  from gensim.utils import save_as_line_sentence
  from gensim.test.utils import get_tmpfile
  from gensim.models import Word2Vec, Doc2Vec, FastText


  # Convert any corpus to the needed format: 1 document per line, words delimited by "" ""
  corpus = api.load(""text8"")
  corpus_fname = get_tmpfile(""text8-file-sentence.txt"")
  save_as_line_sentence(corpus, corpus_fname)

  # Choose num of cores that you want to use (let's use all, models scale linearly now!)
  num_cores = cpu_count()

  # Train models using all cores
  w2v_model = Word2Vec(corpus_file=corpus_fname, workers=num_cores)
  d2v_model = Doc2Vec(corpus_file=corpus_fname, workers=num_cores)
  ft_model = FastText(corpus_file=corpus_fname, workers=num_cores)

  ```
  [Read notebook tutorial with full description.](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Any2Vec_Filebased.ipynb)


### :+1: Improvements

* Add scikit-learn wrapper for `FastText` (__[@mcemilg](https://github.com/mcemilg)__, [#2178](https://github.com/RaRe-Technologies/gensim/pull/2178))
* Add multiprocessing support for `BM25` (__[@Shiki-H](https://github.com/Shiki-H)__, [#2146](https://github.com/RaRe-Technologies/gensim/pull/2146))
* Add `name_only` option for downloader api (__[@aneesh-joshi](https://github.com/aneesh-joshi)__, [#2143](https://github.com/RaRe-Technologies/gensim/pull/2143))
* Make `word2vec2tensor` script compatible with `python3` (__[@vsocrates](https://github.com/vsocrates)__, [#2147](https://github.com/RaRe-Technologies/gensim/pull/2147))
* Add custom filter for `Wikicorpus` (__[@mattilyra](https://github.com/mattilyra)__, [#2089](https://github.com/RaRe-Technologies/gensim/pull/2089))
* Make `similarity_matrix` support non-contiguous dictionaries (__[@Witiko](https://github.com/Witiko)__, [#2047](https://github.com/RaRe-Technologies/gensim/pull/2047))


### :red_circle: Bug fixes

* Fix memory consumption in `AuthorTopicModel` (__[@philipphager](https://github.com/philipphager)__, [#2122](https://github.com/RaRe-Technologies/gensim/pull/2122))
* Correctly process empty documents in `AuthorTopicModel` (__[@probinso](https://github.com/probinso)__, [#2133](https://github.com/RaRe-Technologies/gensim/pull/2133))
* Fix ZeroDivisionError `keywords` issue with short input (__[@LShostenko](https://github.com/LShostenko)__, [#2154](https://github.com/RaRe-Technologies/gensim/pull/2154))
* Fix `min_count` handling in phrases detection using `npmi_scorer` (__[@lopusz](https://github.com/lopusz)__, [#2072](https://github.com/RaRe-Technologies/gensim/pull/2072))
* Remove duplicate count from `Phraser` log message (__[@robguinness](https://github.com/robguinness)__, [#2151](https://github.com/RaRe-Technologies/gensim/pull/2151))
* Replace `np.integer` -> `np.int` in `AuthorTopicModel` (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2145](https://github.com/RaRe-Technologies/gensim/pull/2145))


### :books: Tutorial and doc improvements

* Update docstring with new analogy evaluation method (__[@akutuzov](https://github.com/akutuzov)__, [#2130](https://github.com/RaRe-Technologies/gensim/pull/2130))
* Improve `prune_at` parameter description for `gensim.corpora.Dictionary` (__[@yxonic](https://github.com/yxonic)__, [#2128](https://github.com/RaRe-Technologies/gensim/pull/2128))
* Fix `default` -> `auto` prior parameter in documentation for lda-related models (__[@Laubeee](https://github.com/Laubeee)__, [#2156](https://github.com/RaRe-Technologies/gensim/pull/2156))
* Use heading instead of bold style in `gensim.models.translation_matrix` (__[@nzw0301](https://github.com/nzw0301)__, [#2164](https://github.com/RaRe-Technologies/gensim/pull/2164))
* Fix quote of vocabulary from `gensim.models.Word2Vec` (__[@nzw0301](https://github.com/nzw0301)__, [#2161](https://github.com/RaRe-Technologies/gensim/pull/2161))
* Replace deprecated parameters with new in docstring of `gensim.models.Doc2Vec` (__[@xuhdev](https://github.com/xuhdev)__, [#2165](https://github.com/RaRe-Technologies/gensim/pull/2165))
* Fix formula in Mallet documentation (__[@Laubeee](https://github.com/Laubeee)__, [#2186](https://github.com/RaRe-Technologies/gensim/pull/2186))
* Fix minor semantic issue in docs for `Phrases` (__[@RunHorst](https://github.com/RunHorst)__, [#2148](https://github.com/RaRe-Technologies/gensim/pull/2148))
* Fix typo in documentation (__[@KenjiOhtsuka](https://github.com/KenjiOhtsuka)__, [#2157](https://github.com/RaRe-Technologies/gensim/pull/2157))
* Additional documentation fixes (__[@piskvorky](https://github.com/piskvorky)__, [#2121](https://github.com/RaRe-Technologies/gensim/pull/2121))

### :warning: Deprecations (will be removed in the next major release)

* Remove
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`
",1349775
580,False,False,2018-07-06T09:07:59Z,2018-07-06T13:57:44Z,"## 3.5.0, 2018-07-06

This release comprises a glorious 38 pull requests from 28 contributors. Most of the effort went into improving the documentation—hence the release code name ""Docs 💬""!

Apart from the **massive overhaul of all Gensim documentation** (including docstring style and examples—[you asked for it](https://rare-technologies.com/gensim-survey-2018/)), we also managed to sneak in some new functionality and a number of bug fixes. As usual, see the notes below for a complete list, with links to pull requests for more details.

**Huge thanks to all contributors!** Nobody loves working on documentation. 3.5.0 is a result of several months of laborious, unglamorous, and sometimes invisible work. Enjoy!


### :books: Documentation improvements

* Overhaul documentation for `*2vec` models (__[@steremma](https://github.com/steremma)__ & __[@piskvorky](https://github.com/piskvorky)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1944](https://github.com/RaRe-Technologies/gensim/pull/1944), [#2087](https://github.com/RaRe-Technologies/gensim/pull/2087))
* Fix documentation for LDA-related models (__[@steremma](https://github.com/steremma)__ & __[@piskvorky](https://github.com/piskvorky)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#2026](https://github.com/RaRe-Technologies/gensim/pull/2026))
* Fix documentation for utils, corpora, inferfaces (__[@piskvorky](https://github.com/piskvorky)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#2096](https://github.com/RaRe-Technologies/gensim/pull/2096))
* Update non-API docs (about, intro, license etc) (__[@piskvorky](https://github.com/piskvorky)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#2101](https://github.com/RaRe-Technologies/gensim/pull/2101))
* Refactor documentation for `gensim.models.phrases` (__[@CLearERR](https://github.com/CLearERR)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1950](https://github.com/RaRe-Technologies/gensim/pull/1950))
* Fix HashDictionary documentation (__[@piskvorky](https://github.com/piskvorky)__, [#2073](https://github.com/RaRe-Technologies/gensim/pull/2073))
* Fix docstrings for `gensim.models.AuthorTopicModel` (__[@souravsingh](https://github.com/souravsingh)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1907](https://github.com/RaRe-Technologies/gensim/pull/1907))
* Fix docstrings for HdpModel, lda_worker & lda_dispatcher (__[@gyanesh-m](https://github.com/gyanesh-m)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1912](https://github.com/RaRe-Technologies/gensim/pull/1912))
* Fix format & links for `gensim.similarities.docsim` (__[@CLearERR](https://github.com/CLearERR)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#2030](https://github.com/RaRe-Technologies/gensim/pull/2030))
* Remove duplication of class documentation for `IndexedCorpus` (__[@darindf](https://github.com/darindf)__, [#2033](https://github.com/RaRe-Technologies/gensim/pull/2033))
* Refactor documentation for `gensim.models.coherencemodel` (__[@CLearERR](https://github.com/CLearERR)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1933](https://github.com/RaRe-Technologies/gensim/pull/1933))
* Fix docstrings for `gensim.sklearn_api` (__[@steremma](https://github.com/steremma)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1895](https://github.com/RaRe-Technologies/gensim/pull/1895))
* Disable google-style docstring support (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#2106](https://github.com/RaRe-Technologies/gensim/pull/2106))
* Fix docstring of `gensim.models.KeyedVectors.similarity_matrix` (__[@Witiko](https://github.com/Witiko)__, [#1971](https://github.com/RaRe-Technologies/gensim/pull/1971))
* Consistently use `smart_open()` instead of `open()` in notebooks (__[@sharanry](https://github.com/sharanry)__, [#1812](https://github.com/RaRe-Technologies/gensim/pull/1812))


### :star2: New features:

* Add `add_entity` method to `KeyedVectors` to allow adding word vectors manually (__[@persiyanov](https://github.com/persiyanov)__, [#1957](https://github.com/RaRe-Technologies/gensim/pull/1957))
* Add inference for new unseen author to `AuthorTopicModel` (__[@Stamenov](https://github.com/Stamenov)__, [#1766](https://github.com/RaRe-Technologies/gensim/pull/1766))
* Add `evaluate_word_analogies` (will replace `accuracy`) method to `KeyedVectors` (__[@akutuzov](https://github.com/akutuzov)__, [#1935](https://github.com/RaRe-Technologies/gensim/pull/1935))
* Add Pivot Normalization to `TfidfModel` (__[@markroxor](https://github.com/markroxor)__, [#1780](https://github.com/RaRe-Technologies/gensim/pull/1780))



### :+1: Improvements

* Allow initialization with `max_final_vocab` in lieu of `min_count` in `Word2Vec`(__[@aneesh-joshi](https://github.com/aneesh-joshi)__, [#1915](https://github.com/RaRe-Technologies/gensim/pull/1915))
* Add `dtype` argument for `chunkize_serial` in `LdaModel` (__[@darindf](https://github.com/darindf)__, [#2027](https://github.com/RaRe-Technologies/gensim/pull/2027))
* Increase performance in `Phrases.analyze_sentence` (__[@JonathanHourany](https://github.com/JonathanHourany)__, [#2070](https://github.com/RaRe-Technologies/gensim/pull/2070))
* Add `ns_exponent` parameter to control the negative sampling distribution for `*2vec` models (__[@fernandocamargoti](https://github.com/fernandocamargoti)__, [#2093](https://github.com/RaRe-Technologies/gensim/pull/2093))


### :red_circle: Bug fixes:


* Fix `Doc2Vec.infer_vector` + notebook cleanup (__[@gojomo](https://github.com/gojomo)__, [#2103](https://github.com/RaRe-Technologies/gensim/pull/2103))
* Fix linear decay for learning rate in `Doc2Vec.infer_vector` (__[@umangv](https://github.com/umangv)__, [#2063](https://github.com/RaRe-Technologies/gensim/pull/2063))
* Fix negative sampling floating-point error for `gensim.models.Poincare (__[@jayantj](https://github.com/jayantj)__, [#1959](https://github.com/RaRe-Technologies/gensim/pull/1959))
* Fix loading `word2vec` and `doc2vec` models saved using old Gensim versions (__[@manneshiva](https://github.com/manneshiva)__, [#2012](https://github.com/RaRe-Technologies/gensim/pull/2012))
* Fix `SoftCosineSimilarity.get_similarities` on corpora ssues/1955) (__[@Witiko](https://github.com/Witiko)__, [#1972](https://github.com/RaRe-Technologies/gensim/pull/1972))
* Fix return dtype for `matutils.unitvec` according to input dtype (__[@o-P-o](https://github.com/o-P-o)__, [#1992](https://github.com/RaRe-Technologies/gensim/pull/1992))
* Fix passing empty dictionary to `gensim.corpora.WikiCorpus` (__[@steremma](https://github.com/steremma)__, [#2042](https://github.com/RaRe-Technologies/gensim/pull/2042))
* Fix bug in `Similarity.query_shards` in multiprocessing case (__[@bohea](https://github.com/bohea)__, [#2044](https://github.com/RaRe-Technologies/gensim/pull/2044))
* Fix SMART from TfidfModel for case when `df == ""n""` (__[@PeteBleackley](https://github.com/PeteBleackley)__, [#2021](https://github.com/RaRe-Technologies/gensim/pull/2021))
* Fix OverflowError when loading a large term-document matrix in compiled MatrixMarket format (__[@arlenk](https://github.com/arlenk)__, [#2001](https://github.com/RaRe-Technologies/gensim/pull/2001))
* Update rules for removing table markup from Wikipedia dumps (__[@chaitaliSaini](https://github.com/chaitaliSaini)__, [#1954](https://github.com/RaRe-Technologies/gensim/pull/1954))
* Fix `_is_single` from `Phrases` for case when corpus is a NumPy array (__[@rmalouf](https://github.com/rmalouf)__, [#1987](https://github.com/RaRe-Technologies/gensim/pull/1987))
* Fix tests for `EuclideanKeyedVectors.similarity_matrix` (__[@Witiko](https://github.com/Witiko)__, [#1984](https://github.com/RaRe-Technologies/gensim/pull/1984))
* Fix deprecated parameters in `D2VTransformer` and `W2VTransformer`(__[@MritunjayMohitesh](https://github.com/MritunjayMohitesh)__, [#1945](https://github.com/RaRe-Technologies/gensim/pull/1945))
* Fix `Doc2Vec.infer_vector` after loading old `Doc2Vec` (`gensim<=3.2`)(__[@manneshiva](https://github.com/manneshiva)__, [#1974](https://github.com/RaRe-Technologies/gensim/pull/1974))
* Fix inheritance chain for `load_word2vec_format` (__[@DennisChen0307](https://github.com/DennisChen0307)__, [#1968](https://github.com/RaRe-Technologies/gensim/pull/1968))
* Update Keras version (avoid bug from `keras==2.1.5`) (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1963](https://github.com/RaRe-Technologies/gensim/pull/1963))



### :warning: Deprecations (will be removed in the next major release)
* Remove
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`
",1349775
581,False,False,2018-03-01T10:28:03Z,2018-03-01T10:34:38Z,"## 3.4.0, 2018-03-01

### :star2: New features:
* Massive optimizations of `gensim.models.LdaModel`: much faster training, using Cython. (__[@arlenk](https://github.com/arlenk)__, [#1767](https://github.com/RaRe-Technologies/gensim/pull/1767))
	- Training benchmark :boom:

	  | dataset | old LDA [sec] | optimized LDA [sec] | speed up |
	  |---------|---------------|---------------------|---------|
	  | nytimes | 3473 | **1975** | **1.76x** | 
	  | enron   | 774 | **437** |  **1.77x** |

	- This change **affects all models that depend on `LdaModel`**, such as `LdaMulticore`, `LdaSeqModel`, `AuthorTopicModel`.
* Huge speed-ups to corpus I/O with `MmCorpus` (Cython) (__[@arlenk](https://github.com/arlenk)__, [#1825](https://github.com/RaRe-Technologies/gensim/pull/1825))
	- File reading benchmark

	  |     dataset   | file compressed? | old MmReader [sec] | optimized MmReader [sec] | speed up      |
	  |---------------|:-----------:|:------------:|:------------------:|:-------------:|
	  | enron         |      no     |      22.3    |     **2.6**        |    **8.7x**   |
	  |               |     yes     |      37.3    |    **14.4**        |    **2.6x**   |
	  | nytimes       |      no     |      419.3   |    **49.2**        |    **8.5x**   |
	  |               |     yes     |      686.2   |    **275.1**       |    **2.5x**   |
	  | text8         |      no     |      25.4    |     **2.5**        |   **10.1x**   |
	  |               |     yes     |      41.9    |    **17.0**        |    **2.5x**   |

	- Overall, a **2.5x** speedup for compressed `.mm.gz` input and **8.5x** :fire::fire::fire: for uncompressed plaintext `.mm`.

* Performance and memory optimization to `gensim.models.FastText` :rocket: (__[@jbaiter](https://github.com/jbaiter)__, [#1916](https://github.com/RaRe-Technologies/gensim/pull/1916))
	- Benchmark (first 500,000 articles from English Wikipedia)

	  | Metric                 | old FastText         | optimized FastText  | improvement |
	  | -----------------------| -----------------| -------------------|-------------|
	  | Training time (1 epoch)     |      4823.4s (80.38 minutes)    |  **1873.6s (31.22 minutes)**  | **2.57x** |
	  | Training time (full) | 1h 26min 13s | **36min 43s** | **2.35x** |
	  | Training words/sec   |  72,781  | **187,366** | **2.57x** |
	  | Training peak memory   | 5.2 GB  |  **3.7 GB** | **1.4x** | 
    
    - Overall, a **2.5x** speedup & memory usage reduced by **30%**.

* Implemented [Soft Cosine Measure](https://en.wikipedia.org/wiki/Cosine_similarity#Soft_cosine_measure) (__[@Witiko](https://github.com/Witiko)__, [#1827](https://github.com/RaRe-Technologies/gensim/pull/1827))
	- New method for assessing document similarity, a nice faster alternative to [WMD, Word Mover's Distance](http://proceedings.mlr.press/v37/kusnerb15.pdf)
	- Benchmark

	  | Technique | MAP score | Duration     |
	  |-----------|-----------|--------------|
	  | softcossim| **45.99** | **1.24 sec** |
	  | wmd-relax | 44.48     | 12.22 sec    |
	  |  cossim   | 44.22     | 4.39 sec     |
	  | wmd-gensim| 44.08     | 98.29 sec    |

	- [Soft Cosine notebook with detailed description, examples & benchmarks](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb)
	- Related papers:
		- [Soft Similarity and Soft Cosine Measure: Similarity of Features in Vector Space Model](http://www.scielo.org.mx/pdf/cys/v18n3/v18n3a7.pdf)
		- [SimBow at SemEval-2017 Task 3: Soft-Cosine Semantic Similarity between Questions for Community Question Answering](http://www.aclweb.org/anthology/S17-2051)
		- [Vector Space Representations in IR](https://github.com/witiko-masters-thesis/thesis/blob/master/main.pdf)


### :+1: Improvements:
* New method to show the Gensim installation parameters: `python -m gensim.scripts.package_info --info`. Use this when reporting problems, for easier debugging. Fix #1902 (__[@sharanry](https://github.com/sharanry)__, [#1903](https://github.com/RaRe-Technologies/gensim/pull/1903))
* Added a flag to optionally skip network-related tests, to help maintainers avoid network issues with CI services (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1930](https://github.com/RaRe-Technologies/gensim/pull/1930))
* Added `license` field to `setup.py`, allowing the use of tools like `pip-licenses` (__[@nils-werner](https://github.com/nils-werner)__, [#1909](https://github.com/RaRe-Technologies/gensim/pull/1909))

### :red_circle: Bug fixes:
* Fix Python 3 compatibility for `gensim.corpora.UciCorpus.save_corpus` (__[@darindf](https://github.com/darindf)__, [#1875](https://github.com/RaRe-Technologies/gensim/pull/1875))
* Add `wv` property to KeyedVectors for backward compatibility. Fix #1882 (__[@manneshiva](https://github.com/manneshiva)__, [#1884](https://github.com/RaRe-Technologies/gensim/pull/1884))
* Fix deprecation warning from `inspect.getargspec`. Fix #1878 (__[@aneesh-joshi](https://github.com/aneesh-joshi)__, [#1887](https://github.com/RaRe-Technologies/gensim/pull/1887))
* Add `LabeledSentence` to `gensim.models.doc2vec` for backward compatibility. Fix #1886 (__[@manneshiva](https://github.com/manneshiva)__, [#1891](https://github.com/RaRe-Technologies/gensim/pull/1891))
* Fix empty output bug in `Phrases` (when using `model[tokens]` twice). Fix #1401 (__[@sj29-innovate](https://github.com/sj29-innovate)__, [#1853](https://github.com/RaRe-Technologies/gensim/pull/1853))
* Fix type problems for `D2VTransformer.fit_transform`. Fix #1834 (__[@Utkarsh-Mishra-CIC](https://github.com/Utkarsh-Mishra-CIC)__, [#1845](https://github.com/RaRe-Technologies/gensim/pull/1845))
* Fix `datatype` parameter for `KeyedVectors.load_word2vec_format`. Fix #1682 (__[@pushpankar](https://github.com/pushpankar)__, [#1819](https://github.com/RaRe-Technologies/gensim/pull/1819))
* Fix deprecated parameters in `doc2vec-lee` notebook (__[@TheFlash10](https://github.com/TheFlash10)__, [#1918](https://github.com/RaRe-Technologies/gensim/pull/1918))
* Fix file-like closing bug in `gensim.corpora.MmCorpus`. Fix #1869 (__[@sj29-innovate](https://github.com/sj29-innovate)__, [#1911](https://github.com/RaRe-Technologies/gensim/pull/1911))
* Fix precision problem in `test_similarities.py`, no more FP fails. (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1928](https://github.com/RaRe-Technologies/gensim/pull/1928))
* Fix encoding in Lee corpus reader. (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1931](https://github.com/RaRe-Technologies/gensim/pull/1931))
* Fix OOV pairs counter in `WordEmbeddingsKeyedVectors.evaluate_word_pairs`. (__[@akutuzov](https://github.com/akutuzov)__, [#1934](https://github.com/RaRe-Technologies/gensim/pull/1934))


### :books: Tutorial and doc improvements:
* Fix example block for `gensim.models.Word2Vec` (__[@nzw0301](https://github.com/nzw0301)__, [#1870](https://github.com/RaRe-Technologies/gensim/pull/1876))
* Fix `doc2vec-lee` notebook (__[@numericlee](https://github.com/numericlee)__, [#1870](https://github.com/RaRe-Technologies/gensim/pull/1870))
* Store images from `README.md` directly in repository. Fix #1849 (__[@ibrahimsharaf](https://github.com/ibrahimsharaf)__, [#1861](https://github.com/RaRe-Technologies/gensim/pull/1861))
* Add windows venv activate command to `CONTRIBUTING.md` (__[@aneesh-joshi](https://github.com/aneesh-joshi)__, [#1880](https://github.com/RaRe-Technologies/gensim/pull/1880))
* Add anaconda-cloud badge. Partial fix #1901 (__[@sharanry](https://github.com/sharanry)__, [#1905](https://github.com/RaRe-Technologies/gensim/pull/1905))
* Fix docstrings for lsi-related code (__[@steremma](https://github.com/steremma)__, [#1892](https://github.com/RaRe-Technologies/gensim/pull/1892))
* Fix parameter description of  `sg` parameter for `gensim.models.word2vec` (__[@mdcclv](https://github.com/mdcclv)__, [#1919](https://github.com/RaRe-Technologies/gensim/pull/1919))
* Refactor documentation for `gensim.similarities.docsim` and `MmCorpus-related`. (__[@CLearERR](https://github.com/CLearERR)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1910](https://github.com/RaRe-Technologies/gensim/pull/1910))
* Fix docstrings for `gensim.test.utils` (__[@yurkai](https://github.com/yurkai)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1904](https://github.com/RaRe-Technologies/gensim/pull/1904))
* Refactor docstrings for `gensim.scripts`. Partial fix #1665 (__[@yurkai](https://github.com/yurkai)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1792](https://github.com/RaRe-Technologies/gensim/pull/1792))
* Refactor API reference `gensim.corpora`. Partial fix #1671 (__[@CLearERR](https://github.com/CLearERR)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1835](https://github.com/RaRe-Technologies/gensim/pull/1835))
* Fix documentation for `gensim.models.wrappers` (__[@kakshay21](https://github.com/kakshay21)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1859](https://github.com/RaRe-Technologies/gensim/pull/1859))
* Fix docstrings for `gensim.interfaces` (__[@yurkai](https://github.com/yurkai)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1913](https://github.com/RaRe-Technologies/gensim/pull/1913))


### :warning: Deprecations (will be removed in the next major release)
* Remove
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`

",1349775
582,False,False,2018-02-02T13:47:56Z,2018-02-02T13:50:11Z,"## 3.3.0, 2018-02-02

:star2: New features:
* Re-designed all ""*2vec"" implementations (__[@manneshiva](https://github.com/manneshiva)__, [#1777](https://github.com/RaRe-Technologies/gensim/pull/1777))
    - Modular organization of `Word2Vec`, `Doc2Vec`, `FastText`, etc ..., making it easier to add new models in the future and re-use code
    - Fully backward compatible (even with loading models stored by a previous Gensim version)
    - [Detailed documentation for the *2vec refactoring project](https://github.com/manneshiva/gensim/wiki/Any2Vec-Refactoring-Summary)

* Improve `gensim.scripts.segment_wiki` by retaining interwiki links. Fix #1712
 (__[@steremma](https://github.com/steremma)__, [PR #1839](https://github.com/RaRe-Technologies/gensim/pull/1839))
    - Optionally extract interlinks from Wikipedia pages (use the `--include-interlinks` option). This will output one additional JSON dict for each article:
        ```
        {
            ""interlinks"": {
                ""article title 1"": ""interlink text 1"",
                ""article title 2"": ""interlink text 2"",
                ...
            }
        }
        ```

    - Example: extract the Wikipedia graph with article links as edges, from a raw Wikipedia dump:
        ```bash
        python -m gensim.scripts.segment_wiki --include-interlinks --file ~/Downloads/enwiki-latest-pages-articles.xml.bz2 --output ~/Desktop/enwiki-latest.jsonl.gz
        ```
        - Read this field from the `segment_wiki` output:

        ```python
        import json
        from smart_open import smart_open

        with smart_open(""enwiki-latest.jsonl.gz"") as infile:
            for doc in infile:
                doc = json.loads(doc)

                src_node = doc['title']
                dst_nodes = doc['interlinks'].keys()

                print(u""Source node: {}"".format(src_node))
                print(u""Destination nodes: {}"".format(u"", "".join(dst_nodes)))
                break

        """"""
        OUTPUT:

        Source node: Anarchism
        Destination nodes: anarcha-feminist, Ivan Illich, Adolf Brand, Josiah Warren, will (philosophy), anarcha-feminism, Anarchism in Mexico, Lysander Spooner, English Civil War, G8, Sebastien Faure, Nihilist movement, Sébastien Faure, Left-wing politics, imamate, Pierre Joseph Proudhon, anarchist communism, Università popolare (Italian newspaper), 1848 Revolution, Synthesis anarchism, labour movement, anarchist communists, collectivist anarchism, polyamory, post-humanism, postcolonialism, anti war movement, State (polity), security culture, Catalan people, Stoicism, Progressive education, stateless society, Umberto I of Italy, German language, Anarchist schools of thought, NEFAC, Jacques Ellul, Spanish Communist Party, Crypto-anarchism, ruling class, non-violence, Platformist, The History of Sexuality, Revolutions of 1917–23, Federación Anarquista Ibérica, propaganda of the deed, William B. Greene, Platformism, mutually exclusive, Fraye Arbeter Shtime, Adolf Hitler, oxymoron, Paris Commune, Anarchism in Italy#Postwar years and today, Oranienburg, abstentionism, Free Society, Henry David Thoreau, privative alpha, George I of Greece, communards, Gustav Landauer, Lucifer the Lightbearer, Moses Harman, coercion, regicide, rationalist, Resistance during World War II, Christ (title), Bohemianism, individualism, Crass, black bloc, Spanish Revolution of 1936, Erich Mühsam, Empress Elisabeth of Austria, Free association (communism and anarchism), general strike, Francesc Ferrer i Guàrdia, Catalan anarchist pedagogue and free-thinker, veganarchism, Traditional knowledge, Japanese Anarchist Federation, Diogenes of Sinope, Hierarchy, sexual revolution, Naturism, Bavarian Soviet Republic, February Revolution, Eugene Varlin, Renaissance humanism, Mexican Liberal Party, Friedrich Engels, Fernando Tarrida del Mármol, Caliphate, Marxism, Jesus, John Cage, Umanita Nova, Anarcho-pacifism, Peter Kropotkin, Religious anarchism, Anselme Bellegarrigue, civilisation, moral obligation, hedonist, Free Territory (Ukraine), -ism, neo-liberalism, Austrian School, philosophy, freethought, Joseph Goebbels, Conservatism, anarchist economics, Cavalier, Maximilien de Robespierre, Comstockery, Dorothy Day, Anarchism in France, Fédération anarchiste, World Economic Forum, Amparo Poch y Gascón, Sex Pistols, women's rights, collectivisation, Taoism, common ownership, William Batchelder Greene, Collective farming, popular education, biphobia, targeted killings, Protestant Christianity, state socialism, Marie François Sadi Carnot, Stephen Pearl Andrews, World Trade Organization, Communist Party of Spain (main), Pluto Press, Levante, Spain, Alexander Berkman, Wilhelm Weitling, Kharijites, Bolshevik, Liberty (1881–1908), Anarchist Aragon, social democrats, Dielo Truda, Post-left anarchy, Age of Enlightenment, Blanquism, Walden, mutual aid (organization), Far-left politics, privative, revolutions of 1848, anarchism and nationalism, punk rock, Étienne de La Boétie, Max Stirner, Jacobin (politics), agriculture, anarchy, Confederacion General del Trabajo de España, toleration, reformism, International Anarchist Congress of Amsterdam, The Ego and Its Own, Ukraine, Civil Disobedience (Thoreau), Spanish Civil War, David Graeber, Anarchism and issues related to love and sex, James Guillaume, Insurrectionary anarchism, Political repression, International Workers' Association, Barcelona, Bulgaria, Voline, Zeno of Citium, anarcho-communists, organized religion, libertarianism, bisexuality, Ricardo Flores Magón, Henri Zisly, Eight-hour day, Freetown Christiania, heteronormativity, Mikhail Bakunin, Propagandaministerium, Ezra Heywood, individual reappropriation, Modern School (United States), archon, Confédération nationale du travail, socialist movement, History of Islam, Max Nettlau, Political Justice, Reichstag fire, Anti-Christianity, decentralised, Issues in anarchism#Communism, deschooling, Christian movement, squatter, Anarchism in Germany, Catalonia, Louise Michel, Solidarity Federation, What is Property?, European individualist anarchism, Pierre-Joseph Proudhon, Mexican Revolution, wikt:anarchism, Blackshirts, Jewish anarchism, Russian Civil War, property rights, anti-authoritarian, individual reclamation, propaganda by the deed, from each according to his ability, to each according to his need, Feminist movement, Confiscation, social anarchism, Anarchism in Russia, Daniel Guérin, Uruguayan Anarchist Federation, Anarcha-feminism, Enragés, Cynicism (philosophy), workers' council, The Word (free love), Allen Ginsberg, Campaign for Nuclear Disarmament, antimilitarism, Workers' self-management, Federación Obrera Regional Argentina, self-governance, free market, Carlos I of Portugal, Simon Critchley, Anti-clericalism, heterosexual, Layla AbdelRahim, Mexican Anarchist Federation, Anarchism and Marxism, October Revolution, Anti-nuclear movement, Joseph Déjacque, Bolsheviks, Luigi Fabbri, morality, Communist party, Sam Dolgoff, united front, Ammon Hennacy, social ecology, commune (intentional community), Oscar Wilde, French Revolution, egoist anarchism, Comintern, transphobia, anarchism without adjectives, social control, means of production, Michel Onfray, Anarchism in France#The Fourth Republic (1945–1958), syndicalism, Anarchism in Spain, Iberian Anarchist Federation, International of Anarchist Federations, Emma Goldman, Netherlands, anarchist free school, International Workingmen's Association, Queer anarchism, Cantonal Revolution, trade unionism, Karl Marx, LGBT community, humanism, Anti-fascism, Carrara, political philosophy, Anarcho-transhumanism, libertarian socialist, Russian Revolution (1917), Two Cheers for Anarchism: Six Easy Pieces on Autonomy, Dignity, and Meaningful Work and Play, Emile Armand, insurrectionary anarchism, individual, Zhuang Zhou, Free Territory, White movement, Greenwich Village, Virginia Bolten, transcendentalist, public choice theory, wikt:brigand, Issues in anarchism#Participation in statist democracy, free love, Mutualism (economic theory), Anarchist St. Imier International, censorship, federalist, 6 February 1934 crisis, biennio rosso, anti-clerical, centralism, Anarchism: A Documentary History of Libertarian Ideas, minarchism, James C. Scott, First International, homosexuality, political theology, spontaneous order, Oranienburg concentration camp, anarcho-communism, negative liberty, post-modernism, Anarchism in Italy, Leopold Kohr, union of egoists, counterculture, Miguel Gimenez Igualada, philosophical anarchism, International Libertarian Solidarity, homosexual, Counterculture of the 1960s, Errico Malatesta, strikebreaker, Workers' Party of Marxist Unification, Clifford Harper, Reification (fallacy), patriarchy, anarchist law, Apostle (Christian), market (economics), Summerhill School, positive liberty, socialism, feminism, Direct action, Melchor Rodríguez García, William Godwin, Nazi concentration camps, Synthesist anarchism, Margaret Anderson, Han Ryner, Federation of Organized Trades and Labor Unions, technology, Workers Solidarity Movement, Edmund Burke, Encyclopædia Britannica, state (polity), Herbert Read, Park Güell, utilitarian, far right leagues, Limited government, self-ownership, Pejorative, homophobia, Industrial Workers of the World, The Dispossessed, Hague Congress (1872), Stalinism, Reciprocity (cultural anthropology), Fernand Pelloutier, individualist anarchism in France, The False Principle of our Education, individualist anarchism, Pierre Monatte, Soviet Union, counter-economics, Rudolf Rocker, Anarchism and capitalism, Parma, Black Rose Books, lesbian, Arditi del Popolo, Emile Armand (1872–1962), who propounded the virtues of free love in the Parisian anarchist milieu of the early 20th century, collectivism, Development criticism, John Henry Mackay, Benoît Broutchoux, Illegalism, Laozi, feminist, Christiaan Cornelissen, Syndicalist Workers' Federation, anarcho-syndicalism, Andalusia, Renzo Novatore, trade union, autonomist marxism, dictatorship of the proletariat, Mujeres Libres, Voltairine de Cleyre, Post-anarchism, participatory economics, Confederación Nacional del Trabajo, Syncretic politics, direct democracy, Jean-Jacques Rousseau, Green anarchism, Surrealism, labour unions, A. S. Neill, christian anarchist, Bonnot Gang, Anti-capitalism, Anarchism in Brazil, simple living, enlightened self-interest, Confédération générale du travail, class conflict, International Workers' Day, Hébertists, Gerrard Winstanley, Francoism, anarcho-pacifist, Andrej Grubacic, individualist anarchist and social anarchist thinkers., April Carter, private property, penal colonies, Libertarian socialism, Camillo Berneri, Christian anarchism, transhumanism, Lucifer, the Light-Bearer, Edna St. Vincent Millay, unschooling, Leo Tolstoy, M. E. Lazarus, Spanish Anarchists, Buddhist anarchism, ideology, William McKinley, anarcho-primitivism, Francesc Pi i Margall, :Category:Anarchism by country, International Workers Association, Anarcho-capitalism, Lois Waisbrooker, wikt:Solidarity, Baja California, social revolution, Unione Sindacale Italiana, Lev Chernyi, Alex Comfort, Sonnenburg, Leon Czolgosz, Volin, utopian, Argentine Libertarian Federation, Nudism, Left-wing market anarchism, insurrection, definitional concerns in anarchist theory, infinitive, affinity group, World Trade Organization Ministerial Conference of 1999 protest activity, class struggle, nonviolence, John Zerzan, poststructuralist, Noam Chomsky, Second Fitna, Julian Beck, Philadelphes, League of Peace and Freedom, Fédération Anarchiste, Kronstadt rebellion, Cold War, André Breton, Silvio Gesell, libertarian anarchism, voluntary association, anti-globalisation movement, birth control, L. Susan Brown, anarcho-naturism, personal property, Roundhead, Harold Barclay, The Joy of Sex, Council communism, Lucía Sánchez Saornil, tyrannicide, Neopaganism, lois scélérates, Johann Most, Anarchist Catalonia, Albert Camus, Protests of 1968, Alexander II of Russia, Spain's economy, Federazione Anarchica Italiana, Cuba, German Revolution of 1918–1919, stirner, Property is theft, Situationist International, law and economics

        ```

* Add support for [SMART notation](https://nlp.stanford.edu/IR-book/html/htmledition/document-and-query-weighting-schemes-1.html) for `TfidfModel`. Fix #1785 (__[@markroxor](https://github.com/markroxor)__, [#1791](https://github.com/RaRe-Technologies/gensim/pull/1791))
    - Natural extension of `TfidfModel` to allow different weighting and normalization schemes
        ```python
        from gensim.corpora import Dictionary
        from gensim.models import TfidfModel
        import gensim.downloader as api

        data = api.load(""text8"")
        dct = Dictionary(data)
        corpus = [dct.doc2bow(line) for line in data]

        # Train Tfidf model using the SMART notation, smartirs=""ntc"" where
        # 'n' - natural term frequency
        # 't' - idf document frequency
        # 'c' - cosine normalization
        #
        # More information about possible values available in documentation or https://nlp.stanford.edu/IR-book/html/htmledition/document-and-query-weighting-schemes-1.html

        model = TfidfModel(corpus, id2word=dct, smartirs=""ntc"")
        vectorized_corpus = list(model[corpus])

        ```
    - [SMART Information Retrieval System (wiki)](https://en.wikipedia.org/wiki/SMART_Information_Retrieval_System)

* Add CircleCI for building Gensim documentation. Fix #1807 (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1822](https://github.com/RaRe-Technologies/gensim/pull/1822))
    - An easy way to preview the rendered documentation (especially, if don't use Linux)
        - Go to ""Details"" link of CircleCI in your PR, click on the ""Artifacts"" tab, choose the HTML file that you want to view; a new tab will open with the rendered HTML page
    - Integration with Github, to see the documentation directly from the pull request page
        - Install a user-script plugin: [greasemonkey (for firefox)](https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/) or [tampermonkey (for chrome)](https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=en)
        - Add [this user-script](https://gist.github.com/menshikh-iv/bfe9b8ef2db10e9511aa9fe5935a7289) to the plugin
        - Now you’ll see a new button ""See CircleCI doc for this PR"" in each PR in the Gensim repository. Click it to see the full rendered documentation.


:red_circle: Bug fixes:
* Fix import in `get_my_ip`. Fix #1771 (__[@darindf](https://github.com/darindf)__, [#1772](https://github.com/RaRe-Technologies/gensim/pull/1772))
* Fix tox.ini/setup.cfg configuration (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1815](https://github.com/RaRe-Technologies/gensim/pull/1815))
* Fix formula in `gensim.summarization.bm25`. Fix #1828 (__[@sj29-innovate](https://github.com/sj29-innovate)__, [#1833](https://github.com/RaRe-Technologies/gensim/pull/1833))
* Fix the train method of `TranslationMatrix` (__[@robotcator](https://github.com/robotcator)__, [#1838](https://github.com/RaRe-Technologies/gensim/pull/1838))
* Fix positional params used for `gensim.models.CoherenceModel` in `gensim.models.callbacks` (__[@Alexjmsherman](https://github.com/Alexjmsherman)__, [#1823](https://github.com/RaRe-Technologies/gensim/pull/1823))
* Fix parameter setting for `FastText.train`. Fix #1818 (__[@sj29-innovate](https://github.com/sj29-innovate)__, [#1837](https://github.com/RaRe-Technologies/gensim/pull/1837))
* Pin python2 explicitly for building documentation (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1840](https://github.com/RaRe-Technologies/gensim/pull/1840))
* Remove dispatcher deadlock for distributed LDA (__[@darindf](https://github.com/darindf)__, [#1817](https://github.com/RaRe-Technologies/gensim/pull/1817))
* Fix `score_function` from `LexicalEntailmentEvaluation`. Fix #1858 (__[@hachibaka](https://github.com/hachibaka)__, [#1863](https://github.com/RaRe-Technologies/gensim/pull/1863))
* Fix symmetrical case for hellinger distance. Fix #1854 (__[@caiyulun](https://github.com/caiyulun)__, [#1860](https://github.com/RaRe-Technologies/gensim/pull/1860))
* Remove wrong logging at import. Fix #1706 (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1871](https://github.com/RaRe-Technologies/gensim/pull/1871))


:books: Tutorial and doc improvements:
* Refactor documentation API Reference for `gensim.summarization` (__[@yurkai](https://github.com/yurkai)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1709](https://github.com/RaRe-Technologies/gensim/pull/1709))
* Fix docstrings for `gensim.similarities.index`. Partial fix #1666 (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1681](https://github.com/RaRe-Technologies/gensim/pull/1681))
* Fix docstrings for `gensim.models.translation_matrix` (__[@KokuKUSIAKU](https://github.com/KokuKUSIAKU)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1806](https://github.com/RaRe-Technologies/gensim/pull/1806))
* Fix docstrings for `gensim.models.rpmodel` (__[@jazzmuesli](https://github.com/jazzmuesli)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1802](https://github.com/RaRe-Technologies/gensim/pull/1802))
* Fix docstrings for `gensim.utils` (__[@kakshay21](https://github.com/kakshay21)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1797](https://github.com/RaRe-Technologies/gensim/pull/1797))
* Fix docstrings for `gensim.matutils` (__[@Cheukting](https://github.com/Cheukting)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1804](https://github.com/RaRe-Technologies/gensim/pull/1804))
* Fix docstrings for `gensim.models.logentropy_model` (__[@minggli](https://github.com/minggli)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1803](https://github.com/RaRe-Technologies/gensim/pull/1803))
* Fix docstrings for `gensim.models.normmodel` (__[@AustenLamacraft](https://github.com/AustenLamacraft)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1805](https://github.com/RaRe-Technologies/gensim/pull/1805))
* Refactor API reference `gensim.topic_coherence`. Fix #1669 (__[@CLearERR](https://github.com/CLearERR)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1714](https://github.com/RaRe-Technologies/gensim/pull/1714))
* Fix documentation for `gensim.corpora.dictionary` and `gensim.corpora.hashdictionary`. Partial fix #1671 (__[@CLearERR](https://github.com/CLearERR)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1814](https://github.com/RaRe-Technologies/gensim/pull/1814))
* Fix documentation for `gensim.corpora`. Partial fix #1671 (__[@anotherbugmaster](https://github.com/anotherbugmaster)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1729](https://github.com/RaRe-Technologies/gensim/pull/1729))
* Update banner in doc pages (__[@piskvorky](https://github.com/piskvorky)__, [#1865](https://github.com/RaRe-Technologies/gensim/pull/1865))
* Fix errors in the doc2vec-lee notebook (__[@PeterHamilton](https://github.com/PeterHamilton)__, [#1841](https://github.com/RaRe-Technologies/gensim/pull/1841))
* Add wordnet mammal train file for Poincare notebook (__[@jayantj](https://github.com/jayantj)__, [#1781](https://github.com/RaRe-Technologies/gensim/pull/1781))
* Update Poincare notebooks (#1774) (__[@jayantj](https://github.com/jayantj)__, [#1774](https://github.com/RaRe-Technologies/gensim/pull/1774))
* Update contributing guide. Fix #1786 (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1793](https://github.com/RaRe-Technologies/gensim/pull/1793))
* Add `model_to_dict` one-liner to word2vec notebook. Fix #1269 (__[@kakshay21](https://github.com/kakshay21)__, [#1776](https://github.com/RaRe-Technologies/gensim/pull/1776))
* Add word embedding viz to word2vec notebook. Fix #1419 (__[@markroxor](https://github.com/markroxor)__, [#1800](https://github.com/RaRe-Technologies/gensim/pull/1800))
* Fix description of `sg` parameter for `gensim.models.FastText` (__[@akutuzov](https://github.com/akutuzov)__, [#1801](https://github.com/RaRe-Technologies/gensim/pull/1801))
* Fix typo in `doc2vec-IMDB`. Fix #1788 (__[@apoorvaeternity](https://github.com/apoorvaeternity)__, [#1796](https://github.com/RaRe-Technologies/gensim/pull/1796))
* Remove outdated bz2 examples from tutorials[2] (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1868](https://github.com/RaRe-Technologies/gensim/pull/1868))
* Remove outdated `bz2` + `MmCorpus` examples from tutorials (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1867](https://github.com/RaRe-Technologies/gensim/pull/1867))



:+1: Improvements:
* Refactor tests for `gensim.corpora.WikiCorpus` (__[@steremma](https://github.com/steremma)__, [#1821](https://github.com/RaRe-Technologies/gensim/pull/1821))


:warning: Deprecations (will be removed in the next major release)
* Remove
    - `gensim.models.wrappers.fasttext` (obsoleted by the new native `gensim.models.fasttext` implementation)
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki` (all of these obsoleted by the new native  `gensim.scripts.segment_wiki` implementation)
    - ""deprecated"" functions and attributes

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`
",1349775
583,False,False,2017-12-09T14:37:30Z,2017-12-09T19:19:21Z,"## 3.2.0, 2017-12-09

:star2: New features:

* **New download API for corpora and pre-trained models** (__[@chaitaliSaini](https://github.com/chaitaliSaini)__ & __[@menshikh-iv](https://github.com/menshikh-iv)__, [#1705](https://github.com/RaRe-Technologies/gensim/pull/1705) & [#1632](https://github.com/RaRe-Technologies/gensim/pull/1632) & [#1492](https://github.com/RaRe-Technologies/gensim/pull/1492))

    - Download large NLP datasets in one line of Python, then use with memory-efficient data streaming:
        ```python
        import gensim.downloader as api

        for article in api.load(""wiki-english-20171001""):
            print(article)

        ```
    - Don’t waste time searching for good word embeddings, use the curated ones:
        ```python
        import gensim.downloader as api

        model = api.load(""glove-twitter-25"")
        model.most_similar(""engineer"")

        # [('specialist', 0.957542896270752),
        #  ('developer', 0.9548177123069763),
        #  ('administrator', 0.9432312846183777),
        #  ('consultant', 0.93915855884552),
        #  ('technician', 0.9368376135826111),
        #  ('analyst', 0.9342101216316223),
        #  ('architect', 0.9257484674453735),
        #  ('engineering', 0.9159940481185913),
        #  ('systems', 0.9123805165290833),
        #  ('consulting', 0.9112802147865295)]
        ```
    - [Blog post](https://rare-technologies.com/new-api-for-pretrained-nlp-models-and-datasets-in-gensim/) introducing the API and design decisions.
  - [Jupyter notebook with examples](https://github.com/RaRe-Technologies/gensim/blob/be4500e4f0616ec2864c2ce70cb5d4db4b46512d/docs/notebooks/downloader_api_tutorial.ipynb)

* **New model: Poincaré embeddings** (__[@jayantj](https://github.com/jayantj)__, [#1696](https://github.com/RaRe-Technologies/gensim/pull/1696) & [#1700](https://github.com/RaRe-Technologies/gensim/pull/1700) & [#1757](https://github.com/RaRe-Technologies/gensim/pull/1757) & [#1734](https://github.com/RaRe-Technologies/gensim/pull/1734))
    - Embed a graph (taxonomy) in the same way as word2vec embeds words:
        ```python
        from gensim.models.poincare import PoincareRelations, PoincareModel
        from gensim.test.utils import datapath

        data = PoincareRelations(datapath('poincare_hypernyms.tsv'))
        model = PoincareModel(data)
        model.kv.most_similar(""cat.n.01"")

        # [('kangaroo.n.01', 0.010581353439700418),
        # ('gib.n.02', 0.011171531439892076),
        # ('striped_skunk.n.01', 0.012025106076442395),
        # ('metatherian.n.01', 0.01246679759214648),
        # ('mammal.n.01', 0.013281303506525968),
        # ('marsupial.n.01', 0.013941330203709653)]
        ```
    - [Tutorial on Poincaré embeddings](https://github.com/RaRe-Technologies/gensim/blob/920c029ca97f961c8df264672c34936607876694/docs/notebooks/Poincare%20Tutorial.ipynb) (Jupyter notebook).
    - [Model introduction and the journey of its implementation](https://rare-technologies.com/implementing-poincare-embeddings/) (blog post).
    - [Original paper](https://arxiv.org/abs/1705.08039) on arXiv.

* **Optimized FastText** (__[@manneshiva](https://github.com/manneshiva)__, [#1742](https://github.com/RaRe-Technologies/gensim/pull/1742))
  - **New fast multithreaded implementation of FastText**, natively in Python/Cython. Deprecates the existing wrapper for Facebook’s C++ implementation.
    ```python
    import gensim.downloader as api
    from gensim.models import FastText

    model = FastText(api.load(""text8""))
    model.most_similar(""cat"")

    # [('catnip', 0.8538144826889038),
    #  ('catwalk', 0.8136177062988281),
    #  ('catchy', 0.7828493118286133),
    #  ('caf', 0.7826495170593262),
    #  ('bobcat', 0.7745151519775391),
    #  ('tomcat', 0.7732658386230469),
    #  ('moat', 0.7728310823440552),
    #  ('caye', 0.7666271328926086),
    #  ('catv', 0.7651021480560303),
    #  ('caveat', 0.7643581628799438)]

    ```

* **Binary pre-compiled wheels for Windows, OSX and Linux** (__[@menshikh-iv](https://github.com/menshikh-iv)__, [MacPython/gensim-wheels/#7](https://github.com/MacPython/gensim-wheels/pull/7))
    - Users no longer need to have a C compiler for using the fast (Cythonized) version of word2vec, doc2vec, fasttext etc.
    - Faster Gensim pip installation

* Added `DeprecationWarnings` to deprecated methods and parameters, with a clear schedule for removal.

:+1: Improvements:
* Add Montemurro and Zanette's entropy based keyword extraction algorithm. Fix #665 (__[@PeteBleackley](https://github.com/PeteBleackley)__, [#1738](https://github.com/RaRe-Technologies/gensim/pull/1738))
* Fix flake8 E731, E402, refactor tests & sklearn API code. Partial fix #1644  (__[@horpto](https://github.com/horpto)__, [#1689](https://github.com/RaRe-Technologies/gensim/pull/1689))
* Reduce distribution size. Fix #1698 (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1699](https://github.com/RaRe-Technologies/gensim/pull/1699))
* Improve `scan_vocab` speed, `build_vocab_from_freq` method (__[@jodevak](https://github.com/jodevak)__, [#1695](https://github.com/RaRe-Technologies/gensim/pull/1695))
* Improve `segment_wiki` script (__[@piskvorky](https://github.com/piskvorky)__, [#1707](https://github.com/RaRe-Technologies/gensim/pull/1707))
* Add custom `dtype` support for `LdaModel`. Partially fix #1576 (__[@xelez](https://github.com/xelez)__, [#1656](https://github.com/RaRe-Technologies/gensim/pull/1656))
* Add `doc2idx` method for `gensim.corpora.Dictionary`. Fix #1634 (__[@roopalgarg](https://github.com/roopalgarg)__, [#1720](https://github.com/RaRe-Technologies/gensim/pull/1720))
* Add tox and pytest to gensim, integration with Travis and Appveyor. Fix #1613, #1644 (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1721](https://github.com/RaRe-Technologies/gensim/pull/1721))
* Add flag for hiding outdated data for `gensim.downloader.info` (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1736](https://github.com/RaRe-Technologies/gensim/pull/1736))
* Add reproducible order between Python versions for `gensim.corpora.Dictionary` (__[@formi23](https://github.com/formi23)__, [#1715](https://github.com/RaRe-Technologies/gensim/pull/1715))
* Update `tox.ini`, `setup.cfg`, `README.md` (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1741](https://github.com/RaRe-Technologies/gensim/pull/1741))
* Add optimized `logsumexp` for `LdaModel` (__[@arlenk](https://github.com/arlenk)__, [#1745](https://github.com/RaRe-Technologies/gensim/pull/1745))

:red_circle: Bug fixes:
* Fix ranking formula in `gensim.summarization.bm25`. Fix #1718 (__[@souravsingh](https://github.com/souravsingh)__, [#1726](https://github.com/RaRe-Technologies/gensim/pull/1726))
* Fixed incompatibility in persistence for `FastText` wrapper. Fix #1642 (__[@chinmayapancholi13](https://github.com/chinmayapancholi13)__, [#1723](https://github.com/RaRe-Technologies/gensim/pull/1723))
* Fix `gensim.sklearn_api` bug with `documents_columns` parameter. Fix #1676 (__[@chinmayapancholi13](https://github.com/chinmayapancholi13)__, [#1704](https://github.com/RaRe-Technologies/gensim/pull/1704))
* Fix slowdown of CI, remove pytest-cov (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1728](https://github.com/RaRe-Technologies/gensim/pull/1728))
* Replace outdated packages in Dockerfile (__[@rbahumi](https://github.com/rbahumi)__, [#1730](https://github.com/RaRe-Technologies/gensim/pull/1730))
* Replace `num_words` to `topn` in `LdaMallet.show_topics`. Fix #1747 (__[@apoorvaeternity](https://github.com/apoorvaeternity)__, [#1749](https://github.com/RaRe-Technologies/gensim/pull/1749))
* Fix `os.rename` from `gensim.downloader` when 'src' and 'dst' on different partitions (__[@anotherbugmaster](https://github.com/anotherbugmaster)__, [#1733](https://github.com/RaRe-Technologies/gensim/pull/1733))
* Fix `DeprecationWarning` from `logsumexp` (__[@dreamgonfly](https://github.com/dreamgonfly)__, [#1703](https://github.com/RaRe-Technologies/gensim/pull/1703))
* Fix backward compatibility problem in `Phrases.load`. Fix #1751 (__[@alexgarel](https://github.com/alexgarel)__, [#1758](https://github.com/RaRe-Technologies/gensim/pull/1758))
* Fix `load_word2vec_format` from `FastText`. Fix #1743 (__[@manneshiva](https://github.com/manneshiva)__, [#1755](https://github.com/RaRe-Technologies/gensim/pull/1755))
* Fix ipython kernel version in `Dockerfile`. Fix #1762 (__[@rbahumi](https://github.com/rbahumi)__, [#1764](https://github.com/RaRe-Technologies/gensim/pull/1764))
* Fix writing in `segment_wiki` (__[@horpto](https://github.com/horpto)__, [#1763](https://github.com/RaRe-Technologies/gensim/pull/1763))
* Fix write method of file requires byte-like object in `segment_wiki` (__[@horpto](https://github.com/horpto)__, [#1750](https://github.com/RaRe-Technologies/gensim/pull/1750))
* Fix incorrect vectors learned during online training for `FastText`. Fix #1752 (__[@manneshiva](https://github.com/manneshiva)__, [#1756](https://github.com/RaRe-Technologies/gensim/pull/1756))
* Fix `dtype` of `model.wv.syn0_vocab` on updating `vocab` for `FastText`. Fix  #1759 (__[@manneshiva](https://github.com/manneshiva)__, [#1760](https://github.com/RaRe-Technologies/gensim/pull/1760))
* Fix hashing-trick from `FastText.build_vocab`. Fix #1765 (__[@manneshiva](https://github.com/manneshiva)__, [#1768](https://github.com/RaRe-Technologies/gensim/pull/1768))
* Add explicit `DeprecationWarning` for all outdated stuff. Fix #1753 (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1769](https://github.com/RaRe-Technologies/gensim/pull/1769))
* Fix epsilon according to `dtype` in `LdaModel` (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1770](https://github.com/RaRe-Technologies/gensim/pull/1770))

:books: Tutorial and doc improvements:
* Update perf numbers of `segment_wiki` (__[@piskvorky](https://github.com/piskvorky)__, [#1708](https://github.com/RaRe-Technologies/gensim/pull/1708))
* Update docstring for `gensim.summarization.summarize`. Fix #1575 (__[@fbarrios](https://github.com/fbarrios)__, [#1702](https://github.com/RaRe-Technologies/gensim/pull/1702))
* Refactor API Reference for `gensim.parsing`. Fix #1664 (__[@CLearERR](https://github.com/CLearERR)__, [#1684](https://github.com/RaRe-Technologies/gensim/pull/1684))
* Fix typos in doc2vec-wikipedia notebook (__[@youqad](https://github.com/youqad)__, [#1727](https://github.com/RaRe-Technologies/gensim/pull/1727))
* Fix PyPI long description rendering (__[@edigaryev](https://github.com/edigaryev)__, [#1739](https://github.com/RaRe-Technologies/gensim/pull/1739))
* Fix twitter badge src  (__[@menshikh-iv](https://github.com/menshikh-iv)__)
* Fix maillist badge color (__[@menshikh-iv](https://github.com/menshikh-iv)__)

:warning: Deprecations (will be removed in the next major release)
* Remove
    - `gensim.examples`
    - `gensim.nosy`
    - `gensim.scripts.word2vec_standalone`
    - `gensim.scripts.make_wiki_lemma`
    - `gensim.scripts.make_wiki_online`
    - `gensim.scripts.make_wiki_online_lemma`
    - `gensim.scripts.make_wiki_online_nodebug`
    - `gensim.scripts.make_wiki`

* Move
    - `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
    - `gensim.summarization` ➡ `gensim.models.summarization`
    - `gensim.topic_coherence` ➡ `gensim.models._coherence`
    - `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
    - `gensim.parsing.*` ➡ `gensim.utils.text_utils`
",1349775
584,False,False,2017-11-06T12:33:58Z,2017-11-06T16:56:05Z,"## 3.1.0, 2017-11-06


:star2: New features:
* Massive optimizations to LSI model training (__[@isamaru](https://github.com/isamaru)__, [#1620](https://github.com/RaRe-Technologies/gensim/pull/1620) & [#1622](https://github.com/RaRe-Technologies/gensim/pull/1622))
  - LSI model allows use of single precision (float32), to consume  *40% less memory* while being *40% faster*.
  - LSI model can now also accept CSC matrix as input, for further memory and speed boost.
  - Overall, if your entire corpus fits in RAM: 3x faster LSI training (SVD) in 4x less memory!

    ```python
    # just an example; the corpus stream is up to you
    streaming_corpus = gensim.corpora.MmCorpus(""my_tfidf_corpus.mm.gz"")

    # convert your corpus to a CSC sparse matrix (assumes the entire corpus fits in RAM)
    in_memory_csc_matrix = gensim.matutils.corpus2csc(streaming_corpus, dtype=np.float32)

    # then pass the CSC to LsiModel directly
    model = LsiModel(corpus=in_memory_csc_matrix, num_topics=500, dtype=np.float32)
    ```

  - Even if you continue to use streaming corpora (your training dataset is too large for RAM), you should see significantly faster processing times and a lower memory footprint. In our experiments with a very large LSI model, we saw a drop from 29 GB peak RAM and 38 minutes (before) to 19 GB peak RAM and 26 minutes (now):

    ```python
    model = LsiModel(corpus=streaming_corpus, num_topics=500, dtype=np.float32)
    ```

* Add common terms to Phrases. Fix #1258 (__[@alexgarel](https://github.com/alexgarel)__, [#1568](https://github.com/RaRe-Technologies/gensim/pull/1568))
  - Phrases allows to use common terms in bigrams. Before, if you are searching to reveal ngrams like `car_with_driver` and `car_without_driver`, you can either remove stop words before processing, but you will only find `car_driver`, or you won't find any of those forms (because they have three words, but also because high frequency of with will avoid them to be scored correctly), inspired by [ES common grams token filter](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-common-grams-tokenfilter.html).

    ```python
    phr_old = Phrases(corpus)
    phr_new = Phrases(corpus, common_terms=stopwords.words('en'))

    print(phr_old[[""we"", ""provide"", ""car"", ""with"", ""driver""]])  # [""we"", ""provide"", ""car_with"", ""driver""]
    print(phr_new[[""we"", ""provide"", ""car"", ""with"", ""driver""]])  # [""we"", ""provide"", ""car_with_driver""]
    ```

* New [segment_wiki.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/scripts/segment_wiki.py) script (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1483](https://github.com/RaRe-Technologies/gensim/pull/1483) & [#1694](https://github.com/RaRe-Technologies/gensim/pull/1694))
  - CLI script for processing a raw Wikipedia dump (the xml.bz2 format provided by MediaWiki) to extract its articles in a plain text format. It extracts each article's title, section names and section content and saves them as json-line:

    ```bash
    python -m gensim.scripts.segment_wiki -f enwiki-latest-pages-articles.xml.bz2 | gzip > enwiki-latest-pages-articles.json.gz
    ```

     Processing the entire English Wikipedia dump (13.5 GB, link [here](https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2)) takes about 2.5 hours (i7-6700HQ, SSD).

     The output format is one article per line, serialized into JSON:

     ```python
      for line in smart_open('enwiki-latest-pages-articles.json.gz'):  # read the file we just created
          article = json.loads(line)
          print(""Article title: %s"" % article['title'])
          for section_title, section_text in zip(article['section_titles'], article['section_texts']):
              print(""Section title: %s"" % section_title)
              print(""Section text: %s"" % section_text)
      ```

:+1: Improvements:
* Speedup FastText tests (__[@horpto](https://github.com/horpto)__, [#1686](https://github.com/RaRe-Technologies/gensim/pull/1686))
* Add optimization for `SlicedCorpus.__len__` (__[@horpto](https://github.com/horpto)__, [#1679](https://github.com/RaRe-Technologies/gensim/pull/1679))
* Make `word_vec` return immutable vector. Fix #1651 (__[@CLearERR](https://github.com/CLearERR)__, [#1662](https://github.com/RaRe-Technologies/gensim/pull/1662))
* Drop Win x32 support & add rolling builds (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1652](https://github.com/RaRe-Technologies/gensim/pull/1652))
* Fix scoring function in Phrases. Fix #1533, #1635 (__[@michaelwsherman](https://github.com/michaelwsherman)__, [#1573](https://github.com/RaRe-Technologies/gensim/pull/1573))
* Add configuration for flake8 to setup.cfg (__[@mcobzarenco](https://github.com/mcobzarenco)__, [#1636](https://github.com/RaRe-Technologies/gensim/pull/1636))
* Add `build_vocab_from_freq` to Word2Vec, speedup scan\_vocab (__[@jodevak](https://github.com/jodevak)__, [#1599](https://github.com/RaRe-Technologies/gensim/pull/1599))
* Add `most_similar_to_given` method for KeyedVectors (__[@TheMathMajor](https://github.com/TheMathMajor)__, [#1582](https://github.com/RaRe-Technologies/gensim/pull/1582))
* Add `__getitem__` method to Sparse2Corpus to allow direct queries (__[@isamaru](https://github.com/isamaru)__, [#1621](https://github.com/RaRe-Technologies/gensim/pull/1621))

:red_circle: Bug fixes:
* Add single core mode to CoherenceModel. Fix #1683 (__[@horpto](https://github.com/horpto)__, [#1685](https://github.com/RaRe-Technologies/gensim/pull/1685))
* Fix ResourceWarnings in tests. Partially fix #1519 (__[@horpto](https://github.com/horpto)__, [#1660](https://github.com/RaRe-Technologies/gensim/pull/1660))
* Fix DeprecationWarnings generated by deprecated assertEquals. Partial fix #1519 (__[@poornagurram](https://github.com/poornagurram)__, [#1658](https://github.com/RaRe-Technologies/gensim/pull/1658))
* Fix DeprecationWarnings for regex string literals. Fix #1646 (__[@franklsf95](https://github.com/franklsf95)__, [#1649](https://github.com/RaRe-Technologies/gensim/pull/1649))
* Fix pagerank algorithm. Fix #805 (__[@xelez](https://github.com/xelez)__, [#1653](https://github.com/RaRe-Technologies/gensim/pull/1653))
* Fix FastText inconsistent dtype. Fix #1637 (__[@mcobzarenco](https://github.com/mcobzarenco)__, [#1638](https://github.com/RaRe-Technologies/gensim/pull/1638))
* Fix `test_filename_filtering` test (__[@nehaljwani](https://github.com/nehaljwani)__, [#1647](https://github.com/RaRe-Technologies/gensim/pull/1647))

:books: Tutorial and doc improvements:
* Fix code/docstring style (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1650](https://github.com/RaRe-Technologies/gensim/pull/1650))
* Update error message for supervised FastText. Fix #1498 (__[@ElSaico](https://github.com/ElSaico)__, [#1645](https://github.com/RaRe-Technologies/gensim/pull/1645))
* Add ""DOI badge"" to README. Fix #1610 (__[@dphov](https://github.com/dphov)__, [#1639](https://github.com/RaRe-Technologies/gensim/pull/1639))
* Remove duplicate annoy notebook. Fix #1415 (__[@Karamax](https://github.com/Karamax)__, [#1640](https://github.com/RaRe-Technologies/gensim/pull/1640))
* Fix duplication and wrong markup in docs (__[@horpto](https://github.com/horpto)__, [#1633](https://github.com/RaRe-Technologies/gensim/pull/1633))
* Refactor dendrogram & topic network notebooks (__[@parulsethi](https://github.com/parulsethi)__, [#1571](https://github.com/RaRe-Technologies/gensim/pull/1571))
* Fix release badge (__[@menshikh-iv](https://github.com/menshikh-iv)__, [#1631](https://github.com/RaRe-Technologies/gensim/pull/1631))

:warning: Deprecation part (will come into force in the next major release)
* Remove
	- `gensim.examples`
	- `gensim.nosy`
	- `gensim.scripts.word2vec_standalone`
	- `gensim.scripts.make_wiki_lemma`
	- `gensim.scripts.make_wiki_online`
	- `gensim.scripts.make_wiki_online_lemma`
	- `gensim.scripts.make_wiki_online_nodebug`
	- `gensim.scripts.make_wiki`

* Move
	- `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
	- `gensim.summarization` ➡ `gensim.models.summarization`
	- `gensim.topic_coherence` ➡ `gensim.models._coherence`
	- `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
	- `gensim.parsing.*` ➡ `gensim.utils.text_utils`

Also, we'll create `experimental` subpackage for unstable models. Specific lists will be available in the next major release.
",1349775
585,False,False,2017-10-12T08:44:52Z,2017-10-12T10:11:01Z,"## 3.0.1, 2017-10-12

:red_circle: Bug fixes:
* Fix Keras import, speedup importing time. Fix #1614 (@menshikh-v, [#1615](https://github.com/RaRe-Technologies/gensim/pull/1615))
* Fix Sphinx warnings and retrieve all missing .rst (@anotherbugmaster and @menshikh-iv, [#1612](https://github.com/RaRe-Technologies/gensim/pull/1612))
* Fix logger message in lsi_dispatcher (@lorosanu, [#1603](https://github.com/RaRe-Technologies/gensim/pull/1603))


:books: Tutorial and doc improvements:
* Fix spelling (@jberkel, [#1625](https://github.com/RaRe-Technologies/gensim/pull/1625))

:warning: Deprecation part (will come into force in the next release)
* Remove
	- `gensim.examples`
	- `gensim.nosy`
	- `gensim.scripts.word2vec_standalone`
	- `gensim.scripts.make_wiki_lemma`
	- `gensim.scripts.make_wiki_online`
	- `gensim.scripts.make_wiki_online_lemma`
	- `gensim.scripts.make_wiki_online_nodebug`
	- `gensim.scripts.make_wiki`

* Move
	- `gensim.scripts.make_wikicorpus` ➡ `gensim.scripts.make_wiki.py`
	- `gensim.summarization` ➡ `gensim.models.summarization`
	- `gensim.topic_coherence` ➡ `gensim.models._coherence`
	- `gensim.utils` ➡ `gensim.utils.utils` (old imports will continue to work)
	- `gensim.parsing.*` ➡ `gensim.utils.text_utils`

Also, we'll create `experimental` subpackage for unstable models. Specific lists will be available in the next release.

",1349775
586,False,False,2017-09-27T08:57:31Z,2017-09-27T09:00:16Z,"## 3.0.0, 2017-09-27


:star2: New features:
* Add unsupervised FastText to Gensim (@chinmayapancholi13, [#1525](https://github.com/RaRe-Technologies/gensim/pull/1525))
* Add sklearn API for gensim models (@chinmayapancholi13, [#1462](https://github.com/RaRe-Technologies/gensim/pull/1462))
* Add callback metrics for LdaModel and integration with Visdom (@parulsethi, [#1399](https://github.com/RaRe-Technologies/gensim/pull/1399))
* Add TranslationMatrix model (@robotcator, [#1434](https://github.com/RaRe-Technologies/gensim/pull/1434))
* Add word2vec-based coherence. Fix #1380 (@macks22, [#1530](https://github.com/RaRe-Technologies/gensim/pull/1530))


:+1: Improvements:
* Add 'diagonal' parameter for LdaModel.diff (@parulsethi, [#1448](https://github.com/RaRe-Technologies/gensim/pull/1448))
* Add 'score' function for SklLdaModel (@chinmayapancholi13, [#1445](https://github.com/RaRe-Technologies/gensim/pull/1445))
* Update sklearn API for gensim models (@chinmayapancholi13, [#1473](https://github.com/RaRe-Technologies/gensim/pull/1473)) [:warning: breaks backward compatibility]
* Add CoherenceModel to LdaModel.top_topics. Fix #1128 (@macks22, [#1427](https://github.com/RaRe-Technologies/gensim/pull/1427))
* Add dendrogram viz for topics and JS metric (@parulsethi, [#1484](https://github.com/RaRe-Technologies/gensim/pull/1484))
* Add topic network viz (@parulsethi, [#1536](https://github.com/RaRe-Technologies/gensim/pull/1536))
* Replace viewitems to iteritems. Fix #1495 (@HodorTheCoder, [#1508](https://github.com/RaRe-Technologies/gensim/pull/1508))
* Fix Travis config and add style-checking for Ipython Notebooks. Fix #1518, #1520 (@menshikh-iv, [#1522](https://github.com/RaRe-Technologies/gensim/pull/1522))
* Remove mutable args from definitions. Fix #1561 (@zsef123, [#1562](https://github.com/RaRe-Technologies/gensim/pull/1562))
* Add Appveyour for all PRs. Fix #1565 (@menshikh-iv, [#1565](https://github.com/RaRe-Technologies/gensim/pull/1565))
* Refactor code by PEP8. Partially fix #1521 (@zsef123, [#1550](https://github.com/RaRe-Technologies/gensim/pull/1550))
* Refactor code by PEP8 with additional limitations. Fix #1521 (@menshikh-iv, [#1569](https://github.com/RaRe-Technologies/gensim/pull/1569))
* Update FastTextKeyedVectors.\_\_contains\_\_ (@ELind77, [#1499](https://github.com/RaRe-Technologies/gensim/pull/1499))
* Update WikiCorpus tokenization. Fix #1534 (@roopalgarg, [#1537](https://github.com/RaRe-Technologies/gensim/pull/1537))


:red_circle: Bug fixes:
* Remove round in LdaSeqModel.print_topic. Fix #1480 (@menshikh-iv, [#1547](https://github.com/RaRe-Technologies/gensim/pull/1547))
* Fix TextCorpus.samle_text (@menshikh-iv, [#1548](https://github.com/RaRe-Technologies/gensim/pull/1548))
* Fix Mallet wrapper and tests for HDPTransform (@menshikh-iv, [#1555](https://github.com/RaRe-Technologies/gensim/pull/1555))
* Fix incorrect initialization ShardedCorpus with a generator. Fix #1511 (@karkkainenk1, [#1512](https://github.com/RaRe-Technologies/gensim/pull/1512))
* Add verification when summarize_corpus returns null. Fix #1531 (@fbarrios, [#1570](https://github.com/RaRe-Technologies/gensim/pull/1570))
* Fix doctag unicode problem. Fix 1543 (@englhardt, [#1544](https://github.com/RaRe-Technologies/gensim/pull/1544))
* Fix Translation Matrix (@robotcator, [#1594](https://github.com/RaRe-Technologies/gensim/pull/1594))
* Add trainable flag to KeyedVectors.get_embedding_layer. Fix #1557 (@zsef123, [#1558](https://github.com/RaRe-Technologies/gensim/pull/1558))


:books: Tutorial and doc improvements:
* Update exception text in TextCorpus.samle_text. Partial fix #308 (@vlejd, [#1444](https://github.com/RaRe-Technologies/gensim/pull/1444))
* Remove extra filter_token from tutorial (@VorontsovIE, [#1502](https://github.com/RaRe-Technologies/gensim/pull/1502))
* Update Doc2Vec-IMDB notebook (@pahdo, [#1476](https://github.com/RaRe-Technologies/gensim/pull/1476))
* Add Google Tag Manager for site (@yardos, [#1556](https://github.com/RaRe-Technologies/gensim/pull/1556))
* Update docstring explaining lack of multistream support in WikiCopus. Fix #1496 (@polm and @menshikh-iv, [#1515](https://github.com/RaRe-Technologies/gensim/pull/1515))
* Fix PathLineSentences docstring (@gojomo)
* Fix typos from Translation Matrix notebook (@robotcator, [#1598](https://github.com/RaRe-Technologies/gensim/pull/1598))",1349775
587,False,False,2017-07-25T12:52:34Z,2017-07-25T14:11:28Z,"## 2.3.0, 2017-07-25


:star2: New features:
* Add Dockerfile for gensim with external wrappers (@parulsethi, [#1368](https://github.com/RaRe-Technologies/gensim/pull/1368))
* Add sklearn wrapper for Word2Vec (@chinmayapancholi13, [#1437](https://github.com/RaRe-Technologies/gensim/pull/1437))
* Add loss function for Word2Vec. Fix #999 (@chinmayapancholi13, [#1201](https://github.com/RaRe-Technologies/gensim/pull/1201))
* Add sklearn wrapper for AuthorTopic model (@chinmayapancholi13, [#1403](https://github.com/RaRe-Technologies/gensim/pull/1403))


:+1: Improvements:
* Remove unittest2 (@souravsingh, [#1490](https://github.com/RaRe-Technologies/gensim/pull/1490))
* Add multiple scoring methods for Phrases. Partial fix #1363 (@michaelwsherman, [#1464](https://github.com/RaRe-Technologies/gensim/pull/1464))
* Add WordRank wrapper to Dockerfile (@parulsethi, [#1460](https://github.com/RaRe-Technologies/gensim/pull/1460))
* Add PathLineSentences. Fix #1364 (@michaelwsherman, [#1423](https://github.com/RaRe-Technologies/gensim/pull/1423))
* Add TextDirectoryCorpus and refactor TextCorpus. Fix #1387 (@macks22, [#1459](https://github.com/RaRe-Technologies/gensim/pull/1459))
* Add sparse input support with topn parameter in any2sparse. Fix #1294 (@manneshiva, [#1321](https://github.com/RaRe-Technologies/gensim/pull/1321))
* Add seed and length for sample_text. Partial fix #308 (@vlejd, [#1422](https://github.com/RaRe-Technologies/gensim/pull/1422))
* Add word_ngram parameter to FastText (@fsonntag, [#1432](https://github.com/RaRe-Technologies/gensim/pull/1432))


:red_circle: Bug fixes:
* Fix fastText loading from .bin file. Fix #1236 (@prakhar2b, [#1341](https://github.com/RaRe-Technologies/gensim/pull/1341))
* Fix paths in WordRank and running gensim version in Dockerfile (@parulsethi, [#1503](https://github.com/RaRe-Technologies/gensim/pull/1503))
* Fix commit version for gensim in Dockerfile (@parulsethi, [#1491](https://github.com/RaRe-Technologies/gensim/pull/1491))
* Fix encoding problems with tests on windows. Fix #1441 (@menshikh-iv, [#1469](https://github.com/RaRe-Technologies/gensim/pull/1469))
* Fix parameters in score_cbow_pair (@jmhessel, [#1468](https://github.com/RaRe-Technologies/gensim/pull/1468))
* Fix parameters in score_sentence_cbow (@jmhessel, [#1467](https://github.com/RaRe-Technologies/gensim/pull/1467))
* Fix TextDirectoryCorpus on windows (@macks22, [#1463](https://github.com/RaRe-Technologies/gensim/pull/1463))
* Fix gensim version in Dockerfile (@parulsethi, [#1456](https://github.com/RaRe-Technologies/gensim/pull/1456))
* Fix WordOccurenceAccumulator on windows. Fix #1441 (@macks22, [#1449](https://github.com/RaRe-Technologies/gensim/pull/1449))
* Fix scipy/numpy requirements (downgrade). Fix #1450 (@menshikh-iv, [#1450](https://github.com/RaRe-Technologies/gensim/pull/1450))


:books: Tutorial and doc improvements:
* Fix links and spaces in quick start guide (@iamsanten, [#1500](https://github.com/RaRe-Technologies/gensim/pull/1500))
* Fix error of ConcatedDoc2Vec in doc2vec-imdb notebook (@robocator, [#1377](https://github.com/RaRe-Technologies/gensim/pull/1377))
* Fix Sphinx warnings. Fix #1192 (@prerna135, [#1442](https://github.com/RaRe-Technologies/gensim/pull/1442))
* Fix typo in LdaModel.diff method (@parulsethi, [#1461](https://github.com/RaRe-Technologies/gensim/pull/1461))
* Add Tensorboard visualization for LDA (@parulsethi, [#1396](https://github.com/RaRe-Technologies/gensim/pull/1396))
* Update old and add new notebook with CoherenceModel (@macks22, [#1431](https://github.com/RaRe-Technologies/gensim/pull/1431))

",1349775
588,False,False,2017-06-21T16:59:43Z,2017-06-21T17:05:02Z,"## 2.2.0, 2017-06-21


:star2: New features:
* Add sklearn wrapper for RpModel (@chinmayapancholi13, [#1395](https://github.com/RaRe-Technologies/gensim/pull/1395))
* Add sklearn wrappers for LdaModel and LsiModel (@chinmayapancholi13, [#1398](https://github.com/RaRe-Technologies/gensim/pull/1398))
* Add sklearn wrapper for LdaSeq (@chinmayapancholi13, [#1405](https://github.com/RaRe-Technologies/gensim/pull/1405))
* Add keras wrapper for Word2Vec model (@chinmayapancholi13, [#1248](https://github.com/RaRe-Technologies/gensim/pull/1248))
* Add LdaModel.diff method (@menshikh-iv, [#1334](https://github.com/RaRe-Technologies/gensim/pull/1334))
* Allow use of truncated Dictionary for coherence measures. Fix #1342 (@macks22, [#1349](https://github.com/RaRe-Technologies/gensim/pull/1349))


:+1: Improvements:
* Fix save_as_text/load_as_text for Dictionary (@vlejd, [#1402](https://github.com/RaRe-Technologies/gensim/pull/1402))
* Add sampling support for corpus. Fix #308 (@vlejd, [#1408](https://github.com/RaRe-Technologies/gensim/pull/1408))
* Add napoleon extension to sphinx (@rasto2211, [#1411](https://github.com/RaRe-Technologies/gensim/pull/1411))
* Add KeyedVectors support to AnnoyIndexer (@quole, [#1318](https://github.com/RaRe-Technologies/gensim/pull/1318))
* Add BaseSklearnWrapper (@chinmayapancholi13, [#1383](https://github.com/RaRe-Technologies/gensim/pull/1383))
* Replace num_words to topn in model for unification. Fix #1198 (@prakhar2b, [#1200](https://github.com/RaRe-Technologies/gensim/pull/1200))
* Rename out_path to out_name & add logging for WordRank model. Fix #1310 (@parulsethi, [#1332](https://github.com/RaRe-Technologies/gensim/pull/1332))
* Remove multiple iterations of corpus in p_boolean_document (@danielchamberlain, [#1325](https://github.com/RaRe-Technologies/gensim/pull/1325))
* Fix codestyle in TfIdf (@piskvorky, [#1313](https://github.com/RaRe-Technologies/gensim/pull/1313))
* Fix warnings from Sphinx. Partial fix #1192 (@souravsingh, [#1330](https://github.com/RaRe-Technologies/gensim/pull/1330))
* Add test_env to setup.py (@menshikh-iv, [#1336](https://github.com/RaRe-Technologies/gensim/pull/1336))


:red_circle: Bug fixes:
* Add cleanup in annoy test (@prakhar2b, [#1420](https://github.com/RaRe-Technologies/gensim/pull/1420))
* Add cleanup in lda backprop test (@prakhar2b, [#1417](https://github.com/RaRe-Technologies/gensim/pull/1417))
* Fix out-of-vocab in FastText (@jayantj, [#1409](https://github.com/RaRe-Technologies/gensim/pull/1409))
* Add cleanup in WordRank test (@parulsethi, [#1410](https://github.com/RaRe-Technologies/gensim/pull/1410))
* Fix rest requirements in Travis. Partial fix #1393 (@ibrahimsharaf, @menshikh-iv, [#1400](https://github.com/RaRe-Technologies/gensim/pull/1400))
* Fix morfessor exception. Partial fix #1324 (@souravsingh, [#1406](https://github.com/RaRe-Technologies/gensim/pull/1406))
* Fix test for FastText (@prakhar2b, [#1371](https://github.com/RaRe-Technologies/gensim/pull/1371))
* Fix WikiCorpus (@alekol, [#1333](https://github.com/RaRe-Technologies/gensim/pull/1333))
* Fix backward incompatibility for LdaModel (@chinmayapancholi13, [#1327](https://github.com/RaRe-Technologies/gensim/pull/1327))
* Fix support for old and new FastText model format. Fix #1301 (@prakhar2b, [#1319](https://github.com/RaRe-Technologies/gensim/pull/1319))
* Fix wrapper tests. Fix #1323 (@shubhamjain74, [#1359](https://github.com/RaRe-Technologies/gensim/pull/1359))
* Update export_phrases method. Fix #794 (@toumorokoshi, [#1362](https://github.com/RaRe-Technologies/gensim/pull/1362))
* Fix sklearn exception in test (@souravsingh, [#1350](https://github.com/RaRe-Technologies/gensim/pull/1350))


:books: Tutorial and doc improvements:
* Fix incorrect link in tutorials (@aneesh-joshi, [#1426](https://github.com/RaRe-Technologies/gensim/pull/1426))
* Add notebook with sklearn wrapper examples (@chinmayapancholi13, [#1428](https://github.com/RaRe-Technologies/gensim/pull/1428))
* Replace absolute pathes to relative in notebooks (@vochicong, [#1414](https://github.com/RaRe-Technologies/gensim/pull/1414))
* Fix code-style in keras notebook (@chinmayapancholi13, [#1394](https://github.com/RaRe-Technologies/gensim/pull/1394))
* Replace absolute pathes to relative in notebooks (@vochicong, [#1407](https://github.com/RaRe-Technologies/gensim/pull/1407))
* Fix typo in quickstart guide (@vochicong, [#1404](https://github.com/RaRe-Technologies/gensim/pull/1404))
* Update docstring for WordRank. Fix #1384 (@parulsethi, [#1378](https://github.com/RaRe-Technologies/gensim/pull/1378))
* Update docstring for SkLdaModel (@chinmayapancholi13, [#1382](https://github.com/RaRe-Technologies/gensim/pull/1382))
* Update logic for updatetype in LdaModel (@chinmayapancholi13, [#1389](https://github.com/RaRe-Technologies/gensim/pull/1389))
* Update docstring for Doc2Vec (@jstol, [#1379](https://github.com/RaRe-Technologies/gensim/pull/1379))
* Fix docstring for KL-distance (@viciousstar, [#1373](https://github.com/RaRe-Technologies/gensim/pull/1373))
* Update Corpora_and_Vector_Spaces tutorial (@charliejharrison, [#1308](https://github.com/RaRe-Technologies/gensim/pull/1308))
* Add visualization for difference between LdaModel (@menshikh-iv, [#1374](https://github.com/RaRe-Technologies/gensim/pull/1374))
* Fix punctuation & typo in changelog (@piskvorky, @menshikh-iv, [#1366](https://github.com/RaRe-Technologies/gensim/pull/1366))
* Fix PEP8 & typo in several PRs (@menshikh-iv, [#1369](https://github.com/RaRe-Technologies/gensim/pull/1369))
* Update docstrings connected with backward compability in for LdaModel (@chinmayapancholi13, [#1365](https://github.com/RaRe-Technologies/gensim/pull/1365))
* Update Corpora_and_Vector_Spaces tutorial (@schuyler1d, [#1360](https://github.com/RaRe-Technologies/gensim/pull/1360))
* Fix typo in Doc2Vec doctsring (@fujiyuu75, [#1356](https://github.com/RaRe-Technologies/gensim/pull/1356))
* Update Annoy tutorial (@pmbaumgartner, [#1355](https://github.com/RaRe-Technologies/gensim/pull/1355))
* Update temp folder in tutorials (@yl2526, [#1352](https://github.com/RaRe-Technologies/gensim/pull/1352))
* Remove spaces after print in Topics_and_Transformation tutorial (@gsimore, [#1354](https://github.com/RaRe-Technologies/gensim/pull/1354))
* Update Dictionary docstring (@oonska, [#1347](https://github.com/RaRe-Technologies/gensim/pull/1347))
* Add section headings in word2vec notebook (@MikeTheReader, [#1348](https://github.com/RaRe-Technologies/gensim/pull/1348))
* Fix broken urls in starter tutorials (@ka7eh, [#1346](https://github.com/RaRe-Technologies/gensim/pull/1346))
* Update quick start notebook (@yardsale8, [#1345](https://github.com/RaRe-Technologies/gensim/pull/1345))
* Fix typo in quick start notebook (@MikeTheReader, [#1344](https://github.com/RaRe-Technologies/gensim/pull/1344))
* Fix docstring in keyedvectors (@chinmayapancholi13, [#1337](https://github.com/RaRe-Technologies/gensim/pull/1337))",1349775
589,False,False,2017-05-12T11:47:03Z,2017-05-12T11:49:27Z,"## 2.1.0, 2017-05-12

:star2: New features:
* Add modified save_word2vec_format for Doc2Vec, to save document vectors. (@parulsethi, [#1256](https://github.com/RaRe-Technologies/gensim/pull/1256))


:+1: Improvements:
* Add automatic code style check limited only to the code modified in PR (@tmylk, [#1287](https://github.com/RaRe-Technologies/gensim/pull/1287))
* Replace `logger.warn` by `logger.warning` (@chinmayapancholi13, [#1295](https://github.com/RaRe-Technologies/gensim/pull/1295))
* Docs word2vec docstring improvement, deprecation labels (@shubhvachher, [#1274](https://github.com/RaRe-Technologies/gensim/pull/1274))
* Stop passing 'sentences' as parameter to Doc2Vec. Fix #511 (@gogokaradjov, [#1306](https://github.com/RaRe-Technologies/gensim/pull/1306))


:red_circle: Bug fixes:
* Allow indexing with np.int64 in doc2vec. Fix #1231 (@bogdanteleaga, [#1254](https://github.com/RaRe-Technologies/gensim/pull/1254))
* Update Doc2Vec docstring. Fix #1302 (@datapythonista, [#1307](https://github.com/RaRe-Technologies/gensim/pull/1307))
* Ignore rst and ipynb file in Travis flake8 validations (@datapythonista, [#1309](https://github.com/RaRe-Technologies/gensim/pull/1309))


:books: Tutorial and doc improvements:
* Update Tensorboard Doc2Vec notebook (@parulsethi, [#1286](https://github.com/RaRe-Technologies/gensim/pull/1286))
* Update Doc2Vec IMDB Notebook, replace codesc to smart_open (@robotcator, [#1278](https://github.com/RaRe-Technologies/gensim/pull/1278))
* Add explanation of `size` to Word2Vec Notebook (@jbcoe, [#1305](https://github.com/RaRe-Technologies/gensim/pull/1305))
* Add extra param to WordRank notebook. Fix #1276 (@parulsethi, [#1300](https://github.com/RaRe-Technologies/gensim/pull/1300))
* Update warning message in WordRank (@parulsethi, [#1299](https://github.com/RaRe-Technologies/gensim/pull/1299))
",1349775
590,False,False,2017-04-10T23:42:04Z,2017-04-10T23:45:51Z,"
Breaking changes:

Any direct calls to method train() of Word2Vec/Doc2Vec now require an explicit epochs parameter and explicit estimate of corpus size. The most usual way to call `train` is `vec_model.train(sentences, total_examples=self.corpus_count, epochs=self.iter)`
See the [method documentation](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py#L766) for more information.


* Explicit epochs and corpus size in word2vec train(). (@gojomo, @robotcator, [#1139](https://github.com/RaRe-Technologies/gensim/pull/1139), [#1237](https://github.com/RaRe-Technologies/gensim/pull/1237))

New features:

* Add output word prediction in word2vec. Only for negative sampling scheme. See [ipynb]( https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/word2vec.ipynb) (@chinmayapancholi13,[#1209](https://github.com/RaRe-Technologies/gensim/pull/1209))
* scikit_learn wrapper for LSI Model in Gensim (@chinmayapancholi13,[#1244](https://github.com/RaRe-Technologies/gensim/pull/1244))
* Add the 'keep_tokens' parameter to 'filter_extremes'. (@toliwa,[#1210](https://github.com/RaRe-Technologies/gensim/pull/1210))
* Load FastText models with specified encoding (@jayantj,[#1210](https://github.com/RaRe-Technologies/gensim/pull/1189))


Improvements:
* Fix loading large FastText models on Mac. (@jaksmid,[#1196](https://github.com/RaRe-Technologies/gensim/pull/1214))
* Sklearn LDA wrapper now works in sklearn pipeline (@kris-singh,[#1213](https://github.com/RaRe-Technologies/gensim/pull/1213))
* glove2word2vec conversion script refactoring (@parulsethi,[#1247](https://github.com/RaRe-Technologies/gensim/pull/1247))
* Word2vec error message when update called before train . Fix #1162 (@hemavakade,[#1205](https://github.com/RaRe-Technologies/gensim/pull/1205))
* Allow training if model is not modified by ""_minimize_model"". Add deprecation warning. (@chinmayapancholi13,[#1207](https://github.com/RaRe-Technologies/gensim/pull/1207))
* Update the warning text when building vocab on a trained w2v model (@prakhar2b,[#1190](https://github.com/RaRe-Technologies/gensim/pull/1190))

Bug fixes:

*  Fix word2vec reset_from bug in v1.0.1 Fix #1230. (@Kreiswolke,[#1234](https://github.com/RaRe-Technologies/gensim/pull/1234))

* Distributed LDA: checking the length of docs instead of the boolean value, plus int index conversion (@saparina ,[#1191](https://github.com/RaRe-Technologies/gensim/pull/1191))

* syn0_lockf initialised with zero in intersect_word2vec_format() (@KiddoZhu,[#1267](https://github.com/RaRe-Technologies/gensim/pull/1267))

* Fix wordrank max_iter_dump calculation. Fix #1216 (@ajkl,[#1217](https://github.com/RaRe-Technologies/gensim/pull/1217))

* Make SgNegative test use sg (@shubhvachher ,[#1252](https://github.com/RaRe-Technologies/gensim/pull/1252))

* pep8/pycodestyle fixes for hanging indents in Summarization module (@SamriddhiJain  ,[#1202](https://github.com/RaRe-Technologies/gensim/pull/1202))

* WordRank and Mallet wrappers single vs double quote issue in windows.(@prakhar2b,[#1208](https://github.com/RaRe-Technologies/gensim/pull/1208))


* Fix #824 : no corpus in init, but trim_rule in init (@prakhar2b ,[#1186](https://github.com/RaRe-Technologies/gensim/pull/1186))

* Hardcode version number. Fix #1138. ( @tmylk, [#1138](https://github.com/RaRe-Technologies/gensim/pull/1138))

Tutorial and doc improvements:

* Color dictionary according to topic notebook update (@bhargavvader, [#1164](https://github.com/RaRe-Technologies/gensim/pull/1164))

* Fix hdp show_topic/s docstring ( @parulsethi, [#1264](https://github.com/RaRe-Technologies/gensim/pull/1264))

* Add docstrings for word2vec.py forwarding functions ( @shubhvachher, [#1251](https://github.com/RaRe-Technologies/gensim/pull/1251))

* updated description for worker_loop function used in score function ( @chinmayapancholi13 , [#1206](https://github.com/RaRe-Technologies/gensim/pull/1206))
",1349775
591,False,False,2017-03-03T22:49:13Z,2017-03-04T00:29:48Z,"
* Rebuild cumulative table on load. Fix #1180. (@tmylk,[#1181](https://github.com/RaRe-Technologies/gensim/pull/893))
* most_similar_cosmul bug fix (@dkim010, [#1177](https://github.com/RaRe-Technologies/gensim/pull/1177))
* Fix loading old word2vec models pre-1.0.0  (@jayantj, [#1179](https://github.com/RaRe-Technologies/gensim/pull/1179))
* Load utf-8 words in fasttext  (@jayantj, [#1176](https://github.com/RaRe-Technologies/gensim/pull/1176))",1349775
592,False,False,2017-02-24T22:49:01Z,2017-02-24T22:50:59Z,"1.0.0, 2017-02-24

**Deprecated methods:**

In order to share word vector querying code between different training algos(Word2Vec, Fastext, WordRank, VarEmbed)  we have separated storage and querying of word vectors into a separate class `KeyedVectors`.

Two methods and several attributes in word2vec class have been deprecated. The methods are `load_word2vec_format` and `save_word2vec_format`. The attributes are `syn0norm`, `syn0`, `vocab`, `index2word` .  They have been moved to `KeyedVectors` class.

After upgrading to this release you might get exceptions about deprecated methods or missing attributes.

```
DeprecationWarning: Deprecated. Use model.wv.save_word2vec_format instead.
AttributeError: 'Word2Vec' object has no attribute 'vocab'
```

**To remove the exceptions, you should use**
`KeyedVectors.load_word2vec_format` instead of  `Word2Vec.load_word2vec_format`
`word2vec_model.wv.save_word2vec_format` instead of  `word2vec_model.save_word2vec_format`
`model.wv.syn0norm` instead of  `model.syn0norm`
`model.wv.syn0` instead of  `model.syn0`
`model.wv.vocab` instead of `model.vocab`
`model.wv.index2word` instead of  `model.index2word`

**Changelog of this release:**

New features:
- Add Author-topic modeling (@olavurmortensen,[#893](https://github.com/RaRe-Technologies/gensim/pull/893))
- Add FastText word embedding wrapper (@Jayantj,[#847](https://github.com/RaRe-Technologies/gensim/pull/847))
- Add WordRank word embedding  wrapper (@parulsethi,[#1066](https://github.com/RaRe-Technologies/gensim/pull/1066), [#1125](https://github.com/RaRe-Technologies/gensim/pull/1125))
- Add Varembed word embedding wrapper (@anmol01gulati,  [#1067](https://github.com/RaRe-Technologies/gensim/pull/1067)))
- Add sklearn wrapper for LDAModel (@AadityaJ,[#932](https://github.com/RaRe-Technologies/gensim/pull/932))

Deprecated features:
- Move `load_word2vec_format` and `save_word2vec_format` out of Word2Vec class to KeyedVectors  (@tmylk,[#1107](https://github.com/RaRe-Technologies/gensim/pull/1107))
- Move properties `syn0norm`, `syn0`, `vocab`, `index2word` from Word2Vec class to KeyedVectors (@tmylk,[#1147](https://github.com/RaRe-Technologies/gensim/pull/1147))
- Remove support for Python 2.6, 3.3 and 3.4 (@tmylk,[#1145](https://github.com/RaRe-Technologies/gensim/pull/1145))

Improvements:
- Python 3.6 support (@tmylk [#1077](https://github.com/RaRe-Technologies/gensim/pull/1077))  
- Phrases and Phraser allow a generator corpus (ELind77 [#1099](https://github.com/RaRe-Technologies/gensim/pull/1099))
- Ignore DocvecsArray.doctag_syn0norm in save. Fix #789 (@accraze,[#1053](https://github.com/RaRe-Technologies/gensim/pull/1053))
- Fix bug in LsiModel that occurs when id2word is a Python 3 dictionary. (@cvangysel,[#1103](https://github.com/RaRe-Technologies/gensim/pull/1103)
- Fix broken link to paper in readme (@bhargavvader,[#1101](https://github.com/RaRe-Technologies/gensim/pull/1101)) 
- Lazy formatting in evaluate_word_pairs (@akutuzov,[#1084](https://github.com/RaRe-Technologies/gensim/pull/1084)) 
- Deacc option to keywords pre-processing (@bhargavvader,[#1076](https://github.com/RaRe-Technologies/gensim/pull/1076))
- Generate Deprecated exception when using Word2Vec.load_word2vec_format (@tmylk, [#1165](https://github.com/RaRe-Technologies/gensim/pull/1165)) 
- Fix hdpmodel constructor docstring for print_topics (#1152) (@toliwa, [#1152](https://github.com/RaRe-Technologies/gensim/pull/1152)) 
- Default to per_word_topics=False in LDA get_item for performance (@menshikh-iv,   [#1154](https://github.com/RaRe-Technologies/gensim/pull/1154)) 
- Fix bound computation in Author Topic models. (@olavurmortensen,   [#1156](https://github.com/RaRe-Technologies/gensim/pull/1156))
- Write UTF-8 byte strings in tensorboard conversion (@tmylk,[#1144](https://github.com/RaRe-Technologies/gensim/pull/1144))
- Make top_topics and sparse2full compatible with numpy 1.12 strictly int idexing (@tmylk,[#1146](https://github.com/RaRe-Technologies/gensim/pull/1146))

Tutorial and doc improvements:
- Clarifying comment in is_corpus func in utils.py (@greninja,[#1109](https://github.com/RaRe-Technologies/gensim/pull/1109)) 
- Tutorial Topics_and_Transformations fix markdown and add references (@lgmoneda,[#1120](https://github.com/RaRe-Technologies/gensim/pull/1120))
- Fix doc2vec-lee.ipynb results to match previous behavior (@bahbbc,[#1119](https://github.com/RaRe-Technologies/gensim/pull/1119)) 
- Remove Pattern lib dependency in News Classification tutorial (@luizcavalcanti,[#1118](https://github.com/RaRe-Technologies/gensim/pull/1118))
- Corpora_and_Vector_Spaces tutorial text clarification (@lgmoneda,[#1116](https://github.com/RaRe-Technologies/gensim/pull/1116))
- Update Transformation and Topics link from quick start notebook (@mariana393,[#1115](https://github.com/RaRe-Technologies/gensim/pull/1115))
- Quick Start Text clarification and typo correction (@luizcavalcanti,[#1114](https://github.com/RaRe-Technologies/gensim/pull/1114))
- Fix typos in Author-topic tutorial (@Fil,[#1102](https://github.com/RaRe-Technologies/gensim/pull/1102))
- Address benchmark inconsistencies in Annoy tutorial (@droudy,[#1113](https://github.com/RaRe-Technologies/gensim/pull/1113))
- Add note about Annoy speed depending on numpy BLAS setup in annoytutorial.ipynb (@greninja,[#1137](https://github.com/RaRe-Technologies/gensim/pull/1137)) 
- Add documentation for WikiCorpus metadata. (@kirit93, [#1163](https://github.com/RaRe-Technologies/gensim/pull/1163)) 
",1349775
593,False,True,2017-02-17T00:04:30Z,2017-02-17T00:06:12Z,"1.0.0RC2, 2017-02-16

Deprecated methods:

In order to share word vector querying code between different training algos(Word2Vec, Fastext, WordRank, VarEmbed)  we have separated storage and querying of word vectors into a separate class `KeyedVectors`.

Two methods and several attributes in word2vec class have been deprecated. The methods are `load_word2vec_format` and `save_word2vec_format`. The attributes are `syn0norm`, `syn0`, `vocab`, `index2word` .  They have been moved to `KeyedVectors` class.

After upgrading to this release you might get exceptions about deprecated methods or missing attributes.

```
DeprecationWarning: Deprecated. Use model.wv.save_word2vec_format instead.
AttributeError: 'Word2Vec' object has no attribute 'vocab'
```

**To remove the exceptions, you should use**
`KeyedVectors.load_word2vec_format` instead of  `Word2Vec.load_word2vec_format`
`word2vec_model.wv.save_word2vec_format` instead of  `word2vec_model.save_word2vec_format`
`model.wv.syn0norm` instead of  `model.syn0norm`
`model.wv.syn0` instead of  `model.syn0`
`model.wv.vocab` instead of `model.vocab`
`model.wv.index2word` instead of  `model.index2word`
- Add note about Annoy speed depending on numpy BLAS setup in annoytutorial.ipynb (@greninja,[#1137](https://github.com/RaRe-Technologies/gensim/pull/1137)) 
- Remove direct access to properties moved to KeyedVectors (@tmylk,[#1147](https://github.com/RaRe-Technologies/gensim/pull/1147))
- Remove support for Python 2.6, 3.3 and 3.4 (@tmylk,[#1145](https://github.com/RaRe-Technologies/gensim/pull/1145))
- Write UTF-8 byte strings in tensorboard conversion (@tmylk,[#1144](https://github.com/RaRe-Technologies/gensim/pull/1144))
- Make top_topics and sparse2full compatible with numpy 1.12 strictly int idexing (@tmylk,[#1146](https://github.com/RaRe-Technologies/gensim/pull/1146))
",1349775
594,False,False,2017-01-04T01:50:48Z,2017-01-04T02:00:44Z,"0.13.4.1, 2017-01-04
- Disable direct access warnings on save and load of Word2vec/Doc2vec (@tmylk, [#1072](https://github.com/RaRe-Technologies/gensim/pull/1072))
- Making Default hs error explicit (@accraze, [#1054](https://github.com/RaRe-Technologies/gensim/pull/1054)) 
- Removed unnecessary numpy imports (@bhargavvader,  [#1065](https://github.com/RaRe-Technologies/gensim/pull/1065))
- Utils and Matutils changes (@bhargavvader,  [#1062](https://github.com/RaRe-Technologies/gensim/pull/1062)) 
- Tests for the evaluate_word_pairs function (@akutuzov, [#1061](https://github.com/RaRe-Technologies/gensim/pull/1061))
",1349775
595,False,False,2016-12-25T12:06:07Z,2016-12-25T12:08:27Z,"# Deprecation warning

After upgrading to this release you might see deprecation warnings like this:

```
WARNING:gensim.models.word2vec:direct access to syn0norm will not be supported in future gensim releases, please use model.wv.syn0norm
```

These warnings are correct and you are encouraged to change your Word2vec/Doc2vec code to use the new model.wv.syn0norm and model.wv.vocab fields instead of old direct access like model.syn0norm and model.vocab. The direct access will be deprecated in Feb 2017.

**Specifically, you should use**
`model.wv.syn0norm` instead of  `model.syn0norm`
`model.wv.syn0` instead of  `model.syn0`
`model.wv.vocab` instead of `model.vocab`
`model.wv.index2word` instead of  `model.index2word`

The reason for this deprecation is to separate word vectors from word2vec training. There are now new ways to get word vectors that don't involve training word2vec. We are adding capabilities to use word vectors trained in GloVe, FastText, WordRank, Tensorflow and Deeplearning4j word2vec.   In order to have cleaner code and standard APIs for all word embeddings we [extracted](https://github.com/RaRe-Technologies/gensim/pull/980) a `KeyedVectors` class and a word-vectors `wv` variable into the models.

0.13.4, 2016-12-22

Changelog:
- Evaluation of word2vec models against semantic similarity datasets like SimLex-999 (#1047) (@akutuzov, [#1047](https://github.com/RaRe-Technologies/gensim/pull/1047))
- TensorBoard word embedding visualisation of Gensim Word2vec format (@loretoparisi, [#1051](https://github.com/RaRe-Technologies/gensim/pull/1051))
- Throw exception if load() is called on instance rather than the class in word2vec and doc2vec (@dus0x,[(#889](https://github.com/RaRe-Technologies/gensim/pull/889))
- Loading and Saving LDA Models across Python 2 and 3. Fix #853 (@anmolgulati, #913, [#1093](https://github.com/RaRe-Technologies/gensim/pull/1093))
- Fix automatic learning of eta (prior over words) in LDA (@olavurmortensen, [#1024](https://github.com/RaRe-Technologies/gensim/pull/1024)).
  - eta should have dimensionality V (size of vocab) not K (number of topics). eta with shape K x V is still allowed, as the user may want to impose specific prior information to each topic.
  - eta is no longer allowed the ""asymmetric"" option. Asymmetric priors over words in general are fine (learned or user defined).
  - As a result, the eta update (`update_eta`) was simplified some. It also no longer logs eta when updated, because it is too large for that.
  - Unit tests were updated accordingly. The unit tests expect a different shape than before; some unit tests were redundant after the change; `eta='asymmetric'` now should raise an error.
- Optimise show_topics to only call get_lambda once. Fix #1006. (@bhargavvader,  [#1028](https://github.com/RaRe-Technologies/gensim/pull/1028))
- HdpModel doc improvement. Inference and print_topics (@dsquareindia, [#1029](https://github.com/RaRe-Technologies/gensim/pull/1029))
- Removing Doc2Vec defaults so that it won't override Word2Vec defaults. Fix #795 (@markroxor, [#929](https://github.com/RaRe-Technologies/gensim/pull/929))
  Remove warning on gensim import ""pattern not installed"". Fix #1009 (@shashankg7, #1018)
- Add delete_temporary_training_data() function to word2vec and doc2vec models. (@deepmipt-VladZhukov, [#987](https://github.com/RaRe-Technologies/gensim/pull/987))
- New class KeyedVectors to store embedding separate from training code (@anmol01gulati and @droudy, [#980](https://github.com/RaRe-Technologies/gensim/pull/980))
- Documentation improvements (@IrinaGoloshchapova, [#1010](https://github.com/RaRe-Technologies/gensim/pull/1010), [#1011](https://github.com/RaRe-Technologies/gensim/pull/1011))
- LDA tutorial by Olavur, tips and tricks (@olavurmortensen, [#779](https://github.com/RaRe-Technologies/gensim/pull/779)) 
- Add double quote in commmand line to run on Windows (@akarazeev, [#1005](https://github.com/RaRe-Technologies/gensim/pull/1005)) 
- Fix directory names in notebooks to be OS-independent (@mamamot, [#1004](https://github.com/RaRe-Technologies/gensim/pull/1004))
- Respect clip_start, clip_end in most_similar. Fix #601. (@parulsethi, [#994](https://github.com/RaRe-Technologies/gensim/pull/994))
- Replace Python sigmoid function with scipy in word2vec & doc2vec (@markroxor, [#989](https://github.com/RaRe-Technologies/gensim/pull/989))
- WMD to return 0 instead of inf for sentences that contain a single word (@rbahumi, [#986](https://github.com/RaRe-Technologies/gensim/pull/986))
- Pass all the params through the apply call in lda.get_document_topics(), test case to use the per_word_topics through the corpus in test_ldamodel (@parthoiiitm, [#978](https://github.com/RaRe-Technologies/gensim/pull/978))
- Pyro annotations for lsi_worker (@markroxor, [#968](https://github.com/RaRe-Technologies/gensim/pull/968))
",1349775
596,False,False,2016-10-21T12:01:40Z,2016-10-21T13:01:26Z,"0.13.3, 2016-10-20
- Add vocabulary expansion feature to word2vec. (@isohyt, [#900](https://github.com/RaRe-Technologies/gensim/pull/900))
- Tutorial: Reproducing Doc2vec paper result on wikipedia. (@isohyt, [#654](https://github.com/RaRe-Technologies/gensim/pull/654))
- Add Save/Load interface to AnnoyIndexer for index persistence (@fortiema, [#845](https://github.com/RaRe-Technologies/gensim/pull/845))
- Fixed issue [#938](https://github.com/RaRe-Technologies/gensim/issues/938),Creating a unified base class for all topic models. ([@markroxor](https://github.com/markroxor), [#946](https://github.com/RaRe-Technologies/gensim/pull/946))
  -  _breaking change in HdpTopicFormatter.show___topics_
- Add Phraser for Phrases optimization. ( @gojomo & @anujkhare , [#837](https://github.com/RaRe-Technologies/gensim/pull/837))
- Fix issue #743, in word2vec's n_similarity method if at least one empty list is passed ZeroDivisionError is raised (@pranay360, [#883](https://github.com/RaRe-Technologies/gensim/pull/883))
- Change export_phrases in Phrases model. Fix issue #794 (@AadityaJ, [#879](https://github.com/RaRe-Technologies/gensim/pull/879))
  - bigram construction can now support multiple bigrams within one sentence
- Fix issue [#838](https://github.com/RaRe-Technologies/gensim/issues/838), RuntimeWarning: overflow encountered in exp  ([@markroxor](https://github.com/markroxor), [#895](https://github.com/RaRe-Technologies/gensim/pull/895))
-  Change some log messages to warnings as suggested in issue #828. (@rhnvrm, [#884](https://github.com/RaRe-Technologies/gensim/pull/884))
-  Fix issue #851, In summarizer.py, RunTimeError is raised if single sentence input is provided to avoid ZeroDivionError. (@metalaman, #887)
- Fix issue [#791](https://github.com/RaRe-Technologies/gensim/issues/791), correct logic for iterating over SimilarityABC interface. ([@MridulS](https://github.com/MridulS), [#839](https://github.com/RaRe-Technologies/gensim/pull/839))
- Fix RP model loading for large Fortran-order arrays (@piskvorky, [#605](https://github.com/RaRe-Technologies/gensim/issues/938))
- Remove ShardedCorpus from init because of Theano dependency (@tmylk, [#919](https://github.com/RaRe-Technologies/gensim/pull/919))
- Documentation improvements ( @dsquareindia & @tmylk, [#914](https://github.com/RaRe-Technologies/gensim/pull/914), [#906](https://github.com/RaRe-Technologies/gensim/pull/906) )
- Add Annoy memory-mapping example (@harshul1610, [#899](https://github.com/RaRe-Technologies/gensim/pull/899))
",1349775
597,False,False,2016-08-26T15:30:02Z,2016-08-26T15:32:42Z,"0.13.2, 2016-08-19
- wordtopics has changed to word_topics in ldamallet, and fixed issue #764. (@bhargavvader, [#771](https://github.com/RaRe-Technologies/gensim/pull/771)) 
  - assigning wordtopics value of word_topics to keep backward compatibility, for now
- topics, topn parameters changed to num_topics and num_words in show_topics() and print_topics()(@droudy, [#755](https://github.com/RaRe-Technologies/gensim/pull/755))
  - In hdpmodel and dtmmodel
  - NOT BACKWARDS COMPATIBLE!
- Added random_state parameter to LdaState initializer and check_random_state() (@droudy, [#113](https://github.com/RaRe-Technologies/gensim/pull/113))
- Topic coherence update with `c_uci`, `c_npmi` measures.  LdaMallet, LdaVowpalWabbit support. Add `topics` parameter to coherencemodel. Can now provide tokenized topics to calculate coherence value. Faster backtracking. (@dsquareindia, [#750](https://github.com/RaRe-Technologies/gensim/pull/750), [#793](https://github.com/RaRe-Technologies/gensim/pull/793))
- Added a check for empty (no words) documents before starting to run the DTM wrapper if model = ""fixed"" is used (DIM model) as this    causes the an error when such documents are reached in training. (@eickho, [#806](https://github.com/RaRe-Technologies/gensim/pull/806))
- New parameters `limit`, `datatype` for load_word2vec_format(); `lockf` for intersect_word2vec_format (@gojomo, [#817](https://github.com/RaRe-Technologies/gensim/pull/817))
- Changed `use_lowercase` option in word2vec accuracy to `case_insensitive` to account for case variations in training vocabulary (@jayantj, [#804](https://github.com/RaRe-Technologies/gensim/pull/804)
- Link to Doc2Vec on airline tweets example in tutorials page (@544895340 , [#823](https://github.com/RaRe-Technologies/gensim/pull/823))
- Small error on Doc2vec notebook tutorial (@charlessutton, [#816](https://github.com/RaRe-Technologies/gensim/pull/816))
- Bugfix: Full2sparse clipped to use abs value (@tmylk, [#811](https://github.com/RaRe-Technologies/gensim/pull/811))
- WMD docstring: add tutorial link and query example (@tmylk, [#813](https://github.com/RaRe-Technologies/gensim/pull/813))
- Annoy integration to speed word2vec and doc2vec similarity. Tutorial update (@droudy, [#799](https://github.com/RaRe-Technologies/gensim/pull/799),[#792](https://github.com/RaRe-Technologies/gensim/pull/799) )
- Add converter of LDA model between Mallet, Vowpal Wabit and gensim (@dsquareindia, [#798](https://github.com/RaRe-Technologies/gensim/pull/798), [#766](https://github.com/RaRe-Technologies/gensim/pull/766))
- Distributed LDA in different network segments without broadcast (@menshikh-iv , [#782](https://github.com/RaRe-Technologies/gensim/pull/782))
- Update Corpora_and_Vector_Spaces.ipynb (@megansquire, [#772](https://github.com/RaRe-Technologies/gensim/pull/772))
- DTM wrapper bug fixes caused by renaming num_words in #755 (@bhargavvader,  [#770](https://github.com/RaRe-Technologies/gensim/pull/770))
- Add LsiModel.docs_processed attribute (@hobson, [#763](https://github.com/RaRe-Technologies/gensim/pull/763))
- Dynamic Topic Modelling in Python. Google Summer of Code 2016 project. (@bhargavvader, [#739, #831](https://github.com/RaRe-Technologies/gensim/pull/739))
",1349775
598,False,False,2016-06-23T00:16:57Z,2016-06-23T00:19:01Z,"Initial release of Topic Coherence C_v and U_mass. More work will be done here but external API will remain the same.
",1349775
599,False,False,2016-06-22T03:26:05Z,2016-06-22T03:33:44Z,"0.12.5, 2016

Tutorials migrated from website to ipynb (@j9chan, #721), (@jesford, #733, #725, 716)
New doc2vec intro tutorial (@seanlaw, #730)
Gensim Quick Start Tutorial (@andrewjlm, #727)
Add export_phrases(sentences) to model Phrases (hanabi1224 #588)
SparseMatrixSimilarity returns a sparse matrix if maintain_sparsity is True (@davechallis, #590)
added functionality for Topics of Words in document - i.e, dynamic topics. (@bhargavvader, #704)
also included tutorial which explains new functionalities, and document word-topic coloring.
Made normalization an explicit transformation. Added 'l1' norm support (@squareindia, #649)
added term-topics API for most probable topic for word in vocab. (@bhargavvader, #706)
build_vocab takes progress_per parameter for smaller output (@zer0n, #624)
Control whether to use lowercase for computing word2vec accuracy. (@alantian, #607)
Easy import of GloVe vectors using Gensim (Manas Ranjan Kar, #625)
Allow easy port of GloVe vectors into Gensim
Standalone script with command line arguments, compatible with Python>=2.6
Usage: python -m gensim.scripts.glove2word2vec -i glove_vectors.txt -o output_word2vec_compatible.txt
Add similar_by_word() and similar_by_vector() to word2vec (@isohyt, #381)
Convenience method for similarity of two out of training sentences to doc2vec (@ellolo, #707)
Dynamic Topic Modelling Tutorial updated with Dynamic Influence Model (@bhargavvader, #689)
Added function to filter 'n' most frequent words from the dictionary (@abhinavchawla, #718)
Raise warnings if vocab is single character elements and if alpha is increased in word2vec/doc2vec (@dsquareindia, #705)
Tests for wikidump (@jonmcoe, #723)
Mallet wrapper sparse format support (@RishabGoel, #664)
Doc2vec pre-processing script translated from bash to Python (@andrewjlm, #720)
Added Distance Metrics to matutils.pt (@bhargavvader, #656)
",1349775
600,False,True,2016-06-10T04:29:05Z,2016-06-10T04:32:39Z,"# Changes

0.12.5, 2016
- Tutorials migrated from website to ipynb (@j9chan, #721), (@jesford, #733, #725, 716)
- New doc2vec intro tutorial (@seanlaw, #730)
- Gensim Quick Start Tutorial (@andrewjlm, #727)
- Add export_phrases(sentences) to model Phrases (hanabi1224 #588)
- SparseMatrixSimilarity returns a sparse matrix if `maintain_sparsity` is True (@davechallis, #590)
- added functionality for Topics of Words in document - i.e, dynamic topics. (@bhargavvader, #704)
  - also included tutorial which explains new functionalities, and document word-topic coloring.
- Made normalization an explicit transformation. Added 'l1' norm support (@squareindia, #649)
- added term-topics API for most probable topic for word in vocab. (@bhargavvader, #706)
- build_vocab takes progress_per parameter for smaller output (@zer0n, #624)
- Control whether to use lowercase for computing word2vec accuracy. (@alantian, #607)
- Easy import of GloVe vectors using Gensim (Manas Ranjan Kar, #625)
  - Allow easy port of GloVe vectors into Gensim
  - Standalone script with command line arguments, compatible with Python>=2.6 
  - Usage: python -m gensim.scripts.glove2word2vec -i glove_vectors.txt -o output_word2vec_compatible.txt
- Add `similar_by_word()` and `similar_by_vector()` to word2vec (@isohyt, #381)
- Convenience method for similarity of two out of training sentences to doc2vec (@ellolo, #707)
- Dynamic Topic Modelling Tutorial updated with Dynamic Influence Model (@bhargavvader, #689)
- Added function to filter 'n' most frequent words from the dictionary (@abhinavchawla, #718)
- Raise warnings if vocab is single character elements and if alpha is increased in word2vec/doc2vec (@dsquareindia, #705)
- Tests for wikidump (@jonmcoe, #723)
- Mallet wrapper sparse format support (@RishabGoel, #664)
- Doc2vec pre-processing script translated from bash to Python (@andrewjlm, #720)
",1349775
601,False,False,2016-01-31T09:58:00Z,2016-01-31T10:00:08Z,"- Word2vec in line with original word2vec.c (Andrey Kutuzov, #538) 
- Same default values. See diff https://github.com/akutuzov/gensim/commit/6456cbcd75e6f8720451766ba31cc046b4463ae2
- Standalone script with command line arguments matching those of original C tool.
  Usage ./word2vec_standalone.py -train data.txt -output trained_vec.txt -size 200 -window 2 -sample 1e-4
- load_word2vec_format() performance (@svenkreiss, #555)
  - Remove `init_sims()` call for performance improvements when normalized vectors are not needed.
  - Remove `norm_only` parameter (API change). Call `init_sims(replace=True)` after the `load_word2vec_format()` call for the old `norm_only=True` behavior.
- Better internal handling of job batching in word2vec (#535)
  - up to 300% speed up when training on very short documents (~tweets)
- Word2vec allows non-strict unicode error handling (ignore or replace) (Gordon Mohr, #466)
- Doc2Vec `model.docvecs[key]` now raises KeyError for unknown keys (Gordon Mohr, #520)
- Fix `DocvecsArray.index_to_doctag` so `most_similar()` returns string doctags (Gordon Mohr, #560) 
- On-demand loading of the `pattern` library in utils.lemmatize (Jan Zikes, #461)
  - `utils.HAS_PATTERN` flag moved to `utils.has_pattern()`
- Threadsafe Word2Vec/Doc2Vec finish-check to avoid hang/unending Word2Vec/Doc2Vec training (Gordon Mohr, #571)
- Tuned `TestWord2VecModel.test_cbow_hs()` against random failures (Gordon Mohr, #531)
- Prevent ZeroDivisionError when `default_timer()` indicate no elapsed time (Gordon Mohr, #518)
- Forwards compatibility for NumPy > 1.10 (Matti Lyra, #494, #513)
  - LdaModel and LdaMulticore produce a large number of DeprecationWarnings from
    .inference() because the term ids in each chunk returned from utils.grouper
    are floats. This behaviour has been changed so that the term IDs are now ints.
  - utils.grouper returns a python list instead of a numpy array in .update() when
    LdaModel is called in non distributed mode
  - in distributed mode .update() will still call utils.grouper with as_numpy=True
    to save memory
  - LdaModel.update and LdaMulticore.update have a new keyword parameter
    chunks_as_numpy=True/False (defaults to False) that allows controlling
    this behaviour
",1349775
602,False,False,2015-11-06T14:38:43Z,2015-11-06T14:40:06Z,"0.12.3rc1, 05/11/2015
- Make show_topics return value consistent across models (Christopher Corley, #448)
  - All models with the `show_topics` method should return a list of
    `(topic_number, topic)` tuples, where `topic` is a list of
    `(word, probability)` tuples.
  - This is a breaking change that affects users of the `LsiModel`, `LdaModel`,
    and `LdaMulticore` that may be reliant on the old tuple layout of
    `(probability, word)`.
- Mixed integer & string document-tags (keys to doc-vectors) will work (Gordon Mohr, #491)
  - DocvecsArray's `index2doctag` list is renamed/reinterpreted as `offset2doctag`
  - `offset2doctag` entries map to `doctag_syn0` indexes _after_ last plain-int doctag (if any)
  - (If using only string doctags, `offset2doctag` may be interpreted same as `index2doctag`.)
- New Tutorials on Dynamic Topic Modelling and Classification via Word2Vec (@arttii #471, @mataddy #500)
- Auto-learning for the eta parameter on the LdaModel (Christopher Corley, #479)
- Python 3.5 support
- Speed improvements to keyword and summarisation methods (@erbas #441)
- OSX wheels (#504)
- Win build (#492)
",1349775
603,False,True,2015-11-05T19:08:09Z,2015-11-05T19:13:08Z,"0.12.3rc1, 05/11/2015
- Make show_topics return value consistent across models (Christopher Corley, #448)
  - All models with the `show_topics` method should return a list of
    `(topic_number, topic)` tuples, where `topic` is a list of
    `(word, probability)` tuples.
  - This is a breaking change that affects users of the `LsiModel`, `LdaModel`,
    and `LdaMulticore` that may be reliant on the old tuple layout of
    `(probability, word)`.
- Mixed integer & string document-tags (keys to doc-vectors) will work (Gordon Mohr, #491)
  - DocvecsArray's `index2doctag` list is renamed/reinterpreted as `offset2doctag`
  - `offset2doctag` entries map to `doctag_syn0` indexes _after_ last plain-int doctag (if any)
  - (If using only string doctags, `offset2doctag` may be interpreted same as `index2doctag`.)
- New Tutorials on Dynamic Topic Modelling and Classification via Word2Vec (@arttii #471, @mataddy #500)
- Auto-learning for the eta parameter on the LdaModel (Christopher Corley, #479)
- Python 3.5 support
- Speed improvements to keyword and summarisation methods (@erbas #441)
- OSX wheels (#504)
- Win build (#492)
",1349775
604,False,False,2020-02-16T06:19:25Z,2020-02-16T06:34:22Z,"**To download and unpack prebuilt binaries:**
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.5.0/tsv-utils-v1.5.0_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.5.0/tsv-utils-v1.5.0_osx-x86_64_ldc2.tar.gz | tar xz
```
Installation instructions are in the `ReleasePackageReadme.txt` file in the release package.

**To be notified of new releases:**

GitHub supports notification of new releases. Click the ""Watch"" button on the repository page and select ""Releases Only"".

**Release 1.5.0 Changes:**
* Prebuilt binaries have been updated to use the latest LDC compiler (1.20.0).

* `tsv-filter`: Field list support (PR #259).

  Field list provide a compact way to specify multiple fields for a command. Most tsv-utils tools already support field lists, now `tsv-filter` does as well. Examples:
   ```
   $ # Select lines where fields 1-10 are not empty.
   $ tsv-filter --not-empty 1-10 data.tsv
   
   $ # Select lines where fields 1-5 and 17 are less than 100
   $ tsv-filter --lt 1-5,17:100 data.tsv
   ```

* `tsv-filter`: New field length tests based on either characters or bytes (PR #258).

   The new operators allow filtering on field length. Field length can be measured in either characters or bytes. (Characters can occupy multiple bytes in UTF-8). Examples:
   ```
   $ # Keep only lines where field 3 is less than 50 characters
   $ tsv-filter --char-len-lt 3:50 data.tsv

   $ # Find lines where field 5 is more than 20 bytes
   $ tsv-filter --byte-len-gt 5:20
   ```
   Character length tests have names of the form: `--char-len-eq|ne|lt|le|gt|ge]`.  Byte length tests have names of the form: `--byte-len-[eq|ne|lt|le|gt|ge]`.

* `tsv-filter`: Improved error messages when invalid regular expressions are used.

   The error message printed by `tsv-filter` now includes the error text provided by the D regular expression engine. This is helpful when trying to debug complex regular expressions. Examples:
   ```
   $ # Old error message (tsv-filter 1.4.4)
   $ tsv-filter --regex 4:'abc(d|e' data.tsv
   [tsv-filter] Error processing command line arguments: Invalid values in option: '--regex 4:abc(d|e'. Expected: '--regex <field>:<val>' where <field> is a number and <val> is a regular expression.

   $ # New error message (tsv-filter 1.5.0)
   [tsv-filter] Error processing command line arguments: Invalid regular expression: '--regex 4:abc(d|e'. no matching ')'
   Pattern with error: `abc(d|e` <--HERE-- ``
      Expected: '--regex <field>:<val>' or '--regex <field-list>:<val>' where <val> is a regular expression.
   ```
   The formatting of the message can be improved and is likely to be updated in the future.

* `tsv-uniq`: Performance improvements (PRs #234, #235).

   Better memory management and other changes improved `tsv-uniq` performance by 5-35% depending on the operation.

* `tsv-sample`: Performance improvements reading large data blocks from standard input (PR #238).

   Sampling and shuffling operations requiring that all data be read into memory were unnecessarily slow when large amounts of data was read from standard input. Performance issues were noticed with data sizes larger than 10 GB. This is now fixed.

* Sample bash scripts included in release package (PR #254).

   Sample versions of the `tsv-sort` and `tsv-sort-fast` scripts described on the [Tips and Tricks](https://github.com/eBay/tsv-utils/blob/master/docs/TipsAndTricks.md) page are now included in the repository and in prebuilt binary packages.



",55643245
605,False,False,2019-09-23T17:36:42Z,2019-09-23T17:53:18Z,"Changes:
- New `tsv-sample` option `--i|inorder`

  This option preserves input order when using simple or weighted random sampling. These sampling modes are engaged when a sample size is selected via the `--n|num NUM` option. Documentation was updated to better reflect the distinction between shuffling the full data set and random sampling  which selects a subset of lines. (PR #226)

- `tsv-summarize` `--min` and `--max` operators changed to preserve original input string

  The prior behavior of the operators was to read the values to a double, then use numeric formatting to print the recorded double. In some cases this would cause the original input to change, especially if it was a long format number, for example, 16 digits long. (PR #220)

  The prior behavior makes sense for calculations like mean and median, but not for min and max. In particular, preserving the original values allows them to be joined with or compared to the original data.

- Prebuilt binaries have been updated to use the latest LDC compiler (1.17.0).

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.4/tsv-utils-v1.4.4_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.4/tsv-utils-v1.4.4_osx-x86_64_ldc2.tar.gz | tar xz
```",55643245
606,False,False,2019-08-19T05:10:00Z,2019-08-19T05:24:57Z,"Two changes:
- New `tsv-pretty` option `--a|auto-preamble` - Enables automatic detection of preambles. Lines at the start of the file that should be printed as is, without reformatting into pretty printed columns. For more information and examples see PR #218.
- Prebuilt binaries have been updated to use the latest LDC compiler (1.16.0).

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.3/tsv-utils-v1.4.3_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.3/tsv-utils-v1.4.3_osx-x86_64_ldc2.tar.gz | tar xz
```",55643245
607,False,False,2019-06-14T12:31:27Z,2019-06-14T12:48:42Z,"One change:
* Fixes incorrect comma use in the `dub.json` file. Needed to support planned changes in dub. Also needed for dlang CI pipelines.

There are no changes to any of the tools.

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.2/tsv-utils-v1.4.2_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.2/tsv-utils-v1.4.2_osx-x86_64_ldc2.tar.gz | tar xz
```",55643245
608,False,False,2019-04-07T19:18:10Z,2019-04-07T19:35:33Z,"This release contains one new feature and several performance improvements:
* `tsv-uniq --number` - Line numbering grouped by key (new feature). The key is either the whole line or a subset of fields. Each unique key gets its own set of line numbers. See the [tsv-uniq reference](https://github.com/eBay/tsv-utils/blob/master/docs/ToolReference.md#tsv-uniq-reference) for details.
* Improved I/O read performance. This was achieved by using a buffered version of `std.stdio.File.byLine`. Especially effective for narrow files. Tools using `byLine` (most of the tools) typically see a 10-40% performance gain, depending on tool and type of file (measured on OS X). Implementation documentation: [tsv_utils.common.utils.bufferedByLine](https://tsv-utils.dpldocs.info/tsv_utils.common.utils.bufferedByLine.html).
* Updated compiler to LDC 1.15.0 for prebuilt binaries (frontend/druntime/phobos 2.085.1). This includes an update to LLVM 8.0 and a couple of improvements to memory allocation and GC collection. The latter improved performance of several of the tools, especially tools like `tsv-join` that allocate large amounts of memory.

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.1/tsv-utils-v1.4.1_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.4.1/tsv-utils-v1.4.1_osx-x86_64_ldc2.tar.gz | tar xz
```",55643245
609,False,False,2018-11-12T07:48:42Z,2018-11-12T08:04:09Z,"This release modifies `tsv-sample` random value printing so most values are printed in decimal notation, without exponents. This is for subsequent processing by GNU sort. Sorting numbers with exponents requires ""general numeric"" order (option 'g'), which is much slower than ""numeric"" order (option 'n'). See [Shuffling large files](https://github.com/eBay/tsv-utils/blob/master/docs/TipsAndTricks.md#shuffling-large-files) on the [Tips and Tricks](https://github.com/eBay/tsv-utils/blob/master/docs/TipsAndTricks.md) page for more info.

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.3.2/tsv-utils-v1.3.2_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.3.2/tsv-utils-v1.3.2_osx-x86_64_ldc2.tar.gz | tar xz
```",55643245
610,False,False,2018-11-11T09:35:54Z,2018-11-11T09:53:52Z,"In this release:
- `tsv-sample`: Adds full-line as key to distinct sampling. This completes the work that has been done on sampling over the last few point releases. `tsv-sample` now supports a fair set of sampling modes. Performance is also good, in keeping with the tradition of the other tsv-utils tools.
- Prebuilt binaries have been updated to use the latest LDC compiler (1.12.0). This is a significant performance boost to regex search in `tsv-filter`. Unfortunately `csv2tsv` is a little slower.
- The build system now supports using LDC's LTO compiled druntime and phobos libraries (those shipped with the compiler). This eliminates the need to download the druntime and phobos source code at build time. This is more convenient and supports package managers better.
- Code level documentation now generates good documentation when used with the dpldocs documentation system. Go to the [tsv-utils code documentation](https://tsv-utils.dpldocs.info/) to see the result.

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.3.1/tsv-utils-v1.3.1_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.3.1/tsv-utils-v1.3.1_osx-x86_64_ldc2.tar.gz | tar xz
```",55643245
611,False,False,2018-10-21T01:52:58Z,2018-10-21T02:07:45Z,"This release add several new sampling algorithms that improve runtime performance and memory utilization for a number of sampling use-cases. There are no new forms of sampling, just additional algorithms. The new algorithms:
- A skip sampling implementation of Bernoulli sampling.
- An implementation of reservoir sampling ""Algorithm R"" used for unweighted random sampling.
- A line order randomization algorithm based on array shuffling.

Formal performance benchmarks have not been run. However, tests run on Mac OS as part of development show favorable results relative to other available tools, including GNU shuf.

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.2.3/tsv-utils-v1.2.3_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.2.3/tsv-utils-v1.2.3_osx-x86_64_ldc2.tar.gz | tar xz
```
",55643245
612,False,False,2018-10-07T18:13:11Z,2018-10-07T18:30:15Z,"This release adds new capabilities and performance improvements to `tsv-sample`. Documentation was also updated to improve clarity. Key changes:
* New feature: Simple random sampling with replacement - All lines from input sources are read in, then lines are repeated selected at random and written out. Lines can be output multiple times. The process continues until the specified number of samples has been written. Invoke using the `-r|--replace` and `-n|--num NUM` options.
* New feature: Random value printing - A new feature was added for generating random values for all input lines. In the default case it shows the values used for Bernoulli sampling trials. It can also be used with 'distinct' sampling to show the sampling bucket a line is placed in based on the key-fields specified. This feature is invoked with the `--gen-random-inorder` option. A related feature, `--print-random`, was updated so that it is now supported by all applicable sampling modes.
* Line order randomization performance improvements: One of the basic `tsv-sample` use cases is line order randomization. The case where all input lines are being permuted was re-written and is now quite a bit faster and uses less memory. This applies to both weighted and unweighted sampling. (The case where a subsampling is being done via the `-n|--num` option uses reservoir sampling was already fast.)
* Command line option change - The option for specifying the probability used for Bernoulli sampling was changed from `-r|--rate` to `-p|prob`. This was done to create a more consistent set of option names for new features and features that may be added in the future.

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.2.2/tsv-utils-v1.2.2_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.2.2/tsv-utils-v1.2.2_osx-x86_64_ldc2.tar.gz | tar xz
```
",55643245
613,False,False,2018-08-03T21:07:53Z,2018-08-03T21:22:27Z,"This release adds features for `tsv-utils` automated tests. There are no changes to any of the tools.

The new testing features add support for different correct output results for different compiler/library versions. The main case is for changes to error message text, which in some cases includes text from the phobos library.

Alternate test outputs were added for a planned change to Phobos in an upcoming release. This was bundled into a tagged release to support the D language project tester where `tsv-utils` is used.

To download and unpack the prebuilt binaries:
```
$ # Linux
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.2.1/tsv-utils-v1.2.1_linux-x86_64_ldc2.tar.gz | tar xz

$ # MacOS
$ curl -L https://github.com/eBay/tsv-utils/releases/download/v1.2.1/tsv-utils-v1.2.1_osx-x86_64_ldc2.tar.gz | tar xz
```",55643245
614,False,False,2018-07-16T01:58:56Z,2018-07-16T02:12:24Z,This release changes the repository name from `eBay/tsv-utils-dlang` to `eBay/tsv-utils`. This better reflects the functionality provided by the TSV Utilities. There are no other changes. Please report any issues found with the name change on the [Issues page](https://github.com/eBay/tsv-utils/issues).,55643245
615,False,False,2018-06-14T03:32:03Z,2018-06-14T03:46:16Z,"Release v1.1.20 contains a few minor updates:
* `tsv-summarize`: `unique-count` operator - Performance improvement by avoiding unnecessary string copies. 40% faster on one benchmark.
* Bash completion fixes
",55643245
616,False,False,2018-03-18T20:56:46Z,2018-03-18T21:27:35Z,"_**NOTE**_: _Unfortunately, the pre-built binaries for v1.1.19 and earlier releases have been lost. Please use the pre-built binaries from the latest release. There is nothing wrong with the old binaries, if you downloaded one earlier you can continue to use it._

Changes in v1.1.19:
* `tsv-uniq` - New options for printing only repeated lines: `--r|repeated`, `--a|at-least N`.
* `tsv-pretty` - New option for verbatim output of an initial set of lines: `--a|preamble N`.
* `makefile help` - Bug fix in the output.",55643245
617,False,False,2018-02-25T17:04:02Z,2018-02-25T17:31:05Z,"_**NOTE**_: _Unfortunately, the pre-built binaries for v1.1.19 and earlier releases have been lost. Please use the pre-built binaries from the latest release. There is nothing wrong with the old binaries, if you downloaded one earlier you can continue to use it._

Changes in v1.1.18:
* `tsv-uniq` - Added a `--m|max` option to output up to a max number of duplicate lines. The default of course is one.
* `tsv-sample` - Added PGO support. Small gains, up to 5% depending on sampling method.
* Better unit test diagnostic output on ""command line"" tests. This simplifies tracking down errors when tests are run on a system like TravisCI. In the past it was necessary to run the test locally to see what failed.
* Bash completion - Fix a `tsv-filter` option.
* Doc updates - Added a pair of sections to the Tips and Tricks doc. One describing TSV and CSV differences, another giving examples of using `dos2unix` and `iconv` to deal with encoding and newline issues.",55643245
618,False,False,2018-01-26T06:48:11Z,2018-01-26T07:23:48Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.17:

Most of the tools were switched to use output buffering. This is a performance enhancement that works by buffering small writes into larger blocks before writing to the final output destination, usually `stdout`. The amount of benefit depends on the tool and the nature of the file being processed. Narrow files (short lines) see the most benefit, and in some cases run 50% faster. More typical gains are 5-20%.

Output buffering logic is in the `BufferedOutputRange` struct found in `common/src/tsvutil.d`. The resulting source code in each tool turns out to be quite readable.",55643245
619,False,False,2018-01-14T16:12:26Z,2018-01-14T16:55:49Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.16:

The main changes in this release are the use of Profile Guided Optimization (PGO) and the addition of new sampling methods in `tsv-sample`.

**Profile Guided Optimization** - This is a follow-on to the Link Time Optimization work done in [v1.1.15](https://github.com/eBay/tsv-utils-dlang/releases/tag/v1.1.15). It is based on LDC compiler support for LTO and PGO, including the ability to operate on the application code and the D standard libraries (druntime, phobos) together.

Profile Guided Optimization uses data collected from instrumented builds to better optimize executables. The tsv utilities build process has been updated to generate and use instrumentation for several of the tools. LTO and PGO builds are enabled by options passed to `make`. The pre-built binaries available from the [GitHub releases page](https://github.com/eBay/tsv-utils-dlang/releases) are built with LTO and PGO, but they must enabled explicitly when building from source. See [Building with Link Time Optimization and Profile Guided Optimization](docs/BuildingWithLTO.md) for details.

PGO results in material performance gains (10% or more) on `csv2tsv` and `tsv-summarize`, and smaller gains (2-5%) on several other tools. Considering LTO (v1.1.15) and PGO (v1.1.16) combined, performance gains on five of six measured benchmarks ranged from 8-45% on Linux, and 6-57% on MacOS. Three of the benchmarks saw gains greater than 25% on both platforms.

**New sampling methods** - Two sampling methods have been added to `tsv-sample`. One is a simple stream sampling mode that selects a random portion of an input stream based on a sampling rate. Another is a form of sampling known as ""distinct"" sampling. This selects a random portion of records based on a key in the data. For example, if records contain an IP address, sampling to take all records from 1% of the unique IP addresses. See the [tsv-sample reference](docs/ToolReference.md#tsv-sample-reference) for details.

**Other changes**
* `tsv-summarize` bug fix, incorrect headers on two operations.
* Windows line ending detection when running on Unix platforms (Issue #96)
* `tsv-select` performance improvement: Avoid unnecessary memory allocation from std.array.join. A 5% performance improvement and less memory allocation.
",55643245
620,False,False,2017-11-10T06:23:26Z,2017-11-10T07:18:52Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.15:

This release uses new link-time optimization (LTO) available starting with the LDC 1.5 compiler release. This improves the performance of most of the tools, typically by about 10% over the previous release, and significantly more in some cases. Benchmarks can be found in this [slide deck](https://github.com/eBay/tsv-utils-dlang/blob/master/docs/dlang-meetup-14dec2017.pdf) from the Silicon Valley D Meetup, Dec 14, 2017.

Previous releases used Thin LTO on OS X builds. LTO was not used on Linux builds. In the OS X case, LTO was used on the tsv utilities code, but not the code from the D libraries, phobos and druntime.

The LDC 1.5 release supports LTO on both Linux and OS X out of the box, and includes support for building phobos and druntime with LTO.

This release of the tsv utilities adds support for the new LTO capabilities to the makefiles. It is not enabled by default, but can be turned on with make arguments. The prebuilt binaries have been built with LTO turned on. For more information, see [Building With LTO](docs/BuildingWithLTO.md).",55643245
621,False,True,2017-11-05T03:28:59Z,2017-11-05T04:11:03Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.15-beta3:
This release uses new link-time optimization (LTO) available starting with the LDC 1.5 compiler release.",55643245
622,False,False,2017-10-19T07:10:06Z,2017-10-19T14:28:11Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.14:

No functional changes, updates to documentation only.",55643245
623,False,False,2017-09-23T21:27:27Z,2017-09-23T21:47:48Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.13: New tool, `tsv-pretty`.

`tsv-pretty` prints TSV data in an aligned fasion for command-line readability. Headers are detected automatically and numeric values aligned. An example, first without formatting:
```
$ cat sample.tsv
Color   Count   Ht      Wt
Brown   106     202.2   1.5
Canary Yellow   7       106     0.761
Chartreuse	1139	77.02   6.22
Fluorescent Orange	422     1141.7  7.921
Grey	19	140.3	1.03
```
Now with `tsv-pretty`, using header underlining and float formatting:
```
$ tsv-pretty -u -f sample.tsv
Color               Count       Ht     Wt
-----               -----       --     --
Brown                 106   202.20  1.500
Canary Yellow           7   106.00  0.761
Chartreuse           1139    77.02  6.220
Fluorescent Orange    422  1141.70  7.921
Grey                   19   140.30  1.030
```",55643245
624,False,False,2017-06-21T13:11:45Z,2017-06-21T13:48:44Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.12:

Turn on Link Time Optimization (LTO) when using the LDC compiler on OS X. This produces faster executables. The difference is especially notable for the `csv2tsv` tool, which runs about 20% faster. LTO is used in the pre-built OS X binaries and will be used on OS X source code builds (git clone, dub fetch) when building with the LDC compiler.

OS X directly supports LTO with the system linker provided by XCode (Clang / LLVM). LTO can also be used on Linux, but at present it requires installing and building special linker support. This complicates the build process, which is why it is not used on Linux by this toolset. For more information on LDC's LTO support see http://johanengelen.github.io/ldc/2016/11/10/Link-Time-Optimization-LDC.html.",55643245
625,False,False,2017-05-07T23:44:33Z,2017-05-08T00:04:05Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.11:

Main feature is support for field ranges. Any place a list of fields can be entered, field ranges can be used as well. A field range is a pair of field numbers separated by a hyphen. Reverse order is supported as well. Single field numbers and field ranges can be used together. Some examples:
```
$ tsv-select --fields 1,2,17-33,10-7  data.tsv
$ tsv-summarize --group-by 3-5 --median 7-17
$ tsv-uniq --fields 7-10 data.tsv
```

There are also some improvements to error message text.",55643245
626,False,False,2017-04-29T07:25:27Z,2017-04-29T07:33:06Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.10:

This release updates pre-built binaries to use the new LDC release, version 1.1.2. It also switches to static linking for the Linux pre-built binary. This makes the binaries usable on more Linux environments (issue #67). No functional changes.",55643245
627,False,False,2017-04-17T05:30:35Z,2017-04-17T05:39:02Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.18:

No functional changes. All tools now print version information if given `-V` or `--version` options.",55643245
628,False,False,2017-04-10T00:49:43Z,2017-04-10T01:10:42Z,"_**NOTE**_: _Pre-built binaries for this release are no longer available. Please use binaries from the latest release._

Changes in v1.1.7:

No functional changes. Uses Travis-CI to produce pre-built binaries available from Github Releases. Binaries are generated for Linux and Mac using the latest LDC compiler.",55643245
629,False,False,2017-04-06T05:29:41Z,2017-04-06T05:58:43Z,"Code coverage reports are now available as part of automated tests.
A number of small cleanups in the code and documentation.",55643245
630,False,False,2017-03-26T03:18:11Z,2017-03-26T04:02:55Z,"The quantile operator enables calculating arbitrary percentiles when summarizing data. For example, the following command calculates the 10th, 25th, 50th, 75th, 90th percentile values for field 3 in file data.tsv:
```
$ tsv-summarize --quantile 3:0.1,0.25,0.5,0.75,0.9 data.tsv
```

Multiple fields can be specified. To calculate the 90th and 95th percentiles for fields 3,  4, and 5:
```
$ tsv-summarize --quantile 3,4,5:0.9,0.95 data.tsv
```

Quantile interpolation is done using the same method as the `R` default (interpolation method 7).

Other changes:
- Travis CI enabled.
- Additional detail added to the performance benchmark docs.
",55643245
631,False,False,2017-03-22T17:19:20Z,2017-03-22T17:41:05Z,Bug fix: The new `keep-header` tool wasn't properly included in the `dub` build system. It was included in the `make` build system though. (Issue #44).,55643245
632,False,False,2017-03-10T06:39:25Z,2017-03-10T08:09:25Z,Documentation changes related to the new `keep-header` tool.,55643245
633,False,False,2017-03-09T08:02:01Z,2017-03-09T08:23:13Z,"`keep-header` runs unix tools like `sort` and `grep` in a header-aware fashion. For example:
```
$ keep-header file1.txt -- sort
```
sorts the file, but the first line, presumably a header line, is output first and excluded from the sort. Multiple files can specified, only the header from the first file is included in the output.",55643245
634,False,False,2017-03-04T19:00:37Z,2017-03-04T19:24:57Z,The `csv2tsv` tool was sped up 2x by using buffered writes rather than byte-at-a-time writes. The performance benchmarks were re-run to reflect the changes. `csv2tsv` is now the fastest tested tool on it's benchmark.,55643245
635,False,False,2017-02-22T17:52:37Z,2017-02-22T18:06:59Z,"No code changes, but a new set of benchmark results (see the docs/Performance.md).
Bumped the minor version number to reflect the changes in the last few months.
",55643245
636,False,False,2017-02-18T02:14:19Z,2017-02-18T02:22:08Z,"tsv-summarize
- Newest operators were not hooked up correctly to command line args.
- Correction to bash-completion
",55643245
637,False,False,2017-02-13T03:56:32Z,2017-02-13T04:11:47Z,"Two enhancements:
- tsv-summarize: Missing value support. New command line options to either exclude or replace empty fields. This is a common pattern in some data sets. Also, some new operators related to missing values.
- Bash-completion: Definitions enabling command option completion in `bash` shells. Needs to be manually installed. Details in the Tips & Tricks document.
",55643245
638,False,False,2017-02-08T00:16:03Z,2017-02-08T00:38:56Z,"Fixed some edge cases where printing was being done using exponential notation where not intended.
",55643245
639,False,False,2017-02-06T08:16:13Z,2017-02-06T08:34:45Z,"- tsv-summarize: Improved formatting of numeric values, especially when using the `--p|float-precision` option.
- Reorganization of the documentation.
",55643245
640,False,False,2017-01-21T23:22:50Z,2017-01-21T23:58:37Z,"New tool, tsv-sample, does sampling and randomization of data file lines. Both uniform and weighted random sampling is supported. Weighted sampling gets weights from a field in the input data. Implemented using reservoir sampling.
",55643245
641,False,False,2017-01-09T09:55:07Z,2017-01-09T10:04:39Z,,55643245
642,False,False,2017-01-09T08:56:39Z,2017-01-09T09:24:20Z,"- tsv-filter: New tests `--is-numeric`, `--is-finite`, `--is-nan`, `is-infinity`. These are useful to ensure a numeric test like `--gt` (greater than) are run only on field values with validly formatted numbers.
- tsv-summarize: Take advantage the faster `topN` in DMD/Phobos version 2.073.
",55643245
643,False,False,2017-01-04T01:24:29Z,2017-01-04T02:29:29Z,"`tsv-append` concatenates multiple TSV files, similar to the Unix `cat` utility. It is header aware, writing the header from only the first file. It also supports source tracking, adding a column indicating the original file to each row.

Concatenation with header support is useful when preparing data for traditional Unix utilities like sort and sed or applications that read a single file.

Source tracking is useful when creating long/narrow form tabular data. This format is used by many statistics and data mining packages.
",55643245
644,False,False,2016-12-21T08:47:52Z,2016-12-21T09:00:00Z,"Minor improvements to command line arguments:
- Use --help/help-verbose rather than --help/help-brief. The short version (-h | --help) is generally more useful than the long form.
- Add `-H` as a short form of `--header`
",55643245
645,False,False,2016-12-17T19:03:51Z,2016-12-17T19:11:44Z,,55643245
646,False,False,2016-04-19T10:19:23Z,2016-12-12T08:59:26Z,,55643245
647,False,False,2016-12-12T08:06:35Z,2016-12-12T08:31:41Z,"With short-circuiting, commands like

```
$ tsv-filter --not-blank 3 --eq 3:100 file.tsv
$ tsv-filter --str-ne 3:none --eq 3:100 file.tsv
```

will ensure the field is not blank or not the string ""none"" prior to testing for equality to 100. Prior, these tests were not guaranteed to be run first. If they weren't, a numeric conversion error would occur.

Now the tests are guaranteed to be issued in the order listed on the command line. Boolean short-circuiting is used to limited tests to just those needed to determine the outcome.
",55643245
648,False,False,2016-12-11T05:33:59Z,2016-12-11T06:05:12Z,"Initial release of a new tool, tsv-summarize.

tsv-summarize runs aggregation operations on fields. For example, generating the sum or median of a field's values. Summarization calculations can be run across the entire input or can be grouped by key fields. A single row of output is produced for the former, multiple rows for the latter.
",55643245
649,False,False,2016-05-09T05:54:26Z,2016-05-09T07:24:23Z,"Main change is to dub and makefile build setups to better support LDC-1.0.0-beta1. The changes use the correct compiler switch for '-inline' on both DMD and LDC. This is important for DMD performance, but the DMD switch syntax is no longer supported on LDC. The are also minor documentation changes and a minor code optimization.
",55643245
650,False,False,2016-04-30T08:17:13Z,2016-04-30T08:25:32Z,,55643245
651,False,False,2016-04-26T18:03:17Z,2016-04-26T18:10:32Z,"Added a new tool, `csv2tsv`, for converting comma-separated value data to tab-separated format.
",55643245
652,False,False,2017-01-03T17:42:16Z,2017-01-03T20:12:31Z,"## Summary

### New Major Features:
- Ship with Anaconda's [Miniconda](http://conda.pydata.org/miniconda.html) for when there is no python installed on the system.  (Windows-only)
- Vastly improved startup speed (with a fancy loading icon) and removed loading popup, since it is not needed anymore
- Restore application state when opened, including tabs open and terminal history.
- Adding or overriding Environment Variables inside Rodeo

## Details

It's been a month since the last update of Rodeo.  Sorry about the delay.  I was trying to figure out how to help people install Python.

### Built-in Miniconda on Windows

From the feedback that Colin and Elise have been getting, most newbie data scientists struggle with installing Python on Windows machines.  Mac and Linux users are somewhat better at it, but they often like installing libraries and everything themselves, which is honestly quite cool.

Anyway, this new version has Miniconda built into the Windows version.  It will obviously try and run any version it finds on the system first by running ""python"" on the command line, but then it will fall back to the built-in version.  If the built-in version fails, it will show the default starting screen to help people resolve whatever issue they have on their system.

### Removed Starting / Loading Screen

In previous versions of Rodeo 2.x, there was an annoying window that popped up that tried to detect problems with the system that it was running on.  It was seriously annoying, but it was the only solution we could think up for all the problems that people were having with their Jupyter/IPython installations.  

In this new version (2.5.x), we're going to try a different approach and see if it works better.  Instead of trying to detect problems before the main Rodeo application launches, we're going to try and detect problems after they've already happened.  This means that most users will not be blocked or slowed down after they have everything set up nicely.

Um, I also did a bunch of things to speed up the startup speed of Rodeo as well.  On my 2012 MacBook Pro, Rodeo loads in 2.5 seconds.  I have some ideas to get this down to 1 second, but it'll require some new techniques.  The technology inside the Rodeo UI is getting strangely advanced.

### Restore Application State when Reopened

There are two parts to this new feature: Firstly, when Rodeo shuts down it saves the current state of the app.  It remembers what files you have open, the history of the terminal, what your current working directory is -- that is, almost everything.  Secondly, when Rodeo is reopened it tries to restore that state.  Hopefully this feature saves people a lot of time.

This is just the first iteration of this feature, and I want to add auto-saving of files and plots later.

### Adding or overriding Environment Variables inside Rodeo

As wonderful as Python is, it relies on some concepts that beginner data scientists struggle with -- like environment variables.  Even for advanced users, managing environment variables on a system is complex because they're always somewhat global, and there are always several ways to set them depending on operating system and the way an application is started.

<img width=""326"" alt=""screen shot 2016-12-17 at 7 35 02 pm"" src=""https://cloud.githubusercontent.com/assets/4154804/21290626/fa085d7c-c48f-11e6-8961-b91274693e21.png"">

I added an Environment Variables interface in the Preferences to help, and hopefully it makes someone's life easier.  It shows all the environment variables currently affecting their scripts (shown in blue), and lets everyone add or override them safely too (shown in white).  I tried to make it more difficult to mess up your system by moving the PATH and the PYTHON PATH to their own lists.  I don't know if this is the best interface to manage such a thing, so I hope people give lots of feedback in the [forums](http://discuss.yhat.com).

<img width=""594"" alt=""screen shot 2016-12-17 at 7 33 22 pm"" src=""https://cloud.githubusercontent.com/assets/4154804/21290620/c739126a-c48f-11e6-94f8-c7df95a5decc.png"">

### Bonus Features

This is an open source project, and people have been really great about providing feedback and helping out in all kinds of ways.  
- Check existence of current working directory before trying to start python. Thanks fioraz!  [[forum link]](http://discuss.yhat.com/t/terminal-does-not-start-python-rodeo-unusable/411)
- Default to PYTHONIOENCODING=utf-8, since our terminal is utf-8 by default already.  Thank you [teramonagi](http://d.hatena.ne.jp/teramonagi/)!  [[forum link]](http://discuss.yhat.com/t/multi-byte-string-support/399/2)
- Pop up dialog before quitting.  This can be disabled in Preferences &gt; Global or in the quit dialog itself.  This is first step toward warning the user about unsaved work.
- Choose whether to use Pip or Conda to install packages.  This is available in Preferences &gt; Python
- Terminal Cursor is now thin and slightly blinking to match the editor tabs.  This can be changed back through the Preferences as well.
- General improvements to performance all over the place.  You'll probably notice.
",33683694
653,False,False,2016-11-16T17:55:01Z,2016-11-16T19:05:34Z,"Fixes:
- https://github.com/yhat/rodeo/issues/539: International Keyboards that use alt/shift/ctrl for typing keys now unblocked.
",33683694
654,False,False,2016-11-15T21:10:32Z,2016-11-15T21:32:38Z,"New Release
- Fix for clearing history blocks
- Fix for result and text output that contains html.
",33683694
655,False,False,2016-11-14T19:07:30Z,2016-11-14T20:03:47Z,"Summary of New Features
- Brand New Terminal
- Brand New Code Block Runner
- Brand New History
- Skip Startup Screen Button
",33683694
656,False,False,2016-10-03T22:08:42Z,2016-10-03T22:43:01Z,"_**This is a release just for Windows.**_

We replaced the Window's installer gif with a cat gif that Colin found.

Not kidding.  This is real.
",33683694
657,False,False,2016-09-29T12:44:16Z,2016-09-29T13:19:39Z,"Fixes:
- [Variables had disappeared from the environment.](http://discuss.yhat.com/t/environment-pane-remains-empty-after-variable-assignment/273/3)   Fixed with this release.
",33683694
658,False,False,2016-09-28T21:14:48Z,2016-09-28T21:33:50Z,"Fixes
- Apparently posix doesn't exist on Windows.  I knew that, but forgot.  😥   Fixes the long names on windows in the file system navigator
- Allow the saving of files that are not python
",33683694
659,False,False,2016-09-28T18:19:57Z,2016-09-28T19:05:52Z,"## New Features

### Added a new file navigator

I added a tree view component to the file system viewer.  It was really annoying to have to jump between directories, and having a flat view of the current directory made it look like that was the current working directory of python, which isn't always true.  The new tree view allows everyone to look at multiple directories at once, because having different directories for your scripts and your data is nice.

<img width=""563"" alt=""screen shot 2016-09-28 at 3 05 12 pm"" src=""https://cloud.githubusercontent.com/assets/4154804/18928170/fdb3f432-858c-11e6-91d0-0c5cedd62ef6.png"">

Also, the app now watches the file system for new or deleted files, which will appear or disappear from the file tree dynamically.  The view doesn't detect the renaming or moving of files yet across all operating systems, but we'll get there.

I also added two new shortcut buttons.  One takes you to your home directory, and the other goes to the current working directory of python.  Combined with the working directory selector in the info bar at the bottom of the python terminal, we're trying to make it easier to navigate around the file system.

<img width=""378"" alt=""screen shot 2016-09-28 at 3 01 16 pm"" src=""https://cloud.githubusercontent.com/assets/4154804/18928041/74e55e02-858c-11e6-8c20-2fd0c407147c.png"">

There are a lot of things we could do to improve the file system viewer and the python terminal, and this is just the beginning.  🌟 

### Added new file types (SQL, markdown, csv, plain text, julia, JSON, Scala, YAML)

I've added syntax highlighting of a bunch of other languages to the editor view.  You can also change the syntax highlighting of the current file with a new selector tab in the info bar.

<img width=""329"" alt=""screen shot 2016-09-28 at 3 02 11 pm"" src=""https://cloud.githubusercontent.com/assets/4154804/18928083/96f8c4ca-858c-11e6-9fe2-6b462a6f0d15.png"">

## Bug Fixes

None!  The next release is going to have a new way of running code that will cause a lot of the bugs people are running into to disappear.  Hopefully everyone is patient enough to wait for the much improved console and history viewer.  I have it on a local branch, and it will look so much better than the current version...
",33683694
660,False,False,2016-09-23T15:53:32Z,2016-09-23T16:54:19Z,"Fixes:
- Elise found a bug where the DataFrame button in the Environment tab wasn't re-rendering, and that was causing buttons to not open the correct DataFrame when clicked.  This is now fixed.
",33683694
661,False,False,2016-09-22T15:38:54Z,2016-09-22T16:28:40Z,"Fixes:
- Auto-complete docstrings were missing CSS styles in ace-panes.  This is now fixed.
",33683694
662,False,False,2016-09-21T16:56:11Z,2016-09-21T18:14:56Z,"## Summary of New Features
- New style of tabs
- Major performance improvements for how tabs work (about 400% improvement in browser rendering performance, though not python running performance)
- Can now change the working directory of the Console by clicking on the bottom gray bar beneath.
- Can now pop-out the plots tab
- Can now save empty files
- Added Noto fonts to better represent any unicode characters that are not in Roboto.

## Summary of Bug Fixes
- Rodeo used to look for ""python"" even if a different path was set when it was starting up. Now it uses the different path if available.
- Removed Serif fonts that everyone (including me) hated, and replaced them with Roboto (or Helvetica Neue if available).
- ""Run Script"" code now appears in the console history, for consistency.

## The Highly Technical Long Story

### Performance

I should start out with an apology.  I disappeared from the forums for a bit to focus on a particular bit of restructuring that should give us some ridiculous speed improvements for how Rodeo renders in the browser.  As people know, Rodeo runs in Electron, which runs in Chromium, which is basically Google Chrome.  As such, performance could be measured by the number of DOM elements changed after a user action, and since browsers use a painters algorithm to redraw the screen, it would be accurate.

[React](https://facebook.github.io/react/), which is the rendering engine that I'm using, assumes that if any element contains more elements, that it should be redrawn every time there is any change whatsoever to the webpage.  As a result, every action the user was doing in Rodeo was causing an almost complete redraw of the entire screen, because Rodeo is a very complex application with a lot of elements containing other elements.  You can see this when you resize the window, or drag around the gray bar between the tab sections.

The only way to improve the situation is to override React's default behavior.  If I could tell it exactly what had changed we would get a ridiculous performance improvement, because only a small section of the screen (and the DOM tree) would be updated after a user action.

However, before this update Rodeo used a structure that made it difficult to map the DOM elements being rendered to the state of the app that has changed.  It was grouping all the _types of components_ together into lists, and then the tabs were remembering which component they held.  As I continued to add features to this pattern, the complexity skyrocketed and it was taking longer to make new features.  No good.

This new update (2.3.0) resolves this problem by introducing an _Immutable_ data structure for application state.  There are plenty of very interesting articles about the benefits of immutable data, but in our case I could arrange the state of the application to match the structure of the DOM tree, and then to determine if a component should update, I only have to check if the object references attached to that particular component had changed.  Using a library called [seamless-immutable](https://github.com/rtfeldman/seamless-immutable), I threw away the old application state structure and rebuilt it completely -- you can check the changelogs, I've been very busy.

``` js
function shallowEqual(instance, newProps, newState) {
  return equal(instance.props, newProps) && equal(instance.state, newState);
}
```

If the object references of the properties or the state of a component has changed, then that component should redraw.

React has a built-in component that I could have inherited to do this -- however, the reference to the children of a component always changes and that built-in component does not take that into account, so I had to do something different.

```
    const key = aKeys[i],
      aValue = a[key],
      // the 'children' key doesn't matter; it's not in our control
      isChildren = key === 'children',
      // functions don't matter either
      isFunction = typeof aValue === 'function',
      isValueEqual = aValue === b[key];

    if (!isChildren && !isFunction && !isValueEqual) {
      return false;
    }
```

Anyway, hopefully the app feels better now.  😅 

# Pop-out Plots

One of the major new features of this version of Rodeo is the ability to pop out a new window.  This feature is _highly_ experimental, but takes advantage of my use of [Redux](http://redux.js.org/) for changes to application state.  I'm copying a server architecture pattern by using the Redux dispatcher to share all new actions between all browser windows as if it were just a stream of events that components can subscribe to with their reducers.  If that sentence didn't make sense, well, just imagine that every action a user takes or that emerges from Python as an event flowing through a pipe that is being fed into each window.  All the parts of the window are listening to events that they're interested in.  

This means that I should be able to pop out any part of the app into their own windows, and everything will continue to work as if they were in the same window.  

So far I've enabled this feature with plots, but there is enough code that is making strange assumptions about various things that I want to roll out this feature slowly, testing everything along the way.  Next week, I'll add the environment variables as something we can pop out, and the week after maybe something else.

![screen shot 2016-09-21 at 1 25 44 pm](https://cloud.githubusercontent.com/assets/4154804/18723508/d737aa78-8006-11e6-984f-2aba198d1644.png)
",33683694
663,False,False,2016-09-08T01:17:48Z,2016-09-08T01:53:03Z,"# New Features

## Better Packages Tab

Searching and installing of packages is a pain with pip, so we upgraded the Packages tab to be a search.  The search results contain documentation and support links, and a fancy ""Install Package"" button that really just types ""pip install some-package"" for you.

|| Aside: The `pip search` functionality is also missing a _ton_ of packages, so please forgive us if some don't show up.  For example: `pip search matplotlib | grep matplotlib` will mysteriously not return the library that we're after.  However, `pip install matplotlib` works just fine.

Anyway, we did a thing and now matplotlib _will_ show up if you type the full package name into the search.

If the description of a package is in Markdown, it will be rendered nicely.  However, if the description is in reStructuredText, it won't be.  _Yet_.  The only way to render reStructuredText is with a commandline program and a python library called `docutils` and a whole lot of temporary folders, and I don't want to do that to users' machines.

## New Preference: Ace Editor Themes

Soooooo many people asked for themes, but full themes are really difficult to maintain and we only have one developer working on this project (please contribute!)

But as [one user](https://twitter.com/bryancshepherd/status/773942555964764160) suggested, we could just use the [Ace](https://ace.c9.io/) themes that are already available and very easy to configure.  So we did.  🎶 

The themes are grouped into ""dark"" and ""bright"" categories, just like the [Ace Kitchen Sink Example](https://ace.c9.io/build/kitchen-sink.html)  

# Fixes
- Can now save empty files
",33683694
664,False,False,2016-08-29T22:20:38Z,2016-08-29T22:55:17Z,"Fixes:
- Columns with a name of zero (0) are now visible.
- Doubled the timeout of the start screen.
- Timeout errors are now visible as the reason for the error in the start screen.
",33683694
665,False,False,2016-08-26T03:29:16Z,2016-08-26T04:06:59Z,"This is a big one.  There are a ton of large changes that aren't visible, but here are some visible ones:
- Saving and deleting of plots
- ""Use Soft Tabs"" as a preference setting
- ""Show Starting Tutorial"" as a preference setting you can turn off!
- Several major Windows 7 bugs fixed.
- Several minor Windows 8 and 10 installer bugs fixed.
- New buttons to clear, interrupt and restart the Console (although there were menu and keyboard shortcuts before)
- Brand new startup window that emphasizes the python _command_ and not the path that will _hopefully_ catch all the strange python problems that people have
- Rodeo now can be run from the command line on Windows with an option to _not_ show the startup screen.
- `--help` will now show command line options on all OSs.
- All child processes are killed explicitly before the main process exits when quitting from the menu, the window or the keyboard shortcut.
",33683694
666,False,False,2016-08-09T21:17:47Z,2016-08-09T21:48:11Z,"Fixes:
- The File Viewer would be blank when the home directory was `~`.  Fixed!
",33683694
667,False,False,2016-08-09T19:33:27Z,2016-08-09T20:26:01Z,"New Features:
- We made the minimap smaller.  https://github.com/yhat/rodeo/pull/413
- We show the working directory to the user: https://github.com/yhat/rodeo/pull/412
- We changed the starting script to use ! pip install : https://github.com/yhat/rodeo/pull/411
- We added the blog link: https://github.com/yhat/rodeo/pull/410
- Windows Support
",33683694
668,False,False,2016-07-26T18:12:33Z,2016-07-26T19:18:17Z,"Fixed:
- when using the filter for tabs, don't jump to another tab semi-randomly
- docstrings for things in things
- monospace font for docstrings, and a max-height of 30% of the total screen.
",33683694
669,False,False,2016-07-25T00:16:03Z,2016-07-25T13:57:15Z,"New Feature
- partial docstrings
  - it'll find `thing`, but not `thing.thing` unless also `thing` exists.  If that makes sense to you, you'll understand that it needs more work

Fixes
- `open('` and then tab will autocomplete files better than before
",33683694
670,False,False,2016-07-21T15:06:29Z,2016-07-21T15:33:09Z,"New Features
- Indent and Outdent selections in the editor with Tab and Shift-Tab
",33683694
671,False,False,2016-07-20T15:48:21Z,2016-07-20T16:45:42Z,"New Features
- Better startup speed for the first command
- Better Windows support (slightly)
",33683694
672,False,False,2016-07-14T18:04:09Z,2016-07-14T18:31:23Z,"New Features:
- Added a cool loading icon when the data frame is loading.
- Unicode characters now render in Rodeo consistently.
  Fixes:
- The DataFrame viewer wasn't loading when data had special characters is now working.
",33683694
673,False,False,2016-07-13T18:22:55Z,2016-07-13T18:52:21Z,"New Features
- Starting page with instructions of how to use the product
- Can view DataFrames
- Better installation of ipython
",33683694
674,False,False,2016-07-07T19:54:03Z,2016-07-07T21:24:36Z,"New Features:
- `?x`-style
- Can now see the values of primitives in Environment tab
",33683694
675,False,False,2016-06-21T18:33:00Z,2016-06-21T19:51:33Z,"Updates:
- Bash environment variables are now available, just like the real IPython terminal.
- Plots are now newest to oldest, top to bottom.
- Cmd+4 to focus new plot.
- Html Icon background color has been changed to same blue as sidebar.
- Colin added a bunch of tracking stuff to see if people are actually able to use this piece of software.
",33683694
676,False,False,2016-06-16T17:57:59Z,2016-06-16T18:20:25Z,"Patch:
- CPU usage backs off by 100x when python isn't doing anything.  Is less obnoxious with the yielding.

Significantly better for laptop batteries.
",33683694
677,False,False,2016-06-16T16:12:59Z,2016-06-16T17:02:33Z,"Patch:
- includes fix that adds `/usr/local/bin`, `/usr/sbin`, `/sbin` to the PATH on OSX so people's bash scripts don't trip on themselves.
- Allow tabs on the right side to be dragged between the top and bottom portion.
",33683694
678,False,False,2016-06-14T18:35:15Z,2016-06-14T19:06:42Z,"Note: Only the OSX versions have significant testing.  Over the next week we'll be re-testing the windows releases.
",33683694
679,False,False,2016-06-08T17:03:34Z,2016-06-08T17:53:18Z,"Fixes:
- Eliminated race condition where some commands would disappear, causing the prompt to disappear because it thought work was still being done.
- Plot tab is automatically focused when a new one is generated, can be disabled with preferences
- Save File Dialog: When saving a file that already has a name, include the name in the dialog.

<img width=""1076"" alt=""screen shot 2016-06-08 at 1 52 16 pm"" src=""https://cloud.githubusercontent.com/assets/4154804/15904769/4cacdb90-2d80-11e6-8063-18d2af054180.png"">
",33683694
680,False,False,2016-06-07T14:13:01Z,2016-06-07T14:43:22Z,"Patch:
- added survey capability, used for a Register screen at the moment.
- fixed one case in the startup screens where it would not detect python.
",33683694
681,False,False,2016-06-06T17:24:31Z,2016-06-06T17:46:08Z,"Overall:
- Images and iFrames are now clearing with the keyboard shortcut
- Reduces latency of ipython executions by 50x.
- Reports the result of checking for auto-updates if the user manually requested a check.
- Removes extra code that was being used to test the auto-detection. It was preventing the persistence of the user's python cmd setting.
- Uses `which python` as a highly prioritized source of python detection.
",33683694
682,False,False,2016-06-03T14:11:17Z,2016-06-03T14:34:06Z,"Fixes:
- The run button runs the active file
- Shift-Cmd-Enter when the editor is focused runs the active file.
",33683694
683,False,False,2016-06-02T15:33:40Z,2016-06-02T16:03:40Z,"New Features:
- Ctrl-C to kill a long running ipython execution.

Patch:
- Add version to About Rodeo dialog
- Fix the Track Metrics checkbox because it was interacting badly with `false` values.  That might be misinterpreted.

Example:

```
import time
time.sleep(100)
```

Run the above using Ctrl-Enter.  Then using Ctrl-C to trigger a keyboard interrupt.

Keyboard Interrupts look something like this:

![screen shot 2016-06-01 at 5 47 21 pm](https://cloud.githubusercontent.com/assets/4154804/15751931/f221a4a0-28b9-11e6-84ba-cb076d47f372.png)
",33683694
684,False,False,2016-06-01T20:52:33Z,2016-06-01T21:13:37Z,"New Features
- Metrics

Fix
- Allow default values in preferences panel
- Allow checkboxes to retain their values
",33683694
685,False,False,2016-06-01T05:34:41Z,2016-06-01T05:37:02Z,"New Features
- Cmd+1 and Cmd+2 to switch between Editor and Console
- Cmd+Enter to run that line of code or whatever is selected.
",33683694
686,False,False,2016-05-27T13:55:53Z,2016-05-27T14:45:33Z,"Fixes:
- Startup screens guide user through finding or installing python
- Python path can be edited from preferences menu
",33683694
687,False,False,2016-05-21T18:25:53Z,2016-05-21T18:56:06Z,"Enhancement
- The startup screen looks somewhat more official.  This is the start of creating an auto-detection process in the startup screens.
",33683694
688,False,False,2016-05-21T00:40:51Z,2016-05-21T00:59:02Z,"New Features
- Auto-updates to latest version
",33683694
689,False,False,2016-05-20T23:07:01Z,2016-05-20T23:10:39Z,"New Features
- Understands if it is the current version or not
",33683694
690,False,False,2016-05-19T21:11:10Z,2016-05-19T22:14:06Z,,33683694
691,False,False,2019-10-25T18:11:34Z,2019-10-25T18:21:30Z,,658518
692,False,False,2019-08-30T16:51:35Z,2019-08-30T16:58:41Z,,658518
693,False,False,2019-07-26T22:15:00Z,2019-07-26T22:23:23Z,,658518
694,False,False,2019-07-03T16:43:45Z,2019-07-03T16:59:23Z,,658518
695,False,False,2019-06-28T23:32:26Z,2019-06-28T23:42:23Z,,658518
696,False,False,2019-04-24T22:18:24Z,2019-04-24T22:26:22Z,,658518
697,False,False,2019-03-21T21:14:00Z,2019-03-21T21:21:50Z,,658518
698,False,False,2019-02-18T21:56:45Z,2019-02-18T22:04:01Z,,658518
699,False,False,2018-11-30T01:13:38Z,2018-11-30T01:19:24Z,,658518
700,False,False,2018-10-28T04:52:16Z,2018-11-06T16:25:18Z,,658518
701,False,False,2018-10-27T20:28:00Z,2018-10-27T20:34:23Z,,658518
702,False,False,2018-09-27T17:07:43Z,2018-09-27T17:13:05Z,,658518
703,False,False,2018-09-27T16:32:20Z,2018-09-27T16:37:28Z,,658518
704,False,False,2018-09-27T15:03:42Z,2018-09-27T15:09:31Z,,658518
705,False,False,2018-09-21T07:45:14Z,2018-09-21T07:50:22Z,,658518
706,False,False,2018-09-10T21:20:57Z,2018-09-10T21:27:41Z,,658518
707,False,False,2017-09-29T18:59:44Z,2017-09-29T19:04:36Z,,658518
708,False,False,2017-09-15T17:45:32Z,2017-09-15T17:49:49Z,,658518
709,False,False,2017-05-31T22:36:39Z,2017-05-31T22:41:11Z,,658518
710,False,False,2017-04-19T21:27:27Z,2017-04-19T21:32:33Z,,658518
711,False,False,2017-04-10T21:52:39Z,2017-04-10T21:56:38Z,,658518
712,False,False,2015-02-28T00:31:49Z,2015-02-28T00:34:45Z,"See the [release notes](http://ipython.org/ipython-doc/3/whatsnew/version3.html#release-3-0) for what's new.

or get it with pip:

```
pip install --upgrade ""ipython[all]""
```

DO NOT download from the ""Source code"" links below. They are missing git submodules, and won't work.
",658518
713,False,False,2015-02-09T22:58:44Z,2015-02-26T18:17:15Z,,658518
714,False,False,2014-05-21T19:28:11Z,2014-05-21T20:52:17Z,"bugfix release for IPython 2.0. See the [list of backported fixes](http://ipython.org/ipython-doc/2/whatsnew/github-stats-2.0.html).
",658518
715,False,False,2014-02-24T22:07:43Z,2014-02-24T22:23:17Z,"Bugfix release for Python 2.6 and 3.4.

[What's new in 1.2](http://ipython.org/ipython-doc/1/whatsnew/github-stats-1.0.html#issues-closed-in-1-2)
",658518
716,False,False,2014-02-10T21:52:22Z,2014-02-10T22:05:29Z,"IPython 1.2.0 mostly bugfix release

For release notes, see [what's new](http://ipython.org/ipython-doc/rel-1.2.0/whatsnew/github-stats-1.0.html).
",658518
717,False,False,2013-09-09T22:39:46Z,2013-09-09T23:06:09Z,"Mostly bugfix release for 1.0

Patches backported to IPython 1.1.0 (2013/08/08 - 2013/09/09)

These lists are automatically generated, and may be incomplete or contain duplicates.

The following 25 authors contributed 337 commits.
- Benjamin Ragan-Kelley
- Bing Xia
- Bradley M. Froehle
- Brian E. Granger
- Damián Avila
- dhirschfeld
- Dražen Lučanin
- gmbecker
- Jake Vanderplas
- Jason Grout
- Jonathan Frederic
- Kevin Burke
- Kyle Kelley
- Matt Henderson
- Matthew Brett
- Matthias Bussonnier
- Pankaj Pandey
- Paul Ivanov
- rossant
- Samuel Ainsworth
- Stephan Rave
- stonebig
- Thomas Kluyver
- Yaroslav Halchenko
- Zachary Sailer

We closed a total of 76 issues, 58 pull requests and 18 regular issues;
this is the full list (generated with the script :file:`tools/github_stats.py`):

Pull Requests (58):
- PR #4188 - Allow user_ns trait to be None
- PR #4189 - always fire LOCAL_IPS.extend(PUBLIC_IPS)
- PR #4174 - various issues in markdown and rst templates
- PR #4178 - add missing data_javascript
- PR #4181 - nbconvert: Fix, sphinx template not removing new lines from headers
- PR #4043 - don't 'restore_bytes' in from_JSON
- PR #4163 - Fix for incorrect default encoding on Windows.
- PR #4136 - catch javascript errors in any output
- PR #4171 - add nbconvert config file when creating profiles
- PR #4125 - Basic exercise of `ipython [subcommand] -h` and help-all
- PR #4085 - nbconvert: Fix sphinx preprocessor date format string for Windows
- PR #4159 - don't split `.cell` and `div.cell` CSS
- PR #4158 - generate choices for `--gui` configurable from real mapping
- PR #4065 - do not include specific css in embedable one
- PR #4092 - nbconvert: Fix for unicode html headers, Windows + Python 2.x
- PR #4074 - close Client sockets if connection fails
- PR #4064 - Store default codemirror mode in only 1 place
- PR #4104 - Add way to install MathJax to a particular profile
- PR #4144 - help_end transformer shouldn't pick up ? in multiline string
- PR #4143 - update example custom.js
- PR #4142 - DOC: unwrap openssl line in public_server doc
- PR #4141 - add files with a separate `add` call in backport_pr
- PR #4137 - Restore autorestore option for storemagic
- PR #4098 - pass profile-dir instead of profile name to Kernel
- PR #4120 - support `input` in Python 2 kernels
- PR #4088 - nbconvert: Fix coalescestreams line with incorrect nesting causing strange behavior
- PR #4060 - only strip continuation prompts if regular prompts seen first
- PR #4132 - Fixed name error bug in function safe_unicode in module py3compat.
- PR #4121 - move test_kernel from IPython.zmq to IPython.kernel
- PR #4118 - ZMQ heartbeat channel: catch EINTR exceptions and continue.
- PR #4054 - use unicode for HTML export
- PR #4106 - fix a couple of default block values
- PR #4115 - Update docs on declaring a magic function
- PR #4101 - restore accidentally removed EngineError
- PR #4096 - minor docs changes
- PR #4056 - respect `pylab_import_all` when `--pylab` specified at the command-line
- PR #4091 - Make Qt console banner configurable
- PR #4086 - fix missing errno import
- PR #4030 - exclude `.git` in MANIFEST.in
- PR #4047 - Use istype() when checking if canned object is a dict
- PR #4031 - don't close_fds on Windows
- PR #4029 - bson.Binary moved
- PR #4035 - Fixed custom jinja2 templates being ignored when setting template_path
- PR #4026 - small doc fix in nbconvert
- PR #4016 - Fix IPython.start_\* functions
- PR #4021 - Fix parallel.client.View map() on numpy arrays
- PR #4022 - DOC: fix links to matplotlib, notebook docs
- PR #4018 - Fix warning when running IPython.kernel tests
- PR #4019 - Test skipping without unicode paths
- PR #4008 - Transform code before %prun/%%prun runs
- PR #4014 - Fix typo in ipapp
- PR #3987 - get files list in backport_pr
- PR #3974 - nbconvert: Fix app tests on Window7 w/ Python 3.3
- PR #3978 - fix `--existing` with non-localhost IP
- PR #3939 - minor checkpoint cleanup
- PR #3981 - BF: fix nbconvert rst input prompt spacing
- PR #3960 - Don't make sphinx a dependency for importing nbconvert
- PR #3973 - logging.Formatter is not new-style in 2.6

Issues (18):
- #4024 - nbconvert markdown issues
- #4095 - Catch js error in append html in stream/pyerr
- #4156 - Specifying --gui=tk at the command line
- #3818 - nbconvert can't handle Heading with Chinese characters on Japanese Windows OS.
- #4134 - multi-line parser fails on ''' in comment, qtconsole and notebook.
- #3998 - sample custom.js needs to be updated
- #4078 - StoreMagic.autorestore not working in 1.0.0
- #3990 - Buitlin `input` doesn't work over zmq
- #4015 - nbconvert fails to convert all the content of a notebook
- #4059 - Issues with Ellipsis literal in Python 3
- #4103 - Wrong default argument of DirectView.clear
- #4100 - parallel.client.client references undefined error.EngineError
- #4005 - IPython.start_kernel doesn't work.
- #4020 - IPython parallel map fails on numpy arrays
- #3945 - nbconvert: commandline tests fail Win7x64 Py3.3
- #3977 - unable to complete remote connections for two-process 
- #3980 - nbconvert rst output lacks needed blank lines
- #3968 - TypeError: super() argument 1 must be type, not classobj (Python 2.6.6)
",658518
718,False,False,2013-08-09T01:01:50Z,2013-08-09T01:09:53Z,"IPython provides a rich toolkit to help you make the most out of using Python
interactively.  Its main components are:
- Powerful interactive Python shells (terminal- and Qt-based).
- A web-based interactive notebook environment with all shell features plus
  support for embedded figures, animations and rich media.
- Support for interactive data visualization and use of GUI toolkits.
- Flexible, embeddable interpreters to load into your own projects.
- A high-performance library for high level and interactive parallel computing
  that works in multicore systems, clusters, supercomputing and cloud scenarios.

The enhanced interactive Python shells have the following main features:
- Comprehensive object introspection.
- Input history, persistent across sessions.
- Caching of output results during a session with automatically generated
  references.
- Extensible tab completion, with support by default for completion of python
  variables and keywords, filenames and function keywords.
- Extensible system of 'magic' commands for controlling the environment and
  performing many tasks related either to IPython or the operating system.
- A rich configuration system with easy switching between different setups
  (simpler than changing $PYTHONSTARTUP environment variables every time).
- Session logging and reloading.
- Extensible syntax processing for special purpose situations.
- Access to the system shell with user-extensible alias system.
- Easily embeddable in other Python programs and GUIs.
- Integrated access to the pdb debugger and the Python profiler.

The parallel computing architecture has the following main features:
- Quickly parallelize Python code from an interactive Python/IPython session.
- A flexible and dynamic process model that be deployed on anything from
  multicore workstations to supercomputers.
- An architecture that supports many different styles of parallelism, from
  message passing to task farming.
- Both blocking and fully asynchronous interfaces.
- High level APIs that enable many things to be parallelized in a few lines
  of code.
- Share live parallel jobs with other users securely.
- Dynamically load balanced task farming system.
- Robust error handling in parallel code.

The latest development version is always available from IPython's [GitHub
site](http://github.com/ipython).
",658518
719,False,True,2020-03-26T20:47:56Z,2020-03-26T21:07:23Z,Development release for testing purposes,102908804
720,False,False,2020-02-28T23:40:35Z,2020-02-28T23:49:26Z,"**v0.13.3 Feb 28, 2020**
* Fixes
    * Fix a connection closed error when using n_jobs (#853)
* Changes
    * Pin msgpack dependency for Python 3.5; remove dataframe from Dask dependency (#851)
* Documentation Changes
    * Update link to help documentation page in Github issue template (#855)

Thanks to the following people for contributing to this release:
@frances-h, @rwedge",102908804
721,False,True,2020-02-28T22:44:55Z,2020-02-28T22:47:14Z,Development release for testing purposes,102908804
722,False,False,2020-02-01T01:36:50Z,2020-02-01T01:45:57Z,"**v0.13.2 Jan 31, 2020**
* Enhancements
    * Support for Pandas 1.0.0 (#844)
* Changes
    * Remove dependency on s3fs library for anonymous downloads from S3 (#825)
* Testing Changes
    * Added GitHub Action to automatically run performance tests (#840)

Thanks to the following people for contributing to this release:
@frances-h, @rwedge
",102908804
723,False,True,2020-01-31T20:31:14Z,2020-01-31T20:38:28Z,Test release for development purposes,102908804
724,False,False,2019-12-29T02:57:32Z,2019-12-29T03:07:43Z,"**v0.13.1 Dec 28, 2019**
* Enhancements
* Fixes
    * Raise error when given wrong input for ignore_variables (#826)
    * Fix multi-output features not created when there is no child data (#834)
    * Removing type casting in Equals and NotEquals primitives (#504)
* Changes
    * Replace pd.timedelta time units that were deprecated (#822)
    * Move sklearn wrapper to separate library (#835, #837)
* Documentation Changes
* Testing Changes
    * Run unit tests in windows environment (#790)
    * Update boto3 version requirement for tests (#838)

Thanks to the following people for contributing to this release:
@jeffzi, @kmax12, @rwedge, @systemshift",102908804
725,False,False,2019-12-26T21:24:49Z,2019-12-26T21:31:34Z,Test release for development purposes,102908804
726,False,False,2019-11-30T21:53:31Z,2019-11-30T22:02:57Z,"**v0.13.0 Nov 30, 2019**
* Enhancements
    * Added GitHub Action to auto upload releases to PyPI (#816)
* Fixes
    * Fix issue where some primitive options would not be applied (#807)
    * Fix issue with converting to pickle or parquet after adding interesting features (#798, #823)
    * Diff primitive now calculates using all available data (#824)
    * Prevent DFS from creating Identity Features of globally ignored variables (#819)
* Changes
    * Remove python 2.7 support from serialize.py (#812)
    * Make smart_open, boto3, and s3fs optional dependencies (#827)
* Documentation Changes
    * remove python 2.7 support and add 3.7 in install.rst (#805)
    * Fix import error in docs (#803)
    * Fix release title formatting in changelog (#806)
* Testing Changes
    * Use multiple CPUS to run tests on CI (#811)
    * Refactor test entityset creation to avoid saving to disk (#813, #821)
    * Remove get_values() from test_es.py to remove warnings (#820)

Thanks to the following people for contributing to this release:
@frances-h, @jeff-hernandez, @rwedge, @systemshift

**Breaking Changes**

* The libraries used for downloading or uploading from S3 or URLs are now
  optional and will no longer be installed by default.  To use this
  functionality they will need to be installed separately.
* The fix to how the Diff primitive is calculated may slow down the overall
  calculation time of feature lists that use this primitive.",102908804
727,False,True,2019-11-30T20:54:06Z,2019-11-30T20:56:49Z,Test release for development purposes,102908804
728,False,False,2019-10-31T22:27:57Z,2019-10-31T22:32:22Z,"**v0.12.0 Oct 31, 2019**
* Enhancements
    * Added First primitive (#770)
    * Added Entropy aggregation primitive (#779)
    * Allow custom naming for multi-output primitives (#780)
* Fixes
    * Prevents user from removing base entity time index using additional_variables (#768)
    * Fixes error when a multioutput primitive was supplied to dfs as a groupby trans primitive (#786)
* Changes
    * Drop Python 2 support (#759)
    * Add unit parameter to AvgTimeBetween (#771)
    * Require Pandas 0.24.1 or higher (#787)
* Documentation Changes
    * Update featuretools slack link (#765)
    * Set up repo to use Read the Docs (#776)
    * Add First primitive to API reference docs (#782)
* Testing Changes
    * CircleCI fixes (#774)
    * Disable PIP progress bars (#775)

Thanks to the following people for contributing to this release:
@ablacke-ayx, @BoopBoopBeepBoop, @jeffzi, @kmax12, @rwedge, @thehomebrewnerd, @twdobson",102908804
729,False,False,2019-10-17T20:55:54Z,2019-10-17T20:57:42Z,"**v0.4.1** Nov 29, 2018
* Resolve bug preventing using first column as index by default (#308)
* Handle return type when creating features from Id variables (#318)
* Make id an optional parameter of EntitySet constructor (#324)
* Handle primitives with same function being applied to same column (#321)
* Update requirements (#328)
* Clean up DFS arguments (#319)
* Clean up Pandas Backend (#302)
* Update properties of cumulative transform primitives (#320)
* Feature stability between versions documentation (#316)
* Add download count to GitHub readme (#310)
* Fixed #297 update tests to check error strings (#303)
* Remove usage of fixtures in agg primitive tests (#325)",102908804
730,False,False,2019-09-30T22:03:49Z,2019-09-30T22:13:59Z,"**v0.11.0 Sep 30, 2019**
* Enhancements
    * Improve how files are copied and written (#721)
    * Add number of rows to graph in entityset.plot (#727)
    * Added support for pandas DateOffsets in DFS and Timedelta (#732)
    * Enable feature-specific top_n value using a dictionary in encode_features (#735)
    * Added progress_callback parameter to dfs() and calculate_feature_matrix() (#739 #745)
    * Enable specifying primitives on a per column or per entity basis (#748)
* Fixes
    * Fixed entity set deserialization (#720)
    * Added error message when DateTimeIndex is a variable but not set as the time_index (#723)
    * Fixed CumCount and other group-by transform primitives that take ID as input (#733, #754)
    * Fix progress bar undercounting (#743)
* Updated training_window error assertion to only check against observations (#728)
    * Don't delete the whole destination folder while saving entityset (#717)
* Changes
    * Raise warning and not error on schema version mismatch (#718)
    * Change feature calculation to return in order of instance ids provided (#676)
    * Removed time remaining from displayed progress bar in dfs() and calculate_feature_matrix() (#739)
    * Raise warning in normalize_entity() when time_index of base_entity has an invalid type (#749)
    * Remove toolz as a direct dependency (#755)
    * Allow boolean variable types to be used in the Multiply primitive (#756)
* Documentation Changes
    * Updated URL for Compose (#716)
* Testing Changes
    * Update dependencies (#738, #741, #747)

Thanks to the following people for contributing to this release: @angela97lin, @chidauri, @christopherbunn, @frances-h, @jeff-hernandez, @kmax12, @MarcoGorelli, @rwedge, @thehomebrewnerd",102908804
731,False,False,2019-08-25T23:40:44Z,2019-08-25T23:50:16Z,"**v0.10.1 Aug 25, 2019**
* Fixes
    * Fix serialized LatLong data being loaded as strings (#712)
* Documentation Changes
    * Fixed FAQ cell output (#710)

Thanks to the following people for contributing to this release:
@gsheni, @rwedge",102908804
732,False,False,2019-08-19T23:07:52Z,2019-08-19T23:11:08Z,"**v0.10.0 Aug 19, 2019**

**The next non-bugfix release of Featuretools will not support Python 2**

* Enhancements
    * Give more frequent progress bar updates and update chunk size behavior (#631, #696)
    * Added drop_first as param in encode_features (#647)
    * Added support for stacking multi-output primitives (#679)
    * Generate transform features of direct features (#623)
    * Added serializing and deserializing from S3 and deserializing from URLs (#685)
    * Added nlp_primitives as an add-on library (#704)
    * Added AutoNormalize to Featuretools plugins (#699)
    * Added functionality for relative units (month/year) in Timedelta (#692)
    * Added categorical-encoding as an add-on library (#700)
* Fixes
    * Fix performance regression in DFS (#637)
    * Fix deserialization of feature relationship path (#665)
    * Set index after adding ancestor relationship variables (#668)
    * Fix user-supplied variable_types modification in Entity init (#675)
    * Don't calculate dependencies of unnecessary features (#667)
    * Prevent normalize entity's new entity having same index as base entity (#681)
    * Update variable type inference to better check for string values (#683)
* Changes
    * Moved dask, distributed imports (#634)
* Documentation Changes
    * Miscellaneous changes (#641, #658)
    * Modified doc_string of top_n in encoding (#648)
    * Hyperlinked ComposeML (#653)
    * Added FAQ (#620, #677)
    * Fixed FAQ question with multiple question marks (#673)
* Testing Changes
    * Add master, and release tests for premium primitives (#660, #669)
    * Miscellaneous changes (#672, #674)

Thanks to the following people for contributing to this release:
@alexjwang, @allisonportis, @ayushpatidar, @CJStadler, @ctduffy, @gsheni, @jeff-hernandez, @jeremyliweishih, @kmax12, @rwedge, @zhxt95",102908804
733,False,False,2019-07-03T21:06:05Z,2019-07-03T21:18:17Z,"**v0.9.1 July 3, 2019**
* Enhancements
    * Speedup groupby transform calculations (#609)
    * Generate features along all paths when there are multiple paths between entities (#600, #608)
* Fixes
    * Select columns of dataframe using a list (#615)
    * Change type of features calculated on Index features to Categorical (#602)
    * Filter dataframes through forward relationships (#625)
    * Specify Dask version in requirements for python 2 (#627)
    * Keep dataframe sorted by time during feature calculation (#626)
    * Fix bug in encode_features that created duplicate columns of
      features with multiple outputs (#622)
* Changes
    * Remove unused variance_selection.py file (#613)
    * Remove Timedelta data param (#619)
    * Remove DaysSince primitive (#628)
* Documentation Changes
    * Add installation instructions for add-on libraries (#617)
    * Miscellaneous changes (#632, #639)
* Testing Changes
    * Miscellaneous changes (#595, #612)

Thanks to the following people for contributing to this release: @CJStadler, @gsheni, @kkleidal, @kmax12, @rwedge",102908804
734,False,False,2019-06-19T19:04:42Z,2019-06-19T19:14:19Z,"**v0.9.0** June 19, 2019
* Enhancements
    * Add unit parameter to timesince primitives (#558)
    * Add ability to install optional add on libraries (#551)
    * Load and save features from open files and strings (#566)
    * Support custom variable types (#571)
    * Support entitysets which have multiple paths between two entities (#572, #544)
    * Added show_info function, more output information added to CLI `featuretools info` (#525)
* Fixes
    * Normalize_entity specifies error when 'make_time_index' is an invalid string (#550)
    * Schema version added for entityset serialization (#586)
    * Renamed features have names correctly serialized (#585)
    * Improved error message for index/time_index being the same column in normalize_entity and entity_from_dataframe (#583)
    * Removed all mentions of allow_where (#587, #588)
    * Removed unused variable in normalize entity (#589)
    * Change time since return type to numeric (#606)
* Changes
    * Refactor get_pandas_data_slice to take single entity (#547)
    * Updates TimeSincePrevious and Diff Primitives (#561)
    * Remove unecessary time_last variable (#546)
* Documentation Changes
    * Add Featuretools Enterprise to documentation (#563)
    * Miscellaneous changes (#552, #573, #577, #599)
* Testing Changes
    * Miscellaneous changes (#559, #569, #570, #574, #584, #590)

Thanks to the following people for contributing to this release:
@alexjwang, @allisonportis, @CJStadler, @ctduffy, @gsheni, @kmax12, @rwedge
",102908804
735,False,False,2019-05-18T00:28:47Z,2019-05-18T00:29:52Z,"**v0.8.0** May 17, 2019
* Rename NUnique to NumUnique (#510)
* Serialize features as JSON (#532)
* Drop all variables at once in normalize_entity (#533)
* Remove unnecessary sorting from normalize_entity (#535)
* Features cache their names (#536)
* Only calculate features for instances before cutoff (#523)
* Remove all relative imports (#530)
* Added FullName Variable Type (#506)
* Add error message when target entity does not exist (#520)
* New demo links (#542)
* Remove duplicate features check in DFS (#538)
* featuretools_primitives entry point expects list of primitive classes (#529)
* Update ALL_VARIABLE_TYPES list (#526)
* More Informative N Jobs Prints and Warnings (#511)
* Update sklearn version requirements (#541)
* Update Makefile (#519)
* Remove unused parameter in Entity._handle_time (#524)
* Remove build_ext code from setup.py (#513)
* Documentation updates (#512, #514, #515, #521, #522, #527, #545)
* Testing updates (#509, #516, #517, #539)

Thanks to the following people for contributing to this release: @bphi, @CharlesBradshaw, @CJStadler, @glentennis, @gsheni, @kmax12, @rwedge
",102908804
736,False,False,2019-04-24T15:46:35Z,2019-04-24T15:51:05Z,"**v0.7.1** Apr 24, 2019
* Automatically generate feature name for controllable primitives (#481)
* Primitive docstring updates (#489, #492, #494, #495)
* Change primitive functions that returned strings to return functions (#499)
* CLI customizable via entrypoints (#493)
* Improve calculation of aggregation features on grandchildren (#479)
* Refactor entrypoints to use decorator (#483)
* Include doctests in testing suite (#491)
* Documentation updates (#490)
* Update how standard primitives are imported internally (#482)

Thanks to the following people for contributing to this release: @bukosabino, @CharlesBradshaw, @glentennis, @gsheni, @jeff-hernandez, @kmax12, @minkvsky, @rwedge, @thehomebrewnerd ",102908804
737,False,False,2019-03-29T17:16:22Z,2019-03-29T17:19:11Z,"**v0.7.0** Mar 29, 2019
* Improve Entity Set Serialization (#361)
* Support calling a primitive instance's function directly (#461, #468)
* Support other libraries extending featuretools functionality via entrypoints (#452)
* Remove featuretools install command (#475)
* Add GroupByTransformFeature (#455, #472, #476)
* Update Haversine Primitive (#435, #462)
* Add commutative argument to SubtractNumeric and DivideNumeric primitives (#457)
* Add FilePath variable_type (#470)
* Add PhoneNumber, DateOfBirth, URL variable types (#447)
* Generalize infer_variable_type, convert_variable_data and convert_all_variable_data methods (#423)
* Documentation updates (#438, #446, #458, #469)
* Testing updates (#440, #444, #445, #459)

Thanks to the following people for contributing to this release: @bukosabino, @CharlesBradshaw, @ColCarroll, @glentennis, @grayskripko, @gsheni, @jeff-hernandez, @jrkinley, @kmax12, @RogerTangos, @rwedge


**Breaking Changes**
* ``ft.dfs`` now has a ``groupby_trans_primitives`` parameter that DFS uses to automatically construct features that group by an ID column and then apply a transform primitive to search group. This change applies to the following primitives: ``CumSum``, ``CumCount``, ``CumMean``, ``CumMin``, and ``CumMax``.

    Previous behavior

    .. code-block:: python

        ft.dfs(entityset=es,
               target_entity='customers',
               trans_primitives=[""cum_mean""])

    New behavior

    .. code-block:: python

        ft.dfs(entityset=es,
               target_entity='customers',
               groupby_trans_primitives=[""cum_mean""])

* Related to the above change, cumulative transform features are now defined using a new feature class, ``GroupByTransformFeature``.

    Previous behavior

    .. code-block:: python

        ft.Feature([base_feature, groupby_feature], primitive=CumulativePrimitive)


    New behavior

    .. code-block:: python

        ft.Feature(base_feature, groupby=groupby_feature, primitive=CumulativePrimitive)

Summary:
",102908804
738,False,False,2019-02-15T20:08:29Z,2019-02-15T20:10:24Z,"**v0.6.1** Feb 15, 2019
* Cumulative primitives (#410)
* Entity.query_by_values now preserves row order of underlying data (#428)
* Implementing Country Code and Sub Region Codes as variable types (#430)
* Added IPAddress and EmailAddress variable types (#426)
* Install data and dependencies (#403)
* Add TimeSinceFirst, fix TimeSinceLast (#388)
* Allow user to pass in desired feature return types (#372)
* Add new configuration object (#401)
* Replace NUnique get_function (#434)
* _calculate_idenity_features now only returns the features asked for, instead of the entire entity (#429)
* Primitive function name uniqueness (#424)
* Update NumCharacters and NumWords primitives (#419)
* Removed Variable.dtype (#416, #433)
* Change to zipcode rep, str for pandas (#418)
* Remove pandas version upper bound (#408)
* Make S3 dependencies optional (#404)
* Check that agg_primitives and trans_primitives are right primitive type (#397)
* Mean primitive changes (#395)
* Fix transform stacking on multi-output aggregation (#394)
* Fix list_primitives (#391)
* Handle graphviz dependency (#389, #396, #398)
* Testing updates (#402, #417, #433)
* Documentation updates (#400, #409, #415, #417, #420, #421, #422, #431)

Thanks to the following people for contributing to this release:  @CharlesBradshaw, @csala, @floscha, @gsheni, @jxwolstenholme, @kmax12, @RogerTangos, @rwedge",102908804
739,False,False,2019-01-30T23:05:13Z,2019-01-30T23:07:03Z,"**v0.6.0** Jan 30, 2018
* Primitive refactor (#364)
* Mean ignore NaNs (#379)
* Plotting entitysets (#382)
* Add seed features later in DFS process (#357)
* Multiple output column features (#376)
* Add ZipCode Variable Type (#367)
* Add `primitive.get_filepath` and example of primitive loading data from external files (#380)
* Transform primitives take series as input (#385)
* Update dependency requirements (#378, #383, #386)
* Add modulo to override tests (#384)
* Update documentation (#368, #377)
* Update README.md (#366, #373)
* Update CI tests (#359, #360, #375)

Thanks to the following people for contributing to this release: @floscha, @gsheni, @kmax12, @RogerTangos, @rwedge",102908804
740,False,False,2018-12-18T01:40:47Z,2018-12-18T01:40:57Z,"**v0.5.1** Dec 17, 2018

* Add missing dependencies  (#353)
* Move comment to note in documentation  (#352)",102908804
741,False,False,2018-12-17T23:28:47Z,2018-12-17T23:35:29Z,"**v0.5.0** Dec 17, 2018
* Add specific error for duplicate additional/copy_variables in normalize_entity (#348)
* Removed EntitySet._import_from_dataframe (#346)
* Removed time_index_reduce parameter (#344)
* Allow installation of additional primitives (#326)
* Fix DatetimeIndex variable conversion (#342)
* Update Sklearn DFS Transformer (#343)
* Clean up entity creation logic (#336)
* remove casting to list in transform feature calculation (#330)
* Fix sklearn wrapper (#335)
* Add readme to pypi
* Update conda docs after move to conda-forge (#334)
* Add wrapper for scikit-learn Pipelines (#323)
* Remove parse_date_cols parameter from EntitySet._import_from_dataframe (#333)

Thanks to the following people for contributing to this release: @bukosabino, @georgewambold, @gsheni, @jeff-hernandez, @kmax12, and @rwedge.",102908804
742,False,False,2018-10-31T22:18:53Z,2018-10-31T22:21:28Z,"**v0.4.0** Oct 31, 2018
* Remove ft.utils.gen_utils.getsize and make pympler a test requirement (#299)
* Update requirements.txt (#298)
* Refactor EntitySet.find_path(...) (#295)
* Clean up unused methods (#293)
* Remove unused parents property of Entity (#283)
* Removed relationships parameter (#284)
* Improve time index validation (#285)
* Encode features with ""unknown"" class in categorical (#287)
* Allow where clauses on direct features in Deep Feature Synthesis (#279)
* Change to fullargsspec (#288)
* Parallel verbose fixes (#282)
* Update tests for python 3.7 (#277)
* Check duplicate rows cutoff times (#276)
* Load retail demo data using compressed file (#271)",102908804
743,False,False,2018-09-28T21:28:01Z,2018-10-01T15:34:59Z,"**v0.3.1** Sept 28, 2018
- Handling time rewrite (#245)
- Update deep_feature_synthesis.py (#249)
- Handling return type when creating features from DatetimeTimeIndex (#266)
- Update retail.py (#259)
- Improve Consistency of Transform Primitives (#236)
- Update demo docstrings (#268)
- Handle non-string column names (#255)
- Clean up merging of aggregation primitives (#250)
- Add tests for Entity methods (#262)
- Handle no child data when calculating aggregation features with multiple arguments (#264)
- Add `is_string` utils function (#260)
- Update python versions to match docker container (#261)
- Handle where clause when no child data (#258)
- No longer cache demo csvs, remove config file (#257)
- Avoid stacking ""expanding"" primitives (#238)
- Use randomly generated names in retail csv (#233)
- Update README.md (#243)",102908804
744,False,False,2018-08-28T00:40:26Z,2018-08-28T00:41:29Z,"**v0.3.0** Aug 27, 2018
* Improve performance of all feature calculations (#224)
* Update agg primitives to use more efficient functions (#215)
* Optimize metadata calculation (#229)
* More robust handling when no data at a cutoff time (#234)
* Workaround categorical merge (#231)
* Switch which CSV is associated with which variable (#228)
* Remove unused kwargs from query_by_values, filter_and_sort (#225)
* Remove convert_links_to_integers (#219)
* Add conda install instructions (#223, #227)
* Add example of using Dask to parallelize to docs  (#221)",102908804
745,False,False,2018-08-20T16:28:07Z,2018-08-20T16:29:06Z,"**v0.2.2** Aug 20, 2018
* Remove unnecessary check no related instances call and refactor (#209)
* Improve memory usage through support for pandas categorical types (#196)
* Bump minimum pandas version from 0.20.3 to 0.23.0 (#216)
* Better parallel memory warnings (#208, #214)
* Update demo datasets (#187, #201, #207)
* Make primitive lookup case insensitive  (#213)
* Use capital name (#211)
* Set class name for Min (#206)
* Remove `variable_types` from normalize entity (#205)
* Handle parquet serialization with last time index (#204)
* Reset index of cutoff times in calculate feature matrix (#198)
* Check argument types for .normalize_entity (#195)
* Type checking ignore entities.  (#193)
",102908804
746,False,False,2018-07-02T17:32:10Z,2018-07-02T18:58:31Z,"**v0.2.1** July 2, 2018
* Cpu count fix (#176)
* Update flight (#175)
* Move feature matrix calculation helper functions to separate file (#177)",102908804
747,False,False,2018-06-22T22:54:34Z,2018-06-22T22:56:45Z,"**v0.2.0** June 22, 2018
* Multiprocessing (#170)
* Handle unicode encoding in repr throughout Featuretools (#161)
* Clean up EntitySet class (#145)
* Add support for building and uploading conda package (#167)
* Parquet serialization (#152)
* Remove variable stats (#171)
* Make sure index variable comes first (#168)
* No last time index update on normalize (#169)
* Remove list of times as on option for `cutoff_time` in `calculate_feature_matrix` (#165)
* Config does error checking to see if it can write to disk (#162)",102908804
748,False,False,2018-05-30T21:18:05Z,2018-05-30T21:19:38Z,"**v0.1.21** May 30, 2018
* Support Pandas 0.23.0 (#153, #154, #155, #159)
* No EntitySet required in loading/saving features (#141)
* Use s3 demo csv with better column names (#139)
* more reasonable start parameter (#149)
* add issue template (#133)
* Improve tests (#136, #137, #144, #147)
* Remove unused functions (#140, #143, #146)
* Update documentation after recent changes / removals (#157)
* Rename demo retail csv file (#148)
* Add names for binary (#142)
* EntitySet repr to use get_name rather than id (#134)
* Ensure config dir is writable (#135)",102908804
749,False,True,2018-04-30T11:47:55Z,2018-04-30T11:57:48Z,,102908804
750,False,False,2018-04-13T16:19:46Z,2018-04-13T16:22:17Z,"**v0.1.20** Apr 13, 2018
* Improved chunking when calculating feature matrices  (#121)
* Primitives as strings in DFS parameters (#129)
* Integer time index bugfixes (#128)
* Add make_temporal_cutoffs utility function (#126)
* Show all entities, switch shape display to row/col (#124)
* fixed num characters nan fix (#118)
* modify ignore_variables docstring (#117)",102908804
751,False,False,2018-03-21T17:58:11Z,2018-03-21T18:00:35Z,"**v0.1.19** Mar 21, 2018
* More descriptive DFS progress bar (#69)
* Convert text variable to string before NumWords (#106)
* EntitySet.concat() reindexes relationships (#96)
* Keep non-feature columns when encoding feature matrix (#111)
* Uses full entity update for dependencies of uses_full_entity features (#110)
* Update column names in retail demo (#104)
* Handle Transform features that need access to all values of entity (#91)",102908804
752,False,False,2018-02-27T16:24:06Z,2018-02-27T16:25:38Z,"**v0.1.18** Feb 27, 2018
* fixes related instances bug (#97)
* Adding non-feature columns to calculated feature matrix (#78)
* Relax numpy version req (#82)
* Remove `entity_from_csv`, tests, and lint (#71)",102908804
753,False,False,2018-01-18T20:01:13Z,2018-01-18T20:02:21Z,"**v0.1.17** Jan 18, 2018
* LatLong type (#57)
* Last time index fixes (#70)
* Make median agg primitives ignore nans by default (#61)
* Remove Python 3.4 support (#64)
* Change `normalize_entity` to update `secondary_time_index` (#59)
* Unpin requirements (#53)
* associative -> commutative (#56)
* Add Words and Chars primitives (#51)",102908804
754,False,False,2017-12-20T04:35:04Z,2017-12-20T04:35:37Z,"**v0.1.16** 
Dec 19, 2017
    * fix EntitySet.combine_variables and standardize encode_features (#47)
    * Python 3 compatibility (#16)

Thank you to @joshblum for the work on the Python 3 support in this release. ",102908804
755,False,False,2017-12-18T23:44:44Z,2017-12-18T23:45:49Z,"**Changelog**
**v0.1.15** Dec 18, 2017
    * Fix variable type in demo data (#37)
    * Custom primitive kwarg fix (#38)
    * Changed order and text of arguments in make_trans_primitive docstring (#42)",102908804
756,False,False,2017-11-21T01:51:53Z,2017-11-21T01:53:25Z,"Changes
* Last time index (#33)
* Update Scipy version to 1.0.0 (#31)",102908804
757,False,False,2017-11-01T18:13:20Z,2017-11-01T18:14:11Z,"**v0.1.13** November 1, 2017
    * Add MANIFEST.in #26 ",102908804
758,False,False,2017-10-31T20:00:38Z,2017-10-31T20:03:14Z,"v0.1.11 October 31, 2017

* Package linting (#7)
* Custom primitive creation functions (#13)
* Split requirements to separate files and pin to latest versions (#15)
* Select low information features (#18)
* Fix docs typos (#19)
* Fixed Diff primitive for rare nan case (#21)
* added some mising doc strings (#23)
* Trend fix (#22)
* Remove as_dir=False option from EntitySet.to_pickle() (#20)
* Entity Normalization Preserves Types of Copy & Additional Variables (#25)",102908804
759,False,False,2017-10-12T16:33:52Z,2017-10-12T16:34:42Z,"v0.1.10 October 12, 2017
* NumTrue primitive added and docstring of other primitives updated (#11)
* fixed hash issue with same base features (#8)
* Head fix (#9)
* Fix training window (#10)
* Add associative attribute to primitives (#3)
* Add status badges, fix license in setup.py (#1)
* fixed head printout and flight demo index (#2)",102908804
760,False,False,2017-09-09T02:33:02Z,2017-09-09T02:33:40Z,See changelog: https://docs.featuretools.com/v0.1.9/changelog.html,102908804
761,False,False,2020-02-13T19:07:58Z,2020-02-13T00:27:11Z,":fireworks: :ship: :fireworks: **Dagster 0.7.0: Waiting To Exhale** :triumph: :relieved:  :tea: 

We are pleased to announce version 0.7.0 of Dagster, codenamed “Waiting To Exhale”. We set out to make Dagster a solution for production-grade pipelines on modern cloud infrastructure. In service of that goal, we needed to fill missing gaps and incorporate feedback from the community at large. 

Our last release, [0.6.0](https://medium.com/dagster-io/dagster-0-6-0-impossible-princess-898b459375e0), expanded Dagster from local developer experience to a hostable product, allowing for scheduling, execution, and monitoring of pipelines in the cloud.

This release goes further, supporting pipelines with 100s and 1000s of nodes, deployable to modern, scalable cloud infrastructure, with dramatically improved monitoring tools, as well as other features.

Given this, 0.7.0 introduces the following:

* **Revamped, Scalable Dagit** A completely redesigned Dagit with a more intuitive navigation structure, beautiful look-and-feel, and massive performance improvements to handle pipelines with hundreds or even thousands of nodes.
* **Execution Viewer** Executing and historical runs within Dagit uses a new live-updating, queryable waterfall viewer. See below for a preview of the new UI:

https://media.giphy.com/media/Rhx6ujovXlvuKaLCGY/giphy.gif

* A **Dagster-K8s** library which provides the ability to launch runs in ephemeral Kubernetes Pods, as well as an early helm chart for executing pipelines.
* A **Dagster-Celery** library designed to work with K8s that provides global resource management using dedicated queues, and distributed execution of dagster pipelines across a cluster.
* Streamlined **scheduler configuration** and new **backfill APIs and tools** to help manage your scheduled workflows in production.
* A **Dagster-Pandas** integration that provides useful APIs for dataframe validation, summary statistics emission, and auto-documentation in dagit so that you can better understand and control how data flows through your pipelines.
* **Redesigned documentation**, examples, and guides to help flesh out the core ideas behind the system.


**Warning**

There are a substantial number of breaking changes in the 0.7.0 release. These changes effect the scheduler system, config system, required resources, and the type system. We apologize for the thrash, and thank you for bearing with us!

For more info on changes check out the following resources:

Changelog: https://github.com/dagster-io/dagster/blob/master/CHANGES.md 

0.7.0 migration guide: https://github.com/dagster-io/dagster/blob/master/070_MIGRATION.md",131619646
762,False,False,2019-04-18T16:49:43Z,2019-04-18T18:51:32Z,"**API Changes**

- There is now a new top-level configuration section ``storage`` which controls whether or not
  execution should store intermediate values and the history of pipeline runs on the filesystem,
  on S3, or in memory. The ``dagster`` CLI now includes options to list and wipe pipeline run
  history. Facilities are provided for user-defined types to override the default serialization
  used for storage.
- Similarily, there is a new configuration for ``RunConfig`` where the user can specify
  intermediate value storage via an API.
- ``OutputDefinition`` now contains an explicit ``is_optional`` parameter and defaults to being
  not optional.
- New functionality in ``dagster.check``: ``is_list``
- New functionality in ``dagster.seven``: py23-compatible ``FileNotFoundError``, ``json.dump``,
  ``json.dumps``.
- Dagster default logging is now multiline for readability.
- The ``Nothing`` type now allows dependencies to be constructed between solids that do not have
  data dependencies.
- Many error messages have been improved.
- ``throw_on_user_error`` has been renamed to ``raise_on_error`` in all APIs, public and private

**GraphQL**

- The GraphQL layer has been extracted out of Dagit into a separate dagster-graphql package.
- ``startSubplanExecution`` has been replaced by ``executePlan``.
- ``startPipelineExecution`` now supports reexecution of pipeline subsets.

**Dagit**

- It is now possible to reexecute subsets of a pipeline run from Dagit.
- Dagit's `Execute` tab now opens runs in separate browser tabs and a new `Runs` tab allows you to
  browse and view historical runs.
- Dagit no longer scaffolds configuration when creating new `Execute` tabs. This functionality will
  be refined and revisited in the future.
- Dagit's `Explore` tab is more performant on large DAGs.
- The ``dagit -q`` command line flag has been deprecated in favor of a separate command-line
  ``dagster-graphql`` utility.
- The execute button is now greyed out when Dagit is offline.
- The Dagit UI now includes more contextual cues to make the solid in focus and its connections
  more salient.
- Dagit no longer offers to open materializations on your machine. Clicking an on-disk
  materialization now copies the path to your clipboard.
- Pressing Ctrl-Enter now starts execution in Dagit's Execute tab.
- Dagit properly shows List and Nullable types in the DAG view.

**Dagster-Airflow**

- Dagster-Airflow includes functions to dynamically generate containerized (``DockerOperator``-based)
  and uncontainerized (``PythonOperator``-based) Airflow DAGs from Dagster pipelines and config.

**Libraries**

- Dagster integration code with AWS, Great Expectations, Pandas, Pyspark, Snowflake, and Spark
  has been reorganized into a new top-level libraries directory. These modules are now
  importable as ``dagster_aws``, ``dagster_ge``, ``dagster_pandas``, ``dagster_pyspark``,
  ``dagster_snowflake``, and ``dagster_spark``.
- Removed dagster-sqlalchemy and dagma

**Examples**

- Added the event-pipeline-demo, a realistic web event data pipeline using Spark and Scala.
- Added the Pyspark pagerank example, which demonstrates how to incrementally introduce dagster
  into existing data processing workflows.

**Documentation**

- Docs have been expanded, reorganized, and reformatted.
",131619646
763,False,False,2019-03-14T22:24:47Z,2019-03-15T15:40:39Z,Hotfix to not put config values in error messages. Had to re-release because of packaging errors uploaded pypi (.pyc files or similar were included),131619646
764,False,False,2018-11-01T20:30:39Z,2018-11-01T20:31:25Z,Pushing an update because dagit 0.2.8 was getting out-of-date code.,131619646
765,False,False,2018-11-01T17:13:44Z,2018-11-01T17:14:28Z,"- Version bump to deal with likely pypi issue around using a fourth-level version number
- Added more elegant syntax for building solid and context configs",131619646
766,False,False,2018-10-31T23:00:54Z,2018-10-31T23:01:47Z,"Version 0.2.7 Release Notes

Most notable improvements in this release are bunch of improvements to dagit, most notably hot reloading and the in-browser rendering of python error. Also the ability to scaffold configs from the command line is the first fruit of the rearchitecting of the config system.

- Dagster improvements:
	- Added scaffold_config command which generates the template of a yaml file needed to drive the execution of a particular pipeline
	- Added the ability to automatically serialize intermediate inputs as they flow between solids. Consider this alpha quality. It is currently hard-coded to write out to /tmp/dagster/runs/<<run_id>>

- Dagit improvements:
	- Hot-Reloading and in-browser rendering of python errors.
	- Scrolling and performance improvements
	- Keyboard short cuts to navigate between solids using arrow keys
	- In-app previews of notebooks for dagstermill solids",131619646
767,False,False,2018-10-09T00:58:12Z,2018-10-09T00:58:52Z,"Changes:

  - 'run_id' value automatically included in ExecutionContext context
  stack. This is a uuid.
  - Config system update:

  This is a significant change in the config system. Now the top level environment objects (and all descendants) are now part of the dagster type system. Unique types are generated on a per-pipeline basis. This unlocks a few things:

1. The entirety of yaml config files are now type-checked in the same fashion as the user-defined config.
2. One can now pass dictionaries to execute_pipeline that mimic the yaml files exactly. You no longer have to use the dagster.config APIs (although those still work)
3. The entire config system is queryable via graphql (and therefore shows up in dagit). This adds some noise to the type browser (we can mitigate that soon), but this will enable the building of a config-editor is fully aware of the dagster type system.
4. This has one *breaking* change. The yaml file's format has changed slightly.

Previously:

```
context:
   name: context_name
   config: some_config_value
```

Now:

```
context:
   context_name:
       config: some_config_value
```

BREAKING CHANGE: Config format change. See above.",131619646
768,False,False,2018-10-05T03:14:39Z,2018-10-05T03:16:01Z,"Version bump to 0.2.5 (#227)

- Added the Type Explorer in Dagit. You can now browse all the types
declared in a pipeline.
- Added the --watch/--no-watch flag to dagit. This allows you to turn
off watching in cases where there are two many files below the
current working directory.

",131619646
769,False,False,2018-10-01T14:41:18Z,2018-10-01T14:42:05Z,"This version bump contains a few changes (including one breaking
change).

- New, radically improved version of dagit. Vertical layout, and a
beautiful new design. H/T to @bengotow for this spectacular work.
- All types now *require* names. This is breaking change for
ConfigDictionary, which did not require a name. You will
have to change your calls to ConfigDictionary or
ConfigDefinition.config_dict to include a name that is unique to the
Pipeline.
- Solids default to take *no* config definition, rather than a config
definition typed as any.",131619646
770,False,False,2018-09-22T17:29:04Z,2018-09-22T17:31:17Z," Driving factor to release this is a bug in the command line interface in 0.2.2 (https://github.com/dagster-io/dagster/issues/207)

 Other changes in this release:

- CLI interface has changed slightly. Whenver dagit or dagster needs to
specify a function to load a repo or a pipeline, us the -n/--fn-name
flag combo. Before this was split out into to different use cases in
dagster.
- We now have the ability to reuse a single solid definition multiple
times within the same pipeline using the SolidInstance API. See the
corresponding tutorial section for more details.
- Documentation continues to improve.
",131619646
771,False,False,2018-09-20T21:55:57Z,2018-09-20T21:57:08Z,"@channel

The first dot release! up-to-date versions of dagster and dagit 0.2.2. (I just skipped 0.2.1 of dagster so that dagit and dagster are in sync. I won’t get into why pypi is dumb and made me do that)

There are virtually no changes to the python API. This update was for the CLI interface to make it so that you can use it without the repository.yml file and without installed modules.

You can now use dagit (or dagster) like:

`dagit -f step_one.py -r define_pipeline`

to load the pipeline straightaway from a function rather than having to go through repositories and yaml files.",131619646
772,False,False,2018-09-20T21:52:42Z,2018-09-20T21:55:25Z,"This is the first ""major"" release of dagster meant for consumption. The public APIs in this release will be supported for some time.

New things in this release:

- Solids do not specify their dependencies anymore. They are more easily reusable between pipelines. Dependencies now specified at the pipeline level.
- Solids support multiple outputs and branching
- Solids can take config, in addition to inputs and outputs.
- Sources and materializations have been eliminated as formal abstractions. Solids accepting configs enabled this.
- New configuration system with full type system instead of argument dictionary. Configs can be arbitrarily nested and support composite types. 
- New result api
- New execution engine. this now does a compiler-esque pass where a new logical execution graph of nodes is generated from the logical definition files and config.
- Python 2.7, 3.5 and 3.6 now supported
- RepositoryDefinition has been added. pipelines.yml is gone
- Full documentation of all public APIs
- Multi-part tutorial that introduces all concepts.
- @solid now must take info object, which has config and context members. @lambda_solid is for simple cases that do not require config and context.
- ... Much more",131619646
773,False,False,2018-08-17T16:29:02Z,2018-08-17T16:38:11Z,"Just starting to use the tag feature to mark releases for the first time.

This is the last version I will be release before the major breaking change coming in 0.2.0 that will change the way that dependencies are configured and eliminate sources and materializations as formalized abstractions.",131619646
774,False,False,2020-03-18T17:59:02Z,2020-03-18T18:02:01Z,"* validate result dict when instantiating an ExpectationValidationResult (#1133)
* DataDocs: Expectation Suite name on Validation Result pages now link to Expectation Suite page
* `great_expectations init`: cli now asks user if csv has header when adding a Spark Datasource with csv file
* Improve support for using GCP Storage Bucket as a Data Docs Site backend (thanks @hammadzz)
* fix notebook renderer handling for expectations with no column kwarg and table not in their name (#1194 )
",103071520
775,False,False,2020-03-19T23:17:11Z,2020-03-19T23:19:03Z,"# 0.9.7

## Changes

* Update marshmallow dependency to >3. NOTE: as of this release, you MUST use marshamllow >3.0, which REQUIRES python 3. #1187 @jcampbell
  - Schema checking is now stricter for expectation suites, and data_asset_name must not be present as a top-level
    key in expectation suite json. It is safe to remove.
  - Similarly, datasource configuration must now adhere strictly to the required schema, including having any
    required credentials stored in the ""credentials"" dictionary.
* New beta CLI command: `tap new` that generates an executable python file to expedite deployments. #1193 @Aylr
* Added feature maturity in README #1203 @kyleaton

## Fixes

* Fix failing test that should skip if postgresql not running #1199 @cicdw
* bugfix in TableBatchKwargsGenerator docs",103071520
776,False,False,2020-03-13T01:15:47Z,2020-03-13T01:16:57Z,"## What’s Changed

* Notebook empty suite fixes, suite edit bugfixes (#1155) @Aylr
* Update evaluation_parameters.rst (#1167) @spbail
* Update expectation_glossary.rst (#1164) @spbail
* release checklist (#1146) @Aylr",103071520
777,False,False,2020-03-11T02:14:40Z,2020-03-11T02:16:24Z,"* Update CLI `init` flow to support snowflake transient tables
* Use filename for default expectation suite name in CLI `init`
* Tables created by SqlAlchemyDataset use a shorter name with 8 hex characters of randomness instead of a full uuid
* Better error message when config substitution variable is missing
* removed an unused directory in the GE folder
* removed obsolete config error handling
* Docs typo fixes
* Jupyter notebook improvements
* `great_expectations init` improvements
* Simpler messaging in valiation notebooks
* replaced hacky loop with suite list call in notebooks
* CLI suite new now supports `--empty` flag that generates an empty suite and opens a notebook
* add error handling to `init` flow for cases where user tries using a broken file",103071520
778,False,False,2020-03-10T18:56:17Z,2020-03-06T00:43:36Z,"* Add support for transient table creation in snowflake (#1012)
* Improve path support in TupleStoreBackend for better cross-platform compatibility
* New features on `ExpecatationSuite`
    - `.add_citation()`
    - `get_citations()`
* `SampleExpectationsDatasetProfiler` now leaves a citation containing the original batch kwargs
* `great_expectations suite edit` now uses batch_kwargs from citations if they exist
* Bugfix :: suite edit notebooks no longer blow away the existing suite while loading a batch of data
* More robust and tested logic in `suite edit`
* DataDocs: bugfixes and improvements for smaller viewports
* Bugfix :: fix for bug that crashes SampleExpectationsDatasetProfiler if unexpected_percent is of type decimal.Decimal (`#1109 <https://github.com/great-expectations/great_expectations/issues/1109>`_)
",103071520
779,False,False,2020-02-21T23:49:13Z,2020-03-02T17:19:34Z,"# 0.9.2

This is small release with a bug fix and a new feature added to the CLI. To see the names of all suites in your project, run `great_expectations suite list` or call `. list_expectation_suite_names()` on your `DataContext`.

## Details

* Fixes #1095 
* Added a `list_expectation_suites` function to `data_context`, and a corresponding CLI function - `suite list`. (Thanks @talagluck)
* CI no longer enforces legacy python tests.
",103071520
780,False,False,2020-02-21T13:06:00Z,2020-02-21T23:51:51Z,,103071520
781,False,False,2020-02-19T00:04:35Z,2020-02-19T00:24:09Z,"Version 0.9.0 is a major update to Great Expectations! 

The DataContext has continued to evolve into a powerful tool for ensuring that Expectation Suites can properly represent the way users think about their data, and upgrading will make it much easier to store and share expectation suites, and to build data docs that support your whole team. 

You’ll get **awesome new features** including improvements to data docs look and the ability to choose and store metrics for building flexible data quality dashboards.

The changes for version 0.9.0 fall into several broad areas:

Onboarding
--------------

Release 0.9.0 of Great Expectations makes it much easier to get started with the project. The `init` flow has grown
to support a much wider array of use cases and to use more natural language rather than introducing
GreatExpectations concepts earlier. You can more easily configure different backends and datasources, take advantage of guided walkthroughs to find and profile data, and share project configurations with colleagues.

If you have already completed the `init` flow using a previous version of Great Expectations, you do not need to
rerun the command. However, **there are some small changes to your configuration that will be required**. See
[migrating versions](https://docs.greatexpectations.io/en/latest/reference/migrating_versions.html) for details.

CLI Command Improvements
------------------------------------------

With this release we have introduced a consistent naming pattern for accessing subcommands based on the noun (a Great Expectations object like `suite` or `docs`) and verb (an action like `edit` or `new`). The new user experience will allow us to more naturally organize access to CLI tools as new functionality is added.

Expectation Suite Naming and Namespace Changes
------------------------------------------------------

Defining shared expectation suites and validating data from different sources is much easier in this release. The
DataContext, which manages storage and configuration of expectations, validations, profiling, and data docs, no
longer requires that expectation suites live in a datasource-specific “namespace.” Instead, you should name suites
with the logical name corresponding to your data, making it easy to share them or validate against different data
sources. For example, the expectation suite ""npi"" for National Provider Identifier data can now be shared across
teams who access the same logical data in local systems using Pandas, on a distributed Spark cluster, or via a
relational database.

Batch Kwargs, or instructions for a datasource to build a batch of data, are similarly freed from a required
namespace, and you can more easily integrate Great Expectations into workflows where you do not need to use a
BatchKwargsGenerator (usually because you have a batch of data ready to validate, such as in a table or a known
directory).

The most noticeable impact of this API change is in the complete removal of the DataAssetIdentifier class. For
example, the `create_expectation_suite` and `get_batch` methods now no longer require a data_asset_name parameter, relying only on the expectation_suite_name and batch_kwargs to do their job. Similarly, there is no more asset name normalization required. See the upgrade guide for more information.

Metrics and Evaluation Parameter Stores
------------------------------------------------------

Metrics have received much more love in this release of Great Expectations! We've improved the system for declaring evaluation parameters that support dependencies between different expectation suites, so you can easily identify a particular field in the result of one expectation to use as the input into another. And the MetricsStore is now much more flexible, supporting a new ValidationAction that makes it possible to select metrics from a validation result to be saved in a database where they can power a dashboard.

Internal Type Changes and Improvements
------------------------------------------------------

Finally, in this release, we have done a lot of work under the hood to make things more robust, including updating
all of the internal objects to be more strongly typed. That change, while largely invisible to end users, paves the
way for some really exciting opportunities for extending Great Expectations as we build a bigger community around
the project.

We are really excited about this release, and encourage you to upgrade right away to take advantage of the more
flexible naming and simpler API for creating, accessing, and sharing your expectations. As always feel free to join
us on Slack for questions you don't see addressed!",103071520
782,False,False,2020-02-07T15:15:10Z,2020-02-07T15:19:23Z,"* Add support for allow_relative_error to expect_column_quantile_values_to_be_between, allowing Redshift users access to this expectation
* Add support for checking backend type information for datetime columns using expect_column_min_to_be_between and expect_column_max_to_be_between
",103071520
783,False,False,2020-01-15T15:05:05Z,2020-01-15T15:09:03Z,"* Add support for expect_column_values_to_be_of_type for BigQuery backend (#940)
* Add image CDN for community usage stats
* Documentation improvements and fixes",103071520
784,False,False,2019-12-04T21:48:15Z,2019-12-04T21:50:54Z,"* Raise informative error if config variables are declared but unavailable
* Update ExpectationsStore defaults to be consistent across all FixedLengthTupleStoreBackend objects
* Add support for setting spark_options via SparkDFDatasource
* Include tail_weights by default when using build_continuous_partition_object
* Fix Redshift quantiles computation and type detection
* Allow boto3 options to be configured (#887)
",103071520
785,False,False,2019-11-19T03:14:23Z,2019-11-19T03:17:14Z,"* BREAKING CHANGE: move all reader options from the top-level batch_kwargs object to a sub-dictionary called
  ""reader_options"" for SparkDFDatasource and PandasDatasource. This means it is no longer possible to specify
  supplemental reader-specific options at the top-level of `get_batch`,  `yield_batch_kwargs` or `build_batch_kwargs`
  calls, and instead, you must explicitly specify that they are reader_options, e.g. by a call such as:
  `context.yield_batch_kwargs(data_asset_name, reader_options={'encoding': 'utf-8'})`.
* BREAKING CHANGE: move all query_params from the top-level batch_kwargs object to a sub-dictionary called
  ""query_params"" for SqlAlchemyDatasource. This means it is no longer possible to specify supplemental query_params at
  the top-level of `get_batch`,  `yield_batch_kwargs` or `build_batch_kwargs`
  calls, and instead, you must explicitly specify that they are query_params, e.g. by a call such as:
  `context.yield_batch_kwargs(data_asset_name, query_params={'schema': 'foo'})`.
* Add support for filtering validation result suites and validation result pages to show only failed expectations in
  generated documentation
* Add support for limit parameter to batch_kwargs for all datasources: Pandas, SqlAlchemy, and SparkDF; add support
  to generators to support building batch_kwargs with limits specified.
* Include raw_query and query_params in query_generator batch_kwargs
* Rename generator keyword arguments from data_asset_name to generator_asset to avoid ambiguity with normalized names
* Consistently migrate timestamp from batch_kwargs to batch_id
* Include batch_id in validation results
* Fix issue where batch_id was not included in some generated datasets
* Fix rendering issue with expect_table_columns_to_match_ordered_list expectation
* Add support for GCP, including BigQuery and GCS
* Add support to S3 generator for retrieving directories by specifying the `directory_assets` configuration
* Fix warning regarding implicit class_name during init flow
* Expose build_generator API publicly on datasources
* Allow configuration of known extensions and return more informative message when SubdirReaderGenerator cannot find
  relevant files.
* Add support for allow_relative_error on internal dataset quantile functions, and add support for
  build_continuous_partition_objec in Redshift
* Fix truncated scroll bars in value_counts graphs",103071520
786,False,False,2019-11-06T21:25:29Z,2019-11-06T21:28:05Z,"* Improved the tutorials that walk new users through the process of creating expectations and validating data
* Changed the flow of the init command - now it creates the scaffolding of the project and adds a datasource. After that users can choose their path.
* Added a component with links to useful tutorials to the index page of the Data Docs website
* Improved the UX of adding a SQL datasource in the CLI - now the CLI asks for specific credentials for Postgres, MySQL, Redshift and Snowflake, allows continuing debugging in the config file and has better error messages
* Added batch_kwargs information to DataDocs validation results
* Fixed an issue affecting file stores on Windows",103071520
787,False,False,2019-10-29T00:36:29Z,2019-10-29T00:37:56Z,"* Fix a bug in data-docs' rendering of mostly parameter
* Correct wording for expect_column_proportion_of_unique_values_to_be_between
* Set charset and meta tags to avoid unicode decode error in some browser/backend configurations
* Improve formatting of empirical histograms in validation result data docs
* Add support for using environment variables in `config_variables_file_path`
* Documentation improvements and corrections",103071520
788,False,False,2019-10-23T22:41:08Z,2019-10-23T22:43:51Z,"* Add easier support for customizing data-docs css
* Use higher precision for rendering 'mostly' parameter in data-docs; add more consistent locale-based
  formatting in data-docs
* Fix an issue causing visual overlap of large numbers of validation results in build-docs index
* Documentation fixes (thanks @DanielOliver!) and improvements
* Minor CLI wording fixes
* Improved handling of MySql temporary tables
* Improved detection of older config versions",103071520
789,False,False,2019-10-16T15:25:43Z,2019-10-16T16:33:55Z,* Fix an issue where version was reported as '0+unknown',103071520
790,False,False,2019-10-15T22:58:04Z,2019-10-16T00:31:08Z,"Version 0.8.0 is a significant update to Great Expectations, with many improvements focused on configurability and usability.  See the migrating versions guide for more details on specific changes, which include several breaking changes to configs and APIs.

Highlights include:

1. Validation Operators and Actions. Validation operators make it easy to integrate GE into a variety of pipeline runners. They offer one-line integration that emphasizes configurability. See the validation operators and actions feature guide for more information.

   - The DataContext `get_batch` method no longer treats `expectation_suite_name` or `batch_kwargs` as optional; they must be explicitly specified.
   - The top-level GE validate method allows more options for specifying the specific data_asset class to use.

2. First-class support for plugins in a DataContext, with several features that make it easier to configure and
   maintain DataContexts across common deployment patterns.

   - **Environments**: A DataContext can now manage `environment_and_secrets` more easily thanks to more dynamic and flexible variable substitution.
   - **Stores**: A new internal abstraction for DataContexts, `stores_reference`, make extending GE easier by consolidating logic for reading and writing resources from a database, local, or cloud storage.
   - **Types**: Utilities configured in a DataContext are now referenced using `class_name` and `module_name` throughout the DataContext configuration, making it easier to extend or supplement pre-built resources. For now, the ""type"" parameter is still supported but expect it to be removed in a future release.

3. Partitioners: Batch Kwargs are clarified and enhanced to help easily reference well-known chunks of data using a partition_id. Batch ID and Batch Fingerprint help round out support for enhanced metadata around data assets that GE validates. See `batch_identifiers` for more information. The `GlobReaderGenerator`, `QueryGenerator`, `S3Generator`, `SubdirReaderGenerator`, and `TableGenerator` all support partition_id for easily accessing data assets.

4. Other Improvements:

   - We're beginning a long process of some under-the-covers refactors designed to make GE more maintainable as we begin adding additional features.
   - Restructured documentation: our docs have a new structure and have been reorganized to provide space for more easily adding and accessing reference material. Stay tuned for additional detail.
   - The command build-documentation has been renamed build-docs and now by default opens the Data Docs in the users' browser.",103071520
791,False,False,2019-10-04T22:30:27Z,2019-10-04T22:33:04Z,"* Fix an issue where head() lost the column name for SqlAlchemyDataset objects with a single column
* Fix logic for the 'auto' bin selection of `build_continuous_partition_object`
* Add missing jinja2 dependency
* Fix an issue with inconsistent availability of strict_min and strict_max options on `expect_column_values_to_be_between`
* Fix an issue where expectation suite evaluation_parameters could be overriden by values during validate operation",103071520
792,False,False,2019-09-19T20:40:12Z,2019-09-19T20:43:39Z,"* Fix an issue in generated documentation where the Home button failed to return to the index
* Add S3 Generator to module docs and improve module docs formatting
* Add support for views to QueryGenerator
* Add success/failure icons to index page
* Return to uniform histogram creation during profiling to avoid large partitions for internal performance reasons",103071520
793,False,False,2019-09-18T22:41:30Z,2019-09-18T22:50:24Z,"* Add an S3 generator, which will introspect a configured bucket and generate batch_kwargs from identified objects
* Add support to PandasDatasource and SparkDFDatasource for reading directly from S3
* Enhance the Site Index page in documentation so that validation results are sorted and display the newest items first when using the default run-id scheme
* Add a new utility method, `build_continuous_partition_object` which will build partition objects using the dataset API and so supports any GE backend.
* Fix an issue where columns with spaces in their names caused failures in some SqlAlchemyDataset and SparkDFDataset expectations
* Fix an issue where generated queries including null checks failed on MSSQL (#695)
* Fix an issue where evaluation parameters passed in as a set instead of a list could cause JSON serialization problems for the result object (#699)
",103071520
794,False,False,2019-09-04T14:29:56Z,2019-09-04T15:27:47Z,"* BREAKING: slack webhook URL now must be in the profiles.yml file (treat as a secret)
* Profiler improvements:
  - Display candidate profiling data assets in alphabetical order
  - Add columns to the expectation_suite meta during profiling to support human-readable description information
* Improve handling of optional dependencies during CLI init
* Improve documentation for create_expectations notebook
* Fix several anachronistic documentation and docstring phrases (#659, #660, #668, #681; #thanks @StevenMMortimer)
* Fix data docs rendering issues:
  - documentation rendering failure from unrecognized profiled column type (#679; thanks @dinedal))
  - PY2 failure on encountering unicode (#676)",103071520
795,False,False,2019-08-19T19:00:17Z,2019-08-19T19:04:25Z,"* Standardize the way that plugin module loading works. DataContext will begin to use the new-style class and plugin identification moving forward; yml configs should specify class_name and module_name (with module_name optional for GE types). For now, it is possible to use the ""type"" parameter in configuration (as before).
* Add support for custom data_asset_type to all datasources
* Add support for strict_min and strict_max to inequality-based expectations to allow strict inequality checks
(thanks @RoyalTS!)
* Add support for reader_method = ""delta"" to SparkDFDatasource
* Fix databricks generator (thanks @sspitz3!)
* Improve performance of DataContext loading by moving optional import
* Fix several memory and performance issues in SparkDFDataset.
  - Use only distinct value count instead of bringing values to driver
  - Migrate away from UDF for set membership, nullity, and regex expectations
* Fix several UI issues in the data_documentation
  - Move prescriptive dataset expectations to Overview section
  - Fix broken link on Home breadcrumb
  - Scroll follows navigation properly
  - Improved flow for long items in value_set
  - Improved testing for ValidationRenderer
  - Clarify dependencies introduced in documentation sites
  - Improve testing and documentation for site_builder, including run_id filter
  - Fix missing header in Index page and cut-off tooltip
  - Add run_id to path for validation files
",103071520
796,False,False,2019-08-12T21:54:49Z,2019-08-12T21:58:50Z,"* New Validation Renderer! Supports turning validation results into HTML and displays differences between the expected and the observed attributes of a dataset.
* Data Documentation sites are now fully configurable; a data context can be configured to generate multiple  
 sites built with different GE objects to support a variety of data documentation use cases. See data documentation guide for more detail.
* CLI now has a new top-level command, `build-documentation` that can support rendering documentation for specified sites and even named data assets in a specific site.
* Introduced DotDict and LooselyTypedDotDict classes that allow to enforce typing of dictionaries.
* Bug fixes: improved internal logic of rendering data documentation, slack notification, and CLI profile command when datasource argument was not provided.",103071520
797,False,False,2019-08-03T01:37:54Z,2019-08-03T01:41:13Z,* Fix missing requirement for pypandoc brought in from markdown support for notes rendering.,103071520
798,False,False,2019-08-03T01:28:36Z,2019-08-03T01:31:19Z,"* Fix numerous rendering bugs and formatting issues for rendering documentation.
* Add support for pandas extension dtypes in pandas backend of expect_column_values_to_be_of_type and  expect_column_values_to_be_in_type_list and fix bug affecting some dtype-based checks.
* Add datetime and boolean column-type detection in BasicDatasetProfiler.
* Improve BasicDatasetProfiler performance by disabling interactive evaluation when output of expectation is not immediately used for determining next expectations in profile.
* Add support for rendering expectation_suite and expectation_level notes from meta in docs.
* Fix minor formatting issue in readthedocs documentation.",103071520
799,False,False,2019-07-29T15:27:22Z,2019-07-29T15:34:00Z,"* BREAKING: Harmonize expect_column_values_to_be_of_type and expect_column_values_to_be_in_type_list semantics in
  Pandas with other backends, including support for None type and type_list parameters to support profiling.
  *These type expectations now rely exclusively on native python or numpy type names.*
* Add configurable support for Custom DataAsset modules to DataContext
* Improve support for setting and inheriting custom data_asset_type names
* Add tooltips with expectations backing data elements to rendered documentation
* Allow better selective disabling of tests (thanks @RoyalITS)
* Fix documentation build errors causing missing code blocks on readthedocs
* Update the parameter naming system in DataContext to reflect data_asset_name *and* expectation_suite_name
* Change scary warning about discarding expectations to be clearer, less scary, and only in log
* Improve profiler support for boolean types, value_counts, and type detection
* Allow user to specify data_assets to profile via CLI
* Support CLI rendering of expectation_suite and EVR-based documentation",103071520
800,False,False,2019-07-22T17:40:28Z,2019-07-22T17:45:40Z,"* Improved error detection and handling in CLI ""add datasource"" feature
* Fixes in rendering of profiling results (descriptive renderer of validation results)
* Query Generator of SQLAlchemy datasource adds tables in non-default schemas to the data asset namespace
* Added convenience methods to display HTML renderers of sections in Jupyter notebooks
* Implemented prescriptive rendering of expectations for most expectation types",103071520
801,False,False,2019-07-13T00:12:09Z,2019-07-13T00:26:20Z,"v.0.7.1
------------

* Added documentation/tutorials/videos for onboarding and new profiling and documentation features
* Added prescriptive documentation built from expectation suites
* Improved index, layout, and navigation of data context HTML documentation site
* Bug fix: non-Python files were not included in the package
* Improved the rendering logic to gracefully deal with failed expectations
* Improved the basic dataset profiler to be more resilient
* Implement expect_column_values_to_be_of_type, expect_column_values_to_be_in_type_list for SparkDFDataset
* Updated CLI with a new documentation command and improved profile and render commands
* Expectation suites and validation results within a data context are saved in a more readable form (with indentation)
* Improved compatibility between SparkDatasource and InMemoryGenerator
* Optimization for Pandas column type checking
* Optimization for Spark duplicate value expectation (thanks @orenovadia!)
* Default run_id format no longer includes "":"" and specifies UTC time
* Other internal improvements and bug fixes
",103071520
802,False,False,2019-07-04T03:22:24Z,2019-07-04T03:28:35Z,"Version 0.7 of Great Expectations is HUGE. It introduces several major new features
and a large number of improvements, including breaking API changes.

The core vocabulary of expectations remains consistent. Upgrading to 
the new version of GE will primarily require changes to code that
uses data contexts; existing expectation suites will require only changes
to top-level names.

 * Major update of Data Contexts. Data Contexts now offer significantly \
   more support for building and maintaining expectation suites and \
   interacting with existing pipeline systems, including providing a namespace for objects.\
   They can handle integrating, registering, and storing validation results, and
   provide a namespace for data assets, making **batches** first-class citizens in GE.
   Read more: :ref:`data_context` or :py:mod:`great_expectations.data_context`

 * Major refactor of autoinspect. Autoinspect is now built around a module
   called ""profile"" which provides a class-based structure for building
   expectation suites. There is no longer a default  ""autoinspect_func"" --
   calling autoinspect requires explicitly passing the desired profiler. See :ref:`profiling`

 * New ""Compile to Docs"" feature produces beautiful documentation from expectations and expectation
   validation reports, helping keep teams on the same page.

 * Name clarifications: we've stopped using the overloaded terms ""expectations
   config"" and ""config"" and instead use ""expectation suite"" to refer to a
   collection (or suite!) of expectations that can be used for validating a
   data asset.

   - Expectation Suites include several top level keys that are useful \
     for organizing content in a data context: data_asset_name, \
     expectation_suite_name, and data_asset_type. When a data_asset is \
     validated, those keys will be placed in the `meta` key of the \
     validation result.

 * Major enhancement to the CLI tool including `init`, `render` and more flexibility with `validate`

 * Added helper notebooks to make it easy to get started. Each notebook acts as a combination of \
   tutorial and code scaffolding, to help you quickly learn best practices by applying them to \
   your own data.

 * Relaxed constraints on expectation parameter values, making it possible to declare many column
   aggregate expectations in a way that is always ""vacuously"" true, such as
   ``expect_column_values_to_be_between`` ``None`` and ``None``. This makes it possible to progressively
   tighten expectations while using them as the basis for profiling results and documentation.

  * Enabled caching on dataset objects by default.

 * Bugfixes and improvements:

   * New expectations:

     * expect_column_quantile_values_to_be_between
     * expect_column_distinct_values_to_be_in_set

   * Added support for ``head`` method on all current backends, returning a PandasDataset
   * More implemented expectations for SparkDF Dataset with optimizations

     * expect_column_values_to_be_between
     * expect_column_median_to_be_between
     * expect_column_value_lengths_to_be_between

   * Optimized histogram fetching for SqlalchemyDataset and SparkDFDataset
   * Added cross-platform internal partition method, paving path for improved profiling
   * Fixed bug with outputstrftime not being honored in PandasDataset
   * Fixed series naming for column value counts
   * Standardized naming for expect_column_values_to_be_of_type
   * Standardized and made explicit use of sample normalization in stdev calculation
   * Added from_dataset helper
   * Internal testing improvements
   * Documentation reorganization and improvements
   * Introduce custom exceptions for more detailed error logs",103071520
803,False,True,2019-06-07T20:50:11Z,2019-06-08T14:47:59Z,"DataContexts are an opinionated framework for deploying Great Expectations within real data projects.

* Namespaced DataSources
* Batches as first-class citizens
* Tooling for validation
* Helper notebooks
* Compile to Docs

This branch is definitely the future of Great Expectations. Also, these features are in beta, so expect small-to-medium-sized changes in API, behavior, and design.

If you'd like help getting started, please reach out on Slack: https://tinyurl.com/great-expectations-slack

The core team will be more than happy to sit with you (probably via video call) and work with you to install, get started, and answer questions.

",103071520
804,False,False,2019-06-03T16:04:46Z,2019-06-03T16:07:16Z,"* Re-add testing (and support) for py2
* NOTE: Support for SqlAlchemyDataset and SparkDFDataset is enabled via optional install
 (e.g. `pip install great_expectations[sqlalchemy]` or `pip install great_expectations[spark]`)",103071520
805,False,False,2019-05-24T01:25:00Z,2019-05-24T01:31:00Z,"* Add support for SparkDFDataset and caching (HUGE work from @cselig)
* Migrate distributional expectations to new testing framework
* Add support for two new expectations: expect_column_distinct_values_to_contain_set 
  and expect_column_distinct_values_to_equal_set (thanks @RoyalTS)
* FUTURE BREAKING CHANGE: The new cache mechanism for Datasets, \
  when enabled, causes GE to assume that dataset does not change between evaluation of individual expectations. \
  We anticipate this will become the future default behavior.
* BREAKING CHANGE: Drop official support for python 2 and pandas < 0.22
",103071520
806,False,False,2019-04-30T18:20:15Z,2019-04-30T18:22:38Z,"* Fix issue where no result_format available for expect_column_values_to_be_null caused error
* Use vectorized computation in pandas (#443, #445; thanks @RoyalTS)",103071520
807,False,False,2019-04-25T14:00:58Z,2019-04-25T14:06:42Z,"* Restructured class hierarchy to have a more generic DataAsset parent that maintains expectation logic separate from the tabular organization of Dataset expectations
* Added new FileDataAsset and associated expectations (#416 thanks @anhollis)
* Added support for date/datetime type columns in some SQLAlchemy expectations (#413)
* Added support for a multicolumn expectation, expect multicolumn values to be unique (#408)
* Optimization: You can now disable `partial_unexpected_counts` by setting the     `partial_unexpected_count` value to 0 in the result_format argument, and we do not compute it when it would not be returned. (#431, thanks @eugmandel)
* Fix: Correct error in unexpected_percent computations for sqlalchemy when unexpected values exceed limit (#424)
* Fix: Pass meta object to expectation result (#415, thanks @jseeman)
* Add support for multicolumn expectations, with `expect_multicolumn_values_to_be_unique` as an example (#406)
* Add dataset class to from_pandas to simplify using custom datasets (#404, thanks @jtilly)
* Add schema support for sqlalchemy data context (#410, thanks @rahulj51)
* Minor documentation, warning, and testing improvements (thanks @zdog).",103071520
808,False,False,2018-12-19T23:51:49Z,2018-12-19T23:57:59Z,"* Add a new autoinspect API and remove default expectations.
* Improve details for expect_table_columns_to_match_ordered_list (#379, thanks @rlshuhart)
* Linting fixes (thanks @elsander)
* Add support for dataset_class in from_pandas (thanks @jtilly)
* Improve redshift compatibility by correcting faulty isnull operator (thanks @avanderm)
* Adjust partitions to use tail_weight to improve JSON compatibility and
  support special cases of KL Divergence (thanks @anhollis)
* Enable custom_sql datasets for databases with multiple schemas, by
  adding a fallback for column reflection (#387, thanks @elsander)
* Remove `IF NOT EXISTS` check for custom sql temporary tables, for
  Redshift compatibility (#372, thanks @elsander)
* Allow users to pass args/kwargs for engine creation in
  SqlAlchemyDataContext (#369, thanks @elsander)
* Add support for custom schema in SqlAlchemyDataset (#370, thanks @elsander)
* Use getfullargspec to avoid deprecation warnings.
* Add expect_column_values_to_be_unique to SqlAlchemyDataset
* Fix map expectations for categorical columns (thanks @eugmandel)
* Improve internal testing suite (thanks @anhollis and @ccnobbli)
* Consistently use value_set instead of mixing value_set and values_set (thanks @njsmith8)
",103071520
809,False,False,2018-08-29T15:45:52Z,2018-08-29T17:27:00Z,"* Improve CLI help and set CLI return value to the number of unmet expectations
* Add error handling for empty columns to SqlAlchemyDataset, and associated tests
* Fix broken support for older pandas versions (#346)
* Fix pandas deepcopy issue (#342)",103071520
810,False,False,2018-07-12T20:02:40Z,2018-07-12T20:05:36Z,"* Improve type lists in expect_column_type_to_be[_in_list] (thanks @smontanaro and @ccnobbli)
* Update cli to use entry_points for conda compatibility, and add version option to cli
* Remove extraneous development dependency to airflow
* Address SQlAlchemy warnings in median computation
* Improve glossary in documentation
* Add 'statistics' section to validation report with overall validation results (thanks @sotte)
* Add support for parameterized expectations
* Improve support for custom expectations with better error messages (thanks @syk0saje)
* Implement expect_column_value_lenghts_to_[be_between|equal] for SQAlchemy (thanks @ccnobbli)
* Fix PandasDataset subclasses to inherit child class",103071520
811,False,False,2018-05-17T02:09:19Z,2018-05-17T02:18:36Z,"* Fix bugs in expect_column_values_to_[not]_be_null: computing unexpected value percentages and handling all-null (thanks @ccnobbli)
* Support mysql use of Decimal type (thanks @bouke-nederstigt)
* Add new expectation expect_column_values_to_not_match_regex_list.
  * Change behavior of expect_column_values_to_match_regex_list to use python re.findall in PandasDataset, relaxing matching of individuals expressions to allow matches anywhere in the string.
* Fix documentation errors and other small errors (thanks @roblim, @ccnobbli)",103071520
812,False,False,2018-03-24T18:16:57Z,2018-03-24T18:18:47Z,Corrects failure to include new data_context module in source distribution.,103071520
813,False,False,2018-03-23T19:22:56Z,2018-03-23T19:28:51Z,"Welcome to Great Expectations version 0.4.0! Please note that this release includes several major breaking API changes. Please see the changelog below for more information!

v.0.4.0
-------
* Initial implementation of data context API and SqlAlchemyDataset including implementations of the following expectations:
  * expect_column_to_exist
  * expect_table_row_count_to_be
  * expect_table_row_count_to_be_between
  * expect_column_values_to_not_be_null
  * expect_column_values_to_be_null
  * expect_column_values_to_be_in_set
  * expect_column_values_to_be_between
  * expect_column_mean_to_be
  * expect_column_min_to_be
  * expect_column_max_to_be
  * expect_column_sum_to_be
  * expect_column_unique_value_count_to_be_between
  * expect_column_proportion_of_unique_values_to_be_between
* Major refactor of output_format to new result_format parameter. See docs for full details.
  * exception_list and related uses of the term exception have been renamed to unexpected
  * the output formats are explicitly hierarchical now, with BOOLEAN_ONLY < BASIC < SUMMARY < COMPLETE. `column_aggregate_expectation`s now return element count and related information included at the BASIC level or higher.
* New expectation available for parameterized distributions--expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than (what a name! :) -- (thanks @ccnobbli)
* ge.from_pandas() utility (thanks @schrockn)
* Pandas operations on a PandasDataset now return another PandasDataset (thanks @dlwhite5)
* expect_column_to_exist now takes a column_index parameter to specify column order (thanks @louispotok)
* Top-level validate option (ge.validate())
* ge.read_json() helper (thanks @rjurney)
* Behind-the-scenes improvements to testing framework to ensure parity across data contexts.
* Documentation improvements, bug-fixes, and internal api improvements",103071520
814,False,False,2018-02-08T16:12:00Z,2018-02-08T16:21:19Z,,103071520
815,False,False,2017-12-22T17:17:21Z,2017-12-22T17:18:43Z,Version 0.3.0 of great expectations brings significant improvements to documentation and the distributional expectations API.,103071520
816,False,False,2020-03-24T15:58:25Z,2020-03-25T21:28:05Z,"Highlights
--------
- Autoscaler has added Azure Support. (#7080, #7515, #7558, #7494)
	- Ray autoscaler helps you launch a distributed ray cluster using a single command line call!
	- It works on Azure, AWS, GCP, Kubernetes, Yarn, Slurm and local nodes.
- Distributed reference counting is turned on by default. (#7628, #7337)
	- This means all ray objects are tracked and garbage collected only when all references go out of scope. It can be turned off with: `ray.init(_internal_config=json.dumps({""distributed_ref_counting_enabled"": 0}))`.
	- When the object store is full with objects that are still in scope, you can turn on least-recently-used eviction to force remove objects using `ray.init(lru_evict=True)`. 
- A new command `ray memory` is added to help debug memory usage: (#7589)
	- It shows all object IDs that are in scope, their reference types, sizes and creation site.
        - Read more in the docs: https://ray.readthedocs.io/en/latest/memory-management.html.
```
> ray memory
-----------------------------------------------------------------------------------------------------
 Object ID                                Reference Type       Object Size   Reference Creation Site
=====================================================================================================
; worker pid=51230
ffffffffffffffffffffffff0100008801000000  PINNED_IN_MEMORY            8231   (deserialize task arg) __main__..sum_task
; driver pid=51174
45b95b1c8bd3a9c4ffffffff010000c801000000  USED_BY_PENDING_TASK           ?   (task call) memory_demo.py:<module>:13
ffffffffffffffffffffffff0100008801000000  USED_BY_PENDING_TASK        8231   (put object) memory_demo.py:<module>:6
ef0a6c221819881cffffffff010000c801000000  LOCAL_REFERENCE                ?   (task call) memory_demo.py:<module>:14
-----------------------------------------------------------------------------------------------------
```

API change
----------
- Change `actor.__ray_kill__()` to `ray.kill(actor)`. (#7360)
- Deprecate `use_pickle` flag for serialization. (#7474)
- Remove `experimental.NoReturn`. (#7475)
- Remove `experimental.signal API`. (#7477)

Core
----
- Add Apache 2 license header to C++ files. (#7520)
- Reduce per worker memory usage to 50MB. (#7573)
- Option to fallback to LRU on OutOfMemory. (#7410)
- Reference counting for actor handles. (#7434)
- Reference counting for returning object IDs created by a different process. (#7221)
- Use `prctl(PR_SET_PDEATHSIG)` on Linux instead of reaper. (#7150)
- Route asyncio plasma through raylet instead of direct plasma connection. (#7234)
- Remove static concurrency limit from gRPC server. (#7544)
- Remove `get_global_worker()`, `RuntimeContext`. (#7638)
- Fix known issues from 0.8.2 release:
	- Fix passing duplicate by-reference arguments. (#7306)
	- Fix Raise gRPC message size limit to 100MB. (#7269)


RLlib
-----
- New features:
	- Exploration API improvements. (#7373, #7314, #7380)
	- SAC: add discrete action support. (#7320, #7272)
	- Add high-performance external application connector. (#7641)
- Bug fix highlights:
	- PPO torch memory leak and unnecessary torch.Tensor creation and gc'ing. (#7238)
	- Rename sample_batch_size => rollout_fragment_length. (#7503)
	- Fix bugs and speed up SegmentTree.

Tune
----
- Integrate Dragonfly optimizer. (#5955)
- Fix HyperBand errors. (#7563)
- Access Trial Name, Trial ID inside trainable. (#7378)
- Add a new `repeater` class for high variance trials. (#7366)
- Prevent deletion of checkpoint from user-initiated restoration. (#7501)

Libraries
---------
- [Parallel Iterators] Allow for operator chaining after repartition. (#7268)
- [Parallel Iterators] Repartition functionality. (#7163)
- [Serve] `@serve.route` returns a handle, add `handle.scale`, `handle.set_max_batch_size`.  (#7569)
- [RaySGD] PyTorchTrainer --> TorchTrainer. (#7425)
- [RaySGD] Custom training API. (#7211)
- [RaySGD] Breaking User API changes: (#7384)
  - `data_creator` fed to TorchTrainer now must return a dataloader rather than datasets.
  - TorchTrainer automatically sets ""DistributedSampler"" if a DataLoader is returned.
  - `data_loader_config` and `batch_size` are no longer parameters for TorchTrainer.
  - TorchTrainer parallelism is now set by `num_workers`.
  - All TorchTrainer args now must be named parameters.

Java
----
- New Java actor API (#7414)
	- `@RayRemote` annotation is removed.
	- Instead of `Ray.call(ActorClass::method, actor)`, the new API is `actor.call(ActorClass::method)`.
- Allow passing internal config from raylet to Java worker. (#7532)
- Enable direct call by default. (#7408)
- Pass large object by reference. (#7595)

Others
------
- Progress towards Ray Streaming, including a Python API. (#7070, #6755, #7152, #7582)
- Progress towards GCS Service for GCS fault tolerance. (#7292, #7592, #7601, #7166)
- Progress towards cross language call between Java and Python. (#7614, #7634)
- Progress towards Windows compatibility. (#7529, #7509, #7658, #7315)
- Improvement in K8s Operator. (#7521, #7621, #7498, #7459, #7622)
- New documentation for Ray Dashboard. (#7304)

Known issues
--------------
- Ray currently doesn't work on Python 3.5.0, but works on 3.5.3 and above. 

Thanks
------
We thank the following contributors for their work on this release:
@rkooo567, @maximsmol, @suquark, @mitchellstern, @micafan, @ClarkZinzow, @Jimpachnet, @mwbrulhardt, @ujvl, @chaokunyang, @robertnishihara, @jovany-wang, @hyeonjames, @zhijunfu, @datayjz, @fyrestone, @eisber, @stephanie-wang, @allenyin55, @BalaBalaYi, @simon-mo, @thedrow, @ffbin, @amogkam, @TisonKun, @richardliaw, @ijrsvt, @wumuzi520, @mehrdadn, @raulchen, @landcold7, @ericl, @edoakes, @sven1977, @ashione, @jorenretel, @gramhagen, @kfstorm, @anthonyhsyu, @pcmoritz
",71932349
817,False,False,2020-02-24T05:28:41Z,2020-02-24T19:28:20Z,"## Highlights
- Pyarrow is no longer vendored. Ray directly uses the C++ Arrow API. You can use any version of pyarrow with ray. (#7233)
- The dashboard is turned on by default. It shows node and process information, actor information, and Ray Tune trials information. You can also use `ray.show_in_webui` to display custom messages for actors. Please try it out and send us feedback! (#6705, #6820, #6822, #6911, #6932, #6955, #7028, #7034) 
- We have made progress on distributed reference counting (behind a feature flag). You can try it out with `ray.init(_internal_config=json.dumps({""distributed_ref_counting_enabled"": 1}))`. It is designed to help manage memory using precise distributed garbage collection. (#6945, #6946, #7029, #7075, #7218, #7220, #7222, #7235, #7249)

## Breaking changes
- Many experimental Ray libraries are moved to the util namespace. (#7100)
	- `ray.experimental.multiprocessing` => `ray.util.multiprocessing`
	- `ray.experimental.joblib` => `ray.util.joblib`
	- `ray.experimental.iter` => `ray.util.iter`
	- `ray.experimental.serve` => `ray.serve`
	- `ray.experimental.sgd` => `ray.util.sgd`
- Tasks and actors are cleaned up if their owner process dies. (#6818)
- The `OMP_NUM_THREADS` environment variable defaults to 1 if unset. This improves training performance and reduces resource contention. (#6998)
- We now vendor `psutil` and `setproctitle` to support turning the dashboard on by default. Running `import psutil` after `import ray` will use the version of psutil that ships with Ray. (#7031)

## Core
- The Python raylet client is removed. All raylet communication now goes through the core worker. (#6018)
- Calling `delete()` will not delete objects in the in-memory store. (#7117)
- Removed vanilla pickle serialization for task arguments. (#6948)
- Fix bug passing empty bytes into Python tasks. (#7045)
- Progress toward next generation ray scheduler. (#6913)
- Progress toward service based global control store (GCS). (#6686, #7041)

## RLlib 
- Improved PyTorch support, including a PyTorch version of PPO. (#6826, #6770)
- Added distributed SGD for PPO. (#6918, #7084)
- Added an exploration API for controlling epsilon greedy and stochastic exploration. (#6974, #7155)
- Fixed schedule values going negative past the end of the schedule. (#6971, #6973)
- Added support for histogram outputs in TensorBoard. (#6942)
- Added support for parallel and customizable evaluation step. (#6981)

## Tune
- Improved Ax Example. (#7012)
- Process saves asynchronously. (#6912)
- Default to tensorboardx and include it in requirements. (#6836)
- Added experiment stopping api. (#6886)
- Expose progress reporter to users. (#6915)
- Fix directory naming regression. (#6839)
- Handles nan case for asynchyperband. (#6916)
- Prevent memory checkpoints from breaking trial fault tolerance. (#6691)
- Remove keras dependency. (#6827)
- Remove unused tf loggers. (#7090)
- Set correct path when deleting checkpoint folder. (#6758)
- Support callable objects in variant generation. (#6849)

## Autoscaler 
- Ray nodes now respect docker limits. (#7039)
- Add `--all-nodes` option to rsync-up. (#7065)
- Add port-forwarding support for attach. (#7145)
- For AWS, default to latest deep learning AMI. (#6922)
- Added 'ray dashboard' command to proxy ray dashboard in remote machine. (#6959)

## Utility libraries
- Support of scikit-learn with Ray joblib backend. (#6925)
- Parallel iterator support local shuffle. (#6921)
- [Serve] support no http headless services. (#7010)
- [Serve] refactor router to use Ray asyncio support. (#6873)
- [Serve] support composing arbitrary dags. (#7015)
- [RaySGD] support fp16 via PyTorch apex. (#7061)
- [RaySGD] refactor PyTorch sgd documentation. (#6910)
- Improvement in Ray Streaming. (#7043, #6666, #7071)

## Other improvements
- Progress toward Windows compatibility. (#6882, #6823)
- Ray Kubernetes operator improvements. (#6852, #6851, #7091)
- Java support for concurrent actor calls API. (#7022)
- Java support for direct call for normal tasks. (#7193)
- Java support for cross language Python invocation. (#6709)
- Java support for cross language serialization for actor handles. (#7134)

## Known issue
- Passing the same ObjectIDs multiple time as arguments currently doesn't work. (#7296)
- Tasks can exceed gRPC max message size. (#7263)

## Thanks
We thank the following contributors for their work on this release:
@mitchellstern, @hugwi, @deanwampler, @alindkhare, @ericl, @ashione, @fyrestone, @robertnishihara, @pcmoritz, @richardliaw, @yutaizhou, @istoica, @edoakes, @ls-daniel, @BalaBalaYi, @raulchen, @justinkterry, @roireshef, @elpollouk, @kfstorm, @Bassstring, @hhbyyh, @Qstar, @mehrdadn, @chaokunyang, @flying-mojo, @ujvl, @AnanthHari, @rkooo567, @simon-mo, @jovany-wang, @ijrsvt, @ffbin, @AmeerHajAli, @gaocegege, @suquark, @MissiontoMars, @zzyunzhi, @sven1977, @stephanie-wang, @amogkam, @wuisawesome, @aannadi, @maximsmol
",71932349
818,False,False,2020-01-26T16:27:15Z,2020-01-27T22:23:08Z,"Ray 0.8.1 Release Notes
=======================

Highlights
----------
- `ObjectID`s corresponding to `ray.put()` objects and task returns are now reference counted locally in Python and when passed into a remote task as an argument. `ObjectID`s that have a nonzero reference count will not be evicted from the object store. Note that references for `ObjectID`s passed into remote tasks inside of other objects (e.g., `f.remote((ObjectID,))` or `f.remote([ObjectID])`) are not currently accounted for. (#6554)
- `asyncio` actor support: actors can now define `async def` method and Ray will run multiple method invocations in the same event loop. The maximum concurrency level can be adjusted with `ActorClass.options(max_concurrency=2000).remote()`.
- `asyncio` `ObjectID` support: Ray ObjectIDs can now be directly awaited using the Python API. `await my_object_id` is similar to `ray.get(my_object_id)`, but allows context switching to make the operation non-blocking. You can also convert an `ObjectID` to a `asyncio.Future` using `ObjectID.as_future()`.
- Added experimental parallel iterators API (#6644, #6726): `ParallelIterator`s can be used to more convienently load and process data into Ray actors. See the [documentation](https://ray.readthedocs.io/en/latest/iter.html) for details.
- Added multiprocessing.Pool API (#6194): Ray now supports the `multiprocessing.Pool` API out of the box, so you can scale existing programs up from a single node to a cluster by only changing the import statment. See the [documentation](https://ray.readthedocs.io/en/latest/multiprocessing.html) for details.

Core
----
- Deprecated Python 2 (#6581, #6601, #6624, #6665)
- Fixed bug when failing to import remote functions or actors with args and kwargs (#6577)
- Many improvements to the dashboard (#6493, #6516, #6521, #6574, #6590, #6652, #6671, #6683, #6810)
- Progress towards Windows compatibility (#6446, #6548, #6653, #6706)
- Redis now binds to localhost and has a password set by default (#6481)
- Added `actor.__ray_kill__()` to terminate actors immediately (#6523)
- Added 'ray stat' command for debugging (#6622)
- Added documentation for fault tolerance behavior (#6698)
- Treat static methods as class methods instead of instance methods in actors (#6756)

RLlib
-----
- DQN distributional model: Replace all legacy tf.contrib imports with tf.keras.layers.xyz or tf.initializers.xyz (#6772)
- SAC site changes (#6759)
- PG unify/cleanup tf vs torch and PG functionality test cases (tf + torch) (#6650)
- SAC for Mujoco Environments (#6642)
- Tuple action dist tensors not reduced properly in eager mode (#6615)
- Changed foreach_policy to foreach_trainable_policy (#6564)
- Wrapper for the dm_env interface (#6468)

Tune
----
- Get checkpoints paths for a trial after tuning (#6643)
- Async restores and S3/GCP-capable trial FT (#6376)
- Usability errors PBT (#5972)
- Demo exporting trained models in pbt examples (#6533)
- Avoid duplication in TrialRunner execution (#6598)
- Update params for optimizer in reset_config (#6522)
- Support Type Hinting for py3 (#6571)

Other Libraries
---------------
- [serve] Pluggable Queueing Policy (#6492)
- [serve] Added BackendConfig (#6541)
- [sgd] Fault tolerance support for pytorch + revamp documentation (#6465)

Thanks
-------

We thank the following contributors for their work on this release:

@chaokunyang, @Qstar, @simon-mo, @wlx65003, @stephanie-wang, @alindkhare, @ashione, @harrisonfeng, @JingGe, @pcmoritz, @zhijunfu, @BalaBalaYi, @kfstorm, @richardliaw, @mitchellstern, @michaelzhiluo, @ziyadedher, @istoica, @EyalSel, @ffbin, @raulchen, @edoakes, @chenk008, @frthjf, @mslapek, @gehring, @hhbyyh, @zzyunzhi, @zhu-eric, @MissiontoMars, @sven1977, @walterddr, @micafan, @inventormc, @robertnishihara, @ericl, @ZhongxiaYan, @mehrdadn, @jovany-wang, @ujvl, @bharatpn
",71932349
819,False,False,2019-12-17T20:02:28Z,2019-12-18T00:01:09Z,"Ray 0.8.0 Release Notes
=======================

This is the first release with gRPC direct calls enabled by default for both tasks and actors, which substantially improves task submission performance.

Highlights
----------
- Enable gRPC direct calls by default (#6367). In this mode, actor tasks are sent directly from actor to actor over gRPC; the Raylet only coordinates actor creation. Similarly, with tasks, tasks are submitted directly from worker to worker over gRPC; the Raylet only coordinates the scheduling decisions. In addition, small objects (<100KB in size) are no longer placed in the object store. They are inlined into task submissions and returns when possible.

Note: in some cases, reconstruction of large evicted objects is not possible with direct calls. To revert to the 0.7.7 behaviour, you can set the environment variable `RAY_FORCE_DIRECT=0`.

Core
----
- [Dashboard] Add remaining features from old dashboard (#6489)
- Ray Kubernetes Operator Part 1: readme, structure, config and CRD realted file (#6332)
- Make sure numpy >= 1.16.0 is installed for fast pickling support (#6486)
- Avoid workers starting with the same random seed (#6471)
- Properly handle a forwarded task that gets forwarded back (#6271)

RLlib
-----
- (Bug Fix): Remove the extra 0.5 in the Diagonal Gaussian entropy (#6475)
- AlphaZero and Ranked reward implementation (#6385)

Tune
-----
- Add example and tutorial for DCGAN (#6400)
- Report trials by state fairly (#6395)
- Fixed bug in PBT where initial trial result is empty. (#6351)

Other Libraries
---------------
- [sgd] Add support for multi-model multi-optimizer training (#6317)
- [serve] Added deadline awareness (#6442)
- [projects] Return parameters for a command (#6409)
- [streaming] Streaming data transfer and python integration (#6185)


Thanks
-------

We thank the following contributors for their work on this release:

@zplizzi, @istoica, @ericl, @mehrdadn, @walterddr, @ujvl, @alindkhare, @timgates42, @chaokunyang, @eugenevinitsky, @kfstorm, @Maltimore, @visatish, @simon-mo, @AmeerHajAli, @wumuzi520, @robertnishihara, @micafan, @pcmoritz, @zhijunfu, @edoakes, @sytelus, @ffbin, @richardliaw, @Qstar, @stephanie-wang, @Coac, @mitchellstern, @MissiontoMars, @deanwampler, @hhbyyh, @raulchen",71932349
820,False,False,2019-12-15T06:37:03Z,2019-12-16T00:52:31Z,"Ray 0.7.7 Release Notes
=======================

Highlights
----------

- Remote functions and actors now support kwargs and positionals (#5606).
- `ray.get` now supports a `timeout` argument (#6107). If the object isn't available before the timeout passes, a `RayTimeoutError` is raised.
- Ray now supports [detached actors](https://ray.readthedocs.io/en/latest/advanced.html#detached-actors) (#6036), which persist beyond the lifetime of the script that creates them and can be referred to by a user-defined name.
- Added [documentation](https://ray.readthedocs.io/en/latest/deploy-on-yarn.html) for how to deploy Ray on YARN clusters using [Skein](https://jcrist.github.io/skein/) (#6119, #6173).
- The Ray scheduler now attempts to schedule tasks fairly to avoid starvation (#5851).

Core
----

- Progress towards a new backend architecture where tasks and actor tasks are submitted directly between workers. #5783, #5991, #6040, #6054, #6075, #6088, #6122, #6147, #6171, #6177, #6118, #6188, #6259, #6277
- Progress towards Windows compatibility. #6071, #6204, #6205, #6282
- Now using cloudpickle_fast for serialization by default, which supports more types of Python objects without sacrificing performance. #5658, #5805, #5960, #5978
- Various bugfixes. #5946, #6175, #6176, #6231, #6253, #6257, #6276, 

RLlib
-----

- Now using pytorch's function to see if gpu is available. #5890
- Fixed APEX priorities returning zero all the time. #5980
- Fixed leak of TensorFlow assign operations in DQN/DDPG. #5979
- Fixed choosing the wrong neural network model for Atari in 0.7.5. #6087
- Added large scale regression test for RLlib. #6093
- Fixed and added test for LR annealing config. #6101
- Reduced log verbosity. #6154
- Added a microbatch optimizer with an A2C example. #6161

Tune
-----

- Search algorithms now use early stopped trials for optimization. #5651
- Metrics are now outputted via a tabular format. Errors are outputted on a separate table. #5822
- In the distributed setting, checkpoints are now deleted automatically post-sync using an rsync flag. Checkpoints on the driver are garbage collected according to the policy defined by the user. #5877
- A much faster ExperimentAnalysis tool. #5962
- Trial executor callbacks now take in a “Runner” parameter. #5868
- Fixed `queue_trials` so to enable cluster autoscaling with a CPU-Only Head Node. #5900
- Added a TensorBoardX logger. #6133

Other Libraries
---------------

- Serving: Progress towards a new Ray serving library. #5854, #5886, #5894, #5929, #5937, #5961, #6051

Thanks
-------

We thank the following contributors for their amazing contributions:

@zhuohan123, @jovany-wang, @micafan, @richardliaw, @waldroje, @mitchellstern, @visatish, @mehrdadn, @istoica, @ericl, @adizim, @simon-mo, @lsklyut, @zhu-eric, @pcmoritz, @hhbyyh, @suquark, @sotte, @hershg, @pschafhalter, @stackedsax, @edoakes, @mawright, @stephanie-wang, @ujvl, @ashione, @couturierc, @AdamGleave, @robertnishihara, @DaveyBiggers, @daiyaanarfeen, @danyangz, @AmeerHajAli, @mimoralea",71932349
821,False,False,2019-10-19T18:29:40Z,2019-10-24T18:00:22Z,"Ray 0.7.6 Release Notes
=======================

Highlights
----------

- The Ray autoscaler now supports Kubernetes as a backend (#5492). This makes it possible to start a Ray cluster on top of your existing Kubernetes cluster with a simple shell command. 
  + Please see the Kubernetes section of the [autoscaler documentation](https://ray.readthedocs.io/en/latest/autoscaling.html) to get started.
  + This is a new feature and may be rough around the edges. If you run into problems or have suggestions for how to improve Ray on Kubernetes, please file an issue.

- The Ray cluster dashboard has been revamped (#5730, #5857) to improve the UI and include logs and error messages. More improvements will be coming in the near future.
  + You can try out the dashboard by starting Ray with `ray.init(include_webui=True)` or `ray start --include-webui`.
  + Please let us know if you have suggestions for what would be most useful to you in the new dashboard.

Core
----

- Progress towards refactoring the Python worker on top of the core worker. #5750, #5771, #5752
- Fix an issue in local mode where multiple actors didn't work properly. #5863
- Fix class attributes and methods for actor classes. #5802
- Improvements in error messages and handling. #5782, #5746, #5799
- Serialization improvements. #5841, #5725
- Various documentation improvements. #5801, #5792, #5414, #5747, #5780, #5582

RLlib
-----

- Added a link to BAIR blog posts in the documentation. #5762
- Tracing for eager tensorflow policies with `tf.function`. #5705

Tune
-----

- Improved MedianStoppingRule. #5402
- Add PBT + Memnn example. #5723
- Add support for function-based stopping condition. #5754
- Save/Restore for Suggestion Algorithms. #5719
- TensorBoard HParams for TF2.0. #5678

Other Libraries
---------------

- Serving: Progress towards a new Ray serving library. #5849, #5850, #5852

Thanks
-------

We thank the following contributors for their amazing contributions:

@hershg, @JasonWayne, @kfstorm, @richardliaw, @batzner, @vakker, @robertnishihara, @stephanie-wang, @gehring, @edoakes, @zhijunfu, @pcmoritz, @mitchellstern, @ujvl, @simon-mo, @ecederstrand, @mawright, @ericl, @anthonyhsyu, @suquark, @waldroje
",71932349
822,False,False,2019-09-19T23:54:20Z,2019-09-25T00:07:24Z,"# Ray 0.7.5 Release Notes

## Ray API
- Objects created with `ray.put()` are now reference counted. #5590
- Add internal `pin_object_data()` API. #5637
- Initial support for pickle5. #5611
- Warm up Ray on `ray.init()`. #5685
- `redis_address` passed to `ray.init` is now just `address`. #5602

## Core
- Progress towards a common C++ core worker. #5516, #5272, #5566, #5664
- Fix log monitor stall with many log files. #5569
- Print warnings when tasks are unschedulable. #5555
- Take into account resource queue lengths when autoscaling #5702, #5684

## Tune
- TF2.0 TensorBoard support. #5547, #5631
- `tune.function()` is now deprecated. #5601

## RLlib
- Enhancements for TF eager support. #5625, #5683, #5705
- Fix DDPG regression. #5626

## Other Libraries
- Complete rewrite of experimental serving library. #5562
- Progress toward Ray projects APIs. #5525, #5632, #5706
- Add TF SGD implementation for training. #5440 
- Many documentation improvements and bugfixes.
",71932349
823,False,False,2019-09-05T05:50:50Z,2019-09-05T23:11:39Z,"Ray 0.7.4 Release Notes
=================

Highlights
----------

- There were many **documentation improvements** (#5391, #5389, #5175). As we continue to improve the documentation we value your feedback through the “Doc suggestion?” link at the top of the [documentation](https://ray.readthedocs.io/en/latest/). Notable improvements:
  + We’ve added guides for best practices using TensorFlow and PyTorch.
  + We’ve revamped the Walkthrough page for Ray users, providing a better experience for beginners.
  + We’ve revamped guides for using Actors and inspecting internal state.

- Ray supports **memory limits** now to ensure memory-intensive applications run predictably and reliably. You 
   can activate them through the `ray.remote` decorator:
   ```python
   @ray.remote(
       memory=2000 * 1024 * 1024,
       object_store_memory=200 * 1024 * 1024)
   class SomeActor(object):
       def __init__(self, a, b):
           pass
   ```
   You can set limits for the heap and the object store, see the [documentation](https://ray.readthedocs.io/en/latest/memory-management.html).

- There is now preliminary support for **projects**, see the the [project documentation](https://ray.readthedocs.io/en/latest/projects.html). Projects allow you to 
   package your code and easily share it with others, ensuring a reproducible cluster setup. To get started, you 
   can run
   ```shell
   # Create a new project.
   ray project create <project-name>
   # Launch a session for the project in the current directory.
   ray session start
   # Open a console for the given session.
   ray session attach
   # Stop the given session and all of its worker nodes.
   ray session stop
   ```
   Check out the [examples](https://github.com/ray-project/ray/tree/f1dcce5a472fba1c77c4aa023589689efbfeb4f6/python/ray/projects/examples). This is an actively developed new feature so we appreciate your feedback!

**Breaking change:** The `redis_address` parameter was renamed to `address` (#5412, #5602) and the former will be removed in the future.

Core
-----

- Move Java bindings on top of the core worker #5370
- Improve log file discoverability #5580
- Clean up and improve error messages #5368, #5351

RLlib
-----

- Support custom action space distributions #5164
- Add TensorFlow eager support #5436
- Add autoregressive KL #5469
- Autoregressive Action Distributions #5304
- Implement MADDPG agent #5348
- Port Soft Actor-Critic on Model v2 API #5328
- More examples: Add CARLA community example #5333 and rock paper scissors multi-agent example #5336
- Moved RLlib to top level directory #5324

Tune
-----

- Experimental Implementation of the BOHB algorithm #5382
- Breaking change: Nested dictionary results are now flattened for CSV writing: `{“a”: {“b”: 1}} => {“a/b”: 1}` #5346
- Add Logger for MLFlow #5438
- TensorBoard support for TensorFlow 2.0 #5547
- Added examples for XGBoost and LightGBM #5500
- HyperOptSearch now has warmstarting #5372

Other Libraries
---------------

- SGD: Tune interface for Pytorch MultiNode SGD #5350
- Serving: The old version of ray.serve was deprecated #5541
- Autoscaler: Fix ssh control path limit #5476
- Dev experience: Ray CI tracker online at https://ray-travis-tracker.herokuapp.com/

Various fixes: Fix log monitor issues #4382 #5221 #5569, the top-level ray directory was cleaned up #5404

Thanks
-------

We thank the following contributors for their amazing contributions:

@jon-chuang, @lufol, @adamochayon, @idthanm, @RehanSD, @ericl, @michaelzhiluo, @nflu, @pengzhenghao, @hartikainen, @wsjeon, @raulchen, @TomVeniat, @layssi, @jovany-wang, @llan-ml, @ConeyLiu, @mitchellstern, @gregSchwartz18, @jiangzihao2009, @jichan3751, @mhgump, @zhijunfu, @micafan, @simon-mo, @richardliaw, @stephanie-wang, @edoakes, @akharitonov, @mawright, @robertnishihara, @lisadunlap, @flying-mojo, @pcmoritz, @jredondopizarro, @gehring, @holli, @kfstorm

",71932349
824,False,False,2019-08-02T22:03:09Z,2019-08-04T02:37:54Z,"Ray 0.7.3 Release Note
======================

Highlights
----------
-   RLlib [ModelV2API](https://ray.readthedocs.io/en/latest/rllib-models.html) is ready to use. It improves support for Keras and RNN models, as well as allowing object-oriented reuse of variables. ModelV1 API is deprecated. No migration is needed.
-   `ray.experimental.sgd.pytorch.PyTorchTrainer` is ready for early adopters. Checkout the documentation [here](https://ray.readthedocs.io/en/latest/distributed_training.html). We welcome your feedback!
    ```python
    model_creator = lambda config: YourPyTorchModel()
    data_creator = lambda config: YourTrainingSet(), YourValidationSet()

    trainer = PyTorchTrainer(
        model_creator,
        data_creator,
        optimizer_creator=utils.sgd_mse_optimizer,
        config={""lr"": 1e-4},
        num_replicas=2,
        resources_per_replica=Resources(num_gpus=1),
        batch_size=16,
        backend=""auto"")

    for i in range(NUM_EPOCHS):
        trainer.train()
    ```
-   You can query all the clients that have performed `ray.init` to connect to the current cluster with `ray.jobs()`. #5076
    ```python
    >>> ray.jobs()
    [{'JobID': '02000000',
      'NodeManagerAddress': '10.99.88.77',
      'DriverPid': 74949,
      'StartTime': 1564168784,
      'StopTime': 1564168798},
     {'JobID': '01000000',
      'NodeManagerAddress': '10.99.88.77',
      'DriverPid': 74871,
      'StartTime': 1564168742}]
    ```

Core
----
- Improvement on memory storage handling. #5143, #5216, #4893
- Improved workflow:
    - Debugging tool `local_mode` now behaves more consistently. #5060
    - Improved KeyboardInterrupt Exception Handling, stack trace reduced from 115 lines to 22 lines. #5237
-   Ray core:
    - Experimental direct actor call. #5140, #5184
    - Improvement in core worker, the shared module between Python and Java. #5079, #5034, #5062
    - GCS (global control store) was refactored. #5058, #5050

RLlib
-----
- Finished port of all major RLlib algorithms to builder pattern #5277, #5258, #5249
- `learner_queue_timeout` can be configured for async sample optimizer. #5270
- `reproducible_seed` can be used for reproducible experiments. #5197
- Added entropy coefficient decay to IMPALA, APPO and PPO #5043

Tune:
-----
- **Breaking:** `ExperimentAnalysis` is now returned by default from `tune.run`. To obtain a list of trials, use `analysis.trials`. #5115
- **Breaking:** Syncing behavior between head and workers can now be customized (`sync_to_driver`). Syncing behavior (`upload_dir`) between cluster and cloud is now separately customizable (`sync_to_cloud`). This changes the structure of the uploaded directory - now `local_dir` is synced with `upload_dir`. #4450
- Introduce `Analysis` and `ExperimentAnalysis` objects. `Analysis` object will now return all trials in a folder; `ExperimentAnalysis` is a subclass that returns all trials of an experiment. #5115
- Add missing argument `tune.run(keep_checkpoints_num=...)`. Enables only keeping the last N checkpoints. #5117
- Trials on failed nodes will be prioritized in processing. #5053
- Trial Checkpointing is now more flexible. #4728
- Add system performance tracking for gpu, ram, vram, cpu usage statistics - toggle with `tune.run(log_sys_usage=True)`. #4924
- Experiment checkpointing frequency is now less frequent and can be controlled with `tune.run(global_checkpoint_period=...)`. #4859

Autoscaler
----------
- Add a `request_cores` function for manual autoscaling. You can now manually request resources for the autoscaler. #4754
- Local cluster:
    - More readable example yaml with comments. #5290

    - Multiple cluster name is supported. #4864

- Improved logging with AWS NodeProvider. `create_instance` call will be logged. #4998

Others Libraries:
-----------------
- SGD:
    - Example for Training. #5292
    - Deprecate old distributed SGD implementation. #5160
- Kuberentes: Ray namespace added for k8s. #4111
- Dev experience: Add linting pre-push hook. #5154

Thanks:
-------

We thank the following contributors for their amazing contributions:

@joneswong, @1beb, @richardliaw, @pcmoritz, @raulchen, @stephanie-wang, @jiangzihao2009, @LorenzoCevolani, @kfstorm, @pschafhalter, @micafan, @simon-mo, @vipulharsh, @haje01, @ls-daniel, @hartikainen, @stefanpantic, @edoakes, @llan-ml, @alex-petrenko, @ztangent, @gravitywp, @MQQ, @dulex123, @morgangiraud, @antoine-galataud, @robertnishihara, @qxcv, @vakker, @jovany-wang, @zhijunfu, @ericl",71932349
825,False,False,2019-07-01T05:20:11Z,2019-07-03T05:57:19Z,"Core
----
- Improvements
  - Continue moving the worker code to C++. #5031, #4966, #4922, #4899, #5032, #4996, #4875
  - Add a hash table data structure to the Redis modules. #4911
  - Use gRPC for communication between node managers. #4968, #5023, #5024
- Python
   - `@ray.remote` now inherits the function docstring. #4985
   - Remove `typing` module from setup.py `install_requirements`. #4971
- Java
  - Allow users to set JVM options at actor creation time. #4970
- Internal
  - Refactor IDs: `DriverID` -> `JobID`, change all ID functions to camel case. #4964, #4896
  - Improve organization of directory structure. #4898
- Peformance
  - Get task object dependencies in parallel from object store. #4775
  - Flush lineage cache on task submission instead of execution. #4942
  - Remove debug check for uncommitted lineage. #5038

Tune
----
- Add directional metrics for components. #4120, #4915
- Disallow setting `resources_per_trial` when it is already configured. #4880
- Make PBT Quantile fraction configurable. #4912

RLlib
-----
- Add QMIX mixer parameters to optimizer param list. #5014
- Allow Torch policies access to full action input dict in `extra_action_out_fn`. #4894
- Allow access to batches prior to postprocessing. #4871
- Throw error if `sample_async` is used with pytorch for A3C. #5000
- Patterns & User Experience
  - Rename `PolicyEvaluator` => `RolloutWorker`. #4820
  - Port remainder of algorithms to `build_trainer()` pattern. #4920
  - Port DQN to `build_tf_policy()` pattern. #4823
- Documentation
  - Add docs on how to use TF eager execution. #4927
  - Add preprocessing example to offline documentation. #4950

Other Libraries
---------------
- Add support for distributed training with PyTorch. #4797, #4933
- Autoscaler will kill workers on exception. #4997
- Fix handling of non-integral timeout values in `signal.receive`. #5002

Thanks
-----
We thank the following contributors for their amazing contributions: @jiangzihao2009, @raulchen, @ericl, @hershg, @kfstorm, @kiddyboots216, @jovany-wang, @pschafhalter, @richardliaw, @robertnishihara, @stephanie-wang, @simon-mo, @zhijunfu, @ls-daniel, @ajgokhale, @rueberger, @suquark, @guoyuhong, @jovany-wang, @pcmoritz, @hartikainen, @timonbimon, @TianhongDai

",71932349
826,False,False,2019-06-08T06:22:04Z,2019-06-23T21:35:15Z,"Core
----
- Change global state API. #4857
  - `ray.global_state.client_table()` -> `ray.nodes()`
  - `ray.global_state.task_table()` -> `ray.tasks()`
  - `ray.global_state.object_table()` -> `ray.objects()`
  - `ray.global_state.chrome_tracing_dump()` -> `ray.timeline()`
  - `ray.global_state.cluster_resources()` -> `ray.cluster_resources()`
  - `ray.global_state.available_resources()` -> `ray.available_resources()`
- Export remote functions lazily. #4898
- Begin moving worker code to C++. #4875, #4899, #4898
- Upgrade arrow to latest master. #4858
- Upload wheels to S3 under `<branch-name>/<commit-id>`. #4949
- Add hash table to Redis-Module. #4911
- Initial support for distributed training with PyTorch. #4797

Tune
----
- Disallow setting `resources_per_trial` when it is already configured. #4880
- Initial experiment tracking support. #4362

RLlib
-----
- Begin deprecating Python 2 support in RLlib. #4832
- TensorFlow 2 compatibility. #4802
- Allow Torch policies access to full action input dict in `extra_action_out_fn`. #4894
- Allow access to batches prior to postprocessing. #4871
- Port algorithms to `build_trainer()` pattern. #4823
- Rename `PolicyEvaluator` -> `RolloutWorker`. #4820
- Rename `PolicyGraph` -> `Policy`, move from evaluation/ to policy/. #4819
- Support continuous action distributions in IMPALA/APPO. #4771

(Revision: 6/23/2019 - Accidentally included commits that were not part of the release.)",71932349
827,False,False,2019-05-16T05:55:21Z,2019-05-18T22:13:25Z,"Core
----
- Backend bug fixes. #4766, #4763, #4605
- Add experimental API for creating resources at runtime. #3742

Tune
----
- Post-Experiment Tools. #4351
- Add Ax to Tune. #4731
- Tune bug fixes. #4733, #4659, #4747

RLlib
-----
- Remove dependency on TensorFlow. #4764
- TD3/DDPG improvements and MuJoCo benchmarks. #4694
- Evaluation mode implementation for rllib.Trainer class. #4647
- Replace ray.get() with ray_get_and_free() to automatically free object store memory. #4586
- RLLib bug fixes. #4736, #4735, #4652, #4630

Autoscaler
----------
- Add an aggressive autoscaling flag. #4285
- Autoscalar bug fixes. #4782, #4653
",71932349
828,False,False,2019-04-18T18:16:15Z,2019-04-19T05:47:20Z,"Core
----
- Add `delete_creating_tasks` option for `internal.free()` #4588

Tune
----
- Add filter flag for Tune CLI. #4337
- Better handling of ``tune.function`` in global checkpoint. #4519
- Add compatibility to nevergrad 0.2.0+. #4529
- Add `--columns` flag for CLI. #4564
- Add checkpoint eraser. #4490
- Fix checkpointing for Gym types. #4619

RLlib
-----
- Report sampler performance metrics. #4427
- Ensure stats are consistently reported across all algos. #4445
- Cleanup ``TFPolicyGraph``. #4478
- Make batch timeout for remote workers tunable. #4435
- Fix inconsistent weight assignment operations in ``DQNPolicyGraph``. #4504
- Add support for LR schedule to DQN/APEX. #4473
- Add option for RNN state and value estimates to span episodes. #4429
- Create a combination of ``ExternalEnv`` and ``MultiAgentEnv``, called ``ExternalMutliAgentEnv``. #4200
- Support ``prev_state``/``prev_action`` in rollout and fix multiagent. #4565
- Support torch device and distributions. #4553

Java
----
- TestNG outputs more verbose error messages. #4507
- Implement ``GcsClient``. #4601
- Avoid unnecessary memory copy and addd a benchmark. #4611

Autoscaler
----------
- Add support for separate docker containers on head and worker nodes. #4537
- Add an aggressive autoscaling flag. #4285
",71932349
829,False,False,2019-03-22T22:03:29Z,2019-03-25T21:18:48Z,"Core
----
- Build system fully converted to Bazel. #4284, #4280, #4281
- Introduce a set data structure in the GCS. #4199
- Make all arguments to `_remote()` optional. #4305
- Improve object transfer latency by setting `TCP_NODELAY` on all TCP connections. #4318
- Add beginning of experimental serving module. #4095
- Remove Jupyter notebook based UI. #4301
- Add `ray timeline` command line command for dumping Chrome trace. #4239

Tune
----
- Add custom field for serializations. #4237
- Begin adding Tune CLI. #3983, #4321, #4322
- Add optimization to reuse actors. #4218
- Add warnings if the Tune event loop gets clogged. #4353
- Switch preferred API from `tune.run_experiments` to `tune.run`. #4234
- Make the logging from the function API consistent and predictable. #4011

RLlib
-----
- **Breaking:** Flip sign of entropy coefficient in A2C and Impala. #4374
- Add option to continue training even if some workers crash. #4376
- Add asynchronous remote workers. #4253
- Add callback accessor for raw observations. #4212

Java
----
- Improve single-process mode. #4245, #4265
- Package native dependencies into jar. #4367
- Initial support for calling Python functions from Java. #4166

Autoscaler
----------
- Restore error messages for setup errors. #4388

Known Issues
------------
- Object broadcasts on large clusters are inefficient. #2945",71932349
830,False,False,2019-03-05T04:39:09Z,2019-03-06T01:03:05Z,"Breaking
---------
- Removed `redirect_output` and `redirect_worker_output` from `ray.init`, removed deprecated `_submit` method. #4025
- Move `TensorFlowVariables` to `ray.experimental.tf_utils`. #4145

Core
------
- Stream worker logging statements to driver by default. #3892
- Added experimental ray signaling mechanism, see the [documentation](https://ray.readthedocs.io/en/latest/signals.html). #3624
- Make Bazel the default build system. #3898
- Preliminary experimental streaming API for Python. #4126
- Added web dashboard for monitoring node resource usage. #4066
- Improved propagation of backend errors to user. #4039
- Many improvements for the Java frontend. #3687, #3978, #4014, #3943, #3839, #4038, #4039, #4063, #4100, #4179, #4178 
- Support for dataclass serialization. #3964
- Implement actor checkpointing. #3839
- First steps toward cross-language invocations. #3675
- Better defaults for Redis memory usage. #4152

Tune
------
- **Breaking**: Introduce ability to turn off default logging. Deprecates custom_loggers. #4104
- Support custom resources. #2979
- Add initial parameter suggestions for HyperOpt. #3944
- Add scipy-optimize to Tune. #3924
- Add Nevergrad. #3985
- Add number of trials to the trial runner logger. #4068
- Support RESTful API for the webserver. #4080
- Local mode support. #4138
- Dynamic resources for trials. #3974

RLlib
-------
- Basic infrastructure for off-policy estimation. #3941
- Add simplex action space and Dirichlet action distribution. #4070
- Exploration with parameter space noise. #4048
- Custom supervised loss API. #4083
- Add torch policy gradient implementation. #3857 

Autoscaler and Cluster Setup
--------------------------------------
- Add docker run option (e.g. to support nvidia-docker). #3921

Modin
-----
- Upgrade Modin to 0.3.1, see the [release notes](https://github.com/modin-project/modin/releases/tag/v0.3.1). #4058

Known Issues
------------
- Object broadcasts on large clusters are inefficient. #2945
- IMPALA is broken #4329",71932349
831,False,False,2019-02-07T03:11:16Z,2019-03-06T00:11:42Z,"Core
------
- Initial work on porting the build system to Bazel. #3918, #3806, #3867, #3842
- Allow starting Ray processes inside valgrind, gdb, tmux. #3824, #3847
- Stability improvements and bug fixes. #3861, #3962, #3958, #3855, #3736, #3822, #3821, #3925
- Convert Python C extensions to Cython. #3541
- `ray start` can now be used to start Java workers. #3838, #3852
- Enable LZ4 compression in `pyarrow` build. #3931
- Update Redis to version 5.0.3. #3886
- Use one memory-mapped file for Plasma store. #3871, 

Tune
------
- Support for BayesOpt. #3864
- Support for SigOpt. #3844
- Support executing infinite recovery retries for a trial. #3901
- Support `export_formats` option to export policy graphs. #3868
- Cluster and logging improvements. #3906

RLlib
-------
- Support for Asynchronous Proximal Policy Optimization (APPO). #3779
- Support for MARWIL. #3635
- Support for evaluation option in DQN. #3835
- Bug fixes. #3865, #3810, #3938
- Annotations for API stability. #3808

Autoscaler and Cluster Setup
--------------------------------------
- Faster cluster launch and update. #3720
- Bug fixes. #3916, #3860, #3937, #3782, #3969
- Kubernetes configuration improvements. #3875, #3909

Modin
-----
- Update Modin to 0.3.0. #3936 
    - [Modin 0.3.0 release notes](https://github.com/modin-project/modin/releases/tag/v0.3.0)

Known Issues
------------
- Object broadcasts on large clusters are inefficient. #2945 ",71932349
832,False,False,2019-01-16T19:40:54Z,2019-01-17T09:13:23Z,"## Breaking Changes
- The `timeout` argument of `ray.wait` now uses seconds instead of milliseconds. #3706

## Core
- Limit default redis max memory to 10GB. #3630
- Define a `Node` class to manage Ray processes. #3733
- Garbage collection of actor dummy objects. #3593
- Split profile table among many keys in the GCS. #3676
- Automatically try to figure out the memory limit in a docker container. #3605
- Improve multi-threading support. #3672
- Push a warning to all users when large number of workers have been started. #3645
- Refactor code `ray.ObjectID` code. #3674

## Tune
- Change log handling for Tune. #3661
- Tune now supports resuming from cluster failure. #3309, #3725, #3657, #3681
- Support Configuration Merging for Suggestion Algorithms. #3584
- Support nested PBT mutations. #3455

## RLlib
- Add starcraft multiagent env as example. #3542
- Allow development without needing to compile Ray. #3623
- Documentation for I/O API and multi-agent improvements. #3650
- Export policy model checkpoint. #3637
- Refactor PyTorch custom model support. #3634

## Autoscaler
- Add an initial_workers option. #3530
- Add kill and get IP commands to CLI for testing. #3731
- GCP allow manual network configuration. #3748

# Known Issues:
- Object broadcasts on large clusters are inefficient. #2945
",71932349
833,False,False,2018-12-24T01:03:42Z,2018-12-24T03:32:41Z,"## Core
- Added experimental option to limit Redis memory usage. #3499
- Added option for restarting failed actors. #3332
- Fixed Plasma TensorFlow operator memory leak. #3448
- Fixed compatibility issue with TensorFlow and PyTorch. #3574
- Miscellaneous code refactoring and cleanup. #3563 #3564 #3461 #3511
- Documentation. #3427 #3535 #3138
- Several stability improvements. #3592 #3597

## RLlib
- Multi-GPU support for Multi-agent PPO. #3479
- Unclipped actions are sent to learner. #3496
- `rllib rollout` now also preprocesses observations. #3512
- Basic Offline Data API added. #3473
- Improvements to metrics reporting in DQN. #3491
- AsyncSampler no longer auto-concats. #3556
- QMIX Implementation (Experimental). #3548
- IMPALA performance improvements. #3402
- Better error messages. #3444
- PPO performance improvements. #3552

## Autoscaler
- Bug fixes, botocore handling fix. #3454 #3503 #3447

## Ray Tune
- Lambdas now require `tune.function` wrapper. #3457
- Custom loggers, sync functions, and trial names are now supported. #3465
- Improvements to fault tolerance. #3414
- Variant Generator docs clarification. #3583
- `trial_resources` now renamed to `resources_per_trial`. #3580

## Modin
- Modin 0.2.5 is now bundled with Ray
  - `import modin` after `import ray`
  - [Modin 0.2.5 release notes](https://github.com/modin-project/modin/releases/tag/v0.2.5)
- Greater than memory support for object store. #3450 

## Known Issues
- Object broadcasts on large clusters are inefficient. #2945",71932349
834,False,False,2018-12-01T19:39:36Z,2018-12-01T20:04:57Z,"## Breaking Changes
- Renamed `_submit` to `_remote`. #3321
- Object store memory capped at 20GB by default. #3243
- Now `ray.global_state.client_table()` returns a list instead of a dictionary.
- Renamed `ray.global_state.dump_catapult_trace` to `ray.global_state.chrome_tracing_dump`.

## Known Issues
- The Plasma TensorFlow operator leaks memory. #3404
- Object broadcasts on large clusters are inefficient. #2945
- Ape-X leaks memory. #3452
- Action clipping can impede learning (please set clip_actions: False as a workaround) #3496

## Core
- New raylet backend on by default and legacy backend removed. #3020 #3121
- Support for Python 3.7. #2546
- Support for fractional resources (e.g., GPUs). 
- Added `ray stack` for improved debugging (to get stack traces of Python processes on current node). #3213
- Better error messages for low-memory conditions. #3323
- Log file names reorganized under `/tmp/ray/`. #2862
- Improved timeline visualizations. #2306 #3255 

## Modin
- Modin is shipped with Ray. After running `import ray` you can run `import modin`. #3109

## RLlib
- Multi agent support for Ape-X and IMPALA. #3147
- Multi GPU support for IMPALA. #2766
- TD3 optimizations for DDPG. #3353
- Support for Dict and Tuple observation spaces. #3051
- Support for parametric and variable-length action spaces. #3384
- Support batchnorm layers. #3369
- Support custom metrics. #3144

## Autoscaler
- Added `ray submit` for submitting scripts to clusters. #3312
- Added `--new` flag for ray attach. #2973
- Added option to allow private IPs only. #3270 

## Tune
- Support for fractional GPU allocations for trials. #3169
- Better checkpointing and setup. #2889
- Memory tracking and notification. #3298 
- Bug fixes for `SearchAlgorithm`s. #3081 
- Add a `raise_on_failed_trial` flag in run_experiments. #2915
- Better handling of node failures. #3238

## Training
- Experimental support for distributed SGD. #2858 #3033",71932349
835,False,False,2018-09-25T16:49:58Z,2018-09-28T16:36:56Z,"## API
- Add `ray.is_initialized()` to check if `ray.init()` has been called. #2818

## Fixes and Improvements
- Fix issue in which `ray stop` fails to kill plasma object store. #2850
- Remove dependence on `psutil`. #2892

## RLlib
- Set better default for VF clip PPO parameter to avoid silent performance degradation. #2921
- Reward clipping should default to off for non-Atari environments. #2904
- Fix LSTM failing to train on truncated sequences. #2898

## Tune
- Fixed a small bug in trial pausing and cleaned up error messages. #2815",71932349
836,False,False,2018-08-29T20:39:25Z,2018-08-29T21:44:05Z,"## Breaking Changes
- Local mode has changed from `ray.init(driver_mode=ray.PYTHON_MODE)` to `ray.init(local_mode=True)` to improve clarity.

## Autoscaler and Cluster Setup
- Added many convenience commands such as `ray up`, `ray attach`, `ray exec`, and `ray rsync` to simplify launching jobs with Ray.
- Added experimental support for local/on-prem clusters.

## RLlib
- Added the IMPALA algorithm.
- Added the ARS algorithm.
- Added the A2C variant of A3C.
- Added support for distributional DQN.
- Made improvements to multiagent support.
- Added support for model-based rollouts and custom policies.
- Added initial set of reference Atari results.

## Tune
- `SearchAlgorithm`s can now be used separately from `TrialScheduler`s and are found in `ray.tune.suggest`.
- All `TrialScheduler`s have been consolidated under `ray.tune.schedulers`.
- Minor API changes:
    - For `Experiment` configuration, `repeat` has been renamed to `num_samples`.
    - Now, `register_trainable` is handled implicitly.",71932349
837,False,False,2018-07-07T05:31:33Z,2018-07-07T05:32:15Z,,71932349
838,False,False,2018-03-27T05:37:16Z,2018-03-27T05:37:52Z,,71932349
839,False,False,2018-02-04T21:25:25Z,2018-02-04T21:37:42Z,,71932349
840,False,False,2017-11-28T07:02:29Z,2017-11-28T07:03:21Z,,71932349
841,False,False,2017-11-02T03:41:24Z,2017-11-02T03:42:59Z,,71932349
842,False,False,2017-10-01T19:33:13Z,2017-10-01T21:47:58Z,,71932349
843,False,False,2017-08-30T04:38:35Z,2017-08-31T06:58:42Z,,71932349
844,False,False,2017-06-27T05:36:40Z,2017-06-27T05:37:19Z,,71932349
845,False,False,2017-06-27T05:28:08Z,2017-06-27T05:31:37Z,,71932349
846,False,False,2017-05-21T06:25:01Z,2017-05-21T06:27:36Z,,71932349
847,False,False,2020-03-04T10:11:43Z,2020-03-04T12:07:37Z,"We're happy to announce the 0.22.2.post1 bugfix release. 

The 0.22.2.post1 release includes a packaging fix for the source distribution
but the content of the packages is otherwise identical to the content of the
wheels with the 0.22.2 version (without the .post1 suffix).

Change log under https://scikit-learn.org/stable/whats_new/v0.22.html#changes-0-22-2.

This version supports Python versions 3.5 to 3.8.
",843222
848,False,False,2020-01-02T14:48:30Z,2020-01-02T17:23:27Z,"We're happy to announce the 0.22.1 bugfix release. 
Change log under https://scikit-learn.org/stable/whats_new/v0.22.html#changes-0-22-1.

This version supports Python versions 3.5 to 3.8.
",843222
849,False,False,2019-12-02T21:23:08Z,2019-12-03T12:47:32Z,"We're happy to announce the 0.22 release. You can read
the release highlights under https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html
and the long version of the change log under https://scikit-learn.org/stable/whats_new/v0.22.html#changes-0-22.

This version supports Python versions 3.5 to 3.8.",843222
850,False,False,2019-07-30T00:26:07Z,2019-07-30T01:27:57Z,Builds on top of Scikit-learn 0.20.3 to fix regressions and other issues released in version 0.20. See change log at https://scikit-learn.org/0.20/whats_new/v0.20.html,843222
851,False,False,2019-07-29T13:29:18Z,2019-07-30T01:28:12Z,"A bug fix and documentation release, fixing regressions and other issues released in version 0.21. See change log at https://scikit-learn.org/0.21/whats_new/v0.21.html",843222
852,False,False,2019-05-23T13:14:53Z,2019-05-23T15:01:41Z,This version fixes a few bugs released in 0.21.1.,843222
853,False,False,2019-05-15T07:34:22Z,2019-05-15T09:36:58Z,"See changes at https://scikit-learn.org/0.21/whats_new/v0.21.html

Fixes some packaging issues in version 0.21.0 along with a few bugs.",843222
854,False,False,2019-05-09T22:53:00Z,2019-05-10T02:40:02Z,"A new release of Scikit-learn with many new features, enhancements and bug fixes. See https://scikit-learn.org/0.21/whats_new/v0.21.html",843222
855,False,False,2019-03-01T09:07:29Z,2019-03-02T18:07:47Z,"A bug-fix release in the 0.20 series, supporting Python 2 and 3",843222
856,False,False,2018-12-19T08:52:01Z,2018-12-20T00:01:14Z,"Bug-fix release to the 0.20 branch, supporting Python 2 and 3",843222
857,False,False,2018-07-15T15:31:59Z,2018-11-22T02:39:33Z,"Released in July 2018, exclusively in order to support Python 3.7 in the 0.19.X branch.",843222
858,False,False,2018-11-22T23:45:09Z,2018-11-25T12:33:01Z,"Released 21 November 2018.

See changelog at https://scikit-learn.org/0.20/whats_new.html#version-0-20-1",843222
859,False,False,2018-09-25T15:06:34Z,2018-11-22T02:33:10Z,"Released 25 September 2018

See changelog at https://scikit-learn.org/0.20/whats_new.html#version-0-20-0",843222
860,False,False,2017-10-21T23:28:04Z,2017-10-22T18:50:19Z,,843222
861,False,False,2016-11-11T22:15:17Z,2016-11-15T19:07:41Z,,843222
862,False,False,2016-09-27T20:20:36Z,2016-10-18T17:26:42Z,,843222
863,False,False,2016-02-18T13:30:46Z,2016-04-17T19:05:20Z,"This should be the same as 0.17.1, only re-created so zenodo mints a DOI
",843222
864,False,False,2020-02-14T09:34:21Z,2020-02-14T10:03:10Z,"- Progress bar added (#224)
- Character analysis for Text/NLP (#278)
- Themes: configuration and demo's (Orange, Dark)
- Tutorial on modifying the report's structure (#362; #281, #259, #253, #234). This jupyter notebook also demonstrates how to use the Kaggle api together with pandas-profiling.
- Toggle descriptions at correlations.

Deprecation:

- This is the last version to support Python 3.5.

Stability:

- The order of columns changed when sort=""None"" (#377, fixed).
- Pandas v1.0.X is not yet supported (#367, #366, #363, #353, pinned pandas to < 1)
- Improved mixed type detection (#351)
- Refactor of report structures.
- Correlations are more stable (e.g. Phi_k color scale now from 0-1, rows and columns with NaN values are dropped, #329).
- Distinct counts exclude NaNs.
- Fixed alerts in notebooks.

Other improvements:

- Warnings are now sorted.
- Links to Binder and Google Colab are added for notebooks (#349)
- The overview section is tabbed.

* Commit for pandas-profiling v2.5.0

- Progress bar added (#224)
- Character analysis for Text/NLP (#278)
- Themes: configuration and demo's (Orange, Dark)
- Tutorial on modifying the report's structure (#362; #281, #259, #253, #234). This jupyter notebook also demonstrates how to use the Kaggle api together with pandas-profiling.
- Toggle descriptions at correlations.

Deprecation:

- This is the last version to support Python 3.5.

Stability:

- The order of columns changed when sort=""None"" (#377, fixed).
- Pandas v1.0.X is not yet supported (#367, #366, #363, #353, pinned pandas to < 1)
- Improved mixed type detection (#351)
- Refactor of report structures.
- Correlations are more stable (e.g. Phi_k color scale now from 0-1, rows and columns with NaN values are dropped, #329).
- Distinct counts exclude NaNs.
- Fixed alerts in notebooks.

Other improvements:

- Warnings are now sorted.
- Links to Binder and Google Colab are added for notebooks (#349)
- The overview section is tabbed.",49346299
865,False,False,2020-01-09T00:10:42Z,2020-01-08T03:13:44Z,"The v2.4.0 release decouples the data structure of reports from the actual rendering. It's now much simpler to change the user interface, whether the user is in a jupyter notebook, webpage, native application or just wants a json view of the data.

We are also proud to announce that we are accepted for the GitHub Sponsor programme. You are cordially invited to support me [through this programme](https://github.com/sponsors/sbrugman), because you want to see me continue working on this project and to boost community funding, GitHub will match your contribution!

Other improvements:
- extended configuration with better defaults, including minimal mode for big data (#258, #310)
- more example datasets
- rejection of highly correlated variables is generalized (#284, #299)
- many structural and stability improvements (#254, #274, #239)

Special thanks to @marco-cardoso @ajupton @lvwerra @gliptak @neomatrix369 for their contributions.",49346299
866,False,False,2019-07-27T09:08:22Z,2019-07-27T12:18:44Z,"- (Experimental) Support for ""path"" type
- Fix numeric precision (#225)
- Force labels in missing values diagram for large number of columns (#222)
- Add pull request template
- Add [Census Dataset](https://archive.ics.uci.edu/ml/datasets/census+income) from the UCI ML Repository

Thanks @bensdm and @huaiweicheng for your valuable contributions to this version!",49346299
867,False,False,2019-07-22T09:14:21Z,2019-07-22T09:26:09Z,"New release introducing variable size binning (via astropy), PyCharm integration and various fixes and optimizations.

- Added Variable bin sizing via Bayesian Boxing (feature request [#216])
- PyCharm integration, console attempts to detect file type.
- Fixed bug [#215].
- Updated the `missingno` package to 0.4.2, fixing the font size in the `bar` diagram.
- Various optimizations

Thanks to:
@Utsav37 @mansenfranzen  @jakevdp ",49346299
868,False,False,2019-07-11T23:39:01Z,2019-07-11T23:40:47Z,Fix [#211] and README,49346299
869,False,False,2019-07-11T07:29:39Z,2019-07-11T07:30:27Z,"- Fix of [#206]
- Improve code maintainability of the view (HTML templates, notebook)
- Fix bug in dendrogram sizing",49346299
870,False,False,2019-07-06T14:22:51Z,2019-07-06T14:45:08Z,"The `pandas-profiling` release version 2.1.0 includes:

- **Correlations**: correlation calculations are now more fault tolerant ([#51] and [#197]), correlation names in the report are clarified.
- **Jupyter Notebook**: rendering a profiling report is done inside the `srcdoc` attribute (which fixes [#199]), a full-width option is added and the column layout is improved.
- **User experience**: The table styling and sample section formatting is improved.
- **Warnings**: detection added for categorical variable that is suspected to be of the datetime type.
- **Documentation and community**:
	- The [Contribution page](CONTRIBUTING.md) helps users that want to contribute.
	- Typo's fixed [#195], Thank you @abhilashshakti
	- Added more examples.
- **Other bugfixes and improvements**:
	- Add version information to console interface.
	- Fix: Remove one-time used logger [#202]
	- Fix: Dealing with string indices [#200]

Contributors:
@abhilashshakti @adamrossnelson @manycoding @InsciteAnalytics",49346299
871,False,False,2019-06-23T10:06:01Z,2019-06-23T10:08:56Z,Bugfix on version structure for 2.0.2.,49346299
872,False,False,2019-06-22T21:06:32Z,2019-06-22T21:07:20Z,"Revised version structure, fixed recursion preventing installation of dependencies ([#184]).

The setup.py file used to include utils from the package prior to installation.
This causes errors when the dependencies are not yet present.",49346299
873,False,False,2019-06-21T14:31:49Z,2019-06-21T14:32:52Z,"- Add offline support [#177], [#179] and [#180]",49346299
874,False,False,2019-06-19T22:21:08Z,2019-06-19T22:36:21Z,"With 23 commits, 123 files changes and 20+ issues resolved, Pandas Profiling v2.0.0 is a big leap forward. 

Thanks to the great contributions from everyone involved! Special thanks to @JosPolfliet  @conradoqg @eyaltra.",49346299
875,False,False,2019-06-19T07:39:32Z,2019-06-19T07:41:51Z,"- Fix the correlation images (#160).

Contributors:
@kazetof",49346299
876,False,False,2019-04-27T08:59:55Z,2019-04-27T09:04:21Z,"* Multiple Bugfixes
* Enable Travis CI builds

Contributors:
@Aylr @LeonardAukea @kevanshea @endremborza @romainx @drkarthi",49346299
877,False,False,2018-01-10T15:04:35Z,2018-01-10T15:09:19Z,"# Enhancements

- Performance enhancement. It is now possible to disable some heavy resource operations and achieve better performances (see also #76):
  - Correlation checking by turning `check_correlation` to `False` (#43)
  - Recoded checking by turning `check_recoded` to `False`.
- Possibility to install using conda
- Implementation of a new Boolean variable type (#25)
- Add new badges for zeros and highly skewed (#63)
- Code refactoring (internal improvement) to split on main modules in 4 modules (#65)
- Improve types handling
  - types like `list`, `tuple` and `dict` are now officially unsupported until we improve them
  - mixed columns are also correctly handled
  - New Binary variable type supporting native `boolean` type and also binary numeric values (#77)
- Warnings column names have link to corresponding detail in variables section in order to ease the navigation (#66)
- Spearman and Pearson Correlation matrix diagrams added in the report (#83)

# Bug fixes

- #56 Incorrect calculation for % unique for variables with missing values bug
- #11 Avoid to throw an error when calling `get_rejected_variables` while correlation has not been computed
- #68 Avoid to set the matplotlib backend if not necessary",49346299
878,False,False,2017-02-05T17:18:40Z,2017-02-05T17:20:53Z,"Bug fixes and new check for recoded categorical variables. Thanks to all who contributed!
",49346299
879,False,False,2016-09-04T15:04:57Z,2016-09-04T15:15:47Z,"New additions include frequency counts and extreme values for numeric variables.
Pandas-profiling now does all 1d-calculations in a multitprocessing fashion, _vastly_ speeding up runtime.
",49346299
880,False,False,2016-08-03T00:40:38Z,2016-08-03T00:37:27Z,"What's new:
- histograms for date variables
- bug fixes
",49346299
881,False,False,2016-01-24T20:17:21Z,2016-01-26T16:17:33Z,"Initial release.
",49346299
882,False,False,2020-03-26T10:30:28Z,2020-03-26T10:33:33Z,"- Added Features
    - Add count_above and count_below feature (#632)
    - Add convenience bindings for dask dataframes and pyspark dataframes (#651)
- Bugfixes
    - Fix documentation build and feature table in sphinx (#637, #631, #627)
    - Add scripts to API documentation
    - Skip dask test for older python versions (#649)
    - Add missing distributor keyword (#648)
    - Fix tuple input for cwt (#645)",71996613
883,False,False,2020-02-04T21:40:46Z,2020-02-04T21:41:56Z,"- Breaking Change
    - Replace Benjamini-Hochberg implementation with statsmodels implementation (#570)
- Refactoring and Documentation
    - travis.yml (#605)
    - gitignore (#608)
    - Fix docstring of c3 (#590)
    - Feature/pep8 (#607)
- Added Features
    - Improve test coverage (#609)
    - Add ""autolag"" parameter to augmented_dickey_fuller() (#612)
- Bugfixes
    - Feature/pep8 (#607)
    - Fix filtering on warnings with multiprocessing on Windows (#610)
    - Remove outdated logging config (#621)
    - Replace Benjamini-Hochberg implementation with statsmodels implementation (#570)
    -  Fix the kernel and the naming of a notebook (#626)",71996613
884,False,False,2017-10-14T10:28:48Z,2019-11-24T14:45:23Z,"- new feature calculators:
    - fft_aggregated
    - cid_ce
- renamed mean_second_derivate_central to mean_second_derivative_central
- add warning if no relevant features were found in feature selection
- add columns_to_ignore parameter to from_columns method
- add distribution module, contains support for distributed feature extraction on Dask
",71996613
885,False,False,2018-09-07T06:57:01Z,2019-11-24T14:44:50Z,"- general performance improvements
- removed hard pinning of dependencies
- fixed bugs
    - the stock price forecasting notebook
    - the multi classification notebook
",71996613
886,False,False,2019-02-18T15:41:02Z,2019-11-24T14:44:25Z,"- change chunking in energy_ratio_by_chunks to use all data points
- fix warning for spkt_welch_density
- adapt default settings for ""value_count"" and ""range_count""
- added
    - maxlag parameter to agg_autocorrelation function
- now, the kind column of the input DataFrame is cast as str, old derived FC_Settings can become invalid
- only set default_fc_parameters to ComprehensiveFCParameters() if also kind_to_fc_parameters is set None in `extract_features`
- removed pyscaffold
- use asymptotic algorithm to derive kendal tau
",71996613
887,False,False,2019-07-09T11:36:44Z,2019-11-24T14:43:52Z,"- fixed bugs
    - wrong calculation of friedrich coefficients
    - feature selection selected too many features
    - an ignored max_timeshift parameter in roll_time_series
- add deprecation warning for python 2
- added support for index based features
- new feature calculator
    - linear_trend_timewise
- enable the RelevantFeatureAugmenter to be used in cross validated pipelines
- increased scipy dependency to 1.2.0
",71996613
888,False,False,2019-11-23T19:05:47Z,2019-11-24T14:43:19Z,"- Drop python 2.7 support (#568)
- Fixed bugs
  - Fix cache in friedrich_coefficients and agg_linear_trend (#593)
  - Added a check for wrong column names and a test for this check (#586)
  - Make sure to not install the tests folder (#599)
  - Make sure there is at least a single column which we can use for data (#589)
  - Avoid division by zero in energy_ratio_by_chunks (#588)
  - Ensure that get_moment() uses float computations (#584)
  - Preserve index when column_value and column_kind not provided (#576)
  - Add @set_property(""input"", ""pd.Series"") when needed (#582)
  - Fix off-by-one error in longest strike features (fixes #577) (#578)
  - Add `set_property` import (#572)
  - Fix typo (#571)
  - Fix indexing of melted normalized input (#563)
  - Fix travis (#569)
- Remove warnings (#583)
- Update to newest python version (#594)
- Optimizations
  - Early return from change_quantiles if ql >= qh (#591)
  - Optimize mean_second_derivative_central (#587)
  - Improve performance with Numpy's sum function (#567)
  - Optimize mean_change (fixes issue #542) and correct documentation (#574)
",71996613
889,False,False,2020-03-17T21:49:28Z,2020-03-17T22:02:56Z,"Various changes have been made in these two releases:

v<0.7.7>, <12/21/2019> -- Refactor code for combination simplification on combo.
v<0.7.7>, <12/21/2019> -- Extended combination methods by median and majority vote.
v<0.7.7>, <12/22/2019> -- Code optimization and documentation update.
v<0.7.7>, <12/22/2019> -- Enable continuous integration for Python 3.7.
v<0.7.7.1>, <12/29/2019> -- Minor update for SUOD and warning fixes.
v<0.7.8>, <01/05/2019> -- Documentation update.
v<0.7.8>, <01/30/2019> -- Bug fix for kNN (#158).
v<0.7.8>, <03/14/2020> -- Add VAE (implemented by Dr Andrij Vasylenko).
v<0.7.8>, <03/17/2020> -- Add LODA (adapted from tilitools).

The major improvement includes the addition of VAE and LODA, along with multiple minor fixes.
",105699750
890,False,False,2019-12-19T16:12:40Z,2019-12-19T16:31:17Z,"v<0.7.6>, <12/18/2019> -- Update Isolation Forest and LOF to be consistent with sklearn 0.22.
v<0.7.6>, <12/18/2019> -- Add Deviation-based Outlier Detection (LMDD).

The major update is about the compatibility fix for the newly released sklearn 0.22, and LMDD module built by @John-Almardeny ",105699750
891,False,False,2019-10-13T21:42:46Z,2019-10-13T23:07:58Z,"This minor update includes the following items (most of them are bug fix and documentation improvement):

v<0.7.5>, <09/24/2019> -- Fix one dimensional data error in LSCP.
v<0.7.5>, <10/13/2019> -- Document kNN and Isolation Forest's incoming changes.
v<0.7.5>, <10/13/2019> -- SOD optimization (created by John-Almardeny in June).
v<0.7.5>, <10/13/2019> -- Documentation updates.",105699750
892,False,False,2019-04-30T19:50:27Z,2019-04-30T20:30:03Z,"Multiple bug fixes are introduced:

- Fix issue in CBLOF for n_cluster discrepancy.
- Fix issue #23 that kNN fails with Mahalanobis distance.
- Fix for sklearn new behaviour FutureWarning.

Improved documentation:

- Update docs with media coverage.
- Major documentation update for JMLR.
- Add License info and show support to 996.ICU!
- Redesign ReadMe for clarity.

Deprecate two key APIs: fit_predict and fit_predict_score.

Add some new utility functions, e.g., generate_data_clusters.



",105699750
893,False,False,2019-01-29T16:27:31Z,2019-01-29T16:38:09Z,"This release further improves package stability and comprehensiveness.

A set of new models are added:

- LSCP: Locally Selective Combination of Parallel Outlier Ensembles
- XGBOD: Extreme Boosting Based Outlier Detection (Supervised)
- SO_GAAL: Single-Objective Generative Adversarial Active Learning
- MO_GAAL: Multiple-Objective Generative Adversarial Active Learning

Bug fixes are also included, e.g., CBLOF.

Last but not least, a few functions/models are redesigned/optimized:

- Docstring is refactored to numpydoc
- LOCI is optimized with numba
- visualize function is redesigned

",105699750
894,False,False,2018-12-03T21:51:18Z,2018-12-03T22:36:34Z,"Various exciting changes are made in this version. 
Welcome Zain Nasrullah and Winston (Zheng) Li to join the core dev team!

New models are added:
- Stochastic Outlier Selection (SOS) 
- Local Correlation Integral (LOCI)

New continuous integration tools are enabled:
- Appveyor CI
- CodeClimate
- CircleCI

Some bugs are fixed and README is rewritten in rst.",105699750
895,False,False,2018-11-10T21:38:49Z,2018-11-10T21:56:31Z,"In this release, there are multiple exciting new models are introduced, including:
- MCD 
- CBLOF
- AutoEncoder 

Several performance optimizations are also implemented:
- numba
- Parallelization for multi-core support in certain models

Besides, pyod is officially supporting Python 3.7 now. Multiple incremental changes are also in this release, and some corresponding updates due to the dependent library changed (sklearn LOF model) are also included.

Last but not least, welcome Zain Nasrullah to become a core developer for pyod. We are preparing a paper for JMLR. Hopefully, we could refer and cite the library shortly.

A new figure for selected models -> ![Comparision_of_All](https://raw.githubusercontent.com/yzhao062/Pyod/master/examples/ALL.png)",105699750
896,False,True,2018-06-11T16:11:33Z,2018-06-11T17:31:11Z,"In this release, more algorithms are implemented, including PCA and Feature Bagging models. The documentation and test coverage are also improved. A comparison for PyOD algorithms is presented below:
![all](https://user-images.githubusercontent.com/15079146/41247323-a7e801b4-6d7b-11e8-8cce-57bd5ff56d6e.png)
",105699750
897,False,True,2018-06-04T15:23:24Z,2018-06-04T15:36:05Z,"This is the first Github release to sync with PyPI. The current version brings the following changes compared with v0.3.x:

- Supported both Python 2 and 3 now.
- Refactor all models to be sklearn compatible. The models can be easily cloned, modified and viewed.
- Simplified examples for easy reproduction. 
- Optimized code for HBOS and ABOD. Codes are refactored for better stability.
- Added more tests to improve the coverage.
- Added two combination functions, Average() and Maximization()
",105699750
898,False,False,2020-03-24T10:55:35Z,2020-03-24T11:00:50Z,"## Learners - bugfixes

- remove `regr_slim` learner due to pkg (flare) being orphaned on CRAN

## Measures - bugixes

- remove measure `clValid::dunn` and its tests (package orphaned) (#2742)
- Bugfix: `tuneThreshold()` now accounts for the direction of the measure.
  Beforehand, the performance measure was always minimized (#2732).
- Remove adjusted Rsq measure (arsq), fixes #2711

## Filters - bugfixes

- Fixed an issue which caused the random forest minimal depth filter to only return NA values when using thresholding.
  NAs should only be returned for features below the given threshold. (@annette987, #2710)
- Fixed problem which prevented passing filter options via argument `more.args` for simple filters (@annette987, #2709)

## Feature selection - bugfixes

- Fix `print.FeatSelResult()` when bits.to.features is used in `selectFeatures()` (#2721)
- Return a long DF for `getFeatureImportance()` (#2708)

## Misc

- pkgdown: Move changelog to Appendix
- Account for {checkmate} v2.0.0 update (#2734)

- Refactor function calls from packages (`<pkg::fun>`) within ParamSets (#2730) to avoid errors in `listLearners()` if those pkgs are not installed
- `listLearners()` should not fail if a package is not installed (#2717)",12465340
899,False,False,2020-01-10T16:19:01Z,2020-01-10T22:22:10Z,"## plotting 
 
* `n.show` argument had no effect in `plotFilterValues()`. Thanks @albersonmiranda. (#2689) 
 
## Functional Data 
 
PR: #2638 (@pfistl) 
- Added several learners for regression and classification on functional data 
  - classif.classiFunc.(kernel|knn) (knn/kernel using various semi-metrics) 
  - (classif|regr).fgam (Functional generalized additive models) 
  - (classif|regr).FDboost (Boosted functional generalized additive models) 
 
- Added preprocessing steps for feature extraction from functional data 
  - extractFDAFourier (Fourier transform) 
  - extractFDAWavelets (Wavelet features) 
  - extractFDAFPCA (Principal components) 
  - extractFDATsfeatures (Time-Series features from tsfeatures package) 
  - extractFDADTWKernel (Dynamic Time-Warping Kernel) 
  - extractFDAMultiResFeatures (Compute features at multiple resolutions) 
 
- Fixed a bug where multiclass to binaryclass reduction techniques did not work 
  with functional data. 
 
- Several other minor bug fixes and code improvements 
- Extended and clarified documentation for several fda components. 
 
## learners - general 
 
- xgboost: added options 'auto', 'approx' and 'gpu_hist' to param `tree_method` (@albersonmiranda, #2701) 
 
## filters - general 
 
- Allow a custom threholding function to be passed to filterFeatures and makeFilterWrapper (@annette987, #2686) 
- Allow ensemble filters to include multiple base filters of the same type (@annette987, #2688) 
 
## filters - bugfixes 
 
- `filterFeatures()`: Arg `thresh` was not working correctly when applied to ensemble filters. (@annette987, #2699) 
- Fixed incorrect ranking of ensemble filters. Thanks @annette987 (#2698) 
",12465340
900,False,False,2019-11-26T22:20:58Z,2019-11-26T22:22:05Z,"## package infrastructure 
 
- There is now a reference grouping for all functions on the pkgdown site (https://mlr.mlr-org.com/reference/index.html) 
- CI testing now only on Circle CI (previously Travis CI) 
 
## learners - general 
 
- fixed a bug in `classif.xgboost` which prevented passing a watchlist for binary tasks. This was caused by a suboptimal internal label inversion approach. Thanks to @001ben for reporting (#32) (@mllg) 
- update `fda.usc` learners to work with package version >=2.0 
- update `glmnet` learners to upstream package version 3.0.0 
- update `xgboost` learners to upstream version 0.90.2 (@pat-s & @be-marc, #2681) 
- Updated ParamSet for learners `classif.gbm` and `regr.gbm`. Specifically, param `shrinkage` now defaults to 0.1 instead of 0.001. Also more choices for param `distribution` have been added. Internal parallelization by the package is now suppressed (param `n.cores`). (@pat-s, #2651) 
- Update parameters for `h2o.deeplearning` learners (@albersonmiranda, #2668) 
 
## misc 
 
- Add `configureMlr()` to `.onLoad()`, possibly fixing some edge cases (#2585) (@pat-s, #2637) 
 
## learners - bugfixes 
 
- `h2o.gbm` learners were not running until `wcol` was passed somehow due to an internal bug. In addition, this bug caused another issue during prediction where the prediction `data.frame` was somehow formatted as a character rather a numeric. Thanks to @nagdevAmruthnath for bringing this up in #2630. 
 
## filters - general 
 
- Bugfix: Allow `method = ""vh""` for filter `randomForestSRC_var.select` and return informative error message for not supported values. Also argument `conservative` can now be passed. See #2646 and #2639 for more information (@pat-s, #2649) 
* Bugfix: With the new _praznik_ v7.0.0 release filter `praznik_CMIM` does no longer return a result for logical features. See https://gitlab.com/mbq/praznik/issues/19 for more information 
",12465340
901,False,False,2019-08-06T10:01:56Z,2019-08-07T10:15:30Z,"## Breaking 
 
- Instead of a wide `data.frame` filter values are now returned in a long (tidy) `tibble`. This makes it easier to apply post-processing methods (like `group_by()`, etc) (@pat-s, #2456) 
- `benchmark()` does not store the tuning results (`$extract` slot) anymore by default. 
  If you want to keep this slot (e.g. for post tuning analysis), set `keep.extract = TRUE`. 
  This change originated from the fact that the size of `BenchmarkResult` objects with extensive tuning got very large (~ GB) which can cause memory problems during runtime if multiple `benchmark()` calls are executed on HPCs. 
- `benchmark()` does not store the created models (`$models` slot) anymore by default. 
  The reason is the same as for the `$extract` slot above. 
  Storing can be enabled using `models = TRUE`. 
 
## functions - general 
 
- `generateFeatureImportanceData()` gains argument `show.info` which shows the name of the current feature being calculated, its index in the queue and the elapsed time for each feature (@pat-s, #26222) 
 
## learners - general 
 
- `classif.liquidSVM` and `regr.liquidSVM` have been removed because `liquidSVM` has been removed from CRAN. 
- fixed a bug that caused an incorrect aggregation of probabilities in some cases. The bug existed since quite some time and was exposed due to the change of `data.table`s default in `rbindlist()`. See #2578 for more information. (@mllg, #2579) 
- `regr.randomForest` gains three new methods to estimate the standard error: 
  - `se.method = ""jackknife""` 
  - `se.method = ""bootstrap""` 
  - `se.method = ""sd""`   
  See `?regr.randomForest` for more details.   
  `regr.ranger` relies on the functions provided by the package (""jackknife"" and ""infjackknife"" (default))   
  (@jakob-r, #1784) 
- `regr.gbm` now supports `quantile distribution` (@bthieurmel, #2603) 
- `classif.plsdaCaret` now supports multiclass classification (@GegznaV, #2621) 
 
## functions - general 
- `getClassWeightParam()` now also works for Wrapper* Models and ensemble models (@ja-thomas, #891) 
- added `getLearnerNote()` to query the ""Note"" slot of a learner (@alona-sydorova, #2086) 
- `e1071::svm()` now only uses the formula interface if factors are present. This change is supposed to prevent from ""stack overflow"" issues some users encountered when using large datasets. See #1738 for more information. (@mb706, #1740) 
 
## learners - new 
- add learner `cluster.MiniBatchKmeans` from package _ClusterR_ (@Prasiddhi, #2554) 
 
## function - general 
- `plotHyperParsEffect()` now supports facet visualization of hyperparam effects for nested cv (@MasonGallo, #1653) 
- fixed a bug that caused an incorrect aggregation of probabilities in some cases. The bug existed since quite some time and was exposed due to the change of `data.table`s default in `rbindlist()`. See #2578 for more information. (@mllg, #2579) 
- fixed a bug in which `options(on.learner.error)` was not respected in `benchmark()`. This caused `benchmark()` to stop even if it should have continued including `FailureModels` in the result (@dagola, #1984) 
- `getClassWeightParam()` now also works for Wrapper* Models and ensemble models (@ja-thomas, #891) 
- added `getLearnerNote()` to query the ""Note"" slot of a learner (@alona-sydorova, #2086) 
 
## filters - general 
 
- Filter `praznik_mrmr` also supports `regr` and `surv` tasks 
- `plotFilterValues()` got a bit ""smarter"" and easier now regarding the ordering of multiple facets. (@pat-s, #2456) 
- `filterFeatures()`, `generateFilterValuesData()` and `makeFilterWrapper()` gained new examples. (@pat-s, #2456) 
 
## filters - new 
 
- Ensemble features are now supported. These filters combine multiple single filters to create a final ranking based on certain statistical operations. All new filters are listed in a dedicated section ""ensemble filters"" in the [tutorial](https://mlr.mlr-org.com/articles/tutorial/filter_methods.html). 
Tuning of simple features is not supported yet because of a [missing feature](https://github.com/berndbischl/ParamHelpers/pull/206) in _ParamHelpers_. (@pat-s, #2456) 
",12465340
902,False,False,2019-04-26T22:10:36Z,2019-04-26T22:14:04Z,"## general
* add option to use fully predefined indices in resampling (`makeResampleDesc(fixed = TRUE)`) (@pat-s, #2412).
* `Task` help pages are now split into separate ones, e.g. `RegrTask`, `ClassifTask` (@pat-s, #2564)

## functions - new
* `deleteCacheDir()`: Clear the default mlr cache directory (@pat-s, #2463)
* `getCacheDir()`: Return the default mlr cache directory (@pat-s, #2463)

## functions - general
* `getResamplingIndices(inner = TRUE)` now correctly returns the inner indices (before inner indices referred to the subset of the respective outer level train set) (@pat-s, #2413).

## filter - general
* Caching is now used when generating filter values.
  This means that filter values are only computed once for a specific setting and the stored cache is used in subsequent iterations.
  This change inherits a significant speed-up when tuning `fw.perc`, `fw.abs` or `fw.threshold`.
  It can be triggered with the new `cache` argument in `makeFilterWrapper()` or `filterFeatures()` (@pat-s, #2463).

## filter - new
* praznik_JMI
* praznik_DISR
* praznik_JMIM
* praznik_MIM
* praznik_NJMIM
* praznik_MRMR
* praznik_CMIM
* FSelectorRcpp_gain.ratio
* FSelectorRcpp_information.gain
* FSelectorRcpp_symuncert

Additionally, filter names have been harmonized using the following scheme: <pkgname>_<filtername>.
Exeptions are filters included in base R packages.
In this case, the package name is omitted.

## filter - general
* Added filters `FSelectorRcpp_gain.ratio`, `FSelectorRcpp_information.gain` and `FSelectorRcpp_symmetrical.uncertainty` from package `FSelectorRcpp`.
  These filters are ~ 100 times faster than the implementation of the `FSelector` pkg.
  Please note that both implementations do things slightly different internally and the `FSelectorRcpp` methods should not be seen as direct replacement for the `FSelector` pkg.
* filter names have been harmonized using the following scheme: <pkgname>_<filtername>. (@pat-s, #2533)
  - `information.gain` -> `FSelector_information.gain`
  - `gain.ratio` -> `FSelector_gain.ratio`
  - `symmetrical.uncertainty` -> `FSelector_symmetrical.uncertainty`
  - `chi.squared` -> `FSelector_chi.squared`
  - `relief` -> `FSelector_relief`
  - `oneR` -> `FSelector_oneR`
  - `randomForestSRC.rfsrc` -> `randomForestSRC_importance`
  - `randomForestSRC.var.select` -> `randomForestSRC_var.select`
  - `randomForest.importance` -> `randomForest_importance`

* fixed a bug related to the loading of namespaces for required filter packages (@pat-s, #2483)

## learners - new
* classif.liquidSVM (@PhilippPro, #2428)
* regr.liquidSVM (@PhilippPro, #2428)

## learners - general
* regr.h2o.gbm: Various parameters added, `""h2o.use.data.table"" = TRUE` is now the default (@j-hartshorn, #2508)
* h2o learners now support getting feature importance (@markusdumke, #2434)

## learners - fixes
* In some cases the optimized hyperparameters were not applied in the performance level of a nested CV (@berndbischl, #2479)

## featSel - general
 * The FeatSelResult object now contains an additional slot `x.bit.names` that stores the optimal bits
 * The slot `x` now always contains the real feature names and not the bit.names
 * This fixes a bug and makes `makeFeatSelWrapper` usable with custom `bit.names`.
 * Fixed a bug due to which `sffs` crashed in some cases (@bmihaljevic, #2486)",12465340
903,False,False,2018-08-28T01:04:36Z,2018-09-09T14:46:06Z,"## general
* Disabled unit tests for CRAN, we test on travis only now
* Suppress messages with show.learner.output = FALSE

## functions - general
* plotHyperParsEffect: add colors

## functions - new
* getResamplingIndices
* createSpatialResamplingPlots

## learners - general
*  regr.nnet: Removed unneeded params linout, entropy, softmax and censored
*  regr.ranger: Add weight handling

## learners - removed
* {classif,regr}.blackboost: broke API with new release",12465340
904,False,False,2018-06-23T15:38:17Z,2018-06-23T16:00:43Z,"## general
* Support for functional data (fda) using matrix columns has been added.
* Relaxed the way wrappers can be nested -- the only explicitly forbidden
  combination is to wrap a tuning wrapper around another optimization wrapper
* Refactored the resample progress messages to give a better overview and
  distinguish between train and test measures better
* calculateROCMeasures now returns absolute instead of relative values
* Added support for spatial data by providing spatial partitioning methods ""SpCV"" and ""SpRepCV"".
* Added new spatial.task classification task.
* Added new spam.task classification task.
* Classification tasks now store the class distribution in the
  class.distribution member.
* mlr now predicts NA for data that contains NA and learners that do not support
  missing values.
* Tasks are now subsetted in the ""train"" function and the factor levels (for
  classification tasks) based on this subset. This means that the factor level
  distribution is not necessarily the same as for the entire task, and that the
  task descriptions of models in resampling reflect the respective subset, while
  the task description of resample predictions reflect the entire task and not
  necessarily the task of any individual model.
* Added support for growing and fixed window cross-validation for forecasting
  through new resample methods ""GrowingWindowCV"" and ""FixedWindowCV"".

## functions - general
* generatePartialDependenceData: depends now on the ""mmpf"" package,
  removed parameter: ""center"", ""resample"", ""fmin"", ""fmax"" and ""gridsize""
  added parameter: ""uniform"" and ""n"" to configure the grid for the partial dependence plot
* batchmark: allow resample instances and reduction of partial results
* resample, performance: new flag ""na.rm"" to remove NAs during aggregation
* plotTuneMultiCritResultGGVIS: new parameters ""point.info"" and ""point.trafo"" to
  control interactivity
* calculateConfusionMatrix: new parameter ""set"" to specify whether confusion
  matrix should be computed for ""train"", ""test"", or ""both"" (default)
* PlotBMRSummary: Add parameter ""shape""
* plotROCCurves: Add faceting argument
* PreprocWrapperCaret: Add param ""ppc.corr"", ""ppc.zv"", ""ppc.nzv"", ""ppc.n.comp"", ""ppc.cutoff"", ""ppc.freqCut"", ""ppc.uniqueCut""

## functions - new
* makeClassificationViaRegressionWrapper
* getPredictionTaskDesc
* helpLearner, helpLearnerParam: open the help for a learner or get a
  description of its parameters
* setMeasurePars
* makeFunctionalData
* hasFunctionalFeatures
* extractFDAFeatures, reextractFDAFeatures
* extractFDAFourier, extractFDAFPCA, extractFDAMultiResFeatures, extractFDAWavelets
* makeExtractFDAFeatMethod
* makeExtractFDAFeatsWrapper
* getTuneResultOptPath
* makeTuneMultiCritControlMBO: Allows model based multi-critera / multi-objective optimization using mlrMBO

## functions - removed
* Removed plotViperCharts

## measures - general
* measure ""arsq"" now has ID ""arsq""
* measure ""measureMultiLabelF1"" was renamed to ""measureMultilabelF1"" for consistency

## measures - new
* measureBER, measureRMSLE, measureF1
* cindex.uno, iauc.uno

## learners - general
* unified {classif,regr,surv}.penalized{ridge,lasso,fusedlasso} into {classif,regr,surv}.penalized
* fixed a bug where surv.cforest gave wrong risk predictions (#1833)
* fixed bug where classif.xgboost returned NA predictions with multi:softmax
* classif.lda learner: add 'prior' hyperparameter
* ranger: update hyperpar 'respect.unordered.factors', add 'extratrees' and 'num.random.splits'
* h20deeplearning: Rename hyperpar 'MeanSquare' to 'Quadratic'
* h20*: Add support for ""missings"" 

## learners - new
* classif.adaboostm1
* classif.fdaknn
* classif.fdakernel
* classif.fdanp
* classif.fdaglm
* classif.mxff
* regr.fdaFDboost
* regr.mxff

## learners - removed
* {classif,regr}.bdk: broke our API, stability issues
* {classif,regr}.xyf: broke our API, stability issues
* classif.hdrda: package removed from CRAN
* surv.penalized: stability issues

## aggregations - new
* testgroup.sd

## filter - new
* auc
* ranger.permutation, ranger.impurity",12465340
905,False,False,2018-06-23T15:36:08Z,2018-06-23T16:00:33Z,"## general
* The internal class naming of the task descriptions have been changed causing probable incompatibilities with tasks generated under old versions.
* New option on.error.dump to include dumps that can be inspected with the
  debugger with errors
* mlr now supports tuning with Bayesian optimization with mlrMBO

## functions - general
* tuneParams: fixed a small and obscure bug in logging for extremely large ParamSets
* getBMR-operators: now support ""drop"" argument that simplifies the resulting list
* configureMlr: added option ""on.measure.not.applicable"" to handle situations where performance
  cannot be calculated and one wants NA instead of an error - useful in, e.g., larger benchmarks
* tuneParams, selectFeatures: removed memory stats from default output for
  performance reasons (can be restored by using a control object with ""log.fun""
  = ""memory"")
* listLearners: change check.packages default to FALSE
* tuneParams and tuneParamsMultiCrit: new parameter `resample.fun` to specify a custom resampling function to use.
* Deprecated: getTaskDescription, getBMRTaskDescriptions, getRRTaskDescription.
  New names: getTaskDesc, getBMRTaskDescs, getRRTaskDesc.

## functions - new
* getOOBPreds: get out-of-bag predictions from trained models for learners that store them -- these learners have the new ""oobpreds"" property
* listTaskTypes, listLearnerProperties
* getMeasureProperties, hasMeasureProperties, listMeasureProperties
* makeDummyFeaturesWrapper: fuse a learner with a dummy feature creator
* simplifyMeasureNames: shorten measure names to the actual measure, e.g.
  mmce.test.mean -> mmce
* getFailureModelDump, getPredictionDump, getRRDump: get error dumps
* batchmark: Function to run benchmarks with the batchtools package on high performance computing clusters
* makeTuneControlMBO: allows Bayesian optimization

## measures - new
* kendalltau, spearmanrho

## learners - general
* classif.plsdaCaret: added parameter ""method"".
* regr.randomForest: refactored se-estimation code, improved docs and default is now se.method = ""jackknife"".
* regr.xgboost, classif.xgboost: removed ""factors"" property as these learners do not handle categorical features
-- factors are silently converted to integers internally, which may misinterpret the structure of the data
* glmnet: control parameters are reset to factory settings before applying
  custom settings and training and set back to factory afterwards

## learners - removed
* {classif,regr}.avNNet: no longer necessary, mlr contains a bagging wrapper",12465340
906,False,False,2018-06-23T15:33:59Z,2018-06-23T16:00:19Z,"## functions - general
* fixed bug in resample when using predict = ""train"" (issue #1284)
* update to irace 2.0 -- there are algorithmic changes in irace that may affect
  performance
* generateFilterValuesData: fixed a bug wrt feature ordering
* imputeLearner: fixed a bug when data actually contained no NAs
* print.Learner: if a learner hyperpar was set to value ""NA"" this was not
  displayed in printer
* makeLearner, setHyperPars: if you mistype a learner or hyperpar name, mlr
  uses fuzzy matching to suggest the 3 closest names in the message
* tuneParams: tuning with irace is now also parallelized, i.e., different
  learner configs are evaluated in parallel.
* benchmark: mini fix, arg 'learners' now also accepts class strings
* object printers: some mlr printers show head previews of data.frames.
  these now also print info on the total nr of rows and cols and are less confusing
* aggregations: have better properties now, they know whether they require training or
  test set evals
* the filter methods have better R docs
* filter randomForestSRC.var.select: new arg ""method""
* filter mrmr: fixed some smaller bugs and updated properties
* generateLearningCurveData: also accepts single learner, does not require a list
* plotThreshVsPerf: added ""measures"" arg
* plotPartialDependence: can create tile plots with joint partial dependence
  on two features for multiclass classification by facetting across the classes
* generatePartialDependenceData and generateFunctionalANOVAData: expanded
  ""fun"" argument to allow for calculation of weights
* new ""?mlrFamilies"" manual page which lists all families and the functions
  belonging to it
* we are converging on data.table as a standard internally, this should not
  change any API behavior on the outside, though
* generateHyperParsEffectData and plotHyperParsEffect now support more than 2
  hyperparameters
* linear.correlation, rank.correlation, anova.test: use Rfast instead of
  FSelector/custom implementation now, performance should be much better
* use of our own colAUC function instead of the ROCR package for AUC calculation
  to improve performance
* we output resample performance messages for every iteration now
* performance improvements for the auc measure
* createDummyFeatures supports vectors now
* removed the pretty.names argument from plotHyperParsEffect -- labels can be set
  though normal ggplot2 functions on the returned object
* Fixed a bad bug in resample, the slot ""runtime"" or a ResampleResult,
  when the runtime was measured not in seconds but e.g. mins. R measures then potentially in mins,
  but mlr claimed it would be seconds.
* New ""dummy"" learners (that disregard features completely) can be fitted now for baseline comparisons,
  see ""featureless"" learners below.

## functions - new
* filter: randomForest.importance
* generateFeatureImportanceData: permutation-based feature importance and local
  importance
* getFeatureImportanceLearner: new Learner API function
* getFeatureImportance: top level function to extract feature importance
  information
* calculateROCMeasures
* calculateConfusionMatrix: new confusion-matrix like function that calculates
  and tables many receiver operator measures
* makeLearners: create multiple learners at once
* getLearnerId, getLearnerType, getLearnerPredictType, getLearnerPackages
* getLearnerParamSet, getLearnerParVals
* getRRPredictionList
* addRRMeasure
* plotResiduals
* getLearnerShortName
* mergeBenchmarkResults

## functions - renamed
* Renamed rf.importance filter (now deprecated) to randomForestSRC.var.rfsrc
* Renamed rf.min.depth filter (now deprecated) to randomForestSRC.var.select
* Renamed getConfMatrix (now deprecated) to calculateConfusionMatrix
* Renamed setId (now deprecated) to setLearnerId

## functions - removed
* mergeBenchmarkResultLearner, mergeBenchmarkResultTask

## learners - general
* classif.ada: fixed some param problem with rpart.control params
* classif.cforest, regr.cforest, surv.cforest:
  removed parameters ""minprob"", ""pvalue"", ""randomsplits""
  as these are set internally and cannot be changed by the user
* regr.GPfit: some more params for correlation kernel
* classif.xgboost, regr.xgboost: can now properly handle NAs (property was missing and other problems), added ""colsample_bylevel"" parameter
* adapted {classif,regr,surv}.ranger parameters for new ranger version

## learners - new
* multilabel.cforest
* surv.gbm
* regr.cvglmnet
* {classif,regr,surv}.gamboost
* classif.earth
* {classif,regr}.evtree
* {classif,regr}.evtree

## learners - removed
* classif.randomForestSRCSyn, regr.randomForestSRCSyn: due to continued stability issues

## measures - new
* ssr, qsr, lsr
* rrse, rae, mape
* kappa, wkappa
* msle, rmsle
",12465340
907,False,False,2018-06-23T15:27:57Z,2018-06-23T16:00:05Z,"## functions - general
* various cleanups that removed unused code
* subsetTask, getTaskData: arg ""features"" now also accepts logical and integer
* removeConstantFeatures now also operates on data.frames and
  makeRemoveConstantFeaturesWrapper can be used to augment a learner with this
  preprocessing step.
* normalizeFeatures, createDummyFeatures: arg 'exclude' was replaced by 'cols'
* normalizeFeatures is now S3 and can be called also on data.frames
* SMOTEWrapper: fix a bug where ""sw.nn"" was not correctly passed down
* fixed a bug that caused hyperparameters to be not passed on correctly in the
  ModelMultiplexer in some cases
* fix bug with NoFeaturesModel and ModelMultiplexer
* fix small bug in DownsampleWrapper when trained with weights
* getNestedTuneResultsOptPathDf: added new arg ""trafo""
* improve documentation for permutation.importance filter and perform slight
  argument renaming to fix potential name clashes
* plotPartialDependence can plot classification tasks with more than one
  interacted features now
* generateFilterValuesData: added argument 'more.args'
* add pretty.names arguments to plots that show learner short names instead of IDs
* addition of 'data' argument to plotPartialDependence which adds the training
  data to the graph
* added new arguments ""facet.wrap.nrow"" and ""facet.wrap.ncol"" which enable
  arrangement of facets in
  rows and columns to plotting functions

## functions - new
* generateHyperParsEffectData, plotHyperParsEffect
* makeMultilabelClassifierChainsWrapper, makeMultilabelDBRWrapper
  makeMultilabelNestedStackingWrapper, makeMultilabelStackingWrapper
* makeConstantClassWrapper
* generateFunctionalANOVAData

## functions - removed
* getParamSet generic (now in ParamHelpers package)

## functions - renamed
* generatePartialPrediction to generatePartialDependence
* plotPartialPrediction to plotPartialDependence
* plotPartialPredictionGGVIS to plotPartialDependenceGGVIS

## learners - general
* fixed weight handling and weight tag for some learners
* remove unnecessary linear.output parameter for classif.neuralnet
* remove unsupported KSVM parameter value stringdot
* fix some bartMachine compatibility issues
* classif.ranger, regr.ranger and surv.ranger: now respect unordered factors by
  default
* clean up randomForestSRC and randomForestSRCSyn learners
* the ""penalized"" learner were restructured and improved (params were added), also
  see below.
* add stability.nugget parameter for ""regr.km""
* classif.blackboost, regr.blackboost: made sure that arg ""stump"" is passed on
  correctly
* fixed parameter values for WEKA learners IBk, J48, PART, EM, SimpleKMeans, XMeans
* classif.glmboost, regr.glmboost: add parameters stopintern and trace

## learners - new
* classif.C50
* classif.gausspr
* classif.penalized.fusedlasso
* classif.penalized.lasso
* classif.penalized.ridge
* classif.h2o.deeplearning
* classif.h2o.gbm
* classif.h2o.glm
* classif.h2o.randomForest
* classif.rrf
* regr.penalized.fusedlasso
* regr.gausspr
* regr.glm
* regr.GPfit
* regr.h2o.deeplearning
* regr.h2o.gbm
* regr.h2o.glm
* regr.h2o.randomForest
* regr.rrf
* surv.cv.CoxBoost
* surv.penalized.fusedlasso
* surv.penalized.lasso
* surv.penalized.ridge
* cluster.kkmeans
* multilabel.randomforestSRC

## learners - removed
* surv.optimCoxBoostPenalty
* surv.penalized (split up, see new learners above)

## measures - general
* updated gmean measure and unit test, added reference to formula of gmean
* makeCostMeasure: removed arg ""task"", names of cost matrix are checked on measure
  calculation

## measures - new
* multiclass.brier
* brier.scaled
* logloss
* multilabel.subset01, multilabel.f1, multilabel.acc, multilabel.ppv,
  multilabel.tpr
* multiclass.au1p, multiclass.au1u, multiclass.aunp, multiclass.aunu

## measures - renamed
* multiclass.auc to multiclass.au1u
* hamloss to multilabel.hamloss",12465340
908,False,False,2016-02-13T11:32:23Z,2018-06-23T15:59:50Z,"* Feature filter ""univariate"" had a bad name, was deprecated and is now called
  ""univariate.model.score"". The new one also has better defaults.
* (generate/plot)PartialPrediction: added new arg ""geom"" for tile plots
* small fix for plotBMRSummary
* the ModelMultiplexer inherits its predict.type from the base learners now
* check that learners in an ensemble have the same predict.type
* new function getBMRModels to extract stored models from a benchmark result
* Fixed a bug where several learners from the LiblineaR package
  (""classif.LiblineaRL2LogReg"", ""classif.LiblineaRL2SVC"", ""regr.LiblineaRL2L2SVR"")
  were calling the wrong value for ""type"" (0) and thus training the wrong model.
* Fixed a bug where the resampling objects hout, cv2, cv3, cv5, cv10 were not
  documented in the ResampleDesc help page
* regr.xgboost, classif.xgboost: add feval param
* fixed a bug in irace tuning interface with unamed discrete values
* Fixed bugs in ""jackknife"" and ""bootstrap"" se estimators for regr.randomForest.
* Added ""sd"" estimator for regr.randomForest.
* Fixed a mini bug in ModelMultiplexer where hyperpars that are only needed in
  predict were not passed down correctly
* Fixed a bug where the function capLargeValues wasn't working if you passed a
  task.
* capLargeValues now has a new argument ""target"", to prevent from capping response
  values.
* classif.gbm, regr.gbm: Updated possible 'distribution' settings a bit.
* oversample, undersample, makeOversampleWrapper, makeUndersampleWrapper,
  makeOverBaggingWrapper:
  Added arguments to specifically select the sampled class.

## API changes
* listLearners now returns a data frame with properties of the learners if
  create is false

## new functions
* getBMRModels

## removed functions
* generateROCRCurvesData, plotROCRCurves, plotROCRCurvesGGVIS

## new learners
* classif.randomForestSRCSyn
* classif.cvglmnet
* regr.randomForestSRCSyn
* cluster.dbscan

## new measures
* rsq, arsq, expvar",12465340
909,False,False,2015-12-04T18:44:40Z,2018-06-23T15:59:36Z,"* New argument ""models"" for function benchmark
* fixed a bug where 'keep.pred' was ignored in the benchmark function
* some of the very new functions for benchmark plots had to be refactored and/or
  renamed.
  these names are gone from the API:
  plotBenchmarkResult, generateRankMatrixAsBarData, plotRankMatrixAsBar, generateBenchmarkSummaryData, plotBenchmarkSummary,
  this is the new API:
  plotBMRSummary, plotBMRBoxplots, plotBMRRanksAsBarChart",12465340
910,False,False,2015-11-26T20:06:20Z,2018-06-23T15:59:22Z,"* cluster.kmeans: added support for fuzzy clustering (property ""prob"")
* regr.lm: removed some erroneous param settings
* regr.glmnet: added 'family' param and allowed 'gaussian', but also 'poisson'
* disabled plotViperCharts unit tests as VC seems to be offline currently
* multilabel: improve few task getter functions, especially getTaskFormula is
  now correct

## new learners
* regr.glmboost
* cluster.Cobweb",12465340
911,False,False,2015-11-20T17:38:31Z,2018-06-23T15:59:08Z,"* fixed a bug that caused performance() to return incorrect values with
  ResamplePredictions
* we have (somewhat experimental) support for multilabel classification.
  so we now have a task, a new baselearner (rFerns),
  and a generic reduction-to-binary algorithm (MultilabelWrapper)
* tuning: added 'budget' parameter in makeTuneControl* (single-objective)
  and makeTuneMultiCritControl* (multi-objective scenarios), allowing to define
  a maximum ""number of evaluations"" budget for tuning algorithms
* tuning: added 'budget' parameter in makeTuneMultiCritControl*, allowing to
  define a maximum ""number of evaluations"" budget for tuning algorithms
  in the single-objective case
* makeTuneControlGenSA: optimized function will be considered non-smooth
  per default (change via ... args)
* classif.svm, regr.svm: added 'scale' param
* ksvm: added 'cache' param
* plotFilterValuesGGVIS: sort and n_show are interactive, interactive flag removed
* renamed getProbabilities to getPredictionProbabilities and deprecated
  getProbabilities
* plots now use long names for measures where possible
* there was a nasty bug in measure ""mcc"". fixed and unit tested. and apologies.
* removed getTaskFormulaAsString and improved getTaskFormula so the former is
  not needed anymore
* aggregations now have a 'name' property, which is a long name
* generateLearningCurveData and generateThreshVsPerfData now append the
  aggregation id to the output column name if the measure ids are the same
* plotLearningCurve, plotLearningCurveGGVIS, plotThreshVsPerf,
  plotThreshVsPerfGGVIS now have an argument
  'pretty.names' which plots the 'name' element of the measures instead of the 'id'.
* makeCustomResampledMeasure now has arguments 'measure.id' and 'aggregation.id'
  instead of only 'id' which corresponded to the measure. Also, 'name' and note (corresponding to the measure)
  as well as 'aggregation.name' have been added.
* makeCostMeasure now has arguments 'name' and 'id'.
* classification learner now can have a property 'class.weights', supported by
  'class.weights.param'. The latter indicates which of the parameters provides
  that class weights information to the learner.
* class weights integrated in the learner will be used as default for 'wcw.param'
  in 'makeWeightedClassesWrapper'
* listLearners with create = FALSE does not load packages anymore and is
  therefore faster and more reliable; it also supports the additional parameter
  check.packages now that will check whether required packages are installed
  without loading them
* many new functions for statistical benchmark comparisons are added, see below
* rename hasProperties, getProperties to hasLearnerProperties and
  getLearnerProperties
* Learner properties are now implemented object oriented as a state of a Learner.
  Only RLearners have the properties stored in a slot.
  For each class the getter can be overwritten.
* The hill climbing algorithm for stacking (Caruana 04) is implemented as method
  'hill.climb' in 'makeStackedLearner' to select models from base learners, which
  is equivalent to weighted average.
* The model compression algorithm for stacking (Caruana 06) is implemented as
  method 'compress' in 'makeStackedLearner' to first select models from base
  learners and then mimic the behaviour with a super learner. The default super
  learner is neural network.
* relativeOverfitting provides a way to estimate how much a model overfits to
  the training data according to a measure.
* restructured the LiblineaR learners to a more convenient format. These old ones
  were removed:
  classif.LiblineaRBinary, classif.LiblineaRLogReg,  classif.LiblineaRMultiClass.
  For the new ones, see below.
* Added some commonly used ResampleDesc description objects, to save typing in
  resample experiments:
  hout, cv2, cv3, cv5, cv10.
* regr.randomForest: changed default nodesize to 5 (according to randomForest
  defaults)

## new functions
* getDefaultMeasure
* getTaskClassLevels
* getPredictionTruth, getPredictionResponse, getPredictionSE
* convertMLBenchObjToTask
* getBMRLearners, getBMRMeasures, getBMRMeasureIds
* makeMultilabelTask, makeMultilabelWrapper, getMultilabelBinaryPerformances
* generatePartialPredictionData, plotPartialPrediction, and
  plotPartialPredictionGGVIS
* getClassWeightParam
* plotBenchmarkResult, convertBMRToRankMatrix, generateRankMatrixAsBarData,
  plotRankMatrixAsBar, generateBenchmarkSummaryData, plotBenchmarkSummary,
  friedmanTestBMR, friedmanPostHocTestBMR, generateCritDifferencesData,
  plotCritDifferences
* getCaretParamSet
* generateCalibrationData and plotCalibration
* relativeOverfitting
* plotROCCurves

## new measures
* hamloss

## new learners
* multilabel.rFerns
* classif.avNNet
* classif.neuralnet
* regr.avNNet
* classif.clusterSVM
* classif.dcSVM
* classif.gaterSVM
* classif.mlp
* classif.saeDNN
* classif.dbnDNN
* classif.nnTrain
* classif.rknn
* regr.rknn
* classif.xgboost
* regr.xgboost
* classif.rotationForest
* classif.LiblineaRL1L2SVC
* classif.LiblineaRL1LogReg
* classif.LiblineaRL2L1SVC
* classif.LiblineaRL2LogReg
* classif.LiblineaRL1LMultiClassSVC
* regr.LiblineaRL2L1SVR
* regr.LiblineaRL2L2SVR
* classif.ranger
* regr.ranger
* surv.ranger

## new filters
* permutation.importance

## removed functions
* setProperties, addProperties, removeProperties",12465340
912,False,False,2015-06-13T15:20:30Z,2018-06-23T15:58:54Z,"* WrappedModel printer was slightly improved
* ReampleResult now stores the runtime it took to resample in a slot
* getTaskFormula / getTaskFormulaAsString have new argument 'explicit.features'
* getTaskData now has recodeY = ""drop.levels"" which drops empty factor levels
* option fix.factors in makeLearner was renamed to fix.factors.prediction for
  clarity
* showHyperPars was removed. getParamSet does exactly the same thing
* 'resample' and 'benchmark' got the argument keep.pred,
  setting it to FALSE allows to discard the prediction objects to save memory
* we had to slightly change how the mem usage is reported in tuning and feature
  selection
  See TuneControl and FeatSelControl where it is documented what is done now.
* tuneIrace: allows to set the precision / digits within irace (using the argument
  'digits' in makeTuneControlIrace); default is maximum precision
* for plotting in general we try to introduce a ""data layer"", so the data can be
  generated independently of the plotting first, into well-defined objects;
  these can then be plotted with mlr or custom code;
  the naming scheme is always generate<Foo>Data and plot<Foo>
* getFilterValues is deprecated in favor of generateFilterValuesData
* plotFilterValues can now plot multiple filter methods using facetting
* plotROCRCurves has been rewritten to use ggplot2
* classif.ada: added ""loss"" hyperpar
* add missings properties to all ctree and cforest methods:
  regr/classif for ctree, regr/classif/surv for cforest, and regr/classif for blackboost
* learner xgboost was removed, because the package is not on CRAN anymore,
  unfortunately
* reg.km: added param 'iso'
* classif.mda: added param 'start.method' and changed its default to 'lvq', added
  params 'sub.df', 'tot.df' and 'criterion'
* classif.randomForest: 'sampsize' can now be an int vector (instead of a scalar)
* plotThreshVsPerf and plotLearningCurve now have param 'facet'

## new functions
* getTaskSize
* getNestedTuneResultsX, getNestedTuneResultsOptPathDf
* tuneDesign
* generateROCRCurvesData, generateFilterValuesData, generateLearningCurveData,
  plotLearningCurve, generateThreshVsPerfData, plotThreshVsPerf,
* generateThreshVsPerfData accepts Prediction, ResampleResult, lists of
  ResampleResult, and BenchmarkResult objects.
* experimental ggvis functions: plotROCRCurvesGGVIS, plotLearningCurveGGVIS,
  plotTuneMultiCritResultGGVIS, plotThreshVsPerfGGVIS, and plotFilterValuesGGVIS

## new learners:
* classif.bst
* classif.hdrda
* classif.nodeHarvest
* classif.pamr
* classif.rFerns
* classif.sparseLDA
* regr.bst
* regr.frbs
* regr.nodeHarvest
* regr.slim

## new measures:
* brier",12465340
913,False,False,2014-10-29T08:22:12Z,2018-06-23T15:57:17Z,"* The web tutorial was MUCH improved!
* more example tasks and data sets
* Learners and tasks now support ordered factors as features.
  The task description knows whether ordered factors are present and it is checked
  whether the learner supports such a feature. We have set this property 'ordered'
  very conservatively, so very few learners have it, where we are sure ordered
  inputs are handled correctly during training.
  If you know of more models that support this, please inform us.
* basic R learners now have new slots: name (a descriptive name of the algorithm),
  short.name (abbreviation that can be used in plots and tables) and note
  (notes regarding slight changes for the mlr integration of the learner and such).
* makeLearner now supports some options regarding learner error handling and
  output which could before only be set globally via configureMlr
* Additional arguments for imputation functions to allow a more fine-grain
  control of dummy column creation
* imputeMin and imputeMax now subtract or add a multiple of the range of
  the data from the minimum or to the maximum, respectively.
* cluster methods now have property 'prob' when they support fuzzy cluster
  membership probabilities,
  and also then support predict.type = 'prob'. Everything basically works the same
  as for posterior probabilities in classif.* methods.
* predict preserves the rownames of the input in its output
* fixed a bug in createDummyFeatures that caused an error when the data contained
  missing values.
* plotLearnerPrediction works for clustering and allows greyscale plots (for
  printing or articles)
* the whole object-oriented structure behind feature filtering was much
  improved. Smaller changes in the signature of makeFilterWrapper and
  filterFeatures have become necessary.
* fixed a bug in filter methods of the FSelector package that caused an error when
  variable names contained accented letters
* filterFeatures can now be also applied to the result of getFilterValues
* We dropped the data.frame version of some preprocessing operations like
  mergeFactorLevelsBySize,
  joinClassLevels and removeConstantFeatures for consistency. These now always require tasks as input.
* We support a pretty generic framework for stacking / super-learning now, see
  makeStackedLearner
* imbalancy correction + smote:
  ** fix a bug in ""smote"" when only factor features are present
  ** change to oversampling: sample new observations only (with replacement)
  ** extension to smote algorithm (sampling): minority class observations in
  binary classification
  are either chosen via sampling or alternatively, each minority class observation
  is used an equal number of times
* made the getters for BenchmarkResult more consistent. These are now:
  getBMRTaskIds, getBMRLearnerIds, getBMRPredictions, getBMRPerformances,
  getBMRAggrPerformances
  getBMRTuneResults, getFeatSelResults, getBMRFilteredFeatures
  The following methods do not work for BenchmarkResult anymore: getTuneResult, getFeatSelResult
* Removed getFilterResult, because it does the same as getFilteredFeatures

## new learners:
* classif.bartMachine
* classif.lqa
* classif.randomForestSRC
* classif.sda
* regr.ctree
* regr.plsr
* regr.randomForestSRC
* cluster.cmeans
* cluster.DBScan
* cluster.kmeans
* cluster.FarthestFirst
* surv.cvglmnet
* surv.optimCoxBoostPenalty

## new filters:
* variance
* univariate
* carscore
* rf.importance, rf.min.depth
* anova.test, kruskal.test
* mrmr

## new functions
* makeMulticlassWrapper
* makeStackedLearner, getStackedBaseLearnerPredictions
* joinClassLevels
* summarizeColumns, summarizeLevels
* capLargeValues, mergeFactorLevelsBySize",12465340
914,False,False,2015-02-04T04:34:28Z,2018-06-23T15:58:37Z,"* resample now returns an object of class ResampleResult (downward compatible)
  to allow for a print method.
* resampling on features now supported for an arbitrary number of factor features
* mlr supports ViperCharts plots now
* ROC plot via ROCR can now be created automatically, before you had to call
  asROCRPrediction,
  then construct the plots via ROCR your self. See plotROCRCurves
* all mlr measures now have slots ""name"" and ""note""
* exported a few very simple ""getters"" for tasks, see below
* in makeLearner a probability predict.threshold can be set for classifiers, also
  see setPredictThreshold
* in the control objects for tuning and feature selection, the user can now enable
  threshold tuning
* in the control objects for tuning and feature selection, the user can now define
  his own logging function
* default console logging for tuneParams and selectFeatures is more informative,
  it displays time and memory info
* updated some properties of some learners
* Default arguments of classif.bartMachine, classif.randomForestSRC,
  regr.randomForestSRC and sur.randomForestSRC
  have been changed to allow missing data support with default settings.
* externalized measure functions to be used on vectors.
* some minor bug fixes
* required basic learner packages are not loaded into the global namespace
  anymore, requireNamespace
  is used internally instead. this ensures less name clashes and name shadowing
* resample passes dot arguments to the learner hyperpars
* new option ""on.par.out.of.bounds"" to disable out-of-bound checks for model
  parameters
* measures were slightly internally changed. they expose more properties (check
  ?Measure) and some now unnecessary object slots were removed
* classif.lda and classif.qda now have hyperpar ""predict.method""
* filterFeatures and makeFilterWrapper gain an argument for mandatory features
* plotLearnerPrediction has new option ""err.size""
* classif.plsDA and cluster.DBscan for now removed because of problems with the
  underlying learning algorithm
* new aggregation test.join
* the following models now can handle factors and ordereds by extra dummy or int
  encoding:
  classif.glmnet, regr.glmnet, surv.glmnet, surv.cvglmnet, surv.penalized,
  surv.optimCoxBoostPenalty, surv.glmboost, surv.CoxBoost

## new functions
* getTaskType, getTaskId, getTaskTargetNames
* plotROCRCurves
* plotViperCharts
* measureSSE, measureMSE, measureRMSE, measureMEDSE, ...
* PreprocWrapperCaret
* setPredictThreshold

## new learners:
* classif.bdk
* classif.binomial
* classif.extraTrees
* classif.probit
* classif.xgboost
* classif.xyf
* regr.bartMachine
* regr.bcart
* regr.bdk
* regr.bgp
* regr.bgpllm
* regr.blm
* regr.brnn
* regr.btgp
* regr.btgpllm
* regr.btlm
* regr.cubist
* regr.elmNN
* regr.extraTrees
* regr.laGP
* regr.xgboost
* regr.xyf
* surv.rpart",12465340
915,False,False,2020-01-24T22:17:36Z,2020-01-24T23:26:48Z,- Add `cumMin` and `cumMax`,48880766
916,False,False,2020-01-24T19:26:47Z,2020-01-24T19:48:29Z,"## Breaking Changes

- `Table.summary` now returns a `Table` instead of a `String` - Thanks @jackie-h 

## Features

- Table transpose https://github.com/jtablesaw/tablesaw/commit/1b01eaf5c94c8a51d09be7fe2c080a78dc9a03e1 - Thanks @jackie-h 
- Added ability to sample rows while reading a CSV - Thanks @aecio 
- Additional Column and Table create methods

## Cleanup

- Fixed a bunch of SonarCloud warnings
- Improved exception message for duplicate Table columns
- Validation for Table joins",48880766
917,False,False,2020-01-08T18:56:30Z,2020-01-08T19:04:00Z,"## Features
- Upgraded to Smile 2.0 (https://github.com/jtablesaw/tablesaw/pull/735)
- Autocorrelation (https://github.com/jtablesaw/tablesaw/pull/726)
- `InstantColumn` `min` and `max` (https://github.com/jtablesaw/tablesaw/pull/719)
- Enhancements to histogram (https://github.com/jtablesaw/tablesaw/pull/700)
- New `Column.map` method (https://github.com/jtablesaw/tablesaw/pull/705)
- Expose two `FileReader` methods (https://github.com/jtablesaw/tablesaw/pull/701)
- New Plotly config argument (https://github.com/jtablesaw/tablesaw/pull/691)
- Read specific Excel sheet (https://github.com/jtablesaw/tablesaw/pull/683)
- Read JSON subtree (https://github.com/jtablesaw/tablesaw/pull/684)
- Read specific HTML table (https://github.com/jtablesaw/tablesaw/pull/682)

## Bug Fixes
- Only set `LayoutBuilder.autosize` if necessary (https://github.com/jtablesaw/tablesaw/pull/713)",48880766
918,False,False,2019-09-29T18:31:50Z,2019-09-29T19:05:26Z,"## Breaking changes
- `Table.numberColumn` now returns `NumericColumn` instead of `NumberColumn` (https://github.com/jtablesaw/tablesaw/pull/669)

## Features
- Interpolation of missing cells (https://github.com/jtablesaw/tablesaw/pull/664)
- File encoding detection (https://github.com/jtablesaw/tablesaw/pull/654)
- `stdDev` for rolling columns (https://github.com/jtablesaw/tablesaw/pull/666)
- `Column` UI widget in BeakerX (https://github.com/jtablesaw/tablesaw/pull/668)
- Additional `replaceColumn` method (https://github.com/jtablesaw/tablesaw/pull/673)

## Bug Fixes
- Fix reading CSV files with space at edge of column name (https://github.com/jtablesaw/tablesaw/pull/659)
- Fix `ignoreLeadingWhitespace` (https://github.com/jtablesaw/tablesaw/commit/fb207104725eb20a5038b29e7c8828b754d4f36d)
- Fix handling of boolean columns in `SawWriter` (https://github.com/jtablesaw/tablesaw/pull/661)",48880766
919,False,False,2019-09-03T06:02:08Z,2019-09-03T06:11:02Z,"## Deprecations and breaking changes
- Deprecated `data()` methods (https://github.com/jtablesaw/tablesaw/pull/649)
- Renamed `isMissingValue` to `valueIsMissing` (https://github.com/jtablesaw/tablesaw/pull/643)
- Removed `mapToType` added in last release (https://github.com/jtablesaw/tablesaw/pull/583)

## Features
- Analytic Query functions (https://github.com/jtablesaw/tablesaw/pull/606 and https://github.com/jtablesaw/tablesaw/pull/621)
- Deferred execution queries (https://github.com/jtablesaw/tablesaw/pull/574)
- Saw file format persistence (https://github.com/jtablesaw/tablesaw/pull/642)
- Column creation from streams (https://github.com/jtablesaw/tablesaw/pull/634)
- Improved reading from URL (https://github.com/jtablesaw/tablesaw/pull/650)
- `remainder`, `capitalize`, `repeat`, and `concatenate` functions (https://github.com/jtablesaw/tablesaw/pull/635)
- `Figure.builder` (https://github.com/jtablesaw/tablesaw/pull/608)
- Option to ignore whitespace in csv writer (https://github.com/jtablesaw/tablesaw/pull/605 - thanks @sd1998)

## Performance
- Speed up joins (https://github.com/jtablesaw/tablesaw/pull/562)
- Speed up `TextColumn`'s `isIn` method (https://github.com/jtablesaw/tablesaw/pull/613)

## Bug fixes
- Fix NPE when reading incomplete JSON rows (https://github.com/jtablesaw/tablesaw/pull/591)
- Make empty columns be of type string (https://github.com/jtablesaw/tablesaw/pull/626)
- Include missing values in `unique` (https://github.com/jtablesaw/tablesaw/pull/595)
- Fix conversion of missing values in `IntColumn.toDoubleColumn` (https://github.com/jtablesaw/tablesaw/issues/577)
- Fixed `splitOn` for `TextColumn` (https://github.com/jtablesaw/tablesaw/issues/554)
- Handling of null values in `SqlResultSetReader` (https://github.com/jtablesaw/tablesaw/pull/563)

## Documentation
- Began compiling code samples in docs (https://github.com/jtablesaw/tablesaw/pull/637, https://github.com/jtablesaw/tablesaw/pull/639, and https://github.com/jtablesaw/tablesaw/pull/641)

## Development
- Automatically format code (https://github.com/jtablesaw/tablesaw/pull/570 and https://github.com/jtablesaw/tablesaw/pull/568)",48880766
920,False,False,2019-08-02T02:13:51Z,2019-08-02T02:25:20Z,"## Features

- Add `table.stream` (https://github.com/jtablesaw/tablesaw/pull/540)
- Add `fillWith(double)` (https://github.com/jtablesaw/tablesaw/pull/539)
- Add mapToType (https://github.com/jtablesaw/tablesaw/pull/545) - Thanks @ryancerf 
- Add `appendRow` (https://github.com/jtablesaw/tablesaw/commit/6f98623d81d0e57d0cc5e9ab622b518165f7a74d)
- Subplots (https://github.com/jtablesaw/tablesaw/pull/548) - Thanks @kiamesdavies 
- QQ plots and related improvements
- plotly events (https://github.com/jtablesaw/tablesaw/pull/512) - Thanks @tmrn411 


## Bug Fixes

- Data export to Smile (https://github.com/jtablesaw/tablesaw/pull/528) - Thanks @kiamesdavies 
- Unit tests on Windows (https://github.com/jtablesaw/tablesaw/pull/546) - Thanks @paulk-asert 
- Calculation of unique values in string columns (https://github.com/jtablesaw/tablesaw/pull/544) - Thanks @ccleva 
- Ensure tests are run (https://github.com/jtablesaw/tablesaw/pull/551) - Thanks @ccleva 
- `asObjectArray` in numeric columns (https://github.com/jtablesaw/tablesaw/commit/6f9086897b6e85c482f5f4de3bcb71c4ae53295a)
- Possible exception in `toString` (https://github.com/jtablesaw/tablesaw/pull/497) - Thanks @hallvard ",48880766
921,False,False,2019-06-15T01:39:45Z,2019-06-17T02:26:41Z,"## Features
- Improved `RollingColumn` support
- Option for CSV quote character (https://github.com/jtablesaw/tablesaw/pull/536)
- New `dropRange` and `inRange` methods (#534)
- Improved `NumberPredicates` (#532)

## Bug Fixes
- Fix `DoubleColumn.map` (https://github.com/jtablesaw/tablesaw/pull/533)",48880766
922,False,False,2019-06-05T15:13:27Z,2019-06-05T15:21:56Z,"## Breaking changes
- Renamed `join` to `joinOn` so that it will work with Groovy (https://github.com/jtablesaw/tablesaw/pull/531)

## Features
- Added `set` with predicate method (https://github.com/jtablesaw/tablesaw/pull/530)",48880766
923,False,False,2019-05-31T02:48:02Z,2019-06-04T16:37:34Z,- Make `PackedInstant.toString` parsable by `Instant.parse`,48880766
924,False,False,2019-05-31T01:47:22Z,2019-06-04T16:36:24Z,- Implement `InstantParser`,48880766
925,False,False,2019-05-30T21:41:04Z,2019-06-04T16:36:00Z,"- Fix `InstantColumnType.create`
- Bump `jackson-databind` to pull in security fix",48880766
926,False,False,2019-05-21T19:23:33Z,2019-06-04T16:35:05Z,"- `InstantColumn` support in `Row` and `DataFrameJoiner`
- Additional `DataFrameReader` parameter validation",48880766
927,False,False,2019-05-19T18:08:38Z,2019-06-04T16:33:37Z,- Add `InstantColumn` support to `Relation`,48880766
928,False,False,2019-05-19T03:42:47Z,2019-06-04T16:32:40Z,"## Features
- Add `InstantColumn` (https://github.com/jtablesaw/tablesaw/pull/518)
- More configurable column type detection (https://github.com/jtablesaw/tablesaw/pull/521)
- Added option for turning off html escaping in html table output
- Additional date parsing capabilities (https://github.com/jtablesaw/tablesaw/issues/506)

## Fixes
- Fix for `precision` of `0` in `JdbcResultSet` (https://github.com/jtablesaw/tablesaw/pull/523)

## Cleanup
- Remove circular dependency between reader packages and core package
- Remove unused epoch conversion methods (https://github.com/jtablesaw/tablesaw/pull/513)",48880766
929,False,False,2019-03-31T18:01:30Z,2019-03-31T18:11:02Z,"- Implemented `maxCharsPerColumn` CSV parser setting
- Fix `DateTimeParser` issue
- Switch from reflections to classgraph
- Updated pebble version in jsplot",48880766
930,False,False,2019-03-24T05:38:39Z,2019-03-24T13:47:14Z,- Use header option in `HtmlReader`,48880766
931,False,False,2019-03-24T04:03:21Z,2019-03-24T04:14:52Z,"- Fix `HTMLReader` when using `InputStream`
- Fix reading from `URL` when charset is specified",48880766
932,False,False,2019-03-24T00:36:33Z,2019-03-24T00:39:33Z,"- Major improvements to `HtmlWriter`
- Fixed `print(1)`
- Added marker support for bar and histogram",48880766
933,False,False,2019-03-12T04:48:18Z,2019-03-13T04:12:57Z,- Improved interface for `DataWriter`,48880766
934,False,False,2019-03-12T04:08:56Z,2019-03-13T04:12:12Z,- Optional `DataReader` modules are now working,48880766
935,False,False,2019-03-11T17:09:57Z,2019-03-13T04:10:45Z,- Introduce `ReaderRegistry` and new `DataFrameReader` methods,48880766
936,False,False,2019-03-09T01:06:04Z,2019-03-09T01:19:54Z,"## Major features
- XLSX support (https://github.com/jtablesaw/tablesaw/pull/470). Thanks @hallvard 
- New optional module structure, which was unfortunately broken (https://github.com/jtablesaw/tablesaw/pull/475)

## Enhancements
- Implemented plot.ly's `categoryOrder`
- Support comment character in CSV files (https://github.com/jtablesaw/tablesaw/pull/483). Thanks @jmcgonegal 
- Plot.ly template customization (#482). Thanks @hallvard 
- Configure shade plugin to create OSGi bundles (https://github.com/jtablesaw/tablesaw/pull/481). Thanks @hallvard 

## Bug fixes
- Fixed `stepWithRows`

## Development
- Upgrade to junit 5 (https://github.com/jtablesaw/tablesaw/pull/476)",48880766
937,False,False,2019-02-19T18:40:11Z,2019-02-19T18:44:46Z,"- Fat columns returned from file readers by default
- Fixed-width file support (Thanks @Sparow199)
- Improved marker support
- Support for custom color bars on scatter charts with scaled colors
- Additional table creation validation
- Fixed numeric to string conversion",48880766
938,False,False,2019-02-09T17:08:42Z,2019-02-09T17:15:57Z,- Adds ability to read and write JSON data,48880766
939,False,False,2019-02-02T04:03:16Z,2019-02-02T04:14:54Z,"- Fix for `NullPointerException` in `Table.read().csv()`
- Fix for marker color
- Minor join performance improvements
- Fix for Windows line ending issues
- Fix for reading SQL result set
- Allow pie charts to take floating points
- Fixed sorting in `TimeSeriesPlot`",48880766
940,False,False,2018-11-20T04:37:55Z,2019-01-05T05:27:21Z,"* Tweaks to CSV sampling
* Fix `isMissing` for `StringColumn` and `TextColumn`. Thanks @armarti ",48880766
941,False,False,2019-01-05T05:14:32Z,2019-01-05T05:25:40Z,"* Improved Smile integration
* Pivot table functionality
* Bug fix for conversion from Hive bigInt
* SQL number type mapping. Thanks @gregorco
* Bug fix for `unique()`
* Improved `null` handling for `StringColumn`
* SQL Date support",48880766
942,False,False,2018-11-03T16:06:26Z,2018-11-03T16:22:57Z,"With this release we wanted to strike a balance between making the implementation and maintenance of the library more approachable, reducing memory usage, and providing powerful operations.

We provide non-double numeric column types so that data can be held in memory in a less memory-intensive manner. All computations return `DoubleColumn`. The alternative would be supporting every pair-wise type of numeric, which would quickly make the library too difficult to contribute to and maintain. The user can convert `DoubleColumn` to less memory intensive column types like `IntColumn` as they choose to reduce in-memory overhead for large tables. For small tables, users may be comfortable keeping all columns as `DoubleColumn`.

Other improvements include:
* Improvements to [Smile](https://haifengl.github.io/smile/) machine learning integration
* Additional CSV parsing options
* Bug fixes

Thanks to @hallvard, @Ebalaitung, @jln-ho, @gregorco for contributing to this release",48880766
943,False,False,2018-08-13T22:21:30Z,2018-08-17T01:38:06Z,* Switched to Univocity library for CSV handling,48880766
944,False,False,2018-08-16T15:43:30Z,2018-08-17T01:37:22Z,"* Fixed generics warnings
* CSV read performance enhancement",48880766
945,False,False,2018-08-12T20:43:54Z,2018-08-13T22:07:39Z,Made Column and ColumnType take parameter arguments reflecting the type of data held in each specialized column/type.,48880766
946,False,False,2018-08-06T15:31:47Z,2018-08-06T15:32:52Z,* Fixed `fillMissing` methods and added corresponding unit test,48880766
947,False,False,2018-08-06T05:22:13Z,2018-08-06T05:26:55Z,* `DoubleColumn` methods now return `DoubleColumn` instead of `NumberColumn`,48880766
948,False,False,2018-08-06T01:09:34Z,2018-08-06T01:18:13Z,* Added full outer joins,48880766
949,False,False,2018-08-05T16:36:37Z,2018-08-05T19:35:17Z,"* Added methods for filling missing values
* Improved `Row` performance",48880766
950,False,False,2018-08-04T12:14:48Z,2018-08-04T12:31:47Z,"Remove's the *plot* sub-project. 

People who need visualization with Tablesaw are encouraged to use the tablesaw-jsplot library instead. This layer is already better in many ways than the original. See the visualization section of the Tablesaw user guide for more information.

The native java plotting code was always something of a mess given the lack of a single, strong, appropriately licensed open-sourcevisualization library in Java. It relied on several other libraries to piece together its functionality, including Smile, XCharts, and JavaFx. 

The JavaFx dependency was particularly concerning since it is large, and was moved to a separate module in Java 9, and removed from the JDK entirely in Java 11, presenting some additional complexity from a build/deployment standpoint across JDK versions. 

Beyond that, the functionality of the library was very limited and both the API and the visual user interface were inconsistent due to the underlying inconsistencies between the libraries it was built on. ",48880766
951,False,False,2018-08-04T11:30:36Z,2018-08-04T12:11:02Z,"This release contains several enhancements, and considerable refactoring, some of which is not backward compatible. It also contains Codacy and travis updates and documentation improvements.

Refactoring:    
- replaced ColumnType.NUMBER with ColumnType.DOUBLE.  It was a bad decision to name the type NUMBER, and this walk-balk of that mistake was inevitable.  If this affects your code, a search/replace of NUMBER with DOUBLE should fix. 
- refactored a large amount of column-type related functionality into a revised ColumnType interface, including moving from enum to class-based column types and removing many places where code switched on column type. The work required to add a new column type is now much clearer and more centralized, although additional work is needed.  
- the above refactoring included a rationalization of column-specific CSV parsing, which had become quite a mess, as it was spread out in many places and included a bunch of special case logic.

Enhancements:
- Extended Joins to allow the client to specify whether duplicate column names should be allowed. If allowed, the duplicate columns are renamed; if not, an exception is thrown if any columns in table 2 has the same name as a column in table 1.
- made column lookup by name case-insensitive in Row. Now it works like column-lookup in Tables.

Docs:
- Extension of Time Series example code",48880766
952,False,False,2018-07-28T16:11:08Z,2018-07-28T17:58:52Z,"Enhancements, documentation, refactoring, and bug fixes in Visualization",48880766
953,False,False,2018-07-23T22:13:52Z,2018-08-01T12:19:32Z,,48880766
954,False,False,2018-07-21T20:36:59Z,2018-07-21T20:57:52Z,"Bug fixes:

- fix for dateTimeFormatter issue #313 and extended formatting fix to time and date columns.
- fix for bug introduced in fix for #229. CrossTab counts were not rendering totals 
- if the first category type was numeric. 

Enhancements:

- Simplified scatter and histogram classes and extended plot types for canned plots
- Improved file handling on Plots, each plot gets its own temp file
- Introduce a number of new canned plot types
- Extensive improvements to visualization documentation.
	
- Provided a converter to Smile's AttributeDataset (#311)
- restored helpful method from removed interface IntConvertibleColumn
- restored useful DoubleArray utils not in TableConverter
",48880766
955,False,False,2018-07-15T22:36:54Z,2018-07-15T22:41:18Z,* Added join convenience methods,48880766
956,False,False,2018-07-15T17:51:38Z,2018-07-15T19:23:46Z,"- Additional rolling aggregates
- Refined missing row handling in csv reader
- Standardized `set(Selection rowSelection, newValue)` API across column types",48880766
957,False,False,2018-07-15T19:18:40Z,2018-07-15T19:21:37Z,"- Added `power` function on `NumberColumn`
- Javadoc now hosted on javadoc.io",48880766
958,False,False,2018-07-14T17:12:05Z,2018-07-15T02:55:38Z,- Removed filtering via `QueryHelper`. Filtering should be done directly via column now,48880766
959,False,False,2018-07-12T16:55:11Z,2018-07-12T17:04:25Z,"* Added `table.as()...` functionality replacing `table.asMatrix()` and adding many new options
* Added an option to `CsvReaderOptions` to provide a missing value string
* Made `Row` constructor public
* Upgraded dependencies",48880766
960,False,False,2018-07-10T05:36:58Z,2018-07-10T05:39:41Z,"### Testing & Documentation

1. Increased test coverage from 44% in core, to 76%.

### Removed:

1. Removed Float, Int, Short, Long column types. An enhanced DoubleColumn is used for all numbers. 
2. Removed TableGroup, SubTable, and NumericSummaryTable. All replaced by standard table or TableSlice and TableSliceGroup.
3. Removed Smile integration
4. Removed experimental time interval support
5. Removed several index types
6. Removed .saw file persistence
7. Removed all deprecated methods
8. Removed methods of limited or unclear utility 
9. Removed Lombok dependency (it caused warnings in Java9 and The IDEA plugin is flakey)
10. Removed duplicate comparator implementations 

### Renamed:

1. Renamed CategoryColumn to StringColumn
1. Renamed NumericColumn interface to NumberColumn
1. Renamed TemporaryView and ViewGroup to TableSlice and TableSliceGroup

### Enhancements:

1. Numerous bug fixes

1. Added filler methods for each column.

1. Added CsvWriteOptions to allow greater control over file writing

1. Improved filtering support
    1. Implemented support for selecting specific columns, including calculated columns, in query result tables.

       ```java
       table.select(dateCol, dateCol.year()).where(nCol(""quantity"").isPositive());
       ```

    1. Standardized naming on queries for tables and columns:

       ```java
       Column c1 = col.where(col.isLessThan(4));
       Table  t1 = tab.where(col.isLessThan(4));
       ```

    1. Added several filtering methods to columns: 

       ```java
       Column c1 = col.inRange(int start, int end);
       Column c2 = col.rows(int… rows);
       Column c3 = col.sampleX(double proportion);
       Column c4 = col.sampleN(int nRows);
       ```

       Added support for using Java 8 predicates to filter columns

    1. Extended table filtering to support direct use of column filter methods (e.g. *col.startsWith(""foo"")*) in table where clauses

    1. Added And, Or, and Not filters to Table API so users don't need to use/know-about QueryHelper for most queries

    1. Added support for chaining ""selections"" so filters can be readily combined

       ```java
       col.where(col.isLessThan(3).and(col.isGreaterThan(-2)));
       ```

1. Improved join support
    1. Added support for left and right outer joins. For example:

       ```java
       table.join(""myJoinColumn"").leftOuter(table2, ""otherJoinColumn"");
       ```

    1. Added support for joining on doubles (after rounding to ints)

1. Reading and printing formatted data
    1. Added support for formatted printing of tables and columns (esp., number and time columns)

       ```java
       dateColumn.setPrintFormatter(DateTimeFormatter.ofPattern(""MMM~dd~yyyy""));
       ```

       ```Java
       doubleColumn.setPrintFormatter(NumberColumnFormatter.ints); 
       ```

    1. Added support for applying a locale for CSV file import

    1. Added support for applying DateTimeFormatters to read specific date/time formats from CSV files.

1. Standardize column instantiation methods
    1. Always use a static *create()* method rather than public constructors
    1. Standardize support for instantiating from lists and arrays.

1. Added support for lag(n) and lead(n) methods on all column types. These return the receivers data offset by n positions:

    ```Java
    Column xLag = columnX.lag(1);
    Column xLead = columnX.lead(1);
    ```

1. Extended PackedLocalTime and PackedLocalDate to be (approximately) functionally equivalent to Java's LocalDate and LocalTime.

1. Added initial support for JavaScript-based plotting using Plot.ly. See [this page](https://jtablesaw.github.io/tablesaw/Plotting.md) for more information. 

1. Improved Aggregation/Summarization

     1. Support for conditional summarization using *summarizeIf()*. The code below counts the number of strings in column that end with ""3"". 

        ```java
        double count = column.summarizeIf(column.endsWith(""3""), count);
        ```

     1. Simplified the CrossTab API, and provided methods for creating CrossTabs (aka contingency tables) in table objects:

        ```java
        table.xTabCounts(""columnA"", ""columnB"");
        ```

     1. Support for table summaries that include summaries of columns created on the fly using mapping functions:

        ```java
        table.summarize(dateColumn.year(), max, min);
        ```

     1. Support for table summaries that include non-numeric columns. For example, the code below applies *countTrue* to the boolean column and *standardDeviation* to the numeric column.

        ```java
        table.summarize(booleanColumn, numberColumn, countTrue, standardDeviation); 
        ```

     1. Support summarizing *by* ""time windows"" groups of n time units (days, weeks, years, etc).

        ```java
        table.summarize(""quantity"", mean, median).by(date.timeWindow(DAYS, 5));
        ```

     1. Support summarizing *by* named time units (months, for example):

        ```java
        table.summarize(""quantity"", mean, median).by(date.month());
        ```

     1. Both of the above are examples of a more general solution: Sub totals can per calculated for groups defined *by* any function that returns a column: 

        ```java
        table.summarize(""quantity"", sumOfSquares).by(strCol.substring(4, 7));
        ```
",48880766
961,False,True,2016-08-07T14:33:37Z,2016-08-07T14:40:10Z,"Aggregating changes and bug fixes for latest push to maven central. This release contains initial support for machine learning models, extensions to the visualization support, and numerous bug-fixes and minor enhancements to the data-frame capability.
",48880766
962,False,True,2016-07-24T13:33:46Z,2016-07-24T13:54:00Z,"New OpenCSV library added. 
Incorporated difference methods for smarks. 
A number of new methods added.
A (small) number of bug fixes, 
",48880766
963,False,True,2016-07-15T11:07:55Z,2016-07-15T11:13:51Z,"Bug fixes for column#isEqualTo(a Value), and Columnar addition/subtraction.

Includes 0.7, with all changes prior to first release maven central.

Note that this is still considered as in-progress, rather than a production-stable release.
",48880766
964,False,True,2016-07-11T17:00:48Z,2016-07-11T17:04:44Z,"Fixed build breakage due to pom dependency
",48880766
965,False,True,2016-07-10T16:46:27Z,2016-07-10T16:48:13Z,"Includes new and improved sorting API
Cleanup of descriptive statistics for all numeric column types
",48880766
966,False,True,2016-07-06T21:52:35Z,2016-07-06T21:55:19Z,"fixed Table append issue #62 
fixed float column missing value bugs
added unit tests to float column
",48880766
967,False,True,2016-07-06T11:25:30Z,2016-07-06T11:28:00Z,"Replaced RoaringBitmap where it was exposed in the API with an Interface called Selection.

Added Selection, and a RoaringBitmap-backed implementation called BitmapBackedSelection.

The intent is to provide greater flexibility going forward as the mechanics of the set operations on table indexes is likely to change. 
",48880766
968,False,True,2016-07-05T02:32:41Z,2016-07-05T02:39:23Z,"Bugfix on crosstab counts. 
Added crosstab column proportions
Cleaned-up crosstab columntype support

Various minor fixes and cosmetic tweaks (access, comments, etc..)

Renaming of mis-named countMissing() method.

Support for generating html table from a tablesaw table.
",48880766
969,False,True,2016-07-03T14:59:32Z,2016-07-03T15:04:10Z,"Includes revisions to standardize CSV file loading methods and generally clean up that interface.
",48880766
970,False,True,2016-06-30T20:48:17Z,2016-06-30T20:50:47Z,"Fixed a set of related bugs afflicting the math functions of float column. Bugs were introduced in mass in a refactoring.
Added smoke tests for most, and functional tests for some of the issues. 
",48880766
971,False,True,2016-06-30T01:53:22Z,2016-06-30T01:55:24Z,"Minor api changes, reformatting, small extensions to cross-tabs
",48880766
972,False,True,2016-06-29T11:45:18Z,2016-06-29T13:30:43Z,"Major restructuring of packages to clarify intent and make it easier to use Tablesaw from a REPL
",48880766
973,False,True,2016-06-27T04:14:24Z,2016-06-27T04:23:11Z,"Fixes bug in Table iteration when using for each loop on the row indexes:  (int row : table)
",48880766
974,False,True,2016-06-26T20:29:10Z,2016-06-26T20:30:26Z,"Extensions of date predicates to cover datetime columns.
",48880766
975,False,True,2016-06-26T17:14:41Z,2016-06-26T17:16:00Z,"Minor functional extensions and minor bug-fixes
",48880766
976,False,True,2016-06-26T12:03:36Z,2016-06-26T12:05:21Z,"Fixed missing value handling in csv column type detection logic.
",48880766
977,False,True,2016-06-26T02:10:19Z,2016-06-26T02:13:08Z,"Added auto-detection of column types in the csv loading routines. As these methods estimate the types from a sample of the data in the column, they may produce incorrect guesses. Additional methods have been added to simplify the process of manually specifying types by producing the list of guestimated types for editing.
",48880766
978,False,True,2016-06-25T01:34:11Z,2016-06-25T03:51:17Z,"Numerous API changes (mostly name changes) regarding dates and times primarily. 
Extension of minor functionality, mostly at the column level.
",48880766
979,False,True,2016-06-23T04:45:51Z,2016-06-23T05:04:46Z,"Minor enhancements in functionality, plus a significant improvement in CSV file loading times when the files contain dates.
Test with 4 columns (one a date) and 1/2 billion rows, completed in 14:45, down from 38:30.
",48880766
980,False,True,2016-06-19T00:11:49Z,2016-06-19T00:15:10Z,"Incorporates support for loading data via SQL/JDBC.
Numerous bug-fixes and performance improvements
",48880766
981,False,True,2016-06-12T15:45:07Z,2016-06-12T15:55:29Z,"This version includes work to reduce the number of imports needed for use in a Java 9 REPL, as well as a few new methods, and documentation enhancements.

The primary area of functionality that remains is to bring support for grouping and aggregation up to the level of functionality in Outlier. 
",48880766
982,False,True,2016-06-12T13:11:32Z,2016-06-12T13:15:29Z,"Numerous bug-fixes, documentation improvements, and functional enhancements, in the area of general table and column functionality, as well as in column-store api and implementation. 
",48880766
983,False,True,2016-06-11T11:01:57Z,2016-06-11T11:06:34Z,"An initial release of Tablesaw. There is considerable functionality here, but APIs will change, and there are numerous issues.  Nevertheless, starting the process of moving towards a production version.
",48880766
984,False,False,2017-09-12T02:27:43Z,2017-09-12T03:01:00Z,"Ensembling's back for it's alpha release, evolutionary algorithms are doing our hyperparameter search now, we've handled a bunch of dependency updates, and a bunch of smaller performance tweaks. ",65155092
985,False,False,2017-07-19T16:15:28Z,2017-07-19T16:17:26Z,,65155092
986,False,False,2017-07-14T05:59:44Z,2017-07-14T06:09:29Z,"Using quantile regression, we can now return prediction intervals. 

Another minor change is adding in a column of absolute changes for feature_responses",65155092
987,False,False,2017-07-09T21:00:26Z,2017-07-09T21:04:01Z,LightGBM and sklearn's gbm now use warm_starting or iterative training to find the best number of trees,65155092
988,False,False,2017-06-13T03:19:16Z,2017-06-13T03:23:41Z,"Avoids double training deep learning models, changes how we sort and order features for analytics reporting, and adds a new `_all_small_categories` category to categorical ensembling.",65155092
989,False,False,2017-06-06T02:11:47Z,2017-06-06T02:14:39Z,Feature responses allows linear-model-like interpretations for non-linear models. ,65155092
990,False,False,2017-05-18T00:58:01Z,2017-05-18T01:01:31Z,"Avoids mutating input DF
Standardizes examples and tests to use `load_ml_model()`",65155092
991,False,False,2017-05-03T00:29:12Z,2017-05-03T00:33:10Z,Some bugfixes,65155092
992,False,False,2017-04-19T05:56:32Z,2017-04-19T06:00:47Z,"Feature learning and categorical ensembling are really cool features that each get us 2-5% accuracy gains!

For full info, check the docs. ",65155092
993,False,False,2017-04-04T01:22:20Z,2017-04-04T01:43:26Z,"Enough incremental improvements have added up that we're now ready to mark a 2.0 release! 

Part of the progress also means deprecating a few unused features that were adding unnecessary complexity and preventing us from implementing new features like ensembling properly. 

New changes for the 2.0 release:
- Refactored and cleaned up code. Ensembling should now be much easier to add in, and in a way that's fast enough to be used in production (getting predictions from 10 models should take less than 10x as long as getting predictions from 1 model)
- Deprecated compute_power
- Deprecated several methods for grid searching over transformation_pipeline hyperparameters (different methods for feature selection, whether or not to do feature scaling, etc.). We just directly made a decision to prioritize the final model hyperparameter search. 
- Deprecated the current implementation of ensembling. It was implemented in such a way that it was not quick enough to make predictions in prod, and thus, did not meet the primary use cases of this project. Part of removing it allows us to reimplement ensembling in a way that is prod-ready. 
- Deprecated X_test and y_test, except for working with calibrate_final_model.
- Added better documentation on features that were in silent alpha release previously. 
- Improved test coverage!

Major changes since the 1.0 release:
- Integrations for deep learning (using TensorFlow and Keras)
- Integration of Microsoft's LightGBM, which appears to be a possibly better version of XGBoost
- Quite a bit more user logging, warning, and input validation/input cleaning
- Quite a few edge case bug fixes and minor performance improvements
- Fully automated test suite with decent test coverage!
- Better documentation
- Support for pandas DataFrames- much more space efficient than lists of dictionaries",65155092
994,False,False,2017-03-15T00:39:10Z,2017-03-16T02:36:10Z,"This will be our final release before v2. 

Includes many recent changes- Deep Learning with Keras/TensorFlow, more efficient hyperparameter optimization, Microsoft's LightGBM, more advanced logging for scoring, and quite a few minor usability improvements (like improved logging when input is not as expected). ",65155092
995,False,False,2016-10-11T02:45:46Z,2016-10-11T02:59:41Z,"As of the 1.3 release, we now support taking in Pandas DataFrames, in addition to a list of dictionaries. 

This is much more memory efficient, allowing us to now train subpredictors in parallel. 

There's also better input validation and message logging to the users. 
",65155092
996,False,False,2020-02-19T07:09:24Z,2020-02-19T07:52:19Z,"# Release 1.4 - 2/19/2020

## Major Features

### Neural Architecture Search
* Support [C-DARTS](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/NAS/CDARTS.md) algorithm and add [the example](https://github.com/microsoft/nni/tree/v1.4/examples/nas/cdarts) using it
* Support a preliminary version of [ProxylessNAS](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/NAS/Proxylessnas.md) and the corresponding [example](https://github.com/microsoft/nni/tree/v1.4/examples/nas/proxylessnas)
* Add unit tests for the NAS framework

### Model Compression
* Support DataParallel for compressing models, and provide [an example](https://github.com/microsoft/nni/blob/v1.4/examples/model_compress/multi_gpu.py) of using DataParallel
* Support [model speedup](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/Compressor/ModelSpeedup.md) for compressed models, in Alpha version

### Training Service
* Support complete PAI configurations by allowing users to specify PAI config file path
* Add example config yaml files for the new PAI mode (i.e., paiK8S)
* Support deleting experiments using sshkey in remote mode (thanks external contributor @tyusr)

### WebUI
* WebUI refactor: adopt fabric framework

### Others
* Support running [NNI experiment at foreground](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/Tutorial/Nnictl.md#manage-an-experiment), i.e., `--foreground` argument in `nnictl create/resume/view`
* Support canceling the trials in UNKNOWN state
* Support large search space whose size could be up to 50mb (thanks external contributor @Sundrops)

## Documentation
* Improve [the index structure](https://nni.readthedocs.io/en/latest/) of NNI readthedocs
* Improve [documentation for NAS](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/NAS/NasGuide.md)
* Improve documentation for [the new PAI mode](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/TrainingService/PaiMode.md)
* Add QuickStart guidance for [NAS](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/NAS/QuickStart.md) and [model compression](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/Compressor/QuickStart.md)
* Improve documentation for [the supported EfficientNet](https://github.com/microsoft/nni/blob/v1.4/docs/en_US/TrialExample/EfficientNet.md)

## Bug Fixes
* Correctly support NaN in metric data, JSON compliant
* Fix the out-of-range bug of `randint` type in search space
* Fix the bug of wrong tensor device when exporting onnx model in model compression
* Fix incorrect handling of nnimanagerIP in the new PAI mode (i.e., paiK8S)",135673451
997,False,False,2019-12-31T05:30:54Z,2019-12-31T06:52:00Z,"# Release 1.3 - 12/30/2019

## Major Features

### Neural Architecture Search Algorithms Support
* [Single Path One Shot](https://github.com/microsoft/nni/tree/v1.3/examples/nas/spos/) algorithm and the example using it

### Model Compression Algorithms Support
* [Knowledge Distillation](https://github.com/microsoft/nni/blob/v1.3/docs/en_US/TrialExample/KDExample.md) algorithm and the example using itExample
* Pruners
    * [L2Filter Pruner](https://github.com/microsoft/nni/blob/v1.3/docs/en_US/Compressor/Pruner.md#3-l2filter-pruner)
    * [ActivationAPoZRankFilterPruner](https://github.com/microsoft/nni/blob/v1.3/docs/en_US/Compressor/Pruner.md#1-activationapozrankfilterpruner)
    * [ActivationMeanRankFilterPruner](https://github.com/microsoft/nni/blob/v1.3/docs/en_US/Compressor/Pruner.md#2-activationmeanrankfilterpruner)
* [BNN Quantizer](https://github.com/microsoft/nni/blob/v1.3/docs/en_US/Compressor/Quantizer.md#bnn-quantizer)
### Training Service
* NFS Support for PAI
    
    Instead of using HDFS as default storage, since OpenPAI v0.11, OpenPAI can have NFS or AzureBlob or other storage as default storage. In this release, NNI extended the support for this recent change made by OpenPAI, and could integrate with OpenPAI v0.11 or later version with various default storage.

* Kubeflow update adoption

    Adopted the Kubeflow 0.7's new supports for tf-operator.

## Engineering (code and build automation)
* Enforced [ESLint](https://eslint.org/) on static code analysis.

## Small changes & Bug Fixes
* correctly recognize builtin tuner and customized tuner
* logging in dispatcher base
* fix the bug where tuner/assessor's failure sometimes kills the experiment.
* Fix local system as remote machine [issue](https://github.com/microsoft/nni/issues/1852)
* de-duplicate trial configuration in smac tuner [ticket](https://github.com/microsoft/nni/issues/1364)",135673451
998,False,False,2019-12-02T07:58:11Z,2019-12-02T08:50:25Z,"# Release 1.2 - 12/2/2019

## Major Features
* [Feature Engineering](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/FeatureEngineering/Overview.md)
  - New feature engineering interface
  - Feature selection algorithms: [Gradient feature selector](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/FeatureEngineering/GradientFeatureSelector.md) & [GBDT selector](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/FeatureEngineering/GBDTSelector.md)
  - [Examples for feature engineering](https://github.com/microsoft/nni/tree/v1.2/examples/feature_engineering)
* Neural Architecture Search (NAS) on NNI
  - [New NAS interface](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/NAS/NasInterface.md)
  - NAS algorithms: [ENAS](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/NAS/Overview.md#enas), [DARTS](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/NAS/Overview.md#darts), [P-DARTS](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/NAS/Overview.md#p-darts) (in PyTorch)
  - NAS in classic mode (each trial runs independently)
* Model compression
  - [New model pruning algorithms](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/Compressor/Overview.md): lottery ticket pruning approach, L1Filter pruner, Slim pruner, FPGM pruner
  - [New model quantization algorithms](https://github.com/microsoft/nni/blob/v1.2/docs/en_US/Compressor/Overview.md): QAT quantizer, DoReFa quantizer
  - Support the API for exporting compressed model.
* Training Service
  - Support OpenPAI token authentication
* Examples:
  - [An example to automatically tune rocksdb configuration with NNI](https://github.com/microsoft/nni/tree/v1.2/examples/trials/systems/rocksdb-fillrandom).
  - [A new MNIST trial example supports tensorflow 2.0](https://github.com/microsoft/nni/tree/v1.2/examples/trials/mnist-tfv2).
* Engineering Improvements
  - For remote training service,  trial jobs require no GPU are now scheduled with round-robin policy instead of random.
  - Pylint rules added to check pull requests, new pull requests need to comply with these [pylint rules](https://github.com/microsoft/nni/blob/v1.2/pylintrc).
* Web Portal & User Experience
  - Support user to add customized trial.
  - User can zoom out/in in detail graphs, except Hyper-parameter.
* Documentation
  - Improved NNI API documentation with more API docstring.

## Bug fix
  - Fix the table sort issue when failed trials haven't metrics. -Issue #1764
  - Maintain selected status(Maximal/Minimal) when the page switched. -PR #1710
  - Make hyper-parameters graph's default metric yAxis more accurate. -PR #1736
  - Fix GPU script permission issue. -Issue #1665",135673451
999,False,False,2019-10-22T08:24:12Z,2019-10-23T03:13:05Z,"# Release 1.1 - 10/23/2019
 
## Major Features
 
* New tuner: [PPO Tuner](https://github.com/microsoft/nni/blob/v1.1/docs/en_US/Tuner/PPOTuner.md)
* [View stopped experiments](https://github.com/microsoft/nni/blob/v1.1/docs/en_US/Tutorial/Nnictl.md#view)
* Tuners can now use dedicated GPU resource (see `gpuIndices` in [tutorial](https://github.com/microsoft/nni/blob/v1.1/docs/en_US/Tutorial/ExperimentConfig.md) for details)
* Web UI improvements
  - Trials detail page can now list hyperparameters of each trial, as well as their start and end time (via ""add column"")
  - Viewing huge experiment is now less laggy
* More examples
  - [EfficientNet PyTorch example](https://github.com/ultmaster/EfficientNet-PyTorch)
  - [Cifar10 NAS example](https://github.com/microsoft/nni/blob/v1.1/examples/trials/nas_cifar10/README.md)
* [Model compression toolkit - Alpha release](https://github.com/microsoft/nni/blob/v1.1/docs/en_US/Compressor/Overview.md): We are glad to announce the alpha release for model compression toolkit on top of NNI, it's still in the experiment phase which might evolve based on usage feedback. We'd like to invite you to use, feedback and even contribute

## Fixed Bugs
 
* Multiphase job hangs when search space exhuasted (issue #1204)
* `nnictl` fails when log not available (issue #1548)",135673451
1000,False,False,2019-08-30T04:50:41Z,2019-09-02T09:38:54Z,"# Release 1.0 - 2/9/2019 

 ## Major Features 
 
* Tuners and Assessors 
    - Support Auto-Feature generator & selection      -Issue#877  -PR #1387 
         + Provide auto feature interface 
         + Tuner based on beam search 
         + [Add Pakdd example](./examples/trials/auto-feature-engineering/README.md) 
    - Add a parallel algorithm to improve the performance of TPE with large concurrency.    -PR #1052  
    - Support multiphase for hyperband    -PR #1257 
 
* Training Service 
     - Support private docker registry   -PR #755 

 * Engineering Improvements 
    - Python wrapper for rest api, support retrieve the values of the metrics in a programmatic way  PR #1318 
    - New python API : get_experiment_id(), get_trial_id()     -PR #1353   -Issue #1331 & -Issue#1368 
    - Optimized NAS Searchspace    -PR #1393 
         + Unify NAS search space with _type -- ""mutable_type""e 
         + Update random search tuner 
    - Set gpuNum as optional      -Issue #1365 
    - Remove outputDir and dataDir configuration in PAI mode       -Issue #1342 
    - When creating a trial in Kubeflow mode, codeDir will no longer be copied to logDir     -Issue #1224 

* Web Portal & User Experience 
    - Show the best metric curve during search progress in WebUI  -Issue #1218 
    - Show the current number of parameters list in multiphase experiment   -Issue1210  -PR #1348 
    - Add ""Intermediate count"" option in AddColumn.      -Issue #1210 
    - Support search parameters value in WebUI     -Issue #1208 
    - Enable automatic scaling of axes for metric value  in default metric graph   -Issue #1360 
    - Add a detailed documentation link to the nnictl command in the command prompt    -Issue #1260 
    - UX improvement for showing Error log   -Issue #1173 

* Documentation 
    - Update the docs structure      -Issue #1231 
    - [Multi phase document improvement](./docs/en_US/AdvancedFeature/MultiPhase.md)     -Issue #1233  -PR #1242 
         + Add configuration example 
    - [WebUI description improvement](./docs/en_US/Tutorial/WebUI.md)  -PR #1419  


## Bug fix 
* (Bug fix)Fix the broken links in 0.9 release  -Issue #1236 
* (Bug fix)Script for auto-complete   
* (Bug fix)Fix pipeline issue that it only check exit code of last command in a script.  -PR #1417 
* (Bug fix)quniform fors tuners      -Issue #1377 
* (Bug fix)'quniform' has different meaning beween GridSearch and other tuner.   -Issue #1335  
* (Bug fix)""nnictl experiment list"" give the status of a ""RUNNING"" experiment as ""INITIALIZED""   -PR #1388 
* (Bug fix)SMAC cannot be installed if nni is installed in dev mode    -Issue #1376  
* (Bug fix)The filter button of the intermediate result cannot be clicked   -Issue #1263  
* (Bug fix)API ""/api/v1/nni/trial-jobs/xxx"" doesn't show a trial's all parameters in multiphase experiment    -Issue #1258  
* (Bug fix)Succeeded trial doesn't have final result but webui show ×××(FINAL)   -Issue #1207  
* (Bug fix)IT for nnictl stop -Issue #1298 
* (Bug fix)fix security warning  
* (Bug fix)Hyper-parameter page broken   -Issue #1332  
* (Bug fix)Run flake8 tests to find Python syntax errors and undefined names -PR #1217 ",135673451
1001,False,False,2019-07-01T09:39:01Z,2019-07-01T11:21:48Z,"# Release 0.9 - 7/1/2019

## Major Features
* General NAS programming interface
    * Add `enas-mode`  and `oneshot-mode` for NAS interface: [PR #1201](https://github.com/microsoft/nni/pull/1201#issue-291094510)
* [Gaussian Process Tuner with Matern kernel](https://github.com/microsoft/nni/blob/master/docs/en_US/Tuner/GPTuner.md) 

* Multiphase experiment supports
    * Added new training service support for multiphase experiment: PAI mode supports multiphase experiment since v0.9.
    * Added multiphase capability for the following builtin tuners: 
        * TPE, Random Search, Anneal, Naïve Evolution, SMAC, Network Morphism, Metis Tuner.
    
    For details, please refer to [Write a tuner that leverages multi-phase](https://github.com/microsoft/nni/blob/master/docs/en_US/AdvancedFeature/MultiPhase.md#write-a-tuner-that-leverages-multi-phase)

* Web Portal
    * Enable trial comparation in Web Portal. For details, refer to [View trials status](https://github.com/microsoft/nni/blob/master/docs/en_US/Tutorial/WebUI.md#view-trials-status)
    * Allow users to adjust rendering interval of Web Portal. For details, refer to [View Summary Page](https://github.com/microsoft/nni/blob/master/docs/en_US/Tutorial/WebUI.md#view-summary-page)
    * show intermediate results more friendly. For details, refer to [View trials status](https://github.com/microsoft/nni/blob/master/docs/en_US/Tutorial/WebUI.md#view-trials-status)
* [Commandline Interface](https://github.com/microsoft/nni/blob/master/docs/en_US/Tutorial/Nnictl.md)
    * `nnictl experiment delete`: delete one or all experiments, it includes log, result, environment information and cache. It uses to delete useless experiment result, or save disk space.
    * `nnictl platform clean`: It uses to clean up disk on a target platform. The provided YAML file includes the information of target platform, and it follows the same schema as the NNI configuration file.
## Bug fix and other changes
* Tuner Installation Improvements: add [sklearn](https://scikit-learn.org/stable/) to nni dependencies.
* (Bug Fix) Failed to connect to PAI http code - [Issue #1076](https://github.com/microsoft/nni/issues/1076)
* (Bug Fix) Validate file name for PAI platform - [Issue #1164](https://github.com/microsoft/nni/issues/1164)
* (Bug Fix) Update GMM evaluation in Metis Tuner
* (Bug Fix) Negative time number rendering in Web Portal - [Issue #1182](https://github.com/microsoft/nni/issues/1182), [Issue #1185](https://github.com/microsoft/nni/issues/1185)
* (Bug Fix) Hyper-parameter not shown correctly in WebUI when there is only one hyper parameter - [Issue #1192](https://github.com/microsoft/nni/issues/1192)
",135673451
1002,False,False,2019-06-04T02:42:40Z,2019-06-05T02:13:48Z,"# Release 0.8 - 6/4/2019 

## Major Features 

* Support NNI on Windows for PAI/Remote mode

    * NNI running on windows for remote mode 

    * NNI running on windows for PAI mode 

* [Advanced features for using GPU](https://github.com/microsoft/nni/blob/v0.8/docs/en_US/ExperimentConfig.md#configuration-spec) 

   * Run multiple trial jobs on the same GPU for local and remote mode 

   * Run trial jobs on the GPU running non-NNI jobs 

* Kubeflow v1beta2 operator

   * Support Kubeflow TFJob/PyTorchJob v1beta2 

* [General NAS programming interface](https://github.com/microsoft/nni/blob/v0.8/docs/en_US/GeneralNasInterfaces.md) 

   * Provide NAS programming interface for users to easily express their neural architecture search space through NNI annotation 

   * Provide a new command `nnictl trial codegen` for debugging the NAS code 

   * Tutorial of NAS programming interface, example of NAS on mnist, customized random tuner for NAS 

* Support resume tuner/advisor's state for experiment resume

   * For experiment resume, tuner/advisor will be resumed by replaying finished trial data 

* Web Portal 

   * Improve the design of copying trial's parameters 

   * Support 'randint' type in hyper-parameter graph 

   * Use should ComponentUpdate to avoid unnecessary render 

## Bug fix and other changes 

* Bug fix that `nnictl update` has inconsistent command styles

* Support import data for SMAC tuner

* Bug fix that experiment state transition from ERROR back to RUNNING

* Fix bug of table entries

* Nested search space refinement

* Refine 'randint' type and support lower bound 

* [Comparison of different hyper-parameter tuning algorithm](https://github.com/microsoft/nni/blob/v0.8/docs/en_US/CommunitySharings/HpoComparision.md) 

* [Comparison of NAS algorithm](https://github.com/microsoft/nni/blob/v0.8/docs/en_US/CommunitySharings/NasComparision.md) 

* [NNI practice on Recommenders](https://github.com/microsoft/nni/blob/v0.8/docs/en_US/CommunitySharings/NniPracticeSharing/RecommendersSvd.md) ",135673451
1003,False,False,2019-04-29T02:49:00Z,2019-04-29T06:19:17Z,"# Release 0.7 - 4/29/2018

## Major Features
* [Support NNI on Windows](./docs/en_US/WindowsLocalMode.md)
    * NNI running on windows for local mode
* [New advisor: BOHB](./docs/en_US/bohbAdvisor.md)
    * Support a new advisor BOHB, which is a robust and efficient hyperparameter tuning algorithm, combines the advantages of Bayesian optimization and Hyperband
* [Support import and export experiment data through nnictl](./docs/en_US/NNICTLDOC.md#experiment)
    * Generate analysis results report after the experiment execution
    * Support import data to tuner and advisor for tuning
* [Designated gpu devices for NNI trial jobs](./docs/en_US/ExperimentConfig.md#localConfig)
    * Specify GPU devices for NNI trial jobs by gpuIndices configuration, if gpuIndices is set in experiment configuration file, only the specified GPU devices are used for NNI trial jobs.
* Web Portal enhancement
    * Decimal format of metrics other than default on the Web UI
    * Hints in WebUI about Multi-phase
    * Enable copy/paste for hyperparameters as python dict
    * Enable early stopped trials data for tuners.
* NNICTL provide better error message
    * nnictl provide more meaningful error message for yaml file format error

## Bug fix
* Unable to kill all python threads after nnictl stop in async dispatcher mode
* nnictl --version does not work with make dev-instal
* All trail jobs status stays on 'waiting' for long time on PAI platform",135673451
1004,False,False,2019-04-02T02:23:00Z,2019-04-02T10:09:15Z,"# Release 0.6 - 4/2/2019
## Major Features
* [Version checking](https://github.com/microsoft/nni/blob/master/docs/en_US/TrainingService/PaiMode.md#version-check)
	* check whether the version is consistent between nniManager and trialKeeper
* [Report final metrics for early stop job](https://github.com/Microsoft/nni/issues/776)
	* If includeIntermediateResults is true, the last intermediate result of the trial that is early stopped by assessor is sent to tuner as final result. The default value of includeIntermediateResults is false.
* [Separate Tuner/Assessor](https://github.com/Microsoft/nni/issues/841)
	* Adds two pipes to separate message receiving channels for tuner and assessor.
* Make log collection feature configurable
* Add intermediate result graph for all trials

## Bug fix
* [Add shmMB config key for PAI](https://github.com/Microsoft/nni/issues/842)
* Fix the bug that doesn't show any result if metrics is dict
* Fix the number calculation issue for float types in hyperband
* Fix a bug in the search space conversion in SMAC tuner
* Fix the WebUI issue when parsing experiment.json with illegal format
* Fix cold start issue in Metis Tuner",135673451
1005,False,False,2019-03-04T07:10:07Z,2019-03-04T09:41:43Z,"# Release 0.5.2.1 - 3/4/2019

* Add release note.
* Fix Metis tuner cold start issue.",135673451
1006,False,False,2019-02-28T09:54:55Z,2019-03-04T07:22:26Z,"# Release 0.5.2 - 3/4/2019
### Improvements
* Curve fitting assessor performance improvement.

### Documentation
* Chinese version document: https://nni.readthedocs.io/zh/latest/
* Debuggability/serviceability document: https://nni.readthedocs.io/en/latest/Tutorial/HowToDebug.html
* Tuner assessor reference: https://nni.readthedocs.io/en/latest/sdk_reference.html#tuner

### Bug Fixes and Other Changes
* Fix a race condition bug that does not store trial job cancel status correctly.
* Fix search space parsing error when using SMAC tuner.
* Fix cifar10 example broken pipe issue.
* Add unit test cases for nnimanager and local training service.
* Add integration test azure pipelines for remote machine, PAI and kubeflow training services.
* Support Pylon in PAI webhdfs client.",135673451
1007,False,False,2019-01-31T09:38:18Z,2019-01-31T09:45:48Z,"# Release 0.5.1 - 1/31/2018
## Improvements
* Making [log directory](https://github.com/Microsoft/nni/blob/v0.5.1/docs/ExperimentConfig.md) configurable
* Support [different levels of logs](https://github.com/Microsoft/nni/blob/v0.5.1/docs/ExperimentConfig.md), making it easier for debugging 

## Documentation
* Reorganized documentation & New Homepage Released: https://nni.readthedocs.io/en/latest/
* Chinese users are able to learn NNI with the translated Chinese doc: 
https://github.com/microsoft/nni/blob/master/README_zh_CN.md
_Dear Contributors_: _We'd love to provide more language translations, contribute to NNI with more languages_ =)

## Bug Fixes and Other Changes
* Fix the bug of installation in python virtualenv, and refactor the installation logic
* Fix the bug of HDFS access failure on PAI mode after PAI is upgraded. 
* Fix the bug that sometimes in-place flushed stdout makes experiment crash
",135673451
1008,False,False,2019-01-14T08:05:34Z,2019-01-15T02:39:09Z,"# Release 0.5.0 - 01/15/2019
## New tuner and assessor supports
  * Support [Metis tuner](docs/HowToChooseTuner.md#MetisTuner) as a new NNI tuner. Metis algorithm has been proofed to be well performed for **online** hyper-parameter tuning.
  * Support [ENAS customized tuner](https://github.com/countif/enas_nni), a tuner contributed by github community user, is an algorithm for neural network search, it could learn neural network architecture via reinforcement learning and serve a better performance than NAS.
  * Support [Curve fitting assessor](docs/HowToChooseTuner.md#Curvefitting) for early stop policy using learning curve extrapolation.
  * Advanced Support of [Weight Sharing](docs/AdvancedNAS.md): Enable weight sharing for NAS tuners, currently through NFS.

## Training Service Enhancement
* [FrameworkController Training service](docs/FrameworkControllerMode.md): Support run experiments using frameworkcontroller on kubernetes
   * FrameworkController is a Controller on kubernetes that is general enough to run (distributed) jobs with various machine learning frameworks, such as tensorflow, pytorch, MXNet.
   * NNI provides unified and simple specification for job definition.
   * MNIST example for how to use FrameworkController.

## User Experience improvements
  * A better trial logging support for NNI experiments in PAI, Kubeflow and FrameworkController mode:
      * An improved logging architecture to send stdout/stderr of trials to NNI manager via Http post. NNI manager will store trial's stdout/stderr messages in local log file.
      * Show the link for trial log file on WebUI.
  * Support to show final result's all key-value pairs.",135673451
1009,False,False,2018-12-20T08:05:43Z,2018-12-20T08:30:25Z,"## Major Features
### New tuner support
  * Support [network morphism](https://github.com/Microsoft/nni/tree/master/src/sdk/pynni/nni/networkmorphism_tuner)

### Training Service Improvements
  * Migrate [Kubeflow training service](https://github.com/microsoft/nni/blob/master/docs/en_US/TrainingService/KubeflowMode.md)'s dependency from kubectl CLI to [Kubernetes API](https://kubernetes.io/docs/concepts/overview/kubernetes-api/) client
  * [Pytorch-operator](https://github.com/kubeflow/pytorch-operator) support for Kubeflow training service.
  * Improvement on local code files uploading to OpenPAI HDFS.

### WebUI improvements
  * Enable modify concurrency number during experiment.
  * Add feedback link to NNI github 'create issue' page
  * Enable customize top 10 trials regarding to metric numbers (largest or smallest)
  * Enable download logs for dispatcher & nnimanager 
  * Enable automatic scaling of axes for metric number

## New example
  * [FashionMnist](https://github.com/Microsoft/nni/tree/master/examples/trials/network_morphism), work together with network morphism tuner.
  * [Distributed MNIST example](https://github.com/Microsoft/nni/tree/master/examples/trials/mnist-distributed-pytorch) written in PyTorch. 

## Others
  * Show version information both in nnictl and WebUI. You can run **nnictl -v** to show your current installed NNI version.
  * Bug Fix
     • fix the bug that WebUI doesn't show latest trial job status, which is caused by OpenPAI token expiration.
     • Update annotation to support displaying real choice in searchspace
",135673451
1010,False,False,2018-12-05T08:58:48Z,2018-12-05T10:18:14Z,"## Major Features
### New Platform Support
  * Support launch NNI experiment on MAC

### New Tuner Support
  * [Grid search tuner](https://github.com/Microsoft/nni/blob/master/src/sdk/pynni/nni/gridsearch_tuner/gridsearch_tuner.py) 
  * [Hyperband tuner](https://github.com/Microsoft/nni/tree/master/src/sdk/pynni/nni/hyperband_advisor)

### New Training Service Support
  * [Kubeflow Training service](https://github.com/microsoft/nni/blob/master/docs/en_US/TrainingService/KubeflowMode.md)
    * Support tf-operator
    * [Distributed trial example](https://github.com/Microsoft/nni/blob/master/examples/trials/mnist-distributed/dist_mnist.py) on Kubeflow

### OpenPAI Training Service Improvements
    *  Support NNI Manager IP configuration(nniManagerIp) in PAI cluster config file, to fix the issue that user’s machine has no eth0 device 
    *  File number in codeDir is capped to 1000 now, to avoid user mistakenly fill root dir for codeDir
    *  Don’t print useless ‘metrics is empty’ log int PAI job’s stdout. Only print useful message once new metrics are recorded, to reduce confusion when user checks PAI trial’s output for debugging purpose
    *  Add timestamp at the beginning of each log entry in trial keeper.
    *  Show trial's hdfsLogPath

### WebUI Improvements and updates
    *  Download experiment parameters
    *  UI support for hyperband tuner
    *  Show experiment error message 
    *  Show line numbers in search space and trial profile
    *  Support search a specific trial by trial number
    *  Remove tensorboard button 

## Others
  * Asynchronous dispatcher
  * Docker file update: added pytorch library 
  * Refactor 'nnictl stop' process, send SIGTERM to nni manager process, rather than calling stop Rest API
",135673451
1011,False,False,2018-11-08T05:52:48Z,2018-11-08T05:53:56Z,"# Release 0.3.4 - 11/8/2018

* Updated several examples
* Fix the bug that Medianstop assessor does not work",135673451
1012,False,False,2018-11-02T14:01:15Z,2018-11-06T11:13:30Z,"# Release 0.3.2 - 11/2/2018

## Major Features
* Support running multiple experiments simultaneously. You can run multiple experiments by specifying a unique port for each experiment:

    ```nnictl create --port 8081 --config <config file path>```

    You can still run the first experiment without '--port' parameter:

    ```nnictl create --config <config file path>```
* A builtin Batch Tuner which iterates all parameter combination, can be used to submit batch trial jobs.
* nni.report_final_result(result) API supports more data types for result parameter, it can be of following types:
    * int
    * float
    * A python dict containing 'default' key, the value of 'default' key should be of type int or float. The dict can contain any other key value pairs.
* Continuous Integration
    * Switched to Azure pipelines
* Others
    * New nni.get_sequence_id() API. Each trial job is allocated a unique sequence number, which can be retrieved by nni.get_sequence_id() API.
    * Download experiment result from WebUI
    * Add trial examples using sklearn and NNI together
    * Support updating max trial number
    * Kaggle competition TGS Salt code as an example
    * NNI Docker image:

      ```docker pull msranni/nni:latest```

## Breaking changes
*   <span style=""color:red"">API nn.get_parameters() is renamed to nni.get_next_parameter(), this is a broken change, all examples of prior releases can not run on v0.3.2, please clone nni repo to get new examples.</span>

    ```git clone -b v0.3.2 https://github.com/Microsoft/nni.git```

## Know issues
[Known Issues in release 0.3.2](https://github.com/Microsoft/nni/labels/nni030knownissues).
",135673451
1013,False,False,2018-11-05T09:51:43Z,2018-11-05T09:44:36Z,"# Release 0.3.3 - 11/5/2018

* Fix tuner path in ga_squad example
* Fix the bug induced by changed nni APIs in mnist_smarparam example
* Fix bug in command `nnictl update ...`",135673451
1014,False,False,2018-09-29T12:25:03Z,2018-09-29T12:28:16Z,"# Release 0.2.0 - 9/29/2018
## Major Features
   * Support for [OpenPAI](https://github.com/Microsoft/pai) (aka pai) Training Service 
      * Support training services on pai mode. NNI trials will be scheduled to run on OpenPAI cluster
      * NNI trial's output (including logs and model file) will be copied to OpenPAI HDFS for further debugging and checking
   * Support [SMAC](https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf) tuner
      * [SMAC](https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf) is based on Sequential Model-Based Optimization (SMBO). It adapts the most prominent previously used model class (Gaussian stochastic process models) and introduces the model class of random forests to SMBO to handle categorical parameters. The SMAC supported by NNI is a wrapper on [SMAC3](https://github.com/automl/SMAC3)
   * Support NNI installation on [conda](https://conda.io/docs/index.html) and python virtual environment
   * Others
      * Update ga squad example and related documentation
      * WebUI UX small enhancement and bug fix

## Known Issues
[Known Issues in release 0.2.0](https://github.com/Microsoft/nni/labels/nni020knownissues).",135673451
1015,False,False,2018-09-10T09:23:56Z,2018-09-10T09:45:22Z,"# Release 0.1.0 - 9/10/2018 (initial release)

Initial release of Neural Network Intelligence (NNI).

## Major Features
   * Installation and Deployment
      * Support pip install and source codes install
      * Support training services on local mode(including Multi-GPU mode) as well as multi-machines mode
   * Tuners, Accessors and Trial
      * Support AutoML algorithms including:  hyperopt_tpe, hyperopt_annealing, hyperopt_random, and evolution_tuner
      * Support assessor(early stop) algorithms including: medianstop algorithm
      * Provide Python API for user defined tuners and accessors
      * Provide Python API for user to wrap trial code as NNI deployable codes
   * Experiments
      * Provide a command line toolkit 'nnictl' for experiments management
      * Provide a web UI for viewing experiments details and managing experiments
   * Continuous Integration
      * Support CI by providing out-of-box integration with [travis-ci](https://github.com/travis-ci) on ubuntu    
   * Others
      * Support simple GPU job scheduling 

## Known Issues
[Known Issues in release 0.1.0](https://github.com/Microsoft/nni/labels/nni010knownissues).
      
   ",135673451
1016,False,False,2020-01-10T06:12:50Z,2020-01-15T05:30:42Z,"# Release notes

This is the 0.9 release of TensorFlow Probability. It is tested and stable against TensorFlow version 2.1.0.

NOTE: The 0.9 releases of TensorFlow Probability will be the last to support Python 2.  Future versions of TensorFlow Probability will require Python 3.5 or later.

## Change notes

- Distributions
  - Add Pixel CNN++ distribution.
  - Breaking change: Remove deprecated behavior of `Poisson.rate` and `Poisson.log_rate`.
  - Breaking change: Remove deprecated behavior of `logits`, `probs` properties.
  - Add `_default_event_space_bijector` to distributions.
  - Add validation that samples are within the support of the distribution.
  - Support positional and keyword args to `JointDistribution.prob` and `JointDistribution.log_prob`.
  - Support `OrderedDict` dtype in `JointDistributionNamed`.
  - `tfd.BatchReshape` is tape-safe
  - More accurate survival function and CDF for the generalized Pareto distribution.
  - Added Plackett-Luce distribution over permutations.
  - Fix long-standing bug with `cdf`, `survival_function`, and `quantile` for `TransformedDistribution`s having decreasing bijectors.
  - Export the DoubleMaxwell distribution.
  - Add method for analytic Bayesian linear regression with LinearOperators.

- Bijectors
  - Breaking change: Scalar bijectors must implement `_is_increasing` if using `cdf`/`survival_function`/`quantile` on `TransformedDistribution`. This supports resolution of a long-standing bug, e.g. `tfb.Scale(scale=-1.)(tfd.HalfNormal(0,1)).cdf` was incorrect.
  - Deprecate tfb.masked_autoregressive_default_template.
  - Fixed inverse numerical stability bug in `tfb.Softfloor`
  - Tape-safe Reshape bijector.

- MCMC
  - Optimize tfp.mcmc.ReplicaExchangeMonteCarlo by replacing TF control flow and
  - ReplicaExchangeMC now can trace exchange proposals/acceptances.
  - Correct implementation of log_accept_ratio in NUTS
  - Return non-cumulated leapfrogs_taken in nuts kernel_result.
  - Make unrolled NUTS reproducible.
  - Bug fix of Generalized U-turn in NUTS.
  - Reduce NUTS test flakiness.
  - Fix convergence test for NUTS.
  - Switch back to original U turn criteria in Hoffman & Gelman 2014.
  - Make autobatched NUTS reproducible.

- STS
  - Update example ""Structural Time Series Modeling Case Studies"" to TF2.0 API.
  - Add fast path for sampling STS LocalLevel models.
  - Support posterior sampling in linear Gaussian state space models.
  - Add a fast path for Kalman smoothing with scalar latents.
  - Add option to disallow drift in STS Seasonal models.

- Breaking change: Removed a number of functions, methods, and classes that were deprecated in TensorFlow Probability 0.8.0 or earlier.
  - Remove deprecated `trainable_distributions_lib`.
  - Remove deprecated property Dirichlet.total_concentration.
  - Remove deprecated `tfb.AutoregressiveLayer` -- use `tfb.AutoregressiveNetwork`.
  - Remove deprecated `tfp.distributions.*` methods.
  - Remove deprecated `tfp.distributions.moving_mean_variance`.
  - Remove two deprecated `tfp.vi` functions.
  - Remove deprecated `tfp.distributions.SeedStream` -- use `tfp.util.SeedStream`.
  - Remove deprecated properties of `tfd.Categorical`.

- Other
  - Add `make_rank_polymorphic` utility, which lifts a callable to a vectorized callable.
  - Dormand-Prince solver supports nested structures. Implemented adjoint sensitivity method for Dormand-Prince solver gradients.
  - Run Travis tests against latest tf-estimator-nightly.
  - Supporting gast 0.3 +
  - Add `tfp.vi.build_factored_surrogate_posterior` utility for automatic black-box variational inference.


## Huge thanks to all the contributors to this release!

  -  Aditya Grover 
  -  Alexey Radul 
  -  Anudhyan Boral 
  -  Arthur Lui 
  -  Billy Lamberta 
  -  Brian Patton 
  -  Christopher Suter 
  -  Colemak 
  -  Dan Moldovan 
  -  Dave Moore 
  -  Dmitrii Kochkov 
  -  Edward Loper 
  -  Emily Fertig 
  -  Ian Langmore 
  -  Jacob Burnim 
  -  Joshua V. Dillon 
  -  Junpeng Lao 
  -  Katherine Wu 
  -  Kibeom Kim 
  -  Kristian Hartikainen 
  -  Mark Daoust 
  -  Pavel Sountsov 
  -  Peter Hawkins 
  -  refraction-ray 
  -  RJ Skerry-Ryan 
  -  Sanket Kamthe 
  -  Sergei Lebedev 
  -  Sharad Vikram 
  -  Srinivas Vasudevan 
  -  Yanhua Sun 
  -  Yash Katariya 
  -  Zachary Nado 
",108053674
1017,False,False,2019-10-01T13:07:11Z,2019-10-01T15:39:29Z,"# Release notes

This is the 0.8 release of TensorFlow Probability. It is tested and stable against TensorFlow version 2.0.0 and 1.15.0rc1.


## Change notes

  - GPU-friendly ""unrolled"" NUTS: [`tfp.mcmc.NoUTurnSampler`](https://github.com/tensorflow/probability/blob/master/discussion/technical_note_on_unrolled_nuts.md)
    - Open-source the unrolled implementation of the No U-Turn Sampler.
    - Switch back to original U turn criteria in Hoffman & Gelman 2014.
    - Bug fix in Unrolled NUTS to make sure it does not lose shape for event_shape=1.
    - Bug fix of U turn check in Unrolled NUTS at the tree extension.
    - Refactor U turn check in Unrolled NUTS.
    - Fix dynamic shape bug in Unrolled NUTS.
    - Move NUTS unrolled into mcmc, with additional clean up.
    - Make sure the unrolled NUTS sampler handle scalar target_log_probs correctly.
    - Change implementation of check U turn to using a tf.while_loop in unrolled NUTS.
    - Implement multinomial sampling across tree (instead of Slice sampling) in unrolled NUTS.
    - Expose additional diagnostics in `previous_kernel_results` in unrolled NUTS so that it works with `*_step_size_adaptation`.

  - MCMC
    - Modify the shape handling in DualAveragingStepSizeAdaptation so that it works with non-scalar event_shape.
    - support structured samples in `tfp.monte_carlo.expectation`.
    - Minor fix for docstring example in leapfrog_integrator

  - VI
    - Add utilities for fitting variational distributions.
    - Improve Csiszar divergence support for joint variational distributions.
    - ensure that joint distributions are correctly recognized as reparameterizable by `monte_carlo_csiszar_f_divergence`.
    - Rename `monte_carlo_csiszar_f_divergence` to `monte_carlo_variational_loss`.
    - Refactor tfp.vi.csiszar_vimco_helper to expose useful leave-one-out statistical tools.

  - Distributions
    - Added `tfp.distributions.GeneralizedPareto`
    - Multinomial and DirichletMultinomial samplers are now reproducible.
    - HMM samples are now reproducible.
    - Cleaning up unneeded conversion to tensor in quantile().
    - Added support for dynamic `num_steps` in `HiddenMarkovModel`
    - Added implementation of quantile() for exponential distributions.
    - Fix entropy of Categorical distribution when logits contains -inf.
    - Annotate float-valued Deterministic distributions as reparameterized.
    - Establish patterns which ensure that TFP objects are ""GradientTape Safe.""
    - ""GradientTape-safe"" distributions: FiniteDiscrete, VonMises, Binomial, Dirichlet, Multinomial, DirichletMultinomial, Categorical, Deterministic
    - Add `tfp.util.DeferredTensor` to delay Tensor operations on `tf.Variable`s (also works for `tf.Tensor`s).
    - Add `probs_parameter`, `logits_parameter` member functions to Categorical-like distributions. In the future users should use these new functions rather than `probs`/`logits` properties because the properties might be `None` if that's how the distribution was parameterized.

  - Bijectors
    - Add `log_scale` parameter to AffineScalar bijector.
    - Added `tfp.bijectors.RationalQuadraticSpline`.
    - Add SoftFloor bijector. (Note: Known inverse bug WIP.)
    - Allow using an arbitrary bijector in RealNVP for the coupling.
    - Allow using an arbitrary bijector in MaskedAutoregressiveFlow for the coupling.

  - Experimental auto-batching system: [`tfp.experimental.auto_batching`](https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/experimental/auto_batching/README.md)
    - Open-source the program-counter-based auto-batching system.
    - Added tfp.experimental.auto_batching, an experimental system to recover batch parallelism across recursive function invocations.
    - Autobatched NUTS supports batching across consecutive trajectories.
    - Add support for field references to autobatching.
    - Increase the amount of Python syntax that ""just works"" in autobatched functions.
    - pop-push fusion optimization in the autobatching system (also recently did tail-call optimization but forgot to add a relnote).
    - Open-source the auto-batched implementation of the No U-Turn Sampler.

  - STS
    - Support TF2/Eager-mode fitting of STS models, and deprecate `build_factored_variational_loss`.
    - Use dual averaging step size adaptation for STS HMC fitting.
    - Add support for imputing missing values in structural time series models.
    - Standardize parameter scales during STS inference.

  - Layers
    - Add WeightNorm layer wrapper.
    - Fix gradients flowing through variables in the old style variational layers.
    - `tf.keras.model.save_model` and `model.save` now defaults to saving a TensorFlow SavedModel.

  - Stats/Math
    - Add calibration metrics to tfp.stats.
    - Add output_gradients argument to value_and_gradient.
    - Add Geyer initial positive sequence truncation criterion to tfp.mcmc.effective_sample_size.
    - Resolve shape inconsistencies in PSDKernels API.
    - Support dynamic-shaped results in `tfp.math.minimize`.
    - ODE: Implement the Adjoint Method for gradients with respect to the initial state.


## Huge thanks to all the contributors to this release!

  -  Alexey Radul 
  -  Anudhyan Boral 
  -  Arthur Lui 
  -  Brian Patton 
  -  Christopher Suter 
  -  Colin Carroll 
  -  Dan Moldovan 
  -  Dave Moore 
  -  Edward Loper 
  -  Emily Fertig 
  -  Gaurav Jain 
  -  Ian Langmore 
  -  Igor Ganichev 
  -  Jacob Burnim 
  -  Jeff Pollock 
  -  Joshua V. Dillon 
  -  Junpeng Lao 
  -  Katherine Wu 
  -  Mark Daoust 
  -  Matthieu Coquet 
  -  Parsiad Azimzadeh 
  -  Pavel Sountsov 
  -  Pavithra Vijay 
  -  PJ Trainor 
  -  prabhu prakash kagitha 
  -  prakashkagitha 
  -  Reed Wanderman-Milne 
  -  refraction-ray 
  -  Rif A. Saurous 
  -  RJ Skerry-Ryan 
  -  Saurabh Saxena 
  -  Sharad Vikram 
  -  Sigrid Keydana 
  -  skeydan 
  -  Srinivas Vasudevan 
  -  Yash Katariya 
  -  Zachary Nado 


",108053674
1018,False,True,2019-08-29T18:31:44Z,2019-08-30T04:27:08Z,"This is the RC0 release candidate of the TensorFlow Probability 0.8 release.

It is tested against TensorFlow 2.0.0-rc0",108053674
1019,False,False,2019-06-19T21:13:07Z,2019-06-20T18:10:12Z,"# Release notes

This is the 0.7 release of TensorFlow Probability. It is tested and stable against TensorFlow version 1.14.0.

## Change notes

  - Internal optimizations to HMC leapfrog integrator.
  - Add FeatureTransformed, FeatureScaled, and KumaraswamyTransformed PSD kernels
  - Added tfp.debugging.benchmarking.benchmark_tf_function.
  - Added optional masking of observations for `hidden_markov_model` methods `posterior_marginals` and `posterior_mode`.
  - Fixed evaluation order of distributions within `JointDistributionNamed`
  - Rename tfb.AutoregressiveLayer to tfb.AutoregressiveNetwork.
  - Support kernel and bias constraints/regularizers/initializers in tfb.AutoregressiveLayer.
  - Created Backward Difference Formula (BDF) solver for stiff ODEs.
  - Update Cumsum bijector.
  - Add distribution layer for masked autoregressive flow in Keras.
  - Shorten `repr`, `str` Distribution strings by using `""?""` instead of `""<unknown>""` to represent `None`.
  - Implement FiniteDiscrete distribution
  - Add Cumsum bijector.
  - Make Seasonal STS more flexible to handle none constant num_steps_per_season for each season.
  - In tfb.BatchNormalization, use keras layer over compat.v1 layer.
  - Forward kwargs in MaskedAutoregressiveFlow.
  - Added tfp.math.pivoted_cholesky for low rank preconditioning.
  - Add `tfp.distributions.JointDistributionCoroutine` for specifying simple directed graphical models via Python generators.
  - Complete the example notebook demonstrating multilevel modeling using TFP.
  - Remove default `None` initializations for Beta and LogNormal parameters.
  - Bug fix in __init__ method of Rational quadratic kernel
  - Add Binomial.sample method.
  - Add SparseLinearRegression structural time series component.
  - Remove TFP support of KL Divergence calculation of tf.compat.v1.distributions which have been deprecated for 6 months.
  - Added `tfp.math.cholesky_concat` (adds columns to a cholesky decomposition)
  - Introduce SchurComplement PSD Kernel
  - Add EllipticalSliceSampler as an experimental MCMC kernel.
  - Remove intercepting/reuse of variables created within DistributionLambda.
  - Support missing observations in structural time series models.
  - Add Keras layer for masked autoregressive flows.
  - Add code block to show recommended style of using JointDistribution.
  - Added example notebook demonstrating multilevel modeling.
  - Correctly decorate the training block in the VI part of the JointDistribution example notebook.
  - Add `tfp.distributions.Sample` for specifying plates in tfd.JointDistribution*.
  - Enable save/load of Keras models with DistributionLambda layers.
  - Add example notebook to show how to use joint distribution sequential for small-median Bayesian graphical model.
  - Add NaN propagation to tfp.stats.percentile.
  - Add `tfp.distributions.JointDistributionSequential` for specifying simple directed graphical models.
  - Enable save/load of models with IndependentX or MixtureX layers.
  - Extend monte_carlo_csiszar_f_divergence so it also work with JointDistribution.
  - Fix typo in `value_and_gradient` docstring.
  - Add `SimpleStepSizeAdaptation`, deprecate `step_size_adaptation_fn`.
  - batch_interp_regular_nd_grid added to tfp.math
  - Adds IteratedSigmoidCentered bijector to unconstrain unit simplex.
  - Add option to constrain seasonal effects to zero-sum in STS models, and enable by default.
  - Add two-sample multivariate equality in distribution.
  - Fix broadcasting errors when forecasting STS models with batch shape.
  - Adds batch slicing support to most distributions in tfp.distributions.
  - Add tfp.layers.VariationalGaussianProcess.
  - Added `posterior_mode` to `HiddenMarkovModel`
  - Add VariationalGaussianProcess distribution.
  - Adds slicing of distributions batch axes as `dist[..., :2, tf.newaxis, 3]`
  - Add tfp.layers.VariableLayer for making a Keras model which ignores inputs.
  - `tfp.math.matrix_rank`.
  - Add KL divergence between two blockwise distributions.
  - `tf.function` decorate `tfp.bijectors`.
  - Add `Blockwise` distribution for concatenating different distribution families.
  - Add and begin using a utility for varying random seeds in tests when desired.
  - Add two-sample calibrated statistical test for equality of CDFs, incl. support for duplicate samples.
  - Deprecating obsolete `moving_mean_variance`.  Use `assign_moving_mean_variance` and manage the variables explicitly.
  - Migrate Variational SGD Optimizer to TF 2.0
  - Migrate SGLD Optimizer to TF 2.0
  - TF2 migration
  - Make all test in MCMC TF2 compatible.
  - Expose HMC parameters via kernel results.
  - Implement a new version of sample_chain with optional tracing.
  - Make MCMC diagnostic tests Eager/TF2 compatible.
  - Implement Categorical to Discrete Values bijector, which maps integer x (0<=x<K) to values[x], where values is a predefined 1D tensor with size K.
  - Run dense, conv variational layer tests in eager mode.
  - Add Empirical distribution to Edward2 (already exists as a TFP distribution).
  - Ensure Gumbel distribution does not produce `inf` samples.
  - Hid tensor shapes from operators in HMM tests
  - Added `Empirical` distribution
  - Add the `Blockwise` bijector.
  - Add `MixtureNormal` and `MixtureLogistic` distribution layers.
  - Experimental support for implicit reparameterization gradients in MixtureSameFamily
  - Fix parameter broadcasting in `DirichletMultinomial`.
  - Add `tfp.math.clip_by_value_preserve_gradient`.
  - Rename InverseGamma `rate` parameter to `scale`, to match its semantics.
  - Added option 'input_output_cholesky' to LKJ distribution.
  - Add a semi-local linear trend STS model component.
  - Added Proximal Hessian Sparse Optimizer (a variant of Newton-Raphson).
  - find_bins(x, edges, ...) added to tfp.stats.
  - Disable explicit caching in masked_autoregressive in eager mode.
  - Add a local level STS model component.
  - Docfix: Fix constraint on valid range of reinterpreted_batch_dims for Independent.

## Huge thanks to all the contributors to this release!

  -  Alexey Radul 
  -  Anudhyan Boral 
  -  axch 
  -  Brian Patton 
  -  cclauss 
  -  Chikanaga Tomoyuki 
  -  Christopher Suter 
  -  Clive Chan 
  -  Dave Moore 
  -  Gaurav Jain 
  -  harrismirza 
  -  Harris Mirza 
  -  Ian Langmore 
  -  Jacob Burnim 
  -  Janosh Riebesell 
  -  Jeff Pollock 
  -  Jiri Simsa 
  -  joeyhaohao 
  -  johndebugger 
  -  Joshua V. Dillon 
  -  Juan A. Navarro P?rez 
  -  Junpeng Lao 
  -  Matej Rizman 
  -  Matthew O'Kelly 
  -  MG92 
  -  Nicola De Cao 
  -  Parsiad Azimzadeh 
  -  Pavel Sountsov 
  -  Philip Pham 
  -  PJ Trainor 
  -  Rif A. Saurous 
  -  Sergei Lebedev 
  -  Sigrid Keydana 
  -  Sophia Gu 
  -  Srinivas Vasudevan 
  -  ykkawana ",108053674
1020,False,True,2019-05-30T01:13:18Z,2019-05-30T01:24:30Z,"This is the 0.7.0-rc0 release of TensorFlow Probability. It is
tested and stable against TensorFlow version 1.14-rc0 and 2.0.0-alpha",108053674
1021,False,False,2019-02-26T18:41:20Z,2019-02-27T01:54:50Z,"# Release notes

This is the 0.6 release of TensorFlow Probability. It is
tested and stable against TensorFlow version 1.13.1.

## Change notes

  - Adds tfp.positive_semidefinite_kernels.RationalQuadratic
  - Support float64 in tfpl.MultivariateNormalTriL.
  - Add IndependentLogistic and IndependentPoisson distribution layers.
  - Add `make_value_setter` interceptor to set values of Edward2 random variables.
  - Implementation of Kalman Smoother, as a member function of LinearGaussianStateSpaceModel.
  - Bijector caching is enabled only in one direction when executing in eager mode. May cause some performance regression in eager mode if repeatedly computing `forward(x)` or `inverse(y)` with the same `x` or `y` value.
  - Handle rank-0/empty event_shape in tfpl.Independent{Bernoulli,Normal}.
  - Run additional tests in eager mode.
  - quantiles(x, n, ...) added to tfp.stats.
  - Makes tensorflow_probability compatible with Tensorflow 2.0 TensorShape indexing.
  - Use scipy.special functions when testing KL divergence for Chi, Chi2.
  - Add methods to create forecasts from STS models.
  - Add a MixtureSameFamily distribution layer.
  - Add Chi distribution.
  - Fix doc typo `tfp.Distribution` -> `tfd.Distribution`.
  - Add Gumbel-Gumbel KL divergence.
  - Add HalfNormal-HalfNormal KL divergence.
  - Add Chi2-Chi2 KL divergence unit tests.
  - Add Exponential-Exponential KL divergence unit tests.
  - Add sampling test for Normal-Normal KL divergence.
  - Add an IndependentNormal distribution layer.
  - Added `posterior_marginals` to `HiddenMarkovModel`
  - Add Pareto-Pareto KL divergence.
  - Add LinearRegression component for structural time series models.
  - Add dataset ops to the graph (or create kernels in Eager execution) during the python Dataset object creation instead doing it during Iterator creation time.
  - Text messages HMC benchmark.
  - Add example notebook encoding a switching Poisson process as an HMM for multiple changepoint detection.
  - Require `num_adaptation_steps` argument to `make_simple_step_size_update_policy`.
  - s/eight_hmc_schools/eight_schools_hmc/ in printed benchmark string.
  - Add `tfp.layers.DistributionLambda` to enable plumbing `tfd.Distribution` instances through Keras models.
  - Adding tfp.math.batch_interp_regular_1d_grid.
  - Update description of fill_triangular to include an in-depth example.
  - Enable bijector/distribution composition, eg, `tfb.Exp(tfd.Normal(0,1))`.
  - linear and midpoint interpolation added to tfp.stats.percentile.
  - Make distributions include only the bijectors they use.
  - tfp.math.interp_regular_1d_grid added
  - tfp.stats.correlation added (Pearson correlation).
  - Update list of edward2 RVs to include recently added Distributions.
  - Density of continuous Uniform distribution includes the upper endpoint.
  - Add support for batched inputs in tfp.glm.fit_sparse.
  -  interp_regular_1d_grid added to tfp.math.
  - Added HiddenMarkovModel distribution.
  - Add Student's T Process.
  - Optimize LinearGaussianStateSpaceModel by avoiding matrix ops when the observations are statically known to be scalar.
  - stddev, cholesky added to tfp.stats.
  - Add methods to fit structual time series models to data with variational inference and HMC.
  - Add Expm1 bijector (Y = Exp(X) - 1).
  -  New stats namespace. covariance and variance added to tfp.stats
  - Make all available MCMC kernels compatible with TransformedTransitionKernel.

## Huge thanks to all the contributors to this release!

  -  Adam Wood
  -  Alexey Radul
  -  Anudhyan Boral
  -  Ashish Saxena
  -  Billy Lamberta
  -  Brian Patton
  -  Christopher Suter
  -  Cyril Chimisov
  -  Dave Moore
  -  Eugene Zhulenev
  -  Griffin Tabor
  -  Ian Langmore
  -  Jacob Burnim
  -  Jakub Arnold
  -  Jiahao Yao
  -  Jihun
  -  Jiming Ye
  -  Joshua V. Dillon
  -  Juan A. Navarro Pérez
  -  Julius Kunze
  -  Julius Plenz
  -  Kristian Hartikainen
  -  Kyle Beauchamp
  -  Matej Rizman
  -  Pavel Sountsov
  -  Peter Roelants
  -  Rif A. Saurous
  -  Rohan Jain
  -  Roman Ring
  -  Rui Zhao
  -  Sergio Guadarrama
  -  Shuhei Iitsuka
  -  Shuming Hu
  -  Srinivas Vasudevan
  -  Tabor473
  -  ValentinMouret
  -  Youngwook Kim
  -  Yuki Nagae",108053674
1022,False,True,2019-02-15T22:03:47Z,2019-02-15T22:05:47Z,This is the 0.6.0-rc1 release candidate of TensorFlow Probability. It is tested against TensorFlow 1.13.0-rc2.,108053674
1023,False,True,2019-01-25T21:31:09Z,2019-01-25T23:39:37Z,"This is the RC0 release candidate of the TensorFlow Probability 0.6 release.

It is tested against TensorFlow 1.13.0-rc0",108053674
1024,False,False,2018-11-06T17:35:32Z,2018-11-06T18:03:19Z,"# Release Notes

This is the 0.5.0 release of TensorFlow Probability. It's tested and stable against TensorFlow 1.12.

## Packaging Change
As of this release, we no longer package a separate GPU-specific build. Users can select the version of TensorFlow they wish to use (CPU or GPU), and TensorFlow Probability will work with both.

As a result, we no longer explicitly list a TensorFlow dependency in our package requirements (since we can't know which version the user will want). If TFP is installed with no TensorFlow package present, or with an unsupported TensorFlow version, we will issue an `ImportError` at time of import.

## Distributions & Bijectors
* All `Distribution`s have been relocated from `tf.distributions` to `tfp.distributions` (the ones in TF are deprecated and will be deleted in TF 2.0).
* Add Triangular distribution.
* Add Zipf distribution.
* Add NormalCDF Bijector.
* Add Multivariate Student's t-distribution.
* Add RationalQuadratic kernel.

## Documentation & Examples
* Add example showing how to fit GLMM using Variational Inference.
* Introduce Gaussian process latent variable model colab.
* Introduce Gaussian process regression example colab
* Add notebook showcasing GLM algorithms and deriving some results about GLMs that those algorithms leverage.

# Huge thanks to all the contributors to this release!
* Akshay Modi
* Alexey Radul
* Anudhyan Boral
* Ashish Saxena
* Ben Zinberg
* Billy Lamberta
* Brian Patton
* Christopher Suter
* Dave Moore
* Ian Langmore
* Joshua V. Dillon
* Kristian Hartikainen
* Malcolm Reynolds
* Pavel Sountsov
* Srinivas Vasudevan
* Xiaojing Wang
* Yifei Feng",108053674
1025,False,True,2018-11-01T05:22:03Z,2018-11-01T05:29:17Z,"This is the RC1 release candidate of the TensorFlow Probability 0.5 release.

It is tested against TensorFlow 1.12.0-rc2

",108053674
1026,False,True,2018-10-29T20:31:42Z,2018-10-29T20:36:02Z,"This is the RC0 release candidate of the TensorFlow Probability 0.5 release.

It is tested against TensorFlow 1.12.0-rc2",108053674
1027,False,False,2018-10-08T16:00:36Z,2018-10-08T16:05:22Z,"# Release Notes

This is the 0.4.0 release of TensorFlow Probability. It's tested and stable against TensorFlow 1.11.

## Distributions & Bijectors
* All TF core Distributions now live in TFP (old ones are deprecated but still there)
* All TF core Bijectors now live in TFP (old ones are deprecated but still there)
* CDF support for `Independent`
* Seasonal effects and Sum components for Structural Time Series
* Add Half-Cauchy Distribution
* DCT (discrete cosine transform) Bijector
* Support dynamic shapes in BatchNormalization Bijector
* Add InverseGaussian Distribution
* Scaffolding for Bayesian Structural Time Series models
* Add VonMises Distribution 
* Add Pareto distrubiton
* Implicit reparameterization for TruncatedNormal

## Sampling & Inference
* Various improvements to BFGS and line search methods
* Add `tape` interceptor in Edward2
* GLM fitting with proximal gradient and L1/L2-regularization
* Support nested interceptors in Edward2

## Documentation & Examples
* Update docs to point to tfp instead of tf/tf.contrib
* Credit card interest notebook
* Bayesian Neural Net (VGG, ResNet18) examples on CIFAR-10 data
* Disentangled Sequential Autoencoder example
* Eager-mode, single-chain No-U-Turn Sampler
* Grammar VAE example using Edward2
* Deep exponential family example using Edward2
* Latent Dirichlet Allocation example using Edward2
* Factorial Mixtures notebook

# Huge thanks to all the contributors to this release!
* Asim Shankar
* Ben Zinberg
* Billy Lamberta
* Brian Patton
* Christopher Suter
* Copybara-Service
* cyrilchimisov
* Dave Moore
* davmre
* Dustin Tran
* Ian Langmore
* jiamingz
* Jiaming Zeng
* Jonathan J Hunt
* Joshua V. Dillon
* Keyon Vafa
* Mark Daoust
* Matthew McAteer
* mgorinova
* mhoffman
* Michael Figurnov
* Mike Dusenberry
* rif
* saxeas
* srvasude
* William D. Irons
* yunhao",108053674
1028,False,True,2018-09-28T20:47:36Z,2018-10-01T21:02:06Z,"This is the 0th release candidate of the 0.4.0 release of TensorFlow Probability.

It is tested against TensorFlow v1.11.0",108053674
1029,False,False,2018-08-14T16:39:15Z,2018-08-14T16:48:33Z,"# Release Notes

This is the 0.3.0 release of TensorFlow Probability. It's tested and stable against TensorFlow 1.10.

## Distributions & Bijectors
* Add the LKJ distribution on correlation matrices.
* Add GammaGamma distribution.
* Adds the VonMisesFisher distribution over points on the unit hypersphere.
* Add CholeskyToInvCholesky bijector.
* Added reparametrizable TruncatedNormal
* Add `tfp.bijectors.Transpose`.
* Add tanh bijection.
* Introduce GaussianProcessRegressionModel
* Introduce GaussianProcess distribution
* Gamma distribution and the derived distributions (Beta, Dirichlet, Student's t, inverse Gamma) are fully reparameterized.
* Add low and high as properties to quantized distribution.
* Collapse WishartCholesky and WishartFull into a single Wishart distribution that takes either a scale or a scale_cholesky argument.
* Add `adjoint` arg to `tfp.bijectors.Affine`.

## Sampling & Inference

* Enable nested interceptors in Edward2.
* Provide interface for controlling the number of HMC iterations during which to adapt the step size.
* Added support for dynamic shapes in the slice sampler.
* Make HMC more efficient and usable for MCEM.
  - Allow stop_gradient to be applied as new state is built (thus enabling recycling `kernel_results.accepted.target_log_prob`).
    - Add hook for user defined adaptive step size code and provide default implementation.
* Added implementation of the Nelder Mead derivative free optimization method.
* Add `tfp.math.random_rayleigh`.

## Documentation & Examples

* Add Edward2 README.md.
* Add migration guide from Edward to TFP.
* Add documentation matching tfp-0.2 release.
* Add colab example which compares fitting HLM's between TF distributions, Stan, and R. Colab was written in collaboration with safyan@.
* Added a preliminary version of a Probabilistic PCA Edward 2 example, and changed the BUILD file accordingly.
* Latent Dirichlet Allocation for 20 newsgroups dataset.
* A detailed case study in using TensorFlow Probability for estimating a covariance matrix.

# Huge thanks to all the contributors to this release!
* Akshay Agrawal
* Billy Lamberta
* Brian Patton
* Christopher Suter
* cyrilchimisov
* davmre
* Dustin Tran
* Ian Langmore
* jjhunt
* Joshua V. Dillon
* Kousuke Ariga
* Michael Figurnov
* Michele Colombo
* rif
* saxeas
* srvasude
* William D. Irons
* Yuan Huang",108053674
1030,False,False,2018-08-09T23:08:10Z,2018-08-09T23:10:42Z,"This is the rc1 release. We never actually built rc1, since we needed to cherrypick a few more things.

This release is tested against TensorFlow v1.10.0",108053674
1031,False,True,2018-08-09T20:17:23Z,2018-08-09T22:04:47Z,"This is the rc1 release. We never actually build rc0, since we ended up advancing the branch state up to master (after some test fixes).

This release is tested against TensorFlow v1.10.0",108053674
1032,False,True,2018-07-24T22:17:27Z,2018-08-09T03:44:27Z,"This is the 0th release candidate of TensorFlow Probability version 0.3.0.

It's tested against TensorFlow 1.10.0",108053674
1033,False,False,2018-07-19T19:06:24Z,2018-07-19T19:11:53Z,"This is the 0.2 release of TensorFlow Probability, our first versioned release.

It is tested against TensorFlow 1.9.0.",108053674
1034,False,True,2018-07-16T21:32:07Z,2018-07-16T23:08:56Z,"This is release candidate rc0, of our 0.2 release of TensorFlow Probability.

It is tested against TensorFlow 1.9.0.",108053674
1035,False,True,2018-06-16T17:10:52Z,2018-06-16T17:26:25Z,"# Release 0.1.0-rc1

This is release candidate rc1, of our first versioned release of TensorFlow Probability.

It is tested against TensorFlow 1.9.0-rc1.",108053674
1036,False,True,2018-06-15T23:38:32Z,2018-06-15T23:49:06Z,"# Release 0.1.0-rc0

This is the 0th release candidate our first versioned release of TensorFlow Probability.",108053674
1037,False,False,2019-07-05T10:18:17Z,2019-07-05T10:23:31Z,"* Bugfixes:
        - Fix cookbook examples for website",1555094
1038,False,False,2017-12-07T19:14:25Z,2017-12-07T19:18:46Z,"### Features
 - Drop all <math.h> function calls [Viktor Gal]
 - Use c++11 std::isnan, std:isfinite, std::isinf [Viktor Gal]

### Bugfixes
 - Port ipython notebooks to be python3 compatible [Viktor Gal]
 - Use the shogun-static library on Windows when linking the interface library [Viktor Gal]
 - Fix python typemap when compiling with MSVC [Viktor Gal]
 - Fix ShogunConfig.cmake paths [Viktor Gal]
 - Fix meta example parser bug in parallel builds [Esben Sørig]",1555094
1039,False,False,2017-11-29T08:24:56Z,2017-11-29T08:27:46Z,"### Bugfixes:
 - Fix installation of examples on WIN32 [Viktor Gal]",1555094
1040,False,False,2017-11-29T01:18:55Z,2017-11-29T01:20:35Z,"### Bugfixes
 - Install headers of GPL models when LICENSE_GPL_SHOGUN is enabled [Viktor Gal]
 - Always turn on LIBSHOGUN_BUILD_STATIC when compiling with MSVC [Viktor Gal]
 - Fix ipython notebook errors [Viktor Gal]",1555094
1041,False,False,2017-11-28T22:32:53Z,2017-11-28T22:34:53Z,"* This release is dedicated for Heiko's successful PhD defense!

* Add conda-forge packages, to get prebuilt binaries via the cross-platform conda package manager [Dougal Sutherland]
* Change interface cmake variables to INTERFACE_*
* Move GPL code to gpl submodule [Heiko Strathmann]

### Features
- Enable using BLAS/LAPACK from Eigen by default [Viktor Gal]
- Add iterators to SGVector and SGMatrix [Viktor Gal]
- Significantly lower the runtime of KernelPCA (GSoC '17) [Michele Mazzoni]
- Refactor FisherLDA and LDA solvers (GSoC '17) [Michele Mazzoni]
- Add automated test for trained model serialization (GSoC '17) [Michele Mazzoni]
- Enable SWIG director classes by default [Viktor Gal]
- Vectorize DotFeatures covariance/mean calculation [Michele Mazzoni]
- Support for premature stopping of model training (GSoC '17) [Giovanni De Toni]
- Add support for observable variables (GSoC '17) [Giovanni De Toni]
- Use TFLogger to serialize observed variables for TensorBoard (GSoC '17) [Giovanni De Toni]
- Drop CMath::dot and SGVector::dot and use linalg::dot [Viktor Gal]
- Added class probabilities for BaggingMachine (GSoC '17) [Olivier Nguyen]
### Bugfixes
- Fix transpose bug in Ruby typemap for matrices [Elias Saalmann]
- Fix MKL detection and linking; use mkl_rt when available [Viktor Gal]
- Fix Windows static linking [Viktor Gal]
- Fix SWIG interface compilation on Windows [qcrist]
- Fix CircularBuffer bug that broke parsing of big CSV and LibSVM files #1991 [Viktor Gal]
- Fix R interface when using clang to compile the interface [Viktor Gal]",1555094
1042,False,False,2017-04-23T09:45:11Z,2017-04-23T10:02:15Z," * Add native MS Windows support [Viktor Gal]
 * Shogun requires the compiler to support C++11 features
 * Shogun cloud online: Jupyter notebook with Shogun from the browser, https://cloud.shogun.ml

### Features
 - LDA now supports 32, 64 and 128 bit floating point numbers [Chris Goldsworthy]
 - Add SHOGUN_NUM_THREADS enviroment variable to control the number of threads
 used by the models in runtime [Viktor Gal]
 - Added Scala Interface to the build [Abhinav Rai]
 - Major re-writing and API changes in kernel statistical hypothesis
 testing framework, significant speed up in permutation test for
 quadratic time MMD, new kernel selection algorithms for quadratic time MMD [Soumyajit De]
### Bugfixes:
  - Fix build error of R interface for R>=3.3.0, #3460 [Heiko Strathmann]
  - Make the code compatible with Eigen 3.3.0 [Viktor Gal]
  - Fix number of CPUs detected on Linux [Viktor Gal]
  - Fix multi-threading in KMeansBase [Viktor Gal]
  - Make ExponentialARDKernel thread-safe [Viktor Gal]
  - Make PRNG thread-safe [Viktor Gal]
  - Fix python interface when using libshogun compiled with OpenMP [Viktor Gal]
  - Fix CART to work with cross-validation [Fernando Iglesias]
### Cleanup, efficiency updates, and API Changes:
  - Port multi-threading to use OpenMP backend in Kernel [Viktor Gal]
  - Fix false sharing in EuclideanDistance [Viktor Gal]
  - Fix out of source build of the whole project [Viktor Gal]
  - Add LIBSHOGUN cmake flag to turn off libshogun compilation [Viktor Gal]
  - Export Shogun target with cmake to enable to build modular interfaces to a
  pre-compiled libshogun on the system without requiring to compile
  libshogun itself [Viktor Gal]
### Notes
 - Contains major rewrite and clean-up of developer documentation in doc/readme [Heiko Strathmann, Lea Götz]
 - Known issue: Octave multithreaded crashes, currently bindings are initialized single-threaded, https://github.com/shogun-toolbox/shogun/issues/3772 [Heiko Strathmann]
",1555094
1043,False,False,2016-11-04T21:33:41Z,2016-11-04T21:40:59Z,"### Features
- GSoC 2016 project of Saurabh Mahindre: Major efficiency improvements for KMeans, LARS, Random Forests, Bagging, KNN.
- Add new Shogun cookbook for documentation and testing across all target languages [Heiko Strathmann, Sergey Lisitsyn, Esben Sorig, Viktor Gal].
- Added option to learn CombinedKernel weights with GP approximate inference [Wu Lin].
- LARS now supports 32, 64, and 128 bit floating point numbers [Chris Goldsworthy].

### Bugfixes:
- Fix gTest segfaults with GCC >= 6.0.0 [Björn Esser].
- Make Java and CSharp install-dir configurable [Björn Esser].
- Autogenerate modshogun.rb with correct module-suffix [Björn Esser].
- Fix KMeans++ initialization [Saurabh Mahindre].

### Cleanup, efficiency updates, and API Changes:
- Make Eigen3 a hard requirement. Bundle if not found on system. [Heiko Strathmann]
- Drop ALGLIB (GPL) dependency in CStatistics and ship CDFLIB (public domain) instead [Heiko Strathmann]
- Drop p-value estimation in model-selection [Heiko Strathmann]
- Static interfaces have been removed [Viktor Gal]
- New base class ShiftInvariantKernel of which GaussianKernel inherits [Rahul De].

### NOTE

This version contains a new CMake option USE_GPL_SHOGUN, which  when set to OFF will exclude all GPL codes from Shogun [Heiko Strathmann].
",1555094
1044,False,False,2016-02-10T18:30:36Z,2016-05-17T16:48:03Z,"This is a new feature and cleanup release.

### Features:
- Added GEMPLP for approximate inference to the structured output framework [Jiaolong Xu].
- Effeciency improvements of the FITC framework for GP inference (FITC_Laplce, FITC, VarDTC) [Wu Lin].
- Added optimisation of inducing variables in sparse GP inference [Wu Lin].
- Added optimisation methods for GP inference (Newton, Cholesky, LBFGS, ...) [Wu Lin]. 
- Added Automatic Relevance Determination (ARD) kernel functionality for variational GP inference [Wu Lin].
- Updated Notebook for variational GP inference [Wu Lin].
- New framework for stochastic optimisation (L1/2 loss, mirror descent, proximal gradients, adagrad, SVRG, RMSProp, adadelta, ...) [Wu Lin].
- New Shogun meta-language for automatically generating code listings in all target languages [Esben Sörig].
- Added periodic kernel [Esben Sörig].
- Add gradient output functionality in Neural Nets [Sanuj Sharma].

### Bugfixes:
- Fixes for java_modular build using OpenJDK [Björn Esser].
- Catch uncaught exceptions in Neural Net code [Khaled Nasr].
- Fix build of modular interfaces with SWIG 3.0.5 on MacOSX [Björn Esser].
- Fix segfaults when calling delete[] twice on SGMatrix-instances [Björn Esser].
- Fix for building with full-hardening-(CXX|LD)FLAGS [Björn Esser].
- Patch SWIG to fix a problem with SWIG and Python >= 3.5 [Björn Esser].
- Add modshogun.rb: make sure narray is loaded before modshogun.so [Björn Esser].
- set working-dir properly when running R (#2654) [Björn Esser].

### Cleanup, efficiency updates, and API Changes:
- Added GPU based dot-products to linalg [Rahul De].
- Added scale methods to linalg [Rahul De].
- Added element wise products to linalg [Rahul De].
- Added element-wise unary operators in linalg [Rahul De].
- Dropped parameter migration framework [Heiko Strathmann].
- Disabled Python integration tests by default [Sergey Lisitsyn, Heiko Strathmann].
",1555094
1045,False,False,2015-01-26T18:46:56Z,2015-01-18T11:10:42Z,"- This release features the work of our 8 GSoC 2014 students [student; mentors]:
  - OpenCV Integration and Computer Vision Applications [Abhijeet Kislay; Kevin Hughes]
  - Large-Scale Multi-Label Classification [Abinash Panda; Thoralf Klein]
  - Large-scale structured prediction with approximate inference [Jiaolong Xu; Shell Hu]
  - Essential Deep Learning Modules [Khaled Nasr; Sergey Lisitsyn, Theofanis Karaletsos]
  - Fundamental Machine Learning: decision trees, kernel density estimation [Parijat Mazumdar ; Fernando Iglesias]
  - Shogun Missionary & Shogun in Education [Saurabh Mahindre; Heiko Strathmann]
  - Testing and Measuring Variable Interactions With Kernels [Soumyajit De; Dino Sejdinovic, Heiko Strathmann]
  - Variational Learning for Gaussian Processes [Wu Lin; Heiko Strathmann, Emtiyaz Khan]
- This release also contains several cleanups and bugfixes:
  - Features:
    - New Shogun project description [Heiko Strathmann]
    - ID3 algorithm for decision tree learning [Parijat Mazumdar]
    - New modes for PCA matrix factorizations: SVD & EVD, in-place or reallocating [Parijat Mazumdar]
    - Add Neural Networks with linear, logistic and softmax neurons [Khaled Nasr]
    - Add kernel multiclass strategy examples in multiclass notebook [Saurabh Mahindre]
    - Add decision trees notebook containing examples for ID3 algorithm [Parijat Mazumdar]
    - Add sudoku recognizer ipython notebook [Alejandro Hernandez]
    - Add in-place subsets on features, labels, and custom kernels [Heiko Strathmann]
    - Add Principal Component Analysis notebook [Abhijeet Kislay]
    - Add Multiple Kernel Learning notebook [Saurabh Mahindre]
    - Add Multi-Label classes to enable Multi-Label classification [Thoralf Klein]
    - Add rectified linear neurons, dropout and max-norm regularization to neural networks [Khaled Nasr]
    - Add C4.5 algorithm for multiclass classification using decision trees [Parijat Mazumdar]
    - Add support for arbitrary acyclic graph-structured neural networks [Khaled Nasr]
    - Add CART algorithm for classification and regression using decision trees [Parijat Mazumdar]
    - Add CHAID algorithm for multiclass classification and regression using decision trees [Parijat Mazumdar]
    - Add Convolutional Neural Networks [Khaled Nasr]
    - Add Random Forests algorithm for ensemble learning using CART [Parijat Mazumdar]
    - Add Restricted Botlzmann Machines [Khaled Nasr]
    - Add Stochastic Gradient Boosting algorithm for ensemble learning [Parijat Mazumdar]
    - Add Deep contractive and denoising autoencoders [Khaled Nasr]
    - Add Deep belief networks [Khaled Nasr]
  - Bugfixes:
    - Fix reference counting bugs in CList when reference counting is on [Heiko Strathmann, Thoralf Klein, lambday]
    - Fix memory problem in PCA::apply_to_feature_matrix [Parijat Mazumdar]
    - Fix crash in LeastAngleRegression for the case D greater than N [Parijat Mazumdar]
    - Fix memory violations in bundle method solvers [Thoralf Klein]
    - Fix fail in library_mldatahdf5.cpp example when http://mldata.org is not working properly [Parijat Mazumdar]
    - Fix memory leaks in Vowpal Wabbit, LibSVMFile and KernelPCA [Thoralf Klein]
    - Fix memory and control flow issues discovered by Coverity [Thoralf Klein]
    - Fix R modular interface SWIG typemap (Requires SWIG >= 2.0.5) [Matt Huska]
  - Cleanup and API Changes:
    - PCA now depends on Eigen3 instead of LAPACK [Parijat Mazumdar]
    - Removing redundant and fixing implicit imports [Thoralf Klein]
    - Hide many methods from SWIG, reducing compile memory by 500MiB [Heiko Strathmann, Fernando Iglesias, Thoralf Klein]
",1555094
1046,False,False,2014-02-17T18:41:58Z,2014-02-17T20:33:59Z,"we are pleased to announce Shogun 3.2.0 !

This release also contains several cleanups and bugfixes:
- Features:
  - Fully support python3 now
  - Add mini-batch k-means [Parijat Mazumdar]
  - Add k-means++ for more details see the [notebook](http://shogun-toolbox.org/static/notebook/current/KMeans.html) [Parijat Mazumdar] 
  - Add sub-sequence string kernel [lambday]
- Bugfixes:
  - Compile fixes for upcoming swig3.0
  - Speedup for gaussian process' apply()
  - Improve unit / integration test checks
  - libbmrm uninitialized memory reads
  - libocas uninitialized memory reads
  - Octave 3.8 compile fixes [Orion Poplawski]
  - Fix java modular compile error [Bjoern Esser]
",1555094
1047,False,False,2017-08-21T00:51:15Z,2017-08-21T00:53:25Z,"Bugfix:
* #51 fixes #50, a bug resulting from changes in scikit-learn v0.19

New features:
* Docker-compose file for easier docker deployment by @marcelmaatkamp ",84231689
1048,False,False,2017-06-23T18:07:24Z,2017-06-23T18:09:33Z,"Features
* #43 Automated ensembling is finally here! Greedy forward model selection introduced

Warning: Project files from version before v0.5.0 will **not work** with v0.5.0",84231689
1049,False,False,2017-06-15T16:02:28Z,2017-06-15T16:03:32Z,"Features
* #35 by @menglewis 
* #37 Added TPOT integration

Warning: v0.4 Project files are not compatible with earlier versions",84231689
1050,False,False,2017-06-07T19:30:07Z,2017-06-07T19:40:07Z,"Features
* #29 #30 Removed append original checkbox and added Identity Transformer preset base learner instead",84231689
1051,False,False,2017-06-07T16:08:08Z,2017-06-07T16:23:12Z,"Features
* #27 More estimators (regressors) by @enisnazif 
* #28 ""Export ensemble as Python package"" changed to ""Export ensemble as Python file"". Also, an additional shortcut for directly exporting a stacked ensemble as a base learner setup. Awesome!
",84231689
1052,False,False,2017-06-06T17:18:36Z,2017-06-06T17:20:10Z,"Features
* #23 More preset cross-validators by @ryanliwag 
* #24 Added preset metrics median absolute error, R2 score, and explained variance score
* #26 Added functionality that stores previous parameter searches. More of a user experience fix.",84231689
1053,False,False,2017-06-04T14:46:20Z,2017-06-04T14:47:45Z,"New Feature:
* #22 Added ability to export a stacked ensemble as a Python package so you can use it on different data.
* #19  by @jef5ez adds Mean Absolute Error as preset metric
 

Docs:
* #22 Added docs for using exported stacked ensemble Python package
* #20 Added docs for using TPOT with Xcessiv",84231689
1054,False,False,2017-06-02T14:09:13Z,2017-06-02T14:13:42Z,Hotfix for 0.3.0. Ended up at 0.3.4 because Pypi problems..,84231689
1055,False,False,2017-06-02T12:00:29Z,2017-06-02T12:02:25Z,"Major feature addition
* #18 - Added an experimental bayesian optimization search beside grid search and random search to allow a bit of automation for hyperparameter tuning.",84231689
1056,False,False,2017-05-31T11:04:11Z,2017-05-31T11:04:39Z,Hotfix for Python 3 users.,84231689
1057,False,False,2017-05-30T12:14:22Z,2017-05-30T12:15:27Z,* #16 Added a few new preset learners and metrics,84231689
1058,False,False,2017-05-29T19:08:08Z,2017-05-29T19:09:21Z,Hotfix for setuptools.,84231689
1059,False,False,2017-05-29T15:53:28Z,2017-05-29T15:55:00Z,"Features 
* Dockerfile added
* Startup script now raises explicit error for Windows OS.

Documentation
* Documentation updated for Dockerfile
",84231689
1060,False,False,2017-05-28T15:55:59Z,2017-05-28T15:58:14Z,"Added features
* #13 

Breaking Change
* Project folders created with Xcessiv<0.2.0 will not work on Xcessiv>=0.2.0. This is due to #13 ",84231689
1061,False,False,2017-05-28T06:46:16Z,2017-05-28T06:48:25Z,"* #12 

* Brand new and more flexible way of defining cross-validation and meta-feature generation method",84231689
1062,False,False,2017-05-26T13:39:12Z,2017-05-26T13:42:02Z,"* Fix UI, when deleting parent component e.g. base learner origin, make sure children components are refreshed (base learners and stacked ensembles

* Major feature change: #11 ",84231689
1063,False,False,2017-05-25T15:06:49Z,2017-05-25T15:09:10Z,"* #9 
* #10 ",84231689
1064,False,False,2017-05-24T17:01:53Z,2017-05-24T17:03:08Z,* #8 ,84231689
1065,False,False,2017-05-24T01:53:52Z,2017-05-24T01:56:23Z,* Hotfix for #6 pointed out by @KhaledSharif,84231689
1066,False,False,2017-05-23T14:28:21Z,2017-05-23T15:13:11Z,,84231689
1067,False,False,2019-11-30T02:15:56Z,2019-11-30T02:20:53Z,"# Wooey 0.11.0

## New Features
1. WooeyWidgets, which enable custom form input elements to be created and used. #175 
2. Korean translations added #254 
3. Improved UI to not allow job operations on message brokers that do not allow them. #285 
4. Django2 Support. #271 

## Bug Fixes
1. Fix bug where all parameters from all subparsers were needed to validate in order to submit a job. #299 
2. Fix bug with escaping parameter arguments that prevented special characters from being 
 used. #296 
3. Fix bug where multiple initial files for a cloned job were not populated. #255 
4. Fix bug in parsing multiple arguments where argparse specifies `action=append` #270 
5. Fix bug in cleaning up empty jobs where workers cannot be contacted. #277 
6. Fix bug where scripts on remote workers were not invalidated after updates on main server. 
 #145 
7. Fix race condition where celery tasks would start before database transaction finished. #297 
8. Handle characters in script version that need to be escaped for urls. #298 ",31502883
1068,False,False,2018-05-20T13:26:54Z,2018-05-20T13:51:30Z,"# Wooey 0.10.0


## New Features
1. Added docker files for development and example deployments!
2. Better documentation!:
  * Added [help with upgrades](http://wooey.readthedocs.io/en/update-migration-docs/upgrade_help.html)
  * Added a [section on the UI](http://wooey.readthedocs.io/en/latest/wooey_ui.html)
3. Subparser Support! Subparsers are now supported for argparse. With this completed, we can begin adding support for other interfaces such as [click](https://github.com/pallets/click)
4. Added checksums to scripts. Scripts now have a checksum so duplicate scripts are not created (and this paves the way for supporting better automatic updates of scripts)
5. Jobs can be cloned into previous script versions. Previously, the `clone` button cloned a job into the latest version of a script. Now, jobs can be cloned into previous versions.

## Bug Fixes
1. Errors from adding scripts are returned as a message instead of an Exception.
2. Dead jobs are now automatically cleaned up. (this removes jobs that are in a state of limbo due to a server crash, etc.).
3. Attempts to access a job that a user did not have permission to access resulted in a 500 error. This now shows the proper page indicating the user has no access to that job.
4. Fixed parsing of default argument parameters that were lists or functions.
5. Fixed zip files overwriting nested output.

## Version Support
1. Supports Django 1.10/1.11 and Celery 4.x
2. Dropped compatibility layers for Django 1.7 and python 3.3

",31502883
1069,False,False,2017-12-20T04:08:35Z,2017-12-20T04:18:27Z,This is a patch release to address clinto having subparser support and changing how parsed scripts are represented.,31502883
1070,False,False,2017-09-05T00:57:45Z,2017-09-05T00:59:16Z,"This is a quick release to address https://github.com/wooey/Wooey/issues/189, where clinto was not reporting errors in parsing scripts through the frontend.",31502883
1071,False,False,2017-01-02T03:00:06Z,2017-01-01T21:55:37Z,"# Wooey v0.9.8

This is primarily a release to address issue #163 where updated scripts would duplicate group names. However, it is a huge release in terms of internationalization!

## New Features
1. Internationalization is now enabled by default in the bootstrapped version of Wooey.
2. Simplified Chinese support has been added thanks to @zjhzxjm!

## Bug Fixes
1. Parameter groups could be duplicated
2. New parameters on script updates would be made when parameter order was rearranged
3. Fixed CSS issue causing the script search sidebar to be hidden
",31502883
1072,False,False,2016-11-28T23:19:36Z,2016-11-29T03:14:21Z,"Minor release to fix incompatibility with recent Celery upgrade to 4.0
",31502883
1073,False,False,2016-09-05T20:05:03Z,2016-09-11T18:53:52Z,"This addresses the remaining bugs from version 0.93:
#148 and #149 -- Switch to using threads to monitor process output for better cross-platform compatibility
#152  -- Fix for argumentless scripts.
",31502883
1074,False,False,2016-08-16T03:12:28Z,2016-08-16T03:14:22Z,"A quick release to address Django 1.10 incompatibility
",31502883
1075,False,False,2016-07-28T11:55:27Z,2016-07-28T20:35:34Z,"# Major Features

## Real time updates of Job status

The output of scripts as well and execution status of a script will be updated in real time so there is no need to reload a page for job updates. By default, this makes use of the database to store job information, but can be easily configured to store this information in a cache layer via the `WOOEY_REALTIME_CACHE` setting.

## Improved updates to scripts

Script parameters are now more intelligently created and parameters that are unchanged between script versions will not be updated. Via the command line, this behavior can be achieved by adding the `--update` flag to the `addscript` command and is automatically performed when updating scripts via the admin. 

## Reduced file duplication

Wooey now performs a checksum on uploaded files to identify duplicated files, and adds a permission layer to users that allows multiple users to access the same uploads (provided that user had the file in the first place to upload!). As an added benefit, this setup paves the way for a media dashboard that will allow users and groups to easily share files with one another.

# Minor Features
- An awesome user, @manicmaniac , added translations for Japanese.
- Automatic deletion of jobs older than a given date
",31502883
1076,False,False,2020-02-24T21:47:38Z,2020-02-24T21:48:32Z,"
##### New Features

- -

##### Changes

- The previously deprecated `OnehotTransactions` has been removed in favor of the `TransactionEncoder.`
- Removed `SparseDataFrame` support in frequent pattern mining functions in favor of pandas >=1.0's new way for working sparse data. If you used `SparseDataFrame` formats, please see pandas' migration guide at https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating ([#667](https://github.com/rasbt/mlxtend/pull/667))


##### Bug Fixes

- -
",22937749
1077,False,False,2020-01-29T03:32:45Z,2020-01-29T03:33:40Z,"
##### New Features

- The `SequentialFeatureSelector` now supports using pre-specified feature sets via the `fixed_features` parameter. ([#578](https://github.com/rasbt/mlxtend/pull/578))
- Adds a new `accuracy_score` function to `mlxtend.evaluate` for computing basic classifcation accuracy, per-class accuracy, and average per-class accuracy. ([#624](https://github.com/rasbt/mlxtend/pull/624) via [Deepan Das](https://github.com/deepandas11))
- `StackingClassifier` and `StackingCVClassifier`now have a `decision_function` method, which serves as a preferred choice over `predict_proba` in calculating roc_auc and average_precision scores when the meta estimator is a linear model or support vector classifier. ([#634](https://github.com/rasbt/mlxtend/pull/634) via [Qiang Gu](https://github.com/qiagu))

##### Changes

- Improve the runtime performance for the `apriori` frequent itemset generating function when `low_memory=True`. Setting `low_memory=False` (default) is still faster for small itemsets, but `low_memory=True` can be much faster for large itemsets and requires less memory.  Also, input validation for  `apriori`, ̀ fpgrowth` and `fpmax` takes a significant amount of time when input pandas DataFrame is large; this is now dramatically reduced when input contains boolean values (and not zeros/ones), which is the case when using `TransactionEncoder`. ([#619](https://github.com/rasbt/mlxtend/pull/619) via [Denis Barbier](https://github.com/dbarbier))
- Add support for newer sparse pandas DataFrame for frequent itemset algorithms. Also, input validation for  `apriori`, ̀ fpgrowth` and `fpmax` runs much faster on sparse DataFrame when input pandas DataFrame contains integer values. ([#621](https://github.com/rasbt/mlxtend/pull/621) via [Denis Barbier](https://github.com/dbarbier))
- Let `fpgrowth` and `fpmax` directly work on sparse DataFrame, they were previously converted into dense Numpy arrays. ([#622](https://github.com/rasbt/mlxtend/pull/622) via [Denis Barbier](https://github.com/dbarbier))

##### Bug Fixes
- Fixes a bug in `mlxtend.plotting.plot_pca_correlation_graph` that caused the explaind variances not summing up to 1. Also, improves the runtime performance of the correlation computation and adds a missing function argument for the explained variances (eigenvalues) if users provide their own principal components. ([#593](https://github.com/rasbt/mlxtend/issues/593) via [Gabriel Azevedo Ferreira](https://github.com/Gabriel-Azevedo-Ferreira))
- Behavior of `fpgrowth` and `apriori` consistent for edgecases such as `min_support=0`. ([#573](https://github.com/rasbt/mlxtend/pull/573) via [Steve Harenberg](https://github.com/harenbergsd))
- `fpmax` returns an empty data frame now instead of raising an error if the frequent itemset set is empty. ([#573](https://github.com/rasbt/mlxtend/pull/573) via [Steve Harenberg](https://github.com/harenbergsd))
- Fixes and issue in `mlxtend.plotting.plot_confusion_matrix`, where the font-color choice for medium-dark cells was not ideal and hard to read. [#588](https://github.com/rasbt/mlxtend/pull/588) via [sohrabtowfighi](https://github.com/sohrabtowfighi))
- The `svd` mode of `mlxtend.feature_extraction.PrincipalComponentAnalysis` now also *n-1* degrees of freedom instead of *n* d.o.f. when computing the eigenvalues to match the behavior of `eigen`. [#595](https://github.com/rasbt/mlxtend/pull/595)
- Disable input validation for `StackingCVClassifier` because it causes issues if pipelines are used as input. [#606](https://github.com/rasbt/mlxtend/pull/606)
",22937749
1078,False,False,2019-07-19T18:15:02Z,2019-07-19T18:16:51Z,"
##### New Features

- Added an enhancement to the existing `iris_data()` such that both the UCI Repository version of the Iris dataset as well as the corrected, original
  version of the dataset can be loaded, which has a slight difference in two data points (consistent with Fisher's paper; this is also the same as in R). (via [#539](https://github.com/rasbt/mlxtend/pull/532) via [janismdhanbad](https://github.com/janismdhanbad))
- Added optional `groups` parameter to `SequentialFeatureSelector` and `ExhaustiveFeatureSelector` `fit()` methods for forwarding to sklearn CV ([#537](https://github.com/rasbt/mlxtend/pull/537) via [arc12](https://github.com/qiaguhttps://github.com/arc12))
- Added a new `plot_pca_correlation_graph` function to the `mlxtend.plotting` submodule for plotting a PCA correlation graph. ([#544](https://github.com/rasbt/mlxtend/pull/544) via [Gabriel-Azevedo-Ferreira](https://github.com/qiaguhttps://github.com/Gabriel-Azevedo-Ferreira))
- Added a `zoom_factor` parameter to the `mlxten.plotting.plot_decision_region` function that allows users to zoom in and out of the decision region plots. ([#545](https://github.com/rasbt/mlxtend/pull/545))
- Added a function `fpgrowth` that implements the FP-Growth algorithm for mining frequent itemsets as a drop-in replacement for the existing `apriori` algorithm. ([#550](https://github.com/rasbt/mlxtend/pull/550) via [Steve Harenberg](https://github.com/harenbergsd))
- New `heatmap` function in `mlxtend.plotting`.  ([#552](https://github.com/rasbt/mlxtend/pull/552))
- Added a function `fpmax` that implements the FP-Max algorithm for mining maximal itemsets as a drop-in replacement for the `fpgrowth` algorithm. ([#553](https://github.com/rasbt/mlxtend/pull/553) via [Steve Harenberg](https://github.com/harenbergsd))
- New `figsize` parameter for the `plot_decision_regions` function in `mlxtend.plotting`. ([#555](https://github.com/rasbt/mlxtend/pull/555) via [Mirza Hasanbasic](https://github.com/kazyka))
- New `low_memory` option for the `apriori` frequent itemset generating function. Setting `low_memory=False` (default) uses a substantially optimized version of the algorithm that is 3-6x faster than the original implementation (`low_memory=True`). ([#567](https://github.com/rasbt/mlxtend/pull/567) via [jmayse](https://github.com/jmayse))

##### Changes

- Now uses the latest joblib library under the hood for multiprocessing instead of `sklearn.externals.joblib`. ([#547](https://github.com/rasbt/mlxtend/pull/547))
- Changes to `StackingCVClassifier` and `StackingCVRegressor` such that first-level models are allowed to generate output of non-numeric type. ([#562](https://github.com/rasbt/mlxtend/pull/562))


##### Bug Fixes

- Fixed documentation of `iris_data()` under `iris.py` by adding a note about differences in the iris data in R and UCI machine learning repo.
- Make sure that if the `'svd'` mode is used in PCA, the number of eigenvalues is the same as when using `'eigen'` (append 0's zeros in that case) ([#565](https://github.com/rasbt/mlxtend/pull/565))",22937749
1079,False,False,2019-05-12T06:40:52Z,2019-05-12T06:42:15Z,"##### New Features

- `StackingCVClassifier` and `StackingCVRegressor` now support `random_state` parameter, which, together with `shuffle`, controls the randomness in the cv splitting. ([#523](https://github.com/rasbt/mlxtend/pull/523) via [Qiang Gu](https://github.com/qiaguhttps://github.com/qiagu))
- `StackingCVClassifier` and `StackingCVRegressor` now have a new `drop_last_proba` parameter. It drops the last ""probability"" column in the feature set since if `True`,
        because it is redundant: p(y_c) = 1 - p(y_1) + p(y_2) + ... + p(y_{c-1}). This can be useful for meta-classifiers that are sensitive to perfectly collinear features. ([#532](https://github.com/rasbt/mlxtend/pull/532))
- Other stacking estimators, including `StackingClassifier`, `StackingCVClassifier` and `StackingRegressor`, support grid search over the `regressors` and even a single base regressor. ([#522](https://github.com/rasbt/mlxtend/pull/522) via [Qiang Gu](https://github.com/qiaguhttps://github.com/qiagu))
- Adds multiprocessing support to `StackingCVClassifier`. ([#522](https://github.com/rasbt/mlxtend/pull/522) via [Qiang Gu](https://github.com/qiaguhttps://github.com/qiagu))
- Adds multiprocessing support to `StackingCVRegressor`. ([#512](https://github.com/rasbt/mlxtend/pull/512) via [Qiang Gu](https://github.com/qiaguhttps://github.com/qiagu))
-  Now, the `StackingCVRegressor` also enables grid search over the `regressors` and even a single base regressor. When there are level-mixed parameters, `GridSearchCV` will try to replace hyperparameters in a top-down order (see the [documentation](http://rasbt.github.io/mlxtend/user_guide/regressor/StackingCVRegressor/) for examples details). ([#515](https://github.com/rasbt/mlxtend/pull/512) via [Qiang Gu](https://github.com/qiaguhttps://github.com/qiagu))
- Adds a `verbose` parameter to `apriori` to show the current iteration number as well as the itemset size currently being sampled. ([#519](https://github.com/rasbt/mlxtend/pull/519)
- Adds an optional `class_name` parameter to the confusion matrix function to display class names on the axis as tick marks. ([#487](https://github.com/rasbt/mlxtend/pull/487) via [sandpiturtle](https://github.com/qiaguhttps://github.com/sandpiturtle))

##### Changes

- Due to new features, restructuring, and better scikit-learn support (for `GridSearchCV`, etc.) the `StackingCVRegressor`'s meta regressor is now being accessed via `'meta_regressor__*` in the parameter grid. E.g., if a `RandomForestRegressor` as meta- egressor was previously tuned via `'randomforestregressor__n_estimators'`, this has now changed to `'meta_regressor__n_estimators'`. ([#515](https://github.com/rasbt/mlxtend/pull/512) via [Qiang Gu](https://github.com/qiaguhttps://github.com/qiagu))
- The same change mentioned above is now applied to other stacking estimators, including `StackingClassifier`, `StackingCVClassifier` and `StackingRegressor`. ([#522](https://github.com/rasbt/mlxtend/pull/522) via [Qiang Gu](https://github.com/qiaguhttps://github.com/qiagu))

##### Bug Fixes

- The `feature_selection.ColumnSelector` now also supports column names of type `int` (in addition to `str` names) if the input is a pandas DataFrame.  ([#500](https://github.com/rasbt/mlxtend/pull/500) via [tetrar124](https://github.com/tetrar124)
- Fix unreadable labels in `plot_confusion_matrix` for imbalanced datasets if `show_absolute=True` and `show_normed=True`. ([#504](https://github.com/rasbt/mlxtend/pull/504))
- Raises a more informative error if a `SparseDataFrame` is passed to `apriori` and the dataframe has integer column names that don't start with `0` due to current limitations of the `SparseDataFrame` implementation in pandas. ([#503](https://github.com/rasbt/mlxtend/pull/503))
- SequentialFeatureSelector now supports DataFrame as input for all operating modes (forward/backward/floating). [#506](https://github.com/rasbt/mlxtend/pull/506)
- `mlxtend.evaluate.feature_importance_permutation` now correctly accepts scoring functions with proper function signature as `metric` argument. [#528](https://github.com/rasbt/mlxtend/pull/528)
",22937749
1080,False,False,2019-01-19T23:48:34Z,2019-01-19T23:49:35Z,"##### New Features

- Adds a new transformer class to `mlxtend.image`, `EyepadAlign`, that aligns face images based on the location of the eyes. ([#466](https://github.com/rasbt/mlxtend/pull/466) by [Vahid Mirjalili](https://github.com/vmirly))
- Adds a new function, `mlxtend.evaluate.bias_variance_decomp` that decomposes the loss of a regressor or classifier into bias and variance terms. ([#470](https://github.com/rasbt/mlxtend/pull/470))
- Adds a `whitening` parameter to `PrincipalComponentAnalysis`, to optionally whiten the transformed data such that the features have unit variance. ([#475](https://github.com/rasbt/mlxtend/pull/475))

##### Changes

- Changed the default solver in `PrincipalComponentAnalysis` to `'svd'` instead of `'eigen'` to improve numerical stability. ([#474](https://github.com/rasbt/mlxtend/pull/474))
- The `mlxtend.image.extract_face_landmarks` now returns `None` if no facial landmarks were detected instead of an array of all zeros. ([#466](https://github.com/rasbt/mlxtend/pull/466))


##### Bug Fixes

- The eigenvectors maybe have not been sorted in certain edge cases if solver was `'eigen'` in `PrincipalComponentAnalysis` and `LinearDiscriminantAnalysis`. ([#477](https://github.com/rasbt/mlxtend/pull/477), [#478](https://github.com/rasbt/mlxtend/pull/478))",22937749
1081,False,False,2018-11-10T04:32:01Z,2018-11-10T04:33:03Z,"##### New Features

- Added a `scatterplotmatrix` function to the `plotting` module. ([#437](https://github.com/rasbt/mlxtend/pull/437))
- Added `sample_weight` option to `StackingRegressor`, `StackingClassifier`, `StackingCVRegressor`, `StackingCVClassifier`, `EnsembleVoteClassifier`. ([#438](https://github.com/rasbt/mlxtend/issues/438))
- Added a `RandomHoldoutSplit` class to perform a random train/valid split without rotation in `SequentialFeatureSelector`, scikit-learn `GridSearchCV` etc. ([#442](https://github.com/rasbt/mlxtend/pull/442))
- Added a `PredefinedHoldoutSplit` class to perform a train/valid split, based on user-specified indices, without rotation in `SequentialFeatureSelector`, scikit-learn `GridSearchCV` etc. ([#443](https://github.com/rasbt/mlxtend/pull/443))
- Created a new `mlxtend.image` submodule for working on image processing-related tasks. ([#457](https://github.com/rasbt/mlxtend/pull/457))
- Added a new convenience function `extract_face_landmarks` based on `dlib` to `mlxtend.image`. ([#458](https://github.com/rasbt/mlxtend/pull/458))
- Added a `method='oob'` option to the `mlxtend.evaluate.bootstrap_point632_score` method to compute the classic out-of-bag bootstrap estimate ([#459](https://github.com/rasbt/mlxtend/pull/459))
- Added a `method='.632+'` option to the `mlxtend.evaluate.bootstrap_point632_score` method to compute the .632+ bootstrap estimate that addresses the optimism bias of the .632 bootstrap ([#459](https://github.com/rasbt/mlxtend/pull/459))
- Added a new `mlxtend.evaluate.ftest` function to perform an F-test for comparing the accuracies of two or more classification models. ([#460](https://github.com/rasbt/mlxtend/pull/460))
- Added a new `mlxtend.evaluate.combined_ftest_5x2cv` function to perform an combined 5x2cv F-Test for comparing the performance of two models. ([#461](https://github.com/rasbt/mlxtend/pull/461))
- Added a new `mlxtend.evaluate.difference_proportions` test for comparing two proportions (e.g., classifier accuracies) ([#462](https://github.com/rasbt/mlxtend/pull/462))


##### Changes

- Addressed deprecations warnings in NumPy 0.15. ([#425](https://github.com/rasbt/mlxtend/pull/425))
- Because of complications in PR ([#459](https://github.com/rasbt/mlxtend/pull/459)), Python 2.7 was now dropped; since official support for Python 2.7 by the Python Software Foundation is ending in approx. 12 months anyways, this re-focussing will hopefully free up some developer time with regard to not having to worry about backward compatibility

##### Bug Fixes

- Fixed an issue with a missing import in `mlxtend.plotting.plot_confusion_matrix`. ([#428](https://github.com/rasbt/mlxtend/pull/428))",22937749
1082,False,False,2018-07-21T02:04:29Z,2018-07-21T02:06:26Z,"### Version 0.13.0 (07/20/2018)

##### New Features

- A meaningful error message is now raised when a cross-validation generator is used with `SequentialFeatureSelector`. ([#377](https://github.com/rasbt/mlxtend/pull/377))
- The `SequentialFeatureSelector` now accepts custom feature names via the `fit` method for more interpretable feature subset reports. ([#379](https://github.com/rasbt/mlxtend/pull/379))
- The `SequentialFeatureSelector` is now also compatible with Pandas DataFrames and uses DataFrame column-names for more interpretable feature subset reports. ([#379](https://github.com/rasbt/mlxtend/pull/379))
- `ColumnSelector` now works with Pandas DataFrames columns. ([#378](https://github.com/rasbt/mlxtend/pull/378) by [Manuel Garrido](https://github.com/manugarri))
- The `ExhaustiveFeatureSelector` estimator in `mlxtend.feature_selection` now is safely stoppable mid-process by control+c. ([#380](https://github.com/rasbt/mlxtend/pull/380))
- Two new functions, `vectorspace_orthonormalization` and `vectorspace_dimensionality` were added to `mlxtend.math` to use the Gram-Schmidt process to convert a set of linearly independent vectors into a set of orthonormal basis vectors, and to compute the dimensionality of a vectorspace, respectively. ([#382](https://github.com/rasbt/mlxtend/pull/382))
- `mlxtend.frequent_patterns.apriori` now supports pandas `SparseDataFrame`s to generate frequent itemsets. ([#404](https://github.com/rasbt/mlxtend/pull/404) via [Daniel Morales](https://github.com/rasbt/mlxtend/pull/404))
- The `plot_confusion_matrix` function now has the ability to show normalized confusion matrix coefficients in addition to or instead of absolute confusion matrix coefficients with or without a colorbar. The text display method has been changed so that the full range of the colormap is used. The default size is also now set based on the number of classes.
- Added support for merging the meta features with the original input features in `StackingRegressor` (via `use_features_in_secondary`) like it is already supported in the other Stacking classes. ([#418](https://github.com/rasbt/mlxtend/pull/418))
- Added a `support_only` to the `association_rules` function, which allow constructing association rules (based on the support metric only) for cropped input DataFrames that don't contain a complete set of antecedent and consequent support values. ([#421](https://github.com/rasbt/mlxtend/pull/421))

##### Changes

- Itemsets generated with `apriori` are now `frozenset`s ([#393](https://github.com/rasbt/mlxtend/issues/393) by [William Laney](https://github.com/WLaney) and [#394](https://github.com/rasbt/mlxtend/issues/394))
- Now raises an error if a input DataFrame to `apriori` contains non 0, 1, True, False values. [#419](https://github.com/rasbt/mlxtend/issues/419))

##### Bug Fixes

- Allow mlxtend estimators to be cloned via scikit-learn's `clone` function. ([#374](https://github.com/rasbt/mlxtend/pull/374))
- Fixes bug to allow the correct use of `refit=False` in `StackingRegressor` and `StackingCVRegressor`  ([#384](https://github.com/rasbt/mlxtend/pull/384) and ([#385](https://github.com/rasbt/mlxtend/pull/385)) by [selay01](https://github.com/selay01))
- Allow `StackingClassifier` to work with sparse matrices when `use_features_in_secondary=True`  ([#408](https://github.com/rasbt/mlxtend/issues/408) by [Floris Hoogenbook](https://github.com/FlorisHoogenboom))
- Allow `StackingCVRegressor` to work with sparse matrices when `use_features_in_secondary=True`  ([#416](https://github.com/rasbt/mlxtend/issues/416))
- Allow `StackingCVClassifier` to work with sparse matrices when `use_features_in_secondary=True`  ([#417](https://github.com/rasbt/mlxtend/issues/417))",22937749
1083,False,False,2018-04-21T18:05:46Z,2018-04-21T18:13:51Z,"##### Downloads

- [Source code (zip)](https://github.com/rasbt/mlxtend/archive/v0.12.0.zip)
- [Source code (tar.gz)](https://github.com/rasbt/mlxtend/archive/v0.12.0.tar.gz)

##### New Features

-  A new `feature_importance_permuation` function to compute the feature importance in classifiers and regressors via the *permutation importance* method ([#358](https://github.com/rasbt/mlxtend/pull/358))
-  The fit method of the `ExhaustiveFeatureSelector` now optionally accepts `**fit_params` for the estimator that is used for the feature selection. ([#354](https://github.com/rasbt/mlxtend/pull/354) by Zach Griffith)
-  The fit method of the `SequentialFeatureSelector` now optionally accepts
`**fit_params` for the estimator that is used for the feature selection. ([#350](https://github.com/rasbt/mlxtend/pull/350) by Zach Griffith)


##### Changes


- Replaced `plot_decision_regions` colors by a colorblind-friendly palette and adds contour lines for decision regions. ([#348](https://github.com/rasbt/mlxtend/issues/348))
- All stacking estimators now raise `NonFittedErrors` if any method for inference is called prior to fitting the estimator. ([#353](https://github.com/rasbt/mlxtend/issues/353))
- Renamed the `refit` parameter of both the `StackingClassifier` and `StackingCVClassifier` to `use_clones` to be more explicit and less misleading. ([#368](https://github.com/rasbt/mlxtend/pull/368))


##### Bug Fixes

- Various changes in the documentation and documentation tools to fix formatting issues ([#363](https://github.com/rasbt/mlxtend/pull/363))
- Fixes a bug where the `StackingCVClassifier`'s meta features were not stored in the original order when `shuffle=True` ([#370](https://github.com/rasbt/mlxtend/pull/370))
- Many documentation improvements, including links to the User Guides in the API docs ([#371](https://github.com/rasbt/mlxtend/pull/371))
",22937749
1084,False,False,2018-03-15T02:32:07Z,2018-03-15T02:34:26Z,"##### New Features

-   New function implementing the resampled paired t-test procedure (`paired_ttest_resampled`)
    to compare the performance of two models
    (also called k-hold-out paired t-test). ([#323](https://github.com/rasbt/mlxtend/issues/323))
-   New function implementing the k-fold paired t-test procedure (`paired_ttest_kfold_cv`)
    to compare the performance of two models
    (also called k-hold-out paired t-test). ([#324](https://github.com/rasbt/mlxtend/issues/324))
-   New function implementing the 5x2cv paired t-test procedure (`paired_ttest_5x2cv`) proposed by Dieterrich (1998)
    to compare the performance of two models. ([#325](https://github.com/rasbt/mlxtend/issues/325))
- A `refit` parameter was added to stacking classes (similar to the `refit` parameter in the `EnsembleVoteClassifier`), to support classifiers and regressors that follow the scikit-learn API but are not compatible with scikit-learn's `clone` function. ([#325](https://github.com/rasbt/mlxtend/issues/324))
- The `ColumnSelector` now has a `drop_axis` argument to use it in pipelines with `CountVectorizers`. ([#333](https://github.com/rasbt/mlxtend/pull/333))

##### Changes


- Raises an informative error message if `predict` or `predict_meta_features` is called prior to calling the `fit` method in `StackingRegressor` and `StackingCVRegressor`. ([#315](https://github.com/rasbt/mlxtend/issues/315))
- The `plot_decision_regions` function now automatically determines the optimal setting based on the feature dimensions and supports anti-aliasing. The old `res`  parameter has been deprecated. ([#309](https://github.com/rasbt/mlxtend/pull/309) by [Guillaume Poirier-Morency](https://github.com/arteymix))
- Apriori code is faster due to optimization in `onehot transformation` and the amount of candidates generated by the `apriori` algorithm. ([#327](https://github.com/rasbt/mlxtend/pull/327) by [Jakub Smid](https://github.com/jaksmid))
- The `OnehotTransactions` class (which is typically often used in combination with the `apriori` function for association rule mining) is now more memory efficient as it uses boolean arrays instead of integer arrays. In addition, the `OnehotTransactions` class can be now be provided with `sparse` argument to generate sparse representations of the `onehot` matrix to further improve memory efficiency. ([#328](https://github.com/rasbt/mlxtend/pull/328) by [Jakub Smid](https://github.com/jaksmid))
- The `OneHotTransactions` has been deprecated and replaced by the `TransactionEncoder`. ([#332](https://github.com/rasbt/mlxtend/pull/332)
- The `plot_decision_regions` function now has three new parameters, `scatter_kwargs`, `contourf_kwargs`, and `scatter_highlight_kwargs`, that can be used to modify the plotting style. ([#342](https://github.com/rasbt/mlxtend/pull/342) by [James Bourbeau](https://github.com/jrbourbeau))


##### Bug Fixes

- Fixed issue when class labels were provided to the `EnsembleVoteClassifier` when `refit` was set to `false`. ([#322](https://github.com/rasbt/mlxtend/issues/322))
- Allow arrays with 16-bit and 32-bit precision in `plot_decision_regions` function. ([#337](https://github.com/rasbt/mlxtend/issues/337))
- Fixed bug that raised an indexing error if the number of items was <= 1 when computing association rules using the conviction metric. ([#340](https://github.com/rasbt/mlxtend/issues/340))",22937749
1085,False,False,2017-12-22T18:23:58Z,2017-12-22T18:25:37Z,"##### New Features

- New `store_train_meta_features` parameter for `fit` in StackingCVRegressor. if True, train meta-features are stored in `self.train_meta_features_`.
    New `pred_meta_features` method for `StackingCVRegressor`. People can get test meta-features using this method. ([#294](https://github.com/rasbt/mlxtend/pull/294) via [takashioya](https://github.com/takashioya))
- The new `store_train_meta_features` attribute and `pred_meta_features` method for the `StackingCVRegressor` were also added to the `StackingRegressor`, `StackingClassifier`, and `StackingCVClassifier` ([#299](https://github.com/rasbt/mlxtend/pull/299) & [#300](https://github.com/rasbt/mlxtend/pull/300)) 
- New function (`evaluate.mcnemar_tables`) for creating multiple 2x2 contigency from model predictions arrays that can be used in multiple McNemar (post-hoc) tests or Cochran's Q or F tests, etc. ([#307](https://github.com/rasbt/mlxtend/issues/307))
- New function (`evaluate.cochrans_q`) for performing Cochran's Q test to compare the accuracy of multiple classifiers. ([#310](https://github.com/rasbt/mlxtend/issues/310))

##### Changes

- Added `requirements.txt` to `setup.py`. ([#304](https://github.com/rasbt/mlxtend/issues/304) via [Colin Carrol](https://github.com/ColCarroll))


##### Bug Fixes

- Improved numerical stability for p-values computed via the the exact McNemar test ([#306](https://github.com/rasbt/mlxtend/issues/306))
- `nose` is not required to use the library ([#302](https://github.com/rasbt/mlxtend/issues/302))",22937749
1086,False,False,2017-11-19T07:18:35Z,2017-11-19T07:24:49Z,"### Version 0.9.1 (2017-11-19)

##### Downloads

- [Source code (zip)](https://github.com/rasbt/mlxtend/archive/v0.9.1.zip)
- [Source code (tar.gz)](https://github.com/rasbt/mlxtend/archive/v0.9.1.tar.gz)

##### New Features

- Added `mlxtend.evaluate.bootstrap_point632_score` to evaluate the performance of estimators using the .632 bootstrap. ([#283](https://github.com/rasbt/mlxtend/pull/283))
- New `max_len` parameter for the frequent itemset generation via the `apriori` function to allow for early stopping. ([#270](https://github.com/rasbt/mlxtend/pull/270))

##### Changes

- All feature index tuples in `SequentialFeatureSelector` or now in sorted order. ([#262](https://github.com/rasbt/mlxtend/pull/262))
- The `SequentialFeatureSelector` now runs the continuation of the floating inclusion/exclusion as described in Novovicova & Kittler (1994). 
Note that this didn't cause any difference in performance on any of the test scenarios but could lead to better performance in certain edge cases. 
([#262](https://github.com/rasbt/mlxtend/pull/262))
- `utils.Counter` now accepts a name variable to help distinguish between multiple counters, time precision can be set with the 'precision' kwarg and the new attribute end_time holds the time the last iteration completed. ([#278](https://github.com/rasbt/mlxtend/pull/278) via [Mathew Savage](https://github.com/matsavage))


##### Bug Fixes

- Fixed an deprecation error that occured with McNemar test when using SciPy 1.0. ([#283](https://github.com/rasbt/mlxtend/pull/283))",22937749
1087,False,False,2017-10-22T00:30:13Z,2017-10-22T00:31:03Z,"##### New Features

- Added `evaluate.permutation_test`, a permutation test for hypothesis testing (or A/B testing) to test if two samples come from the same distribution. Or in other words, a procedure to test the null hypothesis that that two groups are not significantly different (e.g., a treatment and a control group). ([#250](https://github.com/rasbt/mlxtend/pull/250))
- Added `'leverage'` and `'conviction` as evaluation metrics to the `frequent_patterns.association_rules` function. ([#246](https://github.com/rasbt/mlxtend/pull/246) & [#247](https://github.com/rasbt/mlxtend/pull/247))
- Added a `loadings_` attribute to `PrincipalComponentAnalysis` to compute the factor loadings of the features on the principal components. ([#251](https://github.com/rasbt/mlxtend/pull/251))
- Allow grid search over classifiers/regressors in ensemble and stacking estimators. ([#259](https://github.com/rasbt/mlxtend/pull/259))
- New `make_multiplexer_dataset` function that creates a dataset generated by a n-bit Boolean multiplexer for evaluating supervised learning algorithms. ([#263](https://github.com/rasbt/mlxtend/pull/263))
- Added a new `BootstrapOutOfBag` class, an implementation of the out-of-bag bootstrap to evaluate supervised learning algorithms. ([#265](https://github.com/rasbt/mlxtend/pull/265))
- The parameters for `StackingClassifier`, `StackingCVClassifier`, `StackingRegressor`, `StackingCVRegressor`, and `EnsembleVoteClassifier` can now be tuned using scikit-learn's `GridSearchCV` ([#254](https://github.com/rasbt/mlxtend/pull/254) via [James Bourbeau](https://github.com/jrbourbeau))


##### Changes

- The `'support'` column returned by `frequent_patterns.association_rules` was changed to compute the support of ""antecedant union consequent"", and new `antecedant support'` and `'consequent support'` column were added to avoid ambiguity. ([#245](https://github.com/rasbt/mlxtend/pull/245))
- Allow the `OnehotTransactions` to be cloned via scikit-learn's `clone` function, which is required by e.g., scikit-learn's `FeatureUnion` or `GridSearchCV` (via [Iaroslav Shcherbatyi](https://github.com/iaroslav-ai)). ([#249](https://github.com/rasbt/mlxtend/pull/249))

##### Bug Fixes

- Fix issues with `self._init_time` parameter in `_IterativeModel` subclasses. ([#256](https://github.com/rasbt/mlxtend/pull/256))
- Fix imprecision bug that occurred in `plot_ecdf` when run on Python 2.7. ([264](https://github.com/rasbt/mlxtend/pull/264))
- The vectors from SVD in `PrincipalComponentAnalysis` are no being scaled so that the eigenvalues via `solver='eigen'` and `solver='svd'` now store eigenvalues that have the same magnitudes. ([#251](https://github.com/rasbt/mlxtend/pull/251))",22937749
1088,False,False,2017-09-09T08:46:37Z,2017-09-09T08:47:55Z,"##### Downloads

- [Source code (zip)](https://github.com/rasbt/mlxtend/archive/v0.8.0.zip)
- [Source code (tar.gz)](https://github.com/rasbt/mlxtend/archive/v0.8.0.tar.gz)

##### New Features

- Added a `mlxtend.evaluate.bootstrap` that implements the ordinary nonparametric bootstrap to bootstrap a single statistic (for example, the mean. median, R^2 of a regression fit, and so forth) [#232](https://github.com/rasbt/mlxtend/pull/232)
- `SequentialFeatureSelecor`'s `k_features` now accepts a string argument ""best"" or ""parsimonious"" for more ""automated"" feature selection. For instance, if ""best"" is provided, the feature selector will return the feature subset with the best cross-validation performance. If ""parsimonious"" is provided as an argument, the smallest feature subset that is within one standard error of the cross-validation performance will be selected. [#238](https://github.com/rasbt/mlxtend/pull/238)

##### Changes

- `SequentialFeatureSelector` now uses `np.nanmean` over normal mean to support scorers that may return `np.nan`  [#211](https://github.com/rasbt/mlxtend/pull/211) (via [mrkaiser](https://github.com/mrkaiser))
- The `skip_if_stuck` parameter was removed from `SequentialFeatureSelector` in favor of a more efficient implementation comparing the conditional inclusion/exclusion results (in the floating versions) to the performances of previously sampled feature sets that were cached [#237](https://github.com/rasbt/mlxtend/pull/237)
- `ExhaustiveFeatureSelector` was modified to consume substantially less memory [#195](https://github.com/rasbt/mlxtend/pull/195) (via [Adam Erickson](https://github.com/adam-erickson))

##### Bug Fixes

- Fixed a bug where the `SequentialFeatureSelector` selected a feature subset larger than then specified via the `k_features` tuple max-value [#213](https://github.com/rasbt/mlxtend/pull/213)",22937749
1089,False,False,2017-06-23T03:35:22Z,2017-06-23T03:36:58Z,"### Version 0.7.0 (2017-06-22)


##### New Features

- New [mlxtend.plotting.ecdf](http://rasbt.github.io/mlxtend/user_guide/plotting/ecdf/) function for plotting empirical cumulative distribution functions ([#196](https://github.com/rasbt/mlxtend/pull/196)).
- New [`StackingCVRegressor`](http://rasbt.github.io/mlxtend/user_guide/regressor/StackingCVRegressor/) for stacking regressors with out-of-fold predictions to prevent overfitting ([#201](https://github.com/rasbt/mlxtend/pull/201)via [Eike Dehling](https://github.com/EikeDehling)).

##### Changes

- The TensorFlow estimator have been removed from mlxtend, since TensorFlow has now very convenient ways to build on estimators, which render those implementations obsolete.
- `plot_decision_regions` now supports plotting decision regions for more than 2 training features [#189](https://github.com/rasbt/mlxtend/pull/189), via [James Bourbeau](https://github.com/jrbourbeau)).
- Parallel execution in `mlxtend.feature_selection.SequentialFeatureSelector` and `mlxtend.feature_selection.ExhaustiveFeatureSelector` is now performed over different feature subsets instead of the different cross-validation folds to better utilize machines with multiple processors if the number of features is large ([#193](https://github.com/rasbt/mlxtend/pull/193), via [@whalebot-helmsman](https://github.com/whalebot-helmsman)).
- Raise meaningful error messages if pandas `DataFrame`s or Python lists of lists are fed into the `StackingCVClassifer` as a `fit` arguments ([198](https://github.com/rasbt/mlxtend/pull/198)).
- The `n_folds` parameter of the `StackingCVClassifier` was changed to `cv` and can now accept any kind of cross validation technique that is available from scikit-learn. For example, `StackingCVClassifier(..., cv=StratifiedKFold(n_splits=3))` or `StackingCVClassifier(..., cv=GroupKFold(n_splits=3))` ([#203](https://github.com/rasbt/mlxtend/pull/203), via [Konstantinos Paliouras](https://github.com/sque)).

##### Bug Fixes

- `SequentialFeatureSelector` now correctly accepts a `None` argument for the `scoring` parameter to infer the default scoring metric from scikit-learn classifiers and regressors ([#171](https://github.com/rasbt/mlxtend/pull/171)).
- The `plot_decision_regions` function now supports pre-existing axes objects generated via matplotlib's `plt.subplots`. ([#184](https://github.com/rasbt/mlxtend/pull/184), [see example](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/#example-6-working-with-existing-axes-objects-using-subplots))
- Made `math.num_combinations` and `math.num_permutations` numerically stable for large numbers of combinations and permutations ([#200](https://github.com/rasbt/mlxtend/pull/200)).
",22937749
1090,False,False,2017-03-18T22:50:04Z,2017-03-18T22:52:27Z,"### Version 0.6.0 (2017-03-18)


##### Downloads

- [Source code (zip)](https://github.com/rasbt/mlxtend/archive/v0.6.0.zip)
- [Source code (tar.gz)](https://github.com/rasbt/mlxtend/archive/v0.6.0.tar.gz)

##### New Features

- An `association_rules` function is implemented that allows to generate rules based on a list of frequent itemsets (via [Joshua Goerner](https://github.com/JoshuaGoerner)).

##### Changes

- Adds a black `edgecolor` to plots via `plotting.plot_decision_regions` to make markers more distinguishable from the background in `matplotlib>=2.0`.
- The `association` submodule was renamed to `frequent_patterns`.

##### Bug Fixes

- The `DataFrame` index of `apriori` results are now unique and ordered.
",22937749
1091,False,False,2017-02-14T06:24:31Z,2017-02-14T06:26:08Z,"### Version 0.5.1 (2017-02-14)

The CHANGELOG for the current development version is available at
[https://github.com/rasbt/mlxtend/blob/master/docs/sources/CHANGELOG.md](https://github.com/rasbt/mlxtend/blob/master/docs/sources/CHANGELOG.md).

##### New Features
- The `EnsembleVoteClassifier` has a new `refit` attribute that prevents refitting classifiers if `refit=False` to save computational time.
- Added a new `lift_score` function in `evaluate` to compute lift score (via [Batuhan Bardak](https://github.com/bbardakk)).
- `StackingClassifier` and `StackingRegressor` support multivariate targets if the underlying models do (via [kernc](https://github.com/kernc)).
- `StackingClassifier` has a new `use_features_in_secondary` attribute like `StackingCVClassifier`.

##### Changes
- Changed default verbosity level in `SequentialFeatureSelector` to 0
- The `EnsembleVoteClassifier` now raises a `NotFittedError` if the estimator wasn't `fit` before calling `predict`. (via [Anton Loss](https://github.com/avloss))
- Added new TensorFlow variable initialization syntax to guarantee compatibility with TensorFlow 1.0

##### Bug Fixes
- Fixed wrong default value for `k_features` in `SequentialFeatureSelector`
- Cast selected feature subsets in the `SequentialFeautureSelector` as sets to prevent the iterator from getting stuck if the `k_idx` are different permutations of the same combination (via [Zac Wellmer](https://github.com/zacwellmer)).
- Fixed an issue with learning curves that caused the performance metrics to be reversed (via [ipashchenko](https://github.com/ipashchenko))
- Fixed a bug that could occur in the `SequentialFeatureSelector` if there are similarly-well performing subsets in the floating variants (via [Zac Wellmer](https://github.com/zacwellmer)).
",22937749
1092,False,False,2016-11-11T07:19:06Z,2016-11-11T07:20:14Z,"### Version 0.5.0

##### Downloads
- [Source code (zip)](https://github.com/rasbt/mlxtend/archive/0.5.0.zip)
- [Source code (tar.gz)](https://github.com/rasbt/mlxtend/archive/v0.5.0.tar.gz)

##### New Features
- New `ExhaustiveFeatureSelector` estimator in `mlxtend.feature_selection` for evaluating all feature combinations in a specified range
- The `StackingClassifier` has a new parameter `average_probas` that is set to `True` by default to maintain the current behavior. A deprecation warning was added though, and it will default to `False` in future releases (0.6.0); `average_probas=False` will result in stacking of the level-1 predicted probabilities rather than averaging these.
- New `StackingCVClassifier` estimator in 'mlxtend.classifier' for implementing a stacking ensemble that uses cross-validation techniques for training the meta-estimator to avoid overfitting ([Reiichiro Nakano](https://github.com/reiinakano))
- New `OnehotTransactions` encoder class added to the `preprocessing` submodule for transforming transaction data into a one-hot encoded array
- The `SequentialFeatureSelector` estimator in `mlxtend.feature_selection` now is safely stoppable mid-process by control+c, and deprecated print_progress in favor of a more tunable verbose parameter ([Will McGinnis](https://github.com/wdm0006))
- New `apriori` function in `association` to extract frequent itemsets from transaction data for association rule mining
- New `checkerboard_plot` function in `plotting` to plot checkerboard tables / heat maps
- New `mcnemar_table` and `mcnemar` functions in `evaluate` to compute 2x2 contingency tables and McNemar's test

##### Changes
- All plotting functions have been moved to `mlxtend.plotting` for compatibility reasons with continuous integration services and to make the installation of `matplotlib` optional for users of `mlxtend`'s core functionality
- Added a compatibility layer for `scikit-learn 0.18` using the new `model_selection` module  while maintaining backwards compatibility to scikit-learn 0.17.

##### Bug Fixes
- `mlxtend.plotting.plot_decision_regions` now draws decision regions correctly if more than 4 class labels are present
- Raise `AttributeError` in `plot_decision_regions` when the `X_higlight` argument is a 1D array ([chkoar](https://github.com/chkoar))
",22937749
1093,False,False,2016-08-25T02:42:23Z,2016-08-25T02:43:31Z,"### Version 0.4.2 (2016-08-24)

##### New Features
- Added `preprocessing.CopyTransformer`, a mock class that returns copies of
  imput arrays via `transform` and `fit_transform`

##### Changes
- Added AppVeyor to CI to ensure MS Windows compatibility
- Dataset are now saved as compressed .txt or .csv files rather than being imported as Python objects
- `feature_selection.SequentialFeatureSelector` now supports the selection of `k_features` using a tuple to specify a ""min-max"" `k_features` range
- Added ""SVD solver"" option to the `PrincipalComponentAnalysis`
- Raise a `AttributeError` with ""not fitted"" message in `SequentialFeatureSelector` if `transform` or `get_metric_dict` are called prior to `fit`
- Use small, positive bias units in `TfMultiLayerPerceptron`'s hidden layer(s) if the activations are ReLUs in order to avoid dead neurons
- Added an optional `clone_estimator` parameter to the `SequentialFeatureSelector` that defaults to `True`, avoiding the modification of the original estimator objects
- More rigorous type and shape checks in the `evaluate.plot_decision_regions` function
- `DenseTransformer` now doesn't raise and error if the input array is _not_ sparse
- API clean-up using scikit-learn's `BaseEstimator` as parent class for `feature_selection.ColumnSelector`

##### Bug Fixes
- Fixed a problem when a tuple-range was provided as argument to the `SequentialFeatureSelector`'s `k_features` parameter and the scoring metric was more negative than -1 (e.g., as in scikit-learn's MSE scoring function) via [wahutch](https://github.com/wahutch)
- Fixed an `AttributeError` issue when `verbose` > 1 in `StackingClassifier`
- Fixed a bug in `classifier.SoftmaxRegression` where the mean values of the offsets were used to update the bias units rather than their sum
- Fixed rare bug in MLP `_layer_mapping` functions that caused a swap between the random number generation seed when initializing weights and biases
",22937749
1094,False,False,2016-05-02T00:15:44Z,2016-05-02T00:17:23Z,"### Version 0.4.1 (2016-05-01)

##### New Features
- New TensorFlow estimator for Linear Regression ([`tf_regressor.TfLinearRegression`](./user_guide/tf_regressor/TfLinearRegression.md))
- New k-means clustering estimator ([`cluster.Kmeans`](./user_guide/cluster/Kmeans.md))
- New TensorFlow k-means clustering estimator ([`tf_cluster.Kmeans`](./user_guide/tf_cluster/TfKmeans.md))

##### Changes
- Due to refactoring of the estimator classes, the `init_weights` parameter of the `fit` methods was globally renamed to `init_params`
- Overall performance improvements of estimators due to code clean-up and refactoring
- Added several additional checks for correct array types and more meaningful exception messages
- Added optional `dropout` to the [`tf_classifier.TfMultiLayerPerceptron`](./user_guide/tf_classifier/TfMultiLayerPerceptron.md) classifier for regularization
- Added an optional `decay` parameter to the [`tf_classifier.TfMultiLayerPerceptron`](./user_guide/tf_classifier/TfMultiLayerPerceptron.md) classifier for adaptive learning via an exponential decay of the learning rate eta
- Replaced old `NeuralNetMLP` by more streamlined `MultiLayerPerceptron` ([`classifier.MultiLayerPerceptron`](./user_guide/classifier/MultiLayerPerceptron.md)); now also with softmax in the output layer and categorical cross-entropy loss.
- Unified `init_params` parameter for fit functions to continue training where the algorithm left off (if supported)
",22937749
1095,False,False,2016-02-01T00:58:17Z,2016-02-01T01:03:12Z,"### Version 0.3.0 (2016-01-31)
- The `mlxtend.preprocessing.standardize` function now optionally returns the parameters, which are estimated from the array, for re-use. A further improvement makes the `standardize` function smarter in order to avoid zero-division errors
- Added a progress bar tracker to `classifier.NeuralNetMLP`
- Added a function to score predicted vs. target class labels `evaluate.scoring`
- Added confusion matrix functions to create (`evaluate.confusion_matrix`) and plot (`evaluate.plot_confusion_matrix`) confusion matrices
- Cosmetic improvements to the `evaluate.plot_decision_regions` function such as hiding plot axes
- Renaming of `classifier.EnsembleClassfier` to `classifier.EnsembleVoteClassifier`
- Improved random weight initialization in `Perceptron`, `Adaline`, `LinearRegression`, and `LogisticRegression`
- Changed `learning` parameter of `mlxtend.classifier.Adaline` to solver and added ""normal equation"" as closed-form solution solver
- New style parameter and improved axis scaling in `mlxtend.evaluate.plot_learning_curves`
- Hide y-axis labels in `mlxtend.evaluate.plot_decision_regions` in 1 dimensional evaluations
- Added `loadlocal_mnist` to `mlxtend.data` for streaming MNIST from a local byte files into numpy arrays
- New `NeuralNetMLP` parameters: `random_weights`, `shuffle_init`, `shuffle_epoch`
- Sequential Feature Selection algorithms were unified into a single `SequentialFeatureSelector` class with parameters to enable floating selection and toggle between forward and backward selection.
- New `SFS` features such as the generation of pandas `DataFrame` results tables and plotting functions (with confidence intervals, standard deviation, and standard error bars)
- Added support for regression estimators in `SFS`
- Stratified sampling of MNIST (now 500x random samples from each of the 10 digit categories)
- Added Boston `housing dataset`
- Renaming `mlxtend.plotting` to `mlxtend.general_plotting` in order to distinguish general plotting function from specialized utility function such as `evaluate.plot_decision_regions`
- Shuffle fix and new shuffle parameter for classifier.NeuralNetMLP
",22937749
1096,False,False,2015-10-16T00:12:37Z,2015-01-16T05:31:11Z,,22937749
1097,False,False,2020-03-04T21:06:02Z,2020-03-04T22:10:23Z," **IMPORTANT**: If you are using the built-in database you cannot upgrade automatically.
 
 * Update chart requirement for postgres database.
 * Update chart to be compatible with k8s 1.17.
 * Update K8S manager to use v1 and stable APIs.
 * Update deployment (notebooks and tensorboards) to be compatible with K8S 1.17.
 * Update admin CLI commands to target Helm 3 by default.
 * Fix issue with tensorboard v2, add `--host` flag.",77383688
1098,False,False,2020-01-13T03:01:54Z,2020-01-13T03:48:07Z," * Update chart to be compatible with k8s 1.16.
    * N.B. postgres dependency was not updated in this release to provide compatible upgrade with deployment running the built-in database, if you want to have a fully compatible you have to provide your own db.
 * Fix issue with scheduling parallel distributed runs.
 * Fix issue with sort by a metric containing null values, add null last to queries.
 * Fix warning issues in CLI.
 * Fix some security issues.
 * Add docs for helm 3 deploy command.
 * Add keras tracking contrib module.
 * Disable telemetry by default.
 * Fix some package dependency issues.",77383688
1099,False,False,2019-08-15T17:17:28Z,2019-08-15T20:17:35Z," * Allow code download based on commits in CLI: `polyaxon project download --commit=...`
 * Allow code download related to an experiment/job/build in CLI: e.g. `polyaxon experiment -xp 123 code`
 * Fix issue with experiment resume cleaning the experiment's outputs.
 * Fix some docs refs and issues.
",77383688
1100,False,False,2019-08-03T12:52:13Z,2019-08-03T13:09:44Z," * Fix regression in last metric saving (Last metric should always output the last metric from all previous steps).
 * Fix regression registering wrong queue for handling remote logs.
 * Fix regression order-by metrics does not proxy to the correct field.
 * Fix issue in Polystores: GCS might include empty blob names.
 * Add eventual pod restart handling for init process.
 * Update deps with security release.
 * Add docs for elastic stack config for on-prem deployments.",77383688
1101,False,False,2019-07-26T18:26:40Z,2019-07-26T18:28:32Z," * Increase internal API throttling.
 * Make throttle rates configurable.
 * Expose more verbose uwsgi logging for DEBUG and INFO levels.
 * Use monospaced font and correct whitespace in logs viewer.
 * Update notebook spawner to allow downloading artifcats/code: set allow_origin to ""*"".
 * Expose ingress's path configuration.
 * Remove wrong order check on HP tuning Matrix schemas, should be applied only to ranges and not distributions.   
 * Add platform version to footer.
 * Fix bool option's UI dropdown not handling initial state correctly.
 * Fix issue with security context not reflected in the dockerfile template.
 * Fix issue with init container not setting auth context correctly.
 * Fix SSO docs.
 * Fix impersonate urls typos (API and clients).",77383688
1102,False,False,2019-07-18T22:56:52Z,2019-07-18T22:57:45Z," * Upgrade python to 3.7.4.
 * Update default kaniko image tag to v0.9.0.
 * Add note about using pgbouncer for scaling connexions to DB. 
 * Add a conf caching mechanism to prevent hitting the db frequently when requesting config options.
 * Update default admin pages for builds, jobs, experiments, groups, tensorboards, notebooks.
 * Fix issue with registry access update form.
 * Add better handling for refresh auth tokens.
 * Make more defensive confirmation dialog by emphasising entities and actions.
 * Make project deletion harder by requiring the user to enter the project name.
 * Add more CLI checks for dependencies during deployment.
 * Make code path resolving consistent between local run and platform run.
 * Expose `maxConnAge` configuration option for both in-cluster and external postgresql connexion. 
 * Force user to re-login when token expires.
 * Make stream API internal.
 * Internal improvements.",77383688
1103,False,False,2019-07-13T18:40:59Z,2019-07-13T18:59:26Z," * Add asset version context processor.
 * Remove settings dropdown condition on admin interface.
 * Update health and status checks urls to follow best practices.
 * Fix jobs artifacts logging. 
 * Fix dockerfile path resolution for local runs.
 * Add a simple way to inject debug mode command (only CLI side).
 * Fix issue displaying artifacts for S3 stores.
 * Add docs for using Minio for logs/data/artifacts.",77383688
1104,False,False,2019-07-11T10:02:36Z,2019-07-11T11:02:11Z," * Add possibility to specify pod annotations for jobs/experiments/builds/notebooks/tensorboards.
   * By default polyaxon will inject necessary annotations, e.g. when using TPU.
   * Users can now define default annotations for each primitive cluster wide.
   * Polyaxonfile spec allows to override the annotations per run.
 * Add possibility to specify custom pod labels for jobs/experiments/builds/notebooks/tensorboards.
   * By default polyaxon uses recommended k8s labels for all managed resources.
   * Users can now define default custom labels for each primitive cluster wide.
   * Polyaxonfile spec allows to override the labels per run.
   * N.B. The custom labels cannot override Polyaxon's required labels.
 * strengthen statuses check and fall back to db check if keys are evicted.
 * Disable namespace monitoring by default.
 * Disable containers resources monitoring by default.
 * Expose several celery options by worker type.
 * Force rabbitmq confirmation when used as a broker by default.
 * Add gzip to list APIs by default
 * Remove parts requiring privileged mode when deploying Polyaxon.
 * Fix in-cluster redis node scheduling docs: uses master/slave.
 * Fix Helm chart validation when disabling docker-registry.
 * Fix issue detecting some local configs when running polyaxonfiles locally (use_https was not detected correctly).
 * Fix quick creation modes in UI.
 * Fix route for creating Tensorboard in UI.
 * Fix UI issues noticed in offline deployment: self-host all styling requirements.
 * Fix spelling in UI.
 * Fix polyaxonfile spec unable to handle quotes in commands.
 * Update lodash: vulnerability issue.",77383688
1105,False,False,2019-07-05T15:08:05Z,2019-07-05T15:08:23Z,"**If you are upgrading from v0.4, please check the [migration docs](https://docs.polyaxon.com/resources/migration/).**

 * Add ""Cluster Level Dynamic Configuration"":
   * Move scheduling configuration to UI.
   * Move integrations to UI.
   * Move secrets and config maps catalogs to UI.
   * Move github/gitlab/bitbucket/azure authentication setup to UI.
   * Move private repos setup to UI.
   * More hardware accelerator setup to UI.
   * Add possibility to create an access catalog for registries and git repos.
   * Add possibility to create an access catalog for connections, data, logs, outputs. 
   * Move kaniko, default tensorboards config, default notebooks config to UI.  
 * Introduce security group with optional and configurable user UID and group GID for all Polyaxon services and scheduled runs.
 * Mount all volumes with the proper security context.
 * Add a warning when code is big.
 * Add possibility to specify a service account for jobs/experiments/builds/notebooks/tensorboards.
   * By default polyaxon uses a worker service account.
   * Users can now use a default service account for each primitive cluster wide.
   * Polyaxonfile spec allows to override the service account per run.
 * Add possibility to specify a default resources to use for jobs/experiments/builds/notebooks/tensorboards.
   * By default polyaxon schedules runs without resources.
   * Users can now set default resources to use for each primitive cluster wide.
   * Polyaxonfile spec allows to override the resources per run.
 * Add pod restarts.
   * By default polyaxon schedules runs without pod restarts.
   * Users can now set a default pod restarts to use for each primitive cluster wide.
   * Polyaxonfile spec allows to override the pod restarts per run.
 * Add minimum resources requirement for injected containers (init and sidecar).
   * This will fix the issue in clusters with pod security policy requiring that all pods must specify resources. 
 * Update redis chart and support using external/managed redis instance.
 * Update rabbitmq chart and support using external/managed rabbitmq instance.
 * Update docker-registry chart and support using external/managed docker registries.
 * Add possibility to turn-off rabbitmq completely and use Redis as broker instead.
 * Make .polyaxonignore honour .gitignore syntax.
 * Rename declarations section to params.
 * Add typing to Polyaxonfiles and schemas.
 * Extract polyaxon dockerizer logic to reuse in other environments.
 * Add possibility to run polyaxonfiles and update params without changing the yaml files: `polyaxon run -f polyaxonfile.yaml -P param1=value1 -P param2=value2`.
 * Add possibility to run polyaxonfiles locally. 
   * Allow to run experiments (non-distributed) locally either by invoking a python code with a conda/pip env or by generating a dockerfile, with out-of-the box tracking if POLYAXON_NO_OP is not set to true.
 * Deprecate docker registry authentication using user/password in favor of credential stores and credential helpers.
 * Add documentation for using ECR as Docker registry.
 * Mark kaniko stable: possibility to pull / push from any docker registry.
 * Mark jupyter lab stable.
 * Add sorting for outputs.
 * Update internal architecture to allow development and extending the platform with internal plugins.
 * Expose one single port for accessing all internal Polyaxon's APIs.
 * Update e2e tests with different deployments configurations.
 * Extend input schema to allow users to easily convert boolean params to flags in polyaxonfiles.
 * Add caching layer when checking statuses.
 * Add encryptor for managing sensitive data in-cluster with future possibility to use vault as a backend, currently the backend uses fernet encryption.
 * Add possibility to search entities by name or description using regex. 
 * Improve deployment using CLI, add new command: `polyaxon admin`.
 * Extend build kind with `lang_env` to easily export language environment.
 * Add initial work on early stopping policies for hyperparams tuning.
 * Add possibility to install auto-completion for polyaxon CLI.
 * Add possibility to invalidate individual builds and builds under a project.
 * Update API logic to save raw content to post-resolve contexts.
 * Add admin deploy/upgrade --dry_run commands for debugging purposes.
 * Add alpha version of Polyaxon on docker-compose.
 * Allow verify_ssl to be turned on via the CLI.
 * Improve init container stability by introducing retry on ConnectionError.
 * Improve docs for ingress's annotations.
 * Fix issues in log_artifact and log_artifacts.
 * Fix issue with default ssl path: SSL with node port service should not mount certs in /etc/ssl by default.
 * Fix issue when updating the internal API port.
 * Fix issue when using S3 as outputs storage.
 * Fix issue with the Helm chart not working correctly when RBAC is disabled (This is issue was noticed in Minikube with RBAC disabled).
 * Fix issue preventing to install Polyaxon with the latest helm version.
 * Fix issue with default build backend being ignored in some instances.
 * Fix issue breaking Jupyter lab theme in some recent versions.
 * Fix issue with scheduling S3 credentials for tensorboards.
 * Fix Experiment restart --copy creating additional folder.
 * Fix restart and resume experiments in groups not adding the new experiment to the same group.
 * Add resume button to UI. 
 * Add tensorflow tracking to contrib.
 * Improve keras tracking.
 * Add fastai tracking to contrib.
 * Remove several dependencies and replace with simple utils functions.
 * Add initial data/artifacts/logs stores and catalogs.
 * Add initial documentation for Polyflow: an actions/events pipeline engine for creating and automating machine learning workflows.
   * Allow to run ops in parallel while respecting concurrency in pipelines.
   * Allow to run pipelines following schedules: 2 interfaces intervals and crons.
   * Allow to run pipelines with complex ops dependencies as DAGs.
   * All to resolve ops' definitions, from inline templates, local templates, registries of actions/events.
   * Add initial work on supporting airflow out-of-the-box or possibility to easily port ops to Polyaxon to run container native operations.
 * Add templating for operationalizing and reusing Polyaxon's experiments and jobs.",77383688
1106,False,True,2019-07-04T11:26:36Z,2019-07-04T11:27:35Z,,77383688
1107,False,True,2019-07-01T15:37:15Z,2019-07-01T15:38:24Z,,77383688
1108,False,True,2019-07-01T13:08:58Z,2019-07-01T13:31:05Z,,77383688
1109,False,True,2019-06-30T16:55:54Z,2019-06-30T18:02:38Z,,77383688
1110,False,False,2019-04-15T18:31:39Z,2019-04-10T10:11:42Z,"This is a patch release on top of 0.4.3/0.4.2 containing no breaking changes., this version has no data or db migrations.

 * Fix issue with IntegrityError when creating large number of experiments.
 * Add error validation and redirection when creating experiments selection.
 * Add alpha version of configurable security context.
 * Update Polyaxon deploy to handle Minikube and MicroK8S.
 * Optimize and reduce size of official images.
 * Add dockgen package and initial work on local run mode.
 * Add docs for Polyaxon Client authentication options.
 * Update `log_artifact` and `log_artifacts` methods on the Experiment tracking API as an alternative to `experiment.outputs_stores.upload_file/dir`.
 * Fix Polyaxon Chart ingress issues and typos.",77383688
1111,False,True,2019-04-09T15:02:30Z,2019-04-09T15:03:37Z,,77383688
1112,False,True,2019-04-09T11:59:35Z,2019-04-09T12:00:43Z,,77383688
1113,False,False,2019-04-04T14:06:46Z,2019-04-04T07:53:23Z," * Re-enable possibility to create projects from dashboard.
 * Add possibility to create experiments, groups, jobs, and builds from dashboard
   * Different creation modes
   * Creation from current project or from top level by choosing a project
 * Add possibility to start notebooks for projects and tensorboards for projects, experiments, groups from the dashboard.
 * Add possibility to restart experiments from the dashboard.
 * Add tables for notebooks and tensorboards on the dashboard to easily see which tensorboards/notebooks are running or failing and their statuses.
 * Add possibility to stop notebooks and tensorboards from dashboard without going to the individual experiment/group/project. 
 * Add support for multiple secrets in ingress TLS.
 * Add support for Custom Cluster DNS resolvers.
 * Add support for any DNS backend, users deploying Polyaxon on Kubernetes created by Kubespray won't have to switch DNS from CoreDNS to KubeDNS anymore.
 * Add error handling for searches and metric views creation on dashboard.
 * Add proper error handling for dashboard forms and search UIs, show errors generated by frontend validation and server side validation.
 * Add loading indicators to differentiate between non-found entities and fetch in-progress.
 * Add notebooks and tensorboards search APIs.
 * Add several new fields to the search managers.
 * Move NFS-Provisioner from Polyaxon Chart to a separate repo, users can use the NFS-PROVISIONER maintained Helm chart 
   to deploy an NFS server to create MultiReadWrite volumes to use with Polyaxon. 
 * Add documentation on how to use the Provisioner for different aspects of the platform, i.e. data, logs, outputs, ...
 * Remove NGINX Ingress from Polyaxon chart, and create documentation on how to use setup an NGINX Ingress from the stable chart. 
   Users can also bring their own Ingress controller to use with the ingress resource provided in the chart. Polyaxon should work any ingress controller, 
   and docs will be updated to show how to use the major ones.
 * Add missing fields to the polyaxon deploy spec validation.
 * Add `polyaxon deploy` to deployment docs as it is now stable.
 * Add alpha version for parcoords visualization to experiment groups.
 * Add proper editor to show configs, dockerfiles, polyaxonfiles on the dashboard. 
 * Update searches and add some default searches (running, succeeded, and failed), more work to improve UI for creating searches and filters in the upcoming versions.
 * Fix issue with Docker client unable to authenticate to private DockerHub registries.
 * Add new docs section to show specific params needed to use private images on DockerHub.
 * Add SSL docs.
 * Add better handling for creating searches with similar names.
 * Update streams errors handling.
 * Fix some encoding issues and auth error handling in CLI.
 * Add docs/refs url shortcuts on the dashboard header. 
 * Update some packages that have some security and deprecation problems.
 * Remove `eventMonitors` from list of services to scale to prevent duplication of monitored cluster events, 
   and set it to a singleton on the chart to prevent other users from changing the value.
 * Several other internal fixes and improvements.
 * Fix issue requiring users to manually invalidate browser cache.",77383688
1114,False,True,2019-04-03T22:54:35Z,2019-04-03T22:55:24Z,,77383688
1115,False,True,2019-04-03T19:06:01Z,2019-04-03T19:07:20Z,,77383688
1116,False,True,2019-04-02T16:44:03Z,2019-04-02T16:45:54Z,,77383688
1117,False,False,2019-03-15T09:01:35Z,2019-03-14T12:26:55Z," * Add support of native Horovod experiments.
 * Add new fields for experiments: backend and framework.
   * Framework can be used for any experiment as a special field/tag.
   * When using distributed experiments, some frameworks are recognized and will trigger a particular behaviour.
   * Default backend is `native`, i.e. Polyaxon's native behaviour for spawning experiments, 
   additionally users can start distributed experiments on Kubeflow, by changing the backend field to `kubeflow`.
 * Add helm charts to easily deploy TFJob, PytorchJob, and MPIJob without requiring the user to install a full Kubeflow deployment.
 * Add spawners for distributed experiments on Kubeflow's operators: TFJob, PytorchJob, MPIJob.
 * Update distributed experiments logs handling
   * Streaming experiment's logs show all logs.
   * User can stream specific job's logs.
   * Experiment UI shows default job's logs + user can check specific logs of each job.
 * Update schema validation: now extra values or wrong values, even in nested sub-schemas, will raise a validation error.
 * Update icons version.
 * Polyaxon deploy is now in public beta and will be the recommended way to deploy/upgrade the platform.
 * Extend the build subsection behaviour to accepts an environment as well, now users can set the build resources and selectors for the build inside jobs and experiments.
 * Add possibility to download individual outputs files.
 * Fix a regression when downloading outputs from GCS.
 * Fix some issues with outputs tree view.
 * Fix some log formatting issues.
 * Fix readme style issues.
 * Fix some UI issues.
 * Fix some edge cases discovered when using Hyperband.
 * Fix an issue related to pending and initializing statuses not recognised correctly.
 * Several misc regressions fixed and internal enhancements.  ",77383688
1118,False,True,2019-03-14T08:48:30Z,2019-03-14T08:49:14Z,,77383688
1119,False,True,2019-03-14T01:11:55Z,2019-03-14T01:14:03Z,,77383688
1120,False,True,2019-03-13T17:45:13Z,2019-03-13T17:46:55Z,,77383688
1121,False,False,2019-03-01T03:14:12Z,2019-03-01T00:18:38Z," * Add UI for experiment jobs (overview, logs, statuses).
 * Improve logging and logs archiving of distributed experiments.
 * Improve the header's tooltip behaviour.
 * Improve experiment UI by reducing number of tabs.
 * Improve a couple of queries resulting in large memory consumption.
 * Improve CI sync function to handle: 
   * Updating access tokens.
   * Force push mechanism.
   * Fetching of new branches
 * Fix build branch and commit handling, remove `ref` and add a more explicit fields: `commit` and `branch`. 
 * Fix regression in distributed experiments.
 * Fix an issue with experiment job's statuses creation dates.
 * Fix readme editor styles.
 * Fix charts UI adjustment.
 * Fix issue scheduling notebook on TPU.
 * Fix some issues related to corrupted UI state resulting in UI crashing. 
 * Update dependencies exposing security vulnerabilities.
 * Update several libraries to newer and stable versions.",77383688
1122,False,False,2019-02-25T15:05:45Z,2019-02-22T17:47:31Z," * Add configuration to set a default notebook image.
 * Add configuration to set the default notebook backend.
 * Add support for conda environments.
 * Add a first version Polyaxon CI.
 * Add a new status `stopping` for experiment groups to indicate that the scheduler is stopping experiments in the group and prevent others from starting.
 * Attempt solving an issue of high idle cpu usage caused by rabbitmq container.
 * Fix issues due to concurrency for handling and setting correct statuses for experiment jobs.
 * Fix regression in native build failed status.
 * Fix some issues when handling files are not found on buckets.
 * Fix updating unique names.
 * Fix several UI typos",77383688
1123,False,True,2019-02-22T16:38:13Z,2019-02-22T16:40:31Z,,77383688
1124,False,False,2019-02-18T18:39:03Z,2019-02-18T18:41:02Z,"* **important** This version supports only one outputs (either a store or a volume), to simplify deployment of the CE version and reduce confusion.
 * Refactor build process to support plugins and several backends
 * Make native builder lighter.
 * Add support for building containers with Kaniko as a backend in Beta.
 * Add possibility to use own dockerfile to build containers.
 * Add possibility to use contexts to to only mount sub-folders in a repo for specific tasks (e.g. mount /code/processing module for data extraction in job, and /code/training for training in experiments).
 * Add support for running Jupyter Labs in addition to Jupyter notebooks.
 * Allow in-cluster authentication when using notebooks (users can create experiment and track metrics/tags/params in notebooks created by Polyaxon seamlessly).
 * Improve jobs'/experiments' authentications.
 * Disable creation of polyaxonfile.yaml by default on `init` commands to allow users to put their polyaxonfiles wherever they want.
 * Improve usage of external repos (add support for using an access token or user/password).
 * Enable project to either use in-cluster code tracking or code on github/bitbucket/gitlab.
 * Update several internal components handling fetching, extracting and archiving external repos.
 * Improve notebooks build process: Current version only allows serverless notebooks (mounting in-cluster code will be re-enabled later).
 * Add several checks to Experiment Group Studies to prevent non-ending groups on errors.
 * Handle missing experiments in suggestion algorithms gracefully.
 * Enable logs on buckets (GCS/S3/Azure).
 * Re-enable tensorboards to continuously add experiments in project/groups as they outputs values.
 * Improve and separate deletion/archiving of projects/groups/experiments/jobs, and extend UI to support it.
 * Make default tensorboard image configurable. 
 * Make all components' logging level configurable with `logLevel`.
 * Extend `polyaxon run` to switch project context and run a config on any project, e.g. `polyaxon run -p projectA -f /polyaxonfiles/config1.yaml`.
 * Allow users to either upload code `polyaxon upload` or set external repo `polyaxon project git --url=https//... --private`, 
 so that code tracking can be either in-cluster or on external repos, next version will be introducing github/gitlab hooks to automate pushing to training.
 * Add `polyaon deploy` and `polyaxon teardown` to check a config deployment file, deploy a cluster, upgrade, or teardown in Beta.
 * Allow to customize TPU scheduling: default tensorflow version and resource key.
 * Improve installing cloud stores dependencies with polyaxon-client: `polyaxon-client[gcs]`, `polyaxon-client[s3]`, `polyaxon-client[azure]`.
 * Improve tracking of experiments logs running outside of Polyaxon.
 * Fix TPU scheduling.
 * Fix some issues preventing stopping unschedulable notebooks/tensorboards.
 * Fix detection of warning pod statuses.
 * Fix handling of k8s issues with wrong/bad annotation.
 * Fix issue with platform version returning inverted version values.
 * Fix issues interacting with cloud storages and handling of exceptions.
 * Fix some cli encoding issues in python2.x. 
 * Fix some icons.
 * Several internal enhancements.",77383688
1125,False,True,2019-02-18T16:12:09Z,2019-02-18T16:29:01Z,,77383688
1126,False,False,2019-01-27T20:41:51Z,2019-01-27T20:48:40Z," * Fix an issue with a cron job that handles the deletion of archived projects/jobs/experiments/builds.
 * Update ingress to allow users to create an ingress with an IP only without requiring a host.
 * Add `POLYAXON_NO_OP` option to the client/tracking api (polyaxon tracking operation will be ignored), 
 to allow users to perform a dry-run of their code when used outside of a Polyaxon context without crashing.
 * Add possibility to disable verify ssl for Polyaxon client and Polyaxon cli. 
 * Update default rabbitmq image version.
 * Several internal enhancements.",77383688
1127,False,False,2019-01-13T20:12:42Z,2019-01-13T20:13:12Z," * Add possibility to collect logs to a cloud storage bucket (S3/GCS/Azure storage).
 * Add keras callback for tracking metrics.
 * Add possibility to read client config from `.polyaxonclient` file as well as from env vars.
 * Add validation for values containing lists.
 * Add copy-to-clipboard to preserve configuration yaml structure when copying from browser.
 * Add confirmation dialogue before deleting/stopping entities on Dashborad.
 * Add better logs handling for in-cluster jobs and experiments running on other platforms.
 * Enable admin view by default with useful models only.
 * Enhance statuses watch.
 * Add gzip decorator for some endpoints.
 * Enhance stores and options management (internal improvements).
 * Add external registries for managing build images (Beta).
 * Add graceful Handling of wrongly detected gpu nodes.
 * Fix token auto-refresh.
 * Fix user deletion from admin UI.
 * Fis issue with declarations of type list not being handled correctly on dashboard.
 * Fix issue relates to `ls` on GCS.
 * Fix some issues related to detecting changes on Azure.
 * Fix error when the command `config --list` when configuration is not initialized.  
 * Extend in-cluster examples.
 * Add examples for tracking experiments outside of Polyaxon.
 * Introduce Polyaxon deployment lifecycle management (Beta).",77383688
1128,False,True,2019-01-13T18:31:11Z,2019-01-13T18:33:35Z,,77383688
1129,False,False,2018-12-17T11:23:07Z,2018-12-17T11:46:06Z," * Update logging logic, logs are now collected lazily.
 * Use k8s logs timestamps to avoid lags between Polyaxon and k8s.
 * Expose pod name on experiments jobs, jobs, builds, tensorboards in UI & CLI.
 * Update sidecar logic, first step to implement a collector sidecar logic for artiacts/outputs.
 * Deletion of `projects`, `experiment groups`, `experiments`, `jobs`, is now asynchronous, and results in archiving the entity for a certain period.
 * Add archiving period, configurable with `cleaningIntervals.archived` default 7 days, to allow users to recover deleted entities, otherwise, archived entities older than this interval get cleaned.
 * Add support for TPU scheduling.
 * Fix study groups issue related to creating chunks of serializable numpy suggestions.
 * Schedule configmap and secret refs for builds created by experiments/jobs/notebooks.
 * [Security, XSS fixes] Update: bootstrap 3.4.0.
 * Update service account usage for workers to get less permissions.
 * Calculate run time based on running status instead of starting status, the reason is that an experiment can be sent to k8s scheduler, hence it can wait for some time for resources before it starts actually running.
 * Fix UI issue in the job overview tab.
 * Fix smoothing algorithm, was dropping the first metric resulting in wrong visualization, now the smoothing has similar behaviour to the Tensorboard's.
 * Disable ingress by default, and use LoadBalancer as default value for charts.
 * Add host list directly on ingress to use when tls is not enabled.
 * Remove deprecated `polyaxon-logs` service. 
 * Use ocular for monitoring statuses.
 * Use polystores for managing stores.",77383688
1130,False,True,2018-12-17T10:02:05Z,2018-12-17T10:09:01Z,,77383688
1131,False,False,2018-12-03T20:14:43Z,2018-12-03T21:19:50Z," * Add new statuses: ""warning"" and ""unschedulable"".
 * Extend specification to allow `run` to accept multiple commands in polyaxonfiles.
 * Add details information when an experiment is stopped by the system.
 * Allow to edit entities' names from the UI for group/experiment/job/build.
 * Display the name given by the user by default and fall back to the unique name generated by the platform.
 * Add UI meta info about the restarted/resumed/copied jobs/experiments and add ref to the original entity.
 * Add termination reason/status code to failed runs.
 * Fix issue with resumed experiments' outputs getting wrong artifacts.
 * Update statuses logging logic to not drop past events caused by concurrency.
 * Always insert statuses while respecting the state machine before the event was detected.
 * Remove default value for jobs cloning strategy (was added by mistake).
 * Fix issue fetching experiments' declarations in groups' metrics.
 * Fix an issue with stop job api.
 * Fix issue in sidecar monitor.
 * Fix bookmark tooltip style issue.
 * Update some UI styles.",77383688
1132,False,False,2018-11-27T08:56:01Z,2018-11-27T11:47:34Z,"**(Edited to include a miration patch)**
 * Add download button for logs.
 * Add download button for outputs.
 * Make ephemeral tokens ttl a configurable param.
 * Optimize experiment group studies.
 * Extend specification to accept registries with port numbers in the build section.",77383688
1133,False,False,2018-11-21T10:12:36Z,2018-11-21T10:26:43Z," * Add `--init` option to `polyaxon create` to allow users to create and initialize a project at the same time.
 * Use `done` instead of `succeeded` for experiment groups status.
 * Upgrade image and python to 3.6.
 * Update the registration's validation.
 * Update smoothing algorithm: move from spline to moving average.
 * Add search algorithm to group schemas and to cli `polyaxon group get`.
 * Update heartbeat logic: start logic from running status instead of scheduled.
 * Update heartbeat logic: lower check frequency.
 * Move some abstractions from EE to CE.
 * Update error handling for download requests in client.
 * Update token with scopes and refresh mechanism.
 * Improve some apis.
 * Add mechanism to ensure CSRFToken refresh on page refresh.
 * Update kubernetes client.
 * Add dockerizer pull policy.
 * Fix nested outputs relative paths.
 * Fix tabs css behaviour outlining clicks.
 * Fix admin readonly mixin.
 * Fix issues with the ui client POST/DELETE/PATH requests.
 * Fix notebook UI actions.
 * Fix admin styles regression.",77383688
1134,False,False,2018-11-08T23:01:52Z,2018-11-08T23:03:33Z," * (Security) Add IPs/Hosts whitelist configuration.
 * (Security) Make admin view configurable and disable it by default.
 * Add api host/ip configuration to send emails/slack/notifications/integrations with clickable links.
 * Add more validation and edge cases handling for outputs apis.
 * Add loading indicator for dashboard.
 * Add migration to prepare for auth/permission plugins and extensions for the community version (Phase 1).
 * Remove experiment group schemas patch.
 * Minify styles.
 * Fix UI alignment and usability issues.
 * Fix an issue with groups' type not created for studies.",77383688
1135,False,False,2018-11-05T17:37:30Z,2018-11-05T17:49:10Z," * Add experiment selection groups: Users can now compare 2 (or more) experiments by adding them to a selection.
 * Add possibility to visualize metrics and to start a tensorboard for any selection of experiments.
 * Add outputs/artifacts tree view.
 * Add outputs/artifacts files (text/code/images) previewing.
 * Add tensorboard support for events on cloud storage (S3 and GCS).
 * Add refresh button to avoid reloading the whole page (first step to better UX, next step is real-time updates or polling). 
 * Extend tensorboard behaviour to show events from different backend storages (e.g. one experiment persisting events to S3 and another to GCS)
 * Add possibility to delete and stop multiple experiments at once.
 * Allow to configure heartbeat timeout.
 * Allow to support commands with `&&` without the need to create a script.
 * Connect gaps in charts, an issue happens when only a data point is created in a time interval.
 * Extend Groups Component to show the group type (study & selection).
 * Extend private registries to accept dictionaries as well as uri specs.
 * Open access for private repos to public beta. 
 * Add help text to indicate that names must be slugs (a better error handling for the dashboard is needed).
 * Add default node scheduling for tensorboards.
 * Upgrade security warning packages.
 * Enhance cloud storages management.
 * Fix an issue not showing all error logs of builds.
 * Fix an issue with cli exiting if both `--past` and `--follow` are passed, and past api returns a 404.
 * Fix issues related to copy/restart experiment from a group.",77383688
1136,False,False,2018-10-26T12:57:13Z,2018-10-26T13:00:15Z," * Add Azure Storage to public beta.
 * Update SSO behaviour to create users inactive by default.
 * Add support for external public repos.
 * Add support for external private repos (beta).
 * Extend build specification with commit/branch(treeish) for both internal and external repos. 
 * Update and extract sidecar logic to independent service.
 * Add support for external experiment logging.
 * Update and enhance store management.
 * Trigger single build process for experiment groups.
 * Update behaviour of `latest` docker tag, default to not always pull, add configuration to set it up to True.
 * Update and fix several docs issues. 
 * Add port forwarding command docs
 * Add workload heartbeat tracking, jobs/experiments not reporting after a period will be marked as Zombie runs.
 * Enhance internal events management, default is async now.
 * Add possibility to stop tensorboards/notebooks from dashboard.
 * Force experiment statuses to respect the transition matrix.
 * Update logging to track timestamps as well, cli logs commands have option to hide timestamps.
 * Extend health check logic with disk, memory, cache, ...
 * Extract common utils.
 * Remove external repos management.
 * Fix issue with client not reporting correctly last metrics (worker dies before finishing the request).
 * Fix issue with cli outdated param (async).
 * Fix issues related to image builds.
 * Fix some ui issues on safari.",77383688
1137,False,False,2018-10-15T22:07:33Z,2018-10-15T22:22:52Z," * Seamless integration of S3 and GCS is now in public beta, 
   users can load data from cloud storages as well as from persistent volumes and host nodes, 
   they can also manage their outputs and artifacts using these storages, 
   tensorflow's integration is seamless as well for model and checkpoints logging.
 * Fix some issues with Azure Storage (still in private beta). 
 * Add support for user's custom secrets and config maps.
   users can extend Polyaxon runs and workloads with extra environment and secrets.
 * Improve experiments' metrics API by using a queue for frequent updates.
 * Increase throttling rate for metrics reporting.
 * Add possibility to edit charts.
 * Add more automation to chart titles based on metrics/params.
 * Add periodic worker to improve performance.
 * Add cleaning crons to remove old notifications and logs.
 * Add streams health status.
 * Add extra config and annotation to prevent IOError in long running requests.
 * Add draft for out-cluster logging.
 * Fix validation issue related to gitlab usernames containing dots.
 * Fix issue with re-enabling previously disabled nodes. 
 * Fix issues related to artifacts management and absolute paths on users machines.
 * Fix filtering typo for `id` dropdown.",77383688
1138,False,False,2018-10-08T16:42:15Z,2018-10-08T16:42:52Z," * Add experiment groups' metrics/visualizations.
 * Add experiments' metrics comparison.
 * Add readme and note taking on project/group/experiment/job's overviews.
 * (`Data Migration`) Update Experiment's last metric, it will include all values even if they were not reported at the current step. This is a new behaviour to allow user to aggregate and have an overview over 
 all values reported from previous steps/epochs' metrics.
 * Add tags editing from dashboard.
 * Add description editing from dashboard.
 * Add health status endpoint.
 * Add tracking API documentation.
 * Fix issue with hyperparameters tuning; experiment groups are stuck trying to sample new values when user requests larger number of experiments than the provided space (happens only when using discrete distributions).
 * Add is_continuous property to space values.
 * Fix issue with cli upload large files.
 * Fix issue with cli losing connection due to timeout.
 * Update annotation for mounting volumes with read-only option, the read-only is now applied to both the volume and the persistence claim.
 * Update error message for cli upload.
 * Fix `notebook -u` command, an old keyword was still being passed.
 * Update static files caching options.
 * Attempt to stabilize connection to broker(better solution is required).
 * Upgraded requirements.
 * Removed unused frontend dependencies.
 * Update throttling behavior for some endpoints.",77383688
1139,False,False,2018-10-01T14:58:25Z,2018-10-01T15:17:05Z,"This is a patch release on top of 0.2.3 containing no breaking changes.

 * For issues in NodePort deployments: an issue arises with builds and with overall internal connection to api.
 * Improved response time for project/group/experiment detail apis (removed query annotations).
 * Fix some db warnings related to Jsonb default values.",77383688
1140,False,False,2018-09-30T16:31:43Z,2018-09-30T16:57:32Z,"This is a patch release on top of 0.2.3 containing no breaking changes.

 * Add `-l` option to `polyaxon run` to start log automatically after run command.
 * Keep stream connection alive for logs (fix issue with ending sessions).
 * Update client auth: persist token after ephemeral login.
",77383688
1141,False,False,2018-09-27T13:56:31Z,2018-09-27T13:58:07Z," * Fix one major issue with events getting dropped, which led to experiments getting stuck in scheduled status.
 * Add out cluster tracking and instrumentation, users can now track experiment outside of Polyaxon and compare the experiments in Polyaxon.
 * Add possibility to create experiment and experiment groups without polyaxon specification, to allow users to run custom hyperparams tuning.
 * Add ttl and debug mode for runs.
 * Add customizable charts.
 * Add chart views saving functionality.
 * Add metrics views.
 * Extend query spec api to save metrics/params columns.
 * Add group metrics visualization and analysis [Beta].
 * Improve stability of experiment groups (some issues are still under investigation).
 * filter disabled nodes out from cluster api end points. 
 * Add possibility to use GCE/S3/Azure as an outputs and artifact storage  [Beta].
 * Update handling of internal tokens to increase job/experiment security and scoping.
 * Add traceback to the failure event status to get more context.
 * Add code reference endpoint for jobs and experiments.
 * Add data references tracking and extend experiment details api.
 * Add run environment tracking and extend experiment details api.
 * Add handling for evicted pods.
 * Init should not reinitialize ignore files and other cli config files.  
 * Introduce ephemeral auth for experiment and jobs.
 * Update code reference to include branch, url, is_dirty.
 * Add possibility to merge-update tags and params/declarations.
 * Extract env var handling and typing.
 * Fix group stats (counts of experiments in different stages)
 * Fix a UI issue with flexbox in last chrome
 ",77383688
1142,False,False,2018-09-11T14:37:37Z,2018-09-11T14:43:24Z,"This is a patch release on top of 0.2.0 containing only bug fixes and no breaking changes or features.

 * Fix issue with webhooks not serializing events correctly",77383688
1143,False,False,2018-08-29T10:10:45Z,2018-08-29T10:31:37Z,"This is a patch release on top of 0.2.0 containing only bug fixes and no breaking changes or features.

 * Fix issue with serializing experiment jobs' tolerations
 ",77383688
1144,False,False,2018-08-28T14:38:31Z,2018-08-28T15:42:30Z," * Enhance filtering and sorting: better UI and dropdown with filter/sort options
 * Add saved queries
 * Experiments table dashboard can include optional columns: metrics and declarations/params. This will allow to compare experiments in one table.
 * Update log stream to show phase changes instead of disconnecting the session (now you can run and log without providing any id or checking the build)
 * Add REST API docs
 * Include bookmark indicator in dashboard lists
 * Refetch on tab changes to get latest updates
 * Remove some javascript dependencies and reduce bundle size
 * Add cli install to install.polyaxon.com
 * Add exception handling for actions, errors were preventing experiments/jobs from running
 * Lint helm chart
 * Add helm chart CI
 * Fix an issue with csrf token collection
 * Fix issue in reducer that made the state inconsistent
 * Fix an issue with dashboard pagination
 * Fix issue with bookmark page not loading experiments, and only loading when navigating tabs
 * Fix a bug that made loading experiments slow",77383688
1145,False,False,2018-08-21T00:11:03Z,2018-08-21T00:12:50Z," * Add config deployment app to help guide users through the configuration options when deploying Polyaxon
 * Add possibility to delete/stop jobs/experiments from dashboards
 * Update charts to support rolling updates
 * Optimize and fix some issues in some API endpoints
 * Optimize and reduce number of generated queries (More queries to optimize)
 * Update SDK to expose only one client
 * Add a delay before creating the experiment group's experiment to avoid not finding running status
 * Extend config manager to validate different generic specs and raise errors on bad config deployments
 * Abstract serialization of bookmarks to be used for lists
 * Fix an issue with the metrics api's pagination
 * Enhanced the filters ui
 * Consolidate installed libraries",77383688
1146,False,False,2018-08-13T16:18:09Z,2018-08-13T16:40:08Z,"  * Enable users to pull image from private registries
  * Add first version of an abstraction to seamlessly use cloud storage or persistent volumes for data, outputs, and logs
  * Annotate jobs with node used for the scheduling
  * Remove some optional env vars and move them to default values
  * Use configMap and secret envFrom to populate environment
  * Reduce number of partials
  * Update default page size to 20
  * Update usage of secrets and configs
  * Update clean commands
  * Fix an issue with check command
  * Fix a bug related to checking running experiment groups
  * Add missing tests for azure id creation
  * Enhance build and test process
  * Upgrade kubernetes client to 6.0.0
  * Upgrade web socket and request libs
  * Upgrade api and workers requirements
  * Update test requirements
  * Move label and pod/job states schemas to core",77383688
1147,False,False,2018-08-03T08:04:21Z,2018-08-03T08:19:26Z," * Add initial draft of actions
 * Add base integrations mechanism
 * Add notification via emai, slack, pagerduty, mattermost, discord, hipchat, webhooks ...
 * Enlarge docker's shm memory 
 * Fix Microsoft authentication
 * Fix issue with cleaning pre-delete hooks
 * Remove deprecated polyaxon-lib
 * Separate email and admin user in helm chart
 * Fix api service with NodePort
 * Fix issue related to delete project command outside of initialized polyaxon workspace in CLI
 * Redirect directly to dashboard from CLI",77383688
1148,False,False,2018-07-28T23:59:23Z,2018-07-29T00:16:44Z,"* Add possibility to deploy Polyaxon with tls.
* Expose default toleration/affinity for builds, jobs, experiments.
* Add affinity and toleration to spec environment.
* Update spec to use node_selector instead of node_selectors.
* Refactor worker/ps/default_worker/default_ps in environment section.
* Update CLI init command to always create a new config for the project.
* Add shortcuts `-f` for follow and `-p` for past for the logs commands.
* Creating job/build/experiment/group with cli will cache the instance automatically for the following commands.
* Fix some command suggestions.
* Upgrade pyyaml, there was a security issue.
* Improve docker build process.
* Fix pytorch distributed example.
* Update chart cleaning hook delete strategy.
* Fix an issue with detecting the correct k8s minor version.
* Fix issue with docker build process: image name should be lower case.
* Fix Run meta info for builds, jobs, and groups on dashboard.
* Add draft for stats and actions.",77383688
1149,False,False,2018-07-22T15:50:31Z,2018-07-22T15:58:57Z,"  * Build images: You can now `pip install` any file in your code folder without the need to call the file `polyaxon_requirements.txt`. Same thing if you need to build an image and have a shell script you just need to `chmod +x` the file and add it to the build setps.
  * Add bookmarking: You can bookmark your projects/groups/experiments/jobs/builds with Dashboard/API/CLI/Client. If your team is running too many hyper params tuning in many projects, finding the important experiments/jobs/builds can be exhausting since it requires searching each time. Bookmarks allow you to easily save important runs and have access to them in an easy way.
 * Add activity logs: shows recent create/update/delete activities in your team cluster or projects.
 * Add history/recently viewed: This is also something that some teams showed a lot of interests in having, using the platform for a couple of weeks/months and creating thousands of experiments per day, makes it very hard to access the right information.
  * Add support for external PostgreSQL: it's possible to link an external PostgreSQL database instead of the in-cluster one.
 * SSO: Add support for Microsoft Azure authentication. in addition to github, gitlab, bittbucket, and LDAP, now you can allow your team to signup/login to Polyaxon with Microsoft Azure authentication
 * Tooltips: for dates (creation date, update date, starting date, termination date) the dashboard shows a humanized version (e.g. X hours/days ago) this was not super helpful, and many users asked to have the possibility to see the exact values. On your dashboard you can see the dates values by hovering on any date and it will show datetime in the ""YYYY-MM-DD HH:mm:ss"" format.
  * Add docs for replication: the docs now has a section outlining different strategies for replicating Polyaxon.
  * Add docs for postgres HA strategies.
  * Add docs for Microsoft Azure authentication.",77383688
1150,False,False,2018-07-11T08:07:49Z,2018-07-11T08:26:49Z," * Fix some issues with node discovery
 * Optimize access to k8s api
 * Update image build process
 * Optimize resources monitoring on k8s
 * Add bookmarks for project, groups, experiments, jobs, builds
 * Fix some UI issues
 * Update docs
 * Other changes from 🇷🇺",77383688
1151,False,False,2018-07-05T15:06:40Z,2018-07-05T15:10:12Z," * Add support for outputs reference from other jobs and experiments by id and name
 * Update metrics tab with empty metrics
 * Add some error handling for spec validation
 * Fix the instruction pages",77383688
1152,False,False,2018-07-04T15:13:40Z,2018-07-04T15:30:01Z," * Update instructions tabs
 * Expose commit on the query spec
 * Add query spec docs
 * Add statuses tab
 * Add metrics tab
 * Add jobs cleaning
 * Update logic for allowing commits after delete notebooks
 * Update outputs logics for tensorboards",77383688
1153,False,False,2018-07-01T19:01:39Z,2018-07-01T19:17:04Z," * Update dockerizer process: moved from a worker based process that handles image builds to pod being scheduled to build the image if does not exists
 * Possibility to force rebuilding an image
 * Separate run into 2 sections: run and build
 * Add build specification
 * Add tensorboard and notebook specifications
 * Add generic job specification
 * Optimize services images and reduce their sizes
 * Upgrade docker client
 * upgrade kubernetes client
 * Add and test replication for api, workers, and monitors
 * Add tagging for projects, experiments, experiments groups, and jobs
 * Add possibility to name runs (experiments, groups, jobs, builds)
 * Add filtering, you can now filter based on our query spec: started_at:2015-01-01..2018-01-20, tags:foo|bar, metrics__loss:<=0.1
 * Add sorting, you can now sort by different attributes: -created_at, updated_at...
 * Remove upper limit on hptuning, this will allow hptuning algorithm worker to consume more cpu and converge faster.
 * Add download code: you can see now the commit made internally each time you upload the code
 * Add outputs download for experiments and jobs
 * Update tensorboards to support not only projects but also experiments and experiment group
 * Update and enhance ui
 * Add possibility to mount multiple data and outputs volumes
 * Extend the specification to allow to choose an output and data volumes to mount for an experiment or a job
 * Fix several usability and stability issues
 * Extend experiments api to allow to pull metrics and declarations",77383688
1154,False,False,2018-05-21T16:27:34Z,2018-05-21T16:30:51Z,"* Add LDAP auth backend
* Add identity abstraction for oauth and integrations
* Add Github oauth
* Add Bitbucket oauth
* Add Gitlab oauth
* Update landing page and dashboard design
* Update signup/login pages
* Update behaviour of experiment groups finished status
* Expose more params for Bayesian optimization (algorithm was not converging sometime because of the default n_iter and n_warmup value)
* Add more experiment group meta data: run dates and total time, iterations, status, and algorithm search
* Fix issues with parsing numpy types in specification files",77383688
1155,False,False,2018-05-14T16:04:20Z,2018-05-14T16:09:31Z,"
 * Optimize build process and handle concurrent build of the same repo: this will fix issues related to experiment getting stack in the build process and sometimes preventing the iterative hyperparameters algorithms from continuing the search.

 * Add advanced nodes scheduling for experiments and jobs: Previously users could set a default node selectors for core and experiments. Now they have the ability to override these selectors per experiment, experiment job for distributed runs, notebook, and tensorboard.

 * Fix upload command on Windows platform

 * Add more edge cases handling for resumed experiments
       * deleting original should delete resumed experiments
       * resuming a resumed experiment should resume the original experiment

 * Fix issue with stopping experiment groups

 * Add NFS provisioner, this is practical for testing the platform without the need to create a real NFS server.

 * Add event management and backbone for creating notifications and integrations

 * Add tracker

 * Add activity log

 * Update docs requirement",77383688
1156,False,False,2018-05-02T12:58:13Z,2018-05-02T13:01:05Z," * Add restart/resume/copy experiments
 * Fix issue with cyclic redirection when the user's session is expired.
 * Add platform logging
 * Update Bayesian optimization
 * Fix prospector for tests
 * Remove requirement for project name in specifications
 * Add  google GKE tutorial",77383688
1157,False,False,2018-04-23T10:14:34Z,2018-04-23T10:26:43Z,"This new version has breaking changes:

 * Update specification
   * Add kind section to indicate the type of operation to run on Polyaxon.
   * Rename sequential search to grid search
   * Update early stopping schema to use optimization instead of higher: maximize | minimize
   * Move matrix to settings
   * Add config for search algorithms to settings
   * Remove run_type and export strategies form settings
   * All early_stop to stop both individual experiment from running or an experiment group or both.
   * Rename steps to build_steps in run section
   * Rename concurrent_experiment to concurrency
   * Add new method for sampling values
   * Possibilty to provide a seed
   * Rename Sequential search to grid search

Add new hyperparameters search algorithms:

 * Add hyperband
 * Add bayesian optimization [alpha]

Add continous methods for sampling matrix params:
 * pvalues
 * uniform
 * quniform
 * loguniform
 * qloguniform
 * normal
 * qnormal
 * lognormal
 * qlognormal

Add first version of pipelines.

Show logs after experiment is finished [api, ui, client, cli].

Optimize plugin jobs [tensorboards and notebooks].

Separate dahsboard and runner.

Fixed bug issues.",77383688
1158,False,False,2018-03-19T12:33:02Z,2018-03-17T17:32:45Z," * Enhance single experiment spawner
 * Add MXNet spawner and support for distributed MXNet experiments
 * Add Pytorch spawner and support for distributed Pytorch experiments
 * Add Horovod spawner and support for distributed Horovod experiments [WIP]
 * Optimize Tensorflow spawner and distributed Tensorflow experiments
 * Optimize schedulers' logic
 * Optimize docker build process
 ",77383688
1159,False,False,2018-03-09T15:25:34Z,2018-03-09T15:28:49Z," * Add early stopping and number of experiments
 * Use statuses for jupyter notebooks and tensorboards
 * Fix issue with starting multiple tensorboards
 * Rename deleted status to stopped
 * Add admin dashboard",77383688
1160,False,False,2018-03-04T23:29:04Z,2018-03-04T23:49:33Z," * Add Jupyter notebooks
 * Update Tensorboad deployments
 * Apply project permission to project plugin jobs, i.e. tensorboard and notebooks will only be accessible to users with enough project permissions
 * Update dashboard and ui
 * Fix some issues with kubernetes resources tracking",77383688
1161,False,False,2018-02-07T18:28:40Z,2018-02-05T13:08:59Z,,77383688
1162,False,False,2019-03-20T22:22:45Z,2019-03-20T22:31:42Z,"### Added
- [Tokenization] Added NGramTokenizer (#350)
- editorconfig file (#355)
### Fixed
- [Dataset] FilesDataset read samples without additional array (#363)
- [Tokenization] fixed error with numeric token values (#363)
### Changed
- [Math] improved performance with pow and sqrt replacement (#350) 
- [Math] reduce duplicated code in distance metrics (#348)
- update phpunit to 7.5.1 (#335)
- code style fixes (#334)",51325497
1163,False,False,2018-11-07T18:40:31Z,2018-11-07T18:44:56Z,"### Added
- [Clustering] added KMeans associative clustering (#262)
- [Dataset] added removeColumns function to ArrayDataset (#249)
- [Dataset] added a SvmDataset class for SVM-Light (or LibSVM) format files (#237)
- [Dataset] added Mnist Dataset for MNIST file format (#326)
- [Internal] Add performance test for LeastSquares (#263)

### Changed
- [Internal] implement Keep a Changelog format
- [Classification] changed the default kernel type in SVC to Kernel::RBF (#267)
- [Optimizer] removed $initialTheta property and renamed setInitialTheta method to setTheta (#252)
- [Imputer] Throw exception when trying to transform without train data (#314)
- [Math] Micro optimization for matrix multiplication (#255)
- [Internal] Throw proper exception (#259, #251)
- [MLPClassifier] return labels in output (#315)
- [Internal] Update phpstan to 0.10.5 (#320)

### Fixed
- [SVM] ensure DataTransformer::testSet samples array is not empty (#204)
- [Optimizer] optimizer initial theta randomization (#239) 
- [Internal] travis build on osx (#281)
- [SVM] SVM locale (non-locale aware) (#288)
- [Internal] typo, tests, code styles and documentation fixes (#265, #261, #254, #253, #251, #250, #248, #245, #243, #317, #328)
- [Classification] Check if feature exist when predict target in NaiveBayes (#327)",51325497
1164,False,False,2018-02-22T16:06:31Z,2018-02-22T16:07:31Z,* Fix Apriori array keys (#238),51325497
1165,False,False,2018-02-17T23:11:54Z,2018-02-17T23:12:54Z,* Fix KMeans and EigenvalueDecomposition #235,51325497
1166,False,False,2018-02-16T19:41:37Z,2018-02-16T22:41:13Z," * feature [FeatureSelection] implement SelectKBest with scoring functions (#232)
 * feature [FeatureSelection] implement VarianceThreshold - simple baseline approach to feature selection.  (#228)
 * feature [Classification] support probability estimation in SVC (#218)
 * feature [NeuralNetwork] configure an Activation Function per hidden layer (#208)
 * feature [NeuralNetwork] Ability to update learningRate in MLP (#160)
 * feature [Metric] Choose averaging method in classification report (#205)
 * enhancement Add phpstan strict rules (#233)
 * enhancement Flatten directory structure (#220)
 * enhancement Update phpunit/phpunit (#219)
 * enhancement Cache dependencies installed with composer on Travis (#215)
 * enhancement Add support for coveralls.io (#153)
 * enhancement Add phpstan and easy coding standards (#156, #168)
 * enhancement Throw exception when libsvm command fails to run (#200, #202)
 * enhancement Normalize composer.json and sort packages (#214, #210)
 * enhancement Rewrite DBSCAN (#185)
 * fix phpunit include tests path (#230)
 * fix support of a rule in Apriori (#229)
 * fix apriori generates an empty array as a part of the frequent item sets (#224)
 * fix backpropagation random error (#157)
 * fix logistic regression implementation (#169)
 * fix activation functions support (#163)
 * fix string representation of integer labels issue in NaiveBayes (#206)
 * fix the implementation of conjugate gradient method (#184)
 * typo, tests and documentation fixes (#234, #221, #181, #183, #155, #159, #165, #187, #154, #191, #203, #209, #213, #212, #211)",51325497
1167,False,False,2017-11-14T20:56:18Z,2017-11-14T20:58:11Z,"* general [php] Upgrade to PHP 7.1 (#150)
* general [coding standard] fix imports order and drop unused docs typehints
* feature [NeuralNetwork] Add PReLU activation function (#128)
* feature [NeuralNetwork] Add ThresholdedReLU activation function (#129)
* feature [Dataset] Support CSV with long lines (#119)
* feature [NeuralNetwork] Neural networks partial training and persistency (#91)
* feature Add french stopwords (#92)
* feature New methods: setBinPath, setVarPath in SupportVectorMachine (#73)
* feature Linear Discrimant Analysis (LDA) (#82)
* feature Linear algebra operations, Dimensionality reduction and some other minor changes (#81)
* feature Partial training base (#78)
* feature Add delimiter option for CsvDataset (#66)
* feature LogisticRegression classifier & Optimization methods (#63)
* feature Additional training for SVR (#59)
* optimization Comparison - replace eval (#130)
* optimization Use C-style casts (#124)
* optimization Speed up DataTransformer (#122)
* bug DBSCAN fix for associative keys and array_merge performance optimization (#139)
* bug Ensure user-provided SupportVectorMachine paths are valid (#126)
* bug [DecisionTree] Fix string cast #120 (#121)
* bug fix invalid typehint for subs method (#110)
* bug Fix samples transformation in Pipeline training (#94)
* bug Fix division by 0 error during normalization (#83)
* bug Fix wrong docs references (#79)",51325497
1168,False,False,2017-03-05T15:45:48Z,2017-03-05T15:50:48Z,"* AdaBoost improvements by Mustafa Karabulut
* One-v-Rest Classification technique applied to linear classifiers by Mustafa Karabulut",51325497
1169,False,False,2017-02-23T19:59:30Z,2017-02-23T20:03:27Z,"- feature [Classification] - Ensemble Classifiers : Bagging and RandomForest by Mustafa Karabulut
- feature [Classification] - RandomForest::getFeatureImportances() method by Mustafa Karabulut
- feature [Classification] - Linear classifiers: Perceptron, Adaline, DecisionStump by Mustafa Karabulut
- feature [Classification] - AdaBoost algorithm by Mustafa Karabulut
- bug [Math] - Check if matrix is singular doing inverse by Povilas Susinskas
- optimization - Euclidean optimization by Mustafa Karabulut
",51325497
1170,False,False,2017-02-03T16:54:41Z,2017-02-04T10:13:04Z,"```
* feature [Persistency] - ModelManager - save and restore trained models by David Monllaó
* feature [Classification] - DecisionTree implementation by Mustafa Karabulut
* feature [Clustering] - Fuzzy C Means implementation by Mustafa Karabulut
* other small fixes and code styles refactors
```
",51325497
1171,False,False,2016-11-20T21:56:18Z,2016-11-20T21:57:40Z,"```
* feature [Association] - Apriori algorithm implementation
* bug [Metric] - division by zero
```
",51325497
1172,False,False,2016-08-14T17:17:12Z,2016-08-14T17:18:00Z,"Neural Network - MultilayerPerceptron and Backpropagation training 
",51325497
1173,False,False,2016-07-24T12:04:09Z,2016-07-24T12:04:45Z,,51325497
1174,False,False,2016-07-11T22:23:23Z,2016-07-11T22:23:50Z,,51325497
1175,False,False,2016-07-07T22:03:22Z,2016-07-07T22:06:13Z,,51325497
1176,False,False,2020-02-28T18:30:19Z,2020-02-28T18:31:45Z,"- **Enhancement**
    - Allow users to set a gap between training and holdout in time splitters
    - Raise Errors instead of use asserts
- **New**
    - Support pipelines with duplicated learners
    - Add stratified split method
- **Bug Fix**
    - Fix space_time_split holdout
    - Fix compatibility with newer shap version",172931222
1177,False,False,2019-10-07T20:12:28Z,2019-10-07T20:16:06Z,"- **Enhancement**
    - Improve split evaluator to avoid unexpected errors
- **New**
    - Now users can install only the set of requirements they need
    - Add Target encoding learner
    - Add PR AUC and rename AUC evaluator to ROC AUC
- **Bug Fix**
    - Fix bug with space_time_split_dataset fn
- **Documentation**
    - Update space time split DOCSTRING to match the actual behaviour
    - Add more tutorials(Pydata)",172931222
1178,False,False,2019-08-16T13:54:08Z,2019-08-16T13:57:59Z,"## [1.15.1] - 2019-08-16
- **Enhancement**
    - Now learners that have a model exposes it in the logs as `object` key",172931222
1179,False,False,2019-08-12T11:31:17Z,2019-08-12T11:32:50Z,"- **Enhancement**
    - Make `custom_transformer` a pure function
    - Remove unused requirements
- **New**
    - Now features created by one hot enconding can be used in the next steps of pipeline
    - Shap multiclass support
    - Custom model pipeline
- **Bug Fix**
    - Fix the way one hot encoding handle nans
- **Documentation**
    - Minor fix flake8 documentation to make it work in other shells
    - Fix fbeta_score_evaluator docstring
    - Fix typo on onehot_categorizer
    - New tutorial from meetup presentation",172931222
1180,False,False,2019-08-02T14:03:08Z,2019-08-02T14:06:46Z,"**Bug**
    - Remove unused package",172931222
1181,False,False,2019-08-02T14:03:50Z,2019-08-02T14:05:56Z,"**Bug**
    - Remove unused package",172931222
1182,False,False,2019-05-29T21:21:49Z,2019-05-29T21:24:40Z,"- **Bug**
    - Fix packages upper bound version",172931222
1183,False,False,2019-05-29T21:20:35Z,2019-05-29T21:24:04Z,"- **Bug**
    - Fix packages upper bound version",172931222
1184,False,False,2019-04-30T21:37:20Z,2019-04-30T21:38:44Z,"- **Enhancement**
    - Validator accepts predict_oof as argument
- **New**
    - Add CatBoosting regressor
    - Data corruption(Macacaos)
- **Documentation**
    - Multiple fixes in the documentation
    - Add Contribution guide",172931222
1185,False,False,2019-04-24T19:43:52Z,2019-04-24T19:46:52Z,"Minor bug-fixes in the 1.13.x series, it removes a lot of warnings in the `placeholder_imputer`",172931222
1186,False,False,2019-04-22T18:57:43Z,2019-04-22T19:34:24Z,This is the first release of Nubank's data science library.,172931222
1187,False,False,2020-01-03T17:56:21Z,2020-01-03T18:04:20Z,"- Fix compatibility issue with scikit-learn v0.22
- `warm_start` now saves both Primitive Sets and evaluated_pipelines_ from previous runs;
- Fix the error that TPOT assign wrong fitness scores to non-evaluated pipelines (interrupted by `max_min_mins` or `KeyboardInterrupt`) ;
- Fix the bug that mutation operator cannot generate new pipeline when template is not default value and `warm_start` is True;
- Fix the bug that `max_time_mins` cannot stop optimization process when search space is limited.  
- Fix a bug in exported codes when the exported pipeline is only 1 estimator 
- Fix spelling mistakes in documentations 
- Fix some code quality issues ",45495679
1188,False,False,2019-11-05T21:03:54Z,2019-11-05T21:04:49Z,"- **Support for Python 3.4 and below has been officially dropped.** Also support for scikit-learn 0.20 or below has been dropped.
- The support of a metric function with the signature `score_func(y_true, y_pred)` for `scoring parameter` has been dropped.
- Refine `StackingEstimator` for not stacking NaN/Infinity predication probabilities.
- Fix a bug that population doesn't persist even `warm_start=True` when `max_time_mins` is not default value.
- Now the `random_state` parameter in TPOT is used for pipeline evaluation instead of using a fixed random seed of 42 before. The `set_param_recursive` function has been moved to `export_utils.py` and it can be used in exported codes for setting `random_state` recursively in scikit-learn Pipeline. It is used to set `random_state` in `fitted_pipeline_` attribute and exported pipelines.
- TPOT can independently use `generations` and `max_time_mins` to limit the optimization process through using one of the parameters or both.
- `.export()` function will return string of exported pipeline if output filename is not specified.
- Add [`SGDClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) and [`SGDRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) into TPOT default configs.
- Documentation has been updated.
- Fix minor bugs.",45495679
1189,False,False,2019-07-16T16:16:39Z,2019-07-16T17:29:50Z,"- **TPOT v0.10.2 is the last version to support Python 2.7 and Python 3.4.**
- Minor updates for fixing compatibility issues with the latest version of scikit-learn (version > 0.21) and xgboost (v0.90)
- Default value of `template` parameter is changed to `None` instead.
- Fix errors in documentation
",45495679
1190,False,False,2019-04-19T15:18:14Z,2019-04-19T15:19:09Z,"- Add `data_file_path` option into `expert` function for replacing `'PATH/TO/DATA/FILE'` to customized dataset path in exported scripts. (Related issue #838)
- Change python version in CI tests to 3.7
- Add CI tests for macOS.",45495679
1191,False,False,2019-04-12T14:46:44Z,2019-04-12T14:48:07Z,"- Add a new `template` option to specify a desired structure for machine learning pipeline in TPOT. Check [TPOT API](https://epistasislab.github.io/tpot/api/) (it will be updated once it is merge to master branch).
- Add `FeatureSetSelector` operator into TPOT for feature selection based on *priori* export knowledge. Please check our [preprint paper](https://www.biorxiv.org/content/10.1101/502484v1.article-info) for more details (*Note: it was named `DatasetSelector` in 1st version paper but we will rename to FeatureSetSelector in next version of the paper*)
- Refine `n_jobs` parameter to accept value below -1. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one are used. It is related to the issue #846.
- Now `memory`  parameter can create memory cache directory if it does not exist. It is related to the issue #837.
- Fix minor bugs.",45495679
1192,False,False,2019-03-01T18:29:58Z,2019-03-01T18:30:35Z,"- Fix a bug causing that `max_time_mins` parameter doesn't work when `use_dask=True` in TPOT 0.9.5
- Now TPOT saves best pareto values best pareto pipeline s in checkpoint folder
- TPOT raises `ImportError` if operators in the TPOT configuration are not available when `verbosity>2`
- Thank @PGijsbers for the suggestions. Now TPOT can save scores of individuals already evaluated in any generation even the evaluation process of that generation is interrupted/stopped. But it is noted that, in this case, TPOT will raise this **warning message**: `WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.`, because the pipelines in early generation, e.g. 1st generation, are evolved/modified very limited times via evolutionary algorithm. 
- Fix bugs in configuration of `TPOTRegressor`
- Error fixes in documentation ",45495679
1193,False,False,2018-08-31T04:38:29Z,2018-09-04T16:41:09Z,"- **TPOT now supports integration with Dask for parallelization + smart caching**. Big thanks to the Dask dev team for making this happen!

- TPOT now supports for imputation/sparse matrices into `predict` and `predict_proba` functions. 

- `TPOTClassifier` and `TPOTRegressor` now follows scikit-learn estimator API.

- We refined scoring parameter in TPOT API for accepting [`Scorer` object](http://jaquesgrobler.github.io/online-sklearn-build/modules/generated/sklearn.metrics.Scorer.html).

- We refined parameters in VarianceThreshold and FeatureAgglomeration.

- TPOT now supports using memory caching within a Pipeline via a optional `memory` parameter.

- We improved documentation of TPOT.
",45495679
1194,False,False,2017-09-27T17:41:37Z,2017-09-27T17:56:34Z,"* **TPOT now supports sparse matrices** with a new built-in TPOT configurations, ""TPOT sparse"". We are using a custom OneHotEncoder implementation that supports missing values and continuous features.

* We have added an ""early stopping"" option for stopping the optimization process if no improvement is made within a set number of generations. Look up the `early_stop` parameter to access this functionality.

* TPOT now reduces the number of duplicated pipelines between generations, which saves you time during the optimization process.

* TPOT now supports custom scoring functions via the command-line mode.

* We have added a new optional argument, `periodic_checkpoint_folder`, that allows TPOT to periodically save the best pipeline so far to a local folder during optimization process.

* TPOT no longer uses `sklearn.externals.joblib` when `n_jobs=1` to avoid the potential freezing issue [that scikit-learn suffers from](http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux).

* We have added `pandas` as a dependency to read input datasets instead of `numpy.recfromcsv`. NumPy's `recfromcsv` function is unable to parse datasets with complex data types.

* Fixed a bug that `DEFAULT` in the parameter(s) of nested estimator raises `KeyError` when exporting pipelines.

* Fixed a bug related to setting `random_state` in nested estimators. The issue would happen with pipeline with `SelectFromModel` (`ExtraTreesClassifier` as nested estimator) or `StackingEstimator` if nested estimator has `random_state` parameter.

* Fixed a bug in the missing value imputation function in TPOT to impute along columns instead rows.

* Refined input checking for sparse matrices in TPOT.",45495679
1195,False,False,2017-06-01T22:09:48Z,2017-06-01T22:16:40Z,"* **TPOT now detects whether there are missing values in your dataset** and replaces them with the median value of the column.

* TPOT now allows you to set a `group` parameter in the `fit` function so you can use the [GroupKFold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html) cross-validation strategy.

* TPOT now allows you to set a subsample ratio of the training instance with the `subsample` parameter. For example, setting `subsample`=0.5 tells TPOT to create a fixed subsample of half of the training data for the pipeline optimization process. This parameter can be useful for speeding up the pipeline optimization process, but may give less accurate performance estimates from cross-validation.

* **TPOT now has more [built-in configurations](http://rhiever.github.io/tpot/using/#built-in-tpot-configurations)**, including TPOT MDR and TPOT light, for both classification and regression problems.

* `TPOTClassifier` and `TPOTRegressor` now expose three useful internal attributes, `fitted_pipeline_`, `pareto_front_fitted_pipelines_`, and `evaluated_individuals_`. These attributes are described in the [API documentation](http://rhiever.github.io/tpot/api/).

* Oh, **TPOT now has [thorough API documentation](http://rhiever.github.io/tpot/api/)**. Check it out!

* Fixed a reproducibility issue where setting `random_seed` didn't necessarily result in the same results every time. This bug was present since TPOT v0.7.

* Refined input checking in TPOT.

* Removed Python 2 uncompliant code.",45495679
1196,False,False,2017-03-22T20:43:15Z,2017-03-22T20:49:21Z,"TPOT 0.7 is now out, featuring multiprocessing support for Linux and macOS, customizable operator configurations, and more.

* **TPOT now has multiprocessing support (Linux and macOS only).** TPOT allows you to use multiple processes for accelerating pipeline optimization in TPOT with the `n_jobs` parameter in both TPOTClassifier and TPOTRegressor.

* TPOT now allows you to **customize the operators and parameters explored during the optimization process.** TPOT allows you to customize the list of operators and parameters in optimization process of TPOT with the `config_dict` parameter. The format of this customized dictionary can be found in the [online documentation](/using/#tpot-with-code).

* TPOT now allows you to **specify a time limit for evaluating a single pipeline**  (default limit is 5 minutes) in optimization process with the `max_eval_time_mins` parameter, so TPOT won't spend hours evaluating overly-complex pipelines.

* We tweaked TPOT's underlying evolutionary optimization algorithm to work even better, including using the [mu+lambda algorithm](http://deap.readthedocs.io/en/master/api/algo.html#deap.algorithms.eaMuPlusLambda). This algorithm gives you more control of how many pipelines are generated every iteration with the `offspring_size` parameter.

* Fixed a reproducibility issue where setting `random_seed` didn't necessarily result in the same results every time. This bug was present since version 0.6.

* Refined the default operators and parameters in TPOT, so TPOT 0.7 should work even better than 0.6.

* TPOT now supports sample weights in the fitness function if some if your samples are more important to classify correctly than others. The sample weights option works the same as in scikit-learn, e.g., `tpot.fit(x_train, y_train, sample_weights=sample_weights)`.

* The default scoring metric in TPOT has been changed from balanced accuracy to accuracy, the same default metric for classification algorithms in scikit-learn. Balanced accuracy can still be used by setting `scoring='balanced_accuracy'` when creating a TPOT instance.",45495679
1197,False,False,2016-09-02T19:50:21Z,2016-09-02T19:52:19Z,"- **TPOT now supports regression problems!** We have created two separate `TPOTClassifier` and `TPOTRegressor` classes to support classification and regression problems, respectively. The [command-line interface](http://rhiever.github.io/tpot//using/#tpot-on-the-command-line) also supports this feature through the `-mode` parameter.
- TPOT now allows you to **specify a time limit** for the optimization process with the `max_time_mins` parameter, so you don't need to guess how long TPOT will take any more to recommend a pipeline to you.
- Added a new operator that performs feature selection using [ExtraTrees](http://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees) feature importance scores.
- **[XGBoost](https://github.com/dmlc/xgboost) has been added as an optional dependency to TPOT.** If you have XGBoost installed, TPOT will automatically detect your installation and use the `XGBoostClassifier` and `XGBoostRegressor` in its pipelines.
- TPOT now offers a verbosity level of 3 (""science mode""), which outputs the entire Pareto front instead of only the current best score. This feature may be useful for users looking to make a trade-off between pipeline complexity and score.
",45495679
1198,False,False,2016-08-20T02:50:50Z,2016-08-20T03:06:30Z,"After a couple months hiatus in refactor land, we're excited to release the latest and greatest version of TPOT v0.5. For the past couple months, we worked on heavily refactoring TPOT's code base from a hacky research demo into a more elegant code base that will be easier to maintain in the long run. As an added bonus, TPOT now directly optimizes over and exports to scikit-learn [Pipeline objects](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), so your auto-generated code should be _much_ more readable.

Major changes in v0.5:
- Major refactor: Each operator is defined in a separate class file. Hooray for easier-to-maintain code!
- TPOT now **exports directly to scikit-learn Pipelines** instead of hacky code.
- Internal representation of individuals now uses scikit-learn pipelines.
- Parameters for each operator have been optimized so TPOT spends less time exploring useless parameters.
- We have removed pandas as a dependency and instead use numpy matrices to store the data.
- TPOT now uses **k-fold cross-validation** when evaluating pipelines, with a default k = 3. This k parameter can be tuned when creating a new TPOT instance.
- Improved **scoring function support**: Even though TPOT uses balanced accuracy by default, you can now have TPOT use [any of the scoring functions](http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values) that `cross_val_score` supports.
- Added the scikit-learn [Normalizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html) preprocessor.
- Minor text fixes.
",45495679
1199,False,False,2016-06-22T19:54:49Z,2016-06-23T13:01:58Z,"In TPOT 0.4, we've made some major changes to the internals of TPOT and added some convenience functions. We've summarized the changes below.

<ul>
<li>Added new sklearn models and preprocessors
<ul>
<li>AdaBoostClassifier</li>
<li>BernoulliNB</li>
<li>ExtraTreesClassifier</li>
<li>GaussianNB</li>
<li>MultinomialNB</li>
<li>LinearSVC</li>
<li>PassiveAggressiveClassifier</li>
<li>GradientBoostingClassifier</li>
<li>RBFSampler</li>
<li>FastICA</li>
<li>FeatureAgglomeration</li>
<li>Nystroem</li>
</ul></li>
<li>Added operator that inserts virtual features for the count of features with values of zero</li>
<li>Reworked parameterization of TPOT operators
<ul>
<li>Reduced parameter search space with information from a scikit-learn benchmark</li>
<li>TPOT no longer generates arbitrary parameter values, but uses a fixed parameter set instead</li>
</ul></li>
<li>Removed XGBoost as a dependency
<ul>
<li>Too many users were having install issues with XGBoost</li>
<li>Replaced with scikit-learn's GradientBoostingClassifier</li>
</ul></li>
<li>Improved descriptiveness of TPOT command line parameter documentation</li>
<li>Removed min/max/avg details during fit() when verbosity &gt; 1
<ul>
<li>Replaced with tqdm progress bar</li>
<li>Added tqdm as a dependency</li>
</ul></li>
<li>Added <code>fit_predict()</code> convenience function</li>
<li>Added <code>get_params()</code> function so TPOT can operate in scikit-learn's <code>cross_val_score</code> & related functions</li>
</ul>
",45495679
1200,False,False,2016-03-06T03:11:48Z,2016-03-06T17:02:56Z,"Zenodo requires me to make a new release to assign a DOI, so here's that release. This is not a full release.
",45495679
1201,False,False,2016-02-01T20:51:53Z,2016-02-03T13:35:23Z,"This is the version of TPOT that was used in the GECCO 2016 paper, ""Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science.""
",45495679
1202,False,False,2015-12-07T18:35:26Z,2015-12-07T18:52:50Z,"New in v0.2.0:
- TPOT now has the ability to export the optimized pipelines to sklearn code. See the [documentation](http://rhiever.github.io/tpot/examples/Using_TPOT_via_code/) for more information.
- Logistic regression, SVM, and k-nearest neighbors classifiers were added as pipeline operators. Previously, TPOT only included decision tree and random forest classifiers.
- TPOT can now use arbitrary scoring functions for the optimization process. See the [scoring function documentation](http://rhiever.github.io/tpot/examples/Custom_Scoring_Functions/) for more information.
",45495679
1203,False,False,2015-11-17T04:02:27Z,2015-11-18T14:33:38Z,,45495679
1204,False,False,2020-02-24T21:36:23Z,2020-02-24T21:58:42Z,"You can find the release notes for this month's release [in this blog post](https://blog.nteract.io/the-nteract-february-2020-release-3bbd3d2aa811).

That next desktop release will ship on **March 30th, 2020**.

Thank you for using the nteract desktop app! **nteract is a non-profit open-source organization fiscally sponsored by NumFOCUS. If you like our work, please consider [making a recurring donation](https://numfocus.org/donate-to-nteract).**",37496521
1205,False,False,2020-01-27T23:30:23Z,2020-01-28T00:02:57Z,"You can find the release notes for this month's release [in this blog post](https://blog.nteract.io/the-nteract-january-2020-release-a430d50ac0fd).

It's been a while since our last release (Setpember), but we're excited to announce that desktop releases will now ship on a monthly cadence at the end of each month. That mean's we'll see you on **February 24th, 2020 with our next release**.

Thank you for using the nteract desktop app! **nteract is a non-profit open-source organization fiscally sponsored by NumFOCUS. If you like our work, please consider [making a recurring donation](https://numfocus.org/donate-to-nteract).**",37496521
1206,False,False,2019-09-10T02:19:24Z,2019-09-10T02:58:36Z,"### Bug Fixes
- Fixes auto-save failing on open notebooks
- Focus next cell no longer focuses on editor when next cell is Markdown cell
- Fixes syntax highlighting on code blocks in Markdown outputs
",37496521
1207,False,False,2019-07-30T02:54:13Z,2019-07-30T03:11:50Z,"### Bug Fixes
- Fixes rendering for Bokeh in outputs

### Features
- Add supports for newer versions of Vega

### Acknowledgements
- @CrystallineCat ",37496521
1208,False,False,2019-07-15T19:47:19Z,2019-07-16T03:50:10Z,"### Features
- Add support for standard input requests

### Acknowledgements
- @captainsafia 
- @BenRussert ",37496521
1209,False,False,2019-05-20T23:28:03Z,2019-05-22T20:59:18Z,"### Bug Fixes
- Fix height of editor component (https://github.com/nteract/nteract/pull/4409)
-  Fix missing prompt buffer in Markdown cells (https://github.com/nteract/nteract/pull/4396)
- Hide status bar during PDF export (https://github.com/nteract/nteract/pull/4390)
- Use cardinality to get the best default for the hierarchical view (https://github.com/nteract/nteract/pull/4405)

### Acknowledgements
- @jarmokivekas
- @emeeks 
- @and0111",37496521
1210,False,False,2019-05-07T03:57:28Z,2019-05-07T04:26:01Z,"### Bug Fixes

- Updates quit dialog to have friendlier text in the action buttons

### Acknowledgements

- @jarmokivekas
",37496521
1211,False,False,2019-04-22T00:52:09Z,2019-04-22T20:09:13Z,"### Bug Fixes
- Fixes rendering for SVGs as media type
- Fixes issue with desktop theme config not persisting
- Fixes application not quitting when all windows closed on Windows

### Features
- Adds support for opening references to notebooks in nteract

### Notes
We're currently working on updating code signing on Windows for nteract. As a result, we're unfortunately unable to provide signed Windows installs in this release. Windows might prompt you with a notification stating that the application is from an unknown publisher. You can chose to run the application anyway. Thank you for your patience as we work to resolve this issue!

### Acknowledgements
- @BenRussert 
- @captainsafia ",37496521
1212,False,False,2019-04-05T03:13:26Z,2019-04-05T03:28:49Z,"#### Bug Fixes
* Bug fix for Data Explorer column filter (https://github.com/nteract/nteract/pull/4168)
* Fixes to Data Explorer summary and controls (https://github.com/nteract/nteract/pull/4299)

#### Improvements
* The nteract codebase is now using TypeScript under the hood.
* Performance enhancements related to `styled-components`
* Ability to add raw cells (#4002)

#### Acknowledgements
@emeeks 
@rgbkrk 
@BenRussert 
@stormpython 
@mpacer 
@willingc 
@lgeiger 
@kylebarron 
@lisamartin72 
@kelleyblackmore 
@captainsafia
",37496521
1213,False,False,2018-11-06T15:22:19Z,2018-11-06T16:44:38Z,* Fix crash on Windows,37496521
1214,False,False,2018-10-25T14:42:18Z,2018-10-25T14:53:52Z,"Some quick fixes for the last release

* Render notebooks with math properly on start by correctly using MathJax.Queue
* Throw a clear error when opening a notebook whose kernel cannot be located.",37496521
1215,False,False,2018-10-23T04:16:49Z,2018-10-23T04:50:29Z,"* Improved typeahead code completion
* Now supports ""Restart and Run All Cells""
* Send kernel shutdown messages when closing windows
* Mathjax component now using React 16 Context API
* Raw cells now editable!
* Data explorer adopts new blueprint.js components
* Data explorer adapts to dark theme",37496521
1216,False,False,2018-09-30T04:41:37Z,2018-09-30T05:04:45Z,"* New table component for the data explorer
* Data explorer will render on canvas when > 1000 points
* nteract on jupyter now allows python >= 3.5 (for the jupyter server)",37496521
1217,False,False,2018-09-10T23:35:41Z,2018-09-11T01:51:23Z,"## Desktop

* No more pesky kernel shutdown error when no kernel available
* Migrate examples to 🆕 [examples](https://github.com/nteract/examples) repo

## Web

* nteract on jupyter now respects `_xsrf` token
* nteract on jupyter now supports Python < 3.6

## Behind the Scenes

* Upgrade to babel 7 and next.js 7
* `<RichMedia />` component",37496521
1218,False,False,2018-08-15T00:56:17Z,2018-08-15T01:11:38Z,"Main change: LaTeX is back to working and not breaking your entire app 🔣🔥😱😅

See https://github.com/nteract/nteract/pull/3228 for details.

Happy Hacking!",37496521
1219,False,False,2018-08-08T21:03:53Z,2018-08-08T21:29:00Z,"* More help text for Data Explorer
* Palette chooser
* Less bugs in data explorer! Click More Things™!",37496521
1220,False,False,2018-07-31T00:44:59Z,2018-07-31T01:37:35Z,"📊 Data Explorer now has contour plots and heatmaps!

Datetime is now supported in the data explorer.

![contour plots](https://user-images.githubusercontent.com/495634/43361395-7dfacf2c-9282-11e8-8ebd-2fbb75419cf1.gif)

![time series plots](https://user-images.githubusercontent.com/495634/43349170-dba33d88-91b2-11e8-9e4d-42d02e19369c.png)",37496521
1221,False,False,2018-07-15T03:30:36Z,2018-07-15T04:15:42Z,"* _Really_ fixed AppImage build for Linux
* Unified directory listing component for commuter and jupyter extension
* Brand new `@mybinder` components and libraries for caching Binder hosts
* Tray icon for launching notebooks!

## Disclaimer for Desktop

The only bundled kernel with nteract desktop is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.

## Desktop Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.10.0/nteract-0.10.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.10.0/nteract-0.10.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.10.0/nteract-setup-0.10.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.10.0/nteract-0.10.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.10.0/nteract_0.10.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.10.0/nteract-0.10.0-x86_64.AppImage)


",37496521
1222,False,False,2018-06-21T22:40:27Z,2018-06-21T23:23:48Z,"🐧 🐇 📤 

A quick patch release that corrects builds for Linux and addresses some longstanding issues with outputs.

## Desktop

* Fixed AppImage build for Linux

## All Notebook Apps

* Corrected rendering of subsequent `text/plain` `display_data` and `execute_result` outputs
* Improved performance during app usage by using Immutable objects for outputs again, making sure to allow Hydrogen's non-immutable version

## Disclaimer for Desktop

The only bundled kernel with nteract desktop is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.

## Desktop Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.9.1/nteract-0.9.1.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.9.1/nteract-0.9.1-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.9.1/nteract-setup-0.9.1.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.9.1/nteract-0.9.1-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.9.1/nteract_0.9.1_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.9.1/nteract-0.9.1-x86_64.AppImage)

",37496521
1223,False,False,2018-06-14T22:41:45Z,2018-06-14T23:08:44Z,"🤓🔩

## Data Explorer

nteract desktop can now do the automatic dataviz that previously was only released on the jupyter extension.

## Component documentation

We're in the beginnings of documenting our components using [react-styleguidist](https://react-styleguidist.js.org/). You can see a sneak preview at [components.nteract.io](https://components.nteract.io).

## Jupyter Extension

Jupyter Extension has some exciting new additions including near menu parity with nteract desktop 🎉

- 📝 We now have a Monaco editor component

- ""Open..."" has been added to the menu and will redirect the user to the directory listing 

- Notebook cards have been scaled down and padding added to the bottom of the directory listing for easier viewing on smaller screens 

## Gist publishing

Gist publishing is much more stable now! :octocat: _However_, GitHub no longer allows new anonymous gists. 😢 All gists published from nteract must use authentication. 🔐

## Open Recent Menu

Now that we're on Electron 2.x, we can support an ""Open Recent"" menu. Right now it is only supported on macOS.

## Mega Vega

We support vega 2, vega 3, vega-lite 1, and vega-lite 2!

- 🐍 In Python use [Altair](https://altair-viz.github.io/)

- 🌶 In Scala use [Vegas](https://github.com/vegas-viz/Vegas)

![vega](https://user-images.githubusercontent.com/836375/41311196-6d849a2e-6e38-11e8-9d30-21553301beb2.gif)

## Miscellaneous

- Improved kernel clean up
- Better font sizes in drop down menu
- Upgraded to webpack 4\*

# Futures

For the next release, look forward to improved rendering performance and better kernel cleanup.

# Disclaimer for Desktop

The only bundled kernel with nteract desktop is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.

# Desktop Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.9.0/nteract-0.9.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.9.0/nteract-0.9.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.9.0/nteract-setup-0.9.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.9.0/nteract-0.9.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.9.0/nteract_0.9.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.9.0/nteract-0.9.0-x86_64.AppImage)

",37496521
1224,False,False,2018-03-14T21:37:38Z,2018-03-14T21:59:59Z,"## nteract v0.8.4

The Burnt Bernoulli release has a few fixes, though is mostly maintenance work under the hood.

* Cut/Copy/Paste cells now operate on the focused cell
* Pinned cell is gone (see https://github.com/nteract/nteract/pull/2658)
  * We'd love to support this kind of feature with some rethinking on how it's implemented. More than once it's been a stumbling block to maintaining the overall app. 

## Under the covers

We've switched over to a `byRef` structure for contents and kernels within the redux store. As a precursor to directory navigation and kernel switching in the jupyter extension, this brings us a clean setup for remote resources that may not have been loaded yet (or are in various states). Classically, users think there is one kernel running at a time. When you switch kernels (or start a new kernel), you effectively have two running -- the one being shutdown and the one starting up. The overall state structure is documented in [plan.md](https://github.com/nteract/nteract/blob/master/packages/core/plan.md) and looks roughly like this

```js
entities:
  currentNotebookRef: <contentRef>
  kernels:
    byRef:
      [kernelRef]: { // doesn't matter if this is a local or remote kernel
        channels: ...
      }
  contents:
    byRef: 
      [contentRef]: {
        filepath: somewhere
        model: actualNotebookDocument
      }
```

## Commuter and Notebook Preview

* (Re-)Improved syntax highlighting",37496521
1225,False,False,2018-03-08T19:30:38Z,2018-03-08T20:21:54Z,"## Updates

`redux-observable` was missing from dependencies in `@nteract/core`. This fixes the latest releases of `@nteract/commuter` and `@nteract/notebook-preview`. No user facing changes in desktop or the web apps.",37496521
1226,False,False,2018-03-07T20:01:11Z,2018-03-07T20:43:49Z,"Hey all! Thanks for reading the release notes for this nteract.io beta. We've gone through some major refactors to bring you a more stable release than ever before. 👷👷‍♀️ We could really use your help in building nteract out, so let us know how you'd like to be involved. We can get you plugged in!

## Release Notes

### UI features

* Kernels now sorted by display name in the menu (#2591)
* Improve messaging about kernel state (#2628, #2495)
* Log ""extra"" stdout / stderr streams from kernel to chrome console (#2646)
* Theme aware title bar in the webapp (#2551, #2547, #2545)
* Clear pager on output clear (#2525)
* Always create block math if `$$` occurs in markdown (#2499)
* New Menu Items (webapp):
  * Halt Kernel (#2529)
  * Restart Kernel (#2528, #2512)
  * Unhide and Clear All Outputs (#2517, #2520, #2512)
  * Execute All (#2518, #2519)
* Improved menu look (webapp) (#2494)

### Stability

* Editor now tracks subscriptions and closes them (#2505)

### Accessibilty

* All octicon SVGs now have a `<title>` tag to describe their intent (#2587)

### New components

* Notebook selection menu (#2623)
  * Note: not integrated in any app yet

![select your kernel](https://user-images.githubusercontent.com/836375/36950332-60edb18e-1fa9-11e8-90e5-302fd010d55c.gif)

### Big repo changes

* No more `@nteract/types` module (it's part of `@nteract/core` and the originating packages)
* `@nteract/commuter-frontend` has moved into `@nteract/commuter` directly to simplify publishing releases (#2634)

### Developer Experience

* Electron is upgraded to 1.8.3 (#2632)
* Addressed (almost all) flow type misconfigurations -- you're more likely to have a safe and sane setup (#2563, #2570, #2571, #2572, #2573, #2581, #2583, #2584, #2588, #2594, #2595, #2600, #2605, #2607, #2606, #2609, #2611, #2612, #2613, #2621, #2539, #2529, #2515, #2507, #2501)
* Refactored core into a new ""core state"" that switches us to a `byRef` structure and relies heavily on selectors to get state (#2592, #2601, #2603, #2605, #2602, #2614, #2619, #2616, #2620, #2626, #2642, #2541, #2522, #2514, #2511, #2500, #2490, #2493)
* Extract core components into pure and connected (#2578)
* Webpack configurations are more unified across all apps using the nteract webpack configurator (#2593, #2597, #2599, #2627, #2622)
* Hooked up showcase with new monorepo-aware webpack setup (#2622)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.

# Desktop Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.8.0/nteract-0.8.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.8.0/nteract-0.8.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.8.0/nteract-setup-0.8.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.8.0/nteract-0.8.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.8.0/nteract_0.8.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.8.0/nteract-0.8.0-x86_64.AppImage)

",37496521
1227,False,False,2018-02-07T22:11:44Z,2018-02-07T22:24:21Z,"# All Apps

* Fixed kernel stop/kill/restart bug

# Jupyter Extension

* Tightened up menu styling
* Cleaned up about page

# Desktop Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.7.1/nteract-0.7.1.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.7.1/nteract-0.7.1-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.7.1/nteract-setup-0.7.1.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.7.1/nteract-0.7.1-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.7.1/nteract_0.7.1_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.7.1/nteract-0.7.1-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.
",37496521
1228,False,False,2018-02-06T01:43:14Z,2018-02-06T02:08:53Z,"# Summary

* Maths are rendered so beautifully
* Improved kernel launch and shutdown
* We renamed Language ➡ Runtime, don't be alarmed 😇

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.7.0/nteract-0.7.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.7.0/nteract-0.7.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.7.0/nteract-setup-0.7.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.7.0/nteract-0.7.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.7.0/nteract_0.7.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.7.0/nteract-0.7.0-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.
",37496521
1229,False,False,2018-01-25T03:33:15Z,2018-01-25T03:57:26Z,* Hook up automatic kernel launching to the jupyter extension,37496521
1230,False,False,2018-01-25T03:00:11Z,2018-01-25T03:24:32Z,"* :octocat: No more accidentally trying to publish over anonymous gists
* under the covers enhancements to fetching kernelspecs and starting kernels for the jupyter extension",37496521
1231,False,False,2018-01-24T18:47:34Z,2018-01-24T18:58:30Z,"# Summary

This is a beautiful nteract beta release.

* Improved performance since last release
* Support for vega 3 and vegalite 2
* Initial table -> plot renderer (ask for more info)
* Markdown cells can be switched to render with a `ctrl-enter` again

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.6.0/nteract-0.6.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.6.0/nteract-0.6.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.6.0/nteract-setup-0.6.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.6.0/nteract-0.6.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.6.0/nteract_0.6.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.6.0/nteract-0.6.0-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1232,False,False,2018-01-03T20:22:59Z,2018-01-03T20:28:06Z,"# Summary

* Slightly cleaned up CSS
* Happier developers

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.5.5/nteract-0.5.5.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.5.5/nteract-0.5.5-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.5.5/nteract-setup-0.5.5.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.5.5/nteract-0.5.5-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.5.5/nteract_0.5.5_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.5.5/nteract-0.5.5-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1233,False,False,2017-12-31T22:39:26Z,2017-12-31T23:06:57Z,"# Summary

* Initial kernel connectivity much more reliable
* More notes to come

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.5.4/nteract-0.5.4.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.5.4/nteract-0.5.4-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.5.4/nteract-setup-0.5.4.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.5.4/nteract-0.5.4-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.5.4/nteract_0.5.4_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.5.4/nteract-0.5.4-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1234,False,False,2017-11-29T04:07:11Z,2017-11-29T06:47:22Z,"# Summary

* Clear execution count when clearing output (#2111)

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.3/nteract-0.4.3.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.3/nteract-0.4.3-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.3/nteract-setup-0.4.3.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.3/nteract-0.4.3-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.4.3/nteract_0.4.3_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.4.3/nteract-0.4.3-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.
",37496521
1235,False,False,2017-11-27T15:24:26Z,2017-11-27T16:18:00Z,"# Summary

* Fix markdown cell editor (#2104)
* Trim duplicate dependencies

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.2/nteract-0.4.2.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.2/nteract-0.4.2-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.2/nteract-setup-0.4.2.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.2/nteract-0.4.2-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.4.2/nteract_0.4.2_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.4.2/nteract-0.4.2-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1236,False,False,2017-11-27T00:10:30Z,2017-11-27T01:55:59Z,"# Summary

* Pagers have same CSS as outputs again (#2095)
* Ensure codemirror mode gets updated when language changes (#2096)
* Vendorize more CSS -- normalize, codemirror (#2090)

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.1/nteract-0.4.1.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.1/nteract-0.4.1-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.1/nteract-setup-0.4.1.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.1/nteract-0.4.1-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.4.1/nteract_0.4.1_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.4.1/nteract-0.4.1-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.
",37496521
1237,False,False,2017-11-22T00:07:22Z,2017-11-22T01:26:13Z,"# Summary

* Fix cell toolbar styling across themes

![screen shot 2017-11-21 at 5 28 49 pm](https://user-images.githubusercontent.com/836375/33105337-78bb99de-cee1-11e7-8df3-e41a25eb5d72.png)

* Cleaned up pin cell styling

![screen shot 2017-11-21 at 5 29 51 pm](https://user-images.githubusercontent.com/836375/33105366-9a71fe7e-cee1-11e7-9719-4f6b40b8c2b5.png)

* Cleaned up PDF export (note: please let us know how this release is, we've gone through sweeping CSS changes)
* More stable error handling, making usage of React's Error Boundaries. You can now break things more nicely!
* Fix Windows CLI
* Secret under the hood CSS changes that are going to bring nteract components to an app near you!

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.0/nteract-0.4.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.0/nteract-0.4.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.4.0/nteract-setup-0.4.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.4.0/nteract-0.4.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.4.0/nteract_0.4.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.4.0/nteract-0.4.0-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1238,False,False,2017-10-13T17:29:01Z,2017-10-13T21:32:40Z,"# Summary

* Don't shift focus if shift-enter on a sticky cell (#1789)
* Link to release notes in Help Menu. 👋  (#1968)
* Use CSS instead of JavaScript for hover state (#1975, #1972)
* Performance improvements and general enhancements (#1979, #1976, #1973, #1971)
* Fix unclickable cell dropdown menu for small cells (#1978)
* Auto updates for Linux AppImage! (#1980)


# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.4/nteract-0.3.4.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.4/nteract-0.3.4-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.4/nteract-setup-0.3.4.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.4/nteract-0.3.4-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.3.4/nteract_0.3.4_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.3.4/nteract-0.3.4-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1239,False,False,2017-10-10T03:17:12Z,2017-10-10T03:56:49Z,"# Summary

* Bring back the pager! (the `?` help) (#1965)
* Allow kernel interruption on Windows (#1966)
* Show the About Menu Item in the Help menu (#1966)

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.3/nteract-0.3.3.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.3/nteract-0.3.3-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.3/nteract-setup-0.3.3.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.3/nteract-0.3.3-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.3.3/nteract_0.3.3_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.3.3/nteract-0.3.3-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1240,False,False,2017-10-08T23:26:40Z,2017-10-09T00:33:27Z,"# Summary

* Improved validation for [`vdom`](https://github.com/nteract/vdom) output types (#1950, #1963)
* Editor line wrapping now disabled (#1940, #1945)
* Smoother startup (#1938, #1960)
* Slimmer build (only ~54 MB packed, ~142 MB unpacked) (#1934, #1935, #1937, #1941, #1956)
* Various under-the-hood bits (#1946, #1947, #1948, #1953, #1954, #1955, #1958, #1959)

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.2/nteract-0.3.2.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.2/nteract-0.3.2-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.2/nteract-setup-0.3.2.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.2/nteract-0.3.2-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.3.2/nteract_0.3.2_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.3.2/nteract-0.3.2-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.",37496521
1241,False,False,2017-10-04T04:43:10Z,2017-10-04T05:06:20Z,"# Summary

A quick patch release to solve a bug for Linux users ([#1931](https://github.com/nteract/nteract/pull/1931))

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.1/nteract-0.3.1.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.1/nteract-0.3.1-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.1/nteract-setup-0.3.1.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.1/nteract-0.3.1-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.3.1/nteract_0.3.1_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.3.1/nteract-0.3.1-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.

# Release notes for 0.3.x

Check out [v0.3.0](https://github.com/nteract/nteract/releases/tag/v0.3.0) for more thorough notes.",37496521
1242,False,False,2017-10-04T00:21:32Z,2017-10-04T01:03:58Z,"# Summary

This is our last alpha 😅 for the desktop app! 🛠 

This is technically one of our smallest releases with some of the biggest most game changingest features, including auto updating. Check out the release notes down below for more. 😄 

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.0/nteract-0.3.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.0/nteract-0.3.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.3.0/nteract.Setup.0.3.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.3.0/nteract-0.3.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.3.0/nteract_0.3.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.3.0/nteract-0.3.0-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.

# Gratitude

This release wouldn't be as amazing without all the wonderful contributors over the past two weeks (our quickest turnaround time 😝 ). We're loving this version and hope you do too. :heart:

People who contributed to this release:

* Daniel Chen
* John Detlefs
* Lukas Geiger
* Brian Granger
* Tim Head
* Kyle Kelley
* Eric Massey
* Madhumitha Natarajan
* Grant Nestor
* Marius van Niekerk
* M Pacer
* Kayur Patel
* Jay Phelps
* Carol Willing

Bots who contributed to this release:

* Appveyor
* Codecov
* Greenkeeper
* Travis CI

## Features

### Auto updating!

We've wanted this for a long time and now _you_ have access to it. [Demo video](https://www.youtube.com/watch?v=dsmb-Piocs0&feature=youtu.be) of an update.

🤞  Here's to hoping our next release auto upgrades in place for you cleanly after this release.

### `vdom` support

Hot off the presses, we've got integration with the new `vdom` output:

![screen shot 2017-10-03 at 5 57 43 pm](https://user-images.githubusercontent.com/836375/31155627-614674ac-a864-11e7-846c-0f0dc0a013c5.png)

One VDOM example notebook tutorial is built in to the app. Try it out today!

## Bug fixes

* Don't use shellEnv when launched from terminal (https://github.com/nteract/nteract/pull/1906)
* Fix modified indicator on mac
* Don't show close warning when file is already saved

## Extra under the hood 🚗  bits

* App size is smaller, both packed and unpacked
* We're on React 16!
* We're using the new [lettable operators from RxJS](https://github.com/ReactiveX/rxjs/blob/fb3694d0bae56545c4fa31fc2cf5bb6c603f9e83/doc/lettable-operators.md)",37496521
1243,False,False,2017-08-18T03:55:10Z,2017-08-18T04:26:28Z,"# Summary

This is our second to last alpha with massive improvements to user experience and stability. 🛠 

Check out the release notes down below. 😄 

# Installers

- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.2.0/nteract-0.2.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.2.0/nteract-0.2.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.2.0/nteract.Setup.0.2.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.2.0/nteract-0.2.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.2.0/nteract_0.2.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.2.0/nteract-0.2.0-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript (node.js). To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line. For other kernels, check out https://nteract.io/kernels.

# Gratitude

This release wouldn't be as amazing without all the wonderful contributors over the past six months (wow did it take a while to ship this one!). I'm loving this version and hope you do too. :heart:

People who contributed to this release:

* Safia Abdalla
* Ionică Bizău
* Alexander Booth
* Matthias Bussonnier
* John Detlefs
* Jonathan Frederic
* M. Scott Ford
* Lukas Geiger
* Al Johri
* Kyle Kelley
* Joshua Kornblum
* Randall Koutnik
* Gerald Nash
* Madhumitha Natarajan
* Grant Nestor
* Ryan Palo
* Dominique Peretti
* Min RK
* Peggy Rayzis
* Michael Stewart
* Marc Udoff
* Enrique Vidal
* Carol Willing

Bots who contributed to this release:

* Appveyor
* Codecov
* Greenkeeper
* Travis CI

## Features

### GeoJSON customization

The GeoJSON output type now accepts `url_template` and `layer_options` metadata to customize the geojson view. Check out the Notebook:

![look its mars](https://user-images.githubusercontent.com/836375/29480625-86cc75dc-842e-11e7-8cb5-6e72ba0b2bf0.png)

(#1585, #1579)

### Built in Table Viewer

In coordination with Pandas and Frictionless Data, we have a built in table viewer (#1534).

![table](https://user-images.githubusercontent.com/836375/29481159-01a332c4-8433-11e7-8ae5-7aa06dae5c3d.gif)

### Code Introspection

Get documentation inline by hitting a hot key (`cmd-.` on macOS) (#1665, #1488)

![Introspection](https://cloud.githubusercontent.com/assets/15242567/24030134/6437acea-0ab1-11e7-8790-39305329fd29.gif)

### One Dark Theme

Straight from Atom's default theme, it's [one dark theme](https://github.com/atom/one-dark-syntax) (#1756).

![quite dark really](https://user-images.githubusercontent.com/836375/29532970-8fae29e2-8664-11e7-95f4-acb6c5b0fc88.png)

### Other features

* Celltoolbar is now transparent when not hovered so you can see your text (#1615)

![translucent](https://cloud.githubusercontent.com/assets/335567/24727096/9a111f9c-1a09-11e7-88b9-5a4bef3afc80.gif)

* Support more metadata for input/source hiding (#1803, #1697)

* Cell focus no longer shows up on printed copies (#1788)

* Bottom of notebook has extra padding to allow last cell to be at the top (#1781, #1463)

* Vega and VegaLite outputs match official spec now (#1765)

* Prompt before closing (#1759)

* Report nteract version in the notebook metadata (#1747)

* Greatly improve height of display area (#1716)

* Improve performance of rendering text outputs (#1718, #1699)

* Expand collapsed cells on PDF export (#1671)

* Custom completion with recent IPython (#1650)

* Show celltoolbar on hover in addition to focus (#1618)

> Make it easier to reach for an action of a cell with one less click.

* Fade octicon with transitions

> Smooooooth operations

* nsis:perMachine (#1447)


* (Partial) support of raw cells (#1597, #1477)

* v3 Notebooks are converted to v4 notebooks (#1489)

* `File -> Exit (Alt-F4)` for win32 platforms (#1547)

* `cmd+enter` can now run cells on macOS (#1541)

## Bug fixes 🐛

* `nteract` CLI now works on \*nix systems (#1581)
* Complete revamp of scrolling behavior on cell focus (#1850)
* Support tooltip on Windows (#1669)
* Fix regression on viewing markdown rendering when cell not focused (#1846)
* Updated example notebooks (#1845, #1585)
* Surrogate pair handling (#1840)
* Improve kernel shutdown lifecycle (#1837, #1839)
* Data shape inference fixed on data resource transform (#1838)
* Scrollbar no longer visible after expansion (#1627)
* Cell evaluation status reflects overall state properly (#1608)
* Images are no longer centered by default (#1500)
* Feedback on save is more accurate (#1562)

## Under the hood 🚗 

* Optimize our app build even more than last time (#1847, #1780, #1771, #1613)
* Improved app building (#1826, #1774, #1613)
* All our modules aim to be server side renderable (primarily for [commuter](https://github.com/nteract/commuter))
* Compatibility with node 8 & npm5 (#1769, #1738)
* Transforms and notebook model are (internally) deprecating usage of Immutable.JS (#1726)
* Sourcemaps!!! (#1708)
* Up to date with React 15.6, ready for 16 to land (#1676, #1681, more)
* We switched to prettier for js and json formatting during this development cycle, :heart: it



## Announcing new packages

TBD",37496521
1244,False,False,2017-02-09T16:51:36Z,2017-02-09T17:26:12Z,"# Summary

This is our third to last alpha with massive stability improvements. 🛠 

Bonus:  we've begun the process of exporting some of our modules as packages for use in other applications. Stay tuned or get involved!

# Installers
- OS X/macOS
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.1.0/nteract-0.1.0.dmg)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.1.0/nteract-0.1.0-mac.zip)
- Windows
  - [Installer](https://github.com/nteract/nteract/releases/download/v0.1.0/nteract.Setup.0.1.0.exe)
  - [Zip](https://github.com/nteract/nteract/releases/download/v0.1.0/nteract-0.1.0-win.zip)
- Linux
  - [Debian package (Debian, Ubuntu, Mint)](https://github.com/nteract/nteract/releases/download/v0.1.0/nteract_0.1.0_amd64.deb)
  - [App Image](https://github.com/nteract/nteract/releases/download/v0.1.0/nteract-0.1.0-x86_64.AppImage)

# Disclaimer

The only bundled kernel is JavaScript. To detect your current python kernel you will need to run

```
python -m ipykernel install --user
```

at the command line.

# Gratitude

This release wouldn't be as amazing without all the wonderful contributors over the past month. This version of the notebook is looking good and much more stable than before.

People who contributed to this release:
- Safia Abdalla
- Jurmarcus Allen
- Alexander Booth
- John Detlefs
- Lukas Geiger
- Tim Head
- Paul Ivanov
- Kyle Kelley
- Jarmo Kivekas
- Christie Koehler
- Joshua Kornblum
- Ryan Laytham
- Peggy Rayzis
- David Siegel
- Aru Singh

Bots who contributed to this release:
- Greenkeeper
- Codecov

## Features
- Export to PDF for sharing or printing! (https://github.com/nteract/nteract/pull/1358, https://github.com/nteract/nteract/pull/1376, https://github.com/nteract/nteract/pull/1407)

![pdf-export](https://cloud.githubusercontent.com/assets/836375/22819520/541e7398-ef27-11e6-83cf-ba1e06dac11b.png)
- SVG Rendering! (https://github.com/nteract/nteract/pull/1369)

![Map of US Airports in nteract](https://cloud.githubusercontent.com/assets/7001/22308121/f4f91504-e345-11e6-989e-f38cf01345ba.png)
- Bundled ijavascript kernel! (https://github.com/nteract/nteract/pull/1339)

![screen shot 2017-02-10 at 12 14 40 am](https://cloud.githubusercontent.com/assets/836375/22819215/f0bc90ec-ef25-11e6-9597-ab199ce21343.png)
- Show the `display_name` of a kernel in the status bar (https://github.com/nteract/nteract/pull/1351)

## Bug fixes 🐛
- Improved Linux Packaging (https://github.com/nteract/nteract/pull/1299, https://github.com/nteract/nteract/pull/1304)
- Status bar now updates when execution state changes (https://github.com/nteract/nteract/pull/1292)
- Hide scrollbars (https://github.com/nteract/nteract/pull/1293)
- Indenting with tabs fixed (https://github.com/nteract/nteract/pull/1305, https://github.com/nteract/nteract/pull/1424, https://github.com/nteract/nteract/pull/1433)
- Improved Geo Tile decision making (https://github.com/nteract/nteract/pull/1308, https://github.com/nteract/nteract/pull/1426)
- Toolbar updates with cell change (https://github.com/nteract/nteract/pull/1318)
- Kernel launching cleaned up, runs by spec (https://github.com/nteract/nteract/pull/1264, https://github.com/nteract/nteract/pull/1338
- Hack around missing remote issue in Electron (https://github.com/nteract/nteract/pull/1362)
- Swap location of sticky and delete buttons to reduce likelihood of hitting delete instead of run (https://github.com/nteract/nteract/pull/1368)
- So. Much. Flow. (https://github.com/nteract/nteract/pull/1296, https://github.com/nteract/nteract/pull/1332, https://github.com/nteract/nteract/pull/1335, https://github.com/nteract/nteract/pull/1336, https://github.com/nteract/nteract/pull/1337, https://github.com/nteract/nteract/pull/1344, https://github.com/nteract/nteract/pull/1343, https://github.com/nteract/nteract/pull/1345, https://github.com/nteract/nteract/pull/1348, https://github.com/nteract/nteract/pull/1372, https://github.com/nteract/nteract/pull/1374, https://github.com/nteract/nteract/pull/1373, https://github.com/nteract/nteract/pull/1382)
- Markdown cells now compliant (https://github.com/nteract/nteract/pull/1315)
- Slightly hidden models experiment, open an issue or chat with us to play with it :wink: (https://github.com/nteract/nteract/pull/1313)
- When converting a code cell to a markdown cell, it stays in edit mode for you (https://github.com/nteract/nteract/pull/1409)
- Pressing the down arrow when at the bottom of the notebook creates new cells based on what the prior cell is (https://github.com/nteract/nteract/pull/1435)

## Announcing new packages

We've begun shipping React components and libraries from the innards of the Electron app so that separate applications can be built with these, including a web version of nteract (for example, check out [commuter](https://github.com/nteract/commuter)). (https://github.com/nteract/nteract/pull/1443, https://github.com/nteract/nteract/pull/1440). Some of the packages include:
- `@nteract/commutable` (https://github.com/nteract/nteract/pull/1366, https://github.com/nteract/nteract/pull/1379)
- `@nteract/transforms` (https://github.com/nteract/nteract/pull/1420)
",37496521
1245,False,True,2016-11-28T19:04:07Z,2016-11-28T19:12:22Z,"## Summary

Another alpha with a lot of improvements to the editor, performance, and environment.

## Installers

* [OS X / macOS](https://github.com/nteract/nteract/releases/download/v0.0.15/nteract-0.0.15.dmg)
* [Windows](https://github.com/nteract/nteract/releases/download/v0.0.15/nteract-0.0.15.exe)
* [Linux AppImage x64](https://github.com/nteract/nteract/releases/download/v0.0.15/nteract-0.0.15-x86_64.AppImage)

If you need another kind, see the bottom of these release notes.

## Disclaimer

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python -m pip install ipykernel
python -m ipykernel install --user
```

## Gratitude

This release wouldn't be as amazing without all the wonderful contributors over the past month. The nteract notebook is looking _good_.

People who contributed to this release:
- Safia Abdalla
- Thomas Ballinger
- Noah Berman
- Alexander Booth
- John Detlefs
- Darshan Gada
- Lukas Geiger
- Paul Ivanov
- Kyle Kelley
- Laura Kinson
- Joshua Kornblum
- Daniel Noventa
- Victor Perez
- Peggy Rayzis

Bots who contributed to this release:
- Greenkeeper

## Features! :tada:
- Updating displays (#1162, #1158)

![the progress is real](https://cloud.githubusercontent.com/assets/836375/20238495/e0e04526-a8a1-11e6-8db1-e2fae3e14d4c.gif)
- Vega/vega-lite support (#1113, #1146)

![vega lite](https://cloud.githubusercontent.com/assets/836375/19845076/99ef451e-9ef0-11e6-9c6d-7df19de2005c.png)
- Styled scroll bars (#1184, #1247)
- File icons for notebooks! (#1209)

![little notebooks](https://cloud.githubusercontent.com/assets/836375/20683440/d4fb75d4-b560-11e6-940e-680b86d67902.png)
- See your cursor again (#1207)

![Look at that, less blocky parens](https://cloud.githubusercontent.com/assets/13285808/20377230/b44d6b0c-ac5b-11e6-84e3-54f29ff8cab1.png)
- Configuration option for cursor blinking (#1205)
- ""Run cells below"" menu option (#1195)
- Default scroll height larger to accommodate typical output and screen size (#1142)
- Custom DMG Background on macOS (#1126)

![install you some nteract for the greater good](https://cloud.githubusercontent.com/assets/836375/20683835/5987c3d8-b562-11e6-9a61-565ea65aa174.png)
- Improved splash screen, high DPI MP4 (#1064, #1066)

![nteract animatioooooonnnnn](https://github.com/nteract/nteract/blob/54038e85d2976b09c96ef099a3d8732e91734c8b/app/static/loading.gif?raw=true)

## Bug fixes
- Supreme refactors of cell focus (#1197, #1194, #1167)
- Regression: Wrong keys were previously set in the notebook document (on disk), resulting in notebooks that would not load in jupyter (#1224, #1225, #1233, #1180, #1159)
- Modified indicator is _less_ wrong (#1204)
- Handling of messages fixed for many types (#1172)
- GitHub gist error handling updates (#1161, #1156)
- Status bar now shows `loading... | not connected` instead of `| not connected` (#1150)
- Zoom reset now set to 100% (#1138)
- Icon loads on Windows now! (#1057)
",37496521
1246,False,True,2016-10-21T14:59:06Z,2016-10-21T15:03:29Z,"## Summary

Happy Friday! We’ve been working hard to get another alpha release out for you! It’s packed with new features and under the hood enhancements. Check ‘em out below.

If this is your first time using our app, be sure to check out the  [User Guide](https://github.com/nteract/nteract/blob/master/USER_GUIDE.md).

## Disclaimer

Note that we don’t have a built-in kernel with this release yet, so you will need to install the kernels yourself using.

```
python -m pip install ipykernel
python -m ipykernel install --user
```

## Features 🎉 🌮
- Added reinstall script! Run `npm run reinstall` to nuke all `node_modules` and run `npm install`.
- Initialize configuration file and Jupyter runtime directories on app start if they are not already present
- Added Example Notebooks under the File menu
- Added expandable output area
  ![ezgif com-video-to-gif 4](https://cloud.githubusercontent.com/assets/1857993/19603086/7174af70-9775-11e6-878c-c44f4febe429.gif)
- Added User Guide for new application users
- Added a more robust interface for starting nteract from the command line
- Added diagnostics scripts for diagnosing kernel problems, run `npm run diagnostics`
- Fixed stylings on dropdown menus
- Added a JSON display transform
  ![ezgif com-video-to-gif 3](https://cloud.githubusercontent.com/assets/1857993/19603090/77549c84-9775-11e6-8550-ce0025da2327.gif)
- You can now reset the zoom level of the application using Cmd+Option+0
- Add nteract.json configuration to `~/.jupyter`

## Under the Hood 🚗
- Added Flow typings to our React components
- Use WebPack to build/bundle our project
- We’re now using the latest version of Electron
- Removed string refs and other nasties in React components
",37496521
1247,False,True,2016-10-04T03:35:56Z,2016-10-04T03:40:34Z,"## Summary

Incredible alpha with a lot of improvements to the editor, performance, and environment. Skip down to downloads for your own copy on OS X, Linux, or Windows.

## Disclaimer

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python -m pip install ipykernel
python -m ipykernel install --user
```

## Gratitude

This release wouldn't be as amazing without all the wonderful contributors over the past couple weeks. The nteract notebook is looking _good_.

People who contributed to this release:
- Safia Abdalla
- Alexander Booth
- John Detlefs
- Andreea-Daniela Ene
- Sam Evanuk
- Lukas Geiger
- Estevan Jantsk
- Alaina Kafkes
- Abhishek Kapatkar
- Kyle Kelley
- Stephy Miehle
- Phil Plückthun

Bots who contributed to this release:
- Greenkeeper

## Features! :tada:
- Editor: Paren and bracket matching (https://github.com/nteract/nteract/pull/892)
- Editor: Per cell find and replace (https://github.com/nteract/nteract/pull/875) - [Video](https://www.youtube.com/watch?v=VyE0Vb_P9dY) 
- New nteract theme! (https://github.com/nteract/nteract/pull/883)

![super slick nteract color theme](https://cloud.githubusercontent.com/assets/6765732/19022716/1f98cb08-88a4-11e6-890c-d4fffbf4c672.png)
- Environment picks up user's shell environment (https://github.com/nteract/nteract/pull/842)
- Splash page on startup during load (https://github.com/nteract/nteract/pull/853)
- Status bar/gutter (https://github.com/nteract/nteract/pull/815)
- Better table CSS (https://github.com/nteract/nteract/pull/825)
- Blockquote styling (https://github.com/nteract/nteract/pull/850)

![look at those block quotes](https://cloud.githubusercontent.com/assets/836375/18940543/dccb5b6c-85bd-11e6-96d4-f86d83b07458.png)
- Initial support for the comms message spec (https://github.com/nteract/nteract/pull/827, https://github.com/nteract/nteract/pull/858)
- GitHub authentication now more seamless, allows direct login (https://github.com/nteract/nteract/pull/826, https://github.com/nteract/nteract/pull/846, https://github.com/nteract/nteract/pull/862)
- Editor: IPython CodeMirror mode (https://github.com/nteract/nteract/pull/871)

## Bug :bug: fixes
- Cell: Cell is busy as soon as executed, across all cells (https://github.com/nteract/nteract/pull/882)
- Editor: Behaves more like you expect for Intellisense (https://github.com/nteract/nteract/pull/869)
- Editor: Make indentUnit and tabSize match (https://github.com/nteract/nteract/pull/873)
- Output: Metadata now passed through to transforms (https://github.com/nteract/nteract/pull/812)
- Editor: Max-width restriction removed to accommodate longer type ahead completions (https://github.com/nteract/nteract/pull/817)
- Title bar: [OS X] Brought back `setRepresentedFilename` (https://github.com/nteract/nteract/pull/821)

![setRepresentedFilename](https://cloud.githubusercontent.com/assets/836375/18761813/516b6f82-80bb-11e6-8ce5-80c4af69488a.png)
- Ensure that window closure happens after first notebook launched (https://github.com/nteract/nteract/pull/866)
- Status bar: No more floating 👻 text in status bar (https://github.com/nteract/nteract/pull/877)
- Native: Icon path resolved properly (https://github.com/nteract/nteract/pull/881)

🌮 🌯 🍜
",37496521
1248,False,True,2016-09-20T07:34:36Z,2016-09-20T07:41:19Z,"### Bug Fixes
- Ignore Process Serial Number argument on OS X to allow startup

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```
",37496521
1249,False,True,2016-09-20T01:14:16Z,2016-09-20T01:22:31Z,"### Release Notes

NOTE: This release has a first-time startup bug on OS X that is fixed in later releases. Go see [all the later releases](https://github.com/nteract/nteract/releases).

#### Bug Fixes
- New kernels and notebooks now appropriately start off in the user's home directory
- Application now loads appropriately when launched from the command line with notebooks
- Fixed formatting for outputs that are rendered from the R kernel

#### Features
- Users are now prompted about restarting kernels if they have saved a notebook to a new location
- Python 3 is assumed to be the default kernel when launching the app on start, followed by Python 2, then your first kernel lexicographically

#### Under the Hood
- Improvements to RxJS flow for code completion and kernel info acquisition
- Adopted the conventional CHANGELOG standard for commit and PR messages
- Added tests for theming, execution, gist publishing epics, and more
- cellStatuses are now stored within the cellMap as opposed to a separate data structure
- Made react-jupyter-display-area part of the repository

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```
",37496521
1250,False,True,2016-09-14T22:39:09Z,2016-09-14T22:44:45Z,"#### Bug Fixes
- Application now warns user if they have no kernels installed on launch
- Toolbar now only renders options that are available based on cell type
- Autocomplete now works properly in multiline cells and _should_ be more responsive

#### Features
- Markdown content is rendered live as the user types

#### Under the Hood
- Added tests for uncovered code paths
- Application launch now utilizes streams
- Optimizations for code completion streams
- Optimizations for code execution streams

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```
",37496521
1251,False,True,2016-09-12T19:47:53Z,2016-09-12T19:52:15Z,"New alpha release!
- Launch is more seamless with less serialization, resulting in faster startup
- Leaflet/GeoJSON render no longer scrolls on mouse scroll (to allow notebook scroll)
- Much better tested than before
- GitHub publication more stable, respects `GITHUB_TOKEN` environment variable
- Super up to date with RxJS
- Free puppies
- Just kidding

If you don't already have your kernels installed directly, get the Python3 kernel at the very least:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```
",37496521
1252,False,True,2016-09-09T17:46:18Z,2016-09-09T17:48:13Z,"Mega Alpha Release!

## Support for direct GeoJSON

Python:

``` python
import IPython
import json

def geojson(data):
  bundle = {}
  bundle['application/vnd.geo+json'] = data
  IPython.display.display(bundle, raw=True)

import requests
coffee = requests.get(""https://bit.ly/coffeeDC"").json()

geojson(coffee)
```

<img width=""800"" alt=""screen shot 2016-09-09 at 10 54 22 am"" src=""https://cloud.githubusercontent.com/assets/836375/18397171/d5eabeec-767b-11e6-844b-51ced5571ced.png"">

## Direct Plotly support

``` python
import IPython
import json

def plotize(data, layout=None):
  """"""Plot with Plotly.js using the Plotly JSON Chart Schema

  http://help.plot.ly/json-chart-schema/
  """"""
  if layout is None:
    layout = {}

  bundle = {}
  bundle['application/vnd.plotly.v1+json'] = {
    'data': data,
    'layout': layout,
  }

  IPython.display.display(bundle, raw=True)

data = [
  {'x': [1999, 2000, 2001, 2002], 'y': [10, 15, 13, 17], 'type': 'scatter'},
  {'x': [1999, 2000, 2001, 2002], 'y': [16, 5, 11, 9], 'type': 'scatter'}
]

layout = {
  'title': 'How is Plotting, really?',
  'xaxis': { 'title': 'Year', 'showgrid': False, 'zeroline': False },
  'yaxis': { 'title': 'Percent', 'showline': False }
}

plotize(data, layout)
```

<img width=""795"" alt=""screen shot 2016-09-09 at 10 57 00 am"" src=""https://cloud.githubusercontent.com/assets/836375/18397254/2e2660d4-767c-11e6-9bf2-ea2d1e90b93a.png"">

If you have plotly.py, you can also use plotly.py data and layout tricks using their encoder:

``` python
def plotize(data, layout=None):
  """"""Plot with Plotly.js using the Plotly JSON Chart Schema

  http://help.plot.ly/json-chart-schema/
  """"""
  if layout is None:
    layout = {}

  redata = json.loads(json.dumps(data, cls=plotly.utils.PlotlyJSONEncoder))
  relayout = json.loads(json.dumps(layout, cls=plotly.utils.PlotlyJSONEncoder))

  bundle = {}
  bundle['application/vnd.plotly.v1+json'] = {
    'data': redata,
    'layout': relayout,
  }

  IPython.display.display(bundle, raw=True)
```

## Stability fixes

We've got some of those.
",37496521
1253,False,True,2016-08-26T03:28:31Z,2016-08-26T03:37:42Z,"Another alpha release! Mostly stability and performance updates, nothing too crazy.

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```
",37496521
1254,False,True,2016-08-24T19:54:58Z,2016-08-24T20:04:06Z,"Another alpha release, this time with a signed OS X app that _does not_ require libzmq to be installed on the system. :tada:

However, there's a bug where an error will occur on the first time you launch nteract. You can launch again freely after that. We're digging into it.

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```
",37496521
1255,False,True,2016-08-10T19:53:21Z,2016-08-10T19:56:52Z,"Another alpha release, this time with a signed OS X app that _does not_ require libzmq to be installed on the system. :tada:

No built in kernel, you will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```
",37496521
1256,False,True,2016-07-23T17:38:09Z,2016-07-23T17:55:13Z,"Note: this is a bad release with path issues. Posting to leave the issue up.

You will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```

Additionally, you may need ZMQ installed. You can install with `brew` if on a Mac:

```
brew install zmq czmq
```

If it seems _nteract_ is not behaving correctly, you can try to investigate by selecting the `View` menu, then `Toggle Developer Tools`.
",37496521
1257,False,True,2016-05-16T02:58:16Z,2016-05-16T03:05:28Z,"Another pre-alpha, this time with a signed OS X app.

You will need kernels to be installed directly to run nteract:

```
python3 -m pip install ipykernel
python3 -m ipykernel install --user
```

Additionally, you may need ZMQ installed. You can install with `brew` if on a Mac:

```
brew install zmq czmq
```

If it seems _nteract_ is not behaving correctly, you can try to investigate by selecting the `View` menu, then `Toggle Developer Tools`.
",37496521
1258,False,True,2016-05-01T04:05:15Z,2016-05-01T04:07:15Z,"Practicing releases. Nothing to see here just yet.

:wink:
",37496521
1259,False,False,2020-03-02T15:11:45Z,2020-03-02T15:46:03Z,"## New features:
- The main feature of the release is the support of non symmetric trees for training on CPU.
Using non symmetric trees might be useful if one-hot encoding is present, or data has little noise.
To try non symmetric trees change [``grow_policy`` parameter](https://catboost.ai/docs/concepts/parameter-tuning.html#tree-growing-policy).
Starting from this release non symmetric trees are supported for both CPU and GPU training.
- The next big feature improves catboost text features support.
Now tokenization is done during training, you don't have to do lowercasing, digit extraction and other tokenization on your own, catboost does it for you.
- Auto learning-rate is now supported in CPU MultiClass mode.
- CatBoost class supports ``to_regressor`` and ``to_classifier`` methods.

The release also contains a list of bug fixes.",97556265
1260,False,False,2020-01-31T16:09:30Z,2020-01-31T16:55:05Z,"## New features:
- The main feature of this release is the Stochastic Gradient Langevin Boosting (SGLB) mode that can improve quality of your models with non-convex loss functions. To use it specify ``langevin`` option and tune ``diffusion_temperature`` and ``model_shrink_rate``. See [the corresponding paper](https://arxiv.org/abs/2001.07248) for details.

## Improvements:

- Automatic learning rate is applied by default not only for ``Logloss`` objective, but also for ``RMSE`` (on CPU and GPU) and ``MultiClass`` (on GPU).
- Class labels type information is stored in the model. Now estimators in python package return values of proper type in ``classes_`` attribute and for prediction functions with ``prediction_type=Class``. #305, #999, #1017.
  Note: Class labels loaded from datasets in [CatBoost dsv format](https://catboost.ai/docs/concepts/input-data_values-file.html) always have string type now.

## Bug fixes:
- Fixed huge memory consumption for text features. #1107
- Fixed crash on GPU on big datasets with groups (hundred million+ groups).
- Fixed class labels consistency check and merging in model sums (now class names in binary classification are properly checked and added to the result as well)
- Fix for confusion matrix (PR #1152), thanks to @dmsivkov.
- Fixed shap values calculation when ``boost_from_average=True``. #1125
- Fixed use-after-free in fstr PredictionValuesChange with specified dataset
- Target border and class weights are now taken from model when necessary for feature strength, metrics evaluation, roc_curve, object importances and calc_feature_statistics calculations.
- Fixed that L2 regularization was not applied for non symmetric trees for binary classification on GPU.
- [R-package] Fixed the bug that ``catboost.get_feature_importance`` did not work after model is loaded #1064
- [R-package] Fixed the bug that ``catboost.train`` did not work when called with the single dataset parameter. #1162 
- Fixed L2 score calculation on CPU

## Other:

- Starting from this release Java applier is released simultaneously with other components and has the same version.

## Compatibility:

- Models trained with this release require applier from this release or later to work correctly.",97556265
1261,False,False,2019-12-25T16:18:28Z,2019-12-25T20:11:43Z,"## New features:
- String class labels are now supported for binary classification
- [CLI only] Timestamp column for the datasets can be provided in separate files.
- [CLI only] Timesplit feature evaluation.
- Process groups of any size in block processing.


## Bug fixes:
- ``classes_count`` and ``class_weight`` params can be now used with user-defined loss functions. #1119
- Form correct metric descriptions on GPU if ``use_weights`` gets value by default. #1106
- Correct ``model.classes_`` attribute for binary classification (proper labels instead of always ``0`` and ``1``). #984
- Fix ``model.classes_`` attribute when classes_count parameter was specified.
- Proper error message when categorical features specified for MultiRMSE training. #1112
- Block processing: It is valid for all groups in a single block to have weights equal to 0
- fix empty asymmetric tree index calculation. #1104",97556265
1262,False,False,2019-12-11T02:13:44Z,2019-12-11T02:46:42Z,"## New features:
- Have `leaf_estimation_method=Exact` the default for MAPE loss
- Add `CatBoostClassifier.predict_log_proba()`, PR #1095

## Bug fixes:
- Fix usability of read-only numpy arrays, #1101
- Fix python3 compatibility for `get_feature_importance`, PR #1090
- Fix loading model from snapshot for `boost_from_average` mode
",97556265
1263,False,False,2019-11-28T03:51:06Z,2019-11-28T04:17:06Z,"New submodule for text processing!
It contains two classes to help you make text features ready for training:
- [Tokenizer](https://github.com/catboost/catboost/blob/afb8331a638de280ba2aee3831ac9df631e254a0/library/text_processing/tokenizer/tokenizer.pxi#L77) -- use this class to split text into tokens (automatic lowercase and punctuation removal)
- [Dictionary](https://github.com/catboost/catboost/tree/master/library/text_processing/dictionary) -- with this class you create a dictionary which maps tokens to numeric identifiers. You then use these identifiers as new features.

## New features:
- Enabled `boost_from_average` for `MAPE` loss function

## Bug fixes:
- Fixed `Pool` creation from `pandas.DataFrame` with discontinuous columns, #1079
- Fixed `standalone_evaluator`, PR #1083

## Speedups:
- Huge speedup of preprocessing in python-package for datasets with many samples (>10 mln)

We also release precompiled packages for Python 3.8",97556265
1264,False,False,2019-11-19T15:17:02Z,2019-11-19T15:55:01Z,"## New features:
- With this release we support `Text` features for *classification on GPU*. To specify text columns use `text_features` parameter. Achieve better quality by using text information of your dataset. See more in [Learning CatBoost with text features](https://github.com/catboost/tutorials/tree/master/text_features/text_features_in_catboost.ipynb)
- `MultiRMSE` loss function is now available on CPU. Labels for the multi regression mode should be specified in separate `Label` columns
- MonoForest framework for model analysis, based on our NeurIPS 2019 [paper](https://papers.nips.cc/paper/9530-monoforest-framework-for-tree-ensemble-analysis). Learn more in [MonoForest tutorial](https://github.com/catboost/tutorials/tree/master/model_analysis/monoforest_tutorial.ipynb)
- `boost_from_average` is now `True` by default for `Quantile` and `MAE` loss functions, which improves the resulting quality

## Speedups:
- Huge reduction of preprocessing time for datasets loaded from files and for datasets with many samples (> 10 million), which was a bottleneck for GPU training
- 3x speedup for small datasets
",97556265
1265,False,False,2019-10-31T03:11:55Z,2019-10-31T03:32:21Z,"## New features:
- Now `datasets.msrank()` returns _full_ msrank dataset. Previously, it returned the first 10k samples.
We have added `msrank_10k()` dataset implementing the past behaviour.

## Bug fixes:
- `get_object_importance()` now respects parameter `top_size`, #1045 by @ibuda
",97556265
1266,False,False,2019-10-21T16:13:05Z,2019-10-21T16:33:02Z,"- The main feature of the release is huge speedup on small datasets. We now use MVS sampling for CPU regression and binary classification training by default, together with `Plain` boosting scheme for both small and large datasets. This change not only gives the huge speedup but also provides quality improvement!
- The `boost_from_average` parameter is available in `CatBoostClassifier` and `CatBoostRegressor`
- We have added new formats for describing monotonic constraints. For example, `""(1,0,0,-1)""` or `""0:1,3:-1""` or `""FeatureName0:1,FeatureName3:-1""` are all valid specifications. With Python and `params-file` json, lists and dictionaries can also be used

## Bugs fixed:
- Error in `Multiclass` classifier training, #1040
- Unhandled exception when saving quantized pool, #1021
- Python 3.7: `RuntimeError` raised in `StagedPredictIterator`, #848

",97556265
1267,False,False,2019-10-10T13:13:06Z,2019-10-10T15:29:38Z,"## Bugs fixed:
- `System of linear equations is not positive definite` when training MultiClass on Windows, #1022
- Cat feature values could be taken from floating-point data. We have forbidden this
- Handling of numpy.ndarray features data with categorical features is corrected",97556265
1268,False,False,2019-10-01T16:06:42Z,2019-10-01T16:29:06Z,"## Improvements:
- Massive 2x speedup for `MultiClass` with many classes
- Updated MVS implementation. See _Minimal Variance Sampling in Stochastic Gradient Boosting_ by Bulat Ibragimov and Gleb Gusev at [NeurIPS 2019](https://neurips.cc/Conferences/2019)
- Added `sum_models` in R-package, #1007

## Bugs fixed:
- Multi model initialization in python, #995
- Mishandling of 255 borders in training on GPU, #1010
",97556265
1269,False,False,2019-09-24T07:30:24Z,2019-09-24T07:32:21Z,"## Improvements:
- New visualization for parameter tuning. Use `plot=True` parameter in `grid_search` and `randomized_search` methods to show plots in jupyter notebook
- Switched to jemalloc allocator instead of LFalloc in CLI and model interfaces to fix some problems on Windows 7 machines, #881
- Calculation of binary class AUC is faster up to 1.3x
- Added [tutorial](https://github.com/catboost/tutorials/blob/master/convert_onnx_model/tutorial_convert_onnx_models.ipynb) on using fast CatBoost applier with LightGBM models

## Bugs fixed:
- Shap values for `MultiClass` objective don't give constant 0 value for the last class in case of GPU training.
  Shap values for `MultiClass` objective are now calculated in the following way. First, predictions are normalized so that the average of all predictions is zero in each tree. The normalized predictions produce the same probabilities as the non-normalized ones. Then the shap values are calculated for every class separately. Note that since the shap values are calculated on the normalized predictions, their sum for every class is equal to the normalized prediction
- Fixed bug in rangking tutorial, #955
- Allow string value for `per_float_feature_quantization` parameter, #996
",97556265
1270,False,False,2019-09-19T03:16:40Z,2019-09-19T03:31:29Z,"## Improvements:
- For metric MAE on CPU default value of `leaf-estimation-method` is now `Exact`
- Speed up `LossFunctionChange` feature strength computation

## Bugs fixed:
- Broken label converter in grid search for multiclassification, #993
- Incorrect prediction with monotonic constraint, #994
- Invalid value of `eval_metric` in output of `get_all_params()`, #940
- Train AUC is not computed because hint `skip_train~false` is ignored, #970
",97556265
1271,False,False,2019-09-13T15:18:47Z,2019-09-13T15:35:05Z,"## Bugs fixed:
- Incorrect estimation of total RAM size on Windows and Mac OS, #989
- Failure when dataset is a `numpy.ndarray` with `order='F'`
- Disable `boost_from_average` when baseline is specified

## Improvements:
- Polymorphic raw features storage (2x---25x faster data preparation for numeric features in non-float32 columns as either `pandas.DataFrame` or `numpy.ndarray` with `order='F'`).
- Support AUC metric for `CrossEntropy` loss on CPU
- Added `datasets.rotten_tomatoes()`, a textual dataset
- Usability of `monotone_constraints`, #950

## Speedups:
- Optimized computation of `CrossEntropy` metric on CPUs with SSE3
",97556265
1272,False,False,2019-09-10T03:09:43Z,2019-09-10T03:30:39Z,"## New features:
- Sparse data support
- We've implemented and set to default `boost_from_average` in RMSE mode. It gives a boost in quality especially for a small number of iterations.

## Improvements:
- Quantile regression on CPU
- default parameters for Poisson regression

## Speedups:
- A number of speedups for training on CPU
- Huge speedups for loading datasets with categorical features represented as `pandas.Categorical`.
Hint: use `pandas.Categorical` instead of object to speed up loading up to 200x.
",97556265
1273,False,False,2019-08-20T07:08:41Z,2019-08-20T07:25:42Z,"## Breaking changes:
- All metrics except for AUC metric now use weights by default.
## New features:
- Added `boost_from_average` parameter for RMSE training on CPU which might give a boost in quality.
- Added conversion from ONNX to CatBoost. Now you can convert XGBoost or LightGBM model to ONNX, then convert it to CatBoost and use our fast applier. Use `model.load_model(model_path, format=""onnx"")` for that.
## Speed ups:
- Training is  ~15% faster for datasets with categorical features.
## Bug fixes:
- R language: `get_features_importance` with `ShapValues` for `MultiClass`,  #868
- NormalizedGini was not calculated,  #962
- Bug in leaf calculation which could result in slightly worse quality if you use weights in binary classification mode
- Fixed `__builtins__` import in Python3 in PR #957, thanks to @AbhinavanT",97556265
1274,False,False,2019-08-14T08:07:56Z,2019-08-14T08:29:53Z,"## Bug fixes:
- Versions 0.16.* had a bug in python applier with categorical features for applying on more than 128 documents.

## New features:
- It is now possible to use pairwise modes for datasets without groups

## Improvements:
- 1.8x Evaluation speed on asymmetrical trees

",97556265
1275,False,False,2019-08-11T11:35:55Z,2019-08-11T12:10:46Z,"## Breaking changes:
- Renamed column `Feature Index` to `Feature Id` in prettified output of python method `get_feature_importance()`, because it supports feature names now
- Renamed option `per_float_feature_binarization` (`--per-float-feature-binarization`) to `per_float_feature_quantization` (`--per-float-feature-quantization`)
- Removed parameter `inverted` from python `cv` method. Added `type` parameter instead, which can be set to `Inverted`
- Method `get_features()` now works only for datasets without categorical features

## New features
- A new multiclass version of AUC metric, called `AUC Mu`, which was proposed by Ross S. Kleiman on NeurIPS 2019, [link](http://proceedings.mlr.press/v97/kleiman19a/kleiman19a.pdf)
- Added time series cv
- Added `MeanWeightedTarget` in `fstat`
- Added `utils.get_confusion_matrix()`
- Now feature importance can be calculated for non-symmetric trees
",97556265
1276,False,False,2019-08-02T15:14:09Z,2019-08-02T15:59:17Z,"## Breaking changes:
- Removed `get_group_id()` and `get_features()` methods of `Pool` class

## New model analysis tools:
- Added `PredictionDiff` type of `get_feature_importance()` method, which is a new method for model analysis. The method shows how the features influenced the fact that among two samples one has a higher prediction. It allows to debug ranking models: you find a pair of samples ranked incorrectly and you look at what features have caused that.
- Added `plot_predictions()` method

## New features:
- `model.set_feature_names()` method in Python
- Added stratified split to parameter search methods
- Support `catboost.load_model()` from CPU snapshots for numerical-only datasets
- `CatBoostClassifier.score()` now supports `y` as `DataFrame`
- Added `sampling_frequency`, `per_float_feature_binarization`, `monotone_constraints` parameters to `CatBoostClassifier` and `CatBoostRegresssor`

## Speedups:
- 2x speedup of multi-classification mode

## Bugfixes:
- Fixed `score()` for multiclassification, #924
- Fixed `get_all_params()` function,  #926

## Other improvements:
- Clear error messages when a model cannot be saved
",97556265
1277,False,False,2019-07-30T15:30:43Z,2019-07-30T15:52:37Z,"## Breaking changes:
- parameter `fold_count` is now called `cv` in [`grid_search()`](https://catboost.ai/docs/concepts/python-reference_catboost_grid_search.html) and [`randomized_search`](https://catboost.ai/docs/concepts/python-reference_catboost_randomized_search.html)
- cv results are now returned from `grid_search()` and `randomized_search()` in `res['cv_results']` field

## New features:
- R-language function `catboost.save_model()` now supports PMML, ONNX and other formats
- Parameter `monotone_constraints` in python API allows specifying numerical features that the prediction shall depend on monotonically

## Bug fixes:
- Fixed `eval_metric` calculation for training with weights (in release 0.16 evaluation of a metric that was equal to an optimized loss did not use weights by default, so overfitting detector worked incorrectly)

## Improvements:
- Added option `verbose` to `grid_search()` and `randomized_search()`
- Added [tutorial](https://github.com/catboost/tutorials/blob/master/hyperparameters_tuning/hyperparameters_tuning.ipynb) on `grid_search()` and `randomized_search()`
",97556265
1278,False,False,2019-07-24T00:40:26Z,2019-07-24T00:56:32Z,"## Breaking changes:
- `MultiClass` loss has now the same sign as Logloss. It had the other sign before and was maximized, now it is minimized.
- `CatBoostRegressor.score` now returns the value of R^2 metric instead of RMSE to be more consistent with the behavior of scikit-learn regressors.
- Changed metric parameter `use_weights` default value to false (except for ranking metrics)

## New features:
- It is now possible to apply model on GPU
- We have published two new realworld datasets with monotonic constraints, `catboost.datasets.monotonic1()` and `catboost.datasets.monotonic2()`. Before that  there was only `california_housing` dataset in open-source with monotonic constraints. Now you can use these two to benchmark algorithms with monotonic constraints.
- We've added several new metrics to catboost, including `DCG`, `FairLoss`, `HammingLoss`, `NormalizedGini` and `FilteredNDCG`
- Introduced efficient `GridSearch` and `RandomSearch` implementations.
- `get_all_params()` Python function returns the values of all training parameters, both user-defined and default.
- Added more synonyms for training parameters to be more compatible with other GBDT libraries.

## Speedups:
- AUC metric is computationally very expensive. We've implemented parallelized calculation of this metric, now it can be calculated on every iteration (or every k-th iteration) about 4x faster.

## Educational materials:
- We've improved our command-line tutorial, now it has examples of files and more information.

## Fixes:
- Automatic `Logloss` or `MultiClass` loss function deduction for `CatBoostClassifier.fit` now also works if the training dataset is specified as `Pool` or filename string.
- And some other fixes",97556265
1279,False,False,2019-06-28T13:18:15Z,2019-06-28T13:59:31Z,"## Breaking changes:
- Function `get_feature_statistics` is replaced by `calc_feature_statistics`
- Scoring function `Correlation` is renamed to `Cosine`
- Parameter `efb_max_conflict_fraction` is renamed to `sparse_features_conflict_fraction`

## New features:
- Models can be saved in PMML format now.
> **Note:**  PMML does not have full categorical features support, so to have the model in PMML format for datasets with categorical features you need to use set `one_hot_max_size` parameter to some large value, so that all categorical features are one-hot encoded
- Feature names can be used to specify ignored features

## Bug fixes, including:
- Fixed restarting of CV on GPU for datasets without categorical features
- Fixed learning continuation errors with changed dataset (#879) and with model loaded from file (#884)
- Fixed NativeLib for JDK 9+ (PR #857)
",97556265
1280,False,False,2019-05-31T18:26:58Z,2019-05-31T19:05:47Z,"## Bug fixes:
- restored parameter `fstr_type` in Python and R interfaces",97556265
1281,False,False,2019-05-27T16:51:31Z,2019-05-27T17:16:07Z,"## Breaking changes
- cv is now stratified by default for `Logloss`, `MultiClass` and `MultiClassOneVsAll`.
- We have removed `border` parameter of `Logloss` metric. You need to use `target_border` as a separate training parameter now.
- `CatBoostClassifier` now runs `MultiClass` if more than 2 different values are present in training dataset labels.
- `model.best_score_[""validation_0""]` is replaced with `model.best_score_[""validation""]` if a single validation dataset is present.
- `get_object_importance` function parameter `ostr_type` is renamed to `type` in Python and R.

## Model analysis
- Tree visualisation by [@karina-usmanova](https://github.com/karina-usmanova).
- New feature analysis: plotting information about how a feature was used in the model by [@alexrogozin12](https://github.com/alexrogozin12).
- Added `plot` parameter to `get_roc_curve`, `get_fpr_curve` and `get_fnr_curve` functions from `catboost.utils`.
- Supported prettified format for all types of feature importances.

## New ways of doing predictions
- Rust applier by [@shuternay](https://github.com/shuternay).
- DotNet applier by [@17minutes](https://github.com/17minutes).
- One-hot encoding for categorical features in CatBoost CoreML model by Kseniya Valchuk and Ekaterina Pogodina.


## New objectives
- Expectile Regression by [@david-waterworth](https://github.com/david-waterworth).
- Huber loss by [@atsky](https://github.com/atsky).

## Speedups
- Speed up of shap values calculation for single object or for small number of objects by [@Lokutrus](https://github.com/Lokutrus).
- Cheap preprocessing and no fighting of overfitting if there is little amount of iterations (since you will not overfit anyway).

## New functionality
- Prediction of leaf indices.

## New educational materials
- Rust tutorial by [@shuternay](https://github.com/shuternay).
- C# tutorial.
- Leaf indices.
- Tree visualisation tutorial by [@karina-usmanova](https://github.com/karina-usmanova).
- Google Colab tutorial for regression in catboost by [@col14m](https://github.com/col14m).

And a set of fixes for your issues.
",97556265
1282,False,False,2019-04-17T22:07:57Z,2019-04-17T22:30:01Z,"## New features
- Add `has_header` parameter to [`CatboostEvaluation`](https://github.com/catboost/catboost/blob/2f35e0366c0bb6c1b44be89fda0a02fe12f84513/catboost/python-package/catboost/eval/catboost_evaluation.py#L30) class.

## Breaking changes
- Change output feature indices separator (`:` to `;`) in the `CatboostEvaluation` class.
",97556265
1283,False,False,2019-04-13T12:27:25Z,2019-04-13T12:47:29Z,"## Breaking changes
- Changed default value for `--counter-calc-method` option to `SkipTest`

## New features:
- Add guid to trained models. You can access it in Python using [`get_metadata`](https://catboost.ai/docs/concepts/python-reference_catboost_metadata.html) function, for example `print catboost_model.get_metadata()['model_guid']`

## Bug fixes and other changes:
- Compatibility with glibc 2.12
- Improved embedded documentation
- Improved warning and error messages
",97556265
1284,False,False,2019-04-09T12:54:37Z,2019-04-09T04:29:07Z,"## New features:

- GPU training now supports several tree learning strategies, selectable with `grow_policy` parameter. Possible values:
  - `SymmetricTree` -- The tree is built level by level until `max_depth` is reached. On each iteration, all leaves from the last tree level will be split with the same condition. The resulting tree structure will always be symmetric.
  - `Depthwise` -- The tree is built level by level until `max_depth` is reached. On each iteration, all non-terminal leaves from the last tree level will be split. Each leaf is split by condition with the best loss improvement.
  - `Lossguide` -- The tree is built leaf by leaf until `max_leaves` limit is reached. On each iteration, non-terminal leaf with best loss improvement will be split.
  > **Note:** grow policies `Depthwise` and `Lossguide` currently support only training and prediction modes. They do not support model analysis (like feature importances and SHAP values) and saving to different model formats like CoreML, ONNX, and JSON.
  - The new grow policies support several new parameters:
    `max_leaves` -- Maximum leaf count in the resulting tree, default 31. Used only for `Lossguide` grow policy. __Warning:__ It is not recommended to set this parameter greater than 64, as this can significantly slow down training.
    `min_data_in_leaf` -- Minimum number of training samples per leaf, default 1. CatBoost will not search for new splits in leaves with sample count less than  `min_data_in_leaf`. This option is available for `Lossguide` and `Depthwise` grow policies only.
  > **Note:** the new types of trees will be at least 10x slower in prediction than default symmetric trees.

- GPU training also supports several score functions, that might give your model a boost in quality. Use parameter `score_function` to experiment with them.

- Now you can use quantization with more than 255 borders and `one_hot_max_size` > 255 in CPU training.

## New features in Python package:
- It is now possible to use `save_borders()` function to write borders to a file after training.
- Functions `predict`, `predict_proba`, `staged_predict`, and `staged_predict_proba` now support applying a model to a single object, in addition to usual data matrices.

## Speedups:
- Impressive speedups for sparse datsets. Will depend on the dataset, but will be at least 2--3 times for sparse data.

## Breaking changes:
- Python-package class attributes don't raise exceptions now. Attributes return `None` if not initialized.
- Starting from 0.13 we have new feature importances for ranking modes. The new algorithm for feature importances shows how much features contribute to the optimized loss function. They are also signed as opposed to feature importances for not ranking modes which are non negative. This importances are expensive to calculate, thus we decided to not calculate them by default during training starting from 0.14. You need to calculate them after training.
",97556265
1285,False,False,2019-03-20T02:10:26Z,2019-03-20T03:43:31Z,"## Changes:
- Fixed a bug in shap values that was introduced in v0.13
",97556265
1286,False,False,2019-03-13T20:11:12Z,2019-03-14T10:24:39Z,"## Speedups:
- Impressive speedup of CPU training for datasets with predominantly binary features (up to 5-6x).
- Speedup prediction and shap values array casting on large pools (issue [#684](https://github.com/catboost/catboost/issues/684)).
## New features:
- We've introduced a new type of feature importances - `LossFunctionChange`.
  This type of feature importances works well in all the modes, but is especially good for ranking. It is more expensive to calculate, thus we have not made it default. But you can look at it by selecting the type of feature importance.
- Now we support online statistics for categorical features in `QuerySoftMax` mode on GPU.
- We now support feature names in `cat_features`, PR [#679](https://github.com/catboost/catboost/pull/679) by [@infected-mushroom](https://github.com/infected-mushroom) - thanks a lot [@infected-mushroom](https://github.com/infected-mushroom)!
- We've intoduced new sampling_type `MVS`, which speeds up CPU training if you use it.
- Added `classes_` attribute in python.
- Added support for input/output borders files in python package. Thank you [@necnec](https://github.com/necnec) for your PR [#656](https://github.com/catboost/catboost/pull/656)!
- One more new option for working with categorical features is `ctr_target_border_count`.
  This option can be used if your initial target values are not binary and you do regression or ranking. It is equal to 1 by default, but you can try increasing it.
- Added new option `sampling_unit` that allows to switch sampling from individual objects to entire groups.
- More strings are interpreted as missing values for numerical features (mostly similar to pandas' [read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)).
- Allow `skip_train` property for loss functions in cv method. Contributed by GitHub user [@RakitinDen](https://github.com/RakitinDen), PR [#662](https://github.com/catboost/catboost/pull/662), many thanks.
- We've improved classification mode on CPU, there will be less cases when the training diverges.
  You can also try to experiment with new `leaf_estimation_backtracking` parameter.
- Added new compare method for visualization, PR [#652](https://github.com/catboost/catboost/pull/652). Thanks [@Drakon5999](https://github.com/Drakon5999) for your contribution!
- Implemented `__eq__` method for `CatBoost*` python classes (PR [#654](https://github.com/catboost/catboost/pull/654)). Thanks [@daskol](https://github.com/daskol) for your contribution!
- It is now possible to output evaluation results directly to `stdout` or `stderr` in command-line CatBoost in [`calc` mode](https://catboost.ai/docs/concepts/cli-reference_calc-model.html) by specifying `stream://stdout` or `stream://stderr` in `--output-path` parameter argument. (PR [#646](https://github.com/catboost/catboost/pull/646)). Thanks [@towelenee](https://github.com/towelenee) for your contribution!
- New loss function - [Huber](https://en.wikipedia.org/wiki/Huber_loss). Can be used as both an objective and a metric for regression. (PR [#649](https://github.com/catboost/catboost/pull/649)). Thanks [@atsky](https://github.com/atsky) for your contribution!
## Changes:
- Changed defaults for `one_hot_max_size` training parameter for groupwise loss function training.
- `SampleId` is the new main name for former `DocId` column in input data format (`DocId` is still supported for compatibility). Contributed by GitHub user [@daskol](https://github.com/daskol), PR [#655](https://github.com/catboost/catboost/pull/655), many thanks.
- Improved CLI interface for cross-validation: replaced `-X/-Y` options with `--cv`, PR [#644](https://github.com/catboost/catboost/pull/644). Thanks [@tswr](https://github.com/tswr) for your pr!
- `eval_metrics` : `eval_period` is now clipped by total number of trees in the specified interval. PR [#653](https://github.com/catboost/catboost/pull/653). Thanks [@AntPon](https://github.com/AntPon) for your contribution!
## R package:
- Thanks to [@ws171913](https://github.com/ws171913) we made necessary changes to prepare catboost for CRAN integration, PR [#715](https://github.com/catboost/catboost/pull/715). This is in progress now.
- R interface for cross-validation contributed by GitHub user [@brsoyanvn](https://github.com/brsoyanvn), PR [#561](https://github.com/catboost/catboost/pull/561) -- many thanks [@brsoyanvn](https://github.com/brsoyanvn)!
## Educational materials:
- We've added new tutorial for [GPU training on Google Colaboratory](https://github.com/catboost/tutorials/blob/master/tools/google_colaboratory_cpu_vs_gpu_tutorial.ipynb).

We have also done a list of fixes and data check improvements.
Thanks [@brazhenko](https://github.com/brazhenko), [@Danyago98](https://github.com/Danyago98), [@infected-mushroom](https://github.com/infected-mushroom) for your contributions.",97556265
1287,False,False,2019-01-18T16:09:22Z,2019-01-18T16:48:24Z,"## Changes:
* Fixed loading of `epsilon` dataset into memory
* Fixed multiclass learning on GPU for >255 classes
* Improved error handling
* Some other minor fixes
",97556265
1288,False,False,2019-01-10T01:17:13Z,2019-01-10T01:39:47Z,"## Changes:
* Fixed Python compatibility issue in dataset downloading
* Added `sampling_type` parameter for `YetiRankPairwise` loss
",97556265
1289,False,False,2018-12-30T17:07:12Z,2018-12-30T15:33:37Z,"## Changes:
* Support saving models in ONNX format (only for models without categorical features).
* Added new dataset to our `catboost.datasets()` -- dataset epsilon, a large dense dataset for binary classification.
* Speedup of Python `cv` on GPU.
* Fixed creation of `Pool` from `pandas.DataFrame` with `pandas.Categorical` columns.
",97556265
1290,False,False,2018-12-30T17:14:01Z,2018-12-26T05:03:53Z,"# Release 0.12.0
## Breaking changes:
* Class weights are now taken into account by `eval_metrics()`, `get_feature_importance()`, and `get_object_importance()`.
  In previous versions the weights were ignored.
* Parameter `random-strength` for pairwise training (`PairLogitPairwise`, `QueryCrossEntropy`, `YetiRankPairwise`) is not supported anymore.
* Simultaneous use of `MultiClass` and `MultiClassOneVsAll` metrics is now deprecated.

## New functionality:
* `cv` method is now supported on GPU.
* String labels for classes are supported in Python.
  In multiclassification the string class names are inferred from the data.
  In binary classification for using string labels you should employ `class_names` parameter and specify which class is negative (0) and which is positive (1).
  You can also use `class_names` in multiclassification mode to pass all possible class names to the fit function.
* Borders can now be saved and reused.
  To save the feature quantization information obtained during training data preprocessing into a text file use cli option `--output-borders-file`.
  To use the borders for training use cli option `--input-borders-file`.
  This functionanlity is now supported on CPU and GPU (it was GPU-only in previous versions).
  File format for the borders is described [here](https://tech.yandex.com/catboost/doc/dg/concepts/input-data_custom-borders-docpage).
* CLI option `--eval-file` is now supported on GPU.

## Quality improvement:
* Some cases in binary classification are fixed where training could diverge

## Optimizations:
* A great speedup of the Python applier (10x)
* Reduced memory consumption in Python `cv` function (times fold count)

## Benchmarks and tutorials:
* Added [speed benchmarks](catboost/benchmarks/speed_benchmarks) for CPU and GPU on a variety of different datasets.
* Added [benchmarks](catboost/benchmarks/ranking) of different ranking modes. In [this tutorial](catboost/tutorials/ranking/ranking_tutorial.ipynb) we compare different ranking modes in CatBoost, XGBoost and LightGBM.
* Added [tutorial](catboost/tutorials/apply_model/catboost4j_prediction_tutorial.ipynb) for applying model in Java.
* Added [benchmarks](catboost/benchmarks/shap_speed) of SHAP values calculation for CatBoost, XGBoost and LightGBM.
  The benchmarks also contain explanation of complexity of this calculation in all the libraries.

We also made a list of stability improvements and stricter checks of input data and parameters.

And we are so grateful to our community members @canorbal and @neer201 for their contribution to this release. Thank you.",97556265
1291,False,False,2018-12-10T16:37:06Z,2018-12-10T16:58:30Z,"## Changes:
* Pure GPU implementation of NDCG metric
* Enabled LQ loss function
* Fixed NDCG metric on CPU
* Added `model_sum` mode to command line interface
* Added SHAP values benchmark (#566)
* fixed `random_strength` for `Plain` boosting (#448)
* Enabled passing a test pool to caret training (#544)
* Fixed a bug in exporting the model as python code (#556)
* Fixed label mapper for multiclassification custom labels (#523)
* Fixed hash type of categorical features (#558)
* Fixed handling of cross-validation fold count options in python package (#568)
",97556265
1292,False,False,2018-11-13T19:06:23Z,2018-11-13T21:10:17Z,"# Release 0.11.1
## Changes: 
* Accelerated formula evaluation by ~15%
* Improved model application interface
* Improved compilation time for building GPU version
* Better handling of stray commas in list arguments
* Added a benchmark that employs Rossman Store Sales dataset to compare quality of GBDT packages
* Added references to Catboost papers in R-package CITATION file (issue #488)
* Fixed a build issue in compilation for GPU
* Fixed a bug in model applicator
* Fixed model conversion (issue #533)
* Returned pre 0.11 behaviour for `best_score_` and `evals_result_` (issue #539)
* Make valid `.dist-info/RECORD` in python wheel (issue #534)",97556265
1293,False,False,2018-11-07T10:59:45Z,2018-11-07T16:15:51Z,"## Changes:
* Changed default border count for float feature binarization to 254 on CPU to achieve better quality
* Fixed random seed to `0` by default
* Support model with more than 254 feature borders or one hot values when doing predictions
* Added model summation support in python: use `catboost.sum_models()` to sum models with provided weights.
* Added json model tutorial [model_export_as_json_tutorial.ipynb](https://github.com/catboost/catboost/blob/master/catboost/tutorials/apply_model/model_export_as_json_tutorial.ipynb)",97556265
1294,False,False,2018-10-26T04:06:30Z,2018-10-26T09:02:35Z,"## Breaking changes:
In python 3 some functions returned dictionaries with keys of type `bytes` - particularly eval_metrics and get_best_score. These are fixed to have keys of type `str`.
## Changes:
- New metric NumErrors:greater_than=value
- New metric and objective L_q:q=value
- model.score(X, y) - can now work with Pool and labels from Pool",97556265
1295,False,False,2018-10-11T08:21:29Z,2018-10-11T10:30:37Z,"## Changes:
* Added EvalResult output after GPU catboost training
* Supported prediction type option on GPU
* Added `get_evals_result()` method and `evals_result_` property to model in python wrapper to allow user access metric values
* Supported string labels for GPU training in cmdline mode
* Many improvements in JNI wrapper
* Updated NDCG metric: speeded up and added NDCG with exponentiation in numerator as a new NDCG mode
* CatBoost doesn't drop unused features from model after training
* Write training finish time and catboost build info to model metadata

* Fix automatic pairs generation for GPU PairLogitPairwise target",97556265
1296,False,False,2018-09-20T11:54:04Z,2018-09-20T13:39:31Z,"### Main changes:
* Fixed Python 3 support in `catboost.FeaturesData`
* 40% speedup QuerySoftMax CPU training",97556265
1297,False,False,2018-09-17T20:19:44Z,2018-09-18T16:23:04Z,"## Improvements
* 2x Speedup pairwise loss functions
* For all the people struggling with occasional NaNs in test datasets - now we only write warnings about it
## Bugfixes
* We set up default loss_function in `CatBoostClassifier` and `CatBoostRegressor`
* Catboost write `Warning` and `Error` logs to stderr",97556265
1298,False,False,2018-09-13T00:01:43Z,2018-09-13T01:20:08Z,"## Breaking changes
### R package
- In R package we have changed parameter name `target` to `label` in method [`save_pool()`](https://tech.yandex.com/catboost/doc/dg/concepts/r-reference_catboost-save_pool-docpage/)
### Python package
- We don't support Python 3.4 anymore
- CatBoostClassifier and CatBoostRegressor [`get_params()`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboostclassifier_get_params-docpage/) method now returns only the params that were explicitly set when constructing the object. That means that CatBoostClassifier and CatBoostRegressor get_params() will not contain 'loss_function' if it was not specified.
This also means that this code:
```(python)
model1 = CatBoostClassifier()
params = model1.get_params()
model2 = CatBoost(params)
```
will create model2 with default loss_function RMSE, not with Logloss.
This breaking change is done to support sklearn interface, so that sklearn GridSearchCV can work.
- We've removed several attributes and changed them to functions. This was needed to avoid sklearn warnings:
`is_fitted_` => [`is_fitted()`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboostclassifier_is_fitted-docpage/)
`metadata_` => [`get_metadata()`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboostclassifier_metadata-docpage/)
- We removed file with model from constructor of estimator. This was also done to avoid sklearn warnings.
## Educational materials
- We added [tutorial](https://github.com/catboost/tutorials/blob/master/ranking/ranking_tutorial.ipynb) for our ranking modes.
- We published our [slides](https://github.com/catboost/catboost/tree/master/slides), you are very welcome to use them.
## Improvements
### All
- Now it is possible to save model in json format.
- We have added Java interface for CatBoost model
- We now have static linkage with CUDA, so you don't have to install any particular version of CUDA to get catboost working on GPU.
- We implemented both multiclass modes on GPU, it is very fast.
- It is possible now to use multiclass with string labels, they will be inferred from data
- Added `use_weights` parameter to [metrics](https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/). By default all metrics, except for AUC use weights, but you can disable it. To calculate metric value without weights, you need to set this parameter to false. Example: Accuracy:use_weights=false. This can be done only for custom_metrics or eval_metric, not for the objective function. Objective function always uses weights if they are present in the dataset.
- We now use snapshot time intervals. It will work much faster if you save snapshot every 5 or 10 minutes instead of saving it on every iteration.
- Reduced memory consumption by ranking modes.
- Added automatic feature importance evaluation after completion of GPU training.
- Allow inexistent indexes in ignored features list
- Added [new metrics](https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/): `LogLikelihoodOfPrediction`, `RecallAt:top=k`, `PrecisionAt:top=k` and `MAP:top=k`.
- Improved quality for multiclass with weighted datasets.
- Pairwise modes now support automatic pairs generation (see [tutorial](https://github.com/catboost/tutorials/blob/master/ranking/ranking_tutorial.ipynb) for that).
- Metric `QueryAverage` is renamed to a more clear `AverageGain`. This is a very important ranking metric. It shows average target value in top k documents of a group.
Introduced parameter `best_model_min_trees` - the minimal number of trees the best model should have.
### Python
- We now support sklearn GridSearchCV: you can pass categorical feature indices when constructing estimator. And then use it in GridSearchCV.
- We added new method to utils - building of ROC curve: [`get_roc_curve`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_utils_get_roc_curve-docpage/).
- Added [`get_gpu_device_count()`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_utils_get_gpu_device_count-docpage/) method to python package. This is a way to check if your CUDA devices are available.
- We implemented automatical selection of decision-boundary using ROC curve. You can select best classification boundary given the maximum FPR or FNR that you allow to the model. Take a look on [`catboost.select_threshold(self, data=None, curve=None, FPR=None, FNR=None, thread_count=-1)`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_utils_select_threshold-docpage/). You can also calculate FPR and FNR for each boundary value.
- We have added pool slicing: [`pool.slice(doc_indices)`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_pool_slice-docpage/)
- Allow GroupId and SubgroupId specified as strings.
### R package
- GPU support in R package. You need to use parameter `task_type='GPU'` to enable GPU training.
- Models in R can be saved/restored by means of R: save/load or saveRDS/readRDS
## Speedups
- New way of loading data in Python using [FeaturesData structure](https://tech.yandex.com/catboost/doc/dg/concepts/python-features-data__desc-docpage/). Using FeaturesData will speed up both loading data for training and for prediction. It is especially important for prediction, because it gives around 10 to 20 times python prediction speedup.
- Training multiclass on CPU ~ 60% speedup
- Training of ranking modes on CPU ~ 50% speedup
- Training of ranking modes on GPU ~ 50% speedup for datasets with many features and not very many objects
- Speedups of metric calculation on GPU. Example of speedup on our internal dataset: training with - AUC eval metric with test dataset with 2kk objects is speeded up 7sec => 0.2 seconds per iteration.
- Speedup of all modes on CPU training.

We also did a lot of stability improvements, and improved usability of the library, added new parameter synonyms and improved input data validations.


Thanks a lot to all people who created issues on github. And thanks a lot to our contributor https://github.com/pukhlyakova who implemented many new useful metrics!
",97556265
1299,False,False,2018-07-07T19:58:18Z,2018-07-07T20:31:31Z,"## Bugfixes
- Fixed #403 bug in cuda train submodule (training crashed without evaluation set)
- Fixed exception propagation on pool parsing stage
- Add support of string `GroupId` and `SubgroupId` in python-package
- Print real class names instead of their labels in eval output",97556265
1300,False,False,2018-07-05T12:46:28Z,2018-07-05T13:24:34Z,"## Breaking Changes
- We removed calc_feature_importance parameter from Python and R.
Now feature importance calculation is almost free, so we always calculate feature importances. Previously you could disable it if it was slowing down your training.
- We removed Doc type for feature importances. Use Shap instead.
- We moved thread_count parameter in Python get_feature_importance method to the end.

## Ranking
In this release we added several very powerfull ranking objectives:
- PairLogitPairwise
- YetiRankPairwise
- QueryCrossEntropy (GPU only)

Other ranking improvements:
- We have made improvements to our existing ranking objectives QuerySoftMax and PairLogit.
- We have added group weights support.

## Accuracy improvements
- Improvement for datasets with weights
- Now we automatically calculate a good learning rate for you in the start of training, you don't have to specify it. After the training has finished, you can look on the training curve on evaluation dataset and make ajustments to the selected learning rate, but it will already be a good value.

## Speedups:
- Several speedups for GPU training.
- 1.5x speedup for applying the model.
- Speed up multi classificaton training.
- 2x speedup for AUC calculation in eval_metrics.
- Several speedups for eval_metrics for other metrics.
- 100x speed up for Shap values calculation.
- Speedup for feature importance calculation. It used to be a bottleneck for GPU training previously, now it's not.
- We added possibility to not calculate metric on train dataset using `MetricName:hint=skip_train~false` (it might speed up your training if metric calculation is a bottle neck, for example, if you calculate many metrics or if you calculate metrics on GPU).
- We added possibility to calculate metrics only periodically, not on all iterations. Use metric_period for that.
(previously it only disabled verbose output on each iteration).
- Now we disable by default calculation of expensive metrics on train dataset. We don't calculate AUC and PFound metrics on train dataset by default. You can also disable calculation of other metrics on train dataset using `MetricName:hints=skip_train~true`. If you want to calculate AUC or PFound on train dataset you can use `MetricName:hints=skip_train~false`.
- Now if you want to calculate metrics using eval_metrics or during training you can use metric_period to skip some iterations. It will speed up eval_metrics and it might speed up training, especially GPU training.
Note that the most expensive metric calculation is AUC calculation, for this metric and large datasets it makes sense to use metric_period.
If you only want to see less verbose output, and still want to see metric values on every iteration written in file, you can use `verbose=n` parameter
- Parallelization of calculation of most of the metrics during training

## Improved GPU experience
- It is possible now to calculate and visualise custom_metric during training on GPU.
Now you can use our Jupyter visualization, CatBoost viewer or TensorBoard the same way you used it for CPU training. It might be a bottleneck, so if it slows down your training use `metric_period=something` and `MetricName:hint=skip_train~false`
- We switched to CUDA 9.1. Starting from this release CUDA 8.0 will not be supported
- Support for external borders on GPU for cmdline

## Improved tools for model analysis
- We added support of feature combinations to our Shap values implementation.
- Added Shap values for MultiClass and added an example of it's usage to our [Shap tutorial](https://github.com/catboost/tutorials/blob/master/model_analysis/shap_values_tutorial.ipynb).
- Added `prettified` parameter to get_feature_importance(). With `prettified=True` the function will return list of features with names sorted in descending order by their importance.
- Improved interfaces for eval-feature functionality
- Shap values support in R-package

## New features
- It is possible now to save any metainformation to the model.
- Empty values support
- Better support of sklearn
- feature_names_ for CatBoost class
- Added silent parameter
- Better stdout
- Better diagnostic for invalid inputs
- Better documentation
- Added a flag to allow constant labels

## New metrics
We added many new metrics that can be used for visualization, overfitting detection, selecting of best iteration of training or for cross-validation:
- BierScore
- HingeLoss
- HammingLoss
- ZeroOneLoss
- MSLE
- MAE
- BalancedAccuracy
- BalancedErrorRate
- Kappa
- Wkappa
- QueryCrossEntropy
- NDCG

## New ways to apply the model
- Saving model as C++ code
- Saving model with categorical features as Python code

## New ways to build the code
Added make files for binary with CUDA and for Python package

## Tutorials
We created a new [repo with tutorials](https://github.com/catboost/tutorials/), now you don't have to clone the whole catboost repo to run Jupyter notebook with a tutorial.

## Bugfixes
We have also a set of bugfixes and we are gratefull to everyone who has filled a bugreport, helping us making the library better.

## Thanks to our Contributors
This release contains contributions from CatBoost team.
We want to especially mention @pukhlyakova who implemented lots of useful metrics.

As usual we are grateful to all who filed issues or helped resolve them, asked and answered questions.",97556265
1301,False,False,2018-04-24T15:25:03Z,2018-04-25T14:55:30Z,"## Bug Fixes and Other Changes
- New model method `get_cat_feature_indices()` in Python wrapper.
- Minor fixes and stability improvements.",97556265
1302,False,False,2018-04-19T08:05:45Z,2018-04-19T08:22:28Z,"## Breaking changes
- We fixed bug in CatBoost. Pool initialization from `numpy.array` and `pandas.dataframe` with string values that can cause slight inconsistence while using trained model from older versions. Around 1% of cat feature hashes were treated incorrectly. If you expirience quality drop after update you should consider retraining your model.

## Major Features And Improvements
- Algorithm for finding most influential training samples for a given object from the 'Finding Influential Training Samples for Gradient Boosted Decision Trees' [paper](https://arxiv.org/pdf/1802.06640.pdf) is implemented. This mode for every object from input pool calculates scores for every object from train pool. A positive score means that the given train object has made a negative contribution to the given test object prediction. And vice versa for negative scores. The higher score modulo - the higher contribution.
See `get_object_importance` model method in Python package and `ostr` mode in cli-version. Tutorial for Python is available [here](https://github.com/catboost/tutorials/blob/master/model_analysis/object_importance_tutorial.ipynb).
More details and examples will be published in documentation soon.
- We have implemented new way of exploring feature importance - SHAP values from [paper](https://arxiv.org/pdf/1706.06060.pdf). This allows to understand which features are most influent for a given object. You can also get more insite about your model, see details in a [tutorial](https://github.com/catboost/tutorials/blob/master/model_analysis/shap_values_tutorial.ipynb).
- Save model as code functionality published. For now you could save model as Python code with categorical features and as C++ code w/o categorical features.

## Bug Fixes and Other Changes
- Fix `_catboost` reinitialization issues #268 and #269.
- GPU parameter `use_cpu_ram_for_cat_features` renamed to `gpu_cat_features_storage` with posible values `CpuPinnedMemory` and `GpuRam`. Default is `GpuRam`.

## Thanks to our Contributors
This release contains contributions from CatBoost team.

As usual we are grateful to all who filed issues or helped resolve them, asked and answered questions.",97556265
1303,False,False,2018-04-06T08:29:53Z,2018-04-06T10:54:00Z," ## Major Features And Improvements
  - GPU: New `DocParallel` mode for tasks without categorical features and with `—max-ctr-complextiy 1`. Provides best performance for pool with big number of documents.
  - GPU: Distributed training on several GPU host via MPI. See instruction how to build binary [here](https://tech.yandex.com/catboost/doc/dg/concepts/cli-installation-docpage/#multi-node-installation).
  - GPU: Up to 30% learning speed-up for Maxwell and later GPUs with binarization level > 32
 
 ## Bug Fixes and Other Changes
 - Hotfixes for GPU version of python wrapper.",97556265
1304,False,False,2018-04-05T12:53:42Z,2018-04-06T06:48:52Z,"## Major Features And Improvements
- Python wrapper: added methods to download datasets titanic and amazon, to make it easier to try the library (`catboost.datasets`).
- Python wrapper: added method to write column desctiption file (`catboost.utils.create_cd`).
- Made improvements to visualization.
- Support non-numeric values in `GroupId` column.
- [Tutorials](https://github.com/catboost/catboost/blob/master/catboost/tutorials/README.md) section updated.

## Bug Fixes and Other Changes
- Fixed problems with eval_metrics (issue #285)
- Other fixes",97556265
1305,False,False,2018-03-28T21:37:47Z,2018-03-29T09:31:12Z,"## Breaking changes
- Changed parameter order in [`train()`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_train-docpage/) function to be consistant with other GBDT libraries.
- `use_best_model` is set to True by default if `eval_set` labels are present.

## Major Features And Improvements
- New ranking mode [`YetiRank`](https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/#loss-functions__ranking) optimizes `NDGC` and `PFound`.
- New visualisation for `eval_metrics` and `cv` in Jupyter notebook.
- Improved per document feature importance.
- Supported `verbose`=`int`: if `verbose` > 1, `metric_period` is set to this value.
- Supported type(`eval_set`) = list in python. Currently supporting only single `eval_set`.
- Binary classification leaf estimation defaults are changed for weighted datasets so that training converges for any weights.
- Add `model_size_reg` parameter to control model size. Fix `ctr_leaf_count_limit` parameter, also to control model size.
- Beta version of distributed CPU training with only float features support.
- Add `subgroupId` to [Python](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_pool-docpage/)/[R-packages](https://tech.yandex.com/catboost/doc/dg/concepts/r-reference_catboost-load_pool-docpage/).
- Add groupwise metrics support in `eval_metrics`.

## Thanks to our Contributors
This release contains contributions from CatBoost team.

We are grateful to all who filed issues or helped resolve them, asked and answered questions.",97556265
1306,False,False,2018-03-05T12:47:17Z,2018-03-05T14:10:47Z,"## Breaking changes
- `boosting_type` parameter value `Dynamic` is renamed to `Ordered`.
- Data visualisation functionality in Jupyter Notebook requires ipywidgets 7.x+ now.
- `query_id` parameter renamed to `group_id` in Python and R wrappers.
- cv returns pandas.DataFrame by default if Pandas installed. See new parameter [`as_pandas`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_cv-docpage/).

## Major Features And Improvements
- CatBoost build with make file. Now it’s possible to build command-line CPU version of CatBoost under Linux with [make file](https://tech.yandex.com/catboost/doc/dg/concepts/cli-installation-docpage/#make-install). 
- In column description column name `Target` is changed to `Label`. It will still work with previous name, but it is recommended to use the new one.
- `eval-metrics` mode added into cmdline version. Metrics can be calculated for a given dataset using a previously [trained model](https://tech.yandex.com/catboost/doc/dg/concepts/cli-reference_eval-metrics-docpage/).
- New classification metric `CtrFactor` is [added](https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/).
- Load CatBoost model from memory. You can load your CatBoost model from file or initialize it from buffer [in memory](https://github.com/catboost/catboost/blob/master/catboost/CatboostModelAPI.md).
- Now you can run `fit` function using file with dataset: `fit(train_path, eval_set=eval_path, column_description=cd_file)`. This will reduce memory consumption by up to two times.
- 12% speedup for training.

## Bug Fixes and Other Changes
- JSON output data format is [changed](https://tech.yandex.com/catboost/doc/dg/concepts/output-data_training-log-docpage/).
- Python whl binaries with CUDA 9.1 support for Linux OS published into the release assets.
- Added `bootstrap_type` parameter to `CatBoostClassifier` and `Regressor` (issue #263).

## Thanks to our Contributors
This release contains contributions from newbfg and CatBoost team.

We are grateful to all who filed issues or helped resolve them, asked and answered questions.",97556265
1307,False,False,2018-02-09T13:17:46Z,2018-02-09T14:13:03Z,"## Major Features And Improvements
- **BETA** version of distributed mulit-host GPU via MPI training
- Added possibility to import coreml model with oblivious trees. Makes possible to migrate pre-flatbuffers model (with float features only) to current format (issue #235)
- Added QuerySoftMax loss function

## Bug Fixes and Other Changes
- Fixed GPU models bug on pools with both categorical and float features (issue #241)
- Use all available cores by default
- Default float features binarization method set to `GreedyLogSum`
- Fixed not querywise loss for pool with `QueryId`",97556265
1308,False,False,2018-02-02T08:15:19Z,2018-02-02T11:07:45Z,"## Bug Fixes and Other Changes
- Hotfix for critical bug in Python and R wrappers (issue #238)
- Fix `is_classification` check and CV for Logloss (issue #237)
- Added stratified data split in CV
",97556265
1309,False,False,2018-02-01T11:46:25Z,2018-02-01T15:01:59Z,"## Bug Fixes and Other Changes
- Fixed critical bugs in formula evaluation code (issue #236)
- Added `scale_pos_weight` parameter",97556265
1310,False,False,2018-01-29T14:54:24Z,2018-01-30T02:56:05Z,"## Speedups
- 25% speedup of the model applier
- 43% speedup for training on large datasets.
- 15% speedup for `QueryRMSE` and calculation of querywise metrics.
- Large speedups when using binary categorical features.
- Significant (x200 on 5k trees and 50k lines dataset) speedup for plot and stage predict calculations in cmdline.
- Compilation time speedup.

## Major Features And Improvements
- Industry fastest [applier implementation](https://tech.yandex.com/catboost/doc/dg/concepts/c-plus-plus-api-docpage/#c-plus-plus-api).
- Introducing new parameter [`boosting-type`](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_parameters-list-docpage/) to switch between standard boosting scheme and dynamic boosting, described in paper [""Dynamic boosting""](https://arxiv.org/abs/1706.09516).
- Adding new [bootstrap types]( https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_parameters-list-docpage/) `bootstrap_type`, `subsample`. Using `Bernoulli` bootstrap type with `subsample < 1` might increase the training speed.
- Better logging for cross-validation, added [parameter](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_cv-docpage/) `logging_level` and `metric_period` (should be set in training parameters) to cv.
- Added a separate `train` [function](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_train-docpage/) that receives the parameters and returns a trained model.
- Ranking mode `QueryRMSE` now supports default settings for dynamic boosting.
- R-package pre-build binaries are included into release. 
- We added many synonyms to our parameter names, now it is more convenient to try CatBoost if you are used to some other library.

## Bug Fixes and Other Changes
- Fix for CPU `QueryRMSE` with weights.
- Adding several missing parameters into wrappers.
- Fix for data split in querywise modes.
- Better logging.
- From this release we'll provide pre-build R-binaries.
- More parallelisation.
- Memory usage improvements.
- And some other bug fixes.

## Thanks to our Contributors
This release contains contributions from CatBoost team.

We are grateful to all who filed issues or helped resolve them, asked and answered questions.",97556265
1311,False,False,2018-01-09T12:14:35Z,2018-01-09T12:27:57Z,Hot fixes,97556265
1312,False,False,2017-12-28T13:42:59Z,2017-12-28T13:53:30Z,"# Release 0.5.2
  
## Major Features And Improvements
- We've made single document formula applier 4 times faster! 
- `model.shrink` function added in [Python](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboost_shrink-docpage/) and R wrappers. 
- Added new [training parameter](https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_parameters-list-docpage/) `metric_period` that controls output frequency. 
- Added new ranking [metric](https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/) `QueryAverage`. 
- This version contains an easy way to implement new user metrics in C++. How-to example [is provided](https://github.com/catboost/tutorials/blob/master/custom_loss/custom_metric_tutorial.md).

## Bug Fixes and Other Changes
- Stability improvements and bug fixes

As usual we are grateful to all who filed issues, asked and answered questions.",97556265
1313,False,False,2017-12-15T15:30:21Z,2017-12-19T10:57:35Z,Hot fixes,97556265
1314,False,False,2017-11-29T22:49:36Z,2017-11-29T23:24:38Z,"## Major Features And Improvements
- In Python we added a new method `eval_metrics`: now it's possible for a given model to calculate specified metric values for each iteration on specified dataset.
- One command-line binary for CPU and GPU: in CatBoost you can switch between CPU and GPU training by changing single parameter value `task-type CPU` or `GPU` (task_type 'CPU', 'GPU' in python bindings). Windows build still contains two binaries.
- We have speed up the training up to 30% for datasets with a lot of objects.
- Up to 10% speed-up of GPU implementation on Pascal cards

## Breaking Changes
Cmdline:
- Training parameter `gradient-iterations` renamed to `leaf-estimation-iterations`.
- `border` option removed. If you want to specify border for binary classification mode you need to specify it in the following way: `loss-function Logloss:Border=0.5`
- CTR parameters are changed:
   - Removed `priors`, `per-feature-priors`, `ctr-binarization`;
   - Added `simple-ctr`, `combintations-ctr`, `per-feature-ctr`;
   More details will be published in our documentation.

Python and R:
- Training parameter `gradient_iterations` renamed to `leaf_estimation_iterations`.
- `border` option removed. If you want to specify border for binary classification mode you need to specify it in the following way: `loss_function='Logloss:Border=0.5'`
- CTR parameters are changed:
   - Removed `priors`, `per_feature_priors`, `ctr_binarization`;
   - Added `simple_ctr`, `combintations_ctr`, `per_feature_ctr`;
   More details will be published in our documentation.
  
## Bug Fixes and Other Changes
- Stability improvements and bug fixes

As usual we are grateful to all who filed issues, asked and answered questions.",97556265
1315,False,False,2017-11-23T11:05:12Z,2017-11-23T13:10:10Z,Hot fixes,97556265
1316,False,False,2017-11-21T17:07:07Z,2017-11-22T08:38:48Z,"## Breaking Changes
FlatBuffers model format: new CatBoost versions wouldn’t break model compatibility anymore.

## Major Features And Improvements
* Training speedups: we have speed up the training by 33%.
* Two new ranking modes are [available](https://tech.yandex.com/catboost/doc/dg/concepts/loss-functions-docpage/#ranking):
  * `PairLogit` - pairwise comparison of objects from the input dataset. Algorithm maximises probability correctly reorder all dataset pairs.
  * `QueryRMSE` - mix of regression and ranking. It’s trying to make best ranking for each dataset query by input labels.

## Bug Fixes and Other Changes
* **We have fixed a bug that caused quality degradation when using weights < 1.**
* `Verbose` flag is now deprecated, please use `logging_level` instead. You could set the following levels: Silent, Verbose, Info, Debug.
* And some other bugs.

## Thanks to our Contributors
This release contains contributions from: avidale, newbfg, KochetovNicolai and CatBoost team.

We are grateful to all who filed issues or helped resolve them, asked and answered questions.
",97556265
1317,False,False,2017-11-01T17:08:42Z,2017-11-02T08:10:14Z,"## Major Features And Improvements
GPU CUDA support is available. CatBoost supports multi-GPU training. Our GPU implementation is 2 times faster then LightGBM and more then 20 times faster then XGBoost one. Check out the news with benchmarks on our [site](https://catboost.yandex/news#version_0_3).
## Bug Fixes and Other Changes
Stability improvements and bug fixes
## Thanks to our Contributors
This release contains contributions from: daskol and CatBoost team.

We are grateful to all who filed issues or helped resolve them, asked and answered questions.
",97556265
1318,False,False,2017-09-14T11:09:12Z,2017-09-14T11:23:21Z,"## Breaking Changes
* R library interface significantly changed
* New model format: CatBoost v0.2 model binary not compatible with previous versions
* Cross-validation parameters changes: we changed overfitting detector parameters of CV in python so that it is same as those in training.
* CTR types: MeanValue => BinarizedTargetMeanValue

## Major Features And Improvements
* Training speedups: we have speed up the training by 20-30%.
* Accuracy improvement with categoricals: we have changed computation of statistics for categorical features, which leads to better quality.
* New type of overfitting detector: `Iter`. This type of detector was requested by our users. So now you can also stop training by a simple criterion: if after a fixed number of iterations there is no improvement of your evaluation function.
* TensorBoard support: this is another way of looking on the graphs of different error functions both during training and after training has finished. To look at the metrics you need to provide `train_dir` when training your model and then run `""tensorboard --logdir={train_dir}""`
* Jupyter notebook improvements: for our Python library users that experiment with Jupyter notebooks, we have improved our visualisation tool. Now it is possible to save image of the graph. We also have changed scrolling behaviour so that it is more convenient to scroll the notebook.
* NaN features support: we also have added simple but effective way of dealing with NaN features. If you have some NaNs in the train set, they will be changed to a value that is less than the minimum value or greater than the maximum value in the dataset (this is configurable), so that it is guaranteed that they are in their own bin, and a split would separates NaN values from all other values. By default, no NaNs are allowed, so you need to use option `nan_mode` for that. When applying a model, NaNs will be treated in the same way for the features where NaN values were seen in train. It is not allowed to have NaN values in test if no NaNs in train for this feature were provided.
* Snapshotting: we have added snapshotting to our Python and R libraries. So if you think that something can happen with your training, for example machine can reboot, you can use `snapshot_file` parameter - this way after you restart your training it will start from the last completed iteration.
* R library tutorial: we have added [tutorial](https://github.com/catboost/tutorials/blob/master/r_tutorial.ipynb).
* Logging customization: we have added `allow_writing_files` parameter. By default some files with logging and diagnostics are written on disc, but you can turn it off using by setting this flag to False.
* Multiclass mode improvements: we have added a new objective for multiclass mode - `MultiClassOneVsAll`. We also added `class_names` param - now you don't have to renumber your classes to be able to use multiclass. And we have added two new metrics for multiclass: `TotalF1` and `MCC` metrics.
You can use the metrics to look how its values are changing during training or to use overfitting detection or cutting the model by best value of a given metric.
* Any delimeters support: in addition to datasets in `tsv` format, CatBoost now supports files with any delimeters

## Bug Fixes and Other Changes
* Stability improvements and bug fixes

## Thanks to our Contributors
This release contains contributions from: grayskripko, hadjipantelis and CatBoost team.

We are grateful to all who filed issues or helped resolve them, asked and answered questions.",97556265
1319,False,False,2019-11-12T01:32:20Z,2019-11-12T01:39:09Z,"### [Changed]

* PR #1502: Faster symmetry breaking in LabelModel using Munkres algorithm
",52581991
1320,False,False,2019-10-23T04:46:59Z,2019-10-23T04:59:29Z,"### [Breaking Changes]

* PR #1481: removed fault tolerant mode for labeling functions

### [Added]

* PR #1481: fault tolerant mode for appliers

### [Changed]

* PR #1450, 1467: ignore abstains in scoring, except coverage
* PR #1463: serialize all attributes of label model
* PR #1466: fix label model GPU training option
* PR #1477, #1492: pin dependency versions

### [Removed]

* PR #1454: `set_seed` utility removed

### [Contributors]

Thanks to @HiromuHota, @ferhatelmas, and @garaud for their recent contributions!",52581991
1321,False,False,2019-09-06T04:50:57Z,2019-09-06T05:02:27Z,"### [Breaking Changes]

* PR #1453: `SlicingClassifier` renamed to `SliceAwareClassifier`

### [Added]

* PR #1451: add heuristic for breaking symmetry in multiple label model optima case
* PR #1442: integration test for `MultitaskClassifier`

### [Changed]

* PR #1444: fix label model weight clamping behavior
* PR #1445: fix JSON log writer
* PR #1447: fix correct/incorrect count bug in `LFAnalysis`
* PR #1428, #1449: catch invalid label model inputs
* PR #1441: make inputs to `Scorer.score` optional",52581991
1322,False,False,2019-08-15T05:33:19Z,2019-08-15T05:56:55Z,"Version 0.9.0 is a complete redesign of the Snorkel library. There's too much added, changed, and removed to list in this entry. For more information on the release, [check out the project homepage](https://snorkel.org). From here forward, we'll keep a detailed changelog.",52581991
1323,False,True,2018-06-27T04:21:22Z,2018-06-27T04:39:02Z,"### Major changes in v0.7:
* [PyTorch](https://pytorch.org/) classifiers
* Installation now via [Conda](https://conda.io/) and `pip`
* Now [spaCy](https://spacy.io/) is the default parser (v1), with support for v2
* And many more fixes, additions, and new material!",52581991
1324,False,False,2018-05-02T21:20:47Z,2018-05-03T00:11:51Z,Version 0.6.3 adds many bug fixes and improved default hyperparameters for the generative model.,52581991
1325,False,False,2017-07-15T18:56:53Z,2017-07-15T18:57:25Z,,52581991
1326,False,False,2017-01-18T09:53:49Z,2017-01-18T10:00:00Z,,52581991
1327,False,False,2016-12-19T07:21:01Z,2017-01-13T03:58:42Z,,52581991
1328,False,False,2020-03-26T01:42:47Z,2020-03-26T01:43:07Z,"* protect: ignore EROFS (#3527) @efiop
* metrics: diff: fix bug with unchanged raw metrics (#3535) @efiop
* gdrive: config option to move remote file to trash only (#3478) @maxhora
* params: use dpath for xpaths (#3531) @efiop
* metrics: diff: handle deleted/new metric (#3529) @efiop
* remote: Optimize traverse/no_traverse behavior (#3501) @pmrowla
* introduce hyper parameters and config (#3515) @elgehelge
",83878269
1329,False,False,2020-03-24T14:15:12Z,2020-03-24T14:15:25Z,"* pull/checkout: fix empty log output if no state gets changed (#3520) @skshetry
* pull: support pulling git-only imports (#3503) @skshetry
* dvc: add Repo(skip_checks) flag (#3490) @Suor
* git: quote filenames at remind_to_track (#3315) @mroutis
* dvc: update cmd output strings to match docs (#3471) @jorgeorpinel
* external_repo: do not try too hard to fix upstream (#3512) @skshetry
* Revert ""Restyle #3393 introduce hyper parameters and config"" (#3517) @efiop
* Restyle #3393 introduce hyper parameters and config (#3516) @restyled-io
* import: fix output message on not-existing output directory (#3509) @skshetry
* version: fix bug when .git dir is removed, show more info regarding repo (#3508) @skshetry
",83878269
1330,False,False,2020-03-18T21:11:17Z,2020-03-18T21:35:16Z,"* pipeline: fix `--outs` output (#3507) @efiop
* dvc: use consistent messages for InvalidArgumentError (#3506) @efiop
",83878269
1331,False,False,2020-03-18T17:20:22Z,2020-03-18T17:20:40Z,"* git: tree: use item.path instead of item.name (#3505) @efiop
",83878269
1332,False,False,2020-03-17T23:24:19Z,2020-03-17T23:24:36Z,"* version: add supported remotes (#3498) @efiop
* import-url: allow queries in URL (#3432) @casperdcl
* template: pr update (#3495) @casperdcl
* dvc: use protected mode by default (#3472) @efiop
* gc: do not work without specifier when using -c flag (#3493) @skshetry
* completion: add --summary flag on checkout (#3491) @skshetry
",83878269
1333,False,False,2020-03-17T00:08:56Z,2020-03-17T00:09:41Z,"* logger: use standard lazy formatting (#3487) @efiop
* cmd: diff: don't load dir cache for diff (#3468) @pared
* dvc: support Python3.8 (#3463) @skshetry
* Use pre-commit for Git hooks (#3406) @andrewhare
* list: rename target param to path, update docs (#3462) @JIoJIaJIu
* exceptions: use semantic exceptions (#3430) @skshetry
* checkout: show summary by default and introduce --show-changes flag (#3401) @skshetry
* tests: remove use of mocker as context-manager (#3480) @skshetry
* dvc: optimize all target specific commands to not build graph (#3459) @Suor
* tests: add .gitignore files when upon dvc_add (#3455) @pared
* add: do not verify hardlink if file is empty (#3428) @skshetry
* api: docstring updates (2) (#3426) @jorgeorpinel
* completion: bash: misc fixes and updates (#3467) @casperdcl
* gdrive: support Google Service accounts (#3269) @MaxRis
",83878269
1334,False,False,2020-03-10T20:47:01Z,2020-03-10T20:47:33Z,"* deps: upgrade jsonpath_ng to latest version (#3464) @skshetry
* gc: make --all-commits flag visible (#3429) @skshetry
* gdrive: share drive vs just folder id when we set corpora param (#3458) @shcheklein
* list: colorize output (#3351) @JIoJIaJIu
* dvc: optimize building graph (#3443) @Suor
* metrics show: update -h output to match docs (#3420) @jorgeorpinel
* pipelines: fix edges gathering (#3421) @pared
* test: check that no remote backend modules are loaded by default (#3400) @Suor
",83878269
1335,False,False,2020-02-28T00:21:39Z,2020-02-28T00:22:22Z,"* docs: update badges (#3380) @casperdcl
* dont disable existing loggers when dvc is set up (#3345) @ttekampe
* erepo: set up more logging (#3403) @Suor
* erepo: fix relative url on default remote (#2756) (#3378) @tizoc
* Remove Linux pyfastcopy (#3412) @rxxg
* pull: fetch: external: respect `--jobs` (#3413) @casperdcl
* analytics: fix resolving used scm (#3405) @pared
* gdrive: do not import pydrive2 on module load (#3399) @Suor
* SCM: allow multiple DVC repos inside single SCM repo (#3257) @pared
* api: docstring updates (#3352) @jorgeorpinel
* change diff checksum arg name to hash (#3384) @shcheklein
* gdrive: a pair of cleanup refactors (upstream branch) (#3382) @Suor
* gc: make it safer by only activating by use of certain flags (#3363) @skshetry
* Stage: fix used_cache warning on no checksum (#3365) @pared
* remotes.http: Support dvc push for http remotes (#3343) @pmrowla
* completion: bash: properly recurse targets (#3374) @casperdcl
* metadata: add Zenodo, tidy badges and keywords (#3373) @casperdcl
",83878269
1336,False,False,2020-02-20T22:11:41Z,2020-02-20T22:12:29Z,"* Enabled Zenodo integration.
",83878269
1337,False,False,2020-02-20T01:46:51Z,2020-02-20T01:47:14Z,"* test: repro: prevent dvc.stages resetting (#3368) @efiop
",83878269
1338,False,False,2020-02-20T00:40:14Z,2020-02-20T00:40:36Z,"* completion: bash: allow multi-arg completion, minor tidy (#3367) @casperdcl
* Stage: create: reset repo when removing existing stage (#3349) @pared
* Fix bash completion (#3360) @casperdcl
* ui: fix missing progress & tidy (#3335) @casperdcl
",83878269
1339,False,False,2020-02-17T18:30:51Z,2020-02-17T18:31:11Z,"* external_repo: fix bug in path resolution (#3350) @efiop
* get/import: updates output strings, et al. (#3308) @jorgeorpinel
* term: avoid ""under X control"" and other help output updates (#3322) @jorgeorpinel
",83878269
1340,False,False,2020-02-17T15:08:37Z,2020-02-17T15:10:38Z,Fixed `gitpython`'s version in dependencies.,83878269
1341,False,False,2020-02-17T10:44:49Z,2020-02-17T10:45:11Z,"* get/import: retrieve files inside directory outs (#3309) @mroutis
* logger: refactor, remove dead code (#3306) @mroutis
* update: support specifying revision when updating (#3337) @skshetry
",83878269
1342,False,False,2020-02-14T23:14:37Z,2020-02-14T23:15:21Z,"* schema: use a more flexible hash schema (#3333) @efiop
* ui: make progress bars respect `--quiet` (#3316) @casperdcl
* dvc: do not set cache dir if it's not a dvc repo (#3329) @skshetry
* snap: test: add build and deploy checks (#3330) @casperdcl
* imp_url: make default stage fname accompany import target (#3312) @pared
* tests: fix typo on gdrive_client_secret (#3327) @skshetry
* checkout: change loglevel to debug and simplify message (#3326) @skshetry
* logger: log datetime when on debug mode (#3325) @skshetry
* daemon config fix (#3324) @pared
* erepo: fix known sha handling (#3323) @Suor
* repo: Prevent repo from setting log level (#3321) @gauravr
* dvc: refactor config (#3298) @Suor
* add: meaningful message upon adding overlapping paths (#3296) @pared
* introduce `dvc list` command (#3246) @JIoJIaJIu
* black: bump version 19.3b0 -> 19.10b0 (#3307) @mroutis
",83878269
1343,False,False,2020-02-11T20:09:59Z,2020-02-11T20:10:46Z,"* erepo: cache all read only external repos by hexsha (#3286) @Suor
* GDrive improvements and code cleanup (#3294) @shcheklein
* repro: fix bug in _get_active_graph (#3301) @efiop
* diff: use `rev` instead of `ref` (#3299) @efiop
* repo: raise exception if root_dir is not a directory path (#3295) @skshetry
* get/import: they don't work with any DVC project, only DVC repos (as well as Git repos) (#3277) @jorgeorpinel
* add: auto convert absolute_path => relative (#2975) @casperdcl
",83878269
1344,False,False,2020-02-09T23:42:31Z,2020-02-10T02:17:03Z,"* analytics: ignore request.post errors (#3292) @efiop
* logger: allow exc_info in all record types (#3290) @efiop
",83878269
1345,False,False,2020-02-09T16:48:38Z,2020-02-09T16:50:19Z,"* gdrive: add gc command support (#3288) @MaxRis
* check root .gitignore in '_ignored' (#3284) @Aljo-Rovco
* Fix blockers list in rwlock error message (#3285) @Suor
* rwlock: require info keys to be present in schema (#3283) @mroutis
* rwlock: include actionable in error message (#3270) @mroutis",83878269
1346,False,False,2020-02-05T01:20:52Z,2020-02-05T01:21:12Z,"* pipeline: show: outs: eliminate extra edges in DAG (#3217) @fabiosantoscode
* commit: add missing space (#3276) @fabiosantoscode
* diff/metics diff: update argument descriptions, et al. (#3244) @jorgeorpinel
",83878269
1347,False,False,2020-02-02T15:59:01Z,2020-02-02T15:59:27Z,"* remote: bring back manual close_pools() (#3274) @efiop
* diff: format summary to make it more human readable (#3260) @mroutis
",83878269
1348,False,False,2020-01-31T21:30:32Z,2020-01-31T21:31:04Z,"* dvc: do not check for isdir on recursive out collect (#3268) @Suor
* lint:beautysh pre-commit hook (#3263) @casperdcl
* api: prepare for dvcx summon/publish (#3251) @Suor
* diff: reimplement interface and tests from scratch (#3229) @mroutis
",83878269
1349,False,False,2020-01-30T10:03:23Z,2020-01-30T10:38:52Z,"* install: fix post-checkout hook (#3253) @efiop
",83878269
1350,False,False,2020-01-29T20:08:41Z,2020-01-29T20:09:02Z,"* gdrive: Init drive if corpora property value requested. (#3252) @MaxRis
* UI progress cleanup (#2846) @casperdcl
",83878269
1351,False,False,2020-01-28T22:46:11Z,2020-01-28T22:46:36Z,"* Set corpora and driveId params values based on type of remote disk - shared or user's. (#3239) @MaxRis
* config: verify before saving a modification (#3193) @mroutis
* erepo: make it better (#3234) @Suor
",83878269
1352,False,False,2020-01-24T21:36:32Z,2020-01-24T21:36:56Z,"* push: improve 'no remote specified' hint (#3213) @fabiosantoscode
* Remove usage of google-api-python-client deps (#3232) @MaxRis
* install: post-checkout: run only on branches/tags (#3228) @efiop
* remote: verify cache exists on dir checksum (#3225) @pared
* some doc link fixes (#3231) @pared
* erepo: pull each time (#3227) @Suor
",83878269
1353,False,False,2020-01-23T14:36:42Z,2020-01-23T14:37:20Z,"* import-url: test: prevent in-repo testing (#3224) @pared
* Update Google Project credentials to run tests (#3216) @MaxRis
* api: fallback to external_repo if not a DVC repository (#3222) @skshetry
* dvc: add sanity checks for hard/symlinks (#3088) @efiop
* tests: replace spy() with pytest-mock spy (#3208) @fabiosantoscode
* hooks: checkout: fix incorrect dvc repo detection (#3223) @efiop
* get: copy edits aroud --show-url, ""dvc"", et al. (#3220) @jorgeorpinel
* get/imp: update help output descriptions (#3214) @jorgeorpinel
* another attempt at travis dpl snap (#3212) @casperdcl
* brancher: do not get tree if there's no revs (#3211) @skshetry
* fetch: trust remote checksums (#3200) @pared
* fix snap stable & edge release errors (#3209) @casperdcl
* test: add git_dir (#3206) @Suor
* erepo: fix DependencyREPO schema (#3204) @efiop
* exception: fix spelling (#3205) @skshetry
",83878269
1354,False,False,2020-01-20T22:41:45Z,2020-01-20T22:42:17Z,"* dvc: replace flatten_dict with flatten_json (#3202) @efiop
* gdrive: allow configuring no_traverse (#3201) @efiop
* py2: remove use of `six` (#3199) @skshetry
* test: refactor tmp_dir/erepo_dir (#3197) @Suor
* external: refactor external_repo() and its users (#3190) @Suor
* add snap tests (#2956) @casperdcl
",83878269
1355,False,False,2020-01-19T18:04:41Z,2020-01-19T18:06:01Z,"* logger: remote: use lazy formatting (#3178) @efiop
* pull: treat HTTP redirects without Location header as error (#3169) @fabiosantoscode
* api: better code documentation (#3130) @jorgeorpinel
* Fix import issue without remote config in the target (#3120) @sharidas
* completion: get --show-url (#3188) @mroutis
* s3: import boto3 inside _copy instead of module level (#3195) @mroutis
* Restyle s3: copy large objects without chunking (#3187) @restyled-io
* utils: resolve_output: normpath before extracting basename (#3170) @pared
* get: implement --show-url to display only url/path to remote (#3156) @skshetry
* setup: remove py2 backports (#3165) @mroutis
* minor comments (#3173) @casperdcl
* Perf improvement for file copies (#3135) @rxxg
* status: implement support for imported files (#3150) @fabiosantoscode
* conftest: remove dvc_repo, erepo, git, git_erepo (#3142) @pared
* point to troubleshooting guide on too many open files error (#3017) @pared
* major deploy tidy (#3158) @casperdcl
* api: identify local repos with os.path.exists (#3166) @mroutis
* remote: config checksum_jobs (#3133) @JIoJIaJIu
* Fix gdrive multiple parents file list query (#3163) @MaxRis
* dvc: use pydrive2 instead of pydrive (#3161) @efiop
* import: don't forget to set rev_lock for git files (#3151) @efiop
* travis: build snap in parallel with other packages (#3145) @efiop
* test: use helper remotes in external repro (#3149) @skshetry
* test: use helper remotes in child classes of TestDataCloudCLIBase (#3148) @skshetry
* fs: tests: remove repo_dir (#3146) @pared
* ssh: test: unit, utils: test: unit: remove repo_dir (#3147) @pared
* connection: test: unit: remove repo_dir (#3143) @pared
* test: use helper remotes in TestCases (#3136) @skshetry
* tests: repro: unit: migrate to dir helpers (#3138) @pared
* tests: run: unit: migrate to dir helpers (#3139) @pared
* update: tests: unit: migrate to dir helpers (#3141) @pared
* stage: tests: unit: migrate to dir helpers (#3140) @pared
* tests: local: unit: migrate to dir helpers (#3137) @pared
* metrics: introduce `diff` (#3051) @efiop
",83878269
1356,False,False,2020-01-14T09:23:10Z,2020-01-14T09:23:35Z,* Fix build issues.,83878269
1357,False,True,2020-01-13T14:59:05Z,2020-01-13T15:45:35Z,"* test: scm: convert to dir helpers (#3116) @efiop
* get: refactor handling of git files and git-only repos (#3114) @efiop
* test: get_url: convert to dir helpers (#3115) @efiop
* test: init: convert to dir helpers (#3117) @efiop
* tests: external_repo: convert to dir helpers (#3118) @efiop
* add space for import help text (#3126) @pared
* test: refactor ssh related functions in test helper classes (#3123) @skshetry
* summon: fixes and dvcx prereq (#3101) @Suor
* gdrive: add support for teamDriveId (#3016) @efiop
* rwlock: flush and fsync (#3076) @efiop
* get: handle non-DVC repositories (#3097) @fabiosantoscode
* run: tests: migrate to dir helpers (#3094) @pared
* state: tests: migrate to dir helpers (#3096) @pared
* update: tests: migrate to dir helpers (#3100) @pared
* stage: tests: migrate to dir helpers (#3099) @pared
* tests: remove redundant native ssh tests (#3104) @efiop
* py3: use links from os module (#3090) @mroutis
* repro: tests: migrate to dir helpers (#3091) @pared
* dvc: optimize Git.is_tracked() (#3053) @Suor
* Move fs utilities to fs.py from __init__.py (#3093) @algomaster99
* import url: test: migrate to dir helpers (#3072) @pared
* output: tests: migrate to dir helpers (#3083) @pared
* py3: remove code related to py2 limitations (#3034) @mroutis
* remote: test: migrate to dir helpers (#3086) @pared
* pipeline: test: migrate to dir helpers (#3085) @pared
* install: tests: migrate to dir helpers (#3074) @pared
* setup: get rid of py2 reqs (#3082) @efiop
* py3: use format_exc instead of print_exception (#3078) @mroutis
* rwlock: check that .dvc/lock is locked (#3075) @efiop
* ui: warn about ignored options for `dvc status` and a grammar fix (#3027) @Suor
* ui: don't show exception for ""Too many files"" error (#3058) @efiop
* Write test for `walk_files` to check if it accepts Path-like and str objects (#3035) @algomaster99
* fix snap deploy stage (#3064) @casperdcl
* dvc: update gc to remove unpacked dir (#3054) @sharidas
* test: merge _should_test_aws and _get_aws_url inside S3 test helper (#3073) @skshetry
* test: merge _should_test_oss and _get_oss_url inside OSS test helper (#3071) @skshetry
* http/ imp tests - migrate do dir helpers (#3070) @pared
* dependency: test: migrate to dir helpers (#3068) @pared
* cache: test: migrate to dir helpers (#3067) @pared
* analytics: tests: migrate to dir helpers (#3066) @pared
* tests: api: convert to dir helpers (#3044) @pared
* Snap classic deployment (#3063) @casperdcl
* completion: fix --relink problem (#3061) @mroutis
* local-related methods should verify that WorkingTree is in use (#3018) @pared
* tests: remote: local: migrate to dir fixtures (#3049) @pared
* import: allow importing from non-DVC git repositories (#3020) @chatcannon
* test: Merge _should_test_azure and _get_azure_url inside Azure test helper (#3055) @skshetry
* test: add _should_test_gdrive and _get_gdrive_url inside GDrive (#3056) @skshetry
* py3: use yield from where appropriate (#3052) @Suor
* test: do not bootstrap repo template and version files in erepo_dir  (#3045) @Suor
* dvc: optimize and clean up stages collection (#3048) @Suor
* dvc: autowrap repo tree into CleanTree (#3047) @Suor
* test: add @TmpDir.chdir() (#3043) @Suor
* dvc: clean brancher (#3046) @Suor
* py3: refactor exceptions (#3042) @mroutis
* py3: use new magic from PEP 3135 (#3039) @mroutis
* Restyle fix for base None value (#3041) @restyled-io
* Ensure `relpath` accepts str and Path-like objects (#3037) @algomaster99
* metrics: don't show working tree if it is clean (#3025) @Suor
* ui: add checkout --relink to autocomplete scripts (#3026) @Suor
* py3: migrate utils/compat.py to compat.py (#3032) @mroutis
* py3: remove imports from utils.compat (#3031) @mroutis
* py3: remove csv_reader and makedirs from utils/compat.py (#3030) @mroutis
* py3: remove methods for casting bytes in python 2 (#3029) @mroutis
",83878269
1358,False,False,2019-12-25T14:14:05Z,2019-12-25T14:14:47Z,Fix `inflect` version.,83878269
1359,False,False,2020-01-01T01:24:03Z,2020-01-01T01:24:41Z,"* py3: remove string compat related code (#3024) @mroutis
* py3: get rid of is_py checks (#3021) @mroutis
* py3: remove future imports (#3022) @mroutis
* py3: deprecate 2.7 (#3019) @mroutis
* tests: func: convert test_get.py test_utils.py to new fixtures (#3014) @efiop
* repo: move dvcignore from repo to tree (#2974) @pared
* dvc: make graph consist of stages not their paths (#3012) @Suor
* dvc: support granularity for fetch/pull/push/status/checkout (#3002) @efiop
* Improve Google Drive auth failure error reporting (#2991) @MaxRis
* summon: first draft with python specific implementation (#2971) @mroutis
* ui: fix extra newline in dvc version (#3006) @Suor
* test: test ignore nuances (#3003) @Suor
",83878269
1360,False,False,2019-12-24T18:20:27Z,2019-12-24T18:21:01Z,"* dvc: use ' to mark dynamic command output, et al. (#2986) @jorgeorpinel
* tests: use dir_helpers on repo (#2950) @mroutis
* tests: use dir helpers on updater (#2952) @mroutis
* import: test: refactor to dir helpers (#2935) @pared
* ui: reorder checkout options to go from common to rare (#2966) @Suor
* remote: s3: adjust jobs number basing on file descriptors number (#2866) @pared
* import: allow downloading regular files/dirs tracked by git  (#2889) @Baranowski
* Standardize gdrive tests with others remotes (#2958) @MaxRis
* temporary_windows_drive fixture: move to dir_helpers (#2937) @pared
* tests: use dir helpers on analytics (#2951) @mroutis
",83878269
1361,False,False,2019-12-13T22:18:04Z,2019-12-13T22:21:02Z,"* Restyle remote: use absolute from root for gdrive credentials file (#2949) @e3bo 
",83878269
1362,False,False,2019-12-13T18:58:13Z,2019-12-13T18:59:57Z,"* remote: make `copy` links atomic for local/hdfs/ssh (#2943) @efiop
* dvc: add checkout --relink (#2922) @Suor
",83878269
1363,False,False,2019-12-13T18:28:55Z,2019-12-13T18:29:13Z,"* remote: Extend S3 remote support for custom ACL (#2931) @rbvesb
",83878269
1364,False,False,2019-12-13T15:43:26Z,2019-12-13T15:43:52Z,"* dvc: release locks when running a command (#2584) @efiop
* run: provide a hint if we get output duplication error (#2941) @efiop
",83878269
1365,False,False,2019-12-13T01:20:43Z,2019-12-13T01:21:03Z,"* dvc: make flufl.lock opt-in and use zc.lockfile (#2918) @efiop
* test: a couple of dir helpers fixes (#2938) @Suor
* checkout: test: refactor to dir helpers (#2934) @pared
* commit: test: refactor to dir helpers (#2932) @pared
* snap: remove plugs (incompatible with classic) (#2939) @casperdcl
* use cache dir as a default remote when importing from local repo (#2915) @maykulkarni
* import-url: add directories to examples (#2907) @efiop
* test: move: convert to dir helpers (#2926) @pared
",83878269
1366,False,False,2019-12-06T21:15:53Z,2019-12-06T21:16:21Z,"* remote: base: download: don't walk dir twice (#2909) @efiop
* add: test: convert to dir helpers 1 (#2898) @pared
* import-url: support directories (#2894) @verasativa
",83878269
1367,False,False,2019-12-07T12:54:36Z,2019-12-07T12:54:58Z,"* dvc/dagascii: Use pager instead of AsciiCanvas._do_draw (#2815) @xliiv
",83878269
1368,False,False,2019-12-10T21:04:39Z,2019-12-10T21:05:13Z,"* add: test: convert to dir helpers 3 (#2921) @pared
* get: refactor, clean up and fix `dvc get` implementation (#2925) @Suor
* build_deb: Debian directory appended. Issue #2800 (#2924) @Abrosimov-a-a
* get: copy/download files tracked by Git (#2837) @danihodovic
* test: write a usage text for dir_helpers (#2908) @Suor
* analytics: refactor into a module (#2826) @mroutis
* test: migrate test_ignore (#2913) @Suor
* add: test: convert to dir helpers 2 (#2906) @pared
",83878269
1369,False,False,2019-12-06T00:11:27Z,2019-12-06T00:16:08Z,Fixed pypi package deployment.,83878269
1370,False,False,2019-12-05T14:25:14Z,2019-12-05T14:25:39Z,"* dvc: revert checkout to be silly and fast, relink on dvc add though (#2882) @Suor
* test: refactor tmp dir helper fixtures (#2868) @Suor
* state: quote % in path (#2892) @efiop
* external repo: checkout revision before initializing dvc repo (#2852) @pared
* much grammar such fix (#2883) @casperdcl
* lengthen bars unless nested/threaded (#2857) @casperdcl
* Stream progress (#2875) @casperdcl
* NoRemoteInExternalRepoError: fix message (#2881) @pared
* Snap (#2778) @casperdcl
* Support adding directories in google cloud storage remote (#2853) @skshetry
* s3: Check for all files in given path to match (#2873) @skshetry
* test: skip non supported remotes fast in api tests (#2870) @Suor
* GDrive remote support (#2551) @MaxRis
* s3: ignore empty directories while walking files (#2683) @mroutis
* remote: http: raise exception when response with error status code (#2794) @pared
* remote: protect all remote client/session creation code with locks (#2863) @Suor
* test: refactor & remove redundant test fixtures (#2861) @danihodovic
* perf: optimize cache listing for local, ssh and hdfs (#2836) @Suor
* remote: small .save_info()/.get_checksum() cleanup (#2835) @Suor
* RemoteNotSpecifiedInExternalRepoError: dont pass cause of exception (#2854) @pared
",83878269
1371,False,False,2019-11-26T18:55:49Z,2019-11-26T18:57:15Z,"* Possible fix for #2850. (#2856) @peper0
* remote: fix remote default call with no arguments (#2821) @kaiogu
* Fix typos (#2855) @skshetry
* Fix typo and grammar (#2842) @skshetry
* Refactor `startswith` with `path_isin` util (#2832) @skshetry
* dvc: remove unused config paths (#2827) @Suor
* GS progress for push & pull (#2809) @casperdcl
* use SI prefixes for progress (#2817) @casperdcl
* Display path relative to temporary repo when get/import-ing files (#2798) @skshetry
* perf: switch schema validation library (#2796) @Suor
",83878269
1372,False,False,2019-11-20T06:29:12Z,2019-11-20T06:29:42Z,"* import: intercept and rephrase OutputNotFound message (#2777) @pared
* perf: optimize yaml parsing for stages (#2775) @Suor
* makedirs: fix mode flag is being ignored starting from Python 3.7 (#2790) @shcheklein",83878269
1373,False,False,2019-11-11T01:32:17Z,2019-11-11T01:33:08Z,Fix windows build.,83878269
1374,False,False,2019-11-10T23:53:58Z,2019-11-10T23:54:25Z,"* Add better heuristic for build detection (#2773) @n3hrox
",83878269
1375,False,False,2019-11-18T13:13:19Z,2019-11-18T13:14:15Z,"* Write test for `tmp_fname` to check if it accepts Path-like and str objects (#2808) @algomaster99
* Ensure `remove` accepts str and Path-like objects (#2795) @algomaster99
* perf: a small stage validation optimization (#2786) @Suor
* Improve `LockError` message (#2765) @algomaster99
* dvc: remove reorder_python_imports formatter (#2787) @efiop
* get/import: more meaningful message on NoRemoteError (#2759) @pared
* test: try using azurite 3.3.0-preview (#2785) @efiop
",83878269
1376,False,False,2019-11-10T16:14:09Z,2019-11-10T16:14:42Z,"* Ensure `move` accepts str and Path-like objects (#2769) @algomaster99
* Add win32timezone hook for pyinstaller
",83878269
1377,False,False,2019-11-09T17:40:55Z,2019-11-09T17:41:20Z,"* non-blocking intermediate progress IO (#2767) @casperdcl
",83878269
1378,False,False,2019-11-09T00:08:50Z,2019-11-09T00:09:27Z,"* pyinstaller: add pywin32/win32file hook (#2763) @efiop
* win: use SuppressibleMsgBox instead of MsgBox (#2764) @efiop ",83878269
1379,False,False,2019-11-06T22:25:28Z,2019-11-06T22:25:48Z,"* system: use logging instead of dvc.logger (#2748) @efiop
* Ensure `file_md5` accept str and Path-like objects (#2746) @algomaster99
",83878269
1380,False,False,2019-11-08T19:04:22Z,2019-11-08T19:05:35Z,"* dvc: add workaround for `LookupError: unknown encoding: idna` (#2761) @efiop
* Restyle dvc: add workaround for `LookupError: unknown encoding: idna` (#2762) @restyled-io
* Test for issue #2672 added. (#2758) @kss682
* Ensure `makedirs` accepts str and Path-like objects (#2757) @algomaster99
* analytics: don't verify config from repo (#2753) @efiop
* Ensure `copyfile` accepts str and Path-like objects (#2752) @algomaster99
* ignore: make DvcIgnoreFilter use tree (#2751) @pared
* checkout: don't cleanup links when checking out specific targets (#2750) @efiop
",83878269
1381,False,False,2019-11-06T01:09:04Z,2019-11-06T01:11:16Z,* dvc get leaves dangling symlinks if source repo is set to use symlinks as its cache type (#2745) @shcheklein ,83878269
1382,False,False,2019-11-06T00:13:10Z,2019-11-06T00:13:35Z,"* Remove `get_parent_dirs_up_to` (#2741) @algomaster99
* Ensure `contains_symlink_up_to` accept both str and Path-like objects (#2740) @algomaster99
* sftp: only remove src after an atomic copy during move (#2739) @mroutis
",83878269
1383,False,False,2019-11-05T01:20:24Z,2019-11-05T01:20:49Z,"* dvc: automatically reorder imports (#2736) @efiop
* system: win: use win32file for _getdirinfo (#2735) @efiop
* fix NPE when we do get that does not provide progress callback (#2734) @shcheklein
",83878269
1384,False,False,2019-11-04T20:55:08Z,2019-11-04T20:55:38Z,"* updater: detect conda (#2679) @n3hrox
* fix PR template to mention recommendatory nature of CC and DS (#2723) @shcheklein
",83878269
1385,False,False,2019-11-03T22:38:10Z,2019-11-03T22:41:18Z,"1) [Refactored URLInfo-related logic](https://github.com/iterative/dvc/pull/2707);
2) [Added support for moving between different drives for SSH remotes](https://github.com/iterative/dvc/pull/2709);
3) [Removed ""Multi-threaded"" prefix from progress bars](https://github.com/iterative/dvc/issues/2686); Kudos @kurianbenoy :tada: 
4) [Added unit tests for `get_mtime_and_size`](https://github.com/iterative/dvc/pull/2698); Kudos @algomaster99 :tada: 
5) [Removed cask installation detection](https://github.com/iterative/dvc/issues/2680); Kudos @ATR-oCiTy :tada: 
6) Fixed typos: https://github.com/iterative/dvc/pull/2712, https://github.com/iterative/dvc/pull/2713, https://github.com/iterative/dvc/pull/2714, https://github.com/iterative/dvc/pull/2717, https://github.com/iterative/dvc/pull/2716, https://github.com/iterative/dvc/pull/2715; Kudos @Pandemic179 @eshaan-jeckyll @ATR-oCiTy @the-thirteenth-star @GeorgeSabu-mec @johntharian :tada: :tada: :tada: 
7) [Added pkg manager to `dvc version` output](https://github.com/iterative/dvc/pull/2722); Kudos @kss682 :tada: 
8) [Stopped printing multiple ""Need help?"" footers when encountering multiple exceptions](https://github.com/iterative/dvc/pull/2674); Kudos @n3hrox :tada: ",83878269
1386,False,False,2019-11-01T21:58:17Z,2019-11-01T21:58:41Z,"1) [Introduced additional tests for s3 ETags](https://github.com/iterative/dvc/pull/2695);
2) [Removed obsoleted warning](https://github.com/iterative/dvc/pull/2693); Kudos @sadielbartholomew :tada: 
3) [Fixed bug in `dvc get-url`](https://github.com/iterative/dvc/pull/2705);",83878269
1387,False,False,2019-10-30T15:20:05Z,2019-10-30T15:20:39Z,"1) [Added additional unit tests for fs utils](https://github.com/iterative/dvc/pull/2673);
2) [Temporarily hidden `--all-commits` flag for `gc`](https://github.com/iterative/dvc/pull/2682);
3) [Refactored backtics and single-quotes usage in the code](https://github.com/iterative/dvc/pull/2644);
4) [Added a workaround for flufl.lock bug](https://github.com/iterative/dvc/pull/2688);
5) [Fixed bug when pulling imported directories](https://github.com/iterative/dvc/pull/2692);",83878269
1388,False,False,2019-10-26T20:36:13Z,2019-10-26T20:37:31Z,"1) [Reverted `path.lstrip(""/"")` patch for `dvc get/import`](https://github.com/iterative/dvc/pull/2651)",83878269
1389,False,False,2019-10-25T20:24:43Z,2019-10-25T21:05:23Z,"1) [Initial UI improvements for `dvc add`](https://github.com/iterative/dvc/pull/2546);
2) [Add support for S3 directories as external deps/outs](https://github.com/iterative/dvc/pull/2619);
3) [Exclude dvc/utils/compat.py from DeepSource analysis](https://github.com/iterative/dvc/pull/2670); Kudos @sanketsaurav :tada: 
4) [Dynamically adjust chunk_size when uploading to Google Cloud Storage](https://github.com/iterative/dvc/pull/2661);",83878269
1390,False,False,2019-10-24T20:41:43Z,2019-10-24T20:45:01Z,"1) [Fix ssh password/passphrase prompt collision with the progress bar](https://github.com/iterative/dvc/pull/2660);
2) [Major performance improvement for projects with large (> 1000 dvc-files) DAGs](https://github.com/iterative/dvc/pull/2668);",83878269
1391,False,False,2019-10-24T14:15:30Z,2019-10-24T14:16:25Z,1) [Fix bug in short progress bars](https://github.com/iterative/dvc/pull/2663);,83878269
1392,False,False,2019-10-23T19:48:33Z,2019-10-23T20:04:37Z,"1) [Fixed warning in `dvc version`](https://github.com/iterative/dvc/commit/a0d364e78ad0ad5d10e30017829409d348f3c5f3);
2) [Removing leading `/` in `dvc import/get` path argument](https://github.com/iterative/dvc/pull/2651); Kudos @SrividyaKK :tada: 
3) [Added `--all-commits` support for `dvc gc`](https://github.com/iterative/dvc/pull/2643);
4) [Optimized fetching of imports from external repos](https://github.com/iterative/dvc/pull/2654);
5) [Fixed bug in directory cache collection](https://github.com/iterative/dvc/pull/2656);",83878269
1393,False,False,2019-10-21T22:26:02Z,2019-10-21T22:31:57Z,"1) [Fixed import order](https://github.com/iterative/dvc/pull/2636); Kudos @Naba7 :tada: 
2) [Disable progress bar when output is not a TTY](https://github.com/iterative/dvc/pull/2550);
3) [Deduplicate brancher entries](https://github.com/iterative/dvc/pull/2639);
4) [Deduplicate used cache entries](https://github.com/iterative/dvc/pull/2630);
5) [Fix bug in dvc repository lock that was making ~15 sec slow on Mac and on other systems with bad dns configuration](https://github.com/iterative/dvc/pull/2642);
6) [Fix bug in push/pull/status from http remote, which made dvc hit ulimit for opened file descriptors on Mac and Windows](https://github.com/iterative/dvc/pull/2646);
",83878269
1394,False,False,2019-10-18T11:32:16Z,2019-10-18T11:32:42Z,1) [Fixed extremely slow dvc repository locks caused by a CPython bug](https://github.com/iterative/dvc/pull/2628);,83878269
1395,False,False,2019-10-17T20:13:02Z,2019-10-17T20:13:31Z,"1) [Fixed import order in `dvc/remote/base.py`](https://github.com/iterative/dvc/pull/2626); Kudos @sofia100 :tada: 
2) [Fixed import order in `dvc/__init__.py`](https://github.com/iterative/dvc/pull/2618); Kudos @aloks98 :tada: 
3) [Fixed bug in our progress bars on tiny terminals](https://github.com/iterative/dvc/issues/2598);",83878269
1396,False,False,2019-10-17T18:35:48Z,2019-10-17T18:36:14Z,1) [Don't set default user when connecting to hdfs](https://github.com/iterative/dvc/pull/2622);,83878269
1397,False,False,2019-10-17T12:52:17Z,2019-10-17T12:52:41Z,"1) [Refactored repo lock logic](https://github.com/iterative/dvc/pull/2590);
2) [Caching cloned external repos for `dvc import`](https://github.com/iterative/dvc/pull/2583);
3) [Fixed our bash completion scripts for `dvc import-url` and `get-url` commands](https://github.com/iterative/dvc/pull/2596);
4) [Resetting dvcignore when reloading the DAG](https://github.com/iterative/dvc/pull/2604);
5) [Avoiding creating cache directory until we actually need it](https://github.com/iterative/dvc/pull/2597);
6) [Reduced verbosity of `dvc add`](https://github.com/iterative/dvc/pull/2607);
7) [Made help messages have consistent case](https://github.com/iterative/dvc/pull/2591); Kudos @Hiyorimi :tada: 
8) [Fixed bug in `import/get/import-url/get-url` commands, that caused incorrect output path resolution](https://github.com/iterative/dvc/pull/2610);
9) [Fixed logger to put warnings into stderr instead of stdout](https://github.com/iterative/dvc/pull/2612);
10) [Updated requirements for pyinstaller version](https://github.com/iterative/dvc/pull/2615);",83878269
1398,False,False,2019-10-10T11:40:04Z,2019-10-10T11:47:09Z,"1) [Fix bug in external cache directory](https://github.com/iterative/dvc/pull/2593); Kudos @jahabdank :tada: 
2) [Fix bug in dynamic version generation](https://github.com/iterative/dvc/pull/2592); Kudos @irchanbani :tada: ",83878269
1399,False,False,2019-10-09T08:47:52Z,2019-10-09T08:48:35Z,"1) [Improved README wording](https://github.com/iterative/dvc/pull/2571); Kudos @jimmy1134 :tada: 
2) [Escape paths when adding to gitignore](https://github.com/iterative/dvc/issues/2043);
3) [Fixed typo in `dvc commit` message](https://github.com/iterative/dvc/pull/2577); Kudos @vgerak :tada: 
4) [Adjusted pylintrc to correspond to flake8 and black configs](https://github.com/iterative/dvc/pull/2578); Kudos @vgerak :tada: 
5) [Reduced unecessary verbosity](https://github.com/iterative/dvc/pull/2576); Kudos @vgerak :tada: 
6) [Support opening git-controlled files with our API's `open()` method](https://github.com/iterative/dvc/pull/2566);
7) [Fix bug in mac pkg packages](https://github.com/iterative/dvc/pull/2586);",83878269
1400,False,False,2019-10-03T19:53:33Z,2019-10-03T19:55:22Z,1) [Add shell completion to deb/rpm/mac pkgs](https://github.com/iterative/dvc/issues/2181); Kudos @nik123 :tada: ,83878269
1401,False,False,2019-10-02T07:17:22Z,2019-10-02T07:17:58Z,1) [Improve PATH modification rules when running from pyenv](https://github.com/iterative/dvc/pull/2562);,83878269
1402,False,False,2019-10-01T07:56:00Z,2019-10-01T09:04:31Z,"1) [Add a friendly error for unicode on python 2](https://github.com/iterative/dvc/issues/2524);
2) [Make spaces consistent in the messages](https://github.com/iterative/dvc/pull/2544); Kudos @yfarjoun :tada: 
3) [Fix LD_LIBRARY_PATH issue when running git from binary dvc package](https://github.com/iterative/dvc/issues/2471);
4) [Improve ssh error messages](https://github.com/iterative/dvc/issues/2535);
5) [Make `dvc run/repro` cleanup the environment from pyenv modifications when running a command](https://github.com/iterative/dvc/issues/2506);
6) [Make `dvc run/repro` use --norc/--noprofile shell flags when running a command](https://github.com/iterative/dvc/issues/2506);",83878269
1403,False,False,2019-09-26T15:34:06Z,2019-09-26T15:34:35Z,1) [Don't forget to install `psutil` when building dvc binary package with pyinstaller](https://github.com/iterative/dvc/issues/2537);,83878269
1404,False,False,2019-09-25T08:12:20Z,2019-09-25T08:12:45Z,"1) [Add support for reflink, hardlink, symlink for ssh external outputs](https://github.com/iterative/dvc/issues/1652);
2) [Fix `dvc move` bug](https://github.com/iterative/dvc/pull/2485);
3) [Deduplicate links on checkout and ensure proper link type and permissions](https://github.com/iterative/dvc/pull/2488);
4) [Use NFS and CIFS compatible locks in dvc repository](https://github.com/iterative/dvc/pull/2461);
5) [Fixed bug in improper relpath calculation which was causing problems with deeply nested dependencies](https://github.com/iterative/dvc/pull/2496);
6) [Prevent using dvcfiles as dependencies or outputs](https://github.com/iterative/dvc/pull/2493);
7) [Optimized imports to speedup dvc launch time](https://github.com/iterative/dvc/issues/2445);
8) [Stop corrupting git hooks by `dvc install`](https://github.com/iterative/dvc/pull/2505);
9) [Move repo locks from CLI to API](https://github.com/iterative/dvc/pull/2519);
10) [Make `dvc pull` download data for `dvc import`ed dvcfiles](https://github.com/iterative/dvc/pull/2499);
11) [Fixed bug in daemon launcher that sometimes wasn't calling the same script that it was running from](https://github.com/iterative/dvc/pull/2523);
12) [Added a workaround for `pyenv` modifying `PATH` when running `dvc`](https://github.com/iterative/dvc/pull/2525);",83878269
1405,False,False,2019-09-09T17:28:37Z,2019-09-09T17:29:07Z,"1) [Fix bug in our git hooks, which made them incompatible with dash](https://github.com/iterative/dvc/commit/2d2ac67e50e4614d5a4d236b15171bd3b50648e6);
2) [Don't write default wdir to DVC-files](https://github.com/iterative/dvc/pull/2478);
3) [Introduce `--always-changed` flag for `dvc run`](https://github.com/iterative/dvc/pull/2479);
4) [Fix `gitignore` bug when using `symlinks` as link type](https://github.com/iterative/dvc/issues/2476);",83878269
1406,False,False,2019-09-06T21:13:05Z,2019-09-06T21:16:20Z,"1) [Make `dvc get` print a hint when dvc-file is specified instead of output path](https://github.com/iterative/dvc/issues/2468);
2) [Deduplicate data on second `dvc add`](https://github.com/iterative/dvc/issues/2016);
3) [Properly handke `dvc get` on a git repo that is not a dvc repo](https://github.com/iterative/dvc/issues/2430);
4) [Fix bug in `dvc get`, that wasn't restoring proper environment when running git from our binary built by pyinstaller](https://github.com/iterative/dvc/issues/2471);",83878269
1407,False,False,2019-09-04T15:36:11Z,2019-09-04T15:38:22Z,1) [Fixed bug that made dvc unprotect files for every use](https://github.com/iterative/dvc/issues/2125#issuecomment-527945049);,83878269
1408,False,False,2019-09-03T21:37:25Z,2019-09-03T21:39:09Z,"1) [Fix bug in `dvc add` where it was setting incorrect `wdir`](https://github.com/iterative/dvc/pull/2427);
2) [Fix bug in `gc` for clouds, where it wasn't able to process paths with subdirectories](https://github.com/iterative/dvc/issues/2394);
3) [Fixed a bunch of confusing messages from `dvc repro` output](https://github.com/iterative/dvc/pull/2440);
4) [Fixed bug in `active_stages`](https://github.com/iterative/dvc/pull/2428);
5) [Improved progress bars for pull/push/checkout/etc operations](https://github.com/iterative/dvc/pull/2436);
6) [Fixed `dvc remove` help message](https://github.com/iterative/dvc/pull/2457);
7) [Fixed misleading error message when trying to `dvc get` from invalid dvc repo](https://github.com/iterative/dvc/pull/2460);",83878269
1409,False,False,2019-08-21T22:51:57Z,2019-08-21T22:52:56Z,"1) [Made first steps to improving UI by migrating to tqdm instead of using our own progress bar](https://github.com/iterative/dvc/pull/2333);
2) [Fixed bug in `dvc move`, that wouldn't commit changes properly](https://github.com/iterative/dvc/pull/2421);
3) [Added support for kerberos for ssh remotes](https://github.com/iterative/dvc/pull/2424); Kudos @JoshuaPostel :tada: ",83878269
1410,False,False,2019-08-20T00:56:14Z,2019-08-20T00:56:39Z,"1) [Added support for ACL for s3 remotes](https://github.com/iterative/dvc/issues/2414); Kudos @AlJohri :tada: 
2) [Added proper handling for unsupported `no_traverse false` option in HTTP(s) remotes](https://github.com/iterative/dvc/issues/2380);",83878269
1411,False,False,2019-08-19T13:01:16Z,2019-08-19T13:02:08Z,"1) [Added support for streaming data files from remotes through our Python API](https://github.com/iterative/dvc/issues/2311);
2) [Fixed git post-checkout hook to not run `dvc checkout` if the user is simply checking-out a specific file](https://github.com/iterative/dvc/issues/2400); Kudos @gthb :tada: 
3) [Fixed bug in signal handler for `dvc run/repro`](https://github.com/iterative/dvc/issues/2406);",83878269
1412,False,False,2019-08-15T11:06:58Z,2019-08-15T11:07:35Z,"1) [Fixed bug in `dvc diff` output](https://github.com/iterative/dvc/issues/1874);
2) [Added support for shared cache within a user group](https://github.com/iterative/dvc/pull/2298);
3) [Added support for file streaming from Azure remote through Python API](https://github.com/iterative/dvc/pull/2371);
4) [Added support for multiple targets for `dvc metrics show`](https://github.com/iterative/dvc/pull/2319);
5) [Added support for faster `status` for azure remote](https://github.com/iterative/dvc/pull/2319);",83878269
1413,False,False,2019-08-05T11:53:13Z,2019-08-05T11:53:57Z,"1) [Improved up-to-date message printed by `dvc status`](https://github.com/iterative/dvc/pull/2364); Kudos @SRITANU :tada: 
2) [Refactored scm/git classes](https://github.com/iterative/dvc/pull/2351); Kudos @RahulR19 :tada: 
3) [Updated azure requirements](https://github.com/iterative/dvc/pull/2370);",83878269
1414,False,False,2019-08-01T20:35:21Z,2019-08-01T20:35:54Z,"1) [Don't use `.dvc/lock` and `.dvc/state.lock` when running `dvc get` to workaround NFS and CIFS limitations](https://github.com/iterative/dvc/issues/2135);
2) [Run dvc in git hooks only if current branch is a dvc repository](https://github.com/iterative/dvc/issues/2208); Kudos @gthb :tada: 
3) [Speedup (up to x2) `dvc pull/push/fetch` with multiple targets specified](https://github.com/iterative/dvc/issues/2308);
4) [Remove `--show-checksums` option from `dvc status` command](https://github.com/iterative/dvc/issues/2085); Kudos @kurianbenoy :tada: 
5) [Fix bug in `dvc repro`, which threw an error when specifying `--single-item` through CLI](https://github.com/iterative/dvc/issues/2354);",83878269
1415,False,False,2019-07-28T21:55:05Z,2019-07-28T22:03:13Z,"1) [`-x|--xpath` specified in `dvc metrics show` command now overrides xpath defined in the dvc-file](https://github.com/iterative/dvc/issues/2285);
2) [Deduplicated files in a hint printed by in `dvc run` command](https://github.com/iterative/dvc/issues/1475);
3) [Temporarily fixed ruamel.yaml version range to avoid installation problems on alpine linux](https://github.com/iterative/dvc/issues/2334); Kudos @AlexJoz :tada: ",83878269
1416,False,False,2019-07-25T00:49:29Z,2019-07-25T00:50:05Z,"1) [Support older `md5` tool versions for external ssh deps/outs;](https://github.com/iterative/dvc/issues/2242)
2) [Add a workaround for submodules bug in gitpython;](https://github.com/iterative/dvc/issues/1898); Kudos @gdyuldin :tada: 
3) [Fixed bash autocompletion;](https://github.com/iterative/dvc/issues/2069)Kudos @Naba7 :tada: 
4) [Fixed bugs in ssh remote that caused unexpected errors;](https://github.com/iterative/dvc/issues/2280)
5) [Sped up dir checksum calculation for ssh remote;](https://github.com/iterative/dvc/pull/2278)
6) [Fixed recursion when using deepcopy for PathInfos;](https://github.com/iterative/dvc/issues/2259)
7) [Fixed --jobs bug in pull/push/etc;](https://github.com/iterative/dvc/pull/2289)
8) [Lock `dvc import-url` stages by default;](https://github.com/iterative/dvc/pull/2307)
9) [Fixed bug that caused dvc-file checksum change when `meta` field changes;](https://github.com/iterative/dvc/issues/2209)
10) [Fixed bug in ssh remote, that caused multiple password prompts;](https://github.com/iterative/dvc/issues/2305)
11) [Fixed bug in checksum calculation for directories, that caused dvc to not use state db for files inside of that dir, which resulted in performance degradation;](https://github.com/iterative/dvc/issues/2258)
12) [Temporarily made psutil dependency optional for `dvc version` command;](https://github.com/iterative/dvc/issues/2284)",83878269
1417,False,False,2019-07-15T17:33:54Z,2019-07-15T17:34:11Z,"1) [Fixed directory collection process](https://github.com/iterative/dvc/pull/2270);
2) [Fixed signal handling bug in `dvc run`](https://github.com/iterative/dvc/pull/2271);",83878269
1418,False,False,2019-07-15T08:41:30Z,2019-07-15T08:42:34Z,"1) [Fixed a bug in `dvc import` that was throwing an error if path to data was specified with a trailing /](https://github.com/iterative/dvc/issues/2237);
2) [Supported dvcignores for ignoring files/dirs when using `dvc add/run/etc`;](https://github.com/iterative/dvc/issues/1876);
3) [Removed beta warnings from `dvc import`](https://github.com/iterative/dvc/pull/2257);
4) [Fixed bug in `dvc run` where it would try to use build cache for callback stages](https://github.com/iterative/dvc/issues/1913);
5) [Fixed bug in `dvc import`, where it wasn't adding output to the gitignore](https://github.com/iterative/dvc/issues/2263);
6) [Excluded analytics warning from `dvc init` message when analytics is disabled](https://github.com/iterative/dvc/issues/2267); Kudos @mindsbackyard :tada: 
7) [SSH remote now uses connection pool to speedup external deps/outs scenario](https://github.com/iterative/dvc/pull/2264);",83878269
1419,False,False,2019-07-11T09:36:35Z,2019-07-11T09:44:13Z,"1) [Unified terminology in dvc help messages](https://github.com/iterative/dvc/pull/2112);
2) [Fixed ssh race condition when creating cache directories](https://github.com/iterative/dvc/issues/1862);
3) [Optimized state db access when cleaning up unused links on checkout](https://github.com/iterative/dvc/issues/2093);
4) [Updated bash autocomplete script](https://github.com/iterative/dvc/pull/2195); Kudos @Naba7 🎉 
5) [Switched to using travis windows builds instead of appveyor](https://github.com/iterative/dvc/pull/2222);
6) [Parallelized checksum computations for directories](https://github.com/iterative/dvc/issues/2073); Kudos @Witiko 🎉 
7) [Fixed a bug where dvc checkout was leaving old workspace links when there was no checksum in the dvc file](https://github.com/iterative/dvc/issues/2146);
8) [Optimized DAG build, achieving >x20 performance improvement](https://github.com/iterative/dvc/issues/2203);
9) [Fixed a bug in scm, where dvc was trying to fetch remote branches if there were none such branches locally](https://github.com/iterative/dvc/issues/2213);
10) [Optimize repro to not check status if --force is arlready specified](https://github.com/iterative/dvc/pull/2245);
11) [Started using travis stages to properly organize release deployment](https://github.com/iterative/dvc/pull/2249);",83878269
1420,False,False,2019-06-26T15:10:41Z,2019-06-26T15:13:49Z,"1) [Fix bug in `relpath` on Windows, that made it return not str if first argument was PathInfo](https://github.com/iterative/dvc/issues/2188);
2) [Stop explicitly parsing env to obtain s3 settings and leave that to boto3 to handle internally](https://github.com/iterative/dvc/pull/2193);",83878269
1421,False,False,2019-06-25T20:13:16Z,2019-06-25T20:13:53Z,"1) [Make progress bars respect `-q|--quiet`](https://github.com/iterative/dvc/pull/1377);
2) [Optimize stat calls when collecting metadata](https://github.com/iterative/dvc/pull/2072);
3) [Don't spin up thread pool when `--jobs 1` is set for `push/pull/fetch/status -c`](https://github.com/iterative/dvc/pull/2074);
4) [Fix `track changes with git` message](https://github.com/iterative/dvc/pull/2077/files); Kudos @ricardoserradas :medal_sports:
5) [Make `dvc version` report fs type and supported link types](https://github.com/iterative/dvc/issues/1983); Kudos @algomaster99 :medal_sports: 
6) [Add description for rpm and deb packages](https://github.com/iterative/dvc/issues/1718); Kudos @kurianbenoy  :medal_sports: 
7) [Support AWS S3 encryption](https://github.com/iterative/dvc/issues/1967); Kudos @dberenbaum :medal_sports: 
8) [Optimize cache validation for large directories](https://github.com/iterative/dvc/issues/1969);
9) [Add a better description for `targets` arguments in `push/pull/fetch/status` commands](https://github.com/iterative/dvc/pull/2111); Kudos @sanidhyamangal :medal_sports: 
10) [Make `dvc status -c` more informative by providing a better progress bar when collecting status for remotes](https://github.com/iterative/dvc/issues/1762);
11) [Fix bug when having your cache on another partition on Windows caused a crash during checksum computation](https://github.com/iterative/dvc/issues/2119);
12) [Fix bug in `dvc metrics` where it was reproting `master` branch when listing metrics for all tags](https://github.com/iterative/dvc/issues/2079);
13) [Standartisize order of command options in help messages](https://github.com/iterative/dvc/pull/2134); Kudos @vibhor98 :medal_sports: 
14) [Use `pathspec` instead of `dulwich` to handle `dvcignore`](https://github.com/iterative/dvc/issues/2010);
15) [Handle `SIGINT` gracefully when `dvc run`-ing a command](https://github.com/iterative/dvc/issues/1593); Kudos @vasinkd :medal_sports: 
16) [Use more sftp connections to speed up status collection on SSH remotes](https://github.com/iterative/dvc/pull/2131);
17) [Introduced `dvc import/get` commands to handle importing/downloading from other dvc repositories. `dvc import` is in beta state and is not ready for production. Old `dvc import` is now called `dvc import-url`. Also introduced `dvc get-url` for downloading from ulr to provide command symmetry.](https://github.com/iterative/dvc/pull/2160);
18) [Introduced python API for opening and reading files from dvc repositories](https://github.com/iterative/dvc/pull/2162);
19) [Fix `dvc pipeline show -c` command](https://github.com/iterative/dvc/issues/2170);
20) [Check DVC-file name validity before actually running the command](https://github.com/iterative/dvc/issues/2150);",83878269
1422,False,False,2019-05-29T10:44:58Z,2019-05-29T10:45:52Z,"1) [Ditch `requirements.txt` in favor of `extras` in `setup.py`](https://github.com/iterative/dvc/issues/1979); Kudos @algomaster99 🎉 
2) [Use `reflinks` when copying files;](https://github.com/iterative/dvc/issues/2057) Kudos @Witiko 🎉 
3) [Support `remote://` notation for `push/pull/status`;](https://github.com/iterative/dvc/issues/2066)",83878269
1423,False,False,2019-05-28T21:00:27Z,2019-05-28T22:56:30Z,"1) Fixed unexpected behavior of `dvc pipeline show --dot`, that led to accidental stage file corruption; Kudos @TomHortons :tada: 
2) Updated bash/zsh completion;
3) Switched from python2 to python3.7 when building our binary packages;
4) Added support for `-R|--recursive` flag for `dvc repro`; Kudos @prihoda :tada: 
5) Temporarily rolled back cache dir optimization to a more robust but slower cache verification logic. The new optimization is coming soon;
",83878269
1424,False,False,2019-05-20T17:28:02Z,2019-05-20T17:28:25Z,"1) [Fixed bug on windows that prevented users from using external cache directory on a different drive](https://github.com/iterative/dvc/issues/1976)
2) [Fixed bug in reporting errors during uploading to ssh](https://github.com/iterative/dvc/issues/1996); Kudos @kurianbenoy 
3) [Fixed urlib3 dependency issue](https://github.com/iterative/dvc/issues/2008)",83878269
1425,False,False,2019-05-13T20:38:12Z,2019-05-13T20:42:13Z,"1) [Removed duplicate of `dvc add` help from `dvc --help`](https://github.com/iterative/dvc/issues/1987);
2) [Fixed a bug that didn't allow `dvc import` to work with https urls](https://github.com/iterative/dvc/issues/1988);
3) [Optimized `dvc checkout` to save checksums for created workspace files without checksum re-calculation](https://github.com/iterative/dvc/issues/1991);",83878269
1426,False,False,2019-05-11T21:01:01Z,2019-05-11T21:01:36Z,1) Fix install requirements in setup.py;,83878269
1427,False,False,2019-05-11T18:55:22Z,2019-05-11T18:56:34Z,"1) [Fixed README formatting](https://github.com/iterative/dvc/pull/1879); Kudos @maggyero;
2) [Switched to using `reflink, copy` as default cache links to provide the most user-friendly experience](https://github.com/iterative/dvc/pull/1841);
3) [Introduced initial implementation for `.dvcignore`, that allows specifying which directories dvc should skip while looking for dvc files](https://github.com/iterative/dvc/pull/1820);
4) [Fixed the bug with etag corrupting for external outputs on s3 that were uploaded as multipart objects](https://github.com/iterative/dvc/pull/1867); Kudos @olveirap;
5) [Introduced `-l|--locked` option for `dvc pipeline show` to show locked dvc stages](https://github.com/iterative/dvc/pull/1882); Kudos @rpip;
6) [Added support for `-f|--file` option for `dvc import` that lets you specify dvc file name that this stage is going to be saved to](https://github.com/iterative/dvc/pull/1895); Kudos @vyloy;
7) [DVC no longer removes comments from dvc files](https://github.com/iterative/dvc/pull/1885); Kudos @Suor
8) [Started using mock-ssh to test ssh remotes](https://github.com/iterative/dvc/pull/1908); Kudos @ag613915cao
9) [Added `meta` field into dvc files, that can be used for arbitrary user-defined data](https://github.com/iterative/dvc/pull/1903); Kudos @Suor
10) [Fixed the bug in `dvc metrics` that was not able to access dvc files if command wasn’t run from repo root](https://github.com/iterative/dvc/pull/1907);
11) [Added support for ssh directories as external dependencies and outputs. Done refactoring to generalize directory-related logic for all remotes](https://github.com/iterative/dvc/pull/1892);
12) [Fixed the bug with dvc not protecting files that were added again](https://github.com/iterative/dvc/pull/1925);
13) [Invalidate build cache for persistent outputs](https://github.com/iterative/dvc/pull/1877);
14) [Implemented `--downstream` option for `dvc repro`](https://github.com/iterative/dvc/pull/1926);
15) [Cleanup temporary test dirs](https://github.com/iterative/dvc/pull/1904); Kudos @Suor
16) [Enabled ssh tests on windows](https://github.com/iterative/dvc/pull/1911); Kudos @ag613915cao
17) [Warn about slow links](https://github.com/iterative/dvc/pull/1914);
18) [Switched to a more feature-rich jsonpath-ng for `dvc metrics show`](https://github.com/iterative/dvc/pull/1944); Kudos @brbarkley
19) [Fix the bug in `dvc metrics show`, where it would raise an exception if it didn’t find a metric file on some branch](https://github.com/iterative/dvc/pull/1937);
20) [Stop duplicating `metrics` tests](https://github.com/iterative/dvc/pull/1948); Kudos @Suor
21) [Show a warning if user is trying to recursively add a large directory instead of adding it as a whole](https://github.com/iterative/dvc/pull/1935);
22) [Optimized `status` calculation on `pull`](https://github.com/iterative/dvc/pull/1950);
23) [Added `pre-push` git hook, that calls `dvc push`](https://github.com/iterative/dvc/pull/1951);
24) [Fix `dvc metrics show` bug on systems with non-unicode locales set](https://github.com/iterative/dvc/pull/1956);
25) [Skip ignored tests instead of making them appear like they’ve passed](https://github.com/iterative/dvc/pull/1962); Kudos @Suor;
26) [Added support for `~/.ssh/config`](https://github.com/iterative/dvc/pull/1965); Kudos @khamutov
27) [Fixed README formatting](https://github.com/iterative/dvc/pull/1966); Kudos @msaroufim
28) [Added support for Alibaba Cloud](https://github.com/iterative/dvc/pull/1961); Kudos @nanaya-tachibana
29) [Introduced `dvc version` command](https://github.com/iterative/dvc/pull/1963); Kudos @algomaster99
30) [Shortened commit hashes in `dvc diff` output](https://github.com/iterative/dvc/pull/1906); Kudos @jorgeorpinel
31) [Append to git hook if it already exists](https://github.com/iterative/dvc/pull/1980);
32) [Optimized status calculation for remotes](https://github.com/iterative/dvc/pull/1981);
33) [Replaced dict path_info-s with proper classes that are able to print a nice looking url](https://github.com/iterative/dvc/pull/1968)",83878269
1428,False,False,2019-04-11T15:12:13Z,2019-04-11T15:12:29Z,"1) [Fix bugs in dynamic dvc version generation;](https://github.com/iterative/dvc/issues/1866)
2) [Fix improper exception logging bug;](https://github.com/iterative/dvc/issues/1869)
3) [Deprecated `dvc run --remove-outs`;](https://github.com/iterative/dvc/issues/1853)",83878269
1429,False,False,2019-04-09T20:28:01Z,2019-04-09T20:29:33Z,1) [Fix bug in error handling on failed `dvc repro`;](https://github.com/iterative/dvc/issues/1858) ,83878269
1430,False,False,2019-04-09T13:49:14Z,2019-04-09T13:49:48Z,"1) Add a temporary fix for osx binary packages;
2) [Support defining remotes through other remotes;](https://github.com/iterative/dvc/issues/1614)",83878269
1431,False,True,2019-04-09T12:01:35Z,2019-04-09T12:02:34Z,1) [Fix bug where `dvc checkout/remove` were not able to handle broken symlinks;](https://github.com/iterative/dvc/issues/1856),83878269
1432,False,False,2019-04-08T12:46:31Z,2019-04-08T12:46:54Z,"1) [Introduced `dvc diff` command. Kudos @django-kz :medal_sports: !](https://github.com/iterative/dvc/pull/1778)
2) [Fixed bug in stage file generation for external ouputs;](https://github.com/iterative/dvc/pull/1837)
3) [Fixed bug in dynamic version generation for our pip packages;](https://github.com/iterative/dvc/issues/1824)
4) [Refactored dvc logging to be more pythonic;](https://github.com/iterative/dvc/issues/1753)
5) [Refactored log capturing in our tests to use pytest's caplog;](https://github.com/iterative/dvc/issues/1797)
6) [Added `python_requires` and version classifiers to our pip package; Kudos @hugovk :medal_sports: !](https://github.com/iterative/dvc/pull/1845)
7) [Dropped support for Python 3.4 due to it reaching EOL; Kudos @hugovk :medal_sports: !](https://github.com/iterative/dvc/pull/1847)
8) [Fixed bug in our daemon worker that was spawning processes recursively;](https://github.com/iterative/dvc/issues/1803)

Welcome new contributors @django-kz and @hugovk ! :tada: :tada: :tada: ",83878269
1433,False,False,2019-04-04T14:23:42Z,2019-04-04T14:25:19Z,1) [Fix the bug with improper stage md5 calculation caused by not excluded `persist` field](https://github.com/iterative/dvc/issues/1828);,83878269
1434,False,False,2019-04-03T19:36:39Z,2019-04-03T19:37:56Z,"1) [Fix bug in binary dvc packages, where google-cloud-storage wasn't included](https://github.com/iterative/dvc/issues/1697);",83878269
1435,False,False,2019-04-02T21:06:37Z,2019-04-02T21:08:14Z,"1) [`dvc metrics show` now nicely formats multiline metrics files like tsv/htsv, csv/hcsv, json](https://github.com/iterative/dvc/issues/1716); Kudos @mroutis :medal_sports: 
2) [`dvc remote add` no longer silently overwrites existing sections](https://github.com/iterative/dvc/issues/1760);
3) [Use a workaround to bypass SIP protection on osx, when accessing libSystem](https://github.com/iterative/dvc/issues/1515);
4) [Don't try to create existing container on azure](https://github.com/iterative/dvc/issues/1811); Kudos @AmitAronovitch :medal_sports: 
5) Dvc repository now uses read-only http remote for our images instead of s3;
6) Fix bug in `dvc status` where an error is raised if cache is not present locally nor on the remote;
7) [Fix progress bar on `dvc pull`](https://github.com/iterative/dvc/issues/1807); Kudos @pared :medal_sports: 
8) [Automatically detect metrics file type by extension](https://github.com/iterative/dvc/issues/1553); Kudos @cand126 :medal_sports: 

Welcome new contributor @AmitAronovitch ! :tada: ",83878269
1436,False,False,2019-03-29T19:51:58Z,2019-03-29T19:52:35Z,"1) [Fix color codes on Windows](https://github.com/iterative/dvc/issues/1698);
2) Migrated from nose to pytest;
3) [Started using progress bar for checkout instead of verbose info messages](https://github.com/iterative/dvc/issues/1643);
4) [Refactored brancher](https://github.com/iterative/dvc/pull/1709);
5) [Updated *sh completion](https://github.com/iterative/dvc/issues/1732);
6) [Increased verbosity of dvc info messages](https://github.com/iterative/dvc/issues/1735) Kudos @PeterFogh 🏅  ;
7) [Added support for `dvc pipeline show --tree`](https://github.com/iterative/dvc.org/issues/219) Kudos @puhoshville 🏅 ;
8) [Fixed not working metrics show in `dvc repro -m`](https://github.com/iterative/dvc/issues/1740);
9) [Fixed link removal bug in `dvc checkout/pull`](https://github.com/iterative/dvc/issues/1788);
10) [Improved `dvc cmd --help` by including links to documentation](https://github.com/iterative/dvc/pull/1767) Kudos @J0 🏅 ;

Welcome new contributors @PeterFogh @J0 @puhoshville ! 🚀 ",83878269
1437,False,False,2019-03-14T21:00:47Z,2019-03-14T21:01:43Z,1) [Fix bug where wdir was not converted to unixpath when saved to a dvc file](https://github.com/iterative/dvc/issues/1721);,83878269
1438,False,False,2019-03-14T14:15:40Z,2019-03-14T14:18:00Z,"1) Warn when there is no cache locally or on the remote;
2) Fix NotDvcRepoError message;
3) Ignore cryptography's warnings caused by paramiko;
4) Fix posixpath/ntpath mixup in ssh remote driver on windows;",83878269
1439,False,False,2019-03-13T13:24:13Z,2019-03-13T13:26:42Z,"1) Support choosing between `list_objects` and `list_objects_v2` for s3 remote using `listobjects` config option;
2) Use decorator for cleaning up gitignore on error and reminding to add to git;
3) Fix bug in dvc state where inode wasn't converted to sqlite format  properly;",83878269
1440,False,True,2019-03-10T14:56:22Z,2019-03-10T14:59:26Z,"1) Fix the message for dvc file formatting error;
2) Support `-f|--file` for `dvc add`;
3) Fix bug in ssh remote driver on windows;",83878269
1441,False,False,2019-03-03T03:07:29Z,2019-03-03T03:08:13Z,1) Fix stage checksum calculation when `wdir` is default;,83878269
1442,False,False,2019-03-01T19:26:42Z,2019-03-01T20:41:18Z,"1) Multiple test improvements;
2) Fix a bug in `dvc repro`, when callback stages were not reproduced and instead a build cache was used;
3) `dvc status` with `--remote` now implies `--cloud`;
4) Raise exception when output/dependency doesn't exist. Previously this was handled properly only for local outputs/dependencies;
5) Use temporary file as an intermediary step when uploading to ssh remote to prevent cache corruption;
6) Use cache directory mtime/inode/size to do cache validation faster;
7) Support `dvc run --wdir` as a way to run dvc file command from a directory that doesn't match dvc file location;
8) Gracefully handle a case when a progress bar is interrupted with a prompt;
9) Support `dvc add` for symlinks that point to a location within or outside the current project;
10) Multiple code refactorings;",83878269
1443,False,False,2019-02-19T19:44:01Z,2019-02-19T19:49:50Z,"1) Use sftp for push/pull/status instead of full ssh;
2) Fix types in `dvc metrics`;
3) Fix `dvc move` bug with improper stage file resolving;
4) Fix a bug in external outputs caching, where we didn't check if cache already exists;",83878269
1444,False,False,2019-02-18T02:16:56Z,2019-02-18T02:18:01Z,1) Fix bug in updating state db for cache and link during `dvc add`;,83878269
1445,False,False,2019-02-17T13:11:26Z,2019-02-17T13:15:07Z,"1) Add md5 entries for cache and link to state db during `dvc add` so that sequential commands don't have to recompute checksums for it;
2) Improve `dvc status` output;
3) Introduce `dvc commit` command along with `--no-commit` flags for `run/add/repro`;",83878269
1446,False,False,2019-02-16T07:28:36Z,2019-02-16T07:30:07Z,"1) Fix metrics handling for directories;
2) Fix url parsing for ssh remote;
3) Fix `dvc repro --ignore-build-cache` logic;
4) Optimize imports in dvc;",83878269
1447,False,False,2019-02-12T03:03:39Z,2019-02-12T03:04:36Z,1) Fix metrics show all braches/tags behavior when target is not specified;,83878269
1448,False,False,2019-02-11T23:51:25Z,2019-02-11T23:52:15Z,1) Fix updater bug on python2;,83878269
1449,False,False,2019-02-10T19:51:16Z,2019-02-10T19:52:03Z,1) Add support for cached metrics `-m` to `dvc run`;,83878269
1450,False,False,2019-02-09T19:07:57Z,2019-02-09T19:09:10Z,1) Fix pkb build in environments without gitpython;,83878269
1451,False,False,2019-02-09T05:31:59Z,2019-02-09T05:40:51Z,1) Fix build issue on py2 on windows;,83878269
1452,False,True,2019-02-09T02:17:56Z,2019-02-09T02:18:43Z,1) py2: fix unicode issue when working with os.environ.,83878269
1453,False,True,2019-02-09T01:06:18Z,2019-02-09T01:06:49Z,1) Fix pyenv issue on travis;,83878269
1454,False,True,2019-02-08T08:32:19Z,2019-02-08T08:35:56Z,"1) Improve unicode support;
2) Status now returns non-zero code in `-q|--quiet` mode to reflect whether or not the pipeline is up-to-date;
3) Added support for `Content-Md5` as an `ETag` alternative in http(s) remote driver;
4) Unified coding style by using ""black"" tool;
5) Implemented `-R|--recursive` support for `dvc metrics show`; Kudos @tdeboissiere ;
6) `dvc import` now supports `--resume` option to resume downloading if previous download failed;
7) Added support for `credentialpath`(aka `GOOGLE_APPLICATION_CREDENTIALS`) to gs remote driver;
8) `dvc checkout` now suggests `git checkout` just in case user mixed the two and tried to run `dvc checkout <branch>`; Kudos @mhham ;
9) Fix bug in `dvc add` that would throw an error if you try to call it twice in a row on the same file;",83878269
1455,False,False,2019-01-26T12:53:58Z,2019-01-26T13:04:51Z,"1) Don't forget to set projectname when connecting to a Google Storage Cloud remote;
2) Use PYTHONPATH when launching analytics worker;
3) Improve `dvc move` help message;",83878269
1456,False,False,2019-01-24T16:14:57Z,2019-01-24T16:15:38Z,1) Fixed a typo in RemoteBase class;,83878269
1457,False,False,2019-01-24T15:36:49Z,2019-01-24T15:38:48Z,1) Fix bug in the improper md5 computation for dvc files;,83878269
1458,False,False,2019-01-23T22:21:48Z,2019-01-23T22:22:48Z,"1) Refactored logging subsystem;
2) Improved `dvc init` messages;
3) Supported `remote://` syntax for local remotes;
4) Supported relative paths for local remotes;
5) Introduced `dvc cache` command;
6) `dvc push/pull/etc` are now throwing a warning when stages are not up to date;
7) Refactored deps/outs classes;
8) Supported specifying port in the url for ssh remote;
9) Fixed the bug with improper command escaping on `dvc run`;
10) Refactored remote classes;
11) Supported recursive push/pull/etc;
12) Fixed the bug with improper path resolution when `dvc move` receives a file name with a suffix.
13) Fixed the bug with improper file/directory size cast in our state database;
14) Fixed the bug with improper file size calculation;
15) Refactored `dvc import` error message;
16) Fixed the bug with dvc file not being moved on `dvc move`;
17) Made first iterations to comply with pylint;
18) Introduced another level of the build cache, that will checkout files instead of running the command on `dvc run`, if it detects that this stage has been ran already;
19) Fixed the bug with improper directory path handling in `dvc move`;
20) Fixed the bug with cyclic dependencies in a DAG of a project, as well as introduced additional levels of checks to prevent that from happening;
",83878269
1459,False,False,2018-12-24T16:39:59Z,2018-12-24T16:56:36Z,Fix deb/rpm issue with a missing symlink;,83878269
1460,False,True,2018-12-24T06:56:23Z,2018-12-24T06:57:25Z,Fix improper symlink resolving when generating a binary package for osx;,83878269
1461,False,True,2018-12-24T03:13:46Z,2018-12-24T03:14:36Z,"1) Fix duplicated logs;
2) Enable flake8 checks for tests;
3) Add file completion for `dvc add` command for bash/zsh;
4) Fix `dvc run` description;
5) Speedup logger by shortcutting it in non-verbose mode;
6) Mention `private key` in ssh password prompt;
7) Add option to disable ssl in for s3 remotes;
8) Prevent argument duplication with deps/outs in `dvc run`;
9) Introduce `--ignore-build-cache`;
10) Introduce `dvc remote default` command;
11) Support prefix for azure remotes;
12) Fix scheme detection for local outputs/deps with colons in names;
13) Optimize dir cache collection;
14) Fix `--all-pipelines` option for `dvc repro`;
15) Save file size in state db to help detect changes on filesystems with low mtime resolution;
16) Fix daemon when running in binary mode;
17) Use nice urls for analytics/updater endpoints;
18) Various RFC improvements;",83878269
1462,False,False,2018-12-05T05:38:57Z,2018-12-05T05:39:49Z,"1) Support global and system configs;
2) Optimize imports to decrease dvc startup time;
3) Handle KeyboardInterrupt gracefully;
4) Don't re-run the command, if dvc file for it already exists and didn't change; Kudos @vernt ;
5) Fix bug in dvc status for external outputs;
6) Introduce dvc run --overwrite-dvcfile;
7) Introduce dvc run --ignore-build-cache;
8) Introduce dvc run --remove-outs;
9) Unprotect outputs on dvc run by default;
10) Don't copy files when unprotecting data, if it is a copy or a reflink;
11) Use md5 instead of ETag for external outputs/dependencies in Google Cloud Storage remote;
12) Fix double logging issue in tests;",83878269
1463,False,False,2018-11-30T23:48:35Z,2018-11-30T23:54:48Z,"1) Respect the `-q|--quiet` option in progress bar and update msg;
2) Verify that `-c|--cwd` is not pointing to a directory that is an output of another stage;
3) Fix error message in `dvc lock` command;
4) Don't report locked callback stages as changed;
5) Exclude `locked` and `metrics` keys when computing md5 for a dvc file;
6) Use quotes to wrap arguments with spaces in a command supplied to `dvc run`;
7) Load default cloud dynamically;",83878269
1464,False,False,2018-11-28T21:39:21Z,2018-11-28T21:43:57Z,"1) Auto-detect output name for `dvc import URL`;
2) Properly handle non-existing files in `dvc checkout`;",83878269
1465,False,False,2018-11-27T07:42:49Z,2018-11-27T07:43:27Z,"1) Fix bug in update checks; Kudos @pared ;
",83878269
1466,False,False,2018-11-26T20:02:34Z,2018-11-26T20:04:28Z,"1) Allow non-existing files as targets for `dvc metrics add`;
2) Support HTTP(s) as external dependency and remote(pull/fetch/status only);
3) Fix bug in `dvc checkout` confirmation prompt;",83878269
1467,False,False,2018-11-24T11:53:02Z,2018-11-24T11:54:04Z,1) Support `dvc status --with-deps`;,83878269
1468,False,False,2018-11-23T03:00:22Z,2018-11-23T03:01:59Z,1) Fix bug in interactive mode for `dvc pipeline show --ascii` on Windows;,83878269
1469,False,False,2018-11-20T10:30:25Z,2018-11-20T10:31:14Z,"1) Add welcome message for `dvc init`;
2) Fix `dvc pull --force`;",83878269
1470,False,False,2018-11-18T18:22:36Z,2018-11-18T19:10:37Z,"1) Spawn background process to fetch updates;
2) Ask user for confirmation when deleting files on checkout;
3) Bug fixes;",83878269
1471,False,False,2018-11-15T11:55:48Z,2018-11-15T17:24:37Z,"1) Checkout no longer removes the whole directory, and checks individual files instead;
2) Automatically ignoring temporary state files;
3) Increase state db size limit from 10M to 100M entries;",83878269
1472,False,False,2018-11-11T21:12:08Z,2018-11-11T21:14:18Z,"1) Warn if user is using fish shell;
2) Show progress bar when linking large dirs;
3) Add workaround for VACUUM bug in sqlite on python 3.6 and 3.7;",83878269
1473,False,False,2018-11-08T12:45:44Z,2018-11-08T12:49:56Z,"1) Added ability to collect garbage in several projects using `dvc gc -p`. Kudos @ynop ;
2) Introduced `dvc pipeline list` command to list all the pipelines in the project;
3) Added custom update instructions depending on detected environment;
4) AWS s3 remote driver now uses default boto3 session and supports IAM roles;",83878269
1474,False,False,2018-11-06T15:39:57Z,2018-11-06T17:22:34Z,"1) Add confirmation prompt for `dvc remove -p`;
2) Make `-q` and `-v` mutually exclusive in CLI;
3) Don't forget about not cached outputs when checking for cycle dependencies;
4) Fix BaseSCM in no-scm scenario;
5) Make updater message more noticeable;
6) Fix bug in logger, where errors were printed to stdout instead of stderr;
7) Add `dvc gc` support for Azure remote;
8) Support `-d|--with-deps` for `dvc checkout`;",83878269
1475,False,False,2018-10-27T07:32:35Z,2018-10-27T07:35:15Z,"1) Check for circular dependencies;
2) Don't use dvc lock on `dvc root` command;
3) Check that `--cwd` is inside the project;
4) Fix `dvc run` bug on cygwin;
5) Introduce optional protected mode;
",83878269
1476,False,False,2018-10-23T00:13:54Z,2018-10-23T00:14:01Z,1) Fix bug in non-captured symlink/hardlink exception;,83878269
1477,False,False,2018-10-21T22:38:21Z,2018-10-21T22:40:04Z,"1) Fix bug in --all-tags and --all-branches not working together;
2) Fix bug in hardlink method on windows;
3) Don't create links for empty files;
4) Add pre-checkout hook that will call `dvc status`;",83878269
1478,False,False,2018-10-19T20:34:16Z,2018-10-19T20:41:33Z,"1) Fix bug in progress bar overlay;
2) Properly check requirements for remotes when dvc is using legacy config;
3) Fix bug in download/upload methods for remotes when operation fails for a single file;
4) Add a workaround for bug in os.stat() where st_ino is cast to signed integer instead of unsigned;",83878269
1479,False,False,2018-10-16T02:27:56Z,2018-10-16T02:30:54Z,"1) Bash and Zsh completion. Kudos @mroutis ;
2) Use `dvc-test` prefix in test dirs;
3) Check if cache inside directory has changed;
4) Use int64 to store uint64 to workaround sqlite limitation;",83878269
1480,False,False,2018-10-12T12:58:39Z,2018-10-12T12:59:38Z,1) Fix bug in getdirinfo() on Windows. Kudos @amjadsaadeh;,83878269
1481,False,False,2018-10-12T01:22:26Z,2018-10-12T01:23:29Z,"1) Import asciimatics only when needed;
2) Fix bug in state database where inode didn't fit into INTEGER PRIMARY KEY column;",83878269
1482,False,False,2018-10-11T13:11:17Z,2018-10-11T13:11:23Z,"1) `dvc repro` now shows which dependencies have changed;
2) Fix reflink on Darwin;",83878269
1483,False,False,2018-10-09T18:01:17Z,2018-10-09T18:06:03Z,"1) Add confirmation prompt for garbage collector;
2) Fix StageFileFormatError exception message;
3) Update networkx version requirements;
4) Use asccimatics to provide scrollable graphs for `dvc pipeline show --ascii`;
5) Stop using ntfsutils module;
6) Fix coverage uploading for codecov;
7) Don't use close_fds on windows in hdfs driver;",83878269
1484,False,False,2018-10-01T18:35:42Z,2018-10-01T18:36:55Z,"1) Fix env vars for the s3 remote;
2) Improve test coverage;",83878269
1485,False,False,2018-10-01T12:47:20Z,2018-10-01T13:12:28Z,"1) Introduce `-T|--all-tags` option;
2) Introduce per-remote `--jobs` default;",83878269
1486,False,False,2018-09-29T20:06:51Z,2018-09-29T20:09:53Z,"1) Support env variables for s3 remote;
2) Introduce `-P|--all-pipelines` for `dvc repro`;
3) Check for updates once a day instead of once a week;
4) More verbose output;
5) Added state file version check;
6) Abandoned asciicanvas package; ",83878269
1487,False,False,2018-09-28T08:05:52Z,2018-09-28T08:06:42Z,1) Fix bug in error reporting in `dvc move` command;,83878269
1488,False,False,2018-09-27T05:58:36Z,2018-09-27T06:01:27Z,"1) Introduced `--dot` option for `dvc pipeline show` that will output the pipeline in a dot format, that can be then rendered with graphviz. Kudos @pared .
2) Fix bug in ssh remote driver where it would as several times for password when performing `dvd pull`;
3) Add a note about default behavior to `dvc remove` help message;
4) Removed unused code;",83878269
1489,False,False,2018-09-23T11:46:36Z,2018-09-23T11:47:15Z,"1) Updater README links;
2) Updated requirements for pip;
3) Replaced cffi with ctypes;",83878269
1490,False,False,2018-09-22T11:53:30Z,2018-09-22T12:00:38Z,"1) Stopped using pyreflink module due to maintainer's unresponsiveness;
2) Now building osx packages on OS X 10.11 in order to provide forward compatibility;",83878269
1491,False,False,2018-09-21T08:09:00Z,2018-09-21T08:09:55Z,"1) State file now uses sqlite database instead of json file;
2) Introduced configurable limits for state file size;
3) Introduced configurable cleanup quotas for state file;
4) Fixed bug in `dvc repro --dry` where it was checking for missing dependencies;
5) Fixed bug in `dvc run` where it was producing empty dvc files when ran without arguments;
6) State and link state files are now combined into single `.dvc/state`;
7) Fixed bug in dvc where it was scanning unnecessary directories looking for dvc files;
8) Fixed bug in `dvc run` where it was allowing to specify `-f` with subdirectories, causing following `dvc repro` to fail;
9) DVC now lists files that it has changed and tells that they could be added with git;
10) Added ability to configure password for SSH remote;
11) Introduced `-p|--pipeline` option for `dvc repro` to reproduce the whole pipeline that the specified dvc file belongs to;
12) Fixed bug in ssh remote driver where it was hanging if there were too much files on the remote;
13) Support git submodules; Kudos @jeepkd;
14) Introduce `-d|--with-deps` option for `dvc pull/push/fetch/status`;
15) Fixed bug in `pull/push` progress bar where it was showing improperly joined paths on windows;
",83878269
1492,False,False,2018-09-10T12:57:24Z,2018-09-10T12:59:44Z,"1) Fix recv() bug in ssh remote;
2) Fix bug with deps that don't exist;",83878269
1493,False,False,2018-09-08T18:39:20Z,2018-09-08T18:40:23Z,"1) Add ability to configure timeout for ssh remote;
2) Properly handle io when executing commands on the remote host through ssh;",83878269
1494,False,False,2018-09-05T14:12:19Z,2018-09-05T14:19:49Z,1) Lower thread number multiplier for pull/push/fetch;,83878269
1495,False,False,2018-09-04T16:30:28Z,2018-09-04T16:32:11Z,"1) Limit state db size;
2) Limit size of the files state for which is going to be cached in the state db/file;
3) Speedup state db dump() speed x10 by using json.dumps() instead of json.dump();",83878269
1496,False,False,2018-09-02T21:21:23Z,2018-09-02T21:23:01Z,"1) Fixed bug in effective mtime calculation for dir trees;
2) Fixed bug in state dump when calculating checksum for directories;",83878269
1497,False,False,2018-08-31T02:09:32Z,2018-08-31T02:10:02Z,1) Fix `dvc remote remove`;,83878269
1498,False,False,2018-08-29T21:51:45Z,2018-08-29T21:52:53Z,"1) Fix README.rst formatting on pypi;
2) Add `-y|--yes` option for `dvc run`;",83878269
1499,False,False,2018-08-29T16:32:55Z,2018-08-29T16:34:01Z,1) Fix mtime computation for directories;,83878269
1500,False,False,2018-08-29T13:01:28Z,2018-08-29T13:02:38Z,"1) Fix test for changed data in a dir;
2) Fix bug in remote config;",83878269
1501,False,False,2018-08-29T11:02:31Z,2018-08-29T11:05:51Z,"1) Properly merge config with local config;
2) Recursively compute mtime for the directory;",83878269
1502,False,False,2018-08-28T10:05:36Z,2018-08-28T10:06:18Z,1) Fix `pipeline show` bug on empty pipelines;,83878269
1503,False,False,2018-08-27T14:51:09Z,2018-08-27T14:53:11Z,"1) Check that stage file name is `Dvcfile` or ends with `.dvc`;
2) Print a message when pipeline is up to date for `dvc repro`;
3) Add ability to configure ssh port;
4) Add ability to configure ssh key file;
5) Fix cornercases for `pipeline show`;",83878269
1504,False,False,2018-08-24T12:54:04Z,2018-08-24T12:54:44Z,1) Fix 'status' bug for s3 remote;,83878269
1505,False,False,2018-08-23T10:14:50Z,2018-08-23T10:16:01Z,"1) Fix help message for `pipeline show` and `repro` when no dvc file is specified;
2) Fix an issue with s3 credentials;
3) Improve code coverage;",83878269
1506,False,False,2018-08-23T01:48:45Z,2018-08-23T01:49:14Z,Fix grandalf version;,83878269
1507,False,False,2018-08-22T14:22:04Z,2018-08-22T14:23:32Z,"1) DAG visualization using ASCII rendering;
2) Introduced `--recursive` option for `dvc add`;
3) Fixed logger coloring;
4) Bug fixes;",83878269
1508,False,False,2018-08-17T11:24:42Z,2018-08-17T11:25:07Z,1. Fix improper .dvc file name when adding external local file;,83878269
1509,False,False,2018-08-14T02:12:53Z,2018-08-14T02:21:01Z,"1) Introduced `--dry` option for `dvc repro` that only prints commands without actually executing;
2) Intrudced `-i|--interactive` option for `dvc repro` that reproduces stages in interactive mode, asking user for confirmation. Also introduced `core.interactive` option for the config to make it default behaviour;
3) Optimizations for remote dependencies/outputs;
4) Multiple UX improvements;
5) Bug fixes;",83878269
1510,False,False,2018-08-07T03:02:08Z,2018-08-07T03:03:30Z,1. Fix error in VersionAction;,83878269
1511,False,False,2018-08-07T02:32:41Z,2018-08-07T02:33:33Z,1. Use 'extras_require' in setup.py for backward compatibility;,83878269
1512,False,False,2018-08-07T01:50:36Z,2018-08-07T01:59:10Z,"1. Fix `dvc` help output;
2. Add more verbose messages for run/add/checkout;
3. Fix LD_LIBRARY_PATH issue with binary dvc packages;
4. Fix install_requires in setup.py;",83878269
1513,False,False,2018-08-05T21:31:27Z,2018-08-05T21:32:15Z,"1. Fix dvc --version that on some versions of python prints to stderr and on some stdout;
2. Fix install requirements;",83878269
1514,False,False,2018-08-05T01:47:23Z,2018-08-05T01:50:17Z,"1. Added `--dry` and `-i|--iterative` for `dvc repro`;
2. Added confirmation prompt for overwriting dvc files with `dvc run`;
3. Fixed README formatting;
4. Fixed `dvc` and `dvc -h` formatting;
5. Improved test coverage;",83878269
1515,False,False,2018-08-03T19:43:18Z,2018-08-03T19:43:52Z,Fixed pypi issue with futures.,83878269
1516,False,False,2018-08-03T18:35:44Z,2018-08-03T18:37:12Z,"1. Added additional progress info/bar for long running operations such as computing md5 for a large file or directory;
2. Fixed python runtime requirements;
3. Fixed links/logos in README;",83878269
1517,False,False,2018-08-01T21:39:45Z,2018-08-01T21:40:09Z,1) Fix README.rst formatting;,83878269
1518,False,False,2018-07-25T17:23:22Z,2018-07-25T17:25:12Z,"1. Fixed bug on Python 3.7;
2. Fixed coding style errors detected by flake8;
3. Fixed bug in `dvc push/pull/fetch` where `-a|--all-branches` argument didn't have any effect;",83878269
1519,False,False,2018-07-24T12:46:46Z,2018-07-24T13:03:51Z,"1. Bug fix for improper .dvc file resolution of `dvc add`;
2. Bug fix for os-dependent dir cache files;",83878269
1520,False,False,2018-07-23T19:42:22Z,2018-07-23T19:46:02Z,"1. Fixed bug in `dvc metrics show` when file is explicitly specified;
2. Fixed bug in _find_root() when dvc didn't check if the mount point itself was a dvc repository. Kudos @hfchong ;
3. Fixed bug in updater where there was no get() timeout;",83878269
1521,False,False,2018-07-20T15:51:27Z,2018-07-20T16:02:42Z,"1. Bug fixes for Amazon S3 driver;
2. Bug fix for `dvc status` warning for locked stages;
3. Improved test coverage;",83878269
1522,False,False,2018-07-19T09:43:28Z,2018-07-19T09:45:22Z,"1. Performance improvements.
2. Added support for CSV and Headed CSV(HCSV) to `dvc metrics`.
3. Improved test coverage.",83878269
1523,False,False,2018-07-17T13:26:22Z,2018-07-17T13:27:51Z,"1. Commands such as `dvc status\fetch\pull\push` now take into account locked stages.
2. Support `dvc add` for external files(e.g. `dvc add s3://mybucket/myfile.txt`).
3. Support `dvc import` for external outputs(e.g. `dvc import s3://mybucket/file.txt s3://mybucket/myworkdir/file.txt`).
4. Added `dvc destroy` to delete DVC from the repository.
5. Bug fixes.",83878269
1524,False,False,2018-07-14T15:00:05Z,2018-07-14T15:02:26Z,"1. Added `dvc pipeline show` for showning pipeline stages for target stage.
2. Bug fixes for our tests.",83878269
1525,False,False,2018-07-12T07:41:34Z,2018-07-12T07:50:12Z,"1. Added support for Microsoft Azure Blob Storage. Kudos @c-w and @EricSchles.
2. Fixed a bug with non-deterministic md5 computation for directories.
3. Added support for dvc gc -c|--cloud to collect remote garbage.",83878269
1526,False,False,2018-07-07T22:13:21Z,2018-07-07T22:28:19Z,"1. Bugfix for improper usage of logger.debug() in _read_metric().
2. Bugfix for `dvc metrics show` in binary packages caused by the bug in ply module.",83878269
1527,False,False,2018-07-07T00:43:16Z,2018-07-07T00:45:00Z,"1. Bugfix for the improper comparison of versions in updater.
2. Bugfix for the output of `dvc metrics show` without `all-branches`.",83878269
1528,False,False,2018-07-06T01:56:30Z,2018-07-06T02:05:07Z,"1. Support for LOCAL/S3/GS/SSH/HDFS external dependencies, outputs and cache.
2. Misc bug fixes and performance improvements.
3. Added `-c|--cwd` option for `dvc repro` to change directory before reproduction. Similar to `make -C`.
4. Added `-p|--purge` option for `dvc remove` to remove the dvc file.
5. Introduced `dvc import` to import external files and track them as dependencies.
6. Added `-m|--metrics` option for `dvc repro` to output metrics after reproduction.
7. Added `-d|--default` option for `dvc remote add` to set remote as a default one.
8. `Data cloud` is now included into `Remote` class. All remote drivers for local/s3/gs/hdfs/ssh are now located under dvc/remote/. New remote types are easy to add.
9. Added `--all-branches` option for push/pull/fetch/gc to operate on cache for all present branches.
10. Introduced `dvc move` to allow renaming data files added with `dvc add`.
11. Introduced `dvc lock/unlock` to lock/unlock dvc files from reproduction.
12. Added support for a list of cache types. E.g. `dvc config cache.type reflink,copy`.",83878269
1529,False,False,2018-05-17T15:32:01Z,2018-05-17T15:37:56Z,"1) Bug fixes;
2) Added `dvc install` for installing git post-checkout hook;
3) Support `dvc checkout` for a single file;
4) Support for reflink/hardlink/symlink/copy types of cache links;
5) Support for configurable and shareable cache dirs;
6) Stages without dependencies are now ran by `dvc repro`;
7) Dvc now checks for updates once a week and prints a warning if newer version is available;
",83878269
1530,False,False,2018-04-20T08:23:17Z,2018-04-20T08:26:07Z,"1) Config schema verification
2) Clouds in config are replaced with remotes. Introduced special command `dvc remote` for adding/modifying/deleting remotes. `dvc push/pull/fetch/status` now accepts -r|--remote argument for specifying the particular remote repository you want to use(use `dvc config core.remote myremote` to setup default remote repo).
3) GCP cloud no longer requires ProjectName, as long as your credentials are setup correctly and `gsutil` works for you.
4) DVC version is now generated dynamically, depending on whether it is release version or from the git(e.g. dvc 0.9.5+89ed2c.mod).
5) Fixed automatic dvcfile name generation for `dvc run -o directory/`.
6) Both dvcfiles and configs are no longer written empty parameters to.
7) Test coverage increased to 91%.
8) Experimental SSH cloud support added.
9) Cloud drivers now use local state to obtain md5, instead of recomputing it every time.
10) Introduced local config(.dvc/config.local).
11) AWS cloud migrated from boto to boto3.
12) Introduces 'md5' field for dvcfiles, which allows us to detect if dvcfile itself has changed(i.e. cmd).
13) Non-binary dependencies are now converted to POSIX format(CRLF -> CR) while computing md5, so that dependencies which point to files tracked by git are now compatible on windows and *nix.
14) Introduced `dvc metrics` for reading metrics on all branches.",83878269
1531,False,False,2018-04-04T14:57:13Z,2018-04-04T14:58:25Z,Use POSIX path on windows and convert to POSIX for backward compatibility.,83878269
1532,False,False,2018-04-03T18:32:40Z,2018-04-03T18:35:37Z,"1) Fixed bug in data cloud key creation on Windows.
2) Added dynamic versions(using commit SHA) for dvc built from upstream repo.
3) Added long package description for pypi.",83878269
1533,False,False,2018-03-21T10:23:22Z,2018-03-21T10:24:25Z,Pypi package fixes.,83878269
1534,False,False,2018-03-21T08:34:11Z,2018-03-21T08:54:18Z,,83878269
1535,False,False,2017-05-04T08:03:08Z,2017-05-04T08:10:50Z,"DVC beta release.

Make your data science projects reproducible and shareable.

Includes:
- Import files, http links and drupbox links
- Command reproduction: recursion, force-reproduction
- Data synchronization: AWS S3 and GCP Storage
- Data item locks
- End-to-end machine learning tutorial: stackoverflow tag classification",83878269
1536,False,False,2020-03-12T00:13:27Z,2020-03-12T00:29:10Z,"- Change Pachyderm license from Apache 2.0 to Pachyderm Community License
- Changes to how resources are applied to pipeline containers (#4675)
- Changes to GitHook and Prometheus ports (#4537)
- Changes to handle S3 credentials passed to S3 gateway when Auth is disabled (#4585)
- Changes to add support for ‘zsh’ shell (#4494)
- Changes to allow only critical servers to startup with `--required-critical-servers-only` (#4536)
- Changes to improve job logging (#4538)
- Changes to support copying files from output repo to input repos (#4475)
- Changes to ‘flush job’ CLI to support streaming output with --raw option (#4569)
- Changes to remove cluster ID check (#4532)
- Adds annotations and labels to top-level pipeline spec (#4608) (NOTE: If your pipeline spec specifies “service.annotations”, it is recommended that you follow the upgrade path and manually update the pipelines specs to include annotations under the new metadata tag)
- Adds support for S3 inputs & outputs in pipeline specs (#4605, #4660)
- New interactive Pachyderm Shell. The shell provides an easier way to interact with pachctl, including advanced auto-completion support (#4485, #4557)
- Adds support for creating secrets through Pachyderm. (#4483)
- Adds support for disabling commit progress indicator to reduce load on etcd (#4696)
- Fixes a bug that ignored the EDITOR environment variable (#4672)
- Fixes a bug that would cause restore failures from v1.8.x version to v1.9.x+ version (#4662)
- Fixes a bug that would result in missing output data, under specific conditions, when a job resumes processing (#4656)
- Fixes a bug that caused errors when specifying a branch name as the provenance of a new commit (#4657)
- Fixes a bug that would leave a stats commit open under some failure conditions during run pipeline (#4637)
- Fixes a bug that resulted in a stuck merge process when some commits are left in an unfinished state (#4595)
- Fixes a bug that ignored the cron pipeline overwrite value when ‘run cron’ is called from the command line (#4517)
- Fixes a bug that caused `edit pipeline` command to open an empty file (#4526)
- Fixes a bug where some unfinished commit finish times displayed the Unix Epoch time. (#4539)
- Fixes a family of bugs and edge conditions with spout marker (#4487)
- Fixes a bug that would cause crash in ‘diff file’ command (#4601)
- Fixes a bug that caused a crash when `run pipeline` is executed with stats enabled (#4615)
- Fixes a bug that incorrectly skips duplicate datums in a union, under specific conditions (#4691)
- Fixes a bug that ignored the logging level set in the environment variable (#4706) 
",23653453
1537,False,False,2020-03-10T01:59:33Z,2020-03-10T02:04:10Z,Built by goxc,23653453
1538,False,False,2020-03-06T17:21:27Z,2020-03-06T17:24:50Z,Built by goxc,23653453
1539,False,False,2020-03-03T01:58:25Z,2020-03-03T02:00:40Z,Built by goxc,23653453
1540,False,False,2020-03-03T01:12:03Z,2020-03-03T01:15:45Z,Built by goxc,23653453
1541,False,False,2020-02-28T22:58:55Z,2020-02-28T23:04:15Z,Built by goxc,23653453
1542,False,False,2020-02-07T19:51:16Z,2020-02-11T01:47:41Z,Built by goxc,23653453
1543,False,False,2020-02-05T06:42:49Z,2020-02-06T23:09:51Z,Built by goxc,23653453
1544,False,False,2020-02-01T01:52:54Z,2020-02-01T03:10:17Z,"Release Notes:

- New configuration for deployments (exposed through pachctl deploy flags):
- Only require critical servers to startup and run without error (--require-critical-servers-only). (#4512)
- Improved job logging. (#4523)
- Fixes a bug where some unfinished commit finish times displayed the Unix Epoch time. (#4524)
- Fixes a bug with edit pipeline. (#4530)
- Removed cluster id check. (#4534)
- Fixes a bug with spout markers. (#4487)",23653453
1545,False,False,2020-01-30T19:51:45Z,2020-01-30T23:05:11Z,Built by goxc,23653453
1546,False,False,2020-01-30T19:51:45Z,2020-01-30T22:35:40Z,Built by goxc,23653453
1547,False,False,2020-02-07T19:51:16Z,2020-02-11T01:52:02Z,"Release notes:

- New configuration for deployments (exposed through pachctl deploy flags):
  - Object storage upload concurrency limit (--upload-concurrency-limit). (#4393)
- Various configuration improvements. (#4442)
- Fixes a bug that would cause workers to segfault. (#4459)
- Upgrades pachyderm to go 1.13.5. (#4472)
- New configuration for amazon and custom deployments (exposed through pachctl deploy amazon/custom flags):
  - Disabling ssl (--disable-ssl) (#4473)
  - Skipping certificate verification (--no-verify-ssl) (#4473)
- Further improves the logging and error reporting during pachd startup. (#4486)
- Removes pprof http server from pachd (debugging should happen through the debug api). (#4496)
- Removes k8s api access from worker code. (#4498)",23653453
1548,False,False,2020-01-09T19:53:50Z,2020-01-09T23:15:58Z,Built by goxc,23653453
1549,False,False,2019-12-20T22:40:24Z,2019-12-22T08:17:39Z,Built by goxc,23653453
1550,False,False,2020-01-30T19:51:45Z,2020-01-30T22:51:36Z,"Release notes:

- Fixes a bug that causes `pachctl` to connect to the wrong cluster (#4416)
- Fixes a bug that causes hashtree resource leak in certain conditions (#4420)
- Fixes a family of minor bugs found through static code analysis (#4410)
- Fixes a family of bugs that caused pachd panic when it processed invalid arguments (#4391)
- Fixes a family of bugs that caused deploy yaml to fail (#4290)
- Changes to use standard go modules instead of old vendor directory (#4323)
- Changes to add additional logging during pachd startup (#4447)
- Changes to CLI to add a command, `run cron <pipeline>` to manually trigger a CRON pipeline (#4419)
- Changes to improve performance of join datum processing (#4441)
- Open source Pachyderm S3 gateway to allow applications to interact with PFS storage (#4399)",23653453
1551,False,False,2019-12-20T22:40:24Z,2019-12-22T08:24:05Z,"- Adds support for spout marker to keep track of metadata during spout processing. (#4224)
- Updates GPT 2 example to use GPU. (#4325)
- Fixes a bug that did not extract all the pipeline fields (#4204)
- Fixes a bug that did not retry a previously skipped datum when pipeline specs are updated. (#4310)
- Fixes a family of bugs which failed the building of docker images with `create pipeline --build` command. (#4319)
- Fixed a bug that did not prompt users if auto-derivation of docker credentials fails. (#4319)
- Changes to track commit progress through DAG. (#4203)
- Changes to CLI syntax for `run pipeline` to accept `—job` option to re-run a job. (#4267) 
- Changes to CLI syntax for `inspect` to accept `branch` option. (#4293)
- Changes to CLI output for `list repo` and `list pipeline` to show description. (#4368)
- Changes to CLI output for `list commit` to show progress and description while removing parent and duration output. (#4368)
",23653453
1552,False,False,2019-11-19T01:17:33Z,2019-11-19T01:33:43Z,Built by goxc,23653453
1553,False,False,2019-11-19T01:17:33Z,2019-11-19T01:35:28Z,"- Fixes a bug that prevent the `--reprocess` flag in `edit pipeline` from working. (#4232)
- Changes the CLI syntax for `run pipeline` to accept commit branch pairs. (#4262)
- Fixes a bug that caused `pachctl logs --follow` to exit immediately. (#4259)
- Fixes a bug that joins to sometimes miss pairs that matched. (#4256)
- Fixes a bug that prevent pachyderm from deploying on Kuberentes 1.6 without modifying manifests. (#4242)
- Fixes a family of bugs that could cause output and stats commits to remain open and block later jobs. (#4215)",23653453
1554,False,False,2019-10-22T23:34:46Z,2019-10-22T23:49:06Z,Built by goxc,23653453
1555,False,True,2019-10-18T18:47:17Z,2019-10-18T18:54:59Z,Built by goxc,23653453
1556,False,True,2019-10-16T22:13:43Z,2019-10-16T23:23:07Z,Built by goxc,23653453
1557,False,True,2019-10-16T22:23:28Z,2019-10-16T22:54:43Z,Built by goxc,23653453
1558,False,False,2019-10-15T19:22:03Z,2019-10-15T23:10:12Z,Built by goxc,23653453
1559,False,False,2019-10-04T22:42:38Z,2019-10-04T22:46:04Z,- Fixes a bug that prevent pachctl from connecting to clusters with TLS enabled. (#4167),23653453
1560,False,False,2019-10-02T21:39:12Z,2019-10-02T21:42:46Z,"- Fixes a bug which would cause jobs to report success despite datum failures. (#4158)
- Fixes a bug which prevent Disk resource requests in pipelines from working. (#4157)
- Fixes a bug which caused `pachctl fsck --fix` to exit with an error and not complete the fix. (#4155)
- Pachctl contexts now have support for importing Kubernetes contexts. (#4152)
- Fixes a bug which caused Spouts to create invalid provenance. (#4145)
- Fixes a bug which allowed creation, but not deletion, of pipelines with invalid names. (#4133)
- Fixes a bug which caused ListTag to fail with WriteHeader already called. (#4132)
- Increases the max transaction operations and max request bytes values for etcd's deployment. (#4121)
- Fixes a bug that caused `run pipeline` to crash pachd. (#4109)
- Pachctl deploy amazon now exposes several new s3 connection options. (#4107)
- Readds the `--namespace` flag to `port forward`. (#4105)
- Removes and unused field `Batch` from the pipeline spec. (#4104)",23653453
1561,False,False,2019-09-18T18:53:46Z,2019-09-18T18:58:03Z,"- Adds support for yaml formatted pipelines specs. (#4078)
- Fixes a bug that caused the Salt field to be stripped from restored pipelines. (#4086)
- Fixes a bug that caused datums to fail with `io: read/write on closed pipe`. (#4085)
- Fixes a bug that prevented reading logs from running jobs with stats enabled. (#4083)
- Fixes a bug that prevented putting files into output commits via s3gateway. (#4076)
- Adds support for joins (#3989)",23653453
1562,False,True,2019-09-16T19:16:48Z,2019-09-17T21:18:38Z,Built by goxc,23653453
1563,False,False,2019-09-11T21:05:37Z,2019-09-12T00:48:18Z,- Fixes a bug that caused pipelines to recompute everything when they were restored. (#4079),23653453
1564,False,True,2019-09-10T18:52:01Z,2019-09-10T21:55:19Z,Built by goxc,23653453
1565,False,False,2019-09-06T18:57:26Z,2019-09-06T19:01:55Z,"- Fixes a a bug (#4053) which made it impossible to read files written to output commits with `put file`. (#4055)
- Adds a flag `--fix` to `pachctl fsck` which will fix some of the issues that it detects. (#4052)
- Fixes a bug (#3879) which caused `pachctl debug dump` to hit max message size issues. (#4015)
- The Microsoft Azure Blob Storage client has been upgraded to the most recent version. (#4000)
- Extract now correctly extracts the `pod_patch` and `pod_spec` for pipelines. (#3964, thanks to @mrene)
- S3Gateway now has support for multi-part uploads. (#3903)
- S3Gateway now has support for multi-deletes. (#4004)
- S3Geteway now has support for auth. (#3937)",23653453
1566,False,True,2019-08-13T19:43:35Z,2019-08-13T19:55:50Z,Built by goxc,23653453
1567,False,False,2019-08-07T21:24:23Z,2019-08-07T21:29:16Z,"- Fixes a bug that caused the Azure driver to lock up when there were too many active requests. (#3970)
- Increases the max message size for etcd, this should eliminate errors that would appear with large etcd requests such as those created when deleting repos and pipelines. (#3958)
- Fixes several bugs that would cause commits not to be finished when jobs encountered errors, which would lead to pipelines getting stuck. (#3951)",23653453
1568,False,False,2019-07-25T21:36:30Z,2019-07-25T22:17:04Z,"- Fixes a bug that broke Pachyderm on Openshift. (#3935, thanks to @jiangytcn)
- Fixes a bug that caused pachctl to crash when deleting a transaction while no active transaction was set. (#3929)
- Fixes a bug that broke provenance when deleting a repo or pipeline. (#3925)",23653453
1569,False,False,2019-07-18T19:25:00Z,2019-07-18T19:50:17Z,"- Pachyderm now uses go modules. (#3870)
- `pachctl diff file` now diffs content, similar to `git diff`. (#3866)
- It's now possible to create spout services as ingress endpoints. (#3829)
- Pachyderm now supports contexts as a way to access multiple clusters. (#3786)
- Fixes a bug that causes `pachctl put file --overwrite` to fail when reading from stdin. (#3882)
- Fixes a bug that caused jobs from run pipeline to succeed when they should fail. (#3872)
- Fixes a bug that caused workers to get stuck in a crashloop. (#3858)
- Fixes a bug that causes pachd to panic when a pipeline had no transform. (#3866)",23653453
1570,False,False,2019-06-12T22:50:40Z,2019-06-13T18:13:12Z,"- `pachctl` now has a new, more consistent syntax that's more inline with other container clis such as `kubectl`. (#3617)
- Pachyderm now exposes an s3 interface to the data stored in pfs. (#3411, #3432, #3508)
- Pachyderm now supports transactional PFS operations. (#3658)
- The `--history` flag has been extended to `list job` and `list pipeline` (in addition to `list file`.) (#3692)
- The ancestry syntax for accessing branches (`master^`) has been extended to include forward references i.e. `master.1`. (#3692)
- You can now define service annotations and service type in your pipeline specs. (#3755, thanks to @cfga and @DanielMorales9)
- You can now define error handlers for your pipelines. (#3611)
- Pachyderm has a new command, `fsck` which will check pfs for corruption issues. (#3691)
- Pachyderm has a new command, `run pipeline` which allows you to manually trigger a pipelined on a set of commits. (#3642)
- Commits now store the original branch that they were created on. (#3583)
- Pachyderm now exposes tracing via Jaeger. (#3541)
- Fixes several issues that could lead to object store corruption, particularly on alternative object stores. (#3797)
- Fixes several issues that could cause pipelines to get hung under heavy load. (#3788)
- Fixes an issue that caused jobs downstream from jobs that output nothing to fail. (#3787)
- Fixes a bug that prevent stats from being toggled on after a pipeline had already run. (#3744)
- Fixes a bug that caused `pachctl` to crash in `list commit`. (#3699)
- Fixes a bug that caused provenance to get corrupted on `delete commit`. (#3696)
- A few minor bugs in the output and erroring behavior of `list file` have been fixed. (#3601, #3596)
- Preflight object store tests have been revamped and their error output made less confusing. (#3592)
- A bug that causes stopping a pipeline to create a new job has been fixed. (#3585)
- Fixes a bug that caused pachd to panic if the `input` field of a pipeline was nil. (#3580)
- The performance of `list job` has been greatly improved. (#3557)
- `atom` inputs have been removed and use `pfs` inputs instead. (#3639)
- The `ADDRESS` env var for connecting to pachd has been removed, use `PACHD_ADDRESS` instead. (#3638)
",23653453
1571,False,False,2019-06-11T23:55:11Z,2019-06-12T00:04:37Z,Built by goxc,23653453
1572,False,True,2019-06-06T21:25:02Z,2019-06-11T18:25:06Z,Custom build.,23653453
1573,False,False,2019-05-30T00:40:00Z,2019-05-30T00:55:37Z,Built by goxc,23653453
1574,False,False,2019-05-28T20:59:57Z,2019-05-28T21:13:55Z,"- Make the 'put file' directory traversal change backwards compatible for legacy branches (#3707)
- Several fixes to provenance (#3734):
  - Force provenance to be transitively closed
  - Propagate all affected branches on deleteCommit
  - Fix weird two branches with one commit bugs
- Added a new fsck utility for PFS (#3734)
- Make stats somewhat toggleable (#3758)
- Example of spouts using kafka (#3752)
- Refactor/fix some of the PFS upload steps (#3750)",23653453
1575,False,False,2018-11-16T08:00:00Z,2019-05-23T17:57:53Z,Built by goxc,23653453
1576,False,False,2019-05-08T22:18:04Z,2019-05-08T22:22:03Z,Built by goxc,23653453
1577,False,False,2018-11-15T08:00:00Z,2019-05-07T17:07:11Z,Built by goxc,23653453
1578,False,False,2018-11-14T08:00:00Z,2019-05-02T06:41:02Z,Built by goxc,23653453
1579,False,True,2019-04-18T18:47:48Z,2019-04-18T21:21:48Z,Built by goxc,23653453
1580,False,False,2019-03-08T21:18:45Z,2019-03-08T21:22:39Z,"- The semantics of Cron inputs have changed slightly, each tick will now be a separate file unless the `Overwrite` flag is set to true, which will get you the old behavior. The name of the emitted file is now the timestamp that triggered the cron, rather than a static filename. Pipelines that use cron will need to be updated to work in 1.8.6. See [the docs](https://docs.pachyderm.io/en/latest/reference/pipeline_spec.html#cron-input) for more info. (#3509)
- 1.8.6 contains alpha support for a new kind of pipeline, spouts, which take no inputs and run continuously outputting (or spouting) data. Documentation and an example of spout usage will be in a future release. (#3531)
- New debug commands have been added to `pachctl` to easily profile running pachyderm clusters. They are `debug-profile` `debug-binary` and `debug-pprof`.  See the docs for these commands for more information. (#3559)
- The performance of `list-job` has been greatly improved. (#3557)
- `pachctl undeploy` now asks for confirmation in all cases. (#3535)
- Logging has been unified and made less verbose. (#3532)
- Bogus output in with `--raw` flags has been removed. (#3523, thanks to @mdaniel)
- Fixes a bug in `list-file --history` that would cause it to fail with too many files. (#3516)
- `pachctl deploy` is more liberal in what it accepts for bucket names. (#3506)
- `pachctl` now respects Kubernetes auth when port-forwarding. (#3504)
- Output repos now report non-zero sizes, the size reported is that of the HEAD commit of the master branch. (#3475)
- Pachyderm will no longer mutate custom image names when there's no registry. (#3487, thanks to @mdaniel)
- Fixes a bug that caused `pod_patch` and `pod_spec` to be reapplied over themselves. (#3484, thanks to @mdaniel)
",23653453
1581,False,True,2019-02-19T19:51:23Z,2019-02-20T22:16:11Z,Built by goxc,23653453
1582,False,False,2019-02-18T22:07:52Z,2019-02-20T01:21:49Z,"- New shuffle step which should improve the merge performance on certain workloads. (#3349)
- Changed repo size algorithm. (#3475)",23653453
1583,False,False,2019-02-12T17:37:55Z,2019-02-12T17:40:37Z,"- Azure Blob Storage block size has been changed to 4MB due to object body too large errors. (#3464)
- Fixed a bug in `--no-metrics` and `--no-port-forwarding`. (#3462)
- Fixes a bug that caused `list-job` to panic if the `Reason` field was too short. (#3453)
",23653453
1584,False,False,2019-02-07T00:39:45Z,2019-02-07T00:43:09Z,"- `--push-images` on `create-pipeline` has been replaced with `--build` which builds and pushes docker images. (#3370)
- Fixed a bug that would cause malformed config files to panic pachctl. (#3336)
- Port-forwarding will now happen automatically when commands are run. (#3340)
- Fix bug where `create-pipeline` accepts names which Kubernetes considers invalid. (#3344)
- Fix a bug where put-file would respond `master not found` for an open commit. (#3184)
- Fix a bug where jobs with stats enabled and no datums would never close their stats commit. (#3355)
- Pipelines now reject files paths with utf8 unprintable characters. (#3356)
- Fixed a bug in the Azure driver that caused it to choke on large files. (#3378)
- Fixed a bug that caused pipelines go into a loop and log a lot when they were stopped. (#3397)
- `ADDRESS` has been renamed to `PACHD_ADDRESS` to be less generic. `ADDRESS` will still work for the remainder of the 1.8.x series of releases. (#3415)
- The `pod_spec` field in pipelines has been revamped to use JSON Merge Patch (rfc7386) Additionally, a field, `pod_patch` has been added the the pipeline spec which is similar to `pod_spec` but uses JSON Patches (rfc6902) instead. (#3427)
- Pachyderm developer names should no longer appear in backtraces. (#3436)",23653453
1585,False,False,2019-01-30T22:14:57Z,2019-01-30T22:23:34Z,Built by goxc,23653453
1586,False,False,2019-01-25T21:51:20Z,2019-01-25T22:05:40Z,Built by goxc,23653453
1587,False,False,2019-01-24T23:03:48Z,2019-01-24T23:10:58Z,Built by goxc,23653453
1588,False,False,2019-01-23T22:32:42Z,2019-01-24T00:57:35Z,Built by goxc,23653453
1589,False,False,2019-01-21T16:47:28Z,2019-01-21T22:25:39Z,Built by goxc,23653453
1590,False,False,2019-01-04T22:44:51Z,2019-01-04T22:51:27Z,- Updated support for GPUs (through device plugins),23653453
1591,False,False,2018-12-19T20:27:26Z,2018-12-19T22:43:17Z,"- Adds support for viewing file history via the `--history` flag to `list-file` (#3277, #3299).
- Adds a new job state, `merging` which indicates that a job has finished processing everything and is merging the results together (#3261).
- Fixes a bug that prevented s3 `put-file` from working (#3273).
- `atom` inputs have been renamed to `pfs` inputs. They behave the same, `atom` still works but is deprecated and will be removed in 1.9.0 (#3258).
- Removed `message` and `description` from `put-file`, they don't work with the new multi `put-file` features and weren't commonly used enough to reimplement. For similar functionality use `start-commit` (#3251).
",23653453
1592,False,False,2018-12-04T02:42:01Z,2018-12-04T02:49:40Z,"- Completely rewritten hashtree backend that provides massive performance boosts.
- Single sign-on Auth via Okta.
- Support for groups and robot users.
- Support for splitting file formats with headers and footers such as SQL and CSV.",23653453
1593,False,False,2018-12-03T20:36:51Z,2018-12-03T20:55:31Z,Built by goxc,23653453
1594,False,True,2018-11-15T01:35:27Z,2018-11-15T01:48:22Z,"This RC includes most of the major feature adds of v1.8 including massive performance boosts, single sign-on Auth via Okta, and support for groups and robot users.

Features not available in this RC:
- Native SQL support with `put-file --split sql`
-  `incremental:true` in the pipeline_spec has been temporarily disabled

",23653453
1595,False,False,2018-11-14T01:46:03Z,2018-11-14T01:47:58Z,"* SAML support (with groups, if the IdP can send a user's groups in an attribute)
* Hide sensitive env vars from pipeline workers
* Expose job output commit to pipeline workers
* Documentation updates:
  * Deferring
  * SQL imports
  * `--iam-role`
* New ""lazy shuffle"" example
* Minor bug fixes and performance improvements",23653453
1596,False,False,2018-11-06T18:56:21Z,2018-11-06T19:21:05Z,Built by goxc,23653453
1597,False,False,2018-10-22T23:38:37Z,2018-10-22T23:43:56Z,Built by goxc,23653453
1598,False,False,2018-10-05T23:15:26Z,2018-10-05T23:19:41Z,"- Adds `put-file --split` support for SQL dumps. (#3064)
- Adds support for headers and footers for data types passed to `--split` such as CSV and the above mentioned SQL. (#3064)
- Adds support for accessing previous versions of pipelines using the same syntax as is used with commits. I.e. `pachctl inspect-pipeline foo^` will give the previous version of `foo`. (#3159)
- Adds support in pipelines for additional Kubernetes primitives on workers, including: node selectors, priority class and storage requests and limits. Additionally there is now a field in the pipeline spec `pod_spec` that allows you to set any field on the pod using json. (#3169)",23653453
1599,False,False,2018-09-25T01:02:26Z,2018-09-25T01:05:50Z,"- Moves garbage collection over to a bloom filter based indexing method. This greatly decreases the amount of memory that garbage collection requires, at the cost of a small probability of not deleting objects that should be. Garbage collection can be made more accurate by using more memory with the flag `--memory` passed to `pachctl garbage-collect`. (#3161)",23653453
1600,False,False,2018-09-18T18:30:41Z,2018-09-18T18:33:58Z,- Fixes multiple issues that could cause jobs to hang when they encountered intermittent errors such as network hiccups. (#3155),23653453
1601,False,False,2018-09-06T00:25:51Z,2018-09-06T18:02:31Z,- Greatly improves the performance of the pfs FUSE implementation. Performance should be close to on par with the that of `pachctl get-file`. The only trade-off is that the new implementation will use disk space to cache file contents. (#3140),23653453
1602,False,False,2018-08-21T17:42:23Z,2018-08-21T17:55:55Z,"- Pachyderm's FUSE support (`pachctl mount`) has been rewritten. (#3088)
- `put-file` requests that put files from multiple sources (`-i` or `-r`) now create a single commit. (#3118) 
- Fixes a bug that caused `put-file` to throw spurious warnings about URL formatted paths. (#3117)
- Several fixes have been made to which user code runs as to allow services such as Jupyter to work out of the box. (#3085)
- `pachctl` now has `auth set-config` and `auth get-config` commands. (#3095)",23653453
1603,False,False,2018-08-03T01:20:28Z,2018-08-03T01:23:02Z,"- Workers no longer run privileged containers. (#3031) To achieve this a few modifications had to be made to the `/pfs` directory that may impact some user code. Directories under `/pfs` are now symlinks to directories, previously they were bind-mounts (which requires that the container be privileged). Furthermore there's now a hidden directory under `/pfs` called `.scratch` which contains the directories that the symlinks under `/pfs` point to.
- The number of times datums are retries is now configurable. (#3033)
- Fixed a bug that could cause Kubernetes errors to prevent pipelines from coming up permanently. (#3043, #3005)
- Robot users can now modify admins. (#3049)
- Fixed a bug that could permanently lock robot-only admins out of the cluster. (#3050)
- Fixed a couple of bugs (#3045, #3046) that occurred when a pipeline was rapidly updated several times. (#3054)
- `restore` now propagates user credentials, allowing it to work on clusters with auth turned on. (#3057)
- Adds a `debug-dump` command which dumps running goroutines from the cluster. (#3078)
- `pachd` now prints a full goroutine dump if it encounters an error. (#3103)",23653453
1604,False,False,2018-07-05T23:30:14Z,2018-07-05T23:33:59Z,"- Fixes a bug that prevented image pull secrets from propagating through `pachctl deploy`. (#2956, thanks to @jkinkead)
- Fixes a bug that made `get-file` fail on empty files. (#2960)
- `ListFile` and `GlobFile` now return results leixcographically sorted. (#2972)
- Fixes a bug that caused `Extract` to crash. (#2973)
- Fixes a bug that caused pachd to crash when given a pipeline without a name field. (#2974)
- Adds dial options to the Go client's connect methods. (#2978)
- `pachctl get-logs` now accepts `-p` as a synonym for `--pipeline`. (#3009, special thanks to @jdelfino)
- Fixes a bug that caused connections to leak in the vault plugin. (#3016)
- Fixes a bug that caused incremental pipelines that are downstream from other pipelines to not run incrementally. (#3023)
- Updates monitoring deployments to use the latest versions of Influx, Prometheus and Grafana. (#3026)
- Fixes a bug that caused `update-pipeline` to modify jobs that had already run. (#3028)",23653453
1605,False,False,2018-05-23T20:22:56Z,2018-05-23T20:31:15Z,"- Fixes an issue that caused etcd deployment to fail when using a StatefulSet. (#2929, #2937)
- Fixes an issue that prevented pipelines from starting up. (#2949)",23653453
1606,False,False,2018-05-22T18:54:47Z,2018-05-22T19:38:41Z,"- Pachyderm now exposes metrics via Prometheus. (#2856)
- File commands now all support globbing syntax. I.e. you can do pachctl list-file ... foo/*. (#2870)
- garbage-collect is now safer and less error prone. (#2912)
- put-file no longer requires starting (or finishing) a commit. Similar to put-file -c, but serverside. (#2890)
- pachctl deploy --dry-run can now output YAML as well as JSON. Special thanks to @jkinkead. (#2872)
- Requirements on pipeline container images have been removed. (#2897)
- Pachyderm no longer requires privileged pods. (#2887)
- Fixes several issues that prevented deleting objects in degraded states. (#2912)
- Fixes bugs that could cause stats branches to not be cleaned up. (#2855)
- Fixes 2 bugs related to auth services not coming up completely. (#2843)
- Fixes a bug that prevented pachctl deploy storage amazon from working. (#2863)
- Fixes a class of bugs that occurred due to misuse of our collections package. (#2865)
- Fixes a bug that caused list-job to delete old jobs if you weren't logged in. (#2879)
- Fixes a bug that caused put-file --split to create too many goroutines. (#2906)
- Fixes a bug that prevent deploying to AWS using an IAM role. (#2913)
- Pachyderm now deploys and uses the latest version of etcd. (#2914)",23653453
1607,False,False,2018-04-19T18:27:35Z,2018-04-19T18:30:44Z,"- Introduces a new model for scaling up and down pipeline workers. [Read more](http://docs.pachyderm.io/en/latest/reference/pipeline_spec.html#standby-optional).
- It's now possible to run Pachyderm without workers needing access to the docker socket. (#2813)
- Fixes a bug that caused stats enabled pipelines to get stuck in a restart loop if they were deleted and recreated. (#2816)
- Fixes a bug that broke logging due to removing newlines between log messages. (#2852)
- Fixes a bug that caused pachd to segfault when etcd didn't come up properly. (#2840)
- Fixes a bug that would cause jobs to occasionally fail with a ""broken pipe"" error. (#2832)
- `pachctl version` now supports the `--raw` flag like other `pachctl` commands. (#2817)
- Fixes a bug that caused `max_queue_size` to be ignored in pipelines. (#2818)",23653453
1608,False,False,2018-03-27T00:55:03Z,2018-03-27T01:06:28Z,"- Implements a new algorithm for triggering jobs in response to new commits.
- Pachyderm now tracks subvenance, the inverse of provenance.
- Branches now track provenance and subvenance.
- Restrictions on delete-commit have been removed, you can now delete any commit and the DAG will repair itself appropriately.
- Pachyderm workers no longer use long running grpc requests to schedule work, they use an etcd based queue instead. This solves a number of bugs we had with larger jobs.
- You can now backup and restore you cluster with extract and restore.
- Pipelines now support timeouts, both for the job as a whole or for individual datums.
- You can now follow jobs logs with -f.
- Support for Kubernetes RBAC.
- Docker images with entrypoints can now be run, you do this by not specifying a cmd.
- Pachctl now has bash completion, including for values stored within it. (pachctl completion to install it)
- pachctl deploy now has a --namespace flag to deploy to a specific namespace.
- You can non longer commit directly to output repos, this would cause a number of problems with the internal model that were tough to recover from.",23653453
1609,False,False,2018-03-22T19:36:57Z,2018-03-22T19:37:50Z,- Fixes a bug in extract that prevented some migrations from completing.,23653453
1610,False,False,2018-03-21T20:15:14Z,2018-03-21T20:18:17Z,Built by goxc,23653453
1611,False,False,2018-03-19T20:02:27Z,2018-03-19T20:05:25Z,Built by goxc,23653453
1612,False,True,2018-03-01T22:22:24Z,2018-03-02T21:26:02Z,Built by goxc,23653453
1613,False,False,2018-02-27T18:50:45Z,2018-02-28T00:24:16Z,Built by goxc,23653453
1614,False,False,2018-02-27T23:54:08Z,2018-03-22T19:38:01Z,- Adds admin commands `extract` and `restore`.,23653453
1615,False,False,2018-02-13T21:17:17Z,2018-02-16T00:18:10Z,Built by goxc,23653453
1616,False,False,2018-01-29T23:26:28Z,2018-01-29T23:30:46Z,"- Fixed an issue that could cause output data to get doubled. (#2644)
- Fix / add filtering of jobs in `list-job` by input commits. (#2642)
- Extends bash completion to cover values as well as keywords. (#2617)
- Adds better validation of file paths. (#2627)

Special thanks to contributor @brycemcanally for his contributions to Pachyderm over this release cycle.",23653453
1617,False,False,2018-01-11T21:28:41Z,2018-01-11T21:31:54Z,"Built by goxc

Changes include:

- [Support for Google Service Accounts](https://github.com/pachyderm/pachyderm/pull/2610)
- [RBAC support](https://github.com/pachyderm/pachyderm/pull/2605)
- [Follow and tail logs](https://github.com/pachyderm/pachyderm/pull/2574)
- [Expose public IP for githook service](https://github.com/pachyderm/pachyderm/pull/2571)

Bug Fixes:

- [Handle many 100k+ files in a single commit, which allows users to more easily manage/version millions of files.](https://github.com/pachyderm/pachyderm/pull/2599)
- [Fix datum status in the UI](https://github.com/pachyderm/pachyderm/pull/2585)
",23653453
1618,False,False,2017-12-11T19:19:03Z,2017-12-11T20:08:30Z,"Built by goxc

- Users can now specify k8s resource limits on a pipeline
- Users can specify a `datum_timeout` and `job_timeout` on a pipeline
- Minio S3V2 support
- New worker model (to eliminate long running grpc calls)

",23653453
1619,False,False,2017-11-17T22:32:16Z,2017-11-17T22:53:46Z,"- Adds support for Kubernetes 1.8
- Fixes a bug that caused jobs with small numbers of datums not to use available nodes for processing. #2480.",23653453
1620,False,False,2017-11-15T19:54:45Z,2017-11-16T18:32:24Z,Built by goxc,23653453
1621,False,False,2017-10-26T19:36:31Z,2017-10-26T19:40:49Z,"- Fixes a bug that corrupted large files ingressed from object stores. #2405 
- Fixes a migration bug that could get pipelines stuck in a crash loop
- Fixes an issue with pipelines processing old data #2469 
- Fixes a bug that allowed paused pipelines to restart themselves.",23653453
1622,False,False,2017-10-18T03:20:03Z,2017-10-18T03:23:19Z,"- Changes default memory settings so that Pachyderm works on Minikube out of the box.
- Implements streaming versions of `ListFile` and `GlobFile` which prevents crashing on larger datasets.
- Fixes a race condition with `GetLogs`",23653453
1623,False,False,2017-10-10T00:12:54Z,2017-10-10T00:18:00Z,"- Adds support for private registries. (#2360)
- Fixes a bug that prevent cloud front deployments from working. (#2381)
- Fixes a failure that code arise while watching k8s resources. (#2382)
- Uses k8s' Guaranteed QoS for etcd and pachd. (#2368)",23653453
1624,False,False,2017-10-04T01:08:03Z,2017-10-04T01:11:33Z,"New Features in 1.6:

- Cron Inputs
- Access Control Model
- Advanced Statistic tracking for jobs
- Extended UI",23653453
1625,False,False,2017-10-03T16:48:34Z,2017-10-03T16:53:43Z,Built by goxc,23653453
1626,False,False,2017-09-30T15:54:56Z,2017-09-30T15:59:28Z,Built by goxc,23653453
1627,False,True,2017-09-27T18:52:25Z,2017-09-27T19:00:00Z,Built by goxc,23653453
1628,False,True,2017-09-22T23:40:54Z,2017-09-22T23:44:52Z,Built by goxc,23653453
1629,False,True,2017-09-20T20:38:30Z,2017-09-20T20:42:42Z,Built by goxc,23653453
1630,False,True,2017-09-19T17:07:10Z,2017-09-19T17:18:06Z,Built by goxc,23653453
1631,False,True,2017-09-19T04:08:39Z,2017-09-19T04:23:07Z,Built by goxc,23653453
1632,False,True,2017-09-07T23:39:14Z,2017-09-07T23:52:05Z,,23653453
1633,False,True,2017-09-06T02:11:41Z,2017-09-06T02:24:56Z,Built by goxc,23653453
1634,False,False,2017-08-17T23:11:40Z,2017-08-17T23:14:52Z,"Bug Fixes:

- Fix an issue that prevented deployment on GCE #2139 
- Fix an issue that could cause jobs to hang due to lockups with bind mounts. #2178 
- FromCommit in pipelines is now exclusive and able to be used with branch names as well as commit ids. #2180
- Egress was broken for certain object stores, this should be fixed now. #2156 

New Features:

- Union inputs can now be given the same name, making union much more ergonomic. #2174 
- PutFile now has an `--overwrite` flag which overwrites the previous version of the file rather than appending. #2142 
- We've introduce a new type of input, `Cron`, which can be used to trigger pipelines based on time. #2150.",23653453
1635,False,False,2017-08-05T00:12:56Z,2017-08-05T00:18:40Z,"*The changelog includes changes in 1.5.1 as well.*

### Bug Fixes

* A pipeline can get stuck after repeated worker failures.  (#2064)
* `pachctl port-forward` can leave a orphaned process after it exits.  (#2098)
* `alpine`-based pipelines fail to load input data.  (#2118)
* Logs are written to the object store even when stats is not enabled, slowing down the pipeline unnecessarily.  (#2119)

### Features / Improvements

* Pipelines now support the “stats” feature.  See the [docs](http://pachyderm.readthedocs.io/en/latest/reference/pipeline_spec.html#enable-stats-optional) for details.  (#1998)
* Pipeline cache size is now configurable.  See the [docs](http://pachyderm.readthedocs.io/en/latest/reference/pipeline_spec.html#cache-size-optional) for details.  (#2033)
* `pachctl update-pipeline` now **only** process new input data with the new code; the old input data is not re-processed.  If it’s desired that all data are re-processed, use the `--reprocess` flag.  See the [docs](http://pachyderm.readthedocs.io/en/latest/fundamentals/updating_pipelines.html) for details.  (#2034)
* Pipeline workers now support “pipelining”, meaning that they start downloading the next datums while processing the current datum, thereby improving overall throughput.  (#2057)
* The `scaleDownThreshold` feature has been improved such that when a pipeline is scaled down, the remaining worker only takes up minimal system resources.  (#2091)
",23653453
1636,False,False,2017-08-02T18:55:56Z,2017-08-02T19:08:52Z,Built by goxc,23653453
1637,False,False,2017-07-07T02:03:59Z,2017-07-07T02:12:24Z,"## 1.5.0

### Bug Fixes

* Downstream repos' provenance is not updated properly when `update-pipeline` changes the inputs for a pipeline. (#1958)
* `pachctl version` blocks when pachctl doesn't have Internet connectivity. (#1971)
* `incremental` misbehaves when files are deeply nested. (#1974)
* An `incremental` pipeline blocks if there's provenance among its inputs. (#2002)
* PPS fails to create subsequent pipelines if any pipeline failed to be created. (#2004)
* Pipelines sometimes reprocess datums that have already been processed. (#2008)
* Putting files into open commits fails silently. (#2014)
* Pipelines with inputs that use different branch names fail to create jobs. (#2015)
* `get-logs` returns incomplete logs.  (#2019)

### Features

* You can now use `get-file` and `list-file` on open commits. (#1943)",23653453
1638,False,True,2017-06-26T19:56:34Z,2017-06-26T20:00:26Z,"The full changelog will be posted with the actual 1.5.0 release.

Pachyderm 1.5.0 introduces breaking changes.  To migrate from 1.4.x to 1.5.0, follow [these instructions](http://pachyderm.readthedocs.io/en/latest/deployment/migrations.html#migrate-to-1-5-x).",23653453
1639,False,False,2017-06-14T18:29:40Z,2017-06-14T18:35:25Z,"Bug Fixes:

- Fixes bugs that caused us to swamp etcd with traffic.
- Fixes a bug that could cause corruption to in pipeline output.

Features:

- Readds incremental processing mode
- Adds `DiffFile` which is similar in function to `git diff`
- Adds the ability to use cloudfront as a caching layer for additional scalability on aws.
- `DeletePipeline` now allows you to delete the output repos as well.
- `DeletePipeline` and `DeleteRepo` now support a `--all` flag

Removed Features:

- Removes one-off jobs, they were a rarely used feature and the same behavior can be replicated with pipelines",23653453
1640,False,False,2017-06-07T16:43:17Z,2017-06-07T16:46:27Z,Built by goxc,23653453
1641,False,False,2017-06-01T20:50:27Z,2017-06-01T21:12:21Z,"## Bug fixes

* [Copy elision](http://pachyderm.readthedocs.io/en/latest/reference/best_practices.html#shuffling-files) does not work for directories. (#1803)
* Deleting a file in a closed commit fails silently. (#1804)
* Pachyderm has trouble processing large files. (#1819)
* etcd uses an unexpectedly large amount of space. (#1824)
* `pachctl mount` prints lots of benevolent FUSE errors. (#1840)

## New features

* `create-repo` and `create-pipeline` now accept the `--description` flag, which creates the repo/pipeline with a ""description"" field.  You can then see the description via `inspect-repo/inspect-pipeline`. (#1805)
* Pachyderm now supports garbage collection, i.e. removing data that's no longer referenced anywhere.  See the [docs](http://pachyderm.readthedocs.io/en/latest/reference/best_practices.html#garbage-collection) for details. (#1826)
* Pachyderm now has GPU support!  See the [docs](http://pachyderm.readthedocs.io/en/latest/cookbook/tensorflow_gpu.html) for details. (#1835)
* Most commands in `pachctl` now support the `--raw` flag, which prints the raw JSON data as opposed to pretty-printing.  For instance, `pachctl inspect-pipeline --raw` would print something akin to a pipeline spec. (#1839)
* `pachctl` now supports `delete-commit`, which allows for deleting a commit that's not been finished.  This is useful when you have added the wrong data in a commit and you want to start over.
* The web UI has added a file viewer, which allows for viewing PFS file content in the browser.",23653453
1642,False,False,2017-05-15T19:02:35Z,2017-05-15T19:47:22Z,Built by goxc,23653453
1643,False,False,2017-05-10T16:00:24Z,2017-05-10T16:03:34Z,"Built by goxc

Changelog:

- upgrade UI to 0.3.21
- fixes bug that made jobs thrash when downloading larger datums",23653453
1644,False,False,2017-05-05T23:08:20Z,2017-05-05T23:18:57Z,"## Bug fixes

* `get-logs` returns errors along the lines of `Invalid character…`. (#1741)
* etcd is not properly namespaced. (#1751)
* A job might get stuck if it uses `cp -r` with lazy files. (#1757)
* Pachyderm can use a huge amount of memory, especially when it processes a large number of files. (#1762)
* etcd returns `database space exceeded` errors after the cluster has been running for a while. (#1771)
* Jobs crashing might eventually lead to disk space being exhausted. (#1772)
* `port-forward` uses wrong port for UI websocket requests to remote clusters (#1754)
* Pipelines can end up with no running workers when the cluster is under heavy load. (#1788)
* API calls can start returning `context deadline exceeded` when the cluster is under heavy load. (#1796)

## New features / improvements

* Union input: a pipeline can now take the union of inputs, in addition to the cross-product of them.  Note that the old `inputs` field in the pipeline spec has been deprecated in favor of the new `input` field.  See the [pipeline spec](http://pachyderm.readthedocs.io/en/latest/reference/pipeline_spec.html#input-required) for details. (#1665)
* Copy elision: a pipeline that shuffles files can now be made more efficient by simply outputting symlinks to input files.  See the [docs on shuffling files](http://pachyderm.readthedocs.io/en/latest/reference/best_practices.html#shuffling-files) for details. (#1791)
* `pachctl glob-file`: ever wonder if your glob pattern actually works?  Wonder no more.  You can now use `pachctl glob-file` to see the files that match a given glob pattern. (#1795)
* Workers no longer send/receive data through pachd.  As a result, pachd is a lot more responsive and stable even when there are many ongoing jobs.  (#1742)
",23653453
1645,False,False,2017-04-22T09:44:21Z,2017-04-22T09:48:35Z,"## Bug fixes

* Fix a bug where pachd may crash after creating/updating a pipeline that has many input commits. (#1678)
* Rules for determining when input data is re-processed are made more intuitive.  Before, if you update a pipeline without updating the `transform`, the input data is not re-processed.  Now, different pipelines or different versions of pipelines always re-process data, even if they have the same `transform`. (#1685)
* Fix several issues with jobs getting stuck. (#1717)
* Fix several issues with lazy pipelines getting stuck. (#1721)
* Fix an issue with Minio deployment that results in job crash loop. (#1723)
* Fix an issue where a job can crash if it outputs a large number of files. (#1724)
* Fix an issue that causes intermittent gRPC errors. (#1727)

## New features

* Pachyderm now ships with a web UI!  To deploy a new Pachyderm cluster with the UI, use `pachctl deploy <arguments> --dashboard`.  To deploy the UI onto an existing cluster, use `pachctl deploy <arguments> --dashboard-only`.  To access the UI, simply `pachctl port-forward`, then go to `localhost:38080`.  Note that the web UI is currently in alpha; expect bugs and significant changes.   
* You can now specify the amount of resources (i.e. CPU & memory) used by Pachyderm and etcd.  See `pachctl deploy --help` for details. (#1676)
* You can now specify the amount of resources (i.e. CPU & memory) used by your pipelines.  See the [pipeline spec](http://pachyderm.readthedocs.io/en/latest/reference/pipeline_spec.html#resource-spec-optional) for details. (#1683)",23653453
1646,False,False,2017-04-15T01:17:47Z,2017-04-15T01:21:59Z,"## Bug fixes

* A job can fail to restart when encountering an internal error.
* A deployment with multiple pachd nodes can get stalled jobs.
* `delete-pipeline` is supposed to have the `--delete-jobs` flag but doesn't.
* `delete-pipeline` can fail if there are many jobs in the pipeline.
* `update-pipeline` can fail if the original pipeline has not outputted any commits.
* pachd can crash if etcd is flaky.
* pachd memory can be easily exhausted on GCE deployments.
* If a pipeline is created with multiple input commits already present, all jobs spawn and run in parallel.  After the fix, jobs always run serially.

## Features

* Pachyderm now supports auto-scaling: a pipeline's worker pods can be terminated automatically when the pipeline has been idle for a configurable amount of time.  See the `scaleDownThreshold` field of the [pipeline spec](http://pachyderm.readthedocs.io/en/latest/reference/pipeline_spec.html#scale-down-threshold-optional) for details.
* The processing of a datum can be restarted manually via `restart-datum`.
* Workers' statuses are now exposed through `inspect-job`.
* A job can be stopped manually via `stop-job`.
",23653453
1647,False,False,2017-04-08T05:27:12Z,2017-04-08T05:31:56Z,"## Bug fixes

* Pipelines with multiple inputs process only a subset of data.
* Workers may fall into a crash loop under certain circumstances. (#1606)

## New features

* `list-job` and `inspect-job` now display a job's progress, i.e. they display the number of datums processed thus far, and the total number of datums.
* `delete-pipeline` now accepts an option (`--delete-jobs`) that deletes all jobs in the pipeline. (#1540)
* Azure deployments now support dynamic provisioning of volumes.",23653453
1648,False,False,2017-04-07T00:54:52Z,2017-04-07T01:15:52Z,"## Bug fixes

* Certain network failures may cause a job to be stuck in the `running` state forever.
* A job might get triggered even if one of its inputs is empty.
* Listing or getting files from an empty output commit results in `node """" not found` error.
* Jobs are not labeled as `failure` even when the user code has failed.
* Running jobs do not resume when pachd restarts.
* `put-file --recursive` can fail when there are a large number of files.
* minio-based deployments are broken.

## Features

* `pachctl list-job` and `pachctl inspect-job` now display the number of times each job has restarted.
* `pachctl list-job` now displays the pipeline of a job even if the job hasn't completed.",23653453
1649,False,False,2017-04-05T02:12:00Z,2017-04-05T02:16:11Z,"## Bug fixes

* Getting files from GCE results in errors.
* A pipeline that has multiple inputs might place data into the wrong `/pfs` directories.
* `pachctl put-file --split` errors when splitting to a large number of files.
* Pipeline names do not allow underscores.
* `egress` does not work with a pipeline that outputs a large number of files. 
* Deleting nonexistent files returns errors.
* A job might try to process datums even if the job has been terminated.
* A job doesn't exit after it has encountered a failure.
* Azure backend returns an error if it writes to an object that already exists.

## New features

* `pachctl get-file` now supports the `--recursive` flag, which can be used to download directories.
* `pachctl get-logs` now outputs unstructured logs by default.  To see structured/annotated logs, use the `--raw` flag.",23653453
1650,False,False,2017-03-29T23:04:20Z,2017-03-30T01:26:47Z,Built by goxc,23653453
1651,False,False,2017-03-28T19:07:26Z,2017-03-28T19:16:18Z,[CHANGELOG](https://github.com/pachyderm/pachyderm/blob/master/CHANGELOG.md#140),23653453
1652,False,False,2017-03-27T20:48:59Z,2017-03-27T21:05:20Z,Built by goxc,23653453
1653,False,False,2017-03-27T20:48:59Z,2017-03-27T21:00:48Z,Built by goxc,23653453
1654,False,True,2017-03-24T01:32:34Z,2017-03-24T01:40:57Z,This releases fixes a couple major bugs in RC3 and features major performance improvements.,23653453
1655,False,True,2017-03-15T00:51:05Z,2017-03-15T01:00:38Z,"* Fix an issue where finishing a commit with too many files can fail.
* Fix an issue where parallelism is handled incorrectly.
* Fix an issue where heavy workloads can result in extremely high memory usage.",23653453
1656,False,False,2017-03-13T19:55:25Z,2017-03-13T20:17:30Z,Built by goxc,23653453
1657,False,False,2017-03-11T03:01:19Z,2017-03-11T03:06:00Z,Built by goxc,23653453
1658,False,True,2017-03-10T23:17:48Z,2017-03-10T23:25:11Z,,23653453
1659,False,True,2017-03-09T22:07:40Z,2017-03-10T02:26:52Z,,23653453
1660,False,False,2017-03-09T21:30:00Z,2017-03-09T21:32:41Z,"Built by goxc

Changes include:

- addition of retry logic for all generic temporary network errors",23653453
1661,False,False,2017-03-07T20:48:30Z,2017-03-07T20:51:12Z,"Built by goxc

Changes include:

- fix for pipelines specifying resource requests",23653453
1662,False,False,2017-03-07T02:12:35Z,2017-03-07T02:15:12Z,"Built by goxc

Changes include:

- custom deployment options (to any cloud provider w an s3 compatible obj store)
- specifying resource requests (cpu/mem) per pipeline",23653453
1663,False,False,2017-03-02T01:13:15Z,2017-03-02T01:16:20Z,"Built by goxc

Includes
- update to provide environment variables to set the `PPS_LEASE_PERIOD_SECS`, `PPS_HEARTBEAT_SECS`, and `PPS_MAX_HEARTBEAT_RETRIES` variables
- adds a retry to the heartbeat to insulate jobs from transient network failures
",23653453
1664,False,False,2017-03-01T03:17:38Z,2017-03-01T03:22:28Z,"Built by goxc

Includes:
- fix for hostPath location for jobs running on GKE
",23653453
1665,False,False,2017-02-27T23:15:34Z,2017-02-27T23:40:07Z,"Built by goxc
",23653453
1666,False,False,2017-02-17T22:58:06Z,2017-02-17T23:04:32Z,"Built by goxc
",23653453
1667,False,False,2017-02-16T22:12:50Z,2017-02-16T22:16:35Z,"Built by goxc
",23653453
1668,False,False,2017-02-09T17:39:06Z,2017-02-09T17:43:08Z,"Built by goxc
",23653453
1669,False,False,2017-01-13T23:14:57Z,2017-01-13T23:17:49Z,"Built by goxc
- fix to cluster_id in etcd during pachd initialization
- fix to pachctl docs
- fix to job failure mode
",23653453
1670,False,False,2017-01-10T21:31:46Z,2017-01-10T21:34:49Z,"Built by goxc
",23653453
1671,False,False,2016-12-21T23:29:20Z,2016-12-21T23:33:00Z,"Built by goxc
",23653453
1672,False,False,2016-12-12T20:56:46Z,2016-12-12T21:15:45Z,"Built by goxc
",23653453
1673,False,False,2016-12-07T21:57:47Z,2016-12-07T22:17:44Z,"Built by goxc
",23653453
1674,False,False,2016-12-01T18:13:30Z,2016-12-06T18:06:45Z,"Custom build off of the `gf-branch` to omit the FUSE changes for edge case jobs w particular access patterns on huge data sets.

To install [refer to installation instructions](http://docs.pachyderm.io/en/latest/getting_started/local_installation.html), or simply:

```
# For OSX:
$ brew tap pachyderm/tap && brew install pachctl

```
",23653453
1675,False,False,2016-12-01T02:00:53Z,2016-12-01T18:04:56Z,"Built by goxc
",23653453
1676,False,False,2016-11-23T22:19:23Z,2016-11-23T22:23:56Z,"Built by goxc
",23653453
1677,False,False,2016-10-31T22:41:20Z,2016-10-31T22:44:42Z,"Built by goxc
",23653453
1678,False,False,2016-10-11T18:57:52Z,2016-10-12T00:11:58Z,"Built by goxc
",23653453
1679,False,False,2016-09-23T20:39:04Z,2016-09-23T20:49:29Z,"Built by goxc
",23653453
1680,False,False,2016-09-23T17:27:16Z,2016-09-23T17:38:48Z,"Features:
- PFS has been rewritten to be more reliable and optimizeable
- PFS now has a much simpler name scheme for commits (eg `master/10`)
- PFS now supports merging, there are 2 types of merge. Squash and Replay
- Caching has been added to several of the higher cost parts of PFS
- UpdatePipeline, which allows you to modify an existing pipeline
- Transforms now have an Env section for specifying environment variables
- ArchiveCommit, which allows you to make commits not visible in ListCommit but still present and readable
- ArchiveAll, which archives all data
- PutFile can now take a URL in place of a local file, put multiple files and start/finish its own commits
- Incremental Pipelines now allow more control over what data is shown
- `pachctl deploy` is now the recommended way to deploy a cluster
- `pachctl port-forward` should be a much more reliable way to get your local machine talking to pachd
- `pachctl mount` will recover if it loses and regains contact with pachd
- `pachctl unmount` has been added, it can be used to unmount a single mount or all of them with `-a`
- Benchmarks have been added
- pprof support has been added to pachd
- Parallelization can now be set as a factor of cluster size
- `pachctl put-file` has 2 new flags `-c` and `-i` that make it more usable
- Minikube is now the recommended way to deploy locally

Content:
- Our developer portal is now available at: http://pachyderm.readthedocs.io/en/latest/
- We've added a quick way for people to reach us on Slack at: http://slack.pachyderm.io
- OpenCV example
",23653453
1681,False,False,2016-09-21T23:45:19Z,2016-09-22T00:19:50Z,"Built by goxc
",23653453
1682,False,False,2016-09-12T23:56:14Z,2016-09-13T00:07:43Z,"Built by goxc
",23653453
1683,False,False,2016-09-10T00:55:06Z,2016-09-12T17:36:41Z,"Built by goxc
",23653453
1684,False,False,2016-07-07T23:13:21Z,2016-07-08T00:59:12Z,"Built by goxc
",23653453
1685,False,False,2016-06-14T22:15:56Z,2016-06-14T23:54:22Z,"This point release includes the following:

New Features
- data provenance
- redesign how pipelines deal with inputs; refer to the [pipeline specification](https://github.com/pachyderm/pachyderm/blob/befc8bff7f1e2028bd16851a444ff6894572cb85/doc/pipeline_spec.md) for details
- some makefile checks for dependencies (e.g. kubectl)
- report JSON syntax errors more explicitly
- enable FUSE debugging via manifest flag
- insulate users from IP table errors
- enable dynamic membership (adding/removing nodes from a live cluster)
- provide input/output commid IDs as environment variables to jobs
- allow deletes and reads during an open commit (each container sees the files it has written / deleted appropriately)
- more insights into running pipelines and jobs (via pachctl `list-pipeline`, `inspect-pipeline`, `list-job`, `inspect-job`)

Bug Fixes:
- fully vendored dependencies
- readiness check for pod startup
- fuse edge cases
",23653453
1686,False,True,2016-06-13T19:38:19Z,2016-06-13T20:03:24Z,"We've fixed a lot of things since 1.0 launched and want users to be able to use the new fixes and features, including:
- readiness check for smarter pachd deployment
- data provenance
- updates to the environment variables provided at runtime via PPS
- and other bug fixes
",23653453
1687,False,False,2016-05-05T00:55:14Z,2016-05-05T01:10:42Z,"1.0.0 is the first generally available release of Pachyderm. It's a complete rewrite of the 0.\* series of releases, sharing no code with them. The following major architectural changes have happened since 0.*:
- All network communication and serialization is done using protocol buffers and GRPC.
- BTRFS has been removed, instead it's built on object storage, s3 and GCS are currently supported.
- Everything in Pachyderm is now scheduled on Kubernetes, this includes Pachyderm services and user jobs.
- We now have several access methods, you can use pachctl from the command line, our go client within your own code and the FUSE filesystem layer
",23653453
1688,False,False,2016-05-04T17:43:18Z,2016-05-04T18:11:31Z,"1.0.0 is the first generally available release of Pachyderm. It's a complete rewrite of the 0.\* series of releases, sharing no code with them. The following major architectural changes have happened since 0.*:
- All network communication and serialization is done using protocol buffers and GRPC.
- BTRFS has been removed, instead build on object storage, s3 and GCS are currently supported.
- Everything in Pachyderm is now scheduled on Kubernetes, this includes Pachyderm services and user jobs.
- We now have several access methods, you can use pachctl from the command line, our go client within your own code and the FUSE filesystem layer
",23653453
1689,False,False,2016-04-11T17:54:39Z,2016-04-11T19:28:57Z,,23653453
1690,False,True,2016-02-21T04:16:39Z,2016-02-22T10:12:02Z,"First release candidate for the new production ready Pachyderm.
",23653453
1691,False,False,2015-07-23T22:13:34Z,2015-07-23T22:17:19Z,"This release includes:
- initial support for deployment on Kubernetes
- massively overhauled development commands via a Makefile
- support for development using vagrant
- The first steps in a massive refactor that will completely overhaul pfs and pps making them much more production ready.
",23653453
1692,False,False,2015-07-01T21:49:45Z,2015-07-01T21:53:14Z,"- rename github.com/pachyderm/pfs to github.com/pachyderm/pachyderm
",23653453
1693,False,False,2015-07-01T21:39:36Z,2015-07-01T21:40:43Z,"- s3 integration
- cleanup of scripts
- word count example added
",23653453
1694,False,False,2015-06-23T23:13:50Z,2015-06-23T23:14:52Z,"This release has the following fixes:
- logs are correctly captured from pipelines
- waiting for pipelines is more bulletproof
- fixes a bug with globbing where we'd try to send directories as files
",23653453
1695,False,False,2015-06-17T20:32:22Z,2015-06-17T20:42:52Z,"This point release contains a few minor features and bug fixes:
- allows wrapping in Pachfiles
- pps now works with local images
- docker host can now be set with an environment variable
- pfs now sets content type for data it serves over http
",23653453
1696,False,False,2015-06-15T23:28:05Z,2015-06-15T23:29:37Z,"This release contains a small fix to lib/mapreduce that fixes its tests.
",23653453
1697,False,False,2015-06-12T02:27:27Z,2015-06-12T02:34:32Z,,23653453
1698,False,False,2015-06-07T21:52:38Z,2015-06-07T23:36:07Z,"This release contains changes for easily spinning up Pachyderm clusters on AWS.
",23653453
1699,False,False,2015-05-22T22:16:07Z,2015-05-22T22:17:04Z,"This release adds a Cloud Formation template and modifies deploy a bit to work with the template.
",23653453
1700,False,False,2015-05-19T07:30:21Z,2015-05-20T06:31:27Z,,23653453
1701,False,True,2015-05-14T22:26:14Z,2015-05-14T23:52:00Z,"First release with replication.
By clusters will store 3 copies of the data.
Pfs uses etcd to achieve automatic, in the event of a netsplit whichever side can still write to etcd will wind up with a working pfs cluster.

This release also adds a much more rigorous test suite.
",23653453
1702,False,False,2015-04-14T08:08:24Z,2015-04-14T08:18:52Z,"This release hardens the pipeline code to various errors that can occur in user submitted jobs such as memory leaks and infinite loops. It also fixes several concurrency bugs in the pipelines.
",23653453
1703,False,False,2015-03-14T01:19:12Z,2015-03-14T01:25:08Z,"New Features:
- Single node mode
- btrfs dependency is now much more resilient, this helps pfs to run correctly on platforms besides CoreOS
- Jobs now accept `limit`, `parallel` and `timeout` parameters which give better control over execution and allow downsampling
",23653453
1704,False,False,2015-02-20T10:00:38Z,2015-02-20T10:02:04Z,"This release fixes the scripts scripts/dev-intall and scripts/dev-post-receive.
",23653453
1705,False,False,2015-02-11T22:35:11Z,2015-02-11T22:39:38Z,"New features:
- pfs now runs a local Docker registry within the cluster
- pfs now runs a git daemon within the cluster
- jobs can now be launched via `git push`
- jobs can reference s3 as their input
- development can be orchestrated via `git push` as well
",23653453
1706,False,False,2015-01-23T10:04:49Z,2015-01-24T01:34:26Z,"# v0.3  - 1/23/15

New features:
- Pachyderm MapReduce
- `/job` route for creating MapReduce jobs
",23653453
1707,False,False,2014-12-11T12:15:25Z,2014-12-11T17:14:44Z,"# pfs 0.2 - 12/11/14

## New Features:
- Support for branching via `/branch`
- The `/pfs` route is now `/file`
- Test suite
",23653453
1708,False,False,2014-11-26T22:49:29Z,2014-11-26T22:52:56Z,"# pfs 0.1 - 11/11/14

This is the first public release of pfs.

## Features:
- Basic CRUD operations for the filesystem
- Commit
- Accessing data from previous commits
- Sharding
",23653453
1709,False,False,2020-03-26T07:33:24Z,2020-03-26T13:28:29Z,"## Slice column selection support in loc

We continue to improve `loc` indexer and added the slice column selection support (#1351).

```python
>>> from databricks import koalas as ks
>>> df = ks.DataFrame({'a':list('abcdefghij'), 'b':list('abcdefghij'), 'c': range(10)})
>>> df.loc[:, ""b"":""c""]
   b  c
0  a  0
1  b  1
2  c  2
3  d  3
4  e  4
5  f  5
6  g  6
7  h  7
8  i  8
9  j  9
```

## Slice row selection support in loc for multi-index

We also added the support of slice as row selection in `loc` indexer for multi-index (#1344).

```python
>>> from databricks import koalas as ks
>>> import pandas as pd
>>> df = ks.DataFrame({'a': range(3)}, index=pd.MultiIndex.from_tuples([(""a"", ""b""), (""a"", ""c""), (""b"", ""d"")]))
>>> df.loc[(""a"", ""c""): ""b""]
     a
a c  1
b d  2
```

## Slice row selection support in iloc

We continued to improve `iloc` indexer to support iterable indexes as row selection (#1338).

```python
>>> from databricks import koalas as ks
>>> df = ks.DataFrame({'a':list('abcdefghij'), 'b':list('abcdefghij')})
>>> df.iloc[[-1, 1, 2, 3]]
   a  b
1  b  b
2  c  c
3  d  d
9  j  j
```

## Support of setting values via loc and iloc at Series

Now, we added the basic support of setting values  via `loc` and `iloc` at Series (#1367).

```python
>>> from databricks import koalas as ks
>>> kser = ks.Series([1, 2, 3], index=[""cobra"", ""viper"", ""sidewinder""])
>>> kser.loc[kser % 2 == 1] = -kser
>>> kser
cobra        -1
viper         2
sidewinder   -3
```

## Other new features and improvements

We added the following new feature:

DataFrame:

- `take` (#1292)
- `eval` (#1359)

Series:

- `dot` (#1136)
- `take` (#1357)
- `combine_first` (#1290)

Index:

- `droplevel` (#1340)
- `union` (#1348)
- `take` (#1357)
- `asof` (#1350)

MultiIndex:

- `droplevel` (#1340)
- `unique` (#1342)
- `union` (#1348)
- `take` (#1357)

## Other improvements

- Compute Index.is_monotonic/Index.is_monotonic_decreasing in a distributed manner (#1354)
- Fix SeriesGroupBy.apply() to respect various output (#1339)
- Add the support for operations between different DataFrames in groupby() (#1321)
- Explicitly don't support to disable numeric_only in stats APIs at DataFrame (#1343)
- Fix index operator against Series and Frame to use iloc conditionally (#1336)
- Make nunique in DataFrame to return a Koalas DataFrame instead of pandas' (#1347)
- Fix MultiIndex.drop() to follow renaming et al. (#1356)
- Add column axis in ks.concat (#1349)
- Fix iloc for Series when the series is modified. (#1368)
- Support MultiIndex for duplicated, drop_duplicates. (#1363)
",164026325
1710,False,False,2020-03-12T03:08:31Z,2020-03-12T03:43:20Z,"## Slice support in `iloc`

We improved `iloc` indexer to support slice as row selection. (#1335)

For example,

```py
>>> kdf = ks.DataFrame({'a':list('abcdefghij')})
>>> kdf
   a
0  a
1  b
2  c
3  d
4  e
5  f
6  g
7  h
8  i
9  j
>>> kdf.iloc[2:5]
   a
2  c
3  d
4  e
>>> kdf.iloc[2:-3:2]
   a
2  c
4  e
6  g
>>> kdf.iloc[5:]
   a
5  f
6  g
7  h
8  i
9  j
>>> kdf.iloc[5:2]
Empty DataFrame
Columns: [a]
Index: []
```

## Documentation

We added links to the previous talks in our document. (#1319)

You can see a lot of useful talks from the previous events and we will keep updated.

https://koalas.readthedocs.io/en/latest/getting_started/videos.html

## Other new features and improvements

We added the following new feature:

DataFrame:
- `stack` (#1329)

Series:

- `repeat` (#1328)

Index:

- `difference` (#1325)
- `repeat` (#1328)

MultiIndex:

- `difference` (#1325)
- `repeat` (#1328)

## Other improvements

- DataFrame.pivot should preserve the original index names. (#1316)
- Fix _LocIndexerLike to handle a Series from index. (#1315)
- Support MultiIndex in DataFrame.unstack. (#1322)
- Support Spark UDT when converting from/to pandas DataFrame/Series. (#1324)
- Allow negative numbers for head. (#1330)
- Return a Koalas series instead of pandas' in stats APIs at Koalas DataFrame (#1333)
",164026325
1711,False,False,2020-02-27T13:42:49Z,2020-02-27T14:00:17Z,"## pandas 1.0 support

We added pandas 1.0 support (#1197, #1299), and Koalas now can work with pandas 1.0.

## map_in_pandas

We implemented `DataFrame.map_in_pandas` API (#1276) so Koalas can allow any arbitrary function with pandas DataFrame against Koalas DataFrame. See the example below:

```python
>>> import databricks.koalas as ks
>>> df = ks.DataFrame({'A': range(2000), 'B': range(2000)})
>>> def query_func(pdf):
...     num = 1995
...     return pdf.query('A > @num')
...
>>> df.map_in_pandas(query_func)
         A     B
1996  1996  1996
1997  1997  1997
1998  1998  1998
1999  1999  1999
```

## Standardize code style using Black

As a development only change, we added [Black](https://github.com/psf/black) integration (#1301). Now, all code style is standardized automatically via running `./dev/reformat`, and the style is checked as a part of `./dev/lint-python`.

## Other new features and improvements

We added the following new feature:

DataFrame:

- `query` (#1273)
- `unstack` (#1295)

## Other improvements
- Fix `DataFrame.describe()` to support multi-index columns. (#1279)
- Add util function validate_bool_kwarg (#1281)
- Rename data columns prior to filter to make sure the column names are as expected. (#1283)
- Add an faq about Structured Streaming. (#1298)
- Let extra options have higher priority to allow workarounds (#1296)
- Implement 'keep' parameter for ``drop_duplicates`` (#1303)
- Add a note when type hint is provided to DataFrame.apply (#1310)
- Add a util method to verify temporary column names. (#1262)
",164026325
1712,False,False,2020-02-13T02:37:47Z,2020-02-13T03:31:07Z,"## `head` ordering

Since Koalas doesn't guarantee the row ordering, `head` could return some rows from distributed partition and the result is not deterministic, which might confuse users.

We added a configuration `compute.ordered_head` (#1231), and if it is set to `True`, Koalas performs natural ordering beforehand and the result will be the same as pandas'.
The default value is `False` because the ordering will cause a performance overhead.

```py
>>> kdf = ks.DataFrame({'a': range(10)})
>>> pdf = kdf.to_pandas()
>>> pdf.head(3)
   a
0  0
1  1
2  2

>>> kdf.head(3)
   a
5  5
6  6
7  7
>>> kdf.head(3)
   a
0  0
1  1
2  2

>>> ks.options.compute.ordered_head = True
>>> kdf.head(3)
   a
0  0
1  1
2  2
>>> kdf.head(3)
   a
0  0
1  1
2  2
```

## GitHub Actions

We started trying to use GitHub Actions for CI. (#1254, #1265, #1264, #1267, #1269)

## Other new features and improvements

We added the following new feature:

DataFrame:
- apply (#1259)

## Other improvements

- Fix identical and equals for the comparison between the same object. (#1220)
- Select the series correctly in SeriesGroupBy APIs (#1224)
- Fixes `DataFrame/Series.clip` function to preserve its index. (#1232)
- Throw a better exception in `DataFrame.sort_values` when multi-index column is used (#1238)
- Fix `fillna` not to change index values. (#1241)
- Fix `DataFrame.__setitem__` with tuple-named Series. (#1245)
- Fix `corr` to support multi-index columns. (#1246)
- Fix output of `print()` matches with pandas of Series (#1250)
- Fix fillna to support partial column index for multi-index columns. (#1244)
- Add as_index check logic to groupby parameter (#1253)
- Raising NotImplementedError for elements that actually are not implemented. (#1256)
- Fix where to support multi-index columns. (#1249)
",164026325
1713,False,False,2020-01-23T10:58:29Z,2020-01-23T11:01:57Z,"## `iat` indexer

We continued to improve indexers. Now, `iat` indexer is supported too (#1062).

```python
>>> df = ks.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
...                   columns=['A', 'B', 'C'])
>>> df
    A   B   C
0   0   2   3
1   0   4   1
2  10  20  30

>>> df.iat[1, 2]
1
```

## Other new features and improvements

We added the following new features:

koalas.Index

- `equals` (#1216)
- `identical` (#1215)
- `is_all_dates` (#1205)
- `append` (#1163)
- `to_frame` (#1187)

koalas.MultiIndex:

- `equals` (#1216)
- `identical` (#1215)
- `swaplevel` (#1105)
- `is_all_dates` (#1205)
- `is_monotonic_increasing` (#1183)
- `is_monotonic_decreasing ` (#1183)
- `append` (#1163)
- `to_frame` (#1187)

koalas.DataFrameGroupBy

- `describe` (#1168)


## Other improvements

- Change default write mode to overwrite to be consistent with pandas (#1209)
- Prepare Spark 3 (#1211,  #1181)
- Fix `DataFrame.idxmin/idxmax`. (#1198)
- Fix reset_index with the default index is ""distributed-sequence"". (#1193)
- Fix column name as a tuple in multi column index (#1191)
- Add favicon to doc (#1189)




",164026325
1714,False,False,2020-01-09T02:32:49Z,2020-01-09T03:30:51Z,"## `loc` and `iloc` indexers improvement

We improved `loc` and `iloc` indexers. Now, `loc` can support scalar values as indexers (#1172).

```python
>>> import databricks.koalas as ks
>>>
>>> df = ks.DataFrame([[1, 2], [4, 5], [7, 8]],
...                   index=['cobra', 'viper', 'sidewinder'],
...                   columns=['max_speed', 'shield'])
>>> df.loc['sidewinder']
max_speed    7
shield       8
Name: sidewinder, dtype: int64
>>> df.loc['sidewinder', 'max_speed']
7
```

In addition, Series derived from a different Frame can be used as indexers (#1155).

```python
>>> import databricks.koalas as ks
>>>
>>> ks.options.compute.ops_on_diff_frames = True
>>> 
>>> df1 = ks.DataFrame({'A': [0, 1, 2, 3, 4], 'B': [100, 200, 300, 400, 500]},
...                    index=[20, 10, 30, 0, 50])
>>> df2 = ks.DataFrame({'A': [0, -1, -2, -3, -4], 'B': [-100, -200, -300, -400, -500]},
...                    index=[20, 10, 30, 0, 50])
>>> df1.A.loc[df2.A > -3].sort_index()
10    1
20    0
30    2
```

Lastly, now `loc` uses its natural order according to index identically with pandas' when using the slice (#1159, #1174, #1179). See the example below.

```python
>>> df = ks.DataFrame([[1, 2], [4, 5], [7, 8]],
...                   index=['cobra', 'viper', 'sidewinder'],
...                   columns=['max_speed', 'shield'])
>>> df.loc['cobra':'viper', 'max_speed']
cobra    1
viper    4
Name: max_speed, dtype: int64
```

## Other new features and improvements

We added the following new features:

koalas.Series:

- `get` (#1153)

koalas.Index

- `drop` (#1117)
- `len` (#1161)
- `set_names` (#1134)
- `argmin` (#1162)
- `argmax` (#1162)

koalas.MultiIndex:

- `from_product` (#1144)
- `drop` (#1117)
- `len` (#1161)
- `set_names` (#1134)

## Other improvements

- Add support `from_pandas` for Index/MultiIndex. (#1170)
- Add a hidden column `__natural_order__`. (#1146)
- Introduce `_LocIndexerLike` and consolidate some logic. (#1149)
- Refactor `LocIndexerLike.__getitem__`. (#1152)
- Remove sort in `GroupBy._reduce_for_stat_function`. (#1147)
- Randomize index in tests and fix some window-like functions. (#1151)
- Explicitly don't support `Index.duplicated` (#1131)
- Fix `DataFrame._repr_html_()`. (#1177)",164026325
1715,False,False,2019-12-19T06:04:45Z,2019-12-19T07:18:19Z,"## NumPy's universal function (ufunc) compatibility

We added the compatibility of NumPy ufunc (#1127). Virtually all ufunc compatibilities in Koalas DataFrame were implemented. See the example below:

```python
>>> import databricks.koalas as ks
>>> import numpy as np
>>> kdf = ks.range(10)
>>> np.log(kdf)
         id
0       NaN
1  0.000000
2  0.693147
3  1.098612
4  1.386294
5  1.609438
6  1.791759
7  1.945910
8  2.079442
9  2.197225
```


## Other new features and improvements

We added the following new features:

koalas:

- `to_numeric` (#1060)

koalas.DataFrame:

- `idxmax` (#1054)
- `idxmin` (#1054)
- `pct_change` (#1051)
- `info` (#1124)

koalas.Index

- `fillna` (#1102)
- `min` (#1114)
- `max` (#1114)
- `drop_duplicates` (#1121)
- `nunique` (#1132)
- `sort_values` (#1120)

koalas.MultiIndex:

- `levshape` (#1086)
- `min` (#1114)
- `max` (#1114)
- `sort_values` (#1120)

koalas.SeriesGroupBy

- `head` (#1050)

koalas.DataFrameGroupBy

- `head` (#1050)


## Other improvements

- Setting index name / names for Series (#1079)
- disable 'str' for 'SeriesGroupBy', disable 'DataFrame' for 'GroupBy' (#1097)
- Support 'compute.ops_on_diff_frames' for NumPy ufunc compay in Series (#1128)
- Support arithmetic and comparison APIs on same DataFrames (#1129)
- Fix rename() for Index to support MultiIndex also (#1125)
- Set the upper-bound for pandas. (#1137)
- Fix _cum() for Series to work properly (#1113)
- Fix value_counts() to work properly when dropna is True (#1116, #1142)",164026325
1716,False,False,2019-12-05T01:49:07Z,2019-12-05T01:56:09Z,"## NumPy's universal function (ufunc) compatibility

We added the compatibility of NumPy ufunc (#1096, #1106). Virtually all ufunc compatibilities in Koalas Series were implemented. See the example below:

```python
>>> import databricks.koalas as ks
>>> import numpy as np
>>> kdf = ks.range(10)
>>> kser = np.sqrt(kdf.id)
>>> type(kser)
<class 'databricks.koalas.series.Series'>
>>> kser
0    0.000000
1    1.000000
2    1.414214
3    1.732051
4    2.000000
5    2.236068
6    2.449490
7    2.645751
8    2.828427
9    3.000000
```


## Other new features and improvements

We added the following new features:

koalas:

- `option_context` (#1077)

koalas.DataFrame:

- `where` (#1018)
- `mask` (#1018)
- `iterrows` (#1070)

koalas.Series:

- `pop` (#866)
- `first_valid_index` (#1092)
- `pct_change` (#1071)

koalas.Index

- `symmetric_difference` (#953, #1059)
- `to_numpy ` (#1058)
- `transpose` (#1056)
- `T` (#1056)
- `dropna` (#938)
- `shape` (#1085)
- `value_counts` (#949)

koalas.MultiIndex:

- `symmetric_difference` (#953, #1059)
- `to_numpy ` (#1058)
- `transpose` (#1056)
- `T` (#1056)
- `dropna` (#938)
- `shape` (#1085)
- `value_counts` (#949)


## Other improvements

- Fix comparison operators to treat NULL as False (#1029)
- Make corr return koalas.DataFrame (#1069)
- Include link to Help Thirsty Koalas Fund (#1082)
- Add Null handling for different frames (#1083)
- Allow `Series.__getitem__` to take boolean Series (#1075)
- Produce correct output against multiIndex when 'compute.ops_on_diff_frames' is enabled (#1089)
- Fix idxmax() / idxmin() for Series work properly (#1078)
",164026325
1717,False,False,2019-11-14T04:54:26Z,2019-11-14T05:37:21Z,"## Enable Arrow 0.15.1+

Apache Arrow 0.15.0 did not work well with PySpark 2.4 so it was disabled in the previous version.
With Arrow 0.15.1, now it works in Koalas (#902).

## Expanding and Rolling

We also added `expanding()` and `rolling()` APIs in all `groupby()`, Series and Frame (#985, #991, #990, #1015, #996, #1034, #1037)

- `min`
- `max`
- `sum`
- `mean`
- `std`
- `var`

## Multi-index columns support

We continue improving multi-index columns support. We made the following APIs support multi-index columns:

- `median` (#995)
- `at` (#1049)

## Documentation

We added ""Best Practices"" section in the documentation (#1041) so that Koalas users can read and follow. Please see https://koalas.readthedocs.io/en/latest/user_guide/best_practices.html

## Other new features and improvements

We added the following new features:

koalas.DataFrame:

- `quantile` (#984)
- `explain` (#1042)

koalas.Series:

- `between` (#997)
- `update` (#923)
- `mask` (#1017)

koalas.MultiIndex:

- `from_tuples` (#970)
- `from_arrays` (#1001)


Along with the following improvements:

- Introduce column_scols in InternalFrame substitude for data_columns. (#956)
- Fix different index level assignment when 'compute.ops_on_diff_frames' is enabled (#1045)
- Fix Dataframe.melt function & Add doctest case for melt function (#987)
- Enable creating Index from list like 'Index([1, 2, 3])' (#986)
- Fix combine_frames to handle where the right hand side arguments are modified Series (#1020)
- `setup.py` should support Python 2 to show a proper error message. (#1027)
- Remove `Series.schema`. (#993)

",164026325
1718,False,False,2019-10-31T06:04:00Z,2019-10-31T06:12:03Z,"## Multi-index columns support

We continue improving multi-index columns support. We made the following APIs support multi-index columns:

- `nunique` (#980)
- `to_csv` (#983)

## Documentation

Now, we have installation guide, design principles and FAQ in our public documentation (#914, #944, #963, #964)

## Other new features and improvements

We added the following new features:

koalas

- `merge` (#969)

koalas.DataFrame:

- `keys` (#937)
- `ndim` (#947)

koalas.Series:

- `keys` (#935)
- `mode` (#899)
- `truncate` (#928)
- `xs` (#921)
- `where` (#922)
- `first_valid_index` (#936)

koalas.Index:

- `copy` (#939)
- `unique` (#912)
- `ndim` (#947)
- `has_duplicates` (#946)
- `nlevels` (#945)

koalas.MultiIndex:

- `copy` (#939)
- `ndim` (#947)
- `has_duplicates` (#946)
- `nlevels` (#945)

koalas.Expanding

- `count` (#978)

Along with the following improvements:

- Fix passing options as keyword arguments (#968)
- Make is_monotonic~ work properly for index (#930)
- Fix Series.\_\_getitem\_\_ to work properly (#934)
- Fix reindex when all the given columns are included the existing columns (#975)
- Add datetime as the equivalent python type to TimestampType (#957)
- Fix is_unique to respect the current Spark column (#981)
- Fix bug when assign None to name as Index (#974)
- Use name_like_string instead of str directly. (#942, #950)
",164026325
1719,False,False,2019-10-15T12:58:31Z,2019-10-15T13:37:06Z,"## Disable Arrow 0.15

Apache Arrow 0.15.0 was released on the 5th of October, 2019, which Koalas depends on to execute Pandas UDF, but the Spark community reports [an issue](https://issues.apache.org/jira/browse/SPARK-29367) with PyArrow 0.15.

We decided to set an upper bound for pyarrow version to avoid such issues until we are sure that Koalas works fine with it.

- Set an upper bound for pyarrow version. (#918)

## Multi-index columns support

We continue improving multi-index columns support. We made the following APIs support multi-index columns:

- `pivot_table` (#908)
- `melt` (#920)

## Other new features and improvements

We added the following new features:

koalas.DataFrame:

- `xs` (#892)

koalas.Series:

- `drop_duplicates` (#896)
- `replace` (#903)

koalas.GroupBy:

- `shift` (#910)

Along with the following improvements:

- Implement nested renaming for groupby agg (#904)
- Add 'index_col' parameter to DataFrame.to_spark (#906)
- Add more options to `read_csv` (#916)
- Add NamedAgg (#911)
- Enable DataFrame setting value as list of labels (#905)
",164026325
1720,False,False,2019-10-04T05:00:31Z,2019-10-04T05:08:52Z,"## Koalas Logo

Now that we have an official logo!

![](https://user-images.githubusercontent.com/6477701/66183415-d5ae1180-e6b3-11e9-93e8-bb7d92b5e392.png)

We can see the cute logo in our documents as well.

## Documentation

Also we improved the documentation: https://koalas.readthedocs.io/en/latest/

- Added the logo (#831)
- Added a Jupyter notebook for 10 min tutorial (#843)
- Added the tutorial to the documentation (#853)
- Add some examples for plot implementations in their docstrings (#847)
- Move contribution guide to the official documentation site (#841)

### Binder integration for the 10 min tutorial

You can run a live Jupyter notebook for 10 min tutorial from [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/databricks/koalas/master?filepath=docs%2Fsource%2Fgetting_started%2F10min.ipynb).

## Multi-index columns support

We continue improving multi-index columns support. We made the following APIs support multi-index columns:

- `transform` (#800)
- `round` (#802)
- `unique` (#809)
- `duplicated` (#803)
- `assign` (#811)
- `merge` (#825)
- `plot` (#830)
- `groupby` and its functions (#833)
- `update` (#848)
- `join` (#848)
- `drop_duplicate` (#856)
- `dtype` (#858)
- `filter` (#859)
- `dropna` (#857)
- `replace` (#860)

## Plots

We also continue adding plot APIs as follows:

For DataFrame:

- `plot.kde()` (#784)

## Other new features and improvements

We added the following new features:

koalas.DataFrame:

- `pop` (#791)
- `__iter__` (#836)
- `rename` (#806)
- `expanding` (#840)
- `rolling` (#840)

koalas.Series:

- `aggregate` (#816)
- `agg` (#816)
- `expanding` (#840)
- `rolling` (#840)
- `drop` (#829)
- `copy` (#869)

koalas.DataFrameGroupBy:

- `expanding` (#840)
- `rolling` (#840)

koalas.SeriesGroupBy:

- `expanding` (#840)
- `rolling` (#840)

Along with the following improvements:

- Add squeeze argument to read_csv (#812)
- Raise a more helpful error for duplicated columns in Join (#820)
- Issue with ks.merge to Series (#818)
- Fix `MultiIndex.to_pandas()` and `__repr__()`. (#832)
- Add unit and origin options for to_datetime (#839)
- Fix on wrong error raise in DataFrame.fillna (#844)
- Allow str and list in aggfunc in DataFrameGroupby.agg (#828)
- Add `index_col` argument to `to_koalas()`. (#863)",164026325
1721,False,False,2019-09-19T06:17:20Z,2019-09-19T07:42:49Z,"## Multi-index columns support

We continue improving multi-index columns support (#793, #776). We made the following APIs support multi-index columns:

- `applymap` (#793)
- `shift` (#793)
- `diff` (#793)
- `fillna` (#793)
- `rank` (#793)

Also, we can set tuple or None name for Series and Index. (#776)

```python
>>> import databricks.koalas as ks
>>> kser = ks.Series([1, 2, 3])
>>> kser.name = ('a', 'b')
>>> kser
0    1
1    2
2    3
Name: (a, b), dtype: int64
```

## Plots

We also continue adding plot APIs as follows:

For Series:

- `plot.kde()` (#767)

For DataFrame:

- `plot.hist()` (#780)

## Options

In addition, we added the support for namespace-access in options (#785).

```python
>>> import databricks.koalas as ks
>>> ks.options.display.max_rows
1000
>>> ks.options.display.max_rows = 10
>>> ks.options.display.max_rows
10
```

See also [User Guide](https://koalas.readthedocs.io/en/latest/user_guide/options.html) of our project docs.


## Other new features and improvements

We added the following new features:

koalas.DataFrame:

- `aggregate` (#796)
- `agg` (#796)
- `items` (#787)

koalas.indexes.Index/MultiIndex

- `is_boolean` (#795)
- `is_categorical` (#795)
- `is_floating` (#795)
- `is_integer` (#795)
- `is_interval` (#795)
- `is_numeric` (#795)
- `is_object` (#795)

Along with the following improvements:

- Add `index_col` for `read_json` (#797)
- Add index_col for spark IO reads (#769, #775)
- Add ""sep"" parameter for read_csv (#777)
- Add axis parameter to dataframe.diff (#774)
- Add read_json and let to_json use spark.write.json (#753)
- Use spark.write.csv in to_csv of Series and DataFrame (#749)
- Handle TimestampType separately when convert to pandas' dtype. (#798)
- Fix `spark_df` when `set_index(.., drop=False)`. (#792)

## Backward compatibility

- We removed some parameters in `DataFrame.to_csv` and `DataFrame.to_json` to allow distributed writing (#749, #753)",164026325
1722,False,False,2019-09-05T06:46:53Z,2019-09-05T07:19:11Z,"## Options

We started using options to configure the Koalas' behavior. Now we have the following options:

- `display.max_rows` (#714,  #742)
- `compute.max_rows` (#721, #736)
- `compute.shortcut_limit` (#717)
- `compute.ops_on_diff_frames` (#725)
- `compute.default_index_type` (#723)
- `plotting.max_rows` (#728)
- `plotting.sample_ratio` (#737)

We can also see the list and their descriptions in the [User Guide](https://koalas.readthedocs.io/en/latest/user_guide/options.html) of our project docs.

## Plots

We continue adding plot APIs as follows:

For Series:

- `plot.area()` (#704)

For DataFrame:

- `plot.line()` (#686)
- `plot.bar()` (#695)
- `plot.barh()` (#698)
- `plot.pie()` (#703)
- `plot.area()` (#696)
- `plot.scatter()` (#719)

## Multi-index columns support

We also continue improving multi-index columns support. We made the following APIs support multi-index columns:

- `koalas.concat()` (#680)
- `koalas.get_dummies()` (#695)
- `DataFrame.pivot_table()` (#635)

## Other new features and improvements

We added the following new features:

koalas:

- `read_sql_table()` (#741)
- `read_sql_query()` (#741)
- `read_sql()` (#741)

koalas.DataFrame:

- `style` (#712)

Along with the following improvements:

- `GroupBy.apply` should return Koalas DataFrame instead of pandas DataFrame (#731)
- Fix `rpow` and `rfloordiv` to use proper operators in Series (#735)
- Fix `rpow` and `rfloordiv` to use proper operators in DataFrame (#740)
- Add schema inference support at DataFrame.transform (#732)
- Add `Option` class to support type check and value check in options (#739)
- Added missing tests (#687, #692, #694, #709, #711, #730, #729, #733, #734)

## Backward compatibility

- We renamed two of the default index names from `one-by-one` and `distributed-one-by-one ` to `sequence` and `distributed-sequence` respectively. (#679)
- We moved the configuration for enabling operations on different DataFrames from the environment variable to the option. (#725)
- We moved the configuration for the default index from the environment variable to the option. (#723)",164026325
1723,False,False,2019-08-22T05:51:11Z,2019-08-22T06:35:42Z,"Firstly, we introduced new mode to enable operations on different DataFrames (#633). This mode can be enabled by setting `OPS_ON_DIFF_FRAMES` environment variable is set to `true` as below:

```python
>>> import databricks.koalas as ks
>>>
>>> kdf1 = ks.range(5)
>>> kdf2 = ks.DataFrame({'id': [5, 4, 3]})
>>> (kdf1 - kdf2).sort_index()
    id
0 -5.0
1 -3.0
2 -1.0
3  NaN
4  NaN
```

```python
>>> import databricks.koalas as ks
>>>
>>> kdf = ks.range(5)
>>> kdf['new_col'] = ks.Series([1, 2, 3, 4])
>>> kdf
   id  new_col
0   0      1.0
1   1      2.0
3   3      4.0
2   2      3.0
4   4      NaN
```

Secondly, we also introduced default index and disallowed Koalas DataFrame with no index internally (#639)(#655). For example, if you create Koalas DataFrame from Spark DataFrame, the default index is used. The default index implementation can be configured by setting `DEFAULT_INDEX` as one of three types:

- (default) `one-by-one`: It implements a one-by-one sequence by Window function without
specifying partition. This index type should be avoided when the data is large.

    ```python
    >>> ks.range(3)
       id
    0   0
    1   1
    2   2
    ```

- `distributed-one-by-one`: It implements a one-by-one sequence by group-by and
group-map approach. It still generates a one-by-one sequential index globally.
If the default index must be a one-by-one sequence in a large dataset, this
index can be used.

    ```python
    >>> ks.range(3)
       id
    0   0
    1   1
    2   2
    ```

- `distributed`: It implements a monotonically increasing sequence simply by using
Spark's `monotonically_increasing_id` function. If the index does not have to be
a one-by-one sequence, this index can be used. Performance-wise, this index
almost does not have any penalty comparing to other index types.

    ```python
    >>> ks.range(3)
                 id
    25769803776   0
    60129542144   1
    94489280512   2
    ```

Thirdly, we implemented many plot APIs in Series as follows:

- plot.pie() (#669)
- plot.area() (#670)
- plot.line() (#671)
- plot.barh() (#673)

See the example below:

```python
import databricks.koalas as ks

ks.range(10).to_pandas().id.plot.pie()
```

![image](https://user-images.githubusercontent.com/6477701/63404049-aa7da480-c41c-11e9-9472-f33e5c302dc6.png)

Fourthly, we rapidly improved multi-index columns support continuously. Now multi-index columns are supported in multiple APIs:

- `DataFrame.sort_index()`(#637)
- `GroupBy.diff()`(#653)
- `GroupBy.rank()`(#653)
- `Series.any()`(#652)
- `Series.all()`(#652)
- `DataFrame.any()`(#652)
- `DataFrame.all()`(#652)
- `DataFrame.assign()`(#657)
- `DataFrame.drop()`(#658)
- `DataFrame.reindex()`(#659)
- `Series.quantile()`(#663)
- `Series,transform()`(#663)
- `DataFrame.select_dtypes()`(#662)
- `DataFrame.transpose()`(#664).


Lastly we added new functionalities, especially for groupby-related functionalities, in the past weeks. We added the following features:

koalas.DataFrame

- duplicated() (#569)
- fillna() (#640)
- bfill() (#640)
- pad() (#640)
- ffill() (#640)

koalas.groupby.GroupBy:

- diff() (#622)
- nunique() (#617)
- nlargest() (#654)
- nsmallest() (#654)
- idxmax() (#649)
- idxmin() (#649)

Along with the following improvements:

- Add a basic infrastructure for configurations. (#645)
- Always use `column_index`. (#648)
- Allow to omit type hint in GroupBy.transform, filter, apply (#646)
",164026325
1724,False,False,2019-08-08T04:50:18Z,2019-08-08T05:14:40Z,"We rapidly improved and added new functionalities, especially for groupby-related functionalities, in the past weeks. We also added the following features:

koalas.groupby.GroupBy:

- size() (#593)
- filter() (#614)
- cummax() (#610)
- cummin() (#610)
- cumsum() (#610)
- cumprod() (#610)
- rand() (#619)

koalas.groupby.SeriesGroupBy:

- apply() (#609)
- value_counts() (#613)

koalas.indexes.Index:

- size() (#623)

Along with the following improvements:

- Add multiple aggregations on a single column (#602)
- Add axis=columns to count, var, std, max, sum, min, kurtosis, skew and mean in DataFrame (#605)
- Add Spark DDL formatted string support in read_csv(names=...) (#604)
- Support names of index levels (#621, #629)
- Add as_index argument to groupby. (#627)
- Fix issues related to multi-index column access (#594, #597, #606, #611, #612, #620)
",164026325
1725,False,False,2019-07-25T07:59:02Z,2019-07-25T08:24:34Z,"We added a basic multi-index support in columns (#590) as below. pandas multi-index can be also mapped.

```python
>>> import databricks.koalas as ks
>>> import numpy as np
>>>
>>> arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux']),
...           np.array(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'])]
>>> kdf = ks.DataFrame(np.random.randn(3, 8), index=['A', 'B', 'C'], columns=arrays)
```

```python
>>> kdf
        bar                 baz                 foo                 qux
        one       two       one       two       one       two       one       two
A -1.574777  0.805108  0.139748  1.287946 -1.782297 -0.152292  0.680594  1.419407
B  0.076886 -1.560807  0.403807 -0.715029  1.236899 -0.364483 -1.548554  0.076003
C -0.575168  0.061539 -2.083615 -0.816090 -1.267440  0.745949 -1.194421  0.468818
```

```python
>>> kdf['bar']
        one       two
A -1.574777  0.805108
B  0.076886 -1.560807
C -0.575168  0.061539
```

```python
>>> kdf['bar']['two']
A    0.805108
B   -1.560807
C    0.061539
Name: two, dtype: float64
```

In addition, we are triaging APIs to support and unsupport explicitly (#574)(#580). Some of pandas APIs would explicitly be unsupported according to [Guardrails to prevent users from shooting themselves in the foot](https://github.com/databricks/koalas#guardrails-to-prevent-users-from-shooting-themselves-in-the-foot) and based upon other justifications such as the cost of their operations.

We also added the following features:

koalas.DataFrame:

  - ffill() (#571)
  - bfill() (#570)
  -  filter() (#589)

koalas.Series:

  - idxmax() (#587)
  - idxmin() (#587)

koalas.indexes.Index:

  - Index.rename() (#581)

koalas.groupby.GroupBy:

  - apply() (#584)
  - transform() (#585)

Along with the following improvements:

  - pandas 0.25 support (#579)
  - `method` and `limit` parameter support in `DataFrame.fillna()` (#565)
  - Dots (`.`) in columns names are allowed (#490)
  - Add support of level argument for DataFrame/Series.sort_index() (#583)
",164026325
1726,False,False,2019-07-17T05:42:52Z,2019-07-17T06:39:24Z,"We rapidly improved and added new functionalities in the past week. We also added the following features:

koalas.DataFrame:

  - diff (#562)
  - shift (#562)
  - round (#537)
  - rank (#546)
  - any (#568)
  - all (#568)

koalas.Series:

  - diff (#564)
  - quantile (#566)
  - shift (#563)
  - is_monotonic (#560)
  - is_monotonic_increasing (#560)
  - is_monotonic_decreasing (#560)
  - round (#537)
  - rank (#546)
",164026325
1727,False,False,2019-07-10T05:35:44Z,2019-07-10T06:36:26Z,"We rapidly improved and added new functionalities in the past week. We also added the following features:

koalas:

  - isna (#548)
  - isnull (#548)
  - notna (#548)
  - notnull (#548)

koalas.DataFrame:

  - bool (#533)
  - reindex (#493)
  - pivot (#532)
  - transform (#541)
  - median (#544)
  - cumprod (#545)

koalas.Series:

  - cummax (#534)
  - cummin (#534)
  - cumsum (#534)
  - bool (#533)
  - median (#540)
  - transpose (#543)
  - T (#543)
  - cumprod (#545)
  - hasnans (#547)

Along with the following improvements:

- Fix DataFrame.replace to take `kdf.replace({0: 10, 1: 100})` (#527)",164026325
1728,False,False,2019-07-04T04:54:54Z,2019-07-04T05:18:26Z,"We fixed a critical regression for pandas 0.23.x compatibility (#528, #529)
Now, pandas 0.23.x support is back.",164026325
1729,False,False,2019-07-03T07:40:05Z,2019-07-03T07:46:08Z,"We added infrastructure for usage logging (#494). It allows to use a custom logger to handle each API process failure and success. In Koalas, it has a built-in Koalas logger, `databricks.koalas.usage_logging.usage_logger`,  with Python `logging`.

In addition, Koalas experimentally introduced type hints for both `Series` and `DataFrame` (#453). The new type hints are used as below:

```python
def func(...) -> ks.Series[np.float]:
    ...
def func(...) -> ks.DataFrame[np.float, int, str]:
    ...
```

We also added the following features:

koalas.DataFrame:

- update (#498)
- pivot_table (#386)
- pow (#503)
- rpow (#503)
- mod (#503)
- rmod (#503)
- floordiv (#503)
- rfloordiv (#503)
- T (#469)
- transpose (#469)
- select_dtypes (#510)
- replace (#495)
- cummin (#521)
- cummax (#521)
- cumsum (#521)

koalas.Series:

- rank (#516)

Along with the following improvements:

- Remaining Koalas Series.str functions (#496)
- `nunique` in koalas.groupby.GroupBy.agg (#512)
",164026325
1730,False,False,2019-06-19T09:42:24Z,2019-06-19T10:00:06Z,"We bumped up supporting MLflow to `1.0` and now we can use URI pointing to the model. Please see MLflow documentation for more details. Note that we don't support older versions any more. (#477)

We also added the following features:

koalas:

- melt (#474)

koalas.DataFrame:

- eq (#476)
- ne (#476)
- gt (#476)
- ge(#476)
- lt(#476) 
- le (#476)
- join (#473)
- melt (#474)
- get_dtype_counts (#480)

koalas.Series:

- eq (#476)
- ne (#476)
- gt (#476)
- ge(#476)
- lt(#476) 
- le (#476)
- get_dtype_counts (#480)
- to_frame (#483)

koalas.groupby.GroupBy:

- all (#485)
- any (#485)

Along with the following improvements:

- The Koalas `DataFrame` constructor can now take Koalas `Series`. (#470)
- A lot of missing properties and functions are added to `Series.dt` property (#478)
",164026325
1731,False,False,2019-06-12T10:18:53Z,2019-06-12T10:49:35Z,"We added new functionalities, improved the documentation and fixed some bugs in the past week. Also, `koalas.sql` has an improvement (#448). Now Koalas DataFrame and some regular Python types can be used directly in SQL, for instance, as below:

```python
>>> mydf = ks.range(10)
>>> x = range(4)
>>> ks.sql(""SELECT * from {mydf} WHERE id IN {x}"")
   id
0   0
1   1
2   2
3   3
```

We also added the following features:

koalas

- read_spark_io (#447)
- read_table (#449)
- read_delta (#456)

koalas.DataFrame:

- append (#388)
- from_records (#436)
- to_parquet (#443)
- to_spark_io (#447)
- to_table (#449)
- cache (#397)
- to_delta (#456)
- drop_duplicates (#458)

koalas.Series:

- append (#388)
- str (#429)
- plot (#294)
- hist (#294)

Along with the following improvements:

- mean, sum, skew, kurtosis, min, max, std and var at DataFrame and Series supports `numeric_only` argument (#422)",164026325
1732,False,False,2019-06-05T09:23:05Z,2019-06-05T09:39:33Z,"We refined the internal structure, improved the documentation and added new functionalities in the past week.

We also added the following features:

koalas:

- read_clipboard (#430)
- read_excel (#430)
- read_html (#430)

koalas.DataFrame:

- at (#384)
- nunique (#346)
- add_prefix (#414)
- add_suffix (#414)
- add (#427)
- radd (#427)
- div (#427)
- divide (#427)
- rdiv (#427)
- truediv (#427)
- rtruediv (#427)
- mul (#427)
- multiply (#427)
- rmul (#427)
- sub (#427)
- substract (#427)
- rsub (#427)

koalas.Series:

- at (#384)
- nunique (#346)
- add_prefix (#414)
- add_suffix (#414)
- transform (#428)
",164026325
1733,False,False,2019-05-29T08:20:16Z,2019-05-29T08:23:34Z,"We added basic integration with MLflow, so that models that have the `pyfunc` flavor (which is, most of them), can be loaded as predictors. These predictors then works on both pandas and koalas dataframes with no code change. See the documentation example for details. (#353)

We also added the following features:

koalas.DataFrame:

- sort_index (#380)
- applymap (#390)
- empty (#391)

koalas.Series:

- sort_values (#366)
- to_list (#379)
- sort_index (#380)
- pipe (#392)
- map (#389)
- empty (#391)
- add (#401)
- radd (#401)
- div (#401)
- divide (#401)
- rdiv (#401)
- truediv (#401)
- rtruediv (#401)
- mul (#401)
- multiply (#401)
- rmul (#401)
- sub (#401)
- substract (#401)
- rsub (#401)

Along with the following improvements:

- `DataFrame.merge` function now supports `left_on` and `right_on` arguments. (#381)
- `DataFrame.describe` function now supports `percentiles` argument. (#378)
",164026325
1734,False,False,2019-05-22T08:30:00Z,2019-05-22T08:39:39Z,"We refined the package management and pushed to conda-forge as well as PyPI. Now we can install Koalas with the conda package manager:

```sh
conda install koalas -c conda-forge
```

We also added the following features:

koalas:

- concat (#348)

koalas.DataFrame:

- astype (#349)
- to_records (#298)
- size (#356)
- iloc (#364)
- describe (#375)

koalas.Series:

- to_json (#358)
- to_csv (#358)
- dtypes (#355)
- size (#356)
- to_excel (#361)
- iloc (#364)
- all (#359)
- any (#359)
- dt (#295, #372)
- describe (#375)

Along with the following improvements:

- Explicitly marked functions deprecated in pandas which we won't support without a special reason. (#342)
- Introduced `Index`/`MultiIndex` corresponding to pandas', instead of reusing `Series`. (#341)
",164026325
1735,False,False,2019-05-15T06:39:38Z,2019-05-15T07:17:33Z,"We rapidly improved Koalas in documentation and added new functionalities in the past week. As of this release, all functions are documented. We also added the following features:

koalas:

  - range (#254) - for generating a distributed sequence of data
  - sql (#256) - for running SQL queries

koalas.DataFrame:

  - merge (#264)
  - to_json (#238)
  - to_csv (#239)
  - to_excel (#288)
  - to_clipboard (#257)
  - clip (#297)
  - to_latex (#297)

koalas.Series:

  - unique (#249)
  - to_clipboard (#257)
  - to_latex (#297)
  - clip (#297)
  - fillna (#317)
  - is_unique (#325)
  - sample (#327)

Along with the following improvements:

- Design Principles and Contribution Guide (#246, #255)
- DataFrame.drop now supports columns parameter (#253)
- repr and repr_html improvements (#258) - only shows top 1000 when the number of values/rows in DataFrame and Series exceed 1000.

",164026325
1736,False,False,2019-05-07T04:08:31Z,2019-05-07T04:27:31Z,"We fixed a critical bug for Python 3.5 introduced in v0.2.0. #241 

Also we have added the following features:

koalas.DataFrame:

- isin
- to_dict

koalas.Series:

- isin
- to_dict

and improvements:

koalas.Series:

- `__add__` and `__radd__` now supports string concatenation

koalas.groupby.GroupBy:

- `agg()` now preserves the group keys as indices

and a lot of code and document cleanups.",164026325
1737,False,False,2019-05-02T00:46:46Z,2019-05-02T00:56:36Z,"We have implemented a lot of major functionalities in the past week. Here's a summary of what's new in release v0.2.0.

spark.DataFrame:

- to_koalas is monkey patched into Spark's DataFrame API when koalas package is imported

koalas.DataFrame:

- count
- corr
- dtypes
- groupby
- sort_values now supports ascending, na_position, and inplace parameters 
- to_numpy
- to_pandas (with toPandas as an alias for compatibility with Spark)
- to_string
- Allow direct literal assignment to create a new column
- Various stats functions now work with boolean type
- In notebooks or REPL, automatically display the content of the DataFrame, similar to pandas

koalas.Series:

- alias (as an alias for rename function)
- count
- groupby
- to_numpy
- to_pandas (with toPandas as an alias for compatibility with Spark)
- to_string
- fillna
- Various stats functions now work with boolean type
- In notebooks or REPL, automatically display the content of the Series, similar to pandas

Significantly improved documentation of the project.

Last but not least, we have done some major refactoring of the codebase and its infrastructure to make it more amenable to changes in the future, e.g.

- Now koalas.DataFrame wraps around a Spark DataFrame, rather than directly monkey patching all methods.
- Doctests are enabled and can be run directly in PyCharm
- Mypy type hint linter is added
- Switched from nose to pytest for test infrastructure.
- Introduced utility methods to support older versions of pandas. #210 
- Code coverage report

",164026325
1738,False,False,2019-04-23T16:53:17Z,2019-04-23T17:03:07Z,We rewrote the internals of Koalas to make it more extensible for upcoming features. We also laid down the foundation for API reference docs in this release.,164026325
1739,False,True,2019-04-19T12:03:14Z,2019-04-19T17:55:17Z,"This version significantly expands the amount of functions available. It is still meant to be a technology preview, and users are encouraged to report issues that they encounter with their current pandas code.

Noteworthy features:

 - indexing is now supported
 - slicing and accessing columns is much improved
 - most of the methods are accessible as stubs
 - support for N/A (fillna, dropna, etc.) has been added

We thank all the contributors who have contributed to this release.

",164026325
1740,False,True,2019-03-26T08:26:26Z,2019-03-26T13:50:39Z,"This is the initial release outside Databricks.

This release is meant to be a technology preview. See the README.md file for more information.",164026325
1741,False,False,2020-03-06T23:23:04Z,2020-03-13T14:14:26Z,Monir bug fix with `print` issues and `data_loader` (#1080),178626720
1742,False,True,2020-03-06T21:19:51Z,2020-03-10T23:13:44Z,"## Overview

This is the first joint release between [pytorch-bearer](http://www.pytorchbearer.org) and Lightning, here we come ...

This release adds support for training models on Tensor Processing Units (TPU). We can now train models on GPUs and TPUs by changing a single parameter in `Trainer` (see docs). We are also bringing the flexibility of Bearer into Lightning by allowing for arbitrary user-defined callbacks, see [docs](https://pytorch-lightning.readthedocs.io/en/0.7.0/callbacks.html). 

We are also including a profiler that allows Lightning users to identify training bottlenecks (see [docs](https://pytorch-lightning.readthedocs.io/en/0.7.0/profiler.html)).

This release also includes automatic sampler setup depending on the selected backend, Lightning configures the sampler correctly (no need for user input). 

The loggers have also been extended to support for multiple concurrent loggers to be passed to `Trainer` as an iterable, [docs](https://pytorch-lightning.readthedocs.io/en/0.7.0/loggers.html) and added support for step-based [learning rate scheduling](https://pytorch-lightning.readthedocs.io/en/0.7.0/optimizers.html#learning-rate-scheduling).

At last, lots of bug fixes (see below).

## Detail changes

### Added

- Added automatic sampler setup. Depending on DDP or TPU, lightning configures the sampler correctly (user needs to do nothing)  (#926)
- Added `reload_dataloaders_every_epoch=False` flag for trainer. Some users require reloading data every epoch  (#926)
- Added `progress_bar_refresh_rate=50` flag for trainer. The refresh rate on notebooks  (#926)
- Updated governance docs
- Added a check to ensure that the metric used for early stopping exists before training commences (#542)
- Added `optimizer_idx` argument to `backward` hook (#733)
- Added `entity` argument to `WandbLogger` to be passed to `wandb.init` (#783)
- Added a tool for profiling training runs (#782)
- Improved flexibility for naming of TensorBoard logs, can now set `version` to a `str` to just save to that directory, and use `name=''` to prevent experiment-name directory (#804)
- Added option to specify `step` key when logging metrics (#808)
- Added `train_dataloader`, `val_dataloader` and `test_dataloader` arguments to `Trainer.fit()`, for alternative data parsing (#759)
- Added Tensor Processing Unit (TPU) support (#868)
- Added semantic segmentation example (#751, #876, #881)
- Split callbacks in multiple files (#849)
- Support for user-defined callbacks (#889 and #950)
- Added support for multiple loggers to be passed to `Trainer` as an iterable (e.g. list, tuple, etc.) (#903)
- Added support for step-based learning rate scheduling (#941)
- Added support for logging hparams as `dict` (#1029)
- Checkpoint and early stopping now work without val. step (#1041)
- Support graceful training cleanup after Keyboard Interrupt (#856, #1019)
- Added type hints for function arguments (#912)
- Added default `argparser` for `Trainer` (#952, #1023)
- Added TPU gradient clipping (#963)
- Added max/min number of steps in Trainer (#728)


### Changed

- Changed default TQDM to use `tqdm.auto` for prettier outputs in IPython notebooks (#752)
- Changed `pytorch_lightning.logging` to `pytorch_lightning.loggers` (#767)
- Moved the default `tqdm_dict` definition from Trainer to `LightningModule`, so it can be overridden by the user (#749)
- Moved functionality of `LightningModule.load_from_metrics` into `LightningModule.load_from_checkpoint` (#995)
- Changed Checkpoint path parameter from `filepath` to `dirpath` (#1016)
- Freezed models `hparams` as `Namespace` property (#1029)
- Dropped `logging` config in package init (#1015)
- Renames model steps (#1051)
    * `training_end` >> `training_epoch_end`
    * `validation_end` >> `validation_epoch_end`
    * `test_end` >> `test_epoch_end`
- Refactor dataloading, supports infinite dataloader (#955)
- Create single file in `TensorBoardLogger` (#777)

### Deprecated

- Deprecated `pytorch_lightning.logging` (#767)
- Deprecated `LightningModule.load_from_metrics` in favour of `LightningModule.load_from_checkpoint` (#995, #1079)
- Deprecated `@data_loader` decorator  (#926)
- Deprecated model steps `training_end`, `validation_end` and `test_end` (#1051, #1056)

### Removed

- Removed dependency on `pandas` (#736)
- Removed dependency on `torchvision` (#797)
- Removed dependency on `scikit-learn` (#801)

### Fixed

- Fixed a bug where early stopping `on_end_epoch` would be called inconsistently when `check_val_every_n_epoch == 0` (#743)
- Fixed a bug where the model checkpoint didn't write to the same directory as the logger (#771)
- Fixed a bug where the `TensorBoardLogger` class would create an additional empty log file during fitting (#777)
- Fixed a bug where `global_step` was advanced incorrectly when using `accumulate_grad_batches > 1` (#832)
- Fixed a bug when calling `self.logger.experiment` with multiple loggers (#1009)
- Fixed a bug when calling `logger.append_tags` on a `NeptuneLogger` with a single tag (#1009)
- Fixed sending back data from `.spawn` by saving and loading the trained model in/out of the process (#1017)
- Fixed port collision on DDP (#1010)
- Fixed/tested pass overrides (#918)
- Fixed comet logger to log after train (#892)
- Remove deprecated args to learning rate step function (#890)

## Contributors

@airglow, @akshaykvnit, @AljoSt, @AntixK, @awaelchli, @baeseongsu, @bobkemp, @Borda, @calclavia, @Calysto, @djbyrne, @ethanwharris, @fdelrio89, @hadim, @hanbyul-kim, @jeremyjordan, @kuynzereb, @luiscape, @MattPainter01, @neggert, @onkyo14taro, @peteriz, @shoarora, @SkafteNicki, @smallzzy, @srush, @theevann, @tullie, @williamFalcon, @xeTaiz, @xssChauhan, @yukw777

_If we forgot someone due to not matching commit email with GitHub account, let us know :]_",178626720
1743,False,False,2020-01-21T22:17:40Z,2020-01-21T22:51:10Z,"This release focused on a ton of bug fixes, small optimizations to training but most importantly, clean new docs!

## Major changes

We have released [New documentation](https://pytorch-lightning.readthedocs.io/en/0.6.0/), please bear with us as we fix broken links and patch in missing pieces. 
This project moved to new org [PyTorchLightning](https://github.com/PyTorchLightning), so no longer the root sits on WilliamFalcon/PyTorchLightning. 
We have added own custom Tensorboard logger as default logger. 
We have upgrade Continues Integration to speed up the automatic testing. 
We have fixed GAN training - supporting multiple optimizers.

## Complete changelog

### Added

- Added support for resuming from a specific checkpoint via `resume_from_checkpoint` argument (#516)
- Added support for `ReduceLROnPlateau` scheduler (#320)
- Added support for Apex mode `O2` in conjunction with Data Parallel (#493)
- Added option (`save_top_k`) to save the top k models in the `ModelCheckpoint` class (#128)
- Added `on_train_start` and `on_train_end` hooks to `ModelHooks` (#598)
- Added `TensorBoardLogger` (#607)
- Added support for weight summary of model with multiple inputs (#543)
- Added `map_location` argument to `load_from_metrics` and `load_from_checkpoint` (#625)
- Added option to disable validation by setting `val_percent_check=0` (#649)
- Added `NeptuneLogger` class (#648)
- Added `WandbLogger` class (#627)


### Changed

- Changed the default progress bar to print to stdout instead of stderr (#531)
- Renamed `step_idx` to `step`, `epoch_idx` to `epoch`, `max_num_epochs` to `max_epochs` and `min_num_epochs` to `min_epochs` (#589)
- Renamed several `Trainer` atributes:  (#567)
	* `total_batch_nb` to `total_batches`,
	* `nb_val_batches` to `num_val_batches`,
	* `nb_training_batches` to `num_training_batches`,
	* `max_nb_epochs` to `max_epochs`,
	* `min_nb_epochs` to `min_epochs`,
	* `nb_test_batches` to `num_test_batches`,
	* and `nb_val_batches` to `num_val_batches` (#567)
- Changed gradient logging to use parameter names instead of indexes (#660)
- Changed the default logger to `TensorBoardLogger` (#609)
- Changed the directory for tensorboard logging to be the same as model checkpointing (#706)


### Deprecated

- Deprecated `max_nb_epochs` and `min_nb_epochs` (#567)
- Deprecated the `on_sanity_check_start` hook in `ModelHooks` (#598)


### Removed

- Removed the `save_best_only` argument from `ModelCheckpoint`, use `save_top_k=1` instead (#128)


### Fixed

- Fixed a bug which ocurred when using Adagrad with cuda (#554)
- Fixed a bug where training would be on the GPU despite setting `gpus=0` or `gpus=[]` (#561)
- Fixed an error with `print_nan_gradients` when some parameters do not require gradient (#579)
- Fixed a bug where the progress bar would show an incorrect number of total steps during the validation sanity check when using multiple validation data loaders (#597)
- Fixed support for PyTorch 1.1.0 (#552)
- Fixed an issue with early stopping when using a `val_check_interval < 1.0` in `Trainer` (#492)
- Fixed bugs relating to the `CometLogger` object that would cause it to not work properly (#481)
- Fixed a bug that would occur when returning `-1` from `on_batch_start` following an early exit or when the batch was `None` (#509)
- Fixed a potential race condition with several processes trying to create checkpoint directories (#530)
- Fixed a bug where batch 'segments' would remain on the GPU when using `truncated_bptt > 1` (#532)
- Fixed a bug when using `IterableDataset` (#547](https://github.com/PyTorchLightning/pytorch-lightning/pull/547))
- Fixed a bug where `.item` was called on non-tensor objects (#602)
- Fixed a bug where `Trainer.train` would crash on an uninitialized variable if the trainer was run after resuming from a checkpoint that was already at `max_epochs` (#608)
- Fixed a bug where early stopping would begin two epochs early (#617)
- Fixed a bug where `num_training_batches` and `num_test_batches` would sometimes be rounded down to zero (#649)
- Fixed a bug where an additional batch would be processed when manually setting `num_training_batches` (#653)
- Fixed a bug when batches did not have a `.copy` method (#701)
- Fixed a bug when using `log_gpu_memory=True` in Python 3.6 (#715)
- Fixed a bug where checkpoint writing could exit before completion, giving incomplete checkpoints (#689)
- Fixed a bug where `on_train_end` was not called when early stopping (#723)


## Contributors

@akhti, @alumae, @awaelchli, @Borda, @borisdayma, @ctlaltdefeat, @dreamgonfly, @elliotwaite, @fdiehl, @goodok, @haossr, @HarshSharma12, @Ir1d, @jakubczakon, @jeffling, @kuynzereb, @MartinPernus, @matthew-z, @MikeScarp, @mpariente, @neggert, @rwesterman, @ryanwongsa, @schwobr, @tullie, @vikmary, @VSJMilewski, @williamFalcon, @YehCF

If we forgot someone due to not matching commit email with GitHub account, let us know :]",178626720
1744,False,False,2019-11-06T19:51:49Z,2019-11-06T20:04:32Z,"# Generalization release
The main focus of this release was on adding flexibility and generalization to support broad research cases.

Next release will be Dec 7th (every 30 days).

## Internal Facebook support
@lorenzoFabbri @tullie @myleott @ashwinb  @shootingsoul @vreis
These features were added to support FAIR, FAIAR and broader ML across other FB teams.

In general, we can expose any part that isn't exposed yet where someone might want to override the lightning implementation.

1. Added truncated back propagation through time support (thanks @tullie).

```python
Trainer(truncated_bptt_steps=2)
```

2. Added iterable datasets. 

```python
# return iterabledataset
def train_dataloader(...):
    ds = IterableDataset(...)
    return Dataloader(ds)

# set validation to a fix number of batches
# (checks val every 100 train epochs)
Trainer(val_check_interval=100)
```

3. Add ability to customize backward and other training parts:
```python
    def backward(self, use_amp, loss, optimizer):
        """"""
        Override backward with your own implementation if you need to
        :param use_amp: Whether amp was requested or not
        :param loss: Loss is already scaled by accumulated grads
        :param optimizer: Current optimizer being used
        :return:
        """"""
        if use_amp:
            with amp.scale_loss(loss, optimizer) as scaled_loss:
                scaled_loss.backward()
        else:
            loss.backward()
```

3. DDP custom implementation support (override these hooks):
```python
    def configure_ddp(self, model, device_ids):
        """"""
        Override to init DDP in a different way or use your own wrapper.
        Must return model.
        :param model:
        :param device_ids:
        :return: DDP wrapped model
        """"""
        model = LightningDistributedDataParallel(
            model,
            device_ids=device_ids,
            find_unused_parameters=True
        )
        return model

    def init_ddp_connection(self, proc_rank, world_size):
        """"""
        Connect all procs in the world using the env:// init
        Use the first node as the root address
        """"""

        # use slurm job id for the port number
        # guarantees unique ports across jobs from same grid search
        try:
            # use the last 4 numbers in the job id as the id
            default_port = os.environ['SLURM_JOB_ID']
            default_port = default_port[-4:]

            # all ports should be in the 10k+ range
            default_port = int(default_port) + 15000

        except Exception as e:
            default_port = 12910

        # if user gave a port number, use that one instead
        try:
            default_port = os.environ['MASTER_PORT']
        except Exception:
            os.environ['MASTER_PORT'] = str(default_port)

        # figure out the root node addr
        try:
            root_node = os.environ['SLURM_NODELIST'].split(' ')[0]
        except Exception:
            root_node = '127.0.0.2'

        root_node = self.trainer.resolve_root_node_address(root_node)
        os.environ['MASTER_ADDR'] = root_node
        dist.init_process_group('nccl', rank=proc_rank, world_size=world_size)
```

4. Support for your own apex init or implementation.
```python
    def configure_apex(self, amp, model, optimizers, amp_level):
        """"""
        Override to init AMP your own way
        Must return a model and list of optimizers
        :param amp:
        :param model:
        :param optimizers:
        :param amp_level:
        :return: Apex wrapped model and optimizers
        """"""
        model, optimizers = amp.initialize(
            model, optimizers, opt_level=amp_level,
        )

        return model, optimizers
```

5. DDP2 implementation (inspired by parlai and @stephenroller).  
DDP2 acts as DP in the node and DDP across nodes. 
As a result, an optional method is introduced ```training_end```  
where you can use the outputs of ```training_step``` (performed on each GPU with a portion of the batch),
to do something with the outputs of all batches on the node (ie: negative sampling).
```python
Trainer(distributed_backend='ddp2')  

def training_step(...):
    # x is 1/nb_gpus of the full batch
    out = model(x)
    return {'out': out}

def training_end(self, outputs):
     # all_outs has outs from ALL gpus 
     all_outs = outputs['out']
     loss = softmax(all_outs)
     return {'loss': loss}
```

## Logging
- More logger diversity including Comet.ml.
- Versioned logs for all loggers.   
- switched from print to logging

## progress bar
- now the progress bar has a full bar for the full train + val epochs and a second bar visible only during val.

## loading
- checkpoints now store hparams
- no need to pass tags.csv to restore state because it lives in the checkpoint.

## Slurm resubmit with apex + ddp
- Fixes issue of ddp restore weights blowing out GPU memory (load on cpu first then GPU).
- Saves apex states automatically and restores it for a checkpoint.

## Refactoring
- internal code made modular through Mixins for ease of readability and to minimize merge conflicts.

## Docs
- Tons of doc improvements.

## Thanks!
Thank you to the amazing contributor community! Especially @neggert  and @Borda for reviewing PRs and taking care of a good number of Github issues. The community is thriving and has really embraced making Lightning better.

Great job everyone!



",178626720
1745,False,False,2019-10-05T21:09:30Z,2019-10-05T21:10:04Z,"# 0.5.1   

### Simpler interface  
All trainers now have a default logger, early stopping and checkpoint object. To modify the behavior, pass in your own versions of those. 

- Removed collisions with logger versions by tying it to job id.

### Features
- Added new DDP implementation. It uses DP in a node but allows multiple nodes. Useful for models which need negative samples, etc...
```python
Trainer(distributed_backend='ddp2')
```   

- support for LBFGS. If you pass in LBFGS Lightning handles the closure for you automatically.
- No longer need to set master port, Lightning does it for you using the job id.

# Minor changes   
- training_step and validation_end now return two separate dicts, one for the progress bar and one for logging.

- Added options to memory printing: 'min_max' logs only the max/min memory use. 'all' logs all the GPUs on the root node.  ",178626720
1746,False,False,2019-09-26T14:42:24Z,2019-09-26T14:47:58Z,"This release has breaking API changes. See #124 for all details. 
Syntax changes are:   
```
in trainer options use: train, test, val  
for data: val_dataloader, test_dataloader, train_dataloader
data_batch -> batch    
prog -> progress   
gradient_clip -> gradient_clip_val    
add_log_row_interval -> row_log_interval
```",178626720
1747,False,False,2019-09-16T14:50:59Z,2019-09-16T14:54:49Z,"This release does the following: 

- Moves SLURM resubmit from test-tube to PL (which removes the need for cluster parameter).
- Cluster checkpoint done by Lightning now (not test-tube). Also doesn't require a checkpoint object to restore weights when on cluster.     
- Loads all models on CPU when restoring weights to avoid OOM issues in PyTorch. User now needs to move to GPU manually. However, if using Lightning, lightning will move to correct GPUs automatically.   
- Fixes various subtle bugs in DDP implementation.  
- documentation updates
",178626720
1748,False,False,2019-08-12T20:09:03Z,2019-08-12T20:11:24Z,"- validation_step, val_dataloader are now optional.   
- enabled multiple dataloaders for validation.    
- support for latest test-tube logger optimized for PT 1.2.0.   
- lr_scheduler now activated after epoch    ",178626720
1749,False,False,2019-08-08T16:32:45Z,2019-08-08T16:39:45Z,"# 0.4.0    
0.4.0 is the first public release after a short period testing with public users. Thanks for all the help ironing out bugs to get Lightning to run on everything from notebooks to local to server machines.

#### This release includes:
- Extensively tested code.   
- Cleaner API to accommodate the various research use cases   

#### New features    
- No need for experiment object in trainer.   
- Training continuation (not just weights, but also epoch, global step, etc...) 
    - if the folder the checkpoint callback uses has weights, it loads the last weights automatically.
- training step and validation step don't reduce outputs automatically anymore. This fixes issues with reducing generated outputs for example (images, text).   
- 16-bit can now be used with a single GPU (no DP or DDP in this case). bypasses issue with NVIDIA apex and PT compatibility for DP+16-bit training. 



",178626720
1750,False,False,2019-07-26T23:11:32Z,2019-07-26T23:13:15Z,"- Extra tests for CPU models.
- Experiment object is process-safe, it will only write from process_rank=0",178626720
1751,False,False,2019-07-25T16:22:50Z,2019-07-25T17:28:42Z,"Simplified data loader.

Added a decorator to do lazy loading internally:

Old:  
```python
@property
def tng_dataloader(self):
      if self._tng_dataloader is None:
               self._tng_dataloader = DataLoader(...)
      return self.tng_dataloder
```

Now:

```python
@ptl.data_loader
def tng_dataloader(self):
      return DataLoader(...)
````",178626720
1752,False,False,2019-07-25T02:08:02Z,2019-07-25T02:09:41Z,"Fully tested!

Includes:
- Code coverage (99%)
- Full tests that run multiple models in different configs
- Full tests that test specific functionality in trainer.",178626720
1753,False,False,2020-03-18T14:38:14Z,2020-03-18T14:57:29Z,"# Changelog

## 0.9.8

Released on Mar 18, 2020.

### Features

- None

### Enhancements

- Update Cloud config name for heartbeat settings - [#2081](https://github.com/PrefectHQ/prefect/pull/2081)
- Add examples to Interactive API Docs - [#2122](https://github.com/PrefectHQ/prefect/pull/2122)
- Allow users to skip Docker healthchecks - [#2150](https://github.com/PrefectHQ/prefect/pull/2150)
- Add exists, read, and write interfaces to Result [#2139](https://github.com/PrefectHQ/prefect/issues/2139)
- Add Cloud UI links to Slack Notifications - [#2112](https://github.com/PrefectHQ/prefect/issues/2112)

### Task Library

- None

### Fixes

- Fix S3ResultHandler use of a new boto3 session per thread - [#2108](https://github.com/PrefectHQ/prefect/issues/2108)
- Fix issue with stateful function reference deserialization logic mutating state - [#2159](https://github.com/PrefectHQ/prefect/pull/2159)
- Fix issue with `DateClock` serializer - [#2166](https://github.com/PrefectHQ/prefect/issues/2166)
- Fix issue with scheduling required parameters - [#2166](https://github.com/PrefectHQ/prefect/issues/2166)

### Deprecations

- Deprecate cache\_\* and result_handler options on Task and Flow objects [#2140](https://github.com/PrefectHQ/prefect/issues/2140)

### Breaking Changes

- None

### Contributors

- [alexisprince1994](https://github.com/alexisprince1994)",139199684
1754,False,False,2020-03-04T20:28:18Z,2020-03-04T20:33:49Z,"# Changelog

## 0.9.7

Released on Mar 4, 2020.

### Fixes

- Change `task.log_stdout` retrieval from task runner to `getattr` in order to preserve running flows of older `0.9.x` versions - [#2120](https://github.com/PrefectHQ/prefect/pull/2120)
",139199684
1755,False,False,2020-03-04T15:58:56Z,2020-03-04T16:01:06Z,"# Changelog

## 0.9.6

Released on Mar 4, 2020.

### Features

- Add new diagnostics utility to assist in troubleshooting issues - [#2062](https://github.com/PrefectHQ/prefect/pull/2062)
- Add a jira_notification state handler to create jira tickets for failed tasks or flows - [#1861](https://github.com/PrefectHQ/prefect/pull/1861)
- Add support for Python 3.8 - [#2080](https://github.com/PrefectHQ/prefect/pull/2080)

### Enhancements

- Add PIN 15 (skip refactor) - [#2070](https://github.com/PrefectHQ/prefect/issues/2070)
- Update docs and docstrings related to Result Handlers - [#1792](https://github.com/PrefectHQ/prefect/issues/1792)
- Add volume option to Docker Agent - [#2013](https://github.com/PrefectHQ/prefect/issues/2013)
- `DaskKubernetesEnvironment` now elevates important autoscaling logs as well as possible Kubernetes issues - [#2089](https://github.com/PrefectHQ/prefect/pull/2089)
- Add optional `scheduler_logs` kwarg to the`DaskKubernetesEnvironment` - [#2089](https://github.com/PrefectHQ/prefect/pull/2089)
- Add ERROR log if heartbeat process dies - [#2097](https://github.com/PrefectHQ/prefect/issues/2097)
- Enable stdout logging from inside a task with the kwarg `log_stdout=True` - [#2092](https://github.com/PrefectHQ/prefect/pull/2092)
- Direct links to Cloud flows and flow runs now shown on creation time - [#2109](https://github.com/PrefectHQ/prefect/pull/2109)
- Update docs related to using Context - [#2077](https://github.com/PrefectHQ/prefect/issues/2077)

### Task Library

- Fix expanding of `V1DeleteOptions` kwargs for Kubernetes tasks - [#2083](https://github.com/PrefectHQ/prefect/pull/2083)

### Fixes

- Fix `extra_loggers` config variable not being able to be set via environment variable - [#2089](https://github.com/PrefectHQ/prefect/pull/2089)
- Fix environments not passing down their `extra_loggers` to any created infrastructure - [#2089](https://github.com/PrefectHQ/prefect/pull/2089)
- Don't mutate data when serializing or deserializing - [#2098](https://github.com/PrefectHQ/prefect/issues/2098)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- [Romain Thalineau](https://github.com/romaintha)
",139199684
1756,False,False,2020-02-20T21:51:39Z,2020-02-21T20:27:54Z,"# Changelog

## 0.9.5

Released on Feb 21, 2020.

### Features

- None

### Enhancements

- Better exception for unsubscriptable mapping arguments - [#1821](https://github.com/PrefectHQ/prefect/issues/1821)
- Add DaskGateway tip to docs - [#1959](https://github.com/PrefectHQ/prefect/issues/1959)
- Upload package to PyPI on tag push to master - [#2030](https://github.com/PrefectHQ/prefect/issues/2030)
- Improve package import time - [#2046](https://github.com/PrefectHQ/prefect/issues/2046)

### Task Library

- Fix `V1DeleteOptions` call for Kubernetes tasks - [#2050](https://github.com/PrefectHQ/prefect/pull/2050)
- Add kwargs to `V1DeleteOptions` for Kubernetes tasks - [#2051](https://github.com/PrefectHQ/prefect/pull/2051)

### Fixes

- Ensure microseconds are respected on `start_date` provided to CronClock - [#2031](https://github.com/PrefectHQ/prefect/pull/2031)
- Fix duplicate Client connections when using `--logs` flag from `run cloud` CLI command - [#2056](https://github.com/PrefectHQ/prefect/pull/2056)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- [Romain Thalineau](https://github.com/romaintha)",139199684
1757,False,False,2020-02-14T04:25:21Z,2020-02-14T15:05:42Z,"# Changelog

## 0.9.4

Released on Feb 14, 2020.

### Features

- None

### Enhancements

- Add incremental tutorial - [#1953](https://github.com/PrefectHQ/prefect/issues/1953)
- Improve error handling for unsupported callables - [#1993](https://github.com/PrefectHQ/prefect/pull/1993)
- Accept additional `boto3` client parameters in S3 storage - [#2000](https://github.com/PrefectHQ/prefect/pull/2000)
- Add optional `version_group_id` kwarg to `create_flow_run` for a stable API for flow runs - [#1987](https://github.com/PrefectHQ/prefect/issues/1987)
- Add `extra_loggers` logging configuration for non-Prefect logs in stdout and cloud - [#2010](https://github.com/PrefectHQ/prefect/pull/2010)

### Task Library

- None

### Fixes

- Ensure `ifelse` casts its condition to `bool` prior to evaluation - [#1991](https://github.com/PrefectHQ/prefect/pull/1991)
- Do not perform `ast.literal_eval` on cpu and memory task_definition kwargs for Fargate Agent - [#2010](https://github.com/PrefectHQ/prefect/pull/2010)
- Fix new agent processing with Threadpool causing problem for Fargate Agent with task revisions enabled - [#2022](https://github.com/PrefectHQ/prefect/pull/2022)

### Deprecations

- None

### Breaking Changes

- Remove Airflow Tasks - [#1992](https://github.com/PrefectHQ/prefect/pull/1992)

### Contributors

- [Giorgio Pellero](https://github.com/trapped)
- [Braun Reyes](https://github.com/braunreyes)",139199684
1758,False,False,2020-02-05T15:39:04Z,2020-02-05T16:17:02Z,"# Changelog

## 0.9.3 

Released on Feb 05, 2020.

### Features

- None

### Enhancements

- Improve heartbeat functionality to be robust across platforms - [#1973](https://github.com/PrefectHQ/prefect/pull/1973)
- Run storage healthchecks on other options besides Docker - [1963](https://github.com/PrefectHQ/prefect/pull/1963)
- Cloud logger now attempts to elevate logger errors to flow run logs - [#1961](https://github.com/PrefectHQ/prefect/pull/1961)
- Attach Flow and Task attributes to LogRecords - [#1938](https://github.com/PrefectHQ/prefect/issues/1938)

### Task Library

- None

### Fixes

- Fix uncaught Fargate Agent kwarg parse SyntaxError from `literal_eval` - [#1968](https://github.com/PrefectHQ/prefect/pull/1968)
- Fix FargateTaskEnvironment passing empty auth token to run task - [#1976](https://github.com/PrefectHQ/prefect/pull/1976)
- Fix imagePullSecrets not being automatically passed to jobs created by Kubernetes Agent - [#1982](https://github.com/PrefectHQ/prefect/pull/1982)

### Deprecations

- None

### Breaking Changes

- Remove cancellation hooks - [#1973](https://github.com/PrefectHQ/prefect/pull/1973)

### Contributors

- None",139199684
1759,False,False,2020-01-30T19:22:41Z,2020-01-30T19:30:40Z,"# Changelog

## 0.9.2

Released on Jan 30, 2020.

### Features

- Allow for parameter defaults to vary based on clock - [#1946](https://github.com/PrefectHQ/prefect/pull/1946)

### Enhancements

- More graceful handling of Agents competing for work - [#1956](https://github.com/PrefectHQ/prefect/issues/1956)

### Task Library

- None

### Fixes

- Eliminated possible duplicate flow run issue in all agents - [#1956](https://github.com/PrefectHQ/prefect/issues/1956)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- None",139199684
1760,False,False,2020-01-24T19:51:27Z,2020-01-24T20:14:18Z,"# Changelog

## 0.9.1

Released on Jan 24, 2020.

### Features

- None

### Enhancements

- Docker daemon reconnect attempts + exit on heartbeat failure -[#1918](https://github.com/PrefectHQ/prefect/pull/1918)
- More responsive agent shutdown - [#1921](https://github.com/PrefectHQ/prefect/pull/1921)
- Background all agent flow deployment attempts - [#1928](https://github.com/PrefectHQ/prefect/pull/1928)
- Add show_flow_logs to Docker agent [#1929](https://github.com/PrefectHQ/prefect/issues/1929)
- Add per-task checkpointing opt-out - [#1933](https://github.com/PrefectHQ/prefect/pull/1933)
- The Task 'checkpoint' kwarg will no longer be deprecated to allow opt-out - [#1933](https://github.com/PrefectHQ/prefect/pull/1933)

### Task Library

- None

### Fixes

- Fix the Fargate Agent not parsing kwargs as literals - [#1926](https://github.com/PrefectHQ/prefect/pull/1926)
- Fix issue with result handler default persisting from initialization - [#1936](https://github.com/PrefectHQ/prefect/issues/1936)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- None
",139199684
1761,False,False,2020-01-15T14:40:29Z,2020-01-15T16:03:00Z,"# Changelog

For a high-level description of the new features, please check out our [blog post](https://medium.com/the-prefect-blog/prefect-0-9-0-unlocking-cloud-27e05a96e52a) on this release

## 0.9.0

Released on Jan 15, 2020.

### Features

- Added the ability to leverage native ECS task definition revisions for flow versions in Fargate agent - [#1870](https://github.com/PrefectHQ/prefect/pull/1870)
- Added the ability to pull in kwargs per flow version from S3 on flow submission in Fargate agent - [#1870](https://github.com/PrefectHQ/prefect/pull/1870)
- Add sensible default result handlers to non-Docker storage options - [#1888](https://github.com/PrefectHQ/prefect/issues/1888)

### Enhancements

- Allow for task looping to beyond Python's maximum recursion depth - [#1862](https://github.com/PrefectHQ/prefect/pull/1862)
- Prevent duplication of stdout logs from multiple instantiated agents - [#1866](https://github.com/PrefectHQ/prefect/pull/1866)
- Allow intervals less than 60 seconds in `IntervalClock`s - [#1880](https://github.com/PrefectHQ/prefect/pull/1880)
- Introduce new `Secret.exists` method for checking whether a Secret is available - [#1882](https://github.com/PrefectHQ/prefect/pull/1882)
- Introduce new `-e` CLI options on agent start commands to allow passing environment variables to flow runs - [#1878](https://github.com/PrefectHQ/prefect/issues/1878)
- Stop persisting `None` when calling result handlers - [#1894](https://github.com/PrefectHQ/prefect/pull/1894)
- Change Cancelled state to indicate Finished instead of Failed - [#1903](https://github.com/PrefectHQ/prefect/pull/1903)
- All States now store `cached_inputs` for easier recovery from failure - [#1898](https://github.com/PrefectHQ/prefect/issues/1898)
- Always checkpoint tasks which have result handlers - [#1898](https://github.com/PrefectHQ/prefect/issues/1898)


### Task Library

- Remove implicit requirement that Google Tasks use Prefect Cloud Secrets - [#1882](https://github.com/PrefectHQ/prefect/pull/1882)

### Fixes

- Enforce provision of `max_retries` if specifying `retry_delay` for a `Task` - [#1875](https://github.com/PrefectHQ/prefect/pull/1875)
- Fix issue with reduce tasks in `flow.visualize()` - [#1793](https://github.com/PrefectHQ/prefect/issues/1793)

### Deprecations

- The checkpointing kwarg will be removed from Tasks as it is now a default behavior - [#1898](https://github.com/PrefectHQ/prefect/issues/1898)

### Breaking Changes

- Remove default value for `aws_credentials_secret` on all S3 hooks - [#1886](https://github.com/PrefectHQ/prefect/issues/1886)
- Remove `config.engine.result_handler` section of Prefect config - [#1888](https://github.com/PrefectHQ/prefect/issues/1888)
- Remove default value for `credentials_secret` on `GCSResultHandler` - [#1888](https://github.com/PrefectHQ/prefect/issues/1888)
- Remove default value for `azure_credentials_secret` on `AzureResultHandler` - [#1888](https://github.com/PrefectHQ/prefect/issues/1888)

### Contributors

- [Daryll Strauss](daryll.strauss@gmail.com)
- [Braun Reyes](https://github.com/braunreyes)",139199684
1762,False,False,2019-12-17T19:10:06Z,2019-12-17T21:19:55Z,"# Changelog

## 0.8.1

Released on Dec 17, 2019

### Features

- None

### Enhancements

- Enhanced treatment of nested and ordered constant values - [#1829](https://github.com/PrefectHQ/prefect/pull/1829)
- Add `on_datetime`, `on_date`, and `at_time` filters - [#1837](https://github.com/PrefectHQ/prefect/pull/1837)
- Add `--latest` flag for Kubernetes Agent install CLI command - [#1842](https://github.com/PrefectHQ/prefect/pull/1842)
- Add `--no-cloud-logs` flag for all agents to optionally opt-out of logs being sent to Prefect Cloud - [#1843](https://github.com/PrefectHQ/prefect/pull/1843)
- Agents mark Flow Runs as `Failed` if a deployment error occurs - [#1848](https://github.com/PrefectHQ/prefect/pull/1848)
- `Submitted` states from Agents include deployment identifier information - [#1848](https://github.com/PrefectHQ/prefect/pull/1848)
- Update heartbeats to respect Cloud flow settings - [#1851](https://github.com/PrefectHQ/prefect/pull/1851)
- Add flow run name to `prefect.context` - [#1855](https://github.com/PrefectHQ/prefect/pull/1855)
- Add `--namespace` option for Kubernetes Agent start CLI command - [#1859](https://github.com/PrefectHQ/prefect/pull/1859)
- Add Prefect job resource configuration for Kubernetes Agent - [#1859](https://github.com/PrefectHQ/prefect/pull/1859)

### Task Library

- None

### Fixes

- Fix Agent deployment errors interrupting full list of found Flow Runs - [#1848](https://github.com/PrefectHQ/prefect/pull/1848)
- Fix issue with a single bad log preventing all logs from being sent to Cloud - [#1845](https://github.com/PrefectHQ/prefect/pull/1845)
- Fix Kubernetes Agent passing empty default namespace - [#1839](https://github.com/PrefectHQ/prefect/pull/1839)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- None",139199684
1763,False,False,2019-12-11T16:55:04Z,2019-12-11T17:16:30Z,"# Changelog

## 0.8.0

Released on Dec 11, 2019

### Features

- Universal Deploy: Added new Local Agent to run Flows from Local Storage, Azure Storage, S3 Storage, and GCS Storage - [#1819](https://github.com/PrefectHQ/prefect/pull/1819)
- Added Azure Blob Storage for Flows - [#1831](https://github.com/PrefectHQ/prefect/pull/1831)
- Added GCS Storage for Flows - [#1809](https://github.com/PrefectHQ/prefect/pull/1809)
- Added S3 Storage for Flows - [#1753](https://github.com/PrefectHQ/prefect/pull/1753)

### Enhancements

- Add convenience `parents()` and `children()` classmethods to all State objects for navigating the hierarchy - [#1784](https://github.com/PrefectHQ/prefect/pull/1784)
- Add `--rbac` flag to `prefect agent install` for Kubernetes Agent - [#1822](https://github.com/PrefectHQ/prefect/pull/1822)
- Add `flow_run_name` to the context - [#1815](https://github.com/PrefectHQ/prefect/pull/1815)
- Add `prefect agent install` option to output `supervisord.conf` file for Local Agent - [#1819](https://github.com/PrefectHQ/prefect/pull/1819)
- Add convenience `parents()` and `children()` classmethods to all State objects for navigating the hierarchy - [#1784](https://github.com/PrefectHQ/prefect/pull/1784)
- Add new `not_all_skipped` trigger and set it as the default for merge tasks - [#1768](https://github.com/PrefectHQ/prefect/issues/1768)


### Task Library

- Azure Blob tasks now use newer `BlockBlobService` with connection string authentication - [#1831](https://github.com/PrefectHQ/prefect/pull/1831)

### Fixes

- Fix issue with `flow.visualize()` for mapped tasks which are skipped - [#1765](https://github.com/PrefectHQ/prefect/issues/1765)
- Fix issue with timeouts only being softly enforced - [#1145](https://github.com/PrefectHQ/prefect/issues/1145), [#1686](https://github.com/PrefectHQ/prefect/issues/1686)
- Log agent errors using `write_run_logs` instead of the deprecated `write_run_log` - [#1791](https://github.com/PrefectHQ/prefect/pull/1791)
- Fix issue with `flow.update()` not transferring constants - [#1785](https://github.com/PrefectHQ/prefect/pull/1785)

### Deprecations

- `flow.deploy` is deprecated in favor of `flow.register` - [#1819](https://github.com/PrefectHQ/prefect/pull/1819)

### Breaking Changes

- Default Flow storage is now `Local` instead of `Docker` - [#1819](https://github.com/PrefectHQ/prefect/pull/1819)
- Docker based `LocalAgent` is renamed `DockerAgent` - [#1819](https://github.com/PrefectHQ/prefect/pull/1819)
- `prefect agent start` now defaults to new `LocalAgent` - [#1819](https://github.com/PrefectHQ/prefect/pull/1819)",139199684
1764,False,False,2019-11-26T16:29:34Z,2019-11-26T16:39:50Z,"# Changelog

Released on Nov 26, 2019

### Features

- Add graceful cancellation hooks to Flow and Task runners - [#1758](https://github.com/PrefectHQ/prefect/pull/1758)

### Enhancements

- Add option to specify a run name for `cloud run` CLI command - [#1756](https://github.com/PrefectHQ/prefect/pull/1756)
- Add `work_stealing` option to `DaskKubernetesEnvironment` - [#1760](https://github.com/PrefectHQ/prefect/pull/1760)
- Improve heartbeat thread management - [#1770](https://github.com/PrefectHQ/prefect/pull/1770)
- Add unique scheduler Job name to `DaskKubernetesEnvironment` - [#1772](https://github.com/PrefectHQ/prefect/pull/1772)
- Add informative error when trying to map with the `LocalDaskExecutor` using processes - [#1777](https://github.com/PrefectHQ/prefect/pull/1777)

### Task Library

- None

### Fixes

- Fix issue with heartbeat thread deadlocking dask execution when using a `worker_client` - [#1750](https://github.com/PrefectHQ/prefect/pull/1750)
- Fix issue with Environments not calling `run_flow` on Environment stored on Flow object - [#1752](https://github.com/PrefectHQ/prefect/pull/1752)
- Fix issue with Docker build context when providing custom docker files - [#1762](https://github.com/PrefectHQ/prefect/pull/1762)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- None",139199684
1765,False,False,2019-11-15T20:37:49Z,2019-11-15T20:47:02Z,"## 0.7.2

Released on Nov 15, 2019.

### Features

- Allow users to provide a custom version group ID for controlling Cloud versioning - [#1665](https://github.com/PrefectHQ/prefect/issues/1665)
- Stop autogenerating constant tasks - [#1730](https://github.com/PrefectHQ/prefect/pull/1730)

### Enhancements

- Raise an informative error when context objects are pickled - [#1710](https://github.com/PrefectHQ/prefect/issues/1710)
- Add an option to pass in `run_name` to a flow run to override the auto-generated names when calling `create_flow_run` [#1661](https://github.com/PrefectHQ/cloud/pull/1661)
- Add informative logs in the event that a heartbeat thread dies - [#1721](https://github.com/PrefectHQ/prefect/pull/1721)
- Loosen Job spec requirements for `KubernetesJobEnvironment` - [#1713](https://github.com/PrefectHQ/prefect/pull/1713)
- Loosen `containerDefinitions` requirements for `FargateTaskEnvironment` - [#1713](https://github.com/PrefectHQ/prefect/pull/1713)
- Local Docker agent proactively fails flow runs if image cannot be pulled - [#1395](https://github.com/PrefectHQ/prefect/issues/1395)
- Add graceful keyboard interrupt shutdown for all agents - [#1731](https://github.com/PrefectHQ/prefect/pull/1731)
- `agent start` CLI command now allows for Agent kwargs - [#1737](https://github.com/PrefectHQ/prefect/pull/1737)
- Add users to specify a custom Dockerfile for Docker storage - [#1738](https://github.com/PrefectHQ/prefect/pull/1738)
- Expose `labels` kwarg in `flow.deploy` for convenient labeling of Flows - [#1742](https://github.com/PrefectHQ/prefect/pull/1742)

### Task Library

- None

### Fixes

- `FargateTaskEnvironment` now uses provided `family` for task definition naming - [#1713](https://github.com/PrefectHQ/prefect/pull/1713)
- Fix executor initialization missing `self` in `KubernetesJobEnvironment` - [#1713](https://github.com/PrefectHQ/prefect/pull/1713)
- Fix `identifier_label` not being generated on each run for Kubernetes based environments - [#1718](https://github.com/PrefectHQ/prefect/pull/1718)
- Fix issue where users could not override their user config path when deploying Docker to Cloud - [#1719](https://github.com/PrefectHQ/prefect/pull/1719)
- Respect order of inputs in merge - [#1736](https://github.com/~/1736)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- [Brett Naul](https://github.com/bnaul)",139199684
1766,False,False,2019-11-05T21:02:58Z,2019-11-06T00:08:44Z,"## 0.7.1

Released on Nov 5, 2019

### Features

- None

### Enhancements

- Add a `save`/`load` interface to Flows - [#1685](https://github.com/PrefectHQ/prefect/pull/1685), [#1695](https://github.com/PrefectHQ/prefect/pull/1695)
- Add option to specify `aws_session_token` for the `FargateTaskEnvironment` - [#1688](https://github.com/PrefectHQ/prefect/pull/1688)
- Add `EnvVarSecrets` for loading sensitive information from environment variables - [#1683](https://github.com/PrefectHQ/prefect/pull/1683)
- Add an informative version header to all Cloud client requests - [#1690](https://github.com/PrefectHQ/prefect/pull/1690)
- Auto-label Flow environments when using Local storage - [#1696](https://github.com/PrefectHQ/prefect/pull/1696)
- Batch upload logs to Cloud in a background thread for improved performance - [#1691](https://github.com/PrefectHQ/prefect/pull/1691)
- Include agent labels within each flow's configuration environment - [#1671](https://github.com/PrefectHQ/prefect/issues/1671)

### Task Library

- None

### Fixes

- Fix Fargate Agent access defaults and environment variable support - [#1687](https://github.com/PrefectHQ/prefect/pull/1687)
- Removed default python version for docker builds - [#1705](https://github.com/PrefectHQ/prefect/pull/1705)
- Attempt to install prefect in any docker image (if it is not already installed) - [#1704](https://github.com/PrefectHQ/prefect/pull/1704)
- Kubernetes Agent deployment yaml now respects new `prefecthq/prefect` image tagging convention - [#1707](https://github.com/PrefectHQ/prefect/pull/1707)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- None",139199684
1767,False,False,2019-10-29T19:33:44Z,2019-10-29T19:20:48Z,"## 0.7.0

Released on October 29th, 2019.

### Features

- Flow Affinity: Environments and Agents now support labeling for execution specification - [#1651](https://github.com/PrefectHQ/prefect/pull/1651)
- Add new Secret Tasks for a pluggable and reusable Secrets API - [#1346](https://github.com/PrefectHQ/prefect/issues/1346), [#1587](https://github.com/PrefectHQ/prefect/issues/1587)

### Enhancements

- Add the ability to delete task tag limits using the client - [#1622](https://github.com/PrefectHQ/prefect/pull/1622)
- Adds an ""Ask for help"" button with a link to the prefect.io support page - [#1637](https://github.com/PrefectHQ/prefect/pull/1637)
- Reduces the size of the `prefecthq/prefect` Docker image by ~400MB, which is now the base Docker image used in Flows - [#1648](https://github.com/PrefectHQ/prefect/pull/1648)
- Add a new healthcheck for environment dependencies - [#1653](https://github.com/PrefectHQ/prefect/pull/1653)
- Add default 30 second timeout to Client requests - [#1672](https://github.com/PrefectHQ/prefect/pull/1672)

### Task Library

- Add new Secret Tasks for a pluggable and reusable Secrets API - [#1346](https://github.com/PrefectHQ/prefect/issues/1346), [#1587](https://github.com/PrefectHQ/prefect/issues/1587)
- Add support for directly passing credentials to task library tasks, instead of passing secret names - [#1667](https://github.com/PrefectHQ/prefect/pull/1673)

### Fixes

- Fix defaults for unspecified ARNs in the Fargate Agent - [#1634](https://github.com/PrefectHQ/prefect/pull/1634)
- Fix ShellTask return value on empty stdout - [#1632](https://github.com/PrefectHQ/prefect/pull/1632)
- Fix issue with some Cloud Secrets not being converted from strings - [#1655](https://github.com/PrefectHQ/prefect/pull/1655)
- Fix issue with Agent logging config setting not working - [#1657](https://github.com/PrefectHQ/prefect/pull/1657)
- Fix issue with SnowflakeQuery tasks not working - [#1663](https://github.com/PrefectHQ/prefect/pull/1663)

### Deprecations

- Tasks that accepted the name of a secret (often `credentials_secret`) will raise a deprecation warning - [#1667](https://github.com/PrefectHQ/prefect/pull/1673)

### Breaking Changes

- Fargate Agent now takes in all boto3 camel case arguments instead of specific snake case options - [#1649](https://github.com/PrefectHQ/prefect/pull/1649)
- `kubernetes` is no longer installed by default in deployed flow images - [#1653](https://github.com/PrefectHQ/prefect/pull/1653)
- Tasks that accepted the name of a secret (often `credentials_secret`) no longer have a default value for that argument, as it has been deprecated - [#1667](https://github.com/PrefectHQ/prefect/pull/1673)

### Contributors

- [Tobias Schmidt](https://github.com/royalts)",139199684
1768,False,False,2019-10-16T15:22:03Z,2019-10-16T15:37:35Z,"# Changelog

## 0.6.7

Released on Oct 16, 2019

### Features

- Environments now allow for optional `on_start` and `on_exit` callbacks - [#1610](https://github.com/PrefectHQ/prefect/pull/1610)

### Enhancements

- Raise more informative error when calling `flow.visualize()` if Graphviz executable not installed - [#1602](https://github.com/PrefectHQ/prefect/pull/1602)
- Allow authentication to Azure Blob Storage with SAS token - [#1600](https://github.com/PrefectHQ/prefect/pull/1600)
- Additional debug logs to `Docker Container` and `Docker Image` tasks - [#920](https://github.com/PrefectHQ/prefect/issues/920)
- Changes to Fargate agent to support temporary credentials and IAM role based credentials within AWS compute such as a container or ec2 instance. [#1607](https://github.com/PrefectHQ/prefect/pull/1607)
- Local Secrets set through environment variable now retain their casing - [#1601](https://github.com/PrefectHQ/prefect/issues/1601)
- Agents can accept an optional `name` for logging and debugging - [#1612](https://github.com/PrefectHQ/prefect/pull/1612)
- Added AWS configuration options for Fargate Agent (task_role_arn, execution_role_arn) - [#1614](https://github.com/PrefectHQ/prefect/pull/1614)
- Change EmailTask to accept SMTP server settings as well as an email_from kwarg - [#1619](https://github.com/PrefectHQ/prefect/pull/1619)

### Task Library

- Add `return_all` kwarg to `ShellTask` for optionally returning all lines of stdout - [#1598](https://github.com/PrefectHQ/prefect/pull/1598)
- Add `CosmosDBCreateItem`, `CosmosDBReadItems`, `CosmosDBQueryItems` and  for interacting with data stored on Azure Cosmos DB - [#1617](https://github.com/PrefectHQ/prefect/pull/1617)

### Fixes

- Fix issue with running local Flow without a schedule containing cached tasks - [#1599](https://github.com/PrefectHQ/prefect/pull/1599)
- Remove blank string for `task_run_id` in k8s resource manager - [#1604](https://github.com/PrefectHQ/prefect/pull/1604)
- Fix issue with merge task not working for pandas dataframes and numpy arrays - [#1609](https://github.com/PrefectHQ/prefect/pull/1609)

### Deprecations

- None

### Breaking Changes

- Local Secrets set through environment variable now retain their casing - [#1601](https://github.com/PrefectHQ/prefect/issues/1601)

### Contributors

- [Mark McDonald](https://github.com/mhmcdonal)
- [Sherman K](https://github.com/shrmnk)",139199684
1769,False,False,2019-10-03T21:44:54Z,2019-10-03T21:58:55Z,"## 0.6.6

Released on October 3, 2019

### Features

- Added `KubernetesJobEnvironment` - [#1548](https://github.com/PrefectHQ/prefect/pull/1548)
- Add ability to enforce Task concurrency limits by tag in Prefect Cloud - [#1570](https://github.com/PrefectHQ/prefect/pull/1570)
- Added `FargateTaskEnvironment` - [#1592](https://github.com/PrefectHQ/prefect/pull/1592)

### Enhancements

- Allow the `Client` to more gracefully handle failed login attempts on initialization - [#1535](https://github.com/PrefectHQ/prefect/pull/1535)
- Replace `DotDict` with `box.Box` - [#1518](https://github.com/PrefectHQ/prefect/pull/1518)
- Store `cached_inputs` on Failed states and call their result handlers if they were provided - [#1557](https://github.com/PrefectHQ/prefect/pull/1557)
- `raise_on_exception` no longer raises for Prefect Signals, as these are typically intentional / for control flow - [#1562](https://github.com/PrefectHQ/prefect/pull/1562)
- `run cloud` CLI command takes in optional `--parameters` as a file path pointing to a JSON file - [#1582](https://github.com/PrefectHQ/prefect/pull/1582)
- Always consider `Constant` tasks successful and unpack them immediately instead of submitting them for execution - [#1527](https://github.com/PrefectHQ/prefect/issues/1527)

### Task Library

- Add `BlobStorageDownload` and `BlobStorageUpload` for interacting with data stored on Azure Blob Storage - [#1538](https://github.com/PrefectHQ/prefect/pull/1538)
- Loosen Kubernetes Tasks' requirement of an API secret key - [#1559](https://github.com/PrefectHQ/prefect/pull/1559)
- Add tasks for working in Azure Machine Learning Serviec with Datastores and Datasets - [#1590](https://github.com/PrefectHQ/prefect/pull/1590)

### Fixes

- Fix issue with certain Pause / Resume / Retry pipelines retrying indefinitely - [#1177](https://github.com/PrefectHQ/prefect/issues/1177)
- Kubernetes Agent deployment YAML generation defaults to local Prefect version - [#1573](https://github.com/PrefectHQ/prefect/pull/1573)
- Fix issue with custom result handlers not working when called in `cached_inputs` - [#1585](https://github.com/PrefectHQ/prefect/pull/1585)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- [Fredrik Sannholm](https://github.com/frsann)",139199684
1770,False,False,2019-09-19T23:50:10Z,2019-09-20T01:06:17Z,"# Changelog

Released on September 19th, 2019.

### Features

- Added Fargate agent - [#1521](https://github.com/PrefectHQ/prefect/pull/1521)
- Custom user-written environments can be deployed to Prefect Cloud - [#1534](https://github.com/PrefectHQ/prefect/pull/1534), [#1537](https://github.com/PrefectHQ/prefect/pull/1537)

### Enhancements

- Allow for Agents to correctly run in environments with differently calibrated clocks - [#1402](https://github.com/PrefectHQ/prefect/issues/1402)
- Refactor `RemoteEnvironment` to utilize the `get_flow` storage interface - [#1476](https://github.com/PrefectHQ/prefect/issues/1476)
- Ensure Task logger is available in context throughout every pipeline step of the run - [#1509](https://github.com/PrefectHQ/prefect/issues/1509)
- Skip Docker registry pushing and pulling on empty `registry_url` attribute - [#1525](https://github.com/PrefectHQ/prefect/pull/1525)
- Agents now log platform errors to flow runs which cannot deploy - [#1528](https://github.com/PrefectHQ/prefect/pull/1528)
- Updating `ShellTask` to work more like Airflow Bash Operator for streaming logs and returning values - [#1451](https://github.com/PrefectHQ/prefect/pull/1451)
- Agents now have a verbose/debug logging option for granular output - [#1532](https://github.com/PrefectHQ/prefect/pull/1532)
- `DaskKubernetesEnvironment` now allows for custom scheduler and worker specs - [#1543](https://github.com/PrefectHQ/prefect/pull/1534), [#1537](https://github.com/PrefectHQ/prefect/pull/1537)

### Task Library

- None

### Fixes

- Fix map error by removing `imagePullSecrets` from Kubernetes Agent install if not provided - [#1524](https://github.com/PrefectHQ/prefect/pull/1524)
- Fix issue with two INFO logs not being associated with the Task Run in Cloud - [#1526](https://github.com/PrefectHQ/prefect/pull/1526)
- `execute` CLI command can now load custom environments off of the flow object - [#1534](https://github.com/PrefectHQ/prefect/pull/1534)

### Deprecations

- None

### Breaking Changes

- Update `ShellTask` to return only the last line of stdout, as a string - [#1451](https://github.com/PrefectHQ/prefect/pull/1451)

### Contributors

- [braunreyes](https://github.com/braunreyes)",139199684
1771,False,False,2019-09-11T00:46:54Z,2019-09-11T03:22:22Z,"# Changelog

Released on September 10, 2019

### Features

- Improve Windows compatibility for local development and deploying to Prefect Cloud - [#1441](https://github.com/PrefectHQ/prefect/pull/1441), [#1456](https://github.com/PrefectHQ/prefect/pull/1456), [#1465](https://github.com/PrefectHQ/prefect/pull/1465), [#1466](https://github.com/PrefectHQ/prefect/pull/1466)

### Enhancements

- Add OS platform check to Local Agent for running on Windows machines - [#1441](https://github.com/PrefectHQ/prefect/pull/1441)
- Add `--base-url` argument for Docker daemons to `agent start` CLI command - [#1441](https://github.com/PrefectHQ/prefect/pull/1441)
- Add environment labels for organizing / tagging different Flow execution environments - [#1438](https://github.com/PrefectHQ/prefect/issues/1438)
- Use `-U` option when installing `prefect` in Docker containers to override base image version - [#1461](https://github.com/PrefectHQ/prefect/pull/1461)
- Remove restriction that prevented `DotDict` classes from having keys that shadowed dict methods - [#1462](https://github.com/PrefectHQ/prefect/pull/1462)
- Added livenessProbe to Kubernetes Agent - [#1474](https://github.com/PrefectHQ/prefect/pull/1474)
- Ensure external Dask Clusters do not require Prefect Cloud environment variables to run Cloud flows - [#1481](https://github.com/PrefectHQ/prefect/pull/1481)

### Task Library

- None

### Fixes

- Fix incorrect import in `DaskKubernetesEnvironment` job template - [#1458](https://github.com/PrefectHQ/prefect/pull/1458)
- Raise error on Agents started without an appropriate API token - [#1459](https://github.com/PrefectHQ/prefect/pull/1459)
- Fix bug when calling `as_nested_dict` on `DotDicts` with an `items` key - [#1462](https://github.com/PrefectHQ/prefect/pull/1462)
- Fix `--resource-manager` flag on agent install invalidating `imagePullSecrets` - [#1469](https://github.com/PrefectHQ/prefect/pull/1469)
- Fix issue with user-written result handlers in Prefect Cloud preventing some states from being set - [#1480](https://github.com/PrefectHQ/prefect/pull/1480)

### Deprecations

- None

### Breaking Changes

- None

### Contributors

- [Joe Schmid](https://github.com/joeschmid)
- [Brett Naul](https://github.com/bnaul)",139199684
1772,False,False,2019-08-31T00:37:07Z,2019-08-31T00:41:46Z,"## 0.6.3

Released August 30, 2019

### Fixes

- Fix issue with reduced mapped tasks not respecting retries - [#1436](https://github.com/PrefectHQ/prefect/issues/1436)",139199684
1773,False,False,2019-08-30T21:47:41Z,2019-08-30T22:41:20Z,"# Changelog

## 0.6.2

Released August 30, 2019

### Features

- Added Local, Kubernetes, and Nomad agents - [#1341](https://github.com/PrefectHQ/prefect/pull/1341)
- Add the ability for Tasks to sequentially loop - [#1356](https://github.com/PrefectHQ/prefect/pull/1356)

### Enhancements

- Adds a copy to clipboard button for codeblocks - [#213](https://github.com/prefecthq/prefect/issues/213)
- Updates Vuepress to v1.0.3 - [#770](https://github.com/prefecthq/prefect/issues/770)
- Introduce configurable default for storage class on Flows - [#1044](https://github.com/PrefectHQ/prefect/issues/1044)
- Allow for min and max workers to be specified in `DaskKubernetesEnvironment` - [#1338](https://github.com/PrefectHQ/prefect/pulls/1338)
- Use task and flow names for corresponding logger names for better organization - [#1355](https://github.com/PrefectHQ/prefect/pull/1355)
- `Paused` states subclass `Scheduled` and can have predefined expirations - [#1375](https://github.com/PrefectHQ/prefect/pull/1375)
- Introduce new Flow health checks prior to Cloud deployment - [#1372](https://github.com/PrefectHQ/prefect/issues/1372)
- Improve logging functionality to include tracebacks - [#1374](https://github.com/PrefectHQ/prefect/issues/1374)
- Improve CLI user experience while working with Cloud - [#1384](https://github.com/PrefectHQ/prefect/pull/1384/)
- Users can now create projects from the CLI - [#1388](https://github.com/PrefectHQ/prefect/pull/1388)
- Add a health check to confirm that serialized flows are valid prior to Cloud deploy - [#1397](https://github.com/PrefectHQ/prefect/pull/1397)
- Add `task_slug`, `flow_id`, and `flow_run_id` to context - [#1405](https://github.com/PrefectHQ/prefect/pull/1405)
- Support persistent `scheduled_start_time` for scheduled flow runs when run locally with `flow.run()` - [#1418](https://github.com/PrefectHQ/prefect/pull/1418), [#1429](https://github.com/PrefectHQ/prefect/pull/1429)
- Add `task_args` to `Task.map` - [#1390](https://github.com/PrefectHQ/prefect/issues/1390)
- Add auth flows for `USER`-scoped Cloud API tokens - [#1423](https://github.com/PrefectHQ/prefect/pull/1423)
- Add `AzureResultHandler` for handling results to / from Azure Blob storage containers - [#1421](https://github.com/PrefectHQ/prefect/pull/1421)
- Add new configurable `LocalDaskExecutor` - [#1336](https://github.com/PrefectHQ/prefect/issues/1336)
- Add CLI commands for working with Prefect Cloud auth - [#1431](https://github.com/PrefectHQ/prefect/pull/1431)

### Task Library

- Add new `SnowflakeQuery` task for using snowflake data warehouse - [#1113](https://github.com/PrefectHQ/prefect/issues/1113)

### Fixes

- Fix issue with Docker storage not respecting user-provided image names - [#1335](https://github.com/PrefectHQ/prefect/pull/1335)
- Fix issue with local retries in Cloud not always running in-process - [#1348](https://github.com/PrefectHQ/prefect/pull/1348)

### Deprecations

- Rename `SynchronousExecutor` as `LocalDaskExecutor` - [#1434](https://github.com/PrefectHQ/prefect/pull/1434)

### Breaking Changes

- Rename `CloudEnvironment` to `DaskKubernetesEnvironment` - [#1250](https://github.com/PrefectHQ/prefect/issues/1250)
- Remove unused `queue` method from all executors - [#1434](https://github.com/PrefectHQ/prefect/pull/1434)

### Contributors

- [Alex Kravetz](http://github.com/akravetz)",139199684
1774,False,False,2019-08-08T14:41:02Z,2019-08-08T15:21:03Z,"# Changelog

## 0.6.1

Released August 8, 2019

### Features

- Introduce new `flows.checkpointing` configuration setting for checkpointing Tasks in local execution - [#1283](https://github.com/PrefectHQ/prefect/pull/1283)
- Introduce new, flexible `Schedule` objects - [#1320](https://github.com/PrefectHQ/prefect/pull/1320)

### Enhancements

- Allow passing of custom headers in `Client` calls - [#1255](https://github.com/PrefectHQ/prefect/pull/1255)
- Autogenerate informative names and tags for Docker images built for Flow storage - [#1237](https://github.com/PrefectHQ/prefect/issues/1237)
- Allow mixed-case configuration keys (environment variables are interpolated as lowercase) - [#1288](https://github.com/PrefectHQ/prefect/issues/1288)
- Ensure state handler errors are logged informatively - [#1326](https://github.com/PrefectHQ/prefect/issues/1326)

### Task Library

- Add `BigQueryLoadGoogleCloudStorage` task for loading data into BigQuery from Google Cloud Storage [#1317](https://github.com/PrefectHQ/prefect/pull/1317)

### Fixes

- Fix issue with logs not always arriving in long-standing Dask clusters - [#1244](https://github.com/PrefectHQ/prefect/pull/1244)
- Fix issue with `BuildImage` docker task not actually running to completion - [#1243](https://github.com/PrefectHQ/prefect/issues/1243)
- Fix `run --logs` CLI command not exiting on flow run finished state - [#1319](https://github.com/PrefectHQ/prefect/pull/1319)

### Deprecations

- `OneTimeSchedule` and `UnionSchedule` are deprecated, but remain callable as convenience functions - [#1320](https://github.com/PrefectHQ/prefect/pull/1320)
- Old-style schedules can be deserialized as new-style schedules, but support will eventually be dropped - [#1320](https://github.com/PrefectHQ/prefect/pull/1320)

### Breaking Changes

- `prefect.Client.graphql()` and `prefect.Client.post()` now use an explicit keyword, not `**kwargs`, for variables or parameters - [#1259](https://github.com/PrefectHQ/prefect/pull/1259)
- `auth add` CLI command replaced with `auth login` - [#1319](https://github.com/PrefectHQ/prefect/pull/1319)",139199684
1775,False,False,2019-07-16T16:47:01Z,2019-07-16T16:57:28Z,"# Changelog

## 0.6.0 <Badge text=""beta"" type=""success""/>

Released July 16, 2019

### Features

- Add the Prefect CLI for working with core objects both locally and in cloud - [#1059](https://github.com/PrefectHQ/prefect/pull/1059)
- Add RemoteEnvironment for simple executor based executions - [#1215](https://github.com/PrefectHQ/prefect/pull/1215)
- Add the ability to share caches across Tasks and Flows - [#1222](https://github.com/PrefectHQ/prefect/pull/1222)
- Add the ability to submit tasks to specific dask workers for task / worker affinity - [#1229](https://github.com/PrefectHQ/prefect/pull/1229)

### Enhancements

- Refactor mapped caching to be independent of order - [#1082](https://github.com/PrefectHQ/prefect/issues/1082)
- Refactor caching to allow for caching across multiple runs - [#1082](https://github.com/PrefectHQ/prefect/issues/1082)
- Allow for custom secret names in Result Handlers - [#1098](https://github.com/PrefectHQ/prefect/issues/1098)
- Have `execute cloud-flow` CLI immediately set the flow run state to `Failed` if environment fails - [#1122](https://github.com/PrefectHQ/prefect/pull/1122)
- Validate configuration objects on initial load - [#1136](https://github.com/PrefectHQ/prefect/pull/1136)
- Add `auto_generated` property to Tasks for convenient filtering - [#1135](https://github.com/PrefectHQ/prefect/pull/1135)
- Disable dask work-stealing in kubernetes via scheduler config - [#1166](https://github.com/PrefectHQ/prefect/pull/1166)
- Implement backoff retry settings on Client calls - [#1187](https://github.com/PrefectHQ/prefect/pull/1187)
- Explicitly set Dask keys for a better Dask visualization experience - [#1218](https://github.com/PrefectHQ/prefect/issues/1218)
- Implement a local cache which persists for the duration of a Python session - [#1221](https://github.com/PrefectHQ/prefect/issues/1221)
- Implement in-process retries for Cloud Tasks which request retry in less than one minute - [#1228](https://github.com/PrefectHQ/prefect/pull/1228)
- Support `Client.login()` with API tokens - [#1240](https://github.com/PrefectHQ/prefect/pull/1240)
- Add live log streaming for `prefect run cloud` command - [#1241](https://github.com/PrefectHQ/prefect/pull/1241)

### Task Library

- Add task to trigger AWS Step function workflow [#1012](https://github.com/PrefectHQ/prefect/issues/1012)
- Add task to copy files within Google Cloud Storage - [#1206](https://github.com/PrefectHQ/prefect/pull/1206)
- Add task for downloading files from Dropbox - [#1205](https://github.com/PrefectHQ/prefect/pull/1205)

### Fixes

- Fix issue with mapped caching in Prefect Cloud - [#1096](https://github.com/PrefectHQ/prefect/pull/1096)
- Fix issue with Result Handlers deserializing incorrectly in Cloud - [#1112](https://github.com/PrefectHQ/prefect/issues/1112)
- Fix issue caused by breaking change in `marshmallow==3.0.0rc7` - [#1151](https://github.com/PrefectHQ/prefect/pull/1151)
- Fix issue with passing results to Prefect signals - [#1163](https://github.com/PrefectHQ/prefect/issues/1163)
- Fix issue with `flow.update` not preserving mapped edges - [#1164](https://github.com/PrefectHQ/prefect/issues/1164)
- Fix issue with Parameters and Context not being raw dictionaries - [#1186](https://github.com/PrefectHQ/prefect/issues/1186)
- Fix issue with asynchronous, long-running mapped retries in Prefect Cloud - [#1208](https://github.com/PrefectHQ/prefect/pull/1208)
- Fix issue with automatically applied collections to task call arguments when using the imperative API - [#1211](https://github.com/PrefectHQ/prefect/issues/1211)

### Breaking Changes

- The CLI command `prefect execute-flow` and `prefect execute-cloud-flow` no longer exist - [#1059](https://github.com/PrefectHQ/prefect/pull/1059)
- The `slack_notifier` state handler now uses a `webhook_secret` kwarg to pull the URL from a Secret - [#1075](https://github.com/PrefectHQ/prefect/issues/1075)
- Use GraphQL for Cloud logging - [#1193](https://github.com/PrefectHQ/prefect/pull/1193)
- Remove the `CloudResultHandler` default result handler - [#1198](https://github.com/PrefectHQ/prefect/pull/1198)
- Rename `LocalStorage` to `Local` - [#1236](https://github.com/PrefectHQ/prefect/pull/1236)

### Contributors

- [Kwangyoun Jung](https://github.com/initialkommit)
- [Anes Benmerzoug](https://github.com/AnesBenmerzoug)",139199684
1776,False,False,2019-05-31T16:25:39Z,2019-05-31T16:29:05Z,This release fixes a versioning issue caused by a new release of `marshmallow-oneofschema` that is incompatible with the `marshmallow` version pin in 0.5.4.,139199684
1777,False,False,2019-05-28T20:55:58Z,2019-05-28T20:57:06Z,"# Changelog

## 0.5.4 <Badge text=""beta"" type=""success""/>

Released May 28, 2019

### Features

- Add new `UnionSchedule` for combining multiple schedules, allowing for complex schedule specifications - [#428](https://github.com/PrefectHQ/prefect/issues/428)
- Allow for Cloud users to securely pull Docker images from private registries - [#1028](https://github.com/PrefectHQ/prefect/pull/1028)

### Enhancements

- Add `prefect_version` kwarg to `Docker` storage for controlling the version of prefect installed into your containers - [#1010](https://github.com/PrefectHQ/prefect/pull/1010), [#533](https://github.com/PrefectHQ/prefect/issues/533)
- Warn users if their Docker storage base image uses a different python version than their local machine - [#999](https://github.com/PrefectHQ/prefect/issues/999)
- Add flow run id to k8s labels on Cloud Environment jobs / pods for easier filtering in deployment - [#1016](https://github.com/PrefectHQ/prefect/pull/1016)
- Allow for `SlackTask` to pull the Slack webhook URL from a custom named Secret - [#1023](https://github.com/PrefectHQ/prefect/pull/1023)
- Raise informative errors when Docker storage push / pull fails - [#1029](https://github.com/PrefectHQ/prefect/issues/1029)
- Standardized `__repr__`s for various classes, to remove inconsistencies - [#617](https://github.com/PrefectHQ/prefect/issues/617)
- Allow for use of local images in Docekr storage - [#1052](https://github.com/PrefectHQ/prefect/pull/1052)
- Allow for doc tests and doc generation to run without installing `all_extras` - [#1057](https://github.com/PrefectHQ/prefect/issues/1057)

### Task Library

- Add task for creating new branches in a GitHub repository - [#1011](https://github.com/PrefectHQ/prefect/pull/1011)
- Add tasks to create, delete, invoke, and list AWS Lambda functions [#1009](https://github.com/PrefectHQ/prefect/issues/1009)
- Add tasks for integration with spaCy pipelines [#1018](https://github.com/PrefectHQ/prefect/issues/1018)
- Add tasks for querying Postgres database [#1022](https://github.com/PrefectHQ/prefect/issues/1022)
- Add task for waiting on a Docker container to run and optionally raising for nonzero exit code - [#1061](https://github.com/PrefectHQ/prefect/pull/1061)
- Add tasks for communicating with Redis [#1021](https://github.com/PrefectHQ/prefect/issues/1021)

### Fixes

- Ensure that state change handlers are called even when unexpected initialization errors occur - [#1015](https://github.com/PrefectHQ/prefect/pull/1015)
- Fix an issue where a mypy assert relied on an unavailable import - [#1034](https://github.com/PrefectHQ/prefect/pull/1034)
- Fix an issue where user configurations were loaded after config interpolation had already taken place - [#1037](https://github.com/PrefectHQ/prefect/pull/1037)
- Fix an issue with saving a flow visualization to a file from a notebook - [#1056](https://github.com/PrefectHQ/prefect/pull/1056)
- Fix an issue in which mapped tasks incorrectly tried to run when their upstream was skipped - [#1068](https://github.com/PrefectHQ/prefect/issues/1068)
- Fix an issue in which mapped tasks were not using their caches locally - [#1067](https://github.com/PrefectHQ/prefect/issues/1067)

### Breaking Changes

- Changed the signature of `configuration.load_configuration()` - [#1037](https://github.com/PrefectHQ/prefect/pull/1037)
- Local Secrets now raise `ValueError`s when not found in context - [#1047](https://github.com/PrefectHQ/prefect/pull/1047)

### Contributors

- [Zach Angell](https://github.com/zangell44)
- [Nanda H Krishna](https://nandahkrishna.me)
- [Brett Naul](https://github.com/bnaul)
- [Jeremiah Lewis](https://github.com/jlewis91)
- [Dave Hirschfeld](https://github.com/dhirschfeld)",139199684
1778,False,False,2019-05-07T20:28:44Z,2019-05-07T20:44:12Z,"# Changelog

## 0.5.3

Released May 7, 2019

### Features

- Add new `Storage` and `Environment` specifications - [#936](https://github.com/PrefectHQ/prefect/pull/936), [#956](https://github.com/PrefectHQ/prefect/pull/956)

### Enhancements

- Flow now has optional `storage` keyword - [#936](https://github.com/PrefectHQ/prefect/pull/936)
- Flow `environment` argument now defaults to a `CloudEnvironment` - [#936](https://github.com/PrefectHQ/prefect/pull/936)
- `Queued` states accept `start_time` arguments - [#955](https://github.com/PrefectHQ/prefect/pull/955)
- Add new `Bytes` and `Memory` storage classes for local testing - [#956](https://github.com/PrefectHQ/prefect/pull/956), [#961](https://github.com/PrefectHQ/prefect/pull/961)
- Add new `LocalEnvironment` execution environment for local testing - [#957](https://github.com/PrefectHQ/prefect/pull/957)
- Add new `Aborted` state for Flow runs which are cancelled by users - [#959](https://github.com/PrefectHQ/prefect/issues/959)
- Added an `execute-cloud-flow` CLI command for working with cloud deployed flows - [#971](https://github.com/PrefectHQ/prefect/pull/971)
- Add new `flows.run_on_schedule` configuration option for affecting the behavior of `flow.run` - [#972](https://github.com/PrefectHQ/prefect/issues/972)
- Allow for Tasks with `manual_only` triggers to be root tasks - [#667](https://github.com/PrefectHQ/prefect/issues/667)
- Allow compression of serialized flows [#993](https://github.com/PrefectHQ/prefect/pull/993)
- Allow for serialization of user written result handlers - [#623](https://github.com/PrefectHQ/prefect/issues/623)
- Allow for state to be serialized in certain triggers and cache validators - [#949](https://github.com/PrefectHQ/prefect/issues/949)
- Add new `filename` keyword to `flow.visualize` for automatically saving visualizations - [#1001](https://github.com/PrefectHQ/prefect/issues/1001)
- Add new `LocalStorage` option for storing Flows locally - [#1006](https://github.com/PrefectHQ/prefect/pull/1006)

### Task Library

- None

### Fixes

- Fix Docker storage not pulling correct flow path - [#968](https://github.com/PrefectHQ/prefect/pull/968)
- Fix `run_flow` loading to decode properly by use cloudpickle - [#978](https://github.com/PrefectHQ/prefect/pull/978)
- Fix Docker storage for handling flow names with spaces and weird characters - [#969](https://github.com/PrefectHQ/prefect/pull/969)
- Fix non-deterministic issue with mapping in the DaskExecutor - [#943](https://github.com/PrefectHQ/prefect/issues/943)

### Breaking Changes

- Remove `flow.id` and `task.id` attributes - [#940](https://github.com/PrefectHQ/prefect/pull/940)
- Removed old WIP environments - [#936](https://github.com/PrefectHQ/prefect/pull/936)
  (_Note_: Changes from [#936](https://github.com/PrefectHQ/prefect/pull/936) regarding environments don't break any Prefect code because environments weren't used yet outside of Cloud.)
- Update `flow.deploy` and `client.deploy` to use `set_schedule_active` kwarg to match Cloud - [#991](https://github.com/PrefectHQ/prefect/pull/991)
- Removed `Flow.generate_local_task_ids()` - [#992](#https://github.com/PrefectHQ/prefect/pull/992)

### Contributors

- None",139199684
1779,False,False,2019-04-19T15:46:29Z,2019-04-19T15:50:43Z,"## 0.5.2

Released April 19, 2019

### Features

- Implement two new triggers that allow for specifying bounds on the number of failures or successes - [#933](https://github.com/PrefectHQ/prefect/issues/933)

### Enhancements

- `DaskExecutor(local_processes=True)` supports timeouts - [#886](https://github.com/PrefectHQ/prefect/issues/886)
- Calling `Secret.get()` from within a Flow context raises an informative error - [#927](https://github.com/PrefectHQ/prefect/issues/927)
- Add new keywords to `Task.set_upstream` and `Task.set_downstream` for handling keyed and mapped dependencies - [#823](https://github.com/PrefectHQ/prefect/issues/823)
- Downgrade default logging level to ""INFO"" from ""DEBUG"" - [#935](https://github.com/PrefectHQ/prefect/pull/935)
- Add start times to queued states - [#937](https://github.com/PrefectHQ/prefect/pull/937)
- Add `is_submitted` to states - [#944](https://github.com/PrefectHQ/prefect/pull/944)
- Introduce new `ClientFailed` state - [#938](https://github.com/PrefectHQ/prefect/issues/938)

### Task Library

- Add task for sending Slack notifications via Prefect Slack App - [#932](https://github.com/PrefectHQ/prefect/issues/932)

### Fixes

- Fix issue with timeouts behaving incorrectly with unpickleable objects - [#886](https://github.com/PrefectHQ/prefect/issues/886)
- Fix issue with Flow validation being performed even when eager validation was turned off - [#919](https://github.com/PrefectHQ/prefect/issues/919)
- Fix issue with downstream tasks with `all_failed` triggers running if an upstream Client call fails in Cloud - [#938](https://github.com/PrefectHQ/prefect/issues/938)

### Breaking Changes

- Remove `prefect make user config` from cli commands - [#904](https://github.com/PrefectHQ/prefect/issues/904)
- Change `set_schedule_active` keyword in Flow deployments to `set_schedule_inactive` to match Cloud - [#941](https://github.com/PrefectHQ/prefect/pull/941)

### Contributors

- None",139199684
1780,False,False,2019-04-04T20:22:34Z,2019-04-04T20:33:10Z,"## 0.5.1 <Badge text=""beta"" type=""success""/>

Released April 4, 2019

### Features

- API reference documentation is now versioned - [#270](https://github.com/PrefectHQ/prefect/issues/270)
- Add `S3ResultHandler` for handling results to / from S3 buckets - [#879](https://github.com/PrefectHQ/prefect/pull/879)
- Add ability to use `Cached` states across flow runs in Cloud - [#885](https://github.com/PrefectHQ/prefect/pull/885)

### Enhancements
- Bump to latest version of `pytest` (4.3) - [#814](https://github.com/PrefectHQ/prefect/issues/814)
- `Client.deploy` accepts optional `build` kwarg for avoiding building Flow environment - [#876](https://github.com/PrefectHQ/prefect/pull/876)
- Bump `distributed` to 1.26.1 for enhanced security features - [#878](https://github.com/PrefectHQ/prefect/pull/878)
- Local secrets automatically attempt to load secrets as JSON - [#883](https://github.com/PrefectHQ/prefect/pull/883)
- Add task logger to context for easily creating custom logs during task runs - [#884](https://github.com/PrefectHQ/prefect/issues/884)

### Task Library

- Add `ParseRSSFeed` for parsing a remote RSS feed - [#856](https://github.com/PrefectHQ/prefect/pull/856)
- Add tasks for working with Docker containers and imaged - [#864](https://github.com/PrefectHQ/prefect/pull/864)
- Add task for creating a BigQuery table - [#895](https://github.com/PrefectHQ/prefect/pull/895)

### Fixes

- Only checkpoint tasks if running in cloud - [#839](https://github.com/PrefectHQ/prefect/pull/839), [#854](https://github.com/PrefectHQ/prefect/pull/854)
- Adjusted small flake8 issues for names, imports, and comparisons - [#849](https://github.com/PrefectHQ/prefect/pull/849)
- Fix bug preventing `flow.run` from properly using cached tasks - [#861](https://github.com/PrefectHQ/prefect/pull/861)
- Fix tempfile usage in `flow.visualize` so that it runs on Windows machines - [#858](https://github.com/PrefectHQ/prefect/issues/858)
- Fix issue caused by Python 3.5.2 bug for Python 3.5.2 compatibility - [#857](https://github.com/PrefectHQ/prefect/issues/857)
- Fix issue in which `GCSResultHandler` was not pickleable - [#879](https://github.com/PrefectHQ/prefect/pull/879)
- Fix issue with automatically converting callables and dicts to tasks - [#894](https://github.com/PrefectHQ/prefect/issues/894)

### Breaking Changes

- Change the call signature of `Dict` task from `run(**task_results)` to `run(keys, values)` - [#894](https://github.com/PrefectHQ/prefect/issues/894)

### Contributors

- [ColCarroll](https://github.com/ColCarroll)
- [dhirschfeld](https://github.com/dhirschfeld)
- [BasPH](https://github.com/BasPH)
- [Miloš Garunović](https://github.com/milosgarunovic)
- [Nash Taylor](https://github.com/ntaylorwss)",139199684
1781,False,False,2019-03-24T16:36:39Z,2019-03-24T17:10:30Z,"## 0.5.0

Released March 24, 2019

### Features

- Add `checkpoint` option for individual `Task`s, as well as a global `checkpoint` config setting for storing the results of Tasks using their result handlers - [#649](https://github.com/PrefectHQ/prefect/pull/649)
- Add `defaults_from_attrs` decorator to easily construct `Task`s whose attributes serve as defaults for `Task.run` - [#293](https://github.com/PrefectHQ/prefect/issues/293)
- Environments follow new hierarchy (PIN-3) - [#670](https://github.com/PrefectHQ/prefect/pull/670)
- Add `OneTimeSchedule` for one-time execution at a specified time - [#680](https://github.com/PrefectHQ/prefect/pull/680)
- `flow.run` is now a blocking call which will run the Flow, on its schedule, and execute full state-based execution (including retries) - [#690](https://github.com/PrefectHQ/prefect/issues/690)
- Pre-populate `prefect.context` with various formatted date strings during execution - [#704](https://github.com/PrefectHQ/prefect/pull/704)
- Add ability to overwrite task attributes such as ""name"" when calling tasks in the functional API - [#717](https://github.com/PrefectHQ/prefect/issues/717)
- Release Prefect Core under the Apache 2.0 license - [#762](https://github.com/PrefectHQ/prefect/pull/762)

### Enhancements

- Refactor all `State` objects to store fully hydrated `Result` objects which track information about how results should be handled - [#612](https://github.com/PrefectHQ/prefect/pull/612), [#616](https://github.com/PrefectHQ/prefect/pull/616)
- Add `google.cloud.storage` as an optional extra requirement so that the `GCSResultHandler` can be exposed better - [#626](https://github.com/PrefectHQ/prefect/pull/626)
- Add a `start_time` check for Scheduled flow runs, similar to the one for Task runs - [#605](https://github.com/PrefectHQ/prefect/issues/605)
- Project names can now be specified for deployments instead of IDs - [#633](https://github.com/PrefectHQ/prefect/pull/633)
- Add a `createProject` mutation function to the client - [#633](https://github.com/PrefectHQ/prefect/pull/633)
- Add timestamp to auto-generated API docs footer - [#639](https://github.com/PrefectHQ/prefect/pull/639)
- Refactor `Result` interface into `Result` and `SafeResult` - [#649](https://github.com/PrefectHQ/prefect/pull/649)
- The `manual_only` trigger will pass if `resume=True` is found in context, which indicates that a `Resume` state was passed - [#664](https://github.com/PrefectHQ/prefect/issues/664)
- Added DockerOnKubernetes environment (PIN-3) - [#670](https://github.com/PrefectHQ/prefect/pull/670)
- Added Prefect docker image (PIN-3) - [#670](https://github.com/PrefectHQ/prefect/pull/670)
- `defaults_from_attrs` now accepts a splatted list of arguments - [#676](https://github.com/PrefectHQ/prefect/issues/676)
- Add retry functionality to `flow.run(on_schedule=True)` for local execution - [#680](https://github.com/PrefectHQ/prefect/pull/680)
- Add `helper_fns` keyword to `ShellTask` for pre-populating helper functions to commands - [#681](https://github.com/PrefectHQ/prefect/pull/681)
- Convert a few DEBUG level logs to INFO level logs - [#682](https://github.com/PrefectHQ/prefect/issues/682)
- Added DaskOnKubernetes environment (PIN-3) - [#695](https://github.com/PrefectHQ/prefect/pull/695)
- Load `context` from Cloud when running flows - [#699](https://github.com/PrefectHQ/prefect/pull/699)
- Add `Queued` state - [#705](https://github.com/PrefectHQ/prefect/issues/705)
- `flow.serialize()` will always serialize its environment, regardless of `build` - [#696](https://github.com/PrefectHQ/prefect/issues/696)
- `flow.deploy()` now raises an informative error if your container cannot deserialize the Flow - [#711](https://github.com/PrefectHQ/prefect/issues/711)
- Add `_MetaState` as a parent class for states that modify other states - [#726](https://github.com/PrefectHQ/prefect/pull/726)
- Add `flow` keyword argument to `Task.set_upstream()` and `Task.set_downstream()` - [#749](https://github.com/PrefectHQ/prefect/pull/749)
- Add `is_retrying()` helper method to all `State` objects - [#753](https://github.com/PrefectHQ/prefect/pull/753)
- Allow for state handlers which return `None` - [#753](https://github.com/PrefectHQ/prefect/pull/753)
- Add daylight saving time support for `CronSchedule` - [#729](https://github.com/PrefectHQ/prefect/pull/729)
- Add `idempotency_key` and `context` arguments to `Client.create_flow_run` - [#757](https://github.com/PrefectHQ/prefect/issues/757)
- Make `EmailTask` more secure by pulling credentials from secrets - [#706](https://github.com/PrefectHQ/prefect/issues/706)

### Task Library

- Add `GCSUpload` and `GCSDownload` for uploading / retrieving string data to / from Google Cloud Storage - [#673](https://github.com/PrefectHQ/prefect/pull/673)
- Add `BigQueryTask` and `BigQueryInsertTask` for executing queries against BigQuery tables and inserting data - [#678](https://github.com/PrefectHQ/prefect/pull/678), [#685](https://github.com/PrefectHQ/prefect/pull/685)
- Add `FilterTask` for filtering out lists of results - [#637](https://github.com/PrefectHQ/prefect/issues/637)
- Add `S3Download` and `S3Upload` for interacting with data stored on AWS S3 - [#692](https://github.com/PrefectHQ/prefect/issues/692)
- Add `AirflowTask` and `AirflowTriggerDAG` tasks to the task library for running individual Airflow tasks / DAGs - [#735](https://github.com/PrefectHQ/prefect/issues/735)
- Add `OpenGitHubIssue` and `CreateGitHubPR` tasks for interacting with GitHub repositories - [#771](https://github.com/PrefectHQ/prefect/pull/771)
- Add Kubernetes tasks for deployments, jobs, pods, and services - [#779](https://github.com/PrefectHQ/prefect/pull/779)
- Add Airtable tasks - [#803](https://github.com/PrefectHQ/prefect/pull/803)
- Add Twitter tasks - [#803](https://github.com/PrefectHQ/prefect/pull/803)
- Add `GetRepoInfo` for pulling GitHub repository information - [#816](https://github.com/PrefectHQ/prefect/pull/816)

### Fixes

- Fix edge case in doc generation in which some `Exception`s' call signature could not be inspected - [#513](https://github.com/PrefectHQ/prefect/issues/513)
- Fix bug in which exceptions raised within flow runner state handlers could not be sent to Cloud - [#628](https://github.com/PrefectHQ/prefect/pull/628)
- Fix issue wherein heartbeats were not being called on a fixed interval - [#669](https://github.com/PrefectHQ/prefect/pull/669)
- Fix issue wherein code blocks inside of method docs couldn't use `**kwargs` - [#658](https://github.com/PrefectHQ/prefect/issues/658)
- Fix bug in which Prefect-generated Keys for S3 buckets were not properly converted to strings - [#698](https://github.com/PrefectHQ/prefect/pull/698)
- Fix next line after Docker Environment push/pull from overwriting progress bar - [#702](https://github.com/PrefectHQ/prefect/pull/702)
- Fix issue with `JinjaTemplate` not being pickleable - [#710](https://github.com/PrefectHQ/prefect/pull/710)
- Fix issue with creating secrets from JSON documents using the Core Client - [#715](https://github.com/PrefectHQ/prefect/pull/715)
- Fix issue with deserialization of JSON secrets unnecessarily calling `json.loads` - [#716](https://github.com/PrefectHQ/prefect/pull/716)
- Fix issue where `IntervalSchedules` didn't respect daylight saving time after serialization - [#729](https://github.com/PrefectHQ/prefect/pull/729)

### Breaking Changes

- Remove the `BokehRunner` and associated webapp - [#609](https://github.com/PrefectHQ/prefect/issues/609)
- Rename `ResultHandler` methods from `serialize` / `deserialize` to `write` / `read` - [#612](https://github.com/PrefectHQ/prefect/pull/612)
- Refactor all `State` objects to store fully hydrated `Result` objects which track information about how results should be handled - [#612](https://github.com/PrefectHQ/prefect/pull/612), [#616](https://github.com/PrefectHQ/prefect/pull/616)
- `Client.create_flow_run` now returns a string instead of a `GraphQLResult` object to match the API of `deploy` - [#630](https://github.com/PrefectHQ/prefect/pull/630)
- `flow.deploy` and `client.deploy` require a `project_name` instead of an ID - [#633](https://github.com/PrefectHQ/prefect/pull/633)
- Upstream state results now take precedence for task inputs over `cached_inputs` - [#591](https://github.com/PrefectHQ/prefect/issues/591)
- Rename `Match` task (used inside control flow) to `CompareValue` - [#638](https://github.com/PrefectHQ/prefect/pull/638)
- `Client.graphql()` now returns a response with up to two keys (`data` and `errors`). Previously the `data` key was automatically selected - [#642](https://github.com/PrefectHQ/prefect/pull/642)
- `ContainerEnvironment` was changed to `DockerEnvironment` - [#670](https://github.com/PrefectHQ/prefect/pull/670)
- The environment `from_file` was moved to `utilities.environments` - [#670](https://github.com/PrefectHQ/prefect/pull/670)
- Removed `start_tasks` argument from `FlowRunner.run()` and `check_upstream` argument from `TaskRunner.run()` - [#672](https://github.com/PrefectHQ/prefect/pull/672)
- Remove support for Python 3.4 - [#671](https://github.com/PrefectHQ/prefect/issues/671)
- `flow.run` is now a blocking call which will run the Flow, on its schedule, and execute full state-based execution (including retries) - [#690](https://github.com/PrefectHQ/prefect/issues/690)
- Remove `make_return_failed_handler` as `flow.run` now returns all task states - [#693](https://github.com/PrefectHQ/prefect/pull/693)
- Refactor Airflow migration tools into a single `AirflowTask` in the task library for running individual Airflow tasks - [#735](https://github.com/PrefectHQ/prefect/issues/735)
- `name` is now required on all Flow objects - [#732](https://github.com/PrefectHQ/prefect/pull/732)
- Separate installation ""extras"" packages into multiple, smaller extras - [#739](https://github.com/PrefectHQ/prefect/issues/739)
- `Flow.parameters()` always returns a set of parameters - [#756](https://github.com/PrefectHQ/prefect/pull/756)",139199684
1782,False,False,2019-01-31T19:56:15Z,2019-01-31T19:57:58Z,"
### Major Features

- Add ability to run scheduled flows locally via `on_schedule` kwarg in `flow.run()` - [#519](https://github.com/PrefectHQ/prefect/issues/519)
- Allow tasks to specify their own result handlers, ensure inputs and outputs are stored only when necessary, and ensure no raw data is sent to the database - [#587](https://github.com/PrefectHQ/prefect/pull/587)

### Minor Features

- Allow for building `ContainerEnvironment`s locally without pushing to registry - [#514](https://github.com/PrefectHQ/prefect/issues/514)
- Make mapping more robust when running children tasks multiple times - [#541](https://github.com/PrefectHQ/prefect/pull/541)
- Always prefer `cached_inputs` over upstream states, if available - [#546](https://github.com/PrefectHQ/prefect/pull/546)
- Add hooks to `FlowRunner.initialize_run()` for manipulating task states and contexts - [#548](https://github.com/PrefectHQ/prefect/pull/548)
- Improve state-loading strategy for Prefect Cloud - [#555](https://github.com/PrefectHQ/prefect/issues/555)
- Introduce `on_failure` kwarg to Tasks and Flows for user-friendly failure callbacks - [#551](https://github.com/PrefectHQ/prefect/issues/551)
- Include `scheduled_start_time` in context for Flow runs - [#524](https://github.com/PrefectHQ/prefect/issues/524)
- Add GitHub PR template - [#542](https://github.com/PrefectHQ/prefect/pull/542)
- Allow flows to be deployed to Prefect Cloud without a project id - [#571](https://github.com/PrefectHQ/prefect/pull/571)
- Introduce serialization schemas for ResultHandlers - [#572](https://github.com/PrefectHQ/prefect/issues/572)
- Add new `metadata` attribute to States for managing user-generated results - [#573](https://github.com/PrefectHQ/prefect/issues/573)
- Add new 'JSONResultHandler' for serializing small bits of data without external storage - [#576](https://github.com/PrefectHQ/prefect/issues/576)
- Use `JSONResultHandler` for all Parameter caching - [#590](https://github.com/PrefectHQ/prefect/pull/590)

### Fixes

- Fixed `flow.deploy()` attempting to access a nonexistent string attribute - [#503](https://github.com/PrefectHQ/prefect/pull/503)
- Ensure all logs make it to the logger service in deployment - [#508](https://github.com/PrefectHQ/prefect/issues/508), [#552](https://github.com/PrefectHQ/prefect/issues/552)
- Fix a situation where `Paused` tasks would be treated as `Pending` and run - [#535](https://github.com/PrefectHQ/prefect/pull/535)
- Ensure errors raised in state handlers are trapped appropriately in Cloud Runners - [#554](https://github.com/PrefectHQ/prefect/pull/554)
- Ensure unexpected errors raised in FlowRunners are robustly handled - [#568](https://github.com/PrefectHQ/prefect/pull/568)
- Fixed non-deterministic errors in mapping caused by clients resolving futures of other clients - [#569](https://github.com/PrefectHQ/prefect/pull/569)
- Older versions of Prefect will now ignore fields added by newer versions when deserializing objects - [#583](https://github.com/PrefectHQ/prefect/pull/583)
- Result handler failures now result in clear task run failures - [#575](https://github.com/PrefectHQ/prefect/issues/575)
- Fix issue deserializing old states with empty metadata - [#590](https://github.com/PrefectHQ/prefect/pull/590)
- Fix issue serializing `cached_inputs` - [#594](https://github.com/PrefectHQ/prefect/pull/594)

### Breaking Changes

- Move `prefect.client.result_handlers` to `prefect.engine.result_handlers` - [#512](https://github.com/PrefectHQ/prefect/pull/512)
- Removed `inputs` kwarg from `TaskRunner.run()` - [#546](https://github.com/PrefectHQ/prefect/pull/546)
- Moves the `start_task_ids` argument from `FlowRunner.run()` to `Environment.run()` - [#544](https://github.com/PrefectHQ/prefect/issues/544), [#545](https://github.com/PrefectHQ/prefect/pull/545)
- Convert `timeout` kwarg from `timedelta` to `integer` - [#540](https://github.com/PrefectHQ/prefect/issues/540)
- Remove `timeout` kwarg from `executor.wait` - [#569](https://github.com/PrefectHQ/prefect/pull/569)
- Serialization of States will _ignore_ any result data that hasn't been processed - [#581](https://github.com/PrefectHQ/prefect/pull/581)
- Removes `VersionedSchema` in favor of implicit versioning: serializers will ignore unknown fields and the `create_object` method is responsible for recreating missing ones - [#583](https://github.com/PrefectHQ/prefect/pull/583)
- Convert and rename `CachedState` to a successful state named `Cached`, and also remove the superfluous `cached_result` attribute - [#586](https://github.com/PrefectHQ/prefect/issues/586)
",139199684
1783,False,False,2019-01-08T16:06:26Z,2019-01-08T16:08:28Z,"
### Major Features

- Add support for Prefect Cloud - [#374](https://github.com/PrefectHQ/prefect/pull/374), [#406](https://github.com/PrefectHQ/prefect/pull/406), [#473](https://github.com/PrefectHQ/prefect/pull/473), [#491](https://github.com/PrefectHQ/prefect/pull/491)
- Add versioned serialization schemas for `Flow`, `Task`, `Parameter`, `Edge`, `State`, `Schedule`, and `Environment` objects - [#310](https://github.com/PrefectHQ/prefect/pull/310), [#318](https://github.com/PrefectHQ/prefect/pull/318), [#319](https://github.com/PrefectHQ/prefect/pull/319), [#340](https://github.com/PrefectHQ/prefect/pull/340)
- Add ability to provide `ResultHandler`s for storing private result data - [#391](https://github.com/PrefectHQ/prefect/pull/391), [#394](https://github.com/PrefectHQ/prefect/pull/394), [#430](https://github.com/PrefectHQ/prefect/pull/430/)
- Support depth-first execution of mapped tasks and tracking of both the static ""parent"" and dynamic ""children"" via `Mapped` states - [#485](https://github.com/PrefectHQ/prefect/pull/485)

### Minor Features

- Add new `TimedOut` state for task execution timeouts - [#255](https://github.com/PrefectHQ/prefect/issues/255)
- Use timezone-aware dates throughout Prefect - [#325](https://github.com/PrefectHQ/prefect/pull/325)
- Add `description` and `tags` arguments to `Parameters` - [#318](https://github.com/PrefectHQ/prefect/pull/318)
- Allow edge `key` checks to be skipped in order to create ""dummy"" flows from metadata - [#319](https://github.com/PrefectHQ/prefect/pull/319)
- Add new `names_only` keyword to `flow.parameters` - [#337](https://github.com/PrefectHQ/prefect/pull/337)
- Add utility for building GraphQL queries and simple schemas from Python objects - [#342](https://github.com/PrefectHQ/prefect/pull/342)
- Add links to downloadable Jupyter notebooks for all tutorials - [#212](https://github.com/PrefectHQ/prefect/issues/212)
- Add `to_dict` convenience method for `DotDict` class - [#341](https://github.com/PrefectHQ/prefect/issues/341)
- Refactor requirements to a custom `ini` file specification - [#347](https://github.com/PrefectHQ/prefect/pull/347)
- Refactor API documentation specification to `toml` file - [#361](https://github.com/PrefectHQ/prefect/pull/361)
- Add new SQLite tasks for basic SQL scripting and querying - [#291](https://github.com/PrefectHQ/prefect/issues/291)
- Executors now pass `map_index` into the `TaskRunner`s - [#373](https://github.com/PrefectHQ/prefect/pull/373)
- All schedules support `start_date` and `end_date` parameters - [#375](https://github.com/PrefectHQ/prefect/pull/375)
- Add `DateTime` marshmallow field for timezone-aware serialization - [#378](https://github.com/PrefectHQ/prefect/pull/378)
- Adds ability to put variables into context via the config - [#381](https://github.com/PrefectHQ/prefect/issues/381)
- Adds new `client.deploy` method for adding new flows to the Prefect Cloud - [#388](https://github.com/PrefectHQ/prefect/issues/388)
- Add `id` attribute to `Task` class - [#416](https://github.com/PrefectHQ/prefect/issues/416)
- Add new `Resume` state for resuming from `Paused` tasks - [#435](https://github.com/PrefectHQ/prefect/issues/435)
- Add support for heartbeats - [#436](https://github.com/PrefectHQ/prefect/issues/436)
- Add new `Submitted` state for signaling that `Scheduled` tasks have been handled - [#445](https://github.com/PrefectHQ/prefect/issues/445)
- Add ability to add custom environment variables and copy local files into `ContainerEnvironment`s - [#453](https://github.com/PrefectHQ/prefect/issues/453)
- Add `set_secret` method to Client for creating and setting the values of user secrets - [#452](https://github.com/PrefectHQ/prefect/issues/452)
- Refactor runners into `CloudTaskRunner` and `CloudFlowRunner` classes - [#431](https://github.com/PrefectHQ/prefect/issues/431)
- Added functions for loading default `engine` classes from config - [#477](https://github.com/PrefectHQ/prefect/pull/477)

### Fixes

- Fixed issue with `GraphQLResult` reprs - [#374](https://github.com/PrefectHQ/prefect/pull/374)
- `CronSchedule` produces expected results across daylight savings time transitions - [#375](https://github.com/PrefectHQ/prefect/pull/375)
- `utilities.serialization.Nested` properly respects `marshmallow.missing` values - [#398](https://github.com/PrefectHQ/prefect/pull/398)
- Fixed issue in capturing unexpected mapping errors during task runs - [#409](https://github.com/PrefectHQ/prefect/pull/409)
- Fixed issue in `flow.visualize()` so that mapped flow states can be passed and colored - [#387](https://github.com/PrefectHQ/prefect/issues/387)
- Fixed issue where `IntervalSchedule` was serialized at ""second"" resolution, not lower - [#427](https://github.com/PrefectHQ/prefect/pull/427)
- Fixed issue where `SKIP` signals were preventing multiple layers of mapping - [#455](https://github.com/PrefectHQ/prefect/issues/455)
- Fixed issue with multi-layer mapping in `flow.visualize()` - [#454](https://github.com/PrefectHQ/prefect/issues/454)
- Fixed issue where Prefect Cloud `cached_inputs` weren't being used locally - [#434](https://github.com/PrefectHQ/prefect/issues/434)
- Fixed issue where `Config.set_nested` would have an error if the provided key was nested deeper than an existing terminal key - [#479](https://github.com/PrefectHQ/prefect/pull/479)
- Fixed issue where `state_handlers` were not called for certain signals - [#494](https://github.com/PrefectHQ/prefect/pull/494)

### Breaking Changes

- Remove `NoSchedule` and `DateSchedule` schedule classes - [#324](https://github.com/PrefectHQ/prefect/pull/324)
- Change `serialize()` method to use schemas rather than custom dict - [#318](https://github.com/PrefectHQ/prefect/pull/318)
- Remove `timestamp` property from `State` classes - [#305](https://github.com/PrefectHQ/prefect/pull/305)
- Remove the custom JSON encoder library at `prefect.utilities.json` - [#336](https://github.com/PrefectHQ/prefect/pull/336)
- `flow.parameters` now returns a set of parameters instead of a dictionary - [#337](https://github.com/PrefectHQ/prefect/pull/337)
- Renamed `to_dotdict` -> `as_nested_dict` - [#339](https://github.com/PrefectHQ/prefect/pull/339)
- Moved `prefect.utilities.collections.GraphQLResult` to `prefect.utilities.graphql.GraphQLResult` - [#371](https://github.com/PrefectHQ/prefect/pull/371)
- `SynchronousExecutor` now does _not_ do depth first execution for mapped tasks - [#373](https://github.com/PrefectHQ/prefect/pull/373)
- Renamed `prefect.utilities.serialization.JSONField` -> `JSONCompatible`, removed its `max_size` feature, and no longer automatically serialize payloads as strings - [#376](https://github.com/PrefectHQ/prefect/pull/376)
- Renamed `prefect.utilities.serialization.NestedField` -> `Nested` - [#376](https://github.com/PrefectHQ/prefect/pull/376)
- Renamed `prefect.utilities.serialization.NestedField.dump_fn` -> `NestedField.value_selection_fn` for clarity - [#377](https://github.com/PrefectHQ/prefect/pull/377)
- Local secrets are now pulled from `secrets` in context instead of `_secrets` - [#382](https://github.com/PrefectHQ/prefect/pull/382)
- Remove Task and Flow descriptions, Flow project & version attributes - [#383](https://github.com/PrefectHQ/prefect/issues/383)
- Changed `Schedule` parameter from `on_or_after` to `after` - [#396](https://github.com/PrefectHQ/prefect/issues/396)
- Environments are immutable and return `dict` keys instead of `str`; some arguments for `ContainerEnvironment` are removed - [#398](https://github.com/PrefectHQ/prefect/pull/398)
- `environment.run()` and `environment.build()`; removed the `flows` CLI and replaced it with a top-level CLI command, `prefect run` - [#400](https://github.com/PrefectHQ/prefect/pull/400)
- The `set_temporary_config` utility now accepts a single dict of multiple config values, instead of just a key/value pair, and is located in `utilities.configuration` - [#401](https://github.com/PrefectHQ/prefect/pull/401)
- Bump `click` requirement to 7.0, which changes underscores to hyphens at CLI - [#409](https://github.com/PrefectHQ/prefect/pull/409)
- `IntervalSchedule` rejects intervals of less than one minute - [#427](https://github.com/PrefectHQ/prefect/pull/427)
- `FlowRunner` returns a `Running` state, not a `Pending` state, when flows do not finish - [#433](https://github.com/PrefectHQ/prefect/pull/433)
- Remove the `task_contexts` argument from `FlowRunner.run()` - [#440](https://github.com/PrefectHQ/prefect/pull/440)
- Remove the leading underscore from Prefect-set context keys - [#446](https://github.com/PrefectHQ/prefect/pull/446)
- Removed throttling tasks within the local cluster - [#470](https://github.com/PrefectHQ/prefect/pull/470)
- Even `start_tasks` will not run before their state's `start_time` (if the state is `Scheduled`) - [#474](https://github.com/PrefectHQ/prefect/pull/474)
- `DaskExecutor`'s ""processes"" keyword argument was renamed ""local_processes"" - [#477](https://github.com/PrefectHQ/prefect/pull/477)
- Removed the `mapped` and `map_index` kwargs from `TaskRunner.run()`. These values are now inferred automatically - [#485](https://github.com/PrefectHQ/prefect/pull/485)
- The `upstream_states` dictionary used by the Runners only includes `State` values, not lists of `States`. The use case that required lists of `States` is now covered by the `Mapped` state. - [#485](https://github.com/PrefectHQ/prefect/pull/485)
",139199684
1784,False,False,2018-10-30T16:20:28Z,2018-10-30T16:22:31Z,"

### Major Features

- Refactor `FlowRunner` and `TaskRunner` into a modular `Runner` pipelines - [#260](https://github.com/PrefectHQ/prefect/pull/260), [#267](https://github.com/PrefectHQ/prefect/pull/267)
- Add configurable `state_handlers` for `FlowRunners`, `Flows`, `TaskRunners`, and `Tasks` - [#264](https://github.com/PrefectHQ/prefect/pull/264), [#267](https://github.com/PrefectHQ/prefect/pull/267)
- Add gmail and slack notification state handlers w/ tutorial - [#274](https://github.com/PrefectHQ/prefect/pull/274), [#294](https://github.com/PrefectHQ/prefect/pull/294)

### Minor Features

- Add a new method `flow.get_tasks()` for easily filtering flow tasks by attribute - [#242](https://github.com/PrefectHQ/prefect/pull/242)
- Add new `JinjaTemplateTask` for easily rendering jinja templates - [#200](https://github.com/PrefectHQ/prefect/issues/200)
- Add new `PAUSE` signal for halting task execution - [#246](https://github.com/PrefectHQ/prefect/pull/246)
- Add new `Paused` state corresponding to `PAUSE` signal, and new `pause_task` utility - [#251](https://github.com/PrefectHQ/prefect/issues/251)
- Add ability to timeout task execution for all executors except `DaskExecutor(processes=True)` - [#240](https://github.com/PrefectHQ/prefect/issues/240)
- Add explicit unit test to check Black formatting (Python 3.6+) - [#261](https://github.com/PrefectHQ/prefect/pull/261)
- Add ability to set local secrets in user config file - [#231](https://github.com/PrefectHQ/prefect/issues/231), [#274](https://github.com/PrefectHQ/prefect/pull/274)
- Add `is_skipped()` and `is_scheduled()` methods for `State` objects - [#266](https://github.com/PrefectHQ/prefect/pull/266), [#278](https://github.com/PrefectHQ/prefect/pull/278)
- Adds `now()` as a default `start_time` for `Scheduled` states - [#278](https://github.com/PrefectHQ/prefect/pull/278)
- `Signal` classes now pass arguments to underlying `State` objects - [#279](https://github.com/PrefectHQ/prefect/pull/279)
- Run counts are tracked via `Retrying` states - [#281](https://github.com/PrefectHQ/prefect/pull/281)

### Fixes

- Flow consistently raises if passed a parameter that doesn't exist - [#149](https://github.com/PrefectHQ/prefect/issues/149)

### Breaking Changes

- Renamed `scheduled_time` -> `start_time` in `Scheduled` state objects - [#278](https://github.com/PrefectHQ/prefect/pull/278)
- `TaskRunner.check_for_retry` no longer checks for `Retry` states without `start_time` set - [#278](https://github.com/PrefectHQ/prefect/pull/278)
- Swapped the position of `result` and `message` attributes in State initializations, and started storing caught exceptions as results - [#283](https://github.com/PrefectHQ/prefect/issues/283)
",139199684
1785,False,False,2018-10-01T18:15:55Z,2018-10-02T19:36:28Z,"### Major Features

- Local parallelism with `DaskExecutor` - [#151](https://github.com/PrefectHQ/prefect/issues/151), [#186](https://github.com/PrefectHQ/prefect/issues/186)
- Resource throttling based on `tags` - [#158](https://github.com/PrefectHQ/prefect/issues/158), [#186](https://github.com/PrefectHQ/prefect/issues/186)
- `Task.map` for mapping tasks - [#186](https://github.com/PrefectHQ/prefect/issues/186)
- Added `AirFlow` utility for importing Airflow DAGs as Prefect Flows - [#232](https://github.com/PrefectHQ/prefect/pull/232)

### Minor Features

- Use Netlify to deploy docs - [#156](https://github.com/prefecthq/prefect/issues/156)
- Add changelog - [#153](https://github.com/prefecthq/prefect/issues/153)
- Add `ShellTask` - [#150](https://github.com/prefecthq/prefect/issues/150)
- Base `Task` class can now be run as a dummy task - [#191](https://github.com/PrefectHQ/prefect/pull/191)
- New `return_failed` keyword to `flow.run()` for returning failed tasks - [#205](https://github.com/PrefectHQ/prefect/pull/205)
- some minor changes to `flow.visualize()` for visualizing mapped tasks and coloring nodes by state - [#202](https://github.com/PrefectHQ/prefect/issues/202)
- Added new `flow.replace()` method for swapping out tasks within flows - [#230](https://github.com/PrefectHQ/prefect/pull/230)
- Add `debug` kwarg to `DaskExecutor` for optionally silencing dask logs - [#209](https://github.com/PrefectHQ/prefect/issues/209)
- Update `BokehRunner` for visualizing mapped tasks - [#220](https://github.com/PrefectHQ/prefect/issues/220)
- Env var configuration settings are typed - [#204](https://github.com/PrefectHQ/prefect/pull/204)
- Implement `map` functionality for the `LocalExecutor` - [#233](https://github.com/PrefectHQ/prefect/issues/233)

### Fixes

- Fix issue with Versioneer not picking up git tags - [#146](https://github.com/prefecthq/prefect/issues/146)
- `DotDicts` can have non-string keys - [#193](https://github.com/prefecthq/prefect/issues/193)
- Fix unexpected behavior in assigning tags using contextmanagers - [#190](https://github.com/PrefectHQ/prefect/issues/190)
- Fix bug in initialization of Flows with only `edges` - [#225](https://github.com/PrefectHQ/prefect/pull/225)
- Remove ""bottleneck"" when creating pipelines of mapped tasks - [#224](https://github.com/PrefectHQ/prefect/pull/224)

### Breaking Changes

- Runner refactor - [#221](https://github.com/PrefectHQ/prefect/pull/221)
- Cleaned up signatures of `TaskRunner` methods - [#171](https://github.com/prefecthq/prefect/issues/171)
- Locally, Python 3.4 users can not run the more advanced parallel executors (`DaskExecutor`) [#186](https://github.com/PrefectHQ/prefect/issues/186)
",139199684
1786,False,False,2018-09-06T16:49:52Z,2018-09-06T16:52:05Z,"### Major Features

- Support for user configuration files - [#195](https://github.com/PrefectHQ/prefect/pull/195)

### Minor Features

- None

### Fixes

- Let DotDicts accept non-string keys - [#193](https://github.com/PrefectHQ/prefect/pull/193), [#194](https://github.com/PrefectHQ/prefect/pull/194)

### Breaking Changes

- None",139199684
1787,False,False,2018-08-19T23:17:37Z,2018-08-20T14:09:55Z,"
### Major Features

- BokehRunner - [#104](https://github.com/prefecthq/prefect/issues/104), [#128](https://github.com/prefecthq/prefect/issues/128)
- Control flow: `ifelse`, `switch`, and `merge` - [#92](https://github.com/prefecthq/prefect/issues/92)
- Set state from `reference_tasks` - [#95](https://github.com/prefecthq/prefect/issues/95), [#137](https://github.com/prefecthq/prefect/issues/137)
- Add flow `Registry` - [#90](https://github.com/prefecthq/prefect/issues/90)
- Output caching with various `cache_validators` - [#84](https://github.com/prefecthq/prefect/issues/84), [#107](https://github.com/prefecthq/prefect/issues/107)
- Dask executor - [#82](https://github.com/prefecthq/prefect/issues/82), [#86](https://github.com/prefecthq/prefect/issues/86)
- Automatic input caching for retries, manual-only triggers - [#78](https://github.com/prefecthq/prefect/issues/78)
- Functional API for `Flow` definition
- `State` classes
- `Signals` to transmit `State`

### Minor Features

- Add custom syntax highlighting to docs - [#141](https://github.com/prefecthq/prefect/issues/141)
- Add `bind()` method for tasks to call without copying - [#132](https://github.com/prefecthq/prefect/issues/132)
- Cache expensive flow graph methods - [#125](https://github.com/prefecthq/prefect/issues/125)
- Docker environments - [#71](https://github.com/prefecthq/prefect/issues/71)
- Automatic versioning via Versioneer - [#70](https://github.com/prefecthq/prefect/issues/70)
- `TriggerFail` state - [#67](https://github.com/prefecthq/prefect/issues/67)
- State classes - [#59](https://github.com/prefecthq/prefect/issues/59)

### Fixes

- None

### Breaking Changes

- None
",139199684
1788,False,False,2020-01-08T23:33:05Z,2020-01-08T23:38:01Z,"First release of the year! Also the first release in a while to add a new module, `pathutils`!

* New module [pathutils][pathutils]:
    * [pathutils.augpath][pathutils.augpath] augments a path by modifying its components
    * [pathutils.shrinkuser][pathutils.shrinkuser] inverts :func:`os.path.expanduser`.
    * [pathutils.expandpath][pathutils.expandpath] shell-like environ and tilde expansion
* add `include_dirs` param to [fileutils.iter_find_files][fileutils.iter_find_files]
* Make [funcutils.format_invocation][funcutils.format_invocation] more deterministic
* add [strutils.unwrap_text][strutils.unwrap_text] which does what you think to wrapped text
* Py3 fixes
    * [iterutils.chunked][iterutils.chunked] to work with the `bytes` type ([#231][i231])
    * [cacheutils.ThresholdCounter][cacheutils.ThresholdCounter]'s `get_common_count()`

[i231]: https://github.com/mahmoud/boltons/issues/231
[pathutils]: https://boltons.readthedocs.io/en/latest/pathutils.html
[pathutils.augpath]: https://boltons.readthedocs.io/en/latest/pathutils.html#boltons.pathutils.augpath
[pathutils.augpath]: https://boltons.readthedocs.io/en/latest/pathutils.html#boltons.pathutils.augpath
[pathutils.shrinkuser]: https://boltons.readthedocs.io/en/latest/pathutils.html#boltons.pathutils.shrinkuser
[pathutils.expandpath]: https://boltons.readthedocs.io/en/latest/pathutils.html#boltons.pathutils.expandpath
[strutils.unwrap_text]: https://boltons.readthedocs.io/en/latest/strutils.html#boltons.strutils.unwrap_text
[fileutils.iter_find_files]: http://boltons.readthedocs.org/en/latest/fileutils.html#boltons.fileutils.iter_find_files                  
[funcutils.format_invocation]: https://boltons.readthedocs.io/en/latest/funcutils.html#boltons.funcutils.format_invocation              
[iterutils.chunked]: http://boltons.readthedocs.org/en/latest/iterutils.html#boltons.iterutils.chunked                                  
[cacheutils.ThresholdCounter]: http://boltons.readthedocs.org/en/latest/cacheutils.html#boltons.cacheutils.ThresholdCounter             

**[See complete details for in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md)**

",8307391
1789,False,False,2019-10-29T05:49:27Z,2019-10-29T05:51:32Z,"* [funcutils.format_invocation][funcutils.format_invocation] for formatting simple function calls like `func(pos1, pos2, kw_k=kw_v)`
* [funcutils.format_exp_repr][funcutils.format_exp_repr] for formatting a repr like `Type(pos, kw_k=kw_v)`
* [funcutils.format_nonexp_repr][funcutils.format_nonexp_repr] for formatting a repr like `<Type k=v>`

[funcutils.format_invocation]: https://boltons.readthedocs.io/en/latest/funcutils.html#boltons.funcutils.format_invocation
[funcutils.format_exp_repr]: https://boltons.readthedocs.io/en/latest/funcutils.html#boltons.funcutils.format_exp_repr
[funcutils.format_nonexp_repr]: https://boltons.readthedocs.io/en/latest/funcutils.html#boltons.funcutils.format_nonexp_rep

**[See complete details for 19.3.0 in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1930)**",8307391
1790,False,False,2019-10-19T22:54:16Z,2019-10-19T23:05:46Z,"A few small fixes and enhancements.

**[See complete details for 19.2.0 in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1920)**",8307391
1791,False,False,2019-02-28T08:13:10Z,2019-03-01T06:12:50Z,"A couple enhancements, a couple cleanups, across several modules.

**[See complete details for 19.1.0 in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1910)**",8307391
1792,False,False,2019-02-13T04:21:30Z,2019-03-01T06:12:01Z,"A quick enhancement for wraps/FunctionBuilder supporting type annotations

**[See complete details for 19.0.1 in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1901)**",8307391
1793,False,False,2019-02-11T07:05:22Z,2019-02-11T08:09:50Z,"Maybe the biggest boltons release yet. Several bugfixes, even more new features.

**[See the complete details of 19.0.0 in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1900)**",8307391
1794,False,False,2018-08-29T23:58:57Z,2019-02-11T08:08:39Z,"A few bugfixes and a handy text utility.

**[See complete details for 18.0.1 in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1801)**",8307391
1795,False,False,2018-03-02T08:13:06Z,2019-02-11T08:07:29Z,**[See complete release details in the CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1800)**,8307391
1796,False,False,2017-12-16T07:39:30Z,2019-02-11T08:06:24Z,"*(December 16, 2017)*

A big release with a lot of features and bugfixes, big and small. Just
in time for the holidays!

**[See all the details here!](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1720)**",8307391
1797,False,False,2017-02-27T09:25:54Z,2019-02-11T08:04:18Z,"*(February 27, 2017)*

Add urlutils module, with URL type and find_all_links function. also
update Sentinel for Python 3 falsiness

* Add urlutils module, complete with RFC3986-compliant `URL` type
* Also add `urlutils.find_all_links` function, which heuristically
  finds all links in plaintext, and creates URLs out of them.
* Update typeutils.Sentinel to be appropriately falsy on Python 3",8307391
1798,False,False,2017-01-25T06:59:20Z,2017-01-25T07:15:12Z,"Several tweaks and enhancements to ring in the new year. [Changelog here](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md#1700).
",8307391
1799,False,False,2016-11-06T07:00:08Z,2017-01-25T07:12:46Z,"Mostly bug fixes and various tweaks, optimizations, and documentation. Also added a bit of functionality in the form of ioutils and GUID stuff.
",8307391
1800,False,False,2016-07-19T07:30:48Z,2017-01-25T07:11:59Z,"A few minor changes and a medium-sized breaking change to cacheutils.
",8307391
1801,False,False,2016-06-12T22:14:06Z,2016-06-12T22:17:37Z,"This release primarily contains several statsutils updates, mostly the addition of histogram computation and display. See the [CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md) for details.
",8307391
1802,False,False,2016-06-08T09:57:10Z,2016-06-12T22:16:51Z,"another significant release, thanks to the addition of funcutils.wraps and funcutils.FunctionBuilder. also iterutils.chunked speedup, and tbutils.ParsedException.to_string. See [CHANGELOG](https://github.com/mahmoud/boltons/blob/master/CHANGELOG.md) for details.
",8307391
1803,False,False,2016-05-23T17:00:54Z,2016-06-08T00:00:20Z,"big big update. 

ecoutils, debugutils.wrap_trace preview, timeutils.strpdate, timeutils.daterange, a few socketutils bugs/platform tweaks, statsutils.Stats improvements (esp. describe), strutils.parse_/format_int_list, cacheutils.cachedproperty, and cacheutils.cachedmethod
",8307391
1804,False,False,2016-05-24T17:06:26Z,2016-06-07T23:58:33Z,"a couple of follow-on ecoutils updates (and improved docs)
",8307391
1805,False,False,2016-05-03T08:23:08Z,2016-05-03T16:29:23Z,,8307391
